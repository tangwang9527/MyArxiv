{"2026-02-20T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2602.18429v1","updated":"2026-02-20T18:53:07Z","published":"2026-02-20T18:53:07Z","title":"VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning","summary":"Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.","authors":["Harshul Raj Surana","Arijit Maji","Aryan Vats","Akash Ghosh","Sriparna Saha","Amit Sheth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18425v1","updated":"2026-02-20T18:48:05Z","published":"2026-02-20T18:48:05Z","title":"RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering","summary":"Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.","authors":["Deniz Qian","Hung-Ting Chen","Eunsol Choi"],"pdf_url":"","comment":"18 pages, 12 figures, 12 tables"},{"id":"http://arxiv.org/abs/2602.18420v1","updated":"2026-02-20T18:44:16Z","published":"2026-02-20T18:44:16Z","title":"SPQ: An Ensemble Technique for Large Language Model Compression","summary":"This study presents an ensemble technique, SPQ (SVD-Pruning-Quantization), for large language model (LLM) compression that combines variance-retained singular value decomposition (SVD), activation-based pruning, and post-training linear quantization. Each component targets a different source of inefficiency: i) pruning removes redundant neurons in MLP layers, ii) SVD reduces attention projections into compact low-rank factors, iii) and 8-bit quantization uniformly compresses all linear layers. At matched compression ratios, SPQ outperforms individual methods (SVD-only, pruning-only, or quantization-only) in perplexity, demonstrating the benefit of combining complementary techniques. Applied to LLaMA-2-7B, SPQ achieves up to 75% memory reduction while maintaining or improving perplexity (e.g., WikiText-2 5.47 to 4.91) and preserving accuracy on downstream benchmarks such as C4, TruthfulQA, and GSM8K. Compared to strong baselines like GPTQ and SparseGPT, SPQ offers competitive perplexity and accuracy while using less memory (6.86 GB vs. 7.16 GB for GPTQ). Moreover, SPQ improves inference throughput over GPTQ, achieving up to a 1.9x speedup, which further enhances its practicality for real-world deployment. The effectiveness of SPQ's robust compression through layer-aware and complementary compression techniques may provide practical deployment of LLMs in memory-constrained environments. Code is available at: https://github.com/JiaminYao/SPQ_LLM_Compression/","authors":["Jiamin Yao","Eren Gultepe"],"pdf_url":"","comment":"Accepted to LREC 2026 Main Conference"},{"id":"http://arxiv.org/abs/2602.18417v1","updated":"2026-02-20T18:35:43Z","published":"2026-02-20T18:35:43Z","title":"Subgroups of $U(d)$ Induce Natural RNN and Transformer Architectures","summary":"This paper presents a direct framework for sequence models with hidden states on closed subgroups of U(d). We use a minimal axiomatic setup and derive recurrent and transformer templates from a shared skeleton in which subgroup choice acts as a drop-in replacement for state space, tangent projection, and update map. We then specialize to O(d) and evaluate orthogonal-state RNN and transformer models on Tiny Shakespeare and Penn Treebank under parameter-matched settings. We also report a general linear-mixing extension in tangent space, which applies across subgroup choices and improves finite-budget performance in the current O(d) experiments.","authors":["Joshua Nunley"],"pdf_url":"","comment":"12 pages, 3 figures, 8 tables"},{"id":"http://arxiv.org/abs/2504.21022v2","updated":"2026-02-20T17:50:01Z","published":"2025-04-22T20:32:34Z","title":"ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees","summary":"Linear Temporal Logic (LTL) is a widely used task specification language for autonomous systems. To mitigate the significant manual effort and expertise required to define LTL-encoded tasks, several methods have been proposed for translating Natural Language (NL) instructions into LTL formulas, which, however, lack correctness guarantees. To address this, we propose a new NL-to-LTL translation method, called ConformalNL2LTL that achieves user-defined translation success rates on unseen NL commands. Our method constructs LTL formulas iteratively by solving a sequence of open-vocabulary question-answering (QA) problems using large language models (LLMs). These QA tasks are handled collaboratively by a primary and an auxiliary model. The primary model answers each QA instance while quantifying uncertainty via conformal prediction; when it is insufficiently certain according to user-defined confidence thresholds, it requests assistance from the auxiliary model and, if necessary, from the user. We demonstrate theoretically and empirically that ConformalNL2LTL achieves the desired translation accuracy while minimizing user intervention.","authors":["David Smith Sundarsingh","Jun Wang","Jyotirmoy V. Deshmukh","Yiannis Kantaros"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11409v3","updated":"2026-02-20T17:09:35Z","published":"2025-05-16T16:17:22Z","title":"Visual Planning: Let's Think Only with Images","summary":"Recent advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have substantially enhanced machine reasoning across diverse tasks. However, these models predominantly rely on pure text as the medium for both expressing and structuring reasoning, even when visual information is present. In this work, we argue that language may not always be the most natural or effective modality for reasoning, particularly in tasks involving spatial and geometrical information. Motivated by this, we propose a new paradigm, Visual Planning, which enables planning through purely visual representations for these \"vision-first\" tasks, as a supplementary channel to language-based reasoning. In this paradigm, planning is executed via sequences of images that encode step-by-step inference in the visual domain, akin to how humans sketch or visualize future actions. We introduce a novel reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), empowered by GRPO for post-training large vision models, leading to substantial improvements in planning in a selection of representative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our visual planning paradigm outperforms all other planning variants that conduct reasoning in the text-only space. Our results establish Visual Planning as a viable and promising supplement to language-based reasoning, opening new avenues for tasks that benefit from intuitive, image-based inference.","authors":["Yi Xu","Chengzu Li","Han Zhou","Xingchen Wan","Caiqi Zhang","Anna Korhonen","Ivan Vulić"],"pdf_url":"","comment":"ICLR 2026 (Oral)"},{"id":"http://arxiv.org/abs/2602.18351v1","updated":"2026-02-20T17:03:44Z","published":"2026-02-20T17:03:44Z","title":"Validating Political Position Predictions of Arguments","summary":"Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \\textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.","authors":["Jordan Robinson","Angus R. Williams","Katie Atkinson","Anthony G. Cohn"],"pdf_url":"","comment":"13 pages, 6 figures, 6 tables. Under review"},{"id":"http://arxiv.org/abs/2602.18346v1","updated":"2026-02-20T16:57:44Z","published":"2026-02-20T16:57:44Z","title":"Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System","summary":"In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.","authors":["Pavithra PM Nair","Preethu Rose Anish"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18333v1","updated":"2026-02-20T16:39:07Z","published":"2026-02-20T16:39:07Z","title":"On the \"Induction Bias\" in Sequence Models","summary":"Despite the remarkable practical success of transformer-based language models, recent work has raised concerns about their ability to perform state tracking. In particular, a growing body of literature has shown this limitation primarily through failures in out-of-distribution (OOD) generalization, such as length extrapolation. In this work, we shift attention to the in-distribution implications of these limitations. We conduct a large-scale experimental study of the data efficiency of transformers and recurrent neural networks (RNNs) across multiple supervision regimes. We find that the amount of training data required by transformers grows much more rapidly with state-space size and sequence length than for RNNs. Furthermore, we analyze the extent to which learned state-tracking mechanisms are shared across different sequence lengths. We show that transformers exhibit negligible or even detrimental weight sharing across lengths, indicating that they learn length-specific solutions in isolation. In contrast, recurrent models exhibit effective amortized learning by sharing weights across lengths, allowing data from one sequence length to improve performance on others. Together, these results demonstrate that state tracking remains a fundamental challenge for transformers, even when training and evaluation distributions match.","authors":["M. Reza Ebrahimi","Michaël Defferrard","Sunny Panchal","Roland Memisevic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18326v1","updated":"2026-02-20T16:32:14Z","published":"2026-02-20T16:32:14Z","title":"Predicting Contextual Informativeness for Vocabulary Learning using Deep Learning","summary":"We describe a modern deep learning system that automatically identifies informative contextual examples (\\qu{contexts}) for first language vocabulary instruction for high school student. Our paper compares three modeling approaches: (i) an unsupervised similarity-based strategy using MPNet's uniformly contextualized embeddings, (ii) a supervised framework built on instruction-aware, fine-tuned Qwen3 embeddings with a nonlinear regression head and (iii) model (ii) plus handcrafted context features. We introduce a novel metric called the Retention Competency Curve to visualize trade-offs between the discarded proportion of good contexts and the \\qu{good-to-bad} contexts ratio providing a compact, unified lens on model performance. Model (iii) delivers the most dramatic gains with performance of a good-to-bad ratio of 440 all while only throwing out 70\\% of the good contexts. In summary, we demonstrate that a modern embedding model on neural network architecture, when guided by human supervision, results in a low-cost large supply of near-perfect contexts for teaching vocabulary for a variety of target words.","authors":["Tao Wu","Adam Kapelner"],"pdf_url":"","comment":"8 pages, 3 figures, 4 tables"},{"id":"http://arxiv.org/abs/2602.18324v1","updated":"2026-02-20T16:24:23Z","published":"2026-02-20T16:24:23Z","title":"PsihoRo: Depression and Anxiety Romanian Text Corpus","summary":"Psychological corpora in NLP are collections of texts used to analyze human psychology, emotions, and mental health. These texts allow researchers to study psychological constructs, detect mental health issues and analyze emotional language. However, mental health data can be difficult to collect correctly from social media, due to suppositions made by the collectors. A more pragmatic strategy involves gathering data through open-ended questions and then assessing this information with self-report screening surveys. This method was employed successfully for English, a language with a lot of psychological NLP resources. However, this cannot be stated for Romanian, which currently has no open-source mental health corpus. To address this gap, we have created the first corpus for depression and anxiety in Romanian, by utilizing a form with 6 open-ended questions along with the standardized PHQ-9 and GAD-7 screening questionnaires. Consisting of the texts of 205 respondents and although it may seem small, PsihoRo is a first step towards understanding and analyzing texts regarding the mental health of the Romanian population. We employ statistical analysis, text analysis using Romanian LIWC, emotion detection and topic modeling to show what are the most important features of this newly introduced resource to the NLP community.","authors":["Alexandra Ciobotaru","Ana-Maria Bucur","Liviu P. Dinu"],"pdf_url":"","comment":"This article was accepted at LREC 2026"},{"id":"http://arxiv.org/abs/2510.27512v2","updated":"2026-02-20T16:09:04Z","published":"2025-10-31T14:38:27Z","title":"When Distributions Shifts: Causal Generalization for Low-Resource Languages","summary":"Machine learning models often fail under distribution shifts, a problem exacerbated in low-resource settings where limited data restricts robust generalization. Domain generalization(DG) methods address this challenge by learning representations that remain invariant across domains, frequently leveraging causal principles. In this work, we study two causal DG approaches for low-resource natural language processing. First, we apply causal data augmentation using GPT-4o-mini to generate counterfactual paraphrases for sentiment classification on the NaijaSenti Twitter corpus in Yoruba and Igbo. Second, we investigate invariant causal representation learning with the Debiasing in Aspect Review (DINER) framework for aspect-based sentiment analysis. We extend DINER to a multilingual setting by introducing Afri-SemEval, a dataset of 17 languages translated from SemEval-2014 Task. Experiments show improved robustness to unseen domains, with consistent gains from counterfactual augmentation and enhanced out-of-distribution performance from causal representation learning across multiple languages.","authors":["Mahi Aliyu Aminu","Chisom Chibuike","Fatimo Adebanjo","Omokolade Awosanya","Samuel Oyeneye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18307v1","updated":"2026-02-20T16:05:06Z","published":"2026-02-20T16:05:06Z","title":"VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean","summary":"Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.","authors":["Yutong Xin","Qiaochu Chen","Greg Durrett","Işil Dillig"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18301v1","updated":"2026-02-20T15:54:10Z","published":"2026-02-20T15:54:10Z","title":"On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction","summary":"Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for \"imposing\" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.","authors":["Ivan Bondarenko","Egor Palkin","Fedor Tikunov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18297v1","updated":"2026-02-20T15:50:30Z","published":"2026-02-20T15:50:30Z","title":"Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory","summary":"Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.","authors":["Usman Anwar","Tim Bakker","Dana Kianfar","Cristina Pinneri","Christos Louizos"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2504.02922v4","updated":"2026-02-20T15:27:22Z","published":"2025-04-03T17:50:24Z","title":"Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning","summary":"Model diffing is the study of how fine-tuning changes a model's representations and internal algorithms. Many behaviors of interest are introduced during fine-tuning, and model diffing offers a promising lens to interpret such behaviors. Crosscoders are a recent model diffing method that learns a shared dictionary of interpretable concepts represented as latent directions in both the base and fine-tuned models, allowing us to track how concepts shift or emerge during fine-tuning. Notably, prior work has observed concepts with no direction in the base model, and it was hypothesized that these model-specific latents were concepts introduced during fine-tuning. However, we identify two issues which stem from the crosscoders L1 training loss that can misattribute concepts as unique to the fine-tuned model, when they really exist in both models. We develop Latent Scaling to flag these issues by more accurately measuring each latent's presence across models. In experiments comparing Gemma 2 2B base and chat models, we observe that the standard crosscoder suffers heavily from these issues. Building on these insights, we train a crosscoder with BatchTopK loss and show that it substantially mitigates these issues, finding more genuinely chat-specific and highly interpretable concepts. We recommend practitioners adopt similar techniques. Using the BatchTopK crosscoder, we successfully identify a set of chat-specific latents that are both interpretable and causally effective, representing concepts such as $\\textit{false information}$ and $\\textit{personal question}$, along with multiple refusal-related latents that show nuanced preferences for different refusal triggers. Overall, our work advances best practices for the crosscoder-based methodology for model diffing and demonstrates that it can provide concrete insights into how chat-tuning modifies model behavior.","authors":["Julian Minder","Clément Dumas","Caden Juang","Bilal Chugtai","Neel Nanda"],"pdf_url":"","comment":"51 pages, 33 figures, Accepted at 39th Conference on Neural Information Processing Systems (NeurIPS 2025)"},{"id":"http://arxiv.org/abs/2503.02003v5","updated":"2026-02-20T15:15:52Z","published":"2025-03-03T19:26:04Z","title":"HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs","summary":"An Achilles heel of Large Language Models (LLMs) is their tendency to hallucinate non-factual statements. A response mixed of factual and non-factual statements poses a challenge for humans to verify and accurately base their decisions on. To combat this problem, we propose Highlighted Chain-of-Thought Prompting (HoT), a technique for prompting LLMs to generate responses with XML tags that ground facts to those provided in the question. That is, given an input question, LLMs would first re-format the question to add XML tags highlighting key facts, and then, generate a response with highlights over the facts referenced from the input. Compared to vanilla chain of thought prompting (CoT), HoT reduces the rate of hallucination and separately improves LLM accuracy consistently on over 22 tasks from arithmetic, reading comprehension, to logical reasoning. When asking humans to verify LLM responses, highlights help time-limited participants to more accurately and efficiently recognize when LLMs are correct. Yet, surprisingly, when LLMs are wrong, HoTs tend to fool users into believing that an answer is correct.","authors":["Tin Nguyen","Logan Bolton","Mohammad Reza Taesiri","Trung Bui","Anh Totti Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.16552v3","updated":"2026-02-20T15:01:44Z","published":"2025-06-19T19:13:59Z","title":"Revela: Dense Retriever Learning via Language Modeling","summary":"Dense retrievers play a vital role in accessing external and specialized knowledge to augment language models (LMs). Training dense retrievers typically requires annotated query-document pairs, which are costly to create and scarce in specialized domains (e.g., code) or in complex settings (e.g., requiring reasoning). These practical challenges have sparked growing interest in self-supervised retriever learning. Since LMs are trained to capture token-level dependencies through a self-supervised learning objective (i.e., next token prediction), we can analogously cast retrieval as learning dependencies among chunks of tokens. This analogy naturally leads to the question: How can we adapt self-supervised learning objectives in the spirit of language modeling to train retrievers?\n  To answer this question, we introduce Revela, a unified and scalable training framework for self-supervised retriever learning via language modeling. Revela models semantic dependencies among documents by conditioning next token prediction on local and cross-document context through an in-batch attention mechanism. This attention is weighted by retriever-computed similarity scores, enabling the retriever to be optimized as part of language modeling. We evaluate Revela on domain-specific (CoIR), reasoning-intensive (BRIGHT), and general-domain (BEIR) benchmarks across various retriever backbones. Without annotated or synthetic query-document pairs, Revela surpasses larger supervised models and proprietary APIs on both CoIR and BRIGHT. It achieves BEIR's unsupervised SoTA with ~1000x less training data and 10x less compute. Performance increases with batch size and model size, highlighting Revela's scalability and its promise for self-supervised retriever learning.","authors":["Fengyu Cai","Tong Chen","Xinran Zhao","Sihao Chen","Hongming Zhang","Sherry Tongshuang Wu","Iryna Gurevych","Heinz Koeppl"],"pdf_url":"","comment":"Accepted to ICLR 2026 (Oral). Camera-ready version"},{"id":"http://arxiv.org/abs/2602.18262v1","updated":"2026-02-20T14:45:27Z","published":"2026-02-20T14:45:27Z","title":"Simplifying Outcomes of Language Model Component Analyses with ELIA","summary":"While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.","authors":["Aaron Louis Eidt","Nils Feldhus"],"pdf_url":"","comment":"EACL 2026 System Demonstrations. GitHub: https://github.com/aaron0eidt/ELIA"},{"id":"http://arxiv.org/abs/2510.21087v2","updated":"2026-02-20T14:43:20Z","published":"2025-10-24T02:00:16Z","title":"Designing and Evaluating Chain-of-Hints for Scientific Question Answering","summary":"LLMs are reshaping education, with students increasingly relying on them for learning. Implemented using general-purpose models, these systems are likely to give away the answers, potentially undermining conceptual understanding and critical thinking. Prior work shows that hints can effectively promote cognitive engagement. Building on this insight, we evaluate 18 open-source LLMs on chain-of-hints generation that scaffold users toward the correct answer. We compare two distinct hinting strategies: static hints, pre-generated for each problem, and dynamic hints, adapted to a learners' progress. We evaluate these systems on five pedagogically grounded automatic metrics for hint quality. Using the best performing LLM as the backbone of a quantitative study with 41 participants, we uncover distinct user preferences across hinting strategies, and identify the limitations of automatic evaluation metrics to capture them. Our findings highlight key design considerations for future research on tutoring systems and contribute toward the development of more learner-centered educational technologies.","authors":["Anubhav Jangra","Smaranda Muresan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17081v2","updated":"2026-02-20T14:29:15Z","published":"2025-11-21T09:37:16Z","title":"MUCH: A Multilingual Claim Hallucination Benchmark","summary":"Claim-level Uncertainty Quantification (UQ) is a promising approach to mitigate the lack of reliability in Large Language Models (LLMs). We introduce MUCH, the first claim-level UQ benchmark designed for fair and reproducible evaluation of future methods under realistic conditions. It includes 4,873 samples across four European languages (English, French, Spanish, and German) and four instruction-tuned open-weight LLMs. Unlike prior claim-level benchmarks, we release 24 generation logits per token, facilitating the development of future white-box methods without re-generating data. Moreover, in contrast to previous benchmarks that rely on manual or LLM-based segmentation, we propose a new deterministic algorithm capable of segmenting claims using as little as 0.2% of the LLM generation time. This makes our segmentation approach suitable for real-time monitoring of LLM outputs, ensuring that MUCH evaluates UQ methods under realistic deployment constraints. Finally, our evaluations show that current methods still have substantial room for improvement in both performance and efficiency.","authors":["Jérémie Dentan","Alexi Canesse","Davide Buscaldi","Aymen Shabou","Sonia Vanier"],"pdf_url":"","comment":"To appear in Proceedings of LREC 2026"},{"id":"http://arxiv.org/abs/2602.18232v1","updated":"2026-02-20T14:13:22Z","published":"2026-02-20T14:13:22Z","title":"Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning","summary":"Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.","authors":["Lexiang Tang","Weihao Gao","Bingchen Zhao","Lu Ma","Qiao jin","Bang Yang","Yuexian Zou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18217v1","updated":"2026-02-20T13:55:56Z","published":"2026-02-20T13:55:56Z","title":"Information-Theoretic Storage Cost in Sentence Comprehension","summary":"Real-time sentence comprehension imposes a significant load on working memory, as comprehenders must maintain contextual information to anticipate future input. While measures of such load have played an important role in psycholinguistic theories, they have been formalized, largely, using symbolic grammars, which assign discrete, uniform costs to syntactic predictions. This study proposes a measure of processing storage cost based on an information-theoretic formalization, as the amount of information previous words carry about future context, under uncertainty. Unlike previous discrete, grammar-based metrics, this measure is continuous, theory-neutral, and can be estimated from pre-trained neural language models. The validity of this approach is demonstrated through three analyses in English: our measure (i) recovers well-known processing asymmetries in center embeddings and relative clauses, (ii) correlates with a grammar-based storage cost in a syntactically-annotated corpus, and (iii) predicts reading-time variance in two large-scale naturalistic datasets over and above baseline models with traditional information-based predictors.","authors":["Kohei Kajikawa","Shinnosuke Isono","Ethan Gotlieb Wilcox"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.19605v4","updated":"2026-02-20T13:15:11Z","published":"2025-03-25T12:40:43Z","title":"Lean Formalization of Generalization Error Bound by Rademacher Complexity and Dudley's Entropy Integral","summary":"Understanding and certifying the generalization performance of machine learning algorithms -- i.e. obtaining theoretical estimates of the test error from a finite training sample -- is a central theme of statistical learning theory. Among the many complexity measures used to derive such guarantees, Rademacher complexity yields sharp, data-dependent bounds that apply well beyond classical $0$--$1$ classification. In this study, we formalize the generalization error bound by Rademacher complexity in Lean 4, building on measure-theoretic probability theory available in the Mathlib library. Our development provides a mechanically-checked pipeline from the definitions of empirical and expected Rademacher complexity, through a formal symmetrization argument and a bounded-differences analysis, to high-probability uniform deviation bounds via a formally proved McDiarmid inequality. A key technical contribution is a reusable mechanism for lifting results from countable hypothesis classes (where measurability of suprema is straightforward in Mathlib) to separable topological index sets via a reduction to a countable dense subset. As worked applications of the abstract theorem, we mechanize standard empirical Rademacher bounds for linear predictors under $\\ell_2$ and $\\ell_1$ regularization, and we also formalize a Dudley-type entropy integral bound based on covering numbers and a chaining construction.","authors":["Sho Sonoda","Kazumi Kasaura","Yuma Mizuno","Kei Tsukamoto","Naoto Onda"],"pdf_url":"","comment":"major updated: add L1-regularization and Dudley's entropy integral"},{"id":"http://arxiv.org/abs/2505.15050v5","updated":"2026-02-20T13:14:10Z","published":"2025-05-21T03:15:06Z","title":"Entailed Opinion Matters: Improving the Fact-Checking Performance of Language Models by Relying on their Entailment Ability","summary":"Automated fact-checking has been a challenging task for the research community. Prior work has explored various strategies, such as end-to-end training, retrieval-augmented generation, and prompt engineering, to build robust fact-checking systems. However, their accuracy has not been high enough for real-world deployment. We, on the other hand, propose a new learning paradigm, where evidence classification and entailed justifications made by generative language models (GLMs) are used to train encoder-only language models (ELMs). We conducted a rigorous set of experiments, comparing our approach with recent works along with various prompting and fine-tuning strategies. Additionally, we performed ablation studies, error analysis, quality analysis of model explanations, and a domain generalisation study to provide a comprehensive understanding of our approach.","authors":["Gaurav Kumar","Ayush Garg","Debajyoti Mazumder","Aditya Kishore","Babu kumar","Jasabanta Patro"],"pdf_url":"","comment":"22 pages"},{"id":"http://arxiv.org/abs/2512.01865v2","updated":"2026-02-20T13:12:14Z","published":"2025-12-01T16:48:05Z","title":"Cross-Lingual Interleaving for Speech Language Models","summary":"Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.","authors":["Adel Moumen","Guangzhi Sun","Philip C. Woodland"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.23951v2","updated":"2026-02-20T13:07:32Z","published":"2025-06-30T15:18:50Z","title":"Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders","summary":"Sparse Autoencoders (SAEs) have been successfully used to probe Large Language Models (LLMs) and extract interpretable concepts from their internal representations. These concepts are linear combinations of neuron activations that correspond to human-interpretable features. In this paper, we investigate the effectiveness of SAE-based explainability approaches for sentence classification, a domain where such methods have not been extensively explored. We present a novel SAE-based model ClassifSAE tailored for text classification, leveraging a specialized classifier head and incorporating an activation rate sparsity loss. We benchmark this architecture against established methods such as ConceptShap, Independent Component Analysis, HI-Concept and a standard TopK-SAE baseline. Our evaluation covers several classification benchmarks and backbone LLMs. We further enrich our analysis with two novel metrics for measuring the precision of concept-based explanations, using an external sentence encoder. Our empirical results show that ClassifSAE improves both the causality and interpretability of the extracted features.","authors":["Mathis Le Bail","Jérémie Dentan","Davide Buscaldi","Sonia Vanier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01916v2","updated":"2026-02-20T12:58:11Z","published":"2025-08-03T20:59:29Z","title":"Decomposing Representation Space into Interpretable Subspaces with Unsupervised Learning","summary":"Understanding internal representations of neural models is a core interest of mechanistic interpretability. Due to its large dimensionality, the representation space can encode various aspects about inputs. To what extent are different aspects organized and encoded in separate subspaces? Is it possible to find these ``natural'' subspaces in a purely unsupervised way? Somewhat surprisingly, we can indeed achieve this and find interpretable subspaces by a seemingly unrelated training objective. Our method, neighbor distance minimization (NDM), learns non-basis-aligned subspaces in an unsupervised manner. Qualitative analysis shows subspaces are interpretable in many cases, and encoded information in obtained subspaces tends to share the same abstract concept across different inputs, making such subspaces similar to ``variables'' used by the model. We also conduct quantitative experiments using known circuits in GPT-2; results show a strong connection between subspaces and circuit variables. We also provide evidence showing scalability to 2B models by finding separate subspaces mediating context and parametric knowledge routing. Viewed more broadly, our findings offer a new perspective on understanding model internals and building circuits.","authors":["Xinting Huang","Michael Hahn"],"pdf_url":"","comment":"Published as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2408.03099v2","updated":"2026-02-20T12:46:41Z","published":"2024-08-06T11:04:07Z","title":"Topic Modeling with Fine-tuning LLMs and Bag of Sentences","summary":"Large language models (LLMs) are increasingly used for topic modeling, outperforming classical topic models such as LDA. Commonly, pre-trained LLM encoders such as BERT are used out-of-the-box despite the fact that fine-tuning is known to improve LLMs considerably. The challenge lies in obtaining a suitable labeled dataset for fine-tuning. In this paper, we build on the recent idea of using bags of sentences as the elementary unit for computing topics. Based on this idea, we derive an approach called FT-Topic to perform unsupervised fine-tuning, relying primarily on two steps for constructing a training dataset in an automatic fashion. First, a heuristic method identifies pairs of sentence groups that are assumed to belong either to the same topic or to different topics. Second, we remove sentence pairs that are likely labeled incorrectly. The resulting dataset is then used to fine-tune an encoder LLM, which can be leveraged by any topic modeling approach that uses embeddings. In this work, we demonstrate its effectiveness by deriving a novel state-of-the-art topic modeling method called SenClu. The method achieves fast inference through an expectation-maximization algorithm and hard assignments of sentence groups to a single topic, while allowing users to encode prior knowledge about the topic-document distribution. Code is available at https://github.com/JohnTailor/FT-Topic","authors":["Johannes Schneider"],"pdf_url":"","comment":"This is the submitted journal version of enhanced with the novel fine-tuning part of \"Efficient and Flexible Topic Modeling using Pretrained Embeddings and Bag of Sentences'' which appeared at the International Conference on Agents and Artificial Intelligence(ICAART) in 2024"},{"id":"http://arxiv.org/abs/2507.10587v2","updated":"2026-02-20T12:28:40Z","published":"2025-07-11T14:07:22Z","title":"Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing","summary":"Human users increasingly communicate with large language models (LLMs), but LLMs suffer from frequent overconfidence in their output, even when its accuracy is questionable, which undermines their trustworthiness and perceived legitimacy. Therefore, there is a need for language models to signal their confidence in order to reap the benefits of human-machine collaboration and mitigate potential harms. Verbalized uncertainty is the expression of confidence with linguistic means, an approach that integrates perfectly into language-based interfaces. Most recent research in natural language processing (NLP) overlooks the nuances surrounding human uncertainty communication and the biases that influence the communication of and with machines. We argue for anthropomimetic uncertainty, the principle that intuitive and trustworthy uncertainty communication requires a degree of imitation of human linguistic behaviors. We present a thorough overview of the research in human uncertainty communication, survey ongoing research in NLP, and perform additional analyses to demonstrate so-far underexplored biases in verbalized uncertainty. We conclude by pointing out unique factors in human-machine uncertainty and outlining future research directions towards implementing anthropomimetic uncertainty.","authors":["Dennis Ulmer","Alexandra Lorson","Ivan Titov","Christian Hardmeier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18176v1","updated":"2026-02-20T12:26:03Z","published":"2026-02-20T12:26:03Z","title":"Improving Sampling for Masked Diffusion Models via Information Gain","summary":"Masked Diffusion Models (MDMs) offer greater flexibility in decoding order than autoregressive models but require careful planning to achieve high-quality generation. Existing samplers typically adopt greedy heuristics, prioritizing positions with the highest local certainty to decode at each step. Through failure case analysis, we identify a fundamental limitation of this approach: it neglects the downstream impact of current decoding choices on subsequent steps and fails to minimize cumulative uncertainty. In particular, these methods do not fully exploit the non-causal nature of MDMs, which enables evaluating how a decoding decision reshapes token probabilities/uncertainty across all remaining masked positions. To bridge this gap, we propose the Info-Gain Sampler, a principled decoding framework that balances immediate uncertainty with information gain over future masked tokens. Extensive evaluations across diverse architectures and tasks (reasoning, coding, creative writing, and image generation) demonstrate that Info-Gain Sampler consistently outperforms existing samplers for MDMs. For instance, it achieves a 3.6% improvement in average accuracy on reasoning tasks and a 63.1% win-rate in creative writing. Notably, on reasoning tasks it reduces cumulative uncertainty from 78.4 to 48.6, outperforming the best baseline by a large margin. The code will be available at https://github.com/yks23/Information-Gain-Sampler.","authors":["Kaisen Yang","Jayden Teoh","Kaicheng Yang","Yitong Zhang","Alex Lamb"],"pdf_url":"","comment":"https://github.com/yks23/Information-Gain-Sampler"},{"id":"http://arxiv.org/abs/2602.18171v1","updated":"2026-02-20T12:16:08Z","published":"2026-02-20T12:16:08Z","title":"Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models","summary":"Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.","authors":["Wojciech Michaluk","Tymoteusz Urban","Mateusz Kubita","Soveatin Kuntur","Anna Wroblewska"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18154v1","updated":"2026-02-20T11:40:41Z","published":"2026-02-20T11:40:41Z","title":"FENCE: A Financial and Multimodal Jailbreak Detection Dataset","summary":"Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.","authors":["Mirae Kim","Seonghun Jeong","Youngjun Kwak"],"pdf_url":"","comment":"lrec 2026 accepted paper"},{"id":"http://arxiv.org/abs/2602.18152v1","updated":"2026-02-20T11:33:37Z","published":"2026-02-20T11:33:37Z","title":"The Statistical Signature of LLMs","summary":"Large language models generate text through probabilistic sampling from high-dimensional distributions, yet how this process reshapes the structural statistical organization of language remains incompletely characterized. Here we show that lossless compression provides a simple, model-agnostic measure of statistical regularity that differentiates generative regimes directly from surface text. We analyze compression behavior across three progressively more complex information ecosystems: controlled human-LLM continuations, generative mediation of a knowledge infrastructure (Wikipedia vs. Grokipedia), and fully synthetic social interaction environments (Moltbook vs. Reddit). Across settings, compression reveals a persistent structural signature of probabilistic generation. In controlled and mediated contexts, LLM-produced language exhibits higher structural regularity and compressibility than human-written text, consistent with a concentration of output within highly recurrent statistical patterns. However, this signature shows scale dependence: in fragmented interaction environments the separation attenuates, suggesting a fundamental limit to surface-level distinguishability at small scales. This compressibility-based separation emerges consistently across models, tasks, and domains and can be observed directly from surface text without relying on model internals or semantic evaluation. Overall, our findings introduce a simple and robust framework for quantifying how generative systems reshape textual production, offering a structural perspective on the evolving complexity of communication.","authors":["Ortal Hadad","Edoardo Loru","Jacopo Nudo","Niccolò Di Marco","Matteo Cinelli","Walter Quattrociocchi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18145v1","updated":"2026-02-20T11:18:45Z","published":"2026-02-20T11:18:45Z","title":"Detecting Contextual Hallucinations in LLMs with Frequency-Aware Attention","summary":"Hallucination detection is critical for ensuring the reliability of large language models (LLMs) in context-based generation. Prior work has explored intrinsic signals available during generation, among which attention offers a direct view of grounding behavior. However, existing approaches typically rely on coarse summaries that fail to capture fine-grained instabilities in attention. Inspired by signal processing, we introduce a frequency-aware perspective on attention by analyzing its variation during generation. We model attention distributions as discrete signals and extract high-frequency components that reflect rapid local changes in attention. Our analysis reveals that hallucinated tokens are associated with high-frequency attention energy, reflecting fragmented and unstable grounding behavior. Based on this insight, we develop a lightweight hallucination detector using high-frequency attention features. Experiments on the RAGTruth and HalluRAG benchmarks show that our approach achieves performance gains over verification-based, internal-representation-based, and attention-based methods across models and tasks.","authors":["Siya Qi","Yudong Chen","Runcong Zhao","Qinglin Zhu","Zhanghao Hu","Wei Liu","Yulan He","Zheng Yuan","Lin Gui"],"pdf_url":"","comment":"25 pages, 10 figures"},{"id":"http://arxiv.org/abs/2601.10161v2","updated":"2026-02-20T11:08:07Z","published":"2026-01-15T08:00:25Z","title":"AWED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers","summary":"Named Entity Recognition (NER) is a foundational task in Natural Language Processing (NLP) and Information Retrieval (IR), which facilitates semantic search and structured data extraction. We introduce \\textbf{AWED-FiNER}, an open-source collection of agentic tool, web application, and 53 state-of-the-art expert models that provide Fine-grained Named Entity Recognition (FgNER) solutions across 36 languages spoken by more than 6.6 billion people. The agentic tool enables routing multilingual text to specialized expert models to fetch FgNER annotations within seconds. The web-based platform provides a ready-to-use FgNER annotation service for non-technical users. Moreover, the collection of language-specific extremely small open-source state-of-the-art expert models facilitates offline deployment in resource-constrained scenarios, including edge devices. AWED-FiNER covers languages spoken by over 6.6 billion people, ranging from global languages like English, Chinese, Spanish, and Hindi, to low-resource languages like Assamese, Santali, and Odia, along with a specific focus on extremely low-resource vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo. The resources can be accessed here: Agentic Tool (https://github.com/PrachuryyaKaushik/AWED-FiNER), Web Application (https://hf.co/spaces/prachuryyaIITG/AWED-FiNER), and 53 Expert Detector Models (https://hf.co/collections/prachuryyaIITG/awed-finer).","authors":["Prachuryya Kaushik","Ashish Anand"],"pdf_url":"","comment":"Submitted to SIGIR'26 Low-resource Environments Track"},{"id":"http://arxiv.org/abs/2602.18137v1","updated":"2026-02-20T10:53:09Z","published":"2026-02-20T10:53:09Z","title":"Agentic Adversarial QA for Improving Domain-Specific LLMs","summary":"Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.","authors":["Vincent Grari","Ciprian Tomoiaga","Sylvain Lamprier","Tatsunori Hashimoto","Marcin Detyniecki"],"pdf_url":"","comment":"9 pages, 1 Figure"},{"id":"http://arxiv.org/abs/2503.16021v4","updated":"2026-02-20T10:23:46Z","published":"2025-03-20T10:37:29Z","title":"Imitating AI agents increase diversity in homogeneous information environments but can reduce it in heterogeneous ones","summary":"Recent developments in large language models (LLMs) have facilitated autonomous AI agents capable of imitating human-generated content, raising fundamental questions about how AI may reshape democratic information environments such as news. We develop a large-scale simulation framework to examine the system-level effects of AI-based imitation, using the full population of Danish digital news articles published in 2022. Varying imitation strategies and AI prevalence across information environments with different baseline structures, we show that the effects of AI-driven imitation are strongly context-dependent: imitating AI agents increase semantic diversity in initially homogeneous environments but can reduce diversity in heterogeneous ones. This pattern is qualitatively consistent across multiple LLMs. However, this diversity arises primarily through stylistic differentiation and variance compression rather than factual enrichment, as AI-generated articles tend to omit information while remaining semantically distinct. These findings indicate that AI-driven imitation produces ambivalent transformations of information environments that may shape collective intelligence in democratic societies.","authors":["Emil Bakkensen Johansen","Oliver Baumann"],"pdf_url":"","comment":"53 pages, 13 figures, 4 tables; v2: corrected typographical errors, streamlined language, updated abstract, added supplementary information; v3: restructured appendix, added temperature and embeddings sensitivity checks; v4: additional LLM models introduced, restructured manuscript, additional robustness checks"},{"id":"http://arxiv.org/abs/2601.01944v2","updated":"2026-02-20T10:14:27Z","published":"2026-01-05T09:50:37Z","title":"The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities","summary":"In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.","authors":["Matteo Esposito","Andrea Janes","Valentina Lenarduzzi","Davide Taibi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2508.03923v3","updated":"2026-02-20T10:14:08Z","published":"2025-08-05T21:33:36Z","title":"CoAct-1: Computer-using Multi-Agent System with Coding Actions","summary":"Autonomous agents that operate computers via Graphical User Interfaces (GUIs) often struggle with efficiency and reliability on complex, long-horizon tasks. While augmenting these agents with planners can improve task decomposition, they remain constrained by the inherent limitations of performing all actions through GUI manipulation, leading to brittleness and inefficiency. In this work, we introduce a more robust and flexible paradigm: enabling agents to use coding as a enhanced action. We present CoAct-1, a novel multi-agent system that synergistically combines GUI-based control with direct programmatic execution. CoAct-1 features an Orchestrator that dynamically delegates subtasks to either a conventional GUI Operator or a specialized Programmer agent, which can write and execute Python or Bash scripts. This hybrid approach allows the agent to bypass inefficient GUI action sequences for tasks like file management and data processing, while still leveraging visual interaction when necessary. We evaluate our system on the challenging OSWorld benchmark, where CoAct-1 achieves a new state-of-the-art success rate of 60.76%, significantly outperforming prior methods. Furthermore, our approach dramatically improves efficiency, reducing the average number of steps required to complete a task to just 10.15, compared to 15 for leading GUI agents. Our results demonstrate that integrating coding as a core action provides a more powerful, efficient, and scalable path toward generalized computer automation.","authors":["Linxin Song","Yutong Dai","Viraj Prabhu","Jieyu Zhang","Taiwei Shi","Li Li","Junnan Li","Silvio Savarese","Zeyuan Chen","Jieyu Zhao","Ran Xu","Caiming Xiong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.19657v3","updated":"2026-02-20T09:54:44Z","published":"2026-01-27T14:32:36Z","title":"One Token Is Enough: Improving Diffusion Language Models with a Sink Token","summary":"Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.","authors":["Zihou Zhang","Zheyong Xie","Li Zhong","Haifeng Liu","Shaosheng Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18092v1","updated":"2026-02-20T09:33:16Z","published":"2026-02-20T09:33:16Z","title":"Perceived Political Bias in LLMs Reduces Persuasive Abilities","summary":"Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.","authors":["Matthew DiGiuseppe","Joshua Robison"],"pdf_url":"","comment":"39 pages, 10 figures"},{"id":"http://arxiv.org/abs/2505.20674v3","updated":"2026-02-20T09:16:25Z","published":"2025-05-27T03:47:33Z","title":"PonderLM: Pretraining Language Models to Ponder in Continuous Space","summary":"Humans ponder before articulating complex sentence elements, enabling deeper cognitive processing through focused effort. In this work, we introduce this pondering process into language models by repeatedly invoking the forward process within a single token generation step. During pondering, instead of generating an actual token sampled from the prediction distribution, the model ponders by yielding a weighted sum of all token embeddings according to the predicted token distribution. The generated embedding is then fed back as input for another forward pass. We show that the model can learn to ponder in this way through self-supervised learning, without any human annotations. Experiments across three widely used open-source architectures-GPT-2, Pythia, and LLaMA-and extensive downstream task evaluations demonstrate the effectiveness and generality of our method. On 9 downstream benchmarks, our pondering-enhanced Pythia models significantly outperform the official Pythia models. Notably, our PonderPythia models demonstrate remarkable effectiveness: PonderPythia-2.8B surpasses Pythia-6.9B and rivals Pythia-12B, while our PonderPythia-1B matches TinyLlama-1.1B, a model trained on 10 times more data. The code is available at https://github.com/LUMIA-Group/PonderingLM.","authors":["Boyi Zeng","Shixiang Song","Siyuan Huang","Yixuan Wang","He Li","Ziwei He","Xinbing Wang","Zhiyu Li","Zhouhan Lin"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2511.04108v4","updated":"2026-02-20T09:06:51Z","published":"2025-11-06T06:47:39Z","title":"Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models","summary":"Large Reasoning Models (LRMs) achieve strong performance through explicit chain-of-thought reasoning but suffer from \\textit{overthinking}: generating excessive reasoning tokens even for trivial queries. {Beyond inflating cost, overthinking can be self-defeating: models enter recursive self-doubt loops that exhaust token budgets without producing an answer, causing API timeouts that directly hurt accuracy.} We present an empirical study showing that \\textbf{batch prompting}, originally introduced for throughput optimization, effectively suppresses overthinking at inference time. Across 13 diverse benchmarks with DeepSeek-R1 and OpenAI-o1, batch prompting {reduces reasoning tokens by 76\\% (2{,}950$\\mapsto$710), on average, while preserving or improving accuracy}. Through behavioral analysis, we find that batching induces three beneficial effects: (1) it reduces per-query reasoning effort when multiple queries share a context; (2) it enables pattern induction, where models generalize from earlier examples to solve later ones; and (3) it suppresses hedging behavior (e.g., ``\\texttt{wait,}'' ``\\texttt{let me double-check}'') that signals metacognitive loops. We also show that explicit prompt constraints (``\\texttt{Use no more than 100 tokens in thinking.}'') fail to reduce overthinking; models either ignore them or sacrifice accuracy. These findings reframe batch prompting as more than a cost optimization: it is a practical inference-time technique that improves efficiency and reliability without model modification.","authors":["Saurabh Srivastava","Janit Bidhan","Hao Yan","Abhishek Dey","Tanu Kansal","Paras Kath","Sina Mansouri","Mohit Marvania","Vamsi Shankar Simhadri","Gaurav Singh"],"pdf_url":"","comment":"New version with updated author list"},{"id":"http://arxiv.org/abs/2506.03106v6","updated":"2026-02-20T08:30:55Z","published":"2025-06-03T17:39:02Z","title":"Critique-GRPO: Advancing LLM Reasoning with Natural Language and Numerical Feedback","summary":"Recent advances in reinforcement learning (RL) using numerical rewards have significantly enhanced the complex reasoning capabilities of large language models (LLMs). However, we identify three fundamental limitations of purely numerical feedback: performance plateaus, ineffective spontaneous self-reflection, and persistent failures. We show that plateaued RL models can successfully refine failed solutions when given natural language critiques. Motivated by this, we propose Critique-GRPO, an online RL framework that integrates both natural language and numerical feedback for policy optimization. This approach enables LLMs to learn simultaneously from initial responses and critique-guided refinements, effectively internalizing the exploration benefits of both stages. Extensive experiments show that Critique-GRPO outperforms all compared supervised and RL-based fine-tuning methods, achieving average Pass@1 improvements of approximately +15.0-21.6% on various Qwen models and +7.3% on Llama-3.2-3B-Instruct across eight challenging reasoning tasks. Notably, Critique-GRPO facilitates effective self-improvement through self-critiquing, achieving substantial gains over GRPO, e.g., +16.7% Pass@1 improvement on AIME 2024.","authors":["Xiaoying Zhang","Yipeng Zhang","Hao Sun","Kaituo Feng","Chaochao Lu","Chao Yang","Helen Meng"],"pdf_url":"","comment":"57 pages, updated with new experimental results and implementation details"},{"id":"http://arxiv.org/abs/2602.18037v1","updated":"2026-02-20T07:32:22Z","published":"2026-02-20T07:32:22Z","title":"Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards","summary":"Reinforcement Learning from Human Feedback (RLHF) or Verifiable Rewards (RLVR) are two key steps in the post-training of modern Language Models (LMs). A common problem is reward hacking, where the policy may exploit inaccuracies of the reward and learn an unintended behavior. Most previous works address this by limiting the policy update with a Kullback-Leibler (KL) penalty towards a reference model. We propose a different framing: Train the LM in a way that biases policy updates towards regions in which the reward is more accurate. First, we derive a theoretical connection between the accuracy of a reward model and the flatness of an optimum at convergence. Gradient regularization (GR) can then be used to bias training to flatter regions and thereby maintain reward model accuracy. We confirm these results by showing that the gradient norm and reward accuracy are empirically correlated in RLHF. We then show that Reference Resets of the KL penalty implicitly use GR to find flatter regions with higher reward accuracy. We further improve on this by proposing to use explicit GR with an efficient finite-difference estimate. Empirically, GR performs better than a KL penalty across a diverse set of RL experiments with LMs. GR achieves a higher GPT-judged win-rate in RLHF, avoids overly focusing on the format in rule-based math rewards, and prevents hacking the judge in LLM-as-a-Judge math tasks.","authors":["Johannes Ackermann","Michael Noukhovitch","Takashi Ishida","Masashi Sugiyama"],"pdf_url":"","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2602.18029v1","updated":"2026-02-20T06:54:44Z","published":"2026-02-20T06:54:44Z","title":"Towards More Standardized AI Evaluation: From Models to Agents","summary":"Evaluation is no longer a final checkpoint in the machine learning lifecycle. As AI systems evolve from static models to compound, tool-using agents, evaluation becomes a core control function. The question is no longer \"How good is the model?\" but \"Can we trust the system to behave as intended, under change, at scale?\". Yet most evaluation practices remain anchored in assumptions inherited from the model-centric era: static benchmarks, aggregate scores, and one-off success criteria. This paper argues that such approaches are increasingly obscure rather than illuminating system behavior. We examine how evaluation pipelines themselves introduce silent failure modes, why high benchmark scores routinely mislead teams, and how agentic systems fundamentally alter the meaning of performance measurement. Rather than proposing new metrics or harder benchmarks, we aim to clarify the role of evaluation in the AI era, and especially for agents: not as performance theater, but as a measurement discipline that conditions trust, iteration, and governance in non-deterministic systems.","authors":["Ali El Filali","Inès Bedar"],"pdf_url":"","comment":"19 pages, 3 figures"},{"id":"http://arxiv.org/abs/2602.15854v2","updated":"2026-02-20T05:58:30Z","published":"2026-01-24T06:35:23Z","title":"Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization","summary":"Large language models show potential in task-oriented dialogue systems, yet existing training methods often rely on token-level likelihood or preference optimization, which poorly align with long-horizon task success. To address this, we propose Goal-Oriented Preference Optimization (GOPO), a hierarchical reinforcement learning framework that decouples strategy planning from response generation via an Expert Agent and a Customer Service Agent. The Expert Agent optimizes multi-turn goal preferences at the dialogue-trajectory level, while the Customer Service Agent generates responses strictly aligned with the selected strategy. We evaluate GOPO on public benchmarks and e-commerce customer service datasets, and introduce Task-focused Sequential Engagement (TSE), a sequence-level metric derived from real e-commerce interaction data. On the Mgshop dataset, GOPO improves TSE by 7.7% and 10.3% over PPO and Memento, with consistent gains in sequence-level reward and generation quality. Furthermore, a 14B model trained with GOPO achieves 2.7% and 1.5% higher TSE than Qwen-235B and GPT-5.2, respectively. Ablation studies confirm the Expert Agent's critical role in long-horizon optimization. GOPO demonstrates consistent improvements across other datasets as well. This work establishes a new paradigm for task-oriented dialogue systems in commercial scenarios, with code and datasets to be made public.","authors":["Jingyi Xu","Xingyu Ren","Zhoupeng Shou","Yumeng Zhang","Zhiqiang You"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18008v1","updated":"2026-02-20T05:46:54Z","published":"2026-02-20T05:46:54Z","title":"NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs","summary":"Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem settings substantially oversimplify real-world conditions, leaving it unclear whether LLM-generated mechanistic models are reliable in practice. To address this gap, we introduce the Neural-Integrated Mechanistic Modeling (NIMM) evaluation framework, which evaluates LLM-generated mechanistic models under realistic settings with partial observations and diversified task objectives. Our evaluation reveals fundamental challenges in current baselines, ranging from model effectiveness to code-level correctness. Motivated by these findings, we design NIMMgen, an agentic framework for neural-integrated mechanistic modeling that enhances code correctness and practical validity through iterative refinement. Experiments across three datasets from diversified scientific domains demonstrate its strong performance. We also show that the learned mechanistic models support counterfactual intervention simulation.","authors":["Zihan Guan","Rituparna Datta","Mengxuan Hu","Shunshun Liu","Aiying Zhang","Prasanna Balachandran","Sheng Li","Anil Vullikanti"],"pdf_url":"","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.11495v2","updated":"2026-02-20T05:13:21Z","published":"2026-02-12T02:43:17Z","title":"Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models","summary":"Jailbreaking large language models (LLMs) has emerged as a critical security challenge with the widespread deployment of conversational AI systems. Adversarial users exploit these models through carefully crafted prompts to elicit restricted or unsafe outputs, a phenomenon commonly referred to as Jailbreaking. Despite numerous proposed defense mechanisms, attackers continue to develop adaptive prompting strategies, and existing models remain vulnerable. This motivates approaches that examine the internal behavior of LLMs rather than relying solely on prompt-level defenses. In this work, we study jailbreaking from both security and interpretability perspectives by analyzing how internal representations differ between jailbreak and benign prompts. We conduct a systematic layer-wise analysis across multiple open-source models, including GPT-J, LLaMA, Mistral, and the state-space model Mamba, and identify consistent latent-space patterns associated with harmful inputs. We then propose a tensor-based latent representation framework that captures structure in hidden activations and enables lightweight jailbreak detection without model fine-tuning or auxiliary LLM-based detectors. We further demonstrate that the latent signals can be used to actively disrupt jailbreak execution at inference time. On an abliterated LLaMA-3.1-8B model, selectively bypassing high-susceptibility layers blocks 78% of jailbreak attempts while preserving benign behavior on 94% of benign prompts. This intervention operates entirely at inference time and introduces minimal overhead, providing a scalable foundation for achieving stronger coverage by incorporating additional attack distributions or more refined susceptibility thresholds. Our results provide evidence that jailbreak behavior is rooted in identifiable internal structures and suggest a complementary, architecture-agnostic direction for improving LLM security.","authors":["Sri Durga Sai Sowmya Kadali","Evangelos E. Papalexakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.25860v2","updated":"2026-02-20T04:49:32Z","published":"2025-10-29T18:03:44Z","title":"Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters","summary":"Large language models (LLMs) are increasingly used as raters for evaluation tasks. However, their reliability is often limited for subjective tasks, when human judgments involve subtle reasoning beyond annotation labels. Thinking traces, the reasoning behind a judgment, are highly informative but challenging to collect and curate. We present a human-LLM collaborative framework to infer thinking traces from label-only annotations. The proposed framework uses a simple and effective rejection sampling method to reconstruct these traces at scale. These inferred thinking traces are applied to two complementary tasks: (1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation guidelines for proprietary LLM raters. Across multiple datasets, our methods lead to significantly improved LLM-human agreement. Additionally, the refined annotation guidelines increase agreement among different LLM models. These results suggest that LLMs can serve as practical proxies for otherwise unrevealed human thinking traces, enabling label-only corpora to be extended into thinking-trace-augmented resources that enhance the reliability of LLM raters.","authors":["Xingjian Zhang","Tianhong Gao","Suliang Jin","Tianhao Wang","Teng Ye","Eytan Adar","Qiaozhu Mei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17981v1","updated":"2026-02-20T04:31:40Z","published":"2026-02-20T04:31:40Z","title":"Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering","summary":"Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.","authors":["Amine Kobeissi","Philippe Langlais"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.27118v3","updated":"2026-02-20T04:28:49Z","published":"2025-10-31T02:41:05Z","title":"Probability Distributions Computed by Autoregressive Transformers","summary":"Most expressivity results for transformers treat them as language recognizers (which accept or reject strings), and not as they are used in practice, as language models (which generate strings autoregressively and probabilistically). We characterize the probability distributions that transformer language models can express. We show that making transformer language recognizers autoregressive can sometimes increase their expressivity, and that making them probabilistic can break equivalences that hold in the non-probabilistic case. Our overall contribution is to tease apart what functions transformers are capable of expressing, in their most common use-case as language models.","authors":["Andy Yang","Anej Svete","Jiaoda Li","Anthony Widjaja Lin","Jonathan Rawski","Ryan Cotterell","David Chiang"],"pdf_url":"","comment":"21 pages"},{"id":"http://arxiv.org/abs/2501.14249v10","updated":"2026-02-20T04:23:01Z","published":"2025-01-24T05:27:46Z","title":"Humanity's Last Exam","summary":"Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90\\% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. HLE consists of 2,500 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading. Each question has a known solution that is unambiguous and easily verifiable, but cannot be quickly answered via internet retrieval. State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions. To inform research and policymaking upon a clear understanding of model capabilities, we publicly release HLE at https://lastexam.ai.","authors":["Long Phan","Alice Gatti","Ziwen Han","Nathaniel Li","Josephina Hu","Hugh Zhang","Chen Bo Calvin Zhang","Mohamed Shaaban","John Ling","Sean Shi","Michael Choi","Anish Agrawal","Arnav Chopra","Adam Khoja","Ryan Kim","Richard Ren","Jason Hausenloy","Oliver Zhang","Mantas Mazeika","Dmitry Dodonov","Tung Nguyen","Jaeho Lee","Daron Anderson","Mikhail Doroshenko","Alun Cennyth Stokes","Mobeen Mahmood","Oleksandr Pokutnyi","Oleg Iskra","Jessica P. Wang","John-Clark Levin","Mstyslav Kazakov","Fiona Feng","Steven Y. Feng","Haoran Zhao","Michael Yu","Varun Gangal","Chelsea Zou","Zihan Wang","Serguei Popov","Robert Gerbicz","Geoff Galgon","Johannes Schmitt","Will Yeadon","Yongki Lee","Scott Sauers","Alvaro Sanchez","Fabian Giska","Marc Roth","Søren Riis","Saiteja Utpala","Noah Burns","Gashaw M. Goshu","Mohinder Maheshbhai Naiya","Chidozie Agu","Zachary Giboney","Antrell Cheatom","Francesco Fournier-Facio","Sarah-Jane Crowson","Lennart Finke","Zerui Cheng","Jennifer Zampese","Ryan G. Hoerr","Mark Nandor","Hyunwoo Park","Tim Gehrunger","Jiaqi Cai","Ben McCarty","Alexis C Garretson","Edwin Taylor","Damien Sileo","Qiuyu Ren","Usman Qazi","Lianghui Li","Jungbae Nam","John B. Wydallis","Pavel Arkhipov","Jack Wei Lun Shi","Aras Bacho","Chris G. Willcocks","Hangrui Cao","Sumeet Motwani","Emily de Oliveira Santos","Johannes Veith","Edward Vendrow","Doru Cojoc","Kengo Zenitani","Joshua Robinson","Longke Tang","Yuqi Li","Joshua Vendrow","Natanael Wildner Fraga","Vladyslav Kuchkin","Andrey Pupasov Maksimov","Pierre Marion","Denis Efremov","Jayson Lynch","Kaiqu Liang","Aleksandar Mikov","Andrew Gritsevskiy","Julien Guillod","Gözdenur Demir","Dakotah Martinez","Ben Pageler","Kevin Zhou","Saeed Soori","Ori Press","Henry Tang","Paolo Rissone","Sean R. Green","Lina Brüssel","Moon Twayana","Aymeric Dieuleveut","Joseph Marvin Imperial","Ameya Prabhu","Jinzhou Yang","Nick Crispino","Arun Rao","Dimitri Zvonkine","Gabriel Loiseau","Mikhail Kalinin","Marco Lukas","Ciprian Manolescu","Nate Stambaugh","Subrata Mishra","Tad Hogg","Carlo Bosio","Brian P Coppola","Julian Salazar","Jaehyeok Jin","Rafael Sayous","Stefan Ivanov","Philippe Schwaller","Shaipranesh Senthilkuma","Andres M Bran","Andres Algaba","Kelsey Van den Houte","Lynn Van Der Sypt","Brecht Verbeken","David Noever","Alexei Kopylov","Benjamin Myklebust","Bikun Li","Lisa Schut","Evgenii Zheltonozhskii","Qiaochu Yuan","Derek Lim","Richard Stanley","Tong Yang","John Maar","Julian Wykowski","Martí Oller","Anmol Sahu","Cesare Giulio Ardito","Yuzheng Hu","Ariel Ghislain Kemogne Kamdoum","Alvin Jin","Tobias Garcia Vilchis","Yuexuan Zu","Martin Lackner","James Koppel","Gongbo Sun","Daniil S. Antonenko","Steffi Chern","Bingchen Zhao","Pierrot Arsene","Joseph M Cavanagh","Daofeng Li","Jiawei Shen","Donato Crisostomi","Wenjin Zhang","Ali Dehghan","Sergey Ivanov","David Perrella","Nurdin Kaparov","Allen Zang","Ilia Sucholutsky","Arina Kharlamova","Daniil Orel","Vladislav Poritski","Shalev Ben-David","Zachary Berger","Parker Whitfill","Michael Foster","Daniel Munro","Linh Ho","Shankar Sivarajan","Dan Bar Hava","Aleksey Kuchkin","David Holmes","Alexandra Rodriguez-Romero","Frank Sommerhage","Anji Zhang","Richard Moat","Keith Schneider","Zakayo Kazibwe","Don Clarke","Dae Hyun Kim","Felipe Meneguitti Dias","Sara Fish","Veit Elser","Tobias Kreiman","Victor Efren Guadarrama Vilchis","Immo Klose","Ujjwala Anantheswaran","Adam Zweiger","Kaivalya Rawal","Jeffery Li","Jeremy Nguyen","Nicolas Daans","Haline Heidinger","Maksim Radionov","Václav Rozhoň","Vincent Ginis","Christian Stump","Niv Cohen","Rafał Poświata","Josef Tkadlec","Alan Goldfarb","Chenguang Wang","Piotr Padlewski","Stanislaw Barzowski","Kyle Montgomery","Ryan Stendall","Jamie Tucker-Foltz","Jack Stade","T. Ryan Rogers","Tom Goertzen","Declan Grabb","Abhishek Shukla","Alan Givré","John Arnold Ambay","Archan Sen","Muhammad Fayez Aziz","Mark H Inlow","Hao He","Ling Zhang","Younesse Kaddar","Ivar Ängquist","Yanxu Chen","Harrison K Wang","Kalyan Ramakrishnan","Elliott Thornley","Antonio Terpin","Hailey Schoelkopf","Eric Zheng","Avishy Carmi","Ethan D. L. Brown","Kelin Zhu","Max Bartolo","Richard Wheeler","Martin Stehberger","Peter Bradshaw","JP Heimonen","Kaustubh Sridhar","Ido Akov","Jennifer Sandlin","Yury Makarychev","Joanna Tam","Hieu Hoang","David M. Cunningham","Vladimir Goryachev","Demosthenes Patramanis","Michael Krause","Andrew Redenti","David Aldous","Jesyin Lai","Shannon Coleman","Jiangnan Xu","Sangwon Lee","Ilias Magoulas","Sandy Zhao","Ning Tang","Michael K. Cohen","Orr Paradise","Jan Hendrik Kirchner","Maksym Ovchynnikov","Jason O. Matos","Adithya Shenoy","Michael Wang","Yuzhou Nie","Anna Sztyber-Betley","Paolo Faraboschi","Robin Riblet","Jonathan Crozier","Shiv Halasyamani","Shreyas Verma","Prashant Joshi","Eli Meril","Ziqiao Ma","Jérémy Andréoletti","Raghav Singhal","Jacob Platnick","Volodymyr Nevirkovets","Luke Basler","Alexander Ivanov","Seri Khoury","Nils Gustafsson","Marco Piccardo","Hamid Mostaghimi","Qijia Chen","Virendra Singh","Tran Quoc Khánh","Paul Rosu","Hannah Szlyk","Zachary Brown","Himanshu Narayan","Aline Menezes","Jonathan Roberts","William Alley","Kunyang Sun","Arkil Patel","Max Lamparth","Anka Reuel","Linwei Xin","Hanmeng Xu","Jacob Loader","Freddie Martin","Zixuan Wang","Andrea Achilleos","Thomas Preu","Tomek Korbak","Ida Bosio","Fereshteh Kazemi","Ziye Chen","Biró Bálint","Eve J. Y. Lo","Jiaqi Wang","Maria Inês S. Nunes","Jeremiah Milbauer","M Saiful Bari","Zihao Wang","Behzad Ansarinejad","Yewen Sun","Stephane Durand","Hossam Elgnainy","Guillaume Douville","Daniel Tordera","George Balabanian","Hew Wolff","Lynna Kvistad","Hsiaoyun Milliron","Ahmad Sakor","Murat Eron","Andrew Favre D. O.","Shailesh Shah","Xiaoxiang Zhou","Firuz Kamalov","Sherwin Abdoli","Tim Santens","Shaul Barkan","Allison Tee","Robin Zhang","Alessandro Tomasiello","G. Bruno De Luca","Shi-Zhuo Looi","Vinh-Kha Le","Noam Kolt","Jiayi Pan","Emma Rodman","Jacob Drori","Carl J Fossum","Niklas Muennighoff","Milind Jagota","Ronak Pradeep","Honglu Fan","Jonathan Eicher","Michael Chen","Kushal Thaman","William Merrill","Moritz Firsching","Carter Harris","Stefan Ciobâcă","Jason Gross","Rohan Pandey","Ilya Gusev","Adam Jones","Shashank Agnihotri","Pavel Zhelnov","Mohammadreza Mofayezi","Alexander Piperski","David K. Zhang","Kostiantyn Dobarskyi","Roman Leventov","Ignat Soroko","Joshua Duersch","Vage Taamazyan","Andrew Ho","Wenjie Ma","William Held","Ruicheng Xian","Armel Randy Zebaze","Mohanad Mohamed","Julian Noah Leser","Michelle X Yuan","Laila Yacar","Johannes Lengler","Katarzyna Olszewska","Claudio Di Fratta","Edson Oliveira","Joseph W. Jackson","Andy Zou","Muthu Chidambaram","Timothy Manik","Hector Haffenden","Dashiell Stander","Ali Dasouqi","Alexander Shen","Bita Golshani","David Stap","Egor Kretov","Mikalai Uzhou","Alina Borisovna Zhidkovskaya","Nick Winter","Miguel Orbegozo Rodriguez","Robert Lauff","Dustin Wehr","Colin Tang","Zaki Hossain","Shaun Phillips","Fortuna Samuele","Fredrik Ekström","Angela Hammon","Oam Patel","Faraz Farhidi","George Medley","Forough Mohammadzadeh","Madellene Peñaflor","Haile Kassahun","Alena Friedrich","Rayner Hernandez Perez","Daniel Pyda","Taom Sakal","Omkar Dhamane","Ali Khajegili Mirabadi","Eric Hallman","Kenchi Okutsu","Mike Battaglia","Mohammad Maghsoudimehrabani","Alon Amit","Dave Hulbert","Roberto Pereira","Simon Weber"," Handoko","Anton Peristyy","Stephen Malina","Mustafa Mehkary","Rami Aly","Frank Reidegeld","Anna-Katharina Dick","Cary Friday","Mukhwinder Singh","Hassan Shapourian","Wanyoung Kim","Mariana Costa","Hubeyb Gurdogan","Harsh Kumar","Chiara Ceconello","Chao Zhuang","Haon Park","Micah Carroll","Andrew R. Tawfeek","Stefan Steinerberger","Daattavya Aggarwal","Michael Kirchhof","Linjie Dai","Evan Kim","Johan Ferret","Jainam Shah","Yuzhou Wang","Minghao Yan","Krzysztof Burdzy","Lixin Zhang","Antonio Franca","Diana T. Pham","Kang Yong Loh","Joshua Robinson","Abram Jackson","Paolo Giordano","Philipp Petersen","Adrian Cosma","Jesus Colino","Colin White","Jacob Votava","Vladimir Vinnikov","Ethan Delaney","Petr Spelda","Vit Stritecky","Syed M. Shahid","Jean-Christophe Mourrat","Lavr Vetoshkin","Koen Sponselee","Renas Bacho","Zheng-Xin Yong","Florencia de la Rosa","Nathan Cho","Xiuyu Li","Guillaume Malod","Orion Weller","Guglielmo Albani","Leon Lang","Julien Laurendeau","Dmitry Kazakov","Fatimah Adesanya","Julien Portier","Lawrence Hollom","Victor Souza","Yuchen Anna Zhou","Julien Degorre","Yiğit Yalın","Gbenga Daniel Obikoya"," Rai","Filippo Bigi","M. C. Boscá","Oleg Shumar","Kaniuar Bacho","Gabriel Recchia","Mara Popescu","Nikita Shulga","Ngefor Mildred Tanwie","Thomas C. H. Lux","Ben Rank","Colin Ni","Matthew Brooks","Alesia Yakimchyk"," Huanxu"," Liu","Stefano Cavalleri","Olle Häggström","Emil Verkama","Joshua Newbould","Hans Gundlach","Leonor Brito-Santana","Brian Amaro","Vivek Vajipey","Rynaa Grover","Ting Wang","Yosi Kratish","Wen-Ding Li","Sivakanth Gopi","Andrea Caciolai","Christian Schroeder de Witt","Pablo Hernández-Cámara","Emanuele Rodolà","Jules Robins","Dominic Williamson","Vincent Cheng","Brad Raynor","Hao Qi","Ben Segev","Jingxuan Fan","Sarah Martinson","Erik Y. Wang","Kaylie Hausknecht","Michael P. Brenner","Mao Mao","Christoph Demian","Peyman Kassani","Xinyu Zhang","David Avagian","Eshawn Jessica Scipio","Alon Ragoler","Justin Tan","Blake Sims","Rebeka Plecnik","Aaron Kirtland","Omer Faruk Bodur","D. P. Shinde","Yan Carlos Leyva Labrador","Zahra Adoul","Mohamed Zekry","Ali Karakoc","Tania C. B. Santos","Samir Shamseldeen","Loukmane Karim","Anna Liakhovitskaia","Nate Resman","Nicholas Farina","Juan Carlos Gonzalez","Gabe Maayan","Earth Anderson","Rodrigo De Oliveira Pena","Elizabeth Kelley","Hodjat Mariji","Rasoul Pouriamanesh","Wentao Wu","Ross Finocchio","Ismail Alarab","Joshua Cole","Danyelle Ferreira","Bryan Johnson","Mohammad Safdari","Liangti Dai","Siriphan Arthornthurasuk","Isaac C. McAlister","Alejandro José Moyano","Alexey Pronin","Jing Fan","Angel Ramirez-Trinidad","Yana Malysheva","Daphiny Pottmaier","Omid Taheri","Stanley Stepanic","Samuel Perry","Luke Askew","Raúl Adrián Huerta Rodríguez","Ali M. R. Minissi","Ricardo Lorena","Krishnamurthy Iyer","Arshad Anil Fasiludeen","Ronald Clark","Josh Ducey","Matheus Piza","Maja Somrak","Eric Vergo","Juehang Qin","Benjámin Borbás","Eric Chu","Jack Lindsey","Antoine Jallon","I. M. J. McInnis","Evan Chen","Avi Semler","Luk Gloor","Tej Shah","Marc Carauleanu","Pascal Lauer","Tran Đuc Huy","Hossein Shahrtash","Emilien Duc","Lukas Lewark","Assaf Brown","Samuel Albanie","Brian Weber","Warren S. Vaz","Pierre Clavier","Yiyang Fan","Gabriel Poesia Reis e Silva"," Long"," Lian","Marcus Abramovitch","Xi Jiang","Sandra Mendoza","Murat Islam","Juan Gonzalez","Vasilios Mavroudis","Justin Xu","Pawan Kumar","Laxman Prasad Goswami","Daniel Bugas","Nasser Heydari","Ferenc Jeanplong","Thorben Jansen","Antonella Pinto","Archimedes Apronti","Abdallah Galal","Ng Ze-An","Ankit Singh","Tong Jiang","Joan of Arc Xavier","Kanu Priya Agarwal","Mohammed Berkani","Gang Zhang","Zhehang Du","Benedito Alves de Oliveira Junior","Dmitry Malishev","Nicolas Remy","Taylor D. Hartman","Tim Tarver","Stephen Mensah","Gautier Abou Loume","Wiktor Morak","Farzad Habibi","Sarah Hoback","Will Cai","Javier Gimenez","Roselynn Grace Montecillo","Jakub Łucki","Russell Campbell","Asankhaya Sharma","Khalida Meer","Shreen Gul","Daniel Espinosa Gonzalez","Xavier Alapont","Alex Hoover","Gunjan Chhablani","Freddie Vargus","Arunim Agarwal","Yibo Jiang","Deepakkumar Patil","David Outevsky","Kevin Joseph Scaria","Rajat Maheshwari","Abdelkader Dendane","Priti Shukla","Ashley Cartwright","Sergei Bogdanov","Niels Mündler","Sören Möller","Luca Arnaboldi","Kunvar Thaman","Muhammad Rehan Siddiqi","Prajvi Saxena","Himanshu Gupta","Tony Fruhauff","Glen Sherman","Mátyás Vincze","Siranut Usawasutsakorn","Dylan Ler","Anil Radhakrishnan","Innocent Enyekwe","Sk Md Salauddin","Jiang Muzhen","Aleksandr Maksapetyan","Vivien Rossbach","Chris Harjadi","Mohsen Bahaloohoreh","Claire Sparrow","Jasdeep Sidhu","Sam Ali","Song Bian","John Lai","Eric Singer","Justine Leon Uro","Greg Bateman","Mohamed Sayed","Ahmed Menshawy","Darling Duclosel","Dario Bezzi","Yashaswini Jain","Ashley Aaron","Murat Tiryakioglu","Sheeshram Siddh","Keith Krenek","Imad Ali Shah","Jun Jin","Scott Creighton","Denis Peskoff","Zienab EL-Wasif","Ragavendran P","Michael Richmond","Joseph McGowan","Tejal Patwardhan","Hao-Yu Sun","Ting Sun","Nikola Zubić","Samuele Sala","Stephen Ebert","Jean Kaddour","Manuel Schottdorf","Dianzhuo Wang","Gerol Petruzella","Alex Meiburg","Tilen Medved","Ali ElSheikh","S Ashwin Hebbar","Lorenzo Vaquero","Xianjun Yang","Jason Poulos","Vilém Zouhar","Sergey Bogdanik","Mingfang Zhang","Jorge Sanz-Ros","David Anugraha","Yinwei Dai","Anh N. Nhu","Xue Wang","Ali Anil Demircali","Zhibai Jia","Yuyin Zhou","Juncheng Wu","Mike He","Nitin Chandok","Aarush Sinha","Gaoxiang Luo","Long Le","Mickaël Noyé","Michał Perełkiewicz","Ioannis Pantidis","Tianbo Qi","Soham Sachin Purohit","Letitia Parcalabescu","Thai-Hoa Nguyen","Genta Indra Winata","Edoardo M. Ponti","Hanchen Li","Kaustubh Dhole","Jongee Park","Dario Abbondanza","Yuanli Wang","Anupam Nayak","Diogo M. Caetano","Antonio A. W. L. Wong","Maria del Rio-Chanona","Dániel Kondor","Pieter Francois","Ed Chalstrey","Jakob Zsambok","Dan Hoyer","Jenny Reddish","Jakob Hauser","Francisco-Javier Rodrigo-Ginés","Suchandra Datta","Maxwell Shepherd","Thom Kamphuis","Qizheng Zhang","Hyunjun Kim","Ruiji Sun","Jianzhu Yao","Franck Dernoncourt","Satyapriya Krishna","Sina Rismanchian","Bonan Pu","Francesco Pinto","Yingheng Wang","Kumar Shridhar","Kalon J. Overholt","Glib Briia","Hieu Nguyen"," David","Soler Bartomeu","Tony CY Pang","Adam Wecker","Yifan Xiong","Fanfei Li","Lukas S. Huber","Joshua Jaeger","Romano De Maddalena","Xing Han Lù","Yuhui Zhang","Claas Beger","Patrick Tser Jern Kon","Sean Li","Vivek Sanker","Ming Yin","Yihao Liang","Xinlu Zhang","Ankit Agrawal","Li S. Yifei","Zechen Zhang","Mu Cai","Yasin Sonmez","Costin Cozianu","Changhao Li","Alex Slen","Shoubin Yu","Hyun Kyu Park","Gabriele Sarti","Marcin Briański","Alessandro Stolfo","Truong An Nguyen","Mike Zhang","Yotam Perlitz","Jose Hernandez-Orallo","Runjia Li","Amin Shabani","Felix Juefei-Xu","Shikhar Dhingra","Orr Zohar","My Chiffon Nguyen","Alexander Pondaven","Abdurrahim Yilmaz","Xuandong Zhao","Chuanyang Jin","Muyan Jiang","Stefan Todoran","Xinyao Han","Jules Kreuer","Brian Rabern","Anna Plassart","Martino Maggetti","Luther Yap","Robert Geirhos","Jonathon Kean","Dingsu Wang","Sina Mollaei","Chenkai Sun","Yifan Yin","Shiqi Wang","Rui Li","Yaowen Chang","Anjiang Wei","Alice Bizeul","Xiaohan Wang","Alexandre Oliveira Arrais","Kushin Mukherjee","Jorge Chamorro-Padial","Jiachen Liu","Xingyu Qu","Junyi Guan","Adam Bouyamourn","Shuyu Wu","Martyna Plomecka","Junda Chen","Mengze Tang","Jiaqi Deng","Shreyas Subramanian","Haocheng Xi","Haoxuan Chen","Weizhi Zhang","Yinuo Ren","Haoqin Tu","Sejong Kim","Yushun Chen","Sara Vera Marjanović","Junwoo Ha","Grzegorz Luczyna","Jeff J. Ma","Zewen Shen","Dawn Song","Cedegao E. Zhang","Zhun Wang","Gaël Gendron","Yunze Xiao","Leo Smucker","Erica Weng","Kwok Hao Lee","Zhe Ye","Stefano Ermon","Ignacio D. Lopez-Miguel","Theo Knights","Anthony Gitter","Namkyu Park","Boyi Wei","Hongzheng Chen","Kunal Pai","Ahmed Elkhanany","Han Lin","Philipp D. Siedler","Jichao Fang","Ritwik Mishra","Károly Zsolnai-Fehér","Xilin Jiang","Shadab Khan","Jun Yuan","Rishab Kumar Jain","Xi Lin","Mike Peterson","Zhe Wang","Aditya Malusare","Maosen Tang","Isha Gupta","Ivan Fosin","Timothy Kang","Barbara Dworakowska","Kazuki Matsumoto","Guangyao Zheng","Gerben Sewuster","Jorge Pretel Villanueva","Ivan Rannev","Igor Chernyavsky","Jiale Chen","Deepayan Banik","Ben Racz","Wenchao Dong","Jianxin Wang","Laila Bashmal","Duarte V. Gonçalves","Wei Hu","Kaushik Bar","Ondrej Bohdal","Atharv Singh Patlan","Shehzaad Dhuliawala","Caroline Geirhos","Julien Wist","Yuval Kansal","Bingsen Chen","Kutay Tire","Atak Talay Yücel","Brandon Christof","Veerupaksh Singla","Zijian Song","Sanxing Chen","Jiaxin Ge","Kaustubh Ponkshe","Isaac Park","Tianneng Shi","Martin Q. Ma","Joshua Mak","Sherwin Lai","Antoine Moulin","Zhuo Cheng","Zhanda Zhu","Ziyi Zhang","Vaidehi Patil","Ketan Jha","Qiutong Men","Jiaxuan Wu","Tianchi Zhang","Bruno Hebling Vieira","Alham Fikri Aji","Jae-Won Chung","Mohammed Mahfoud","Ha Thi Hoang","Marc Sperzel","Wei Hao","Kristof Meding","Sihan Xu","Vassilis Kostakos","Davide Manini","Yueying Liu","Christopher Toukmaji","Jay Paek","Eunmi Yu","Arif Engin Demircali","Zhiyi Sun","Ivan Dewerpe","Hongsen Qin","Roman Pflugfelder","James Bailey","Johnathan Morris","Ville Heilala","Sybille Rosset","Zishun Yu","Peter E. Chen","Woongyeong Yeo","Eeshaan Jain","Ryan Yang","Sreekar Chigurupati","Julia Chernyavsky","Sai Prajwal Reddy","Subhashini Venugopalan","Hunar Batra","Core Francisco Park","Hieu Tran","Guilherme Maximiano","Genghan Zhang","Yizhuo Liang","Hu Shiyu","Rongwu Xu","Rui Pan","Siddharth Suresh","Ziqi Liu","Samaksh Gulati","Songyang Zhang","Peter Turchin","Christopher W. Bartlett","Christopher R. Scotese","Phuong M. Cao","Ben Wu","Jacek Karwowski","Davide Scaramuzza","Aakaash Nattanmai","Gordon McKellips","Anish Cheraku","Asim Suhail","Ethan Luo","Marvin Deng","Jason Luo","Ashley Zhang","Kavin Jindel","Jay Paek","Kasper Halevy","Allen Baranov","Michael Liu","Advaith Avadhanam","David Zhang","Vincent Cheng","Brad Ma","Evan Fu","Liam Do","Joshua Lass","Hubert Yang","Surya Sunkari","Vishruth Bharath","Violet Ai","James Leung","Rishit Agrawal","Alan Zhou","Kevin Chen","Tejas Kalpathi","Ziqi Xu","Gavin Wang","Tyler Xiao","Erik Maung","Sam Lee","Ryan Yang","Roy Yue","Ben Zhao","Julia Yoon","Sunny Sun","Aryan Singh","Ethan Luo","Clark Peng","Tyler Osbey","Taozhi Wang","Daryl Echeazu","Hubert Yang","Timothy Wu","Spandan Patel","Vidhi Kulkarni","Vijaykaarti Sundarapandiyan","Ashley Zhang","Andrew Le","Zafir Nasim","Srikar Yalam","Ritesh Kasamsetty","Soham Samal","Hubert Yang","David Sun","Nihar Shah","Abhijeet Saha","Alex Zhang","Leon Nguyen","Laasya Nagumalli","Kaixin Wang","Alan Zhou","Aidan Wu","Jason Luo","Anwith Telluri","Steven Dillmann","Zhengxiang Wang","Junyu Luo","Hugo Lunn","Artem Gazizov","Haoran Qiu","Allen G Hart","Rickard Brüel Gabrielsson","Ido Akov","Artem Lukoianov","Summer Yue","Alexandr Wang","Dan Hendrycks"],"pdf_url":"","comment":"29 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.04587v2","updated":"2026-02-20T03:51:49Z","published":"2026-02-04T14:12:55Z","title":"VILLAIN at AVerImaTeC: Verifying Image-Text Claims via Multi-Agent Collaboration","summary":"This paper describes VILLAIN, a multimodal fact-checking system that verifies image-text claims through prompt-based multi-agent collaboration. For the AVerImaTeC shared task, VILLAIN employs vision-language model agents across multiple stages of fact-checking. Textual and visual evidence is retrieved from the knowledge store enriched through additional web collection. To identify key information and address inconsistencies among evidence items, modality-specific and cross-modal agents generate analysis reports. In the subsequent stage, question-answer pairs are produced based on these reports. Finally, the Verdict Prediction agent produces the verification outcome based on the image-text claim and the generated question-answer pairs. Our system ranked first on the leaderboard across all evaluation metrics. The source code is publicly available at https://github.com/ssu-humane/VILLAIN.","authors":["Jaeyoon Jung","Yejun Yoon","Kunwoo Park"],"pdf_url":"","comment":"A system description paper for the AVerImaTeC shared task at the Ninth FEVER Workshop (co-located with EACL 2026)"},{"id":"http://arxiv.org/abs/2602.01560v2","updated":"2026-02-20T03:07:09Z","published":"2026-02-02T02:54:29Z","title":"Argument Rarity-based Originality Assessment for AI-Assisted Writing","summary":"This study proposes Argument Rarity-based Originality Assessment (AROA), a framework for automatically evaluating argumentative originality in student essays. AROA defines originality as rarity within a reference corpus and evaluates it through four complementary components: structural rarity, claim rarity, evidence rarity, and cognitive depth, quantified via density estimation and integrated with quality adjustment. Experiments using 1,375 human essays and 1,000 AI-generated essays on two argumentative topics revealed three key findings. First, a strong negative correlation ($r = -0.67$) between text quality and claim rarity demonstrates a quality-originality trade-off. Second, while AI essays achieved near-perfect quality scores ($Q = 0.998$), their claim rarity was approximately one-fifth of human levels (AI: 0.037, human: 0.170), indicating that LLMs can reproduce argumentative structure but not semantic originality. Third, the four components showed low mutual correlations ($r = 0.06$--$0.13$ between structural and semantic dimensions), confirming that they capture genuinely independent aspects of originality. These results suggest that writing assessment in the AI era must shift from quality to originality.","authors":["Keito Inoshita","Michiaki Omura","Tsukasa Yamanaka","Go Maeda","Kentaro Tsuji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17949v1","updated":"2026-02-20T03:00:13Z","published":"2026-02-20T03:00:13Z","title":"CUICurate: A GraphRAG-based Framework for Automated Clinical Concept Curation for NLP applications","summary":"Background: Clinical named entity recognition tools commonly map free text to Unified Medical Language System (UMLS) Concept Unique Identifiers (CUIs). For many downstream tasks, however, the clinically meaningful unit is not a single CUI but a concept set comprising related synonyms, subtypes, and supertypes. Constructing such concept sets is labour-intensive, inconsistently performed, and poorly supported by existing tools, particularly for NLP pipelines that operate directly on UMLS CUIs. Methods We present CUICurate, a Graph-based retrieval-augmented generation (GraphRAG) framework for automated UMLS concept set curation. A UMLS knowledge graph (KG) was constructed and embedded for semantic retrieval. For each target concept, candidate CUIs were retrieved from the KG, followed by large language model (LLM) filtering and classification steps comparing two LLMs (GPT-5 and GPT-5-mini). The framework was evaluated on five lexically heterogeneous clinical concepts against a manually curated benchmark and gold-standard concept sets. Results Across all concepts, CUICurate produced substantially larger and more complete concept sets than the manual benchmarks whilst matching human precision. Comparisons between the two LLMs found that GPT-5-mini achieved higher recall during filtering, while GPT-5 produced classifications that more closely aligned with clinician judgements. Outputs were stable across repeated runs and computationally inexpensive. Conclusions CUICurate offers a scalable and reproducible approach to support UMLS concept set curation that substantially reduces manual effort. By integrating graph-based retrieval with LLM reasoning, the framework produces focused candidate concept sets that can be adapted to clinical NLP pipelines for different phenotyping and analytic requirements.","authors":["Victoria Blake","Mathew Miller","Jamie Novak","Sze-yuan Ooi","Blanca Gallego"],"pdf_url":"","comment":"30 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2511.19269v2","updated":"2026-02-20T02:50:33Z","published":"2025-11-24T16:21:25Z","title":"CDLM: Consistency Diffusion Language Models For Faster Sampling","summary":"Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.","authors":["Minseo Kim","Chenfeng Xu","Coleman Hooper","Harman Singh","Ben Athiwaratkun","Ce Zhang","Kurt Keutzer","Amir Gholami"],"pdf_url":"","comment":"Accepted to MLSys 2026"},{"id":"http://arxiv.org/abs/2602.17053v2","updated":"2026-02-20T02:33:10Z","published":"2026-02-19T03:49:37Z","title":"RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models","summary":"Large Reasoning Models (LRMs) exhibit strong performance, yet often produce rationales that sound plausible but fail to reflect their true decision process, undermining reliability and trust. We introduce a formal framework for reasoning faithfulness, defined by two testable conditions: stance consistency (a coherent stance linking reasoning to answer) and causal influence (the stated reasoning causally drives the answer under output-level interventions), explicitly decoupled from accuracy. To operationalize this, we present RFEval, a benchmark of 7,186 instances across seven tasks that probes faithfulness via controlled, output-level counterfactual interventions. Evaluating twelve open-source LRMs, we find unfaithfulness in 49.7% of outputs, predominantly from stance inconsistency. Failures are concentrated in brittle, convergent domains such as math and code, and correlate more with post-training regimes than with scale: within-family ablations indicate that adding current RL-style objectives on top of supervised fine-tuning can reduce reasoning faithfulness, even when accuracy is maintained. Crucially, accuracy is neither a sufficient nor a reliable proxy for faithfulness: once controlling for model and task, the accuracy-faithfulness link is weak and statistically insignificant. Our work establishes a rigorous methodology for auditing LRM reliability and shows that trustworthy AI requires optimizing not only for correct outcomes but also for the structural integrity of the reasoning process. Our code and dataset can be found at project page: https://aidaslab.github.io/RFEval/}{https://aidaslab.github.io/RFEval/","authors":["Yunseok Han","Yejoon Lee","Jaeyoung Do"],"pdf_url":"","comment":"Accepted in ICLR 2026 Poster: https://iclr.cc/virtual/2026/poster/10011763"},{"id":"http://arxiv.org/abs/2504.17311v3","updated":"2026-02-20T02:26:11Z","published":"2025-04-24T07:12:37Z","title":"FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation","summary":"We present FLUKE (Framework for LingUistically-driven and tasK-agnostic robustness Evaluation), a framework for assessing model robustness through systematic minimal variations of test data. FLUKE introduces controlled variations across linguistic levels -- from orthography to dialect and style -- and leverages large language models (LLMs) with human validation to generate modifications. We demonstrate FLUKE's utility by evaluating both fine-tuned models and LLMs across six diverse NLP tasks (four classification and two generation tasks), and reveal that (1) the impact of linguistic variations is highly task-dependent, with some tests being critical for certain tasks but irrelevant for others; (2) LLMs still exhibit significant brittleness to certain linguistic variations, with reasoning LLMs surprisingly showing less robustness on some tasks compared to base models, and scaling improving robustness only for surface-level modifications; (3) models are overall more brittle to natural, fluent modifications such as syntax or style changes (and especially to negation), compared to corruption-style tests such as letter flipping; (4) the ability of a model to use a linguistic feature in generation does not correlate to its robustness to this feature on downstream tasks. These findings highlight the importance of systematic robustness testing for understanding model behaviors.","authors":["Yulia Otmakhova","Hung Thinh Truong","Rahmad Mahendra","Zenan Zhai","Rongxin Zhu","Daniel Beck","Jey Han Lau"],"pdf_url":"","comment":"Accepted to EACL 2026 Findings"},{"id":"http://arxiv.org/abs/2408.07238v3","updated":"2026-02-20T02:02:56Z","published":"2024-08-13T23:59:36Z","title":"Beyond Mimicry to Contextual Guidance: Knowledge Distillation for Interactive AI","summary":"As large language models increasingly mediate firm - customer interactions, firms face a tradeoff: the most capable models perform well but are costly and difficult to control at scale. Existing knowledge distillation methods address this challenge by training weaker, deployable models to imitate frontier outputs; however, such open-loop approaches are poorly suited to interactive, multi-turn settings where responses must be sequenced coherently across conversational states. We propose a shift in what knowledge is distilled - from output imitation to contextual guidance. We develop a framework in which a superior teacher model constructs a reusable library of strategic textual guidance for particular scenarios likely to be encountered by the student. When deployed, the student retrieves the context-specific guidance at inference time, enabling adaptive behavior without retraining. Using customer-service interactions, we show that this approach improves service quality and customer satisfaction relative to standard fine-tuning while maintaining alignment with firm policies. The results position inference-time textual guidance as a scalable and controllable approach to distillation for interactive AI agents in marketing settings.","authors":["Tong Wang","K. Sudhir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17937v1","updated":"2026-02-20T01:56:27Z","published":"2026-02-20T01:56:27Z","title":"Analyzing LLM Instruction Optimization for Tabular Fact Verification","summary":"Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.","authors":["Xiaotang Du","Giwon Hong","Wai-Chung Kwan","Rohit Saxena","Ivan Titov","Pasquale Minervini","Emily Allaway"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17911v1","updated":"2026-02-20T00:17:14Z","published":"2026-02-20T00:17:14Z","title":"Condition-Gated Reasoning for Context-Dependent Biomedical Question Answering","summary":"Current biomedical question answering (QA) systems often assume that medical knowledge applies uniformly, yet real-world clinical reasoning is inherently conditional: nearly every decision depends on patient-specific factors such as comorbidities and contraindications. Existing benchmarks do not evaluate such conditional reasoning, and retrieval-augmented or graph-based methods lack explicit mechanisms to ensure that retrieved knowledge is applicable to given context. To address this gap, we propose CondMedQA, the first benchmark for conditional biomedical QA, consisting of multi-hop questions whose answers vary with patient conditions. Furthermore, we propose Condition-Gated Reasoning (CGR), a novel framework that constructs condition-aware knowledge graphs and selectively activates or prunes reasoning paths based on query conditions. Our findings show that CGR more reliably selects condition-appropriate answers while matching or exceeding state-of-the-art performance on biomedical QA benchmarks, highlighting the importance of explicitly modeling conditionality for robust medical reasoning.","authors":["Jash Rajesh Parekh","Wonbin Kweon","Joey Chan","Rezarta Islamaj","Robert Leaman","Pengcheng Jiang","Chih-Hsuan Wei","Zhizheng Wang","Zhiyong Lu","Jiawei Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17907v1","updated":"2026-02-20T00:12:04Z","published":"2026-02-20T00:12:04Z","title":"Improving Neural Topic Modeling with Semantically-Grounded Soft Label Distributions","summary":"Traditional neural topic models are typically optimized by reconstructing the document's Bag-of-Words (BoW) representations, overlooking contextual information and struggling with data sparsity. In this work, we propose a novel approach to construct semantically-grounded soft label targets using Language Models (LMs) by projecting the next token probabilities, conditioned on a specialized prompt, onto a pre-defined vocabulary to obtain contextually enriched supervision signals. By training the topic models to reconstruct the soft labels using the LM hidden states, our method produces higher-quality topics that are more closely aligned with the underlying thematic structure of the corpus. Experiments on three datasets show that our method achieves substantial improvements in topic coherence, purity over existing baselines. Additionally, we also introduce a retrieval-based metric, which shows that our approach significantly outperforms existing methods in identifying semantically similar documents, highlighting its effectiveness for retrieval-oriented applications.","authors":["Raymond Li","Amirhossein Abaskohi","Chuyuan Li","Gabriel Murray","Giuseppe Carenini"],"pdf_url":"","comment":"20 pages, 5 figures"},{"id":"http://arxiv.org/abs/2602.17905v1","updated":"2026-02-20T00:07:18Z","published":"2026-02-20T00:07:18Z","title":"Games That Teach, Chats That Convince: Comparing Interactive and Static Formats for Persuasive Learning","summary":"Interactive systems such as chatbots and games are increasingly used to persuade and educate on sustainability-related topics, yet it remains unclear how different delivery formats shape learning and persuasive outcomes when content is held constant. Grounding on identical arguments and factual content across conditions, we present a controlled user study comparing three modes of information delivery: static essays, conversational chatbots, and narrative text-based games. Across subjective measures, the chatbot condition consistently outperformed the other modes and increased perceived importance of the topic. However, perceived learning did not reliably align with objective outcomes: participants in the text-based game condition reported learning less than those reading essays, yet achieved higher scores on a delayed (24-hour) knowledge quiz. Additional exploratory analyses further suggest that common engagement proxies, such as verbosity and interaction length, are more closely related to subjective experience than to actual learning. These findings highlight a dissociation between how persuasive experiences feel and what participants retain, and point to important design trade-offs between interactivity, realism, and learning in persuasive systems and serious games.","authors":["Seyed Hossein Alavi","Zining Wang","Shruthi Chockkalingam","Raymond T. Ng","Vered Shwartz"],"pdf_url":"","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2602.18434v1","updated":"2026-02-20T18:59:50Z","published":"2026-02-20T18:59:50Z","title":"Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory","summary":"Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.","authors":["Vatsal Agarwal","Saksham Suri","Matthew Gwilliam","Pulkit Kumar","Abhinav Shrivastava"],"pdf_url":"","comment":"Project page: see https://vatsalag99.github.io/memstream/"},{"id":"http://arxiv.org/abs/2602.18432v1","updated":"2026-02-20T18:59:35Z","published":"2026-02-20T18:59:35Z","title":"SARAH: Spatially Aware Real-time Agentic Humans","summary":"As embodied agents become central to VR, telepresence, and digital human applications, their motion must go beyond speech-aligned gestures: agents should turn toward users, respond to their movement, and maintain natural gaze. Current methods lack this spatial awareness. We close this gap with the first real-time, fully causal method for spatially-aware conversational motion, deployable on a streaming VR headset. Given a user's position and dyadic audio, our approach produces full-body motion that aligns gestures with speech while orienting the agent according to the user. Our architecture combines a causal transformer-based VAE with interleaved latent tokens for streaming inference and a flow matching model conditioned on user trajectory and audio. To support varying gaze preferences, we introduce a gaze scoring mechanism with classifier-free guidance to decouple learning from control: the model captures natural spatial alignment from data, while users can adjust eye contact intensity at inference time. On the Embody 3D dataset, our method achieves state-of-the-art motion quality at over 300 FPS -- 3x faster than non-causal baselines -- while capturing the subtle spatial dynamics of natural conversation. We validate our approach on a live VR system, bringing spatially-aware conversational agents to real-time deployment. Please see https://evonneng.github.io/sarah/ for details.","authors":["Evonne Ng","Siwei Zhang","Zhang Chen","Michael Zollhoefer","Alexander Richard"],"pdf_url":"","comment":"Project page: https://evonneng.github.io/sarah/"},{"id":"http://arxiv.org/abs/2602.18428v1","updated":"2026-02-20T18:49:00Z","published":"2026-02-20T18:49:00Z","title":"The Geometry of Noise: Why Diffusion Models Don't Need Noise Conditioning","summary":"Autonomous (noise-agnostic) generative models, such as Equilibrium Matching and blind diffusion, challenge the standard paradigm by learning a single, time-invariant vector field that operates without explicit noise-level conditioning. While recent work suggests that high-dimensional concentration allows these models to implicitly estimate noise levels from corrupted observations, a fundamental paradox remains: what is the underlying landscape being optimized when the noise level is treated as a random variable, and how can a bounded, noise-agnostic network remain stable near the data manifold where gradients typically diverge? We resolve this paradox by formalizing Marginal Energy, $E_{\\text{marg}}(\\mathbf{u}) = -\\log p(\\mathbf{u})$, where $p(\\mathbf{u}) = \\int p(\\mathbf{u}|t)p(t)dt$ is the marginal density of the noisy data integrated over a prior distribution of unknown noise levels. We prove that generation using autonomous models is not merely blind denoising, but a specific form of Riemannian gradient flow on this Marginal Energy. Through a novel relative energy decomposition, we demonstrate that while the raw Marginal Energy landscape possesses a $1/t^p$ singularity normal to the data manifold, the learned time-invariant field implicitly incorporates a local conformal metric that perfectly counteracts the geometric singularity, converting an infinitely deep potential well into a stable attractor. We also establish the structural stability conditions for sampling with autonomous models. We identify a ``Jensen Gap'' in noise-prediction parameterizations that acts as a high-gain amplifier for estimation errors, explaining the catastrophic failure observed in deterministic blind models. Conversely, we prove that velocity-based parameterizations are inherently stable because they satisfy a bounded-gain condition that absorbs posterior uncertainty into a smooth geometric drift.","authors":["Mojtaba Sahraee-Ardakan","Mauricio Delbracio","Peyman Milanfar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18426v1","updated":"2026-02-20T18:48:36Z","published":"2026-02-20T18:48:36Z","title":"Spatio-Spectroscopic Representation Learning using Unsupervised Convolutional Long-Short Term Memory Networks","summary":"Integral Field Spectroscopy (IFS) surveys offer a unique new landscape in which to learn in both spatial and spectroscopic dimensions and could help uncover previously unknown insights into galaxy evolution. In this work, we demonstrate a new unsupervised deep learning framework using Convolutional Long-Short Term Memory Network Autoencoders to encode generalized feature representations across both spatial and spectroscopic dimensions spanning $19$ optical emission lines (3800A $< λ<$ 8000A) among a sample of $\\sim 9000$ galaxies from the MaNGA IFS survey. As a demonstrative exercise, we assess our model on a sample of $290$ Active Galactic Nuclei (AGN) and highlight scientifically interesting characteristics of some highly anomalous AGN.","authors":["Kameswara Bharadwaj Mantha","Lucy Fortson","Ramanakumar Sankar","Claudia Scarlata","Chris Lintott","Sandor Kruk","Mike Walmsley","Hugh Dickinson","Karen Masters","Brooke Simmons","Rebecca Smethurst"],"pdf_url":"","comment":"This manuscript was previously submitted to ICML for peer review. Reviewers noted that while the underlying VAE-based architecture builds on established methods, its application to spatially-resolved IFS data is promising for unsupervised representation learning in astronomy. This version is released for community visibility. Reviewer decisions: Weak accept and Weak reject (Final: Reject)"},{"id":"http://arxiv.org/abs/2602.18424v1","updated":"2026-02-20T18:46:27Z","published":"2026-02-20T18:46:27Z","title":"CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation","summary":"Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav","authors":["Xia Su","Ruiqi Chen","Benlin Liu","Jingwei Ma","Zonglin Di","Ranjay Krishna","Jon Froehlich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18422v1","updated":"2026-02-20T18:45:29Z","published":"2026-02-20T18:45:29Z","title":"Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control","summary":"Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.","authors":["Linxi Xie","Lisong C. Sun","Ashley Neall","Tong Wu","Shengqu Cai","Gordon Wetzstein"],"pdf_url":"","comment":"Project page here: https://codeysun.github.io/generated-reality"},{"id":"http://arxiv.org/abs/2602.18406v1","updated":"2026-02-20T18:14:05Z","published":"2026-02-20T18:14:05Z","title":"Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges","summary":"Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.","authors":["Minh Dinh","Stéphane Deny"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18400v1","updated":"2026-02-20T18:05:39Z","published":"2026-02-20T18:05:39Z","title":"Exploiting Completeness Perception with Diffusion Transformer for Unified 3D MRI Synthesis","summary":"Missing data problems, such as missing modalities in multi-modal brain MRI and missing slices in cardiac MRI, pose significant challenges in clinical practice. Existing methods rely on external guidance to supply detailed missing state for instructing generative models to synthesize missing MRIs. However, manual indicators are not always available or reliable in real-world scenarios due to the unpredictable nature of clinical environments. Moreover, these explicit masks are not informative enough to provide guidance for improving semantic consistency. In this work, we argue that generative models should infer and recognize missing states in a self-perceptive manner, enabling them to better capture subtle anatomical and pathological variations. Towards this goal, we propose CoPeDiT, a general-purpose latent diffusion model equipped with completeness perception for unified synthesis of 3D MRIs. Specifically, we incorporate dedicated pretext tasks into our tokenizer, CoPeVAE, empowering it to learn completeness-aware discriminative prompts, and design MDiT3D, a specialized diffusion transformer architecture for 3D MRI synthesis, that effectively uses the learned prompts as guidance to enhance semantic consistency in 3D space. Comprehensive evaluations on three large-scale MRI datasets demonstrate that CoPeDiT significantly outperforms state-of-the-art methods, achieving superior robustness, generalizability, and flexibility. The code is available at https://github.com/JK-Liu7/CoPeDiT .","authors":["Junkai Liu","Nay Aung","Theodoros N. Arvanitis","Joao A. C. Lima","Steffen E. Petersen","Daniel C. Alexander","Le Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18394v1","updated":"2026-02-20T17:58:46Z","published":"2026-02-20T17:58:46Z","title":"Self-Aware Object Detection via Degradation Manifolds","summary":"Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.\n  We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.\n  To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.\n  Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.","authors":["Stefan Becker","Simon Weiss","Wolfgang Hübner","Michael Arens"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11409v3","updated":"2026-02-20T17:09:35Z","published":"2025-05-16T16:17:22Z","title":"Visual Planning: Let's Think Only with Images","summary":"Recent advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have substantially enhanced machine reasoning across diverse tasks. However, these models predominantly rely on pure text as the medium for both expressing and structuring reasoning, even when visual information is present. In this work, we argue that language may not always be the most natural or effective modality for reasoning, particularly in tasks involving spatial and geometrical information. Motivated by this, we propose a new paradigm, Visual Planning, which enables planning through purely visual representations for these \"vision-first\" tasks, as a supplementary channel to language-based reasoning. In this paradigm, planning is executed via sequences of images that encode step-by-step inference in the visual domain, akin to how humans sketch or visualize future actions. We introduce a novel reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), empowered by GRPO for post-training large vision models, leading to substantial improvements in planning in a selection of representative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our visual planning paradigm outperforms all other planning variants that conduct reasoning in the text-only space. Our results establish Visual Planning as a viable and promising supplement to language-based reasoning, opening new avenues for tasks that benefit from intuitive, image-based inference.","authors":["Yi Xu","Chengzu Li","Han Zhou","Xingchen Wan","Caiqi Zhang","Anna Korhonen","Ivan Vulić"],"pdf_url":"","comment":"ICLR 2026 (Oral)"},{"id":"http://arxiv.org/abs/2602.18350v1","updated":"2026-02-20T17:02:16Z","published":"2026-02-20T17:02:16Z","title":"Quantum-enhanced satellite image classification","summary":"We demonstrate the application of a quantum feature extraction method to enhance multi-class image classification for space applications. By harnessing the dynamics of many-body spin Hamiltonians, the method generates expressive quantum features that, when combined with classical processing, lead to quantum-enhanced classification accuracy. Using a strong and well-established ResNet50 baseline, we achieved a maximum classical accuracy of 83%, which can be improved to 84% with a transfer learning approach. In contrast, applying our quantum-classical method the performance is increased to 87% accuracy, demonstrating a clear and reproducible improvement over robust classical approaches. Implemented on several of IBM's quantum processors, our hybrid quantum-classical approach delivers consistent gains of 2-3% in absolute accuracy. These results highlight the practical potential of current and near-term quantum processors in high-stakes, data-driven domains such as satellite imaging and remote sensing, while suggesting broader applicability in real-world machine learning tasks.","authors":["Qi Zhang","Anton Simen","Carlos Flores-Garrigós","Gabriel Alvarado Barrios","Paolo A. Erdman","Enrique Solano","Aaron C. Kemp","Vincent Beltrani","Vedangi Pathak","Hamed Mohammadbagherpoor"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16086v2","updated":"2026-02-20T16:45:42Z","published":"2026-02-17T23:20:26Z","title":"LGQ: Learning Discretization Geometry for Scalable and Stable Image Tokenization","summary":"Discrete image tokenization is a key bottleneck for scalable visual generation: a tokenizer must remain compact for efficient latent-space priors while preserving semantic structure and using discrete capacity effectively. Existing quantizers face a trade-off: vector-quantized tokenizers learn flexible geometries but often suffer from biased straight-through optimization, codebook under-utilization, and representation collapse at large vocabularies. Structured scalar or implicit tokenizers ensure stable, near-complete utilization by design, yet rely on fixed discretization geometries that may allocate capacity inefficiently under heterogeneous latent statistics.\n  We introduce Learnable Geometric Quantization (LGQ), a discrete image tokenizer that learns discretization geometry end-to-end. LGQ replaces hard nearest-neighbor lookup with temperature-controlled soft assignments, enabling fully differentiable training while recovering hard assignments at inference. The assignments correspond to posterior responsibilities of an isotropic Gaussian mixture and minimize a variational free-energy objective, provably converging to nearest-neighbor quantization in the low-temperature limit. LGQ combines a token-level peakedness regularizer with a global usage regularizer to encourage confident yet balanced code utilization without imposing rigid grids.\n  Under a controlled VQGAN-style backbone on ImageNet across multiple vocabulary sizes, LGQ achieves stable optimization and balanced utilization. At 16K codebook size, LGQ improves rFID by 11.88% over FSQ while using 49.96% fewer active codes, and improves rFID by 6.06% over SimVQ with 49.45% lower effective representation rate, achieving comparable fidelity with substantially fewer active entries. Our GitHub repository is available at: https://github.com/KurbanIntelligenceLab/LGQ","authors":["Idil Bilge Altun","Mert Onur Cakiroglu","Elham Buxton","Mehmet Dalkilic","Hasan Kurban"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18329v1","updated":"2026-02-20T16:35:24Z","published":"2026-02-20T16:35:24Z","title":"G-LoG Bi-filtration for Medical Image Classification","summary":"Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.","authors":["Qingsong Wang","Jiaxing He","Bingzhe Hou","Tieru Wu","Yang Cao","Cailing Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18322v1","updated":"2026-02-20T16:20:50Z","published":"2026-02-20T16:20:50Z","title":"Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis","summary":"High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.","authors":["Ziteng Cui","Shuhong Liu","Xiaoyu Dong","Xuangeng Chu","Lin Gu","Ming-Hsuan Yang","Tatsuya Harada"],"pdf_url":"","comment":"Journal extension version of CVPR 2025 paper: arXiv:2504.01503"},{"id":"http://arxiv.org/abs/2602.18314v1","updated":"2026-02-20T16:14:21Z","published":"2026-02-20T16:14:21Z","title":"Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting","summary":"Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.","authors":["Tianyi Song","Danail Stoyanov","Evangelos Mazomenos","Francisco Vasconcelos"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2507.08831v4","updated":"2026-02-20T16:14:13Z","published":"2025-07-05T18:04:35Z","title":"View Invariant Learning for Vision-Language Navigation in Continuous Environments","summary":"Vision-Language Navigation in Continuous Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is a key research problem in embodied AI. However, most existing approaches are sensitive to viewpoint changes, i.e. variations in camera height and viewing angle. Here we introduce a more general scenario, V$^2$-VLNCE (VLNCE with Varied Viewpoints) and propose a view-invariant post-training framework, called VIL (View Invariant Learning), that makes existing navigation policies more robust to changes in camera viewpoint. VIL employs a contrastive learning framework to learn sparse and view-invariant features. We also introduce a teacher-student framework for the Waypoint Predictor Module, a standard part of VLNCE baselines, where a view-dependent teacher model distills knowledge into a view-invariant student model. We employ an end-to-end training paradigm to jointly optimize these components. Empirical results show that our method outperforms state-of-the-art approaches on V$^2$-VLNCE by 8-15\\% measured on Success Rate for two standard benchmark datasets R2R-CE and RxR-CE. Evaluation of VIL in standard VLNCE settings shows that despite being trained for varied viewpoints, VIL often still improves performance. On the harder RxR-CE dataset, our method also achieved state-of-the-art performance across all metrics. This suggests that adding VIL does not diminish the standard viewpoint performance and can serve as a plug-and-play post-training method. We further evaluate VIL for simulated camera placements derived from real robot configurations (e.g. Stretch RE-1, LoCoBot), showing consistent improvements of performance. Finally, we present a proof-of-concept real-robot evaluation in two physical environments using a panoramic RGB sensor combined with LiDAR. The code is available at https://github.com/realjoshqsun/V2-VLNCE.","authors":["Josh Qixuan Sun","Huaiyuan Weng","Xiaoying Xing","Chul Min Yeum","Mark Crowley"],"pdf_url":"","comment":"This paper is accepted to RA-L 2026"},{"id":"http://arxiv.org/abs/2602.18309v1","updated":"2026-02-20T16:07:31Z","published":"2026-02-20T16:07:31Z","title":"Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation","summary":"Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an \"in the wild\" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.","authors":["Ziyue Liu","Davide Talon","Federico Girella","Zanxi Ruan","Mattia Mondo","Loris Bazzani","Yiming Wang","Marco Cristani"],"pdf_url":"","comment":"Project page: https://intelligolabs.github.io/lots/"},{"id":"http://arxiv.org/abs/2506.05647v4","updated":"2026-02-20T15:38:19Z","published":"2025-06-06T00:32:04Z","title":"Learning to Weight Parameters for Training Data Attribution","summary":"We study gradient-based data attribution, aiming to identify which training examples most influence a given output. Existing methods for this task either treat network parameters uniformly or rely on implicit weighting derived from Hessian approximations, which do not fully model functional heterogeneity of network parameters. To address this, we propose a method to explicitly learn parameter importance weights directly from data, without requiring annotated labels. Our approach improves attribution accuracy across diverse tasks, including image classification, language modeling, and diffusion, and enables fine-grained attribution for concepts like subject and style.","authors":["Shuangqi Li","Hieu Le","Jingyi Xu","Mathieu Salzmann"],"pdf_url":"","comment":"31 pages"},{"id":"http://arxiv.org/abs/2602.18282v1","updated":"2026-02-20T15:11:04Z","published":"2026-02-20T15:11:04Z","title":"DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control","summary":"Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.","authors":["Shiyan Du","Conghan Yue","Xinyu Cheng","Dongyu Zhang"],"pdf_url":"","comment":"Accepted by AAAI 2026"},{"id":"http://arxiv.org/abs/2510.06170v3","updated":"2026-02-20T15:00:19Z","published":"2025-10-07T17:33:41Z","title":"Smartphone-based iris recognition through high-quality visible-spectrum iris image capture.V2","summary":"Smartphone-based iris recognition in the visible spectrum (VIS) remains difficult due to illumination variability, pigmentation differences, and the absence of standardized capture controls. This work presents a compact end-to-end pipeline that enforces ISO/IEC 29794-6 quality compliance at acquisition and demonstrates that accurate VIS iris recognition is feasible on commodity devices. Using a custom Android application performing real-time framing, sharpness evaluation, and feedback, we introduce the CUVIRIS dataset of 752 compliant images from 47 subjects. A lightweight MobileNetV3-based multi-task segmentation network (LightIrisNet) is developed for efficient on-device processing, and a transformer matcher (IrisFormer) is adapted to the VIS domain. Under a standardized protocol and comparative benchmarking against prior CNN baselines, OSIRIS attains a TAR of 97.9% at FAR=0.01 (EER=0.76%), while IrisFormer, trained only on UBIRIS.v2, achieves an EER of 0.057% on CUVIRIS. The acquisition app, trained models, and a public subset of the dataset are released to support reproducibility. These results confirm that standardized capture and VIS-adapted lightweight models enable accurate and practical iris recognition on smartphones.","authors":["Naveenkumar G Venkataswamy","Yu Liu","Soumyabrata Dey","Stephanie Schuckers","Masudul H Imtiaz"],"pdf_url":"","comment":"The new version is available at arXiv:2512.15548"},{"id":"http://arxiv.org/abs/2602.18258v1","updated":"2026-02-20T14:43:46Z","published":"2026-02-20T14:43:46Z","title":"RoEL: Robust Event-based 3D Line Reconstruction","summary":"Event cameras in motion tend to detect object boundaries or texture edges, which produce lines of brightness changes, especially in man-made environments. While lines can constitute a robust intermediate representation that is consistently observed, the sparse nature of lines may lead to drastic deterioration with minor estimation errors. Only a few previous works, often accompanied by additional sensors, utilize lines to compensate for the severe domain discrepancies of event sensors along with unpredictable noise characteristics. We propose a method that can stably extract tracks of varying appearances of lines using a clever algorithmic process that observes multiple representations from various time slices of events, compensating for potential adversaries within the event data. We then propose geometric cost functions that can refine the 3D line maps and camera poses, eliminating projective distortions and depth ambiguities. The 3D line maps are highly compact and can be equipped with our proposed cost function, which can be adapted for any observations that can detect and extract line structures or projections of them, including 3D point cloud maps or image observations. We demonstrate that our formulation is powerful enough to exhibit a significant performance boost in event-based mapping and pose refinement across diverse datasets, and can be flexibly applied to multimodal scenarios. Our results confirm that the proposed line-based formulation is a robust and effective approach for the practical deployment of event-based perceptual modules. Project page: https://gwangtak.github.io/roel/","authors":["Gwangtak Bae","Jaeho Shin","Seunggu Kang","Junho Kim","Ayoung Kim","Young Min Kim"],"pdf_url":"","comment":"IEEE Transactions on Robotics (T-RO)"},{"id":"http://arxiv.org/abs/2602.18252v1","updated":"2026-02-20T14:39:17Z","published":"2026-02-20T14:39:17Z","title":"On the Adversarial Robustness of Discrete Image Tokenizers","summary":"Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial attacks has not been explored. Ours being the first work studying this topic, we first formulate attacks that aim to perturb the features extracted by discrete tokenizers, and thus change the extracted tokens. These attacks are computationally efficient, application-agnostic, and effective across classification, multimodal retrieval, and captioning tasks. Second, to defend against this vulnerability, inspired by recent work on robust CLIP encoders, we fine-tune popular tokenizers with unsupervised adversarial training, keeping all other components frozen. While unsupervised and task-agnostic, our approach significantly improves robustness to both unsupervised and end-to-end supervised attacks and generalizes well to unseen tasks and data. Unlike supervised adversarial training, our approach can leverage unlabeled images, making it more versatile. Overall, our work highlights the critical role of tokenizer robustness in downstream tasks and presents an important step in the development of safe multimodal foundation models.","authors":["Rishika Bhagwatkar","Irina Rish","Nicolas Flammarion","Francesco Croce"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.19322v2","updated":"2026-02-20T14:37:26Z","published":"2024-11-28T18:59:02Z","title":"SAMa: Material-aware 3D Selection and Segmentation","summary":"Decomposing 3D assets into material parts is a common task for artists, yet remains a highly manual process. In this work, we introduce Select Any Material (SAMa), a material selection approach for in-the-wild objects in arbitrary 3D representations. Building on SAM2's video prior, we construct a material-centric video dataset that extends it to the material domain. We propose an efficient way to lift the model's 2D predictions to 3D by projecting each view into an intermediary 3D point cloud using depth. Nearest-neighbor lookups between any 3D representation and this similarity point cloud allow us to efficiently reconstruct accurate selection masks over objects' surfaces that can be inspected from any view. Our method is multiview-consistent by design, alleviating the need for costly per-asset optimization, and performs optimization-free selection in seconds. SAMa outperforms several strong baselines in selection accuracy and multiview consistency and enables various compelling applications, such as replacing the diffuse-textured materials on a text-to-3D output with PBR materials or selecting and editing materials on NeRFs and 3DGS captures.","authors":["Michael Fischer","Iliyan Georgiev","Thibault Groueix","Vladimir G. Kim","Tobias Ritschel","Valentin Deschaintre"],"pdf_url":"","comment":"Project Page: https://mfischer-ucl.github.io/sama"},{"id":"http://arxiv.org/abs/2507.11551v2","updated":"2026-02-20T13:30:16Z","published":"2025-07-13T07:17:53Z","title":"Landmark Detection for Medical Images using a General-purpose Segmentation Model","summary":"Radiographic images are a cornerstone of medical diagnostics in orthopaedics, with anatomical landmark detection serving as a crucial intermediate step for information extraction. General-purpose foundational segmentation models, such as SAM (Segment Anything Model), do not support landmark segmentation out of the box and require prompts to function. However, in medical imaging, the prompts for landmarks are highly specific. Since SAM has not been trained to recognize such landmarks, it cannot generate accurate landmark segmentations for diagnostic purposes. Even MedSAM, a medically adapted variant of SAM, has been trained to identify larger anatomical structures, such as organs and their parts, and lacks the fine-grained precision required for orthopaedic pelvic landmarks. To address this limitation, we propose leveraging another general-purpose, non-foundational model: YOLO. YOLO excels in object detection and can provide bounding boxes that serve as input prompts for SAM. While YOLO is efficient at detection, it is significantly outperformed by SAM in segmenting complex structures. In combination, these two models form a reliable pipeline capable of segmenting not only a small pilot set of eight anatomical landmarks but also an expanded set of 72 landmarks and 16 regions with complex outlines, such as the femoral cortical bone and the pelvic inlet. By using YOLO-generated bounding boxes to guide SAM, we trained the hybrid model to accurately segment orthopaedic pelvic radiographs. Our results show that the proposed combination of YOLO and SAM yields excellent performance in detecting anatomical landmarks and intricate outlines in orthopaedic pelvic radiographs.","authors":["Ekaterina Stansfield","Jennifer A. Mitterer","Abdulrahman Altahhan"],"pdf_url":"","comment":"13 pages, 8 figures, 2 tables. Submitted to ICONIP 2025"},{"id":"http://arxiv.org/abs/2505.13309v2","updated":"2026-02-20T13:26:38Z","published":"2025-05-19T16:26:18Z","title":"eStonefish-Scenes: A Sim-to-Real Validated and Robot-Centric Event-based Optical Flow Dataset for Underwater Vehicles","summary":"Event-based cameras (EBCs) are poised to transform underwater robotics, yet the absence of labelled event-based datasets for underwater environments severely limits progress in tasks such as visual odometry and obstacle avoidance. Real-world event-based optical flow datasets are scarce, resource-intensive to collect, and lack diversity, while no prior benchmarks target underwater applications. To bridge this gap, we introduce eStonefish-Scenes, a synthetic event-based optical flow dataset generated using the Stonefish simulator, together with an open data generation pipeline for creating customizable underwater environments featuring realistic coral reefs and biologically inspired schools of fish with reactive navigation behaviours. We also present eWiz, a comprehensive library for event-based data processing, encompassing data loading, augmentation, visualization, encoding, training utilities, loss functions, and evaluation metrics. To validate sim-to-real transferability, we collected real-world data using a DAVIS346 hybrid event-and-frame camera mounted on a BlueROV2 in an indoor testing pool. Ground-truth optical flow was derived via homography-based frame-to-poster registration, and per-pixel uncertainty was estimated through Monte Carlo perturbation of keypoint correspondences. This uncertainty was incorporated into the evaluation metrics, enabling reliability-aware performance assessment. A ConvGRU-based optical flow network, trained exclusively on synthetic eStonefish-Scenes data, was evaluated on the real-world sequences without fine-tuning, achieving an uncertainty-weighted average endpoint error of 0.79 pixels. These results demonstrate that the proposed synthetic dataset effectively supports sim-to-real transfer for underwater event-based optical flow estimation, substantially reducing the need for costly real-world data collection.","authors":["Jad Mansour","Sebastian Realpe","Hayat Rajani","Michele Grimaldi","Rafael Garcia","Nuno Gracias"],"pdf_url":"","comment":"This revised version extends the original, which lacked real-world validation. We added a real-world data acquisition study using a DAVIS346 camera on a BlueROV2, a homography-based ground-truth optical flow method with per-pixel uncertainty estimation, and a sim-to-real evaluation using a ConvGRU network trained on synthetic data and tested on real underwater sequences. arXiv admin note: text overlap with arXiv:2412.09209"},{"id":"http://arxiv.org/abs/2602.14498v2","updated":"2026-02-20T13:24:13Z","published":"2026-02-16T06:27:51Z","title":"Uncertainty-Aware Vision-Language Segmentation for Medical Imaging","summary":"We introduce a novel uncertainty-aware multimodal segmentation framework that leverages both radiological images and associated clinical text for precise medical diagnosis. We propose a Modality Decoding Attention Block (MoDAB) with a lightweight State Space Mixer (SSMix) to enable efficient cross-modal fusion and long-range dependency modelling. To guide learning under ambiguity, we propose the Spectral-Entropic Uncertainty (SEU) Loss, which jointly captures spatial overlap, spectral consistency, and predictive uncertainty in a unified objective. In complex clinical circumstances with poor image quality, this formulation improves model reliability. Extensive experiments on various publicly available medical datasets, QATA-COVID19, MosMed++, and Kvasir-SEG, demonstrate that our method achieves superior segmentation performance while being significantly more computationally efficient than existing State-of-the-Art (SoTA) approaches. Our results highlight the importance of incorporating uncertainty modelling and structured modality alignment in vision-language medical segmentation tasks. Code: https://github.com/arya-domain/UA-VLS","authors":["Aryan Das","Tanishq Rachamalla","Koushik Biswas","Swalpa Kumar Roy","Vinay Kumar Verma"],"pdf_url":"","comment":"Accepted in WACV 2026"},{"id":"http://arxiv.org/abs/2602.14514v2","updated":"2026-02-20T13:20:20Z","published":"2026-02-16T06:51:29Z","title":"Efficient Text-Guided Convolutional Adapter for the Diffusion Model","summary":"We introduce the Nexus Adapters, novel text-guided efficient adapters to the diffusion-based framework for the Structure Preserving Conditional Generation (SPCG). Recently, structure-preserving methods have achieved promising results in conditional image generation by using a base model for prompt conditioning and an adapter for structure input, such as sketches or depth maps. These approaches are highly inefficient and sometimes require equal parameters in the adapter compared to the base architecture. It is not always possible to train the model since the diffusion model is itself costly, and doubling the parameter is highly inefficient. In these approaches, the adapter is not aware of the input prompt; therefore, it is optimal only for the structural input but not for the input prompt. To overcome the above challenges, we proposed two efficient adapters, Nexus Prime and Slim, which are guided by prompts and structural inputs. Each Nexus Block incorporates cross-attention mechanisms to enable rich multimodal conditioning. Therefore, the proposed adapter has a better understanding of the input prompt while preserving the structure. We conducted extensive experiments on the proposed models and demonstrated that the Nexus Prime adapter significantly enhances performance, requiring only 8M additional parameters compared to the baseline, T2I-Adapter. Furthermore, we also introduced a lightweight Nexus Slim adapter with 18M fewer parameters than the T2I-Adapter, which still achieved state-of-the-art results. Code: https://github.com/arya-domain/Nexus-Adapters","authors":["Aryan Das","Koushik Biswas","Swalpa Kumar Roy","Badri Narayana Patro","Vinay Kumar Verma"],"pdf_url":"","comment":"Accepted in WACV 2026"},{"id":"http://arxiv.org/abs/2602.18199v1","updated":"2026-02-20T13:17:06Z","published":"2026-02-20T13:17:06Z","title":"A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion","summary":"Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines physically implausible motions (e.g., foot floating) while preserving semantic consistency with the original textual description. Rather than relying on complex physical modeling, we propose a self-supervised and data-driven approach, whereby DMC learns to obtain physically plausible motions when an intentionally distorted motion and the original textual descriptions are given as inputs. We evaluate DMC as a post-hoc module to improve motions obtained from various text-to-motion generation models and demonstrate its effectiveness in improving physical plausibility while enhancing semantic consistency. The experimental results show that DMC reduces FID score by 42.74% on T2M and 13.20% on T2M-GPT, while also achieving the highest R-Precision. When applied to high-quality models like MoMask, DMC improves the physical plausibility of motions by reducing penetration by 33.0% as well as adjusting floating artifacts closer to the ground-truth reference. These results highlight that DMC can serve as a promising post-hoc motion refinement framework for any kind of text-to-motion models by incorporating textual semantics and physical plausibility.","authors":["Gahyeon Shim","Soogeun Park","Hyemin Ahn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18193v1","updated":"2026-02-20T12:59:27Z","published":"2026-02-20T12:59:27Z","title":"BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards","summary":"Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning with rule-based policy principles and a critic-guided reward. A rule-driven ICoT data-synthesis pipeline jump-starts training by generating structured scene descriptions, reasoning chains and labels, cutting annotation costs. Reinforcement learning then refines the model using a composite reward balancing causal coherence with policy adherence. A multitask architecture models intra-modal manipulations (e.g., exaggerated imagery) and cross-modal mismatches (e.g., subtitle-speech drift), boosting robustness. Experiments on real short-video ads show BLM-Guard surpasses strong baselines in accuracy, consistency and generalization.","authors":["Yiran Yang","Zhaowei Liu","Yuan Yuan","Yukun Song","Xiong Ma","Yinghao Song","Xiangji Zeng","Lu Sun","Yulu Wang","Hai Zhou","Shuai Cui","Zhaohan Gong","Jiefei Zhang"],"pdf_url":"","comment":"7 pages, 3 figures. To appear in AAAI 2026"},{"id":"http://arxiv.org/abs/2602.18178v1","updated":"2026-02-20T12:32:39Z","published":"2026-02-20T12:32:39Z","title":"Evaluating Graphical Perception Capabilities of Vision Transformers","summary":"Vision Transformers, ViTs, have emerged as a powerful alternative to convolutional neural networks, CNNs, in a variety of image-based tasks. While CNNs have previously been evaluated for their ability to perform graphical perception tasks, which are essential for interpreting visualizations, the perceptual capabilities of ViTs remain largely unexplored. In this work, we investigate the performance of ViTs in elementary visual judgment tasks inspired by the foundational studies of Cleveland and McGill, which quantified the accuracy of human perception across different visual encodings. Inspired by their study, we benchmark ViTs against CNNs and human participants in a series of controlled graphical perception tasks. Our results reveal that, although ViTs demonstrate strong performance in general vision tasks, their alignment with human-like graphical perception in the visualization domain is limited. This study highlights key perceptual gaps and points to important considerations for the application of ViTs in visualization systems and graphical perceptual modeling.","authors":["Poonam Poonam","Pere-Pau Vázquez","Timo Ropinski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14201v2","updated":"2026-02-20T12:06:11Z","published":"2026-02-15T15:50:55Z","title":"GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery","summary":"The \"thinking-with-images\" paradigm enables multimodal large language models (MLLMs) to actively explore visual scenes via zoom-in tools. This is essential for ultra-high-resolution (UHR) remote sensing VQA, where task-relevant cues are sparse and tiny. However, we observe a consistent failure mode in existing zoom-enabled MLLMs: Tool Usage Homogenization, where tool calls collapse into task-agnostic patterns, limiting effective evidence acquisition. To address this, we propose GeoEyes, a staged training framework consisting of (1) a cold-start SFT dataset, UHR Chain-of-Zoom (UHR-CoZ), which covers diverse zooming regimes, and (2) an agentic reinforcement learning method, AdaZoom-GRPO, that explicitly rewards evidence gain and answer improvement during zoom interactions. The resulting model learns on-demand zooming with proper stopping behavior and achieves substantial improvements on UHR remote sensing benchmarks, with 54.23% accuracy on XLRS-Bench.","authors":["Fengxiang Wang","Mingshuo Chen","Yueying Li","Yajie Yang","Yifan Zhang","Long Lan","Xue Yang","Hongda Sun","Yulin Wang","Di Wang","Jun Song","Jing Zhang","Bo Du"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.11688v2","updated":"2026-02-20T12:03:58Z","published":"2024-10-15T15:24:08Z","title":"Visual Fixation-Based Retinal Prosthetic Simulation","summary":"This study proposes a retinal prosthetic simulation framework driven by visual fixations, inspired by the saccade mechanism, and assesses performance improvements through end-to-end optimization in a classification task. Salient patches are predicted from input images using the self-attention map of a vision transformer to mimic visual fixations. These patches are then encoded by a trainable U-Net and simulated using the pulse2percept framework to predict visual percepts. By incorporating a learnable encoder, we aim to optimize the visual information transmitted to the retinal implant, addressing both the limited resolution of the electrode array and the distortion between the input stimuli and resulting phosphenes. The predicted percepts are evaluated using the self-supervised DINOv2 foundation model, with an optional learnable linear layer for classification accuracy. On a subset of the ImageNet validation set, the fixation-based framework achieves a classification accuracy of 87.72%, using computational parameters based on a real subject's physiological data, significantly outperforming the downsampling-based accuracy of 40.59% and approaching the healthy upper bound of 92.76%. Our approach shows promising potential for producing more semantically understandable percepts with the limited resolution available in retinal prosthetics.","authors":["Yuli Wu","Do Dinh Tan Nguyen","Henning Konermann","Rüveyda Yilmaz","Peter Walter","Johannes Stegmaier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.17160v3","updated":"2026-02-20T11:50:22Z","published":"2025-02-24T13:54:57Z","title":"A Pragmatic Note on Evaluating Generative Models with Fréchet Inception Distance for Retinal Image Synthesis","summary":"Fréchet Inception Distance (FID), computed with an ImageNet pretrained Inception-v3 network, is widely used as a state-of-the-art evaluation metric for generative models. It assumes that feature vectors from Inception-v3 follow a multivariate Gaussian distribution and calculates the 2-Wasserstein distance based on their means and covariances. While FID effectively measures how closely synthetic data match real data in many image synthesis tasks, the primary goal in biomedical generative models is often to enrich training datasets ideally with corresponding annotations. For this purpose, the gold standard for evaluating generative models is to incorporate synthetic data into downstream task training, such as classification and segmentation, to pragmatically assess its performance. In this paper, we examine cases from retinal imaging modalities, including color fundus photography and optical coherence tomography, where FID and its related metrics misalign with task-specific evaluation goals in classification and segmentation. We highlight the limitations of using various metrics, represented by FID and its variants, as evaluation criteria for these applications and address their potential caveats in broader biomedical imaging modalities and downstream tasks.","authors":["Yuli Wu","Fucheng Liu","Rüveyda Yilmaz","Henning Konermann","Peter Walter","Johannes Stegmaier"],"pdf_url":"","comment":"MIDL 2026"},{"id":"http://arxiv.org/abs/2510.09658v3","updated":"2026-02-20T11:40:52Z","published":"2025-10-07T13:30:25Z","title":"Gradient-Sign Masking for Task Vector Transport Across Pre-Trained Models","summary":"When a new release of a foundation model is published, practitioners typically need to repeat fine-tuning, even if the same task was already tackled in the previous version. A promising alternative is to reuse the parameter changes (i.e., task vectors) that capture how a model adapts to a specific task. However, these vectors often fail to transfer across different pre-trained models because their parameter spaces are misaligned. In this work, we show that successful transfer depends strongly on the gradient-sign structure of the new model. Based on this insight, we propose GradFix, which approximates the ideal sign structure and leverages it to transfer knowledge using only a handful of labeled samples. Notably, this requires no additional fine-tuning: we only compute a few target-model gradients without parameter updates and mask the source task vector accordingly. This yields an update that is locally aligned with the target loss landscape, effectively rebasing the task vector onto the new pre-training. We provide a theoretical guarantee that our method ensures first-order descent. Empirically, we demonstrate significant performance gains on vision and language benchmarks, consistently outperforming naive task vector addition and few-shot fine-tuning. We further show that transporting task vectors improves multi-task and multi-source model merging. Code is available at https://github.com/fillo-rinaldi/GradFix.","authors":["Filippo Rinaldi","Aniello Panariello","Giacomo Salici","Fengyuan Liu","Marco Ciccone","Angelo Porrello","Simone Calderara"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.16898v2","updated":"2026-02-20T10:41:16Z","published":"2026-02-18T21:28:56Z","title":"MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation","summary":"Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.MALLVi present a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step Rather than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning.Experiments in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks.Code available at https://github.com/iman1234ahmadi/MALLVI.","authors":["Iman Ahmadi","Mehrshad Taji","Arad Mahdinezhad Kashani","AmirHossein Jadidi","Saina Kashani","Babak Khalaj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18119v1","updated":"2026-02-20T10:18:27Z","published":"2026-02-20T10:18:27Z","title":"RamanSeg: Interpretability-driven Deep Learning on Raman Spectra for Cancer Diagnosis","summary":"Histopathology, the current gold standard for cancer diagnosis, involves the manual examination of tissue samples after chemical staining, a time-consuming process requiring expert analysis. Raman spectroscopy is an alternative, stain-free method of extracting information from samples. Using nnU-Net, we trained a segmentation model on a novel dataset of spatial Raman spectra aligned with tumour annotations, achieving a mean foreground Dice score of 80.9%, surpassing previous work. Furthermore, we propose a novel, interpretable, prototype-based architecture called RamanSeg. RamanSeg classifies pixels based on discovered regions of the training set, generating a segmentation mask. Two variants of RamanSeg allow a trade-off between interpretability and performance: one with prototype projection and another projection-free version. The projection-free RamanSeg outperformed a U-Net baseline with a mean foreground Dice score of 67.3%, offering a meaningful improvement over a black-box training approach.","authors":["Chris Tomy","Mo Vali","David Pertzborn","Tammam Alamatouri","Anna Mühlig","Orlando Guntinas-Lichius","Anna Xylander","Eric Michele Fantuzzi","Matteo Negro","Francesco Crisafi","Pietro Lio","Tiago Azevedo"],"pdf_url":"","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.01844v2","updated":"2026-02-20T10:09:50Z","published":"2026-02-02T09:16:16Z","title":"CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions","summary":"Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\\footnote{As in this example.","authors":["Yuliang Zhan","Jian Li","Wenbing Huang","Wenbing Huang","Yang Liu","Hao Sun"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2509.23880v2","updated":"2026-02-20T10:04:38Z","published":"2025-09-28T13:40:48Z","title":"Learning Adaptive Pseudo-Label Selection for Semi-Supervised 3D Object Detection","summary":"Semi-supervised 3D object detection (SS3DOD) aims to reduce costly 3D annotations utilizing unlabeled data. Recent studies adopt pseudo-label-based teacher-student frameworks and demonstrate impressive performance. The main challenge of these frameworks is in selecting high-quality pseudo-labels from the teacher's predictions. Most previous methods, however, select pseudo-labels by comparing confidence scores over thresholds manually set. The latest works tackle the challenge either by dynamic thresholding or refining the quality of pseudo-labels. Such methods still overlook contextual information e.g. object distances, classes, and learning states, and inadequately assess the pseudo-label quality using partial information available from the networks. In this work, we propose a novel SS3DOD framework featuring a learnable pseudo-labeling module designed to automatically and adaptively select high-quality pseudo-labels. Our approach introduces two networks at the teacher output level. These networks reliably assess the quality of pseudo-labels by the score fusion and determine context-adaptive thresholds, which are supervised by the alignment of pseudo-labels over GT bounding boxes. Additionally, we introduce a soft supervision strategy that can learn robustly under pseudo-label noises. This helps the student network prioritize cleaner labels over noisy ones in semi-supervised learning. Extensive experiments on the KITTI and Waymo datasets demonstrate the effectiveness of our method. The proposed method selects high-precision pseudo-labels while maintaining a wider coverage of contexts and a higher recall rate, significantly improving relevant SS3DOD methods.","authors":["Taehun Kong","Tae-Kyun Kim"],"pdf_url":"","comment":"Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2026"},{"id":"http://arxiv.org/abs/2602.13662v3","updated":"2026-02-20T09:41:11Z","published":"2026-02-14T08:10:27Z","title":"LeafNet: A Large-Scale Dataset and Comprehensive Benchmark for Foundational Vision-Language Understanding of Plant Diseases","summary":"Foundation models and vision-language pre-training have significantly advanced Vision-Language Models (VLMs), enabling multimodal processing of visual and linguistic data. However, their application in domain-specific agricultural tasks, such as plant pathology, remains limited due to the lack of large-scale, comprehensive multimodal image--text datasets and benchmarks. To address this gap, we introduce LeafNet, a comprehensive multimodal dataset, and LeafBench, a visual question-answering benchmark developed to systematically evaluate the capabilities of VLMs in understanding plant diseases. The dataset comprises 186,000 leaf digital images spanning 97 disease classes, paired with metadata, generating 13,950 question-answer pairs spanning six critical agricultural tasks. The questions assess various aspects of plant pathology understanding, including visual symptom recognition, taxonomic relationships, and diagnostic reasoning. Benchmarking 12 state-of-the-art VLMs on our LeafBench dataset, we reveal substantial disparity in their disease understanding capabilities. Our study shows performance varies markedly across tasks: binary healthy--diseased classification exceeds 90% accuracy, while fine-grained pathogen and species identification remains below 65%. Direct comparison between vision-only models and VLMs demonstrates the critical advantage of multimodal architectures: fine-tuned VLMs outperform traditional vision models, confirming that integrating linguistic representations significantly enhances diagnostic precision. These findings highlight critical gaps in current VLMs for plant pathology applications and underscore the need for LeafBench as a rigorous framework for methodological advancement and progress evaluation toward reliable AI-assisted plant disease diagnosis. Code is available at https://github.com/EnalisUs/LeafBench.","authors":["Khang Nguyen Quoc","Phuong D. Dao","Luyl-Da Quach"],"pdf_url":"","comment":"26 pages, 13 figures and 8 tables"},{"id":"http://arxiv.org/abs/2602.02089v2","updated":"2026-02-20T09:39:37Z","published":"2026-02-02T13:35:16Z","title":"UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction","summary":"While 3D Gaussian Splatting (3DGS) enables high-quality, real-time rendering for bounded scenes, its extension to large-scale urban environments gives rise to critical challenges in terms of geometric consistency, memory efficiency, and computational scalability. To address these issues, we present UrbanGS, a scalable reconstruction framework that effectively tackles these challenges for city-scale applications. First, we propose a Depth-Consistent D-Normal Regularization module. Unlike existing approaches that rely solely on monocular normal estimators, which can effectively update rotation parameters yet struggle to update position parameters, our method integrates D-Normal constraints with external depth supervision. This allows for comprehensive updates of all geometric parameters. By further incorporating an adaptive confidence weighting mechanism based on gradient consistency and inverse depth deviation, our approach significantly enhances multi-view depth alignment and geometric coherence, which effectively resolves the issue of geometric accuracy in complex large-scale scenes. To improve scalability, we introduce a Spatially Adaptive Gaussian Pruning (SAGP) strategy, which dynamically adjusts Gaussian density based on local geometric complexity and visibility to reduce redundancy. Additionally, a unified partitioning and view assignment scheme is designed to eliminate boundary artifacts and optimize computational load. Extensive experiments on multiple urban datasets demonstrate that UrbanGS achieves superior performance in rendering quality, geometric accuracy, and memory efficiency, providing a systematic solution for high-fidelity large-scale scene reconstruction.","authors":["Changbai Li","Haodong Zhu","Hanlin Chen","Xiuping Liang","Tongfei Chen","Shuwei Shao","Linlin Yang","Huobin Tan","Baochang Zhang"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.18094v1","updated":"2026-02-20T09:34:21Z","published":"2026-02-20T09:34:21Z","title":"OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models","summary":"Existing Visual-Language Models (VLMs) have achieved significant progress by being trained on massive-scale datasets, typically under the assumption that data are independent and identically distributed (IID). However, in real-world scenarios, it is often impractical to expect that all data processed by an AI system satisfy this assumption. Furthermore, failure to appropriately handle out-of-distribution (OOD) objects may introduce safety risks in real-world applications (e.g., autonomous driving or medical assistance). Unfortunately, current research has not yet provided valid benchmarks that can comprehensively assess the performance of VLMs in response to OOD data. Therefore, we propose OODBench, a predominantly automated method with minimal human verification, for constructing new benchmarks and evaluating the ability of VLMs to process OOD data. OODBench contains 40K instance-level OOD instance-category pairs, and we show that current VLMs still exhibit notable performance degradation on OODBench, even when the underlying image categories are common. In addition, we propose a reliable automated assessment metric that employs a Basic-to-Advanced Progression of prompted questions to assess the impact of OOD data on questions of varying difficulty more fully. Lastly, we summarize substantial findings and insights to facilitate future research in the acquisition and evaluation of OOD data.","authors":["Ling Lin","Yang Bai","Heng Su","Congcong Zhu","Yaoxing Wang","Yang Zhou","Huazhu Fu","Jingrun Chen"],"pdf_url":"","comment":"54 pages, 21 figures"},{"id":"http://arxiv.org/abs/2602.18093v1","updated":"2026-02-20T09:33:59Z","published":"2026-02-20T09:33:59Z","title":"Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers","summary":"Diffusion Transformers (DiT) have emerged as a widely adopted backbone for high-fidelity image and video generation, yet their iterative denoising process incurs high computational costs. Existing training-free acceleration methods rely on feature caching and reuse under the assumption of temporal stability. However, reusing features for multiple steps may lead to latent drift and visual degradation. We observe that model outputs evolve smoothly along much of the diffusion trajectory, enabling principled predictions rather than naive reuse. Based on this insight, we propose \\textbf{PrediT}, a training-free acceleration framework that formulates feature prediction as a linear multistep problem. We employ classical linear multistep methods to forecast future model outputs from historical information, combined with a corrector that activates in high-dynamics regions to prevent error accumulation. A dynamic step modulation mechanism adaptively adjusts the prediction horizon by monitoring the feature change rate. Together, these components enable substantial acceleration while preserving generation fidelity. Extensive experiments validate that our method achieves up to $5.54\\times$ latency reduction across various DiT-based image and video generation models, while incurring negligible quality degradation.","authors":["Hanshuai Cui","Zhiqing Tang","Qianli Ma","Zhi Yao","Weijia Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18089v1","updated":"2026-02-20T09:25:14Z","published":"2026-02-20T09:25:14Z","title":"DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text","summary":"Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.","authors":["Kunwar Arpit Singh","Ankush Prakash","Haroon R Lone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18083v1","updated":"2026-02-20T09:17:12Z","published":"2026-02-20T09:17:12Z","title":"Comparative Assessment of Multimodal Earth Observation Data for Soil Moisture Estimation","summary":"Accurate soil moisture (SM) estimation is critical for precision agriculture, water resources management and climate monitoring. Yet, existing satellite SM products are too coarse (>1km) for farm-level applications. We present a high-resolution (10m) SM estimation framework for vegetated areas across Europe, combining Sentinel-1 SAR, Sentinel-2 optical imagery and ERA-5 reanalysis data through machine learning. Using 113 International Soil Moisture Network (ISMN) stations spanning diverse vegetated areas, we compare modality combinations with temporal parameterizations, using spatial cross-validation, to ensure geographic generalization. We also evaluate whether foundation model embeddings from IBM-NASA's Prithvi model improve upon traditional hand-crafted spectral features. Results demonstrate that hybrid temporal matching - Sentinel-2 current-day acquisitions with Sentinel-1 descending orbit - achieves R^2=0.514, with 10-day ERA5 lookback window improving performance to R^2=0.518. Foundation model (Prithvi) embeddings provide negligible improvement over hand-crafted features (R^2=0.515 vs. 0.514), indicating traditional feature engineering remains highly competitive for sparse-data regression tasks. Our findings suggest that domain-specific spectral indices combined with tree-based ensemble methods offer a practical and computationally efficient solution for operational pan-European field-scale soil moisture monitoring.","authors":["Ioannis Kontogiorgakis","Athanasios Askitopoulos","Iason Tsardanidis","Dimitrios Bormpoudakis","Ilias Tsoumas","Fotios Balampanis","Charalampos Kontoes"],"pdf_url":"","comment":"This paper has been submitted to IEEE IGARSS 2026"},{"id":"http://arxiv.org/abs/2411.15605v3","updated":"2026-02-20T09:05:18Z","published":"2024-11-23T16:52:22Z","title":"GIFT: A Framework Towards Global Interpretable Faithful Textual Explanations of Vision Classifiers","summary":"Understanding the decision processes of deep vision models is essential for their safe and trustworthy deployment in real-world settings. Existing explainability approaches, such as saliency maps or concept-based analyses, often suffer from limited faithfulness, local scope, or ambiguous semantics. We introduce GIFT, a post-hoc framework that aims to derive Global, Interpretable, Faithful, and Textual explanations for vision classifiers. GIFT begins by generating a large set of faithful, local visual counterfactuals, then employs vision-language models to translate these counterfactuals into natural-language descriptions of visual changes. These local explanations are aggregated by a large language model into concise, human-readable hypotheses about the model's global decision rules. Crucially, GIFT includes a verification stage that quantitatively assesses the causal effect of each proposed explanation by performing image-based interventions, ensuring that the final textual explanations remain faithful to the model's true reasoning process. Across diverse datasets, including the synthetic CLEVR benchmark, the real-world CelebA faces, and the complex BDD driving scenes, GIFT reveals not only meaningful classification rules but also unexpected biases and latent concepts driving model behavior. Altogether, GIFT bridges the gap between local counterfactual reasoning and global interpretability, offering a principled approach to causally grounded textual explanations for vision models.","authors":["Éloi Zablocki","Valentin Gerard","Amaia Cardiel","Eric Gaussier","Matthieu Cord","Eduardo Valle"],"pdf_url":"","comment":"TMLR 2026 (featured certification)"},{"id":"http://arxiv.org/abs/2602.02437v4","updated":"2026-02-20T08:55:39Z","published":"2026-02-02T18:34:35Z","title":"UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing","summary":"Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through two complementary reasoning paradigms. We incorporate world knowledge-enhanced textual reasoning into generation to infer implicit knowledge, and leverage editing capabilities for fine-grained editing-like visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared architecture, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for textual reasoning, alongside an agent-generated corpus for visual refinement. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.","authors":["Dianyi Wang","Chaofan Ma","Feng Han","Size Wu","Wei Song","Yibin Wang","Zhixiong Zhang","Tianhang Wang","Siyuan Wang","Zhongyu Wei","Jiaqi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18066v1","updated":"2026-02-20T08:37:58Z","published":"2026-02-20T08:37:58Z","title":"Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation","summary":"Dense Bird's Eye View (BEV) semantic maps are central to autonomous driving, yet current multi-camera methods depend on costly, inconsistently annotated BEV ground truth. We address this limitation with a two-phase training strategy for fine-grained road marking segmentation that removes full supervision during pretraining and halves the amount of training data during fine-tuning while still outperforming the comparable supervised baseline model. During the self-supervised pretraining, BEVFormer predictions are differentiably reprojected into the image plane and trained against multi-view semantic pseudo-labels generated by the widely used semantic segmentation model Mask2Former. A temporal loss encourages consistency across frames. The subsequent supervised fine-tuning phase requires only 50% of the dataset and significantly less training time. With our method, the fine-tuning benefits from rich priors learned during pretraining boosting the performance and BEV segmentation quality (up to +2.5pp mIoU over the fully supervised baseline) on nuScenes. It simultaneously halves the usage of annotation data and reduces total training time by up to two thirds. The results demonstrate that differentiable reprojection plus camera perspective pseudo labels yields transferable BEV features and a scalable path toward reduced-label autonomous perception.","authors":["Daniel Busch","Christian Bohn","Thomas Kurbiel","Klaus Friedrichs","Richard Meyes","Tobias Meisen"],"pdf_url":"","comment":"This Paper has been accepted to the 2026 IEEE Intelligent Vehicles Symposium (IV)"},{"id":"http://arxiv.org/abs/2602.18064v1","updated":"2026-02-20T08:31:26Z","published":"2026-02-20T08:31:26Z","title":"3DMedAgent: Unified Perception-to-Understanding for 3D Medical Analysis","summary":"3D CT analysis spans a continuum from low-level perception to high-level clinical understanding. Existing 3D-oriented analysis methods adopt either isolated task-specific modeling or task-agnostic end-to-end paradigms to produce one-hop outputs, impeding the systematic accumulation of perceptual evidence for downstream reasoning. In parallel, recent multimodal large language models (MLLMs) exhibit improved visual perception and can integrate visual and textual information effectively, yet their predominantly 2D-oriented designs fundamentally limit their ability to perceive and analyze volumetric medical data. To bridge this gap, we propose 3DMedAgent, a unified agent that enables 2D MLLMs to perform general 3D CT analysis without 3D-specific fine-tuning. 3DMedAgent coordinates heterogeneous visual and textual tools through a flexible MLLM agent, progressively decomposing complex 3D analysis into tractable subtasks that transition from global to regional views, from 3D volumes to informative 2D slices, and from visual evidence to structured textual representations. Central to this design, 3DMedAgent maintains a long-term structured memory that aggregates intermediate tool outputs and supports query-adaptive, evidence-driven multi-step reasoning. We further introduce the DeepChestVQA benchmark for evaluating unified perception-to-understanding capabilities in 3D thoracic imaging. Experiments across over 40 tasks demonstrate that 3DMedAgent consistently outperforms general, medical, and 3D-specific MLLMs, highlighting a scalable path toward general-purpose 3D clinical assistants.Code and data are available at \\href{https://github.com/jinlab-imvr/3DMedAgent}{https://github.com/jinlab-imvr/3DMedAgent}.","authors":["Ziyue Wang","Linghan Cai","Chang Han Low","Haofeng Liu","Junde Wu","Jingyu Wang","Rui Wang","Lei Song","Jiang Bian","Jingjing Fu","Yueming Jin"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.18057v1","updated":"2026-02-20T08:17:01Z","published":"2026-02-20T08:17:01Z","title":"Temporal Consistency-Aware Text-to-Motion Generation","summary":"Text-to-Motion (T2M) generation aims to synthesize realistic human motion sequences from natural language descriptions. While two-stage frameworks leveraging discrete motion representations have advanced T2M research, they often neglect cross-sequence temporal consistency, i.e., the shared temporal structures present across different instances of the same action. This leads to semantic misalignments and physically implausible motions. To address this limitation, we propose TCA-T2M, a framework for temporal consistency-aware T2M generation. Our approach introduces a temporal consistency-aware spatial VQ-VAE (TCaS-VQ-VAE) for cross-sequence temporal alignment, coupled with a masked motion transformer for text-conditioned motion generation. Additionally, a kinematic constraint block mitigates discretization artifacts to ensure physical plausibility. Experiments on HumanML3D and KIT-ML benchmarks demonstrate that TCA-T2M achieves state-of-the-art performance, highlighting the importance of temporal consistency in robust and coherent T2M generation.","authors":["Hongsong Wang","Wenjing Yan","Qiuxia Lai","Xin Geng"],"pdf_url":"","comment":"Code is on https://github.com/Giat995/TCA-T2M/"},{"id":"http://arxiv.org/abs/2602.18047v1","updated":"2026-02-20T08:00:17Z","published":"2026-02-20T08:00:17Z","title":"CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras","summary":"City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.","authors":["Rong Fu","Wenxin Zhang","Yibo Meng","Jia Yee Tan","Jiaxuan Lu","Rui Lu","Jiekai Wu","Zhaolu Kang","Simon Fong"],"pdf_url":"","comment":"36 pages, 12 figures"},{"id":"http://arxiv.org/abs/2505.20049v2","updated":"2026-02-20T07:59:28Z","published":"2025-05-26T14:37:35Z","title":"Data-Free Class-Incremental Gesture Recognition with Prototype-Guided Pseudo Feature Replay","summary":"Gesture recognition is an important research area in the field of computer vision. Most gesture recognition efforts focus on close-set scenarios, thereby limiting the capacity to effectively handle unseen or novel gestures. We aim to address class-incremental gesture recognition, which entails the ability to accommodate new and previously unseen gestures over time. Specifically, we introduce a Prototype-Guided Pseudo Feature Replay (PGPFR) framework for data-free class-incremental gesture recognition. This framework comprises four components: Pseudo Feature Generation with Batch Prototypes (PFGBP), Variational Prototype Replay (VPR) for old classes, Truncated Cross-Entropy (TCE) for new classes, and Continual Classifier Re-Training (CCRT). To tackle the issue of catastrophic forgetting, the PFGBP dynamically generates a diversity of pseudo features in an online manner, leveraging class prototypes of old classes along with batch class prototypes of new classes. Furthermore, the VPR enforces consistency between the classifier's weights and the prototypes of old classes, leveraging class prototypes and covariance matrices to enhance robustness and generalization capabilities. The TCE mitigates the impact of domain differences of the classifier caused by pseudo features. Finally, the CCRT training strategy is designed to prevent overfitting to new classes and ensure the stability of features extracted from old classes. Extensive experiments conducted on two widely used gesture recognition datasets, namely SHREC 2017 3D and EgoGesture 3D, demonstrate that our approach outperforms existing state-of-the-art methods by 11.8\\% and 12.8\\% in terms of mean global accuracy, respectively. The code is available on https://github.com/sunao-101/PGPFR-3/.","authors":["Hongsong Wang","Ao Sun","Jie Gui","Liang Wang"],"pdf_url":"","comment":"Code is on https://github.com/sunao-101/PGPFR-3/"},{"id":"http://arxiv.org/abs/2602.18043v1","updated":"2026-02-20T07:52:57Z","published":"2026-02-20T07:52:57Z","title":"Spatio-temporal Decoupled Knowledge Compensator for Few-Shot Action Recognition","summary":"Few-Shot Action Recognition (FSAR) is a challenging task that requires recognizing novel action categories with a few labeled videos. Recent works typically apply semantically coarse category names as auxiliary contexts to guide the learning of discriminative visual features. However, such context provided by the action names is too limited to provide sufficient background knowledge for capturing novel spatial and temporal concepts in actions. In this paper, we propose DiST, an innovative Decomposition-incorporation framework for FSAR that makes use of decoupled Spatial and Temporal knowledge provided by large language models to learn expressive multi-granularity prototypes. In the decomposition stage, we decouple vanilla action names into diverse spatio-temporal attribute descriptions (action-related knowledge). Such commonsense knowledge complements semantic contexts from spatial and temporal perspectives. In the incorporation stage, we propose Spatial/Temporal Knowledge Compensators (SKC/TKC) to discover discriminative object-level and frame-level prototypes, respectively. In SKC, object-level prototypes adaptively aggregate important patch tokens under the guidance of spatial knowledge. Moreover, in TKC, frame-level prototypes utilize temporal attributes to assist in inter-frame temporal relation modeling. These learned prototypes thus provide transparency in capturing fine-grained spatial details and diverse temporal patterns. Experimental results show DiST achieves state-of-the-art results on five standard FSAR datasets.","authors":["Hongyu Qu","Xiangbo Shu","Rui Yan","Hailiang Gao","Wenguan Wang","Jinhui Tang"],"pdf_url":"","comment":"Accepted to TPAMI 2026"},{"id":"http://arxiv.org/abs/2505.17748v2","updated":"2026-02-20T07:51:22Z","published":"2025-05-23T11:15:21Z","title":"Soft-CAM: Making black box models self-explainable for medical image analysis","summary":"Convolutional neural networks (CNNs) are widely used for high-stakes applications like medicine, often surpassing human performance. However, most explanation methods rely on post-hoc attribution, approximating the decision-making process of already trained black-box models. These methods are often sensitive, unreliable, and fail to reflect true model reasoning, limiting their trustworthiness in critical applications. In this work, we introduce SoftCAM, a straightforward yet effective approach that makes standard CNN architectures inherently interpretable. By removing the global average pooling layer and replacing the fully connected classification layer with a convolution-based class evidence layer, SoftCAM preserves spatial information and produces explicit class activation maps that form the basis of the model's predictions. Evaluated on three medical datasets, SoftCAM maintains classification performance while significantly improving both the qualitative and quantitative explanation compared to existing post-hoc methods. Our results demonstrate that CNNs can be inherently interpretable without compromising performance, advancing the development of self-explainable deep learning for high-stakes decision-making. The code is available at https://github.com/kdjoumessi/SoftCAM","authors":["Kerol Djoumessi","Philipp Berens"],"pdf_url":"","comment":"Accepted at the Medical Imaging with Deep Learning Conference (MIDL 2026)"},{"id":"http://arxiv.org/abs/2509.25740v2","updated":"2026-02-20T07:46:31Z","published":"2025-09-30T03:53:11Z","title":"Dragging with Geometry: From Pixels to Geometry-Guided Image Editing","summary":"Interactive point-based image editing serves as a controllable editor, enabling precise and flexible manipulation of image content. However, most drag-based methods operate primarily on the 2D pixel plane with limited use of 3D cues. As a result, they often produce imprecise and inconsistent edits, particularly in geometry-intensive scenarios such as rotations and perspective transformations. To address these limitations, we propose a novel geometry-guided drag-based image editing method-GeoDrag, which addresses three key challenges: 1) incorporating 3D geometric cues into pixel-level editing, 2) mitigating discontinuities caused by geometry-only guidance, and 3) resolving conflicts arising from multi-point dragging. Built upon a unified displacement field that jointly encodes 3D geometry and 2D spatial priors, GeoDrag enables coherent, high-fidelity, and structure-consistent editing in a single forward pass. In addition, a conflict-free partitioning strategy is introduced to isolate editing regions, effectively preventing interference and ensuring consistency. Extensive experiments across various editing scenarios validate the effectiveness of our method, showing superior precision, structural consistency, and reliable multi-point editability. Project page: https://xinyu-pu.github.io/projects/geodrag.","authors":["Xinyu Pu","Hongsong Wang","Jie Gui","Pan Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18022v1","updated":"2026-02-20T06:24:20Z","published":"2026-02-20T06:24:20Z","title":"Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers","summary":"Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value space -- which governs feature aggregation -- entirely unexploited. In this paper, we first reveal that both Key and Value projections in DiT's multi-modal attention layers exhibit a pronounced bias-delta structure, where token embeddings cluster tightly around a layer-specific bias vector. Building on this observation, we propose Dual-Channel Attention Guidance (DCAG), a training-free framework that simultaneously manipulates both the Key channel (controlling where to attend) and the Value channel (controlling what to aggregate). We provide a theoretical analysis showing that the Key channel operates through the nonlinear softmax function, acting as a coarse control knob, while the Value channel operates through linear weighted summation, serving as a fine-grained complement. Together, the two-dimensional parameter space $(δ_k, δ_v)$ enables more precise editing-fidelity trade-offs than any single-channel method. Extensive experiments on the PIE-Bench benchmark (700 images, 10 editing categories) demonstrate that DCAG consistently outperforms Key-only guidance across all fidelity metrics, with the most significant improvements observed in localized editing tasks such as object deletion (4.9% LPIPS reduction) and object addition (3.2% LPIPS reduction).","authors":["Guandong Li","Mengxia Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18020v1","updated":"2026-02-20T06:22:21Z","published":"2026-02-20T06:22:21Z","title":"UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models","summary":"Vision-Language-Action (VLA) models leverage pretrained Vision-Language Models (VLMs) as backbones to map images and instructions to actions, demonstrating remarkable potential for generalizable robotic manipulation. To enhance performance, existing methods often incorporate extra observation cues (e.g., depth maps, point clouds) or auxiliary modules (e.g., object detectors, encoders) to enable more precise and reliable task execution, yet these typically require costly data collection and additional training. Inspired by the finding that Feed-Forward Network (FFN) in language models can act as \"key-value memory\", we propose Uncertainty-aware Observation Reinjection (UAOR), an effective, training-free and plug-and-play module for VLA models. Specifically, when the current language model layer exhibits high uncertainty, measured by Action Entropy, it reinjects key observation information into the next layer's Feed-Forward Network (FFN) through attention retrieval. This mechanism helps VLAs better attend to observations during inference, enabling more confident and faithful action generation. Comprehensive experiments show that our method consistently improves diverse VLA models across simulation and real-world tasks with minimal overhead. Notably, UAOR eliminates the need for additional observation cues or modules, making it a versatile and practical plug-in for existing VLA pipelines. The project page is at https://uaor.jiabingyang.cn.","authors":["Jiabing Yang","Yixiang Chen","Yuan Xu","Peiyan Li","Xiangnan Wu","Zichen Wen","Bowen Fang","Tao Yu","Zhengbo Zhang","Yingda Li","Kai Wang","Jing Liu","Nianfeng Liu","Yan Huang","Liang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18019v1","updated":"2026-02-20T06:18:32Z","published":"2026-02-20T06:18:32Z","title":"DeepSVU: Towards In-depth Security-oriented Video Understanding via Unified Physical-world Regularized MoE","summary":"In the literature, prior research on Security-oriented Video Understanding (SVU) has predominantly focused on detecting and localize the threats (e.g., shootings, robberies) in videos, while largely lacking the effective capability to generate and evaluate the threat causes. Motivated by these gaps, this paper introduces a new chat paradigm SVU task, i.e., In-depth Security-oriented Video Understanding (DeepSVU), which aims to not only identify and locate the threats but also attribute and evaluate the causes threatening segments. Furthermore, this paper reveals two key challenges in the proposed task: 1) how to effectively model the coarse-to-fine physical-world information (e.g., human behavior, object interactions and background context) to boost the DeepSVU task; and 2) how to adaptively trade off these factors. To tackle these challenges, this paper proposes a new Unified Physical-world Regularized MoE (UPRM) approach. Specifically, UPRM incorporates two key components: the Unified Physical-world Enhanced MoE (UPE) Block and the Physical-world Trade-off Regularizer (PTR), to address the above two challenges, respectively. Extensive experiments conduct on our DeepSVU instructions datasets (i.e., UCF-C instructions and CUVA instructions) demonstrate that UPRM outperforms several advanced Video-LLMs as well as non-VLM approaches. Such information.These justify the importance of the coarse-to-fine physical-world information in the DeepSVU task and demonstrate the effectiveness of our UPRM in capturing such information.","authors":["Yujie Jin","Wenxin Zhang","Jingjing Wang","Guodong Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18016v1","updated":"2026-02-20T06:12:48Z","published":"2026-02-20T06:12:48Z","title":"Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating","summary":"Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.","authors":["Jiamin Luo","Xuqian Gu","Jingjing Wang","Jiahong Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.17064v3","updated":"2026-02-20T05:52:53Z","published":"2025-05-18T13:35:23Z","title":"Synthetic History: Evaluating Visual Representations of the Past in Diffusion Models","summary":"As Text-to-Image (TTI) diffusion models become increasingly influential in content creation, growing attention is being directed toward their societal and cultural implications. While prior research has primarily examined demographic and cultural biases, the ability of these models to accurately represent historical contexts remains largely underexplored. To address this gap, we introduce a benchmark for evaluating how TTI models depict historical contexts. The benchmark combines HistVis, a dataset of 30,000 synthetic images generated by three state-of-the-art diffusion models from carefully designed prompts covering universal human activities across multiple historical periods, with a reproducible evaluation protocol. We evaluate generated imagery across three key aspects: (1) Implicit Stylistic Associations: examining default visual styles associated with specific eras; (2) Historical Consistency: identifying anachronisms such as modern artifacts in pre-modern contexts; and (3) Demographic Representation: comparing generated racial and gender distributions against historically plausible baselines. Our findings reveal systematic inaccuracies in historically themed generated imagery, as TTI models frequently stereotype past eras by incorporating unstated stylistic cues, introduce anachronisms, and fail to reflect plausible demographic patterns. By providing a reproducible benchmark for historical representation in generated imagery, this work provides an initial step toward building more historically accurate TTI models.","authors":["Maria-Teresa De Rosa Palmini","Eva Cetinic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18006v1","updated":"2026-02-20T05:43:47Z","published":"2026-02-20T05:43:47Z","title":"MUOT_3M: A 3 Million Frame Multimodal Underwater Benchmark and the MUTrack Tracking Method","summary":"Underwater Object Tracking (UOT) is crucial for efficient marine robotics, large scale ecological monitoring, and ocean exploration; however, progress has been hindered by the scarcity of large, multimodal, and diverse datasets. Existing benchmarks remain small and RGB only, limiting robustness under severe color distortion, turbidity, and low visibility conditions. We introduce MUOT_3M, the first pseudo multimodal UOT benchmark comprising 3 million frames from 3,030 videos (27.8h) annotated with 32 tracking attributes, 677 fine grained classes, and synchronized RGB, estimated enhanced RGB, estimated depth, and language modalities validated by a marine biologist. Building upon MUOT_3M, we propose MUTrack, a SAM-based multimodal to unimodal tracker featuring visual geometric alignment, vision language fusion, and four level knowledge distillation that transfers multimodal knowledge into a unimodal student model. Extensive evaluations across five UOT benchmarks demonstrate that MUTrack achieves up to 8.40% higher AUC and 7.80% higher precision than the strongest SOTA baselines while running at 24 FPS. MUOT_3M and MUTrack establish a new foundation for scalable, multimodally trained yet practically deployable underwater tracking.","authors":["Ahsan Baidar Bakht","Mohamad Alansari","Muhayy Ud Din","Muzammal Naseer","Sajid Javed","Irfan Hussain","Jiri Matas","Arif Mahmood"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18000v1","updated":"2026-02-20T05:27:26Z","published":"2026-02-20T05:27:26Z","title":"Image Quality Assessment: Exploring Quality Awareness via Memory-driven Distortion Patterns Matching","summary":"Existing full-reference image quality assessment (FR-IQA) methods achieve high-precision evaluation by analysing feature differences between reference and distorted images. However, their performance is constrained by the quality of the reference image, which limits real-world applications where ideal reference sources are unavailable. Notably, the human visual system has the ability to accumulate visual memory, allowing image quality assessment on the basis of long-term memory storage. Inspired by this biological memory mechanism, we propose a memory-driven quality-aware framework (MQAF), which establishes a memory bank for storing distortion patterns and dynamically switches between dual-mode quality assessment strategies to reduce reliance on high-quality reference images. When reference images are available, MQAF obtains reference-guided quality scores by adaptively weighting reference information and comparing the distorted image with stored distortion patterns in the memory bank. When the reference image is absent, the framework relies on distortion patterns in the memory bank to infer image quality, enabling no-reference quality assessment (NR-IQA). The experimental results show that our method outperforms state-of-the-art approaches across multiple datasets while adapting to both no-reference and full-reference tasks.","authors":["Xuting Lan","Mingliang Zhou","Xuekai Wei","Jielu Yan","Yueting Huang","Huayan Pu","Jun Luo","Weijia Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18612v4","updated":"2026-02-20T05:08:23Z","published":"2025-05-24T09:21:32Z","title":"Mod-Adapter: Tuning-Free and Versatile Multi-concept Personalization via Modulation Adapter","summary":"Personalized text-to-image generation aims to synthesize images of user-provided concepts in diverse contexts. Despite recent progress in multi-concept personalization, most are limited to object concepts and struggle to customize abstract concepts (e.g., pose, lighting). Some methods have begun exploring multi-concept personalization supporting abstract concepts, but they require test-time fine-tuning for each new concept, which is time-consuming and prone to overfitting on limited training images. In this work, we propose a novel tuning-free method for multi-concept personalization that can effectively customize both object and abstract concepts without test-time fine-tuning. Our method builds upon the modulation mechanism in pre-trained Diffusion Transformers (DiTs) model, leveraging the localized and semantically meaningful properties of the modulation space. Specifically, we propose a novel module, Mod-Adapter, to predict concept-specific modulation direction for the modulation process of concept-related text tokens. It introduces vision-language cross-attention for extracting concept visual features, and Mixture-of-Experts (MoE) layers that adaptively map the concept features into the modulation space. Furthermore, to mitigate the training difficulty caused by the large gap between the concept image space and the modulation space, we introduce a VLM-guided pre-training strategy that leverages the strong image understanding capabilities of vision-language models to provide semantic supervision signals. For a comprehensive comparison, we extend a standard benchmark by incorporating abstract concepts. Our method achieves state-of-the-art performance in multi-concept personalization, supported by quantitative, qualitative, and human evaluations.","authors":["Weizhi Zhong","Huan Yang","Zheng Liu","Huiguo He","Zijian He","Xuesong Niu","Di Zhang","Guanbin Li"],"pdf_url":"","comment":"Accepted by ICLR 2026, project page: https://weizhi-zhong.github.io/Mod-Adapter"},{"id":"http://arxiv.org/abs/2602.17986v1","updated":"2026-02-20T04:46:49Z","published":"2026-02-20T04:46:49Z","title":"From Global Radiomics to Parametric Maps: A Unified Workflow Fusing Radiomics and Deep Learning for PDAC Detection","summary":"Radiomics and deep learning both offer powerful tools for quantitative medical imaging, but most existing fusion approaches only leverage global radiomic features and overlook the complementary value of spatially resolved radiomic parametric maps. We propose a unified framework that first selects discriminative radiomic features and then injects them into a radiomics-enhanced nnUNet at both the global and voxel levels for pancreatic ductal adenocarcinoma (PDAC) detection. On the PANORAMA dataset, our method achieved AUC = 0.96 and AP = 0.84 in cross-validation. On an external in-house cohort, it achieved AUC = 0.95 and AP = 0.78, outperforming the baseline nnUNet; it also ranked second in the PANORAMA Grand Challenge. This demonstrates that handcrafted radiomics, when injected at both global and voxel levels, provide complementary signals to deep learning models for PDAC detection. Our code can be found at https://github.com/briandzt/dl-pdac-radiomics-global-n-paramaps","authors":["Zengtian Deng","Yimeng He","Yu Shi","Lixia Wang","Touseef Ahmad Qureshi","Xiuzhen Huang","Debiao Li"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2504.06629v3","updated":"2026-02-20T03:43:30Z","published":"2025-04-09T07:06:44Z","title":"Analyzing the Training Dynamics of Image Restoration Transformers: A Revisit to Layer Normalization","summary":"This work analyzes the training dynamics of Image Restoration (IR) Transformers and uncovers a critical yet overlooked issue: conventional LayerNorm (LN) drives feature magnitudes to diverge to a million scale and collapses channel-wise entropy. We analyze this in the perspective of networks attempting to bypass LN's constraints that conflict with IR tasks. Accordingly, we address two misalignments between LN and IR: 1) per-token normalization disrupts spatial correlations, and 2) input-independent scaling discards input-specific statistics. To address this, we propose Image Restoration Transformer Tailored Layer Normalization i-LN, a simple drop-in replacement that normalizes features holistically and adaptively rescales them per input. We provide theoretical insights and empirical evidence that this simple design effectively leads to both improved training dynamics and thereby improved performance, validated by extensive experiments.","authors":["MinKyu Lee","Sangeek Hyun","Woojin Jun","Hyunjun Kim","Jiwoo Chung","Jae-Pil Heo"],"pdf_url":"","comment":"Codes are available at: https://github.com/2minkyulee/i-LN"},{"id":"http://arxiv.org/abs/2602.17951v1","updated":"2026-02-20T03:06:22Z","published":"2026-02-20T03:06:22Z","title":"ROCKET: Residual-Oriented Multi-Layer Alignment for Spatially-Aware Vision-Language-Action Models","summary":"Vision-Language-Action (VLA) models enable instruction-following robotic manipulation, but they are typically pretrained on 2D data and lack 3D spatial understanding. An effective approach is representation alignment, where a strong vision foundation model is used to guide a 2D VLA model. However, existing methods usually apply supervision at only a single layer, failing to fully exploit the rich information distributed across depth; meanwhile, naïve multi-layer alignment can cause gradient interference. We introduce ROCKET, a residual-oriented multi-layer representation alignment framework that formulates multi-layer alignment as aligning one residual stream to another. Concretely, ROCKET employs a shared projector to align multiple layers of the VLA backbone with multiple layers of a powerful 3D vision foundation model via a layer-invariant mapping, which reduces gradient conflicts. We provide both theoretical justification and empirical analyses showing that a shared projector is sufficient and outperforms prior designs, and further propose a Matryoshka-style sparse activation scheme for the shared projector to balance multiple alignment losses. Our experiments show that, combined with a training-free layer selection strategy, ROCKET requires only about 4% of the compute budget while achieving 98.5% state-of-the-art success rate on LIBERO. We further demonstrate the superior performance of ROCKET across LIBERO-Plus and RoboTwin, as well as multiple VLA models. The code and model weights can be found at https://github.com/CASE-Lab-UMD/ROCKET-VLA.","authors":["Guoheng Sun","Tingting Du","Kaixi Feng","Chenxiang Luo","Xingguo Ding","Zheyu Shen","Ziyao Wang","Yexiao He","Ang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17929v1","updated":"2026-02-20T01:38:59Z","published":"2026-02-20T01:38:59Z","title":"ZACH-ViT: Regime-Dependent Inductive Bias in Compact Vision Transformers for Medical Imaging","summary":"Vision Transformers rely on positional embeddings and class tokens that encode fixed spatial priors. While effective for natural images, these priors may hinder generalization when spatial layout is weakly informative or inconsistent, a frequent condition in medical imaging and edge-deployed clinical systems. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a compact Vision Transformer that removes both positional embeddings and the [CLS] token, achieving permutation invariance through global average pooling over patch representations. The term \"Zero-token\" specifically refers to removing the dedicated [CLS] aggregation token and positional embeddings; patch tokens remain unchanged and are processed normally. Adaptive residual projections preserve training stability in compact configurations while maintaining a strict parameter budget.\n  Evaluation is performed across seven MedMNIST datasets spanning binary and multi-class tasks under a strict few-shot protocol (50 samples per class, fixed hyperparameters, five random seeds). The empirical analysis demonstrates regime-dependent behavior: ZACH-ViT (0.25M parameters, trained from scratch) achieves its strongest advantage on BloodMNIST and remains competitive with TransMIL on PathMNIST, while its relative advantage decreases on datasets with strong anatomical priors (OCTMNIST, OrganAMNIST), consistent with the architectural hypothesis. These findings support the view that aligning architectural inductive bias with data structure can be more important than pursuing universal benchmark dominance. Despite its minimal size and lack of pretraining, ZACH-ViT achieves competitive performance while maintaining sub-second inference times, supporting deployment in resource-constrained clinical environments. Code and models are available at https://github.com/Bluesman79/ZACH-ViT.","authors":["Athanasios Angelakis"],"pdf_url":"","comment":"15 pages, 12 figures, 7 tables. Code and models available at https://github.com/Bluesman79/ZACH-ViT"},{"id":"http://arxiv.org/abs/2507.18031v2","updated":"2026-02-20T01:29:18Z","published":"2025-07-24T02:04:58Z","title":"ViGText: Deepfake Image Detection with Vision-Language Model Explanations and Graph Neural Networks","summary":"The rapid rise of deepfake technology, which produces realistic but fraudulent digital content, threatens the authenticity of media. Traditional deepfake detection approaches often struggle with sophisticated, customized deepfakes, especially in terms of generalization and robustness against malicious attacks. This paper introduces ViGText, a novel approach that integrates images with Vision Large Language Model (VLLM) Text explanations within a Graph-based framework to improve deepfake detection. The novelty of ViGText lies in its integration of detailed explanations with visual data, as it provides a more context-aware analysis than captions, which often lack specificity and fail to reveal subtle inconsistencies. ViGText systematically divides images into patches, constructs image and text graphs, and integrates them for analysis using Graph Neural Networks (GNNs) to identify deepfakes. Through the use of multi-level feature extraction across spatial and frequency domains, ViGText captures details that enhance its robustness and accuracy to detect sophisticated deepfakes. Extensive experiments demonstrate that ViGText significantly enhances generalization and achieves a notable performance boost when it detects user-customized deepfakes. Specifically, average F1 scores rise from 72.45% to 98.32% under generalization evaluation, and reflects the model's superior ability to generalize to unseen, fine-tuned variations of stable diffusion models. As for robustness, ViGText achieves an increase of 11.1% in recall compared to other deepfake detection approaches. When facing targeted attacks that exploit its graph-based architecture, ViGText limits classification performance degradation to less than 4%. ViGText uses detailed visual and textual analysis to set a new standard for detecting deepfakes, helping ensure media authenticity and information integrity.","authors":["Ahmad ALBarqawi","Mahmoud Nazzal","Issa Khalil","Abdallah Khreishah","NhatHai Phan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.13314v2","updated":"2026-02-20T00:41:30Z","published":"2026-02-10T10:56:47Z","title":"Sim2Radar: Toward Bridging the Radar Sim-to-Real Gap with VLM-Guided Scene Reconstruction","summary":"Millimeter-wave (mmWave) radar provides reliable perception in visually degraded indoor environments (e.g., smoke, dust, and low light), but learning-based radar perception is bottlenecked by the scarcity and cost of collecting and annotating large-scale radar datasets. We present Sim2Radar, an end-to-end framework that synthesizes training radar data directly from single-view RGB images, enabling scalable data generation without manual scene modeling. Sim2Radar reconstructs a material-aware 3D scene by combining monocular depth estimation, segmentation, and vision-language reasoning to infer object materials, then simulates mmWave propagation with a configurable physics-based ray tracer using Fresnel reflection models parameterized by ITU-R electromagnetic properties. Evaluated on real-world indoor scenes, Sim2Radar improves downstream 3D radar perception via transfer learning: pre-training a radar point-cloud object detection model on synthetic data and fine-tuning on real radar yields up to +3.7 3D AP (IoU 0.3), with gains driven primarily by improved spatial localization. These results suggest that physics-based, vision-driven radar simulation can provide effective geometric priors for radar learning and measurably improve performance under limited real-data supervision.","authors":["Emily Bejerano","Federico Tondolo","Aayan Qayyum","Xiaofan Yu","Xiaofan Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17909v1","updated":"2026-02-20T00:13:11Z","published":"2026-02-20T00:13:11Z","title":"A Single Image and Multimodality Is All You Need for Novel View Synthesis","summary":"Diffusion-based approaches have recently demonstrated strong performance for single-image novel view synthesis by conditioning generative models on geometry inferred from monocular depth estimation. However, in practice, the quality and consistency of the synthesized views are fundamentally limited by the reliability of the underlying depth estimates, which are often fragile under low texture, adverse weather, and occlusion-heavy real-world conditions. In this work, we show that incorporating sparse multimodal range measurements provides a simple yet effective way to overcome these limitations. We introduce a multimodal depth reconstruction framework that leverages extremely sparse range sensing data, such as automotive radar or LiDAR, to produce dense depth maps that serve as robust geometric conditioning for diffusion-based novel view synthesis. Our approach models depth in an angular domain using a localized Gaussian Process formulation, enabling computationally efficient inference while explicitly quantifying uncertainty in regions with limited observations. The reconstructed depth and uncertainty are used as a drop-in replacement for monocular depth estimators in existing diffusion-based rendering pipelines, without modifying the generative model itself. Experiments on real-world multimodal driving scenes demonstrate that replacing vision-only depth with our sparse range-based reconstruction substantially improves both geometric consistency and visual quality in single-image novel-view video generation. These results highlight the importance of reliable geometric priors for diffusion-based view synthesis and demonstrate the practical benefits of multimodal sensing even at extreme levels of sparsity.","authors":["Amirhosein Javadi","Chi-Shiang Gau","Konstantinos D. Polyzos","Tara Javidi"],"pdf_url":"","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2602.18429v1","updated":"2026-02-20T18:53:07Z","published":"2026-02-20T18:53:07Z","title":"VIRAASAT: Traversing Novel Paths for Indian Cultural Reasoning","summary":"Large Language Models (LLMs) have made significant progress in reasoning tasks across various domains such as mathematics and coding. However, their performance deteriorates in tasks requiring rich socio-cultural knowledge and diverse local contexts, particularly those involving Indian Culture. Existing Cultural benchmarks are (i) Manually crafted, (ii) contain single-hop questions testing factual recall, and (iii) prohibitively costly to scale, leaving this deficiency largely unmeasured. To address this, we introduce VIRAASAT, a novel, semi-automated multi-hop approach for generating cultural specific multi-hop Question-Answering dataset for Indian culture. VIRAASAT leverages a Knowledge Graph comprising more than 700 expert-curated cultural artifacts, covering 13 key attributes of Indian culture (history, festivals, etc). VIRAASAT spans all 28 states and 8 Union Territories, yielding more than 3,200 multi-hop questions that necessitate chained cultural reasoning. We evaluate current State-of-the-Art (SOTA) LLMs on VIRAASAT and identify key limitations in reasoning wherein fine-tuning on Chain-of-Thought(CoT) traces fails to ground and synthesize low-probability facts. To bridge this gap, we propose a novel framework named Symbolic Chain-of-Manipulation (SCoM). Adapting the Chain-of-Manipulation paradigm, we train the model to simulate atomic Knowledge Graph manipulations internally. SCoM teaches the model to reliably traverse the topological structure of the graph. Experiments on Supervised Fine-Tuning (SFT) demonstrate that SCoM outperforms standard CoT baselines by up to 20%. We release the VIRAASAT dataset along with our findings, laying a strong foundation towards building Culturally Aware Reasoning Models.","authors":["Harshul Raj Surana","Arijit Maji","Aryan Vats","Akash Ghosh","Sriparna Saha","Amit Sheth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18425v1","updated":"2026-02-20T18:48:05Z","published":"2026-02-20T18:48:05Z","title":"RVR: Retrieve-Verify-Retrieve for Comprehensive Question Answering","summary":"Comprehensively retrieving diverse documents is crucial to address queries that admit a wide range of valid answers. We introduce retrieve-verify-retrieve (RVR), a multi-round retrieval framework designed to maximize answer coverage. Initially, a retriever takes the original query and returns a candidate document set, followed by a verifier that identifies a high-quality subset. For subsequent rounds, the query is augmented with previously verified documents to uncover answers that are not yet covered in previous rounds. RVR is effective even with off-the-shelf retrievers, and fine-tuning retrievers for our inference procedure brings further gains. Our method outperforms baselines, including agentic search approaches, achieving at least 10% relative and 3% absolute gain in complete recall percentage on a multi-answer retrieval dataset (QAMPARI). We also see consistent gains on two out-of-domain datasets (QUEST and WebQuestionsSP) across different base retrievers. Our work presents a promising iterative approach for comprehensive answer recall leveraging a verifier and adapting retrievers to a new inference scenario.","authors":["Deniz Qian","Hung-Ting Chen","Eunsol Choi"],"pdf_url":"","comment":"18 pages, 12 figures, 12 tables"},{"id":"http://arxiv.org/abs/2602.18288v1","updated":"2026-02-20T15:35:48Z","published":"2026-02-20T15:35:48Z","title":"A Topology-Aware Positive Sample Set Construction and Feature Optimization Method in Implicit Collaborative Filtering","summary":"Negative sampling strategies are widely used in implicit collaborative filtering to address issues like data sparsity and class imbalance. However, these methods often introduce false negatives, hindering the model's ability to accurately learn users' latent preferences. To mitigate this problem, existing methods adjust the negative sampling distribution based on statistical features from model training or the hardness of negative samples. Nevertheless, these methods face two key limitations: (1) over-reliance on the model's current representation capabilities; (2) failure to leverage the potential of false negatives as latent positive samples to guide model learning of user preferences more accurately. To address the above issues, we propose a Topology-aware Positive Sample Set Construction and Feature Optimization method (TPSC-FO). First, we design a simple topological community-aware false negative identification (FNI) method and observe that topological community structures in interaction networks can effectively identify false negatives. Motivated by this, we develop a topology-aware positive sample set construction module. This module employs a differential community detection strategy to capture topological community structures in implicit feedback, coupled with personalized noise filtration to reliably identify false negatives and convert them into positive samples. Additionally, we introduce a neighborhood-guided feature optimization module that refines positive sample features by incorporating neighborhood features in the embedding space, effectively mitigating noise in the positive samples. Extensive experiments on five real-world datasets and two synthetic datasets validate the effectiveness of TPSC-FO.","authors":["Jiayi Wu","Zhengyu Wu","Xunkai Li","Rong-Hua Li","Guoren Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18283v1","updated":"2026-02-20T15:11:40Z","published":"2026-02-20T15:11:40Z","title":"HyTRec: A Hybrid Temporal-Aware Attention Architecture for Long Behavior Sequential Recommendation","summary":"Modeling long sequences of user behaviors has emerged as a critical frontier in generative recommendation. However, existing solutions face a dilemma: linear attention mechanisms achieve efficiency at the cost of retrieval precision due to limited state capacity, while softmax attention suffers from prohibitive computational overhead. To address this challenge, we propose HyTRec, a model featuring a Hybrid Attention architecture that explicitly decouples long-term stable preferences from short-term intent spikes. By assigning massive historical sequences to a linear attention branch and reserving a specialized softmax attention branch for recent interactions, our approach restores precise retrieval capabilities within industrial-scale contexts involving ten thousand interactions. To mitigate the lag in capturing rapid interest drifts within the linear layers, we furthermore design Temporal-Aware Delta Network (TADN) to dynamically upweight fresh behavioral signals while effectively suppressing historical noise. Empirical results on industrial-scale datasets confirm the superiority that our model maintains linear inference speed and outperforms strong baselines, notably delivering over 8% improvement in Hit Rate for users with ultra-long sequences with great efficiency.","authors":["Lei Xin","Yuhao Zheng","Ke Cheng","Changjiang Jiang","Zifan Zhang","Fanhu Zeng"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2506.16552v3","updated":"2026-02-20T15:01:44Z","published":"2025-06-19T19:13:59Z","title":"Revela: Dense Retriever Learning via Language Modeling","summary":"Dense retrievers play a vital role in accessing external and specialized knowledge to augment language models (LMs). Training dense retrievers typically requires annotated query-document pairs, which are costly to create and scarce in specialized domains (e.g., code) or in complex settings (e.g., requiring reasoning). These practical challenges have sparked growing interest in self-supervised retriever learning. Since LMs are trained to capture token-level dependencies through a self-supervised learning objective (i.e., next token prediction), we can analogously cast retrieval as learning dependencies among chunks of tokens. This analogy naturally leads to the question: How can we adapt self-supervised learning objectives in the spirit of language modeling to train retrievers?\n  To answer this question, we introduce Revela, a unified and scalable training framework for self-supervised retriever learning via language modeling. Revela models semantic dependencies among documents by conditioning next token prediction on local and cross-document context through an in-batch attention mechanism. This attention is weighted by retriever-computed similarity scores, enabling the retriever to be optimized as part of language modeling. We evaluate Revela on domain-specific (CoIR), reasoning-intensive (BRIGHT), and general-domain (BEIR) benchmarks across various retriever backbones. Without annotated or synthetic query-document pairs, Revela surpasses larger supervised models and proprietary APIs on both CoIR and BRIGHT. It achieves BEIR's unsupervised SoTA with ~1000x less training data and 10x less compute. Performance increases with batch size and model size, highlighting Revela's scalability and its promise for self-supervised retriever learning.","authors":["Fengyu Cai","Tong Chen","Xinran Zhao","Sihao Chen","Hongming Zhang","Sherry Tongshuang Wu","Iryna Gurevych","Heinz Koeppl"],"pdf_url":"","comment":"Accepted to ICLR 2026 (Oral). Camera-ready version"},{"id":"http://arxiv.org/abs/2602.18249v1","updated":"2026-02-20T14:32:41Z","published":"2026-02-20T14:32:41Z","title":"Dual-Tree LLM-Enhanced Negative Sampling for Implicit Collaborative Filtering","summary":"Negative sampling is a pivotal technique in implicit collaborative filtering (CF) recommendation, enabling efficient and effective training by contrasting observed interactions with sampled unobserved ones.\n  Recently, large language models (LLMs) have shown promise in recommender systems; however, research on LLM-empowered negative sampling remains underexplored.\n  Existing methods heavily rely on textual information and task-specific fine-tuning, limiting practical applicability.\n  To address this limitation, we propose a text-free and fine-tuning-free Dual-Tree LLM-enhanced Negative Sampling method (DTL-NS).\n  It consists of two modules: (i) an offline false negative identification module that leverages hierarchical index trees to transform collaborative structural and latent semantic information into structured item-ID encodings for LLM inference, enabling accurate identification of false negatives; and (ii) a multi-view hard negative sampling module that combines user-item preference scores with item-item hierarchical similarities from these encodings to mine high-quality hard negatives, thus improving models' discriminative ability.\n  Extensive experiments demonstrate the effectiveness of DTL-NS. For example, on the Amazon-sports dataset, DTL-NS outperforms the strongest baseline by 10.64% and 19.12% in Recall@20 and NDCG@20, respectively.\n  Moreover, DTL-NS can be integrated into various implicit CF models and negative sampling methods, consistently enhancing their performance.","authors":["Jiayi Wu","Zhengyu Wu","Xunkai Li","Rong-Hua Li","Guoren Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18221v1","updated":"2026-02-20T14:00:20Z","published":"2026-02-20T14:00:20Z","title":"The Economical-Ecological Benefits of Matching Non-matching Socks","summary":"Socks are produced and replaced at a massive scale, yet their paired use makes them unusually vulnerable to waste, as the loss of a single sock can strand usable wear-capacity and trigger premature replacement. In this study, we quantify the economic and ecological value of pairing non-matching \\say{orphan} socks, and the social cost that discourages this behaviour. We formalize sock ownership as a sequential decision problem under uncertainty in which socks wear out and disappear stochastically during laundering, while public exposure induces a person-specific mismatch penalty. We conducted an in-person study to estimate mismatch sensitivity and diversity preference, linking behavioural heterogeneity to optimal mixing strategies. Using these results and a computer simulation-based evaluation of interpretable pairing policies, we show that strict matching can appear resource-frugal largely because it generates many sockless days, whereas controlled tolerance for mismatch sustains service and reduces stranded capacity across loss regimes. This study establishes the feasibility of matching non-matching socks while outlining its limitations and challenges.","authors":["Teddy Lazebnik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18206v1","updated":"2026-02-20T13:34:43Z","published":"2026-02-20T13:34:43Z","title":"A Simple yet Effective Negative Sampling Plugin for Constructing Positive Sample Pairs in Implicit Collaborative Filtering","summary":"Most implicit collaborative filtering (CF) models are trained with negative sampling, where existing work designs sophisticated strategies for high-quality negatives while largely overlooking the exploration of positive samples. Although some denoising recommendation methods can be applied to implicit CF for denoising positive samples, they often sparsify positive supervision. Moreover, these approaches generally overlook user activity bias during training, leading to insufficient learning for inactive users. To address these issues, we propose a simple yet effective negative sampling plugin, PSP-NS, from the perspective of enhancing positive supervision signals. It builds a user-item bipartite graph with edge weights indicating interaction confidence inferred from global and local patterns, generates positive sample pairs via replication-based reweighting to strengthen positive signals, and adopts an activity-aware weighting scheme to effectively learn inactive users' preferences. We provide theoretical insights from a margin-improvement perspective, explaining why PSP-NS tends to improve ranking quality (e.g., Precision@k/Recall@k), and conduct extensive experiments on four real-world datasets to demonstrate its superiority. For instance, PSP-NS boosts Recall@30 and Precision@30 by 32.11% and 22.90% on Yelp over the strongest baselines. PSP-NS can be integrated with various implicit CF recommenders or negative sampling methods to enhance their performance.","authors":["Jiayi Wu","Zhengyu Wu","Xunkai Li","Ronghua Li","Guoren Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.10161v2","updated":"2026-02-20T11:08:07Z","published":"2026-01-15T08:00:25Z","title":"AWED-FiNER: Agents, Web applications, and Expert Detectors for Fine-grained Named Entity Recognition across 36 Languages for 6.6 Billion Speakers","summary":"Named Entity Recognition (NER) is a foundational task in Natural Language Processing (NLP) and Information Retrieval (IR), which facilitates semantic search and structured data extraction. We introduce \\textbf{AWED-FiNER}, an open-source collection of agentic tool, web application, and 53 state-of-the-art expert models that provide Fine-grained Named Entity Recognition (FgNER) solutions across 36 languages spoken by more than 6.6 billion people. The agentic tool enables routing multilingual text to specialized expert models to fetch FgNER annotations within seconds. The web-based platform provides a ready-to-use FgNER annotation service for non-technical users. Moreover, the collection of language-specific extremely small open-source state-of-the-art expert models facilitates offline deployment in resource-constrained scenarios, including edge devices. AWED-FiNER covers languages spoken by over 6.6 billion people, ranging from global languages like English, Chinese, Spanish, and Hindi, to low-resource languages like Assamese, Santali, and Odia, along with a specific focus on extremely low-resource vulnerable languages such as Bodo, Manipuri, Bishnupriya, and Mizo. The resources can be accessed here: Agentic Tool (https://github.com/PrachuryyaKaushik/AWED-FiNER), Web Application (https://hf.co/spaces/prachuryyaIITG/AWED-FiNER), and 53 Expert Detector Models (https://hf.co/collections/prachuryyaIITG/awed-finer).","authors":["Prachuryya Kaushik","Ashish Anand"],"pdf_url":"","comment":"Submitted to SIGIR'26 Low-resource Environments Track"},{"id":"http://arxiv.org/abs/2601.01944v2","updated":"2026-02-20T10:14:27Z","published":"2026-01-05T09:50:37Z","title":"The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities","summary":"In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.","authors":["Matteo Esposito","Andrea Janes","Valentina Lenarduzzi","Davide Taibi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2602.18107v1","updated":"2026-02-20T09:54:16Z","published":"2026-02-20T09:54:16Z","title":"SuiteEval: Simplifying Retrieval Benchmarks","summary":"Information retrieval evaluation often suffers from fragmented practices -- varying dataset subsets, aggregation methods, and pipeline configurations -- that undermine reproducibility and comparability, especially for foundation embedding models requiring robust out-of-domain performance. We introduce SuiteEval, a unified framework that offers automatic end-to-end evaluation, dynamic indexing that reuses on-disk indices to minimise disk usage, and built-in support for major benchmarks (BEIR, LoTTE, MS MARCO, NanoBEIR, and BRIGHT). Users only need to supply a pipeline generator. SuiteEval handles data loading, indexing, ranking, metric computation, and result aggregation. New benchmark suites can be added in a single line. SuiteEval reduces boilerplate and standardises evaluations to facilitate reproducible IR research, as a broader benchmark set is increasingly required.","authors":["Andrew Parry","Debasis Ganguly","Sean MacAvaney"],"pdf_url":"","comment":"5 pages, 3 figures, 2 tables, Accepted as a Demonstration to ECIR 2026"},{"id":"http://arxiv.org/abs/2602.16986v2","updated":"2026-02-20T05:25:11Z","published":"2026-02-19T01:15:17Z","title":"Bending the Scaling Law Curve in Large-Scale Recommendation Systems","summary":"Learning from user interaction history through sequential models has become a cornerstone of large-scale recommender systems. Recent advances in large language models have revealed promising scaling laws, sparking a surge of research into long-sequence modeling and deeper architectures for recommendation tasks. However, many recent approaches rely heavily on cross-attention mechanisms to address the quadratic computational bottleneck in sequential modeling, which can limit the representational power gained from self-attention. We present ULTRA-HSTU, a novel sequential recommendation model developed through end-to-end model and system co-design. By innovating in the design of input sequences, sparse attention mechanisms, and model topology, ULTRA-HSTU achieves substantial improvements in both model quality and efficiency. Comprehensive benchmarking demonstrates that ULTRA-HSTU achieves remarkable scaling efficiency gains -- over 5x faster training scaling and 21x faster inference scaling compared to conventional models -- while delivering superior recommendation quality. Our solution is fully deployed at scale, serving billions of users daily and driving significant 4% to 8% consumption and engagement improvements in real-world production environments.","authors":["Qin Ding","Kevin Course","Linjian Ma","Jianhui Sun","Ruochen Liu","Zhao Zhu","Chunxing Yin","Wei Li","Dai Li","Yu Shi","Xuan Cao","Ze Yang","Han Li","Xing Liu","Bi Xue","Hongwei Li","Rui Jian","Daisy Shi He","Jing Qian","Matt Ma","Qunshu Zhang","Rui Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17981v1","updated":"2026-02-20T04:31:40Z","published":"2026-02-20T04:31:40Z","title":"Decomposing Retrieval Failures in RAG for Long-Document Financial Question Answering","summary":"Retrieval-augmented generation is increasingly used for financial question answering over long regulatory filings, yet reliability depends on retrieving the exact context needed to justify answers in high stakes settings. We study a frequent failure mode in which the correct document is retrieved but the page or chunk that contains the answer is missed, leading the generator to extrapolate from incomplete context. Despite its practical significance, this within-document retrieval failure mode has received limited systematic attention in the Financial Question Answering (QA) literature. We evaluate retrieval at multiple levels of granularity, document, page, and chunk level, and introduce an oracle based analysis to provide empirical upper bounds on retrieval and generative performance. On a 150 question subset of FinanceBench, we reproduce and compare diverse retrieval strategies including dense, sparse, hybrid, and hierarchical methods with reranking and query reformulation. Across methods, gains in document discovery tend to translate into stronger page recall, yet oracle performance still suggests headroom for page and chunk level retrieval. To target this gap, we introduce a domain fine-tuned page scorer that treats pages as an intermediate retrieval unit between documents and chunks. Unlike prior passage-based hierarchical retrieval, we fine-tune a bi-encoder specifically for page-level relevance on financial filings, exploiting the semantic coherence of pages. Overall, our results demonstrate a significant improvement in page recall and chunk retrieval.","authors":["Amine Kobeissi","Philippe Langlais"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.10609v4","updated":"2026-02-20T03:40:31Z","published":"2026-01-15T17:24:51Z","title":"iTIMO: An LLM-empowered Synthesis Dataset for Travel Itinerary Modification","summary":"Addressing itinerary modification is crucial for enhancing the travel experience as it is a frequent requirement during traveling. However, existing research mainly focuses on fixed itinerary planning, leaving modification underexplored due to the scarcity of need-to-modify itinerary data. To bridge this gap, we formally define the itinerary modification task and propose a general pipeline to construct the corresponding dataset, namely iTIMO. This pipeline frames the generation of need-to-modify itinerary data as an intent-driven perturbation task. It instructs large language models to perturb real-world itineraries using three operations: REPLACE, ADD, and DELETE. Each perturbation is grounded in three intents: disruptions of popularity, spatial distance, and category diversity. Furthermore, hybrid evaluation metrics are introduced to ensure perturbation effectiveness. We conduct comprehensive benchmarking on iTIMO to analyze the capabilities and limitations of state-of-the-art LLMs. Overall, iTIMO provides a comprehensive testbed for the modification task, and empowers the evolution of traditional travel recommender systems into adaptive frameworks capable of handling dynamic travel needs. Dataset, code and supplementary materials are available at https://github.com/zelo2/iTIMO.","authors":["Zhuoxuan Huang","Yunshan Ma","Hongyu Zhang","Hua Ma","Zhu Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01703v2","updated":"2026-02-20T02:40:50Z","published":"2026-01-05T00:44:17Z","title":"Beyond Homophily: Community Search on Heterophilic Graphs","summary":"Community search aims to identify a refined set of nodes that are most relevant to a given query, supporting tasks ranging from fraud detection to recommendation. Unlike homophilic graphs, many real-world networks are heterophilic, where edges predominantly connect dissimilar nodes. Therefore, structural signals that once reflected smooth, low-frequency similarity now appear as sharp, high-frequency contrasts. However, both classical algorithms (e.g., k-core, k-truss) and recent ML-based models struggle to achieve effective community search on heterophilic graphs, where edge signs or semantics are generally unknown. Algorithm-based methods often return communities with mixed class labels, while GNNs, built on homophily, smooth away meaningful signals and blur community boundaries. Therefore, we propose Adaptive Community Search (AdaptCS), a lightweight framework featuring three key designs: (i) an AdaptCS Encoder that disentangles multi-hop and multi-frequency signals, enabling the model to capture both smooth (homophilic) and contrastive (heterophilic) relations; (ii) a memory-efficient low-rank optimization that removes the main computational bottleneck and ensures model scalability; and (iii) an Adaptive Community Score (ACS) that guides online search by balancing embedding similarity and topological relations. Extensive experiments on both heterophilic and homophilic benchmarks demonstrate that AdaptCS outperforms the best-performing baseline by an average of 11% in F1-score, retains robustness across heterophily levels, and achieves up to 2 orders of magnitude speedup over the strongest ML-based CS baselines.","authors":["Qing Sima","Xiaoyang Wang","Wenjie Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17914v1","updated":"2026-02-20T00:22:43Z","published":"2026-02-20T00:22:43Z","title":"Efficient Filtered-ANN via Learning-based Query Planning","summary":"Filtered ANN search is an increasingly important problem in vector retrieval, yet systems face a difficult trade-off due to the execution order: Pre-filtering (filtering first, then ANN over the passing subset) requires expensive per-predicate index construction, while post-filtering (ANN first, then filtering candidates) may waste computation and lose recall under low selectivity due to insufficient candidates after filtering. We introduce a learning-based query planning framework that dynamically selects the most effective execution plan for each query, using lightweight predictions derived from dataset and query statistics (e.g., dimensionality, corpus size, distribution features, and predicate statistics). The framework supports diverse filter types, including categorical/keyword and range predicates, and is generic to use any backend ANN index. Experiments show that our method achieves up to 4x acceleration with >= 90% recall comparing to the strong baselines.","authors":["Zhuocheng Gan","Yifan Wang"],"pdf_url":"","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2602.18435v1","updated":"2026-02-20T18:59:53Z","published":"2026-02-20T18:59:53Z","title":"Assigning Confidence: K-partition Ensembles","summary":"Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.","authors":["Aggelos Semoglou","John Pavlopoulos"],"pdf_url":"","comment":"31 pages including appendix"},{"id":"http://arxiv.org/abs/2511.18554v2","updated":"2026-02-20T18:59:32Z","published":"2025-11-23T17:59:51Z","title":"Online Smoothed Demand Management","summary":"We introduce and study a class of online problems called online smoothed demand management $(\\texttt{OSDM})$, motivated by paradigm shifts in grid integration and energy storage for large energy consumers such as data centers. In $\\texttt{OSDM}$, an operator makes two decisions at each time step: an amount of energy to be purchased, and an amount of energy to be delivered (i.e., used for computation). The difference between these decisions charges (or discharges) the operator's energy storage (e.g., a battery). Two types of demand arrive online: base demand, which must be covered at the current time, and flexible demand, which can be satisfied at any time before a demand-specific deadline $Δ_t$. The operator's goal is to minimize a cost (subject to above constraints) that combines a cost of purchasing energy, a cost for delivering energy (if applicable), and smoothness penalties on the purchasing and delivery rates to discourage fluctuations and encourage ``grid healthy'' decisions. $\\texttt{OSDM}$ generalizes several problems in the online algorithms literature while being the first to fully model applications of interest. We propose a competitive algorithm for $\\texttt{OSDM}$ called $\\texttt{PAAD}$ (partitioned accounting & aggregated decisions) and show it achieves the optimal competitive ratio. To overcome the pessimism typical of worst-case analysis, we also propose a novel learning framework that provides guarantees on the worst-case competitive ratio (i.e., to provide robustness against nonstationarity) while allowing end-to-end differentiable learning of the best algorithm on historical instances of the problem. We evaluate our algorithms in a case study of a grid-integrated data center with battery storage, showing that $\\texttt{PAAD}$ effectively solves the problem and end-to-end learning achieves substantial performance improvements compared to $\\texttt{PAAD}$.","authors":["Adam Lechowicz","Nicolas Christianson","Mohammad Hajiesmaili","Adam Wierman","Prashant Shenoy"],"pdf_url":"","comment":"Accepted to SIGMETRICS '26. 65 pages, 11 figures"},{"id":"http://arxiv.org/abs/2602.18428v1","updated":"2026-02-20T18:49:00Z","published":"2026-02-20T18:49:00Z","title":"The Geometry of Noise: Why Diffusion Models Don't Need Noise Conditioning","summary":"Autonomous (noise-agnostic) generative models, such as Equilibrium Matching and blind diffusion, challenge the standard paradigm by learning a single, time-invariant vector field that operates without explicit noise-level conditioning. While recent work suggests that high-dimensional concentration allows these models to implicitly estimate noise levels from corrupted observations, a fundamental paradox remains: what is the underlying landscape being optimized when the noise level is treated as a random variable, and how can a bounded, noise-agnostic network remain stable near the data manifold where gradients typically diverge? We resolve this paradox by formalizing Marginal Energy, $E_{\\text{marg}}(\\mathbf{u}) = -\\log p(\\mathbf{u})$, where $p(\\mathbf{u}) = \\int p(\\mathbf{u}|t)p(t)dt$ is the marginal density of the noisy data integrated over a prior distribution of unknown noise levels. We prove that generation using autonomous models is not merely blind denoising, but a specific form of Riemannian gradient flow on this Marginal Energy. Through a novel relative energy decomposition, we demonstrate that while the raw Marginal Energy landscape possesses a $1/t^p$ singularity normal to the data manifold, the learned time-invariant field implicitly incorporates a local conformal metric that perfectly counteracts the geometric singularity, converting an infinitely deep potential well into a stable attractor. We also establish the structural stability conditions for sampling with autonomous models. We identify a ``Jensen Gap'' in noise-prediction parameterizations that acts as a high-gain amplifier for estimation errors, explaining the catastrophic failure observed in deterministic blind models. Conversely, we prove that velocity-based parameterizations are inherently stable because they satisfy a bounded-gain condition that absorbs posterior uncertainty into a smooth geometric drift.","authors":["Mojtaba Sahraee-Ardakan","Mauricio Delbracio","Peyman Milanfar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18419v1","updated":"2026-02-20T18:41:48Z","published":"2026-02-20T18:41:48Z","title":"Benchmarking Graph Neural Networks in Solving Hard Constraint Satisfaction Problems","summary":"Graph neural networks (GNNs) are increasingly applied to hard optimization problems, often claiming superiority over classical heuristics. However, such claims risk being unsolid due to a lack of standard benchmarks on truly hard instances. From a statistical physics perspective, we propose new hard benchmarks based on random problems. We provide these benchmarks, along with performance results from both classical heuristics and GNNs. Our fair comparison shows that classical algorithms still outperform GNNs. We discuss the challenges for neural networks in this domain. Future claims of superiority can be made more robust using our benchmarks, available at https://github.com/ArtLabBocconi/RandCSPBench.","authors":["Geri Skenderi","Lorenzo Buffoni","Francesco D'Amico","David Machado","Raffaele Marino","Matteo Negri","Federico Ricci-Tersenghi","Carlo Lucibello","Maria Chiara Angelini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18417v1","updated":"2026-02-20T18:35:43Z","published":"2026-02-20T18:35:43Z","title":"Subgroups of $U(d)$ Induce Natural RNN and Transformer Architectures","summary":"This paper presents a direct framework for sequence models with hidden states on closed subgroups of U(d). We use a minimal axiomatic setup and derive recurrent and transformer templates from a shared skeleton in which subgroup choice acts as a drop-in replacement for state space, tangent projection, and update map. We then specialize to O(d) and evaluate orthogonal-state RNN and transformer models on Tiny Shakespeare and Penn Treebank under parameter-matched settings. We also report a general linear-mixing extension in tangent space, which applies across subgroup choices and improves finite-budget performance in the current O(d) experiments.","authors":["Joshua Nunley"],"pdf_url":"","comment":"12 pages, 3 figures, 8 tables"},{"id":"http://arxiv.org/abs/2502.05351v2","updated":"2026-02-20T18:35:16Z","published":"2025-02-07T21:44:01Z","title":"Deep Generative model that uses physical quantities to generate and retrieve solar magnetic active regions","summary":"Deep generative models have shown immense potential in generating unseen data that has properties of real data. These models learn complex data-generating distributions starting from a smaller set of latent dimensions. However, generative models have encountered great skepticism in scientific domains due to the disconnection between generative latent vectors and scientifically relevant quantities. In this study, we integrate three types of machine learning models to generate solar magnetic patches in a physically interpretable manner and use those as a query to find matching patches in real observations. We use the magnetic field measurements from Space-weather HMI Active Region Patches (SHARPs) to train a Generative Adversarial Network (GAN). We connect the physical properties of GAN-generated images with their latent vectors to train Support Vector Machines (SVMs) that do mapping between physical and latent spaces. These produce directions in the GAN latent space along which known physical parameters of the SHARPs change. We train a self-supervised learner (SSL) to make queries with generated images and find matches from real data. We find that the GAN-SVM combination enables users to produce high-quality patches that change smoothly only with a prescribed physical quantity, making generative models physically interpretable. We also show that GAN outputs can be used to retrieve real data that shares the same physical properties as the generated query. This elevates Generative Artificial Intelligence (AI) from a means-to-produce artificial data to a novel tool for scientific data interrogation, supporting its applicability beyond the domain of heliophysics.","authors":["Subhamoy Chatterjee","Andres Munoz-Jaramillo","Anna Malanushenko"],"pdf_url":"","comment":"14 pages, 9 figures, accepted for publication in ApJS"},{"id":"http://arxiv.org/abs/2312.12715v3","updated":"2026-02-20T18:33:44Z","published":"2023-12-20T02:21:26Z","title":"Learning Performance Maximizing Ensembles with Explainability Guarantees","summary":"In this paper we propose a method for the optimal allocation of observations between an intrinsically explainable glass box model and a black box model. An optimal allocation being defined as one which, for any given explainability level (i.e. the proportion of observations for which the explainable model is the prediction function), maximizes the performance of the ensemble on the underlying task, and maximizes performance of the explainable model on the observations allocated to it, subject to the maximal ensemble performance condition. The proposed method is shown to produce such explainability optimal allocations on a benchmark suite of tabular datasets across a variety of explainable and black box model types. These learned allocations are found to consistently maintain ensemble performance at very high explainability levels (explaining $74\\%$ of observations on average), and in some cases even outperforming both the component explainable and black box models while improving explainability.","authors":["Vincent Pisztora","Jia Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.06816v4","updated":"2026-02-20T18:28:54Z","published":"2024-10-09T12:14:24Z","title":"Expressiveness of Multi-Neuron Convex Relaxations in Neural Network Certification","summary":"Neural network certification methods heavily rely on convex relaxations to provide robustness guarantees. However, these relaxations are often imprecise: even the most accurate single-neuron relaxation is incomplete for general ReLU networks, a limitation known as the *single-neuron convex barrier*. While multi-neuron relaxations have been heuristically applied to address this issue, two central questions arise: (i) whether they overcome the convex barrier, and if not, (ii) whether they offer theoretical capabilities beyond those of single-neuron relaxations. In this work, we present the first rigorous analysis of the expressiveness of multi-neuron relaxations. Perhaps surprisingly, we show that they are inherently incomplete, even when allocated sufficient resources to capture finitely many neurons and layers optimally. This result extends the single-neuron barrier to a *universal convex barrier* for neural network certification. On the positive side, we show that completeness can be achieved by either (i) augmenting the network with a polynomial number of carefully designed ReLU neurons or (ii) partitioning the input domain into convex sub-polytopes, thereby distinguishing multi-neuron relaxations from single-neuron ones which are unable to realize the former and have worse partition complexity for the latter. Our findings establish a foundation for multi-neuron relaxations and point to new directions for certified robustness, including training methods tailored to multi-neuron relaxations and verification methods with multi-neuron relaxations as the main subroutine.","authors":["Yuhao Mao","Yani Zhang","Martin Vechev"],"pdf_url":"","comment":"ICLR'26"},{"id":"http://arxiv.org/abs/2502.05114v2","updated":"2026-02-20T18:18:48Z","published":"2025-02-07T17:36:13Z","title":"SpecTUS: Spectral Translator for Unknown Structures annotation from EI-MS spectra","summary":"Compound identification and structure annotation from mass spectra is a well-established task widely applied in drug detection, criminal forensics, small molecule biomarker discovery and chemical engineering.\n  We propose SpecTUS: Spectral Translator for Unknown Structures, a deep neural model that addresses the task of structural annotation of small molecules from low-resolution gas chromatography electron ionization mass spectra (GC-EI-MS). Our model analyzes the spectra in \\textit{de novo} manner -- a direct translation from the spectra into 2D-structural representation. Our approach is particularly useful for analyzing compounds unavailable in spectral libraries.\n  In a rigorous evaluation of our model on the novel structure annotation task across different libraries, we outperformed standard database search techniques by a wide margin. On a held-out testing set, including \\numprint{28267} spectra from the NIST database, we show that our model's single suggestion perfectly reconstructs 43\\% of the subset's compounds. This single suggestion is strictly better than the candidate of the database hybrid search (common method among practitioners)\n  in 76\\% of cases. In a~still affordable scenario of~10 suggestions, perfect reconstruction is achieved in 65\\%, and 84\\% are better than the hybrid search.","authors":["Adam Hájek","Michal Starý","Elliott Price","Filip Jozefov","Helge Hecht","Aleš Křenek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18409v1","updated":"2026-02-20T18:18:48Z","published":"2026-02-20T18:18:48Z","title":"Unifying approach to uniform expressivity of graph neural networks","summary":"The expressive power of Graph Neural Networks (GNNs) is often analysed via correspondence to the Weisfeiler-Leman (WL) algorithm and fragments of first-order logic. Standard GNNs are limited to performing aggregation over immediate neighbourhoods or over global read-outs. To increase their expressivity, recent attempts have been made to incorporate substructural information (e.g. cycle counts and subgraph properties). In this paper, we formalize this architectural trend by introducing Template GNNs (T-GNNs), a generalized framework where node features are updated by aggregating over valid template embeddings from a specified set of graph templates. We propose a corresponding logic, Graded template modal logic (GML(T)), and generalized notions of template-based bisimulation and WL algorithm. We establish an equivalence between the expressive power of T-GNNs and GML(T), and provide a unifying approach for analysing GNN expressivity: we show how standard AC-GNNs and its recent variants can be interpreted as instantiations of T-GNNs.","authors":["Huan Luo","Jonni Virtema"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18406v1","updated":"2026-02-20T18:14:05Z","published":"2026-02-20T18:14:05Z","title":"Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges","summary":"Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.","authors":["Minh Dinh","Stéphane Deny"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.02228v2","updated":"2026-02-20T18:12:16Z","published":"2025-10-02T17:14:34Z","title":"xLSTM Scaling Laws: Competitive Performance with Linear Time-Complexity","summary":"Scaling laws play a central role in the success of Large Language Models (LLMs), enabling the prediction of model performance relative to compute budgets prior to training. While Transformers have been the dominant architecture, recent alternatives such as xLSTM offer linear complexity with respect to context length while remaining competitive in the billion-parameter regime. We conduct a comparative investigation on the scaling behavior of Transformers and xLSTM along the following lines, providing insights to guide future model design and deployment. First, we study the scaling behavior for xLSTM in compute-optimal and over-training regimes using both IsoFLOP and parametric fit approaches on a wide range of model sizes (80M-7B) and number of training tokens (2B-2T). Second, we examine the dependence of optimal model sizes on context length, a pivotal aspect that was largely ignored in previous work. Finally, we analyze inference-time scaling characteristics. Our findings reveal that in typical LLM training and inference scenarios, xLSTM scales favorably compared to Transformers. Notably, xLSTM models consistently Pareto-dominate Transformer models, delivering lower cross-entropy loss for the same compute budget.","authors":["Maximilian Beck","Kajetan Schweighofer","Sebastian Böck","Sebastian Lehner","Sepp Hochreiter"],"pdf_url":"","comment":"Accepted at ICLR 2026. Code and data available at https://github.com/NX-AI/xlstm_scaling_laws"},{"id":"http://arxiv.org/abs/2602.18403v1","updated":"2026-02-20T18:12:14Z","published":"2026-02-20T18:12:14Z","title":"Scientific Knowledge-Guided Machine Learning for Vessel Power Prediction: A Comparative Study","summary":"Accurate prediction of main engine power is essential for vessel performance optimization, fuel efficiency, and compliance with emission regulations. Conventional machine learning approaches, such as Support Vector Machines, variants of Artificial Neural Networks (ANNs), and tree-based methods like Random Forests, Extra Tree Regressors, and XGBoost, can capture nonlinearities but often struggle to respect the fundamental propeller law relationship between power and speed, resulting in poor extrapolation outside the training envelope. This study introduces a hybrid modeling framework that integrates physics-based knowledge from sea trials with data-driven residual learning. The baseline component, derived from calm-water power curves of the form $P = cV^n$, captures the dominant power-speed dependence, while another, nonlinear, regressor is then trained to predict the residual power, representing deviations caused by environmental and operational conditions. By constraining the machine learning task to residual corrections, the hybrid model simplifies learning, improves generalization, and ensures consistency with the underlying physics. In this study, an XGBoost, a simple Neural Network, and a Physics-Informed Neural Network (PINN) coupled with the baseline component were compared to identical models without the baseline component. Validation on in-service data demonstrates that the hybrid model consistently outperformed a pure data-driven baseline in sparse data regions while maintaining similar performance in populated ones. The proposed framework provides a practical and computationally efficient tool for vessel performance monitoring, with applications in weather routing, trim optimization, and energy efficiency planning.","authors":["Orfeas Bourchas","George Papalambrou"],"pdf_url":"","comment":"Accepted to the KGML Bridge at AAAI 2026 (non-archival)"},{"id":"http://arxiv.org/abs/2602.18401v1","updated":"2026-02-20T18:07:09Z","published":"2026-02-20T18:07:09Z","title":"Leakage and Second-Order Dynamics Improve Hippocampal RNN Replay","summary":"Biological neural networks (like the hippocampus) can internally generate \"replay\" resembling stimulus-driven activity. Recent computational models of replay use noisy recurrent neural networks (RNNs) trained to path-integrate. Replay in these networks has been described as Langevin sampling, but new modifiers of noisy RNN replay have surpassed this description. We re-examine noisy RNN replay as sampling to understand or improve it in three ways: (1) Under simple assumptions, we prove that the gradients replay activity should follow are time-varying and difficult to estimate, but readily motivate the use of hidden state leakage in RNNs for replay. (2) We confirm that hidden state adaptation (negative feedback) encourages exploration in replay, but show that it incurs non-Markov sampling that also slows replay. (3) We propose the first model of temporally compressed replay in noisy path-integrating RNNs through hidden state momentum, connect it to underdamped Langevin sampling, and show that, together with adaptation, it counters slowness while maintaining exploration. We verify our findings via path-integration of 2D triangular and T-maze paths and of high-dimensional paths of synthetic rat place cell activity.","authors":["Josue Casco-Rodriguez","Nanda H. Krishna","Richard G. Baraniuk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18396v1","updated":"2026-02-20T18:01:59Z","published":"2026-02-20T18:01:59Z","title":"PRISM-FCP: Byzantine-Resilient Federated Conformal Prediction via Partial Sharing","summary":"We propose PRISM-FCP (Partial shaRing and robust calIbration with Statistical Margins for Federated Conformal Prediction), a Byzantine-resilient federated conformal prediction framework that utilizes partial model sharing to improve robustness against Byzantine attacks during both model training and conformal calibration. Existing approaches address adversarial behavior only in the calibration stage, leaving the learned model susceptible to poisoned updates. In contrast, PRISM-FCP mitigates attacks end-to-end. During training, clients partially share updates by transmitting only $M$ of $D$ parameters per round. This attenuates the expected energy of an adversary's perturbation in the aggregated update by a factor of $M/D$, yielding lower mean-square error (MSE) and tighter prediction intervals. During calibration, clients convert nonconformity scores into characterization vectors, compute distance-based maliciousness scores, and downweight or filter suspected Byzantine contributions before estimating the conformal quantile. Extensive experiments on both synthetic data and the UCI Superconductivity dataset demonstrate that PRISM-FCP maintains nominal coverage guarantees under Byzantine attacks while avoiding the interval inflation observed in standard FCP with reduced communication, providing a robust and communication-efficient approach to federated uncertainty quantification.","authors":["Ehsan Lari","Reza Arablouei","Stefan Werner"],"pdf_url":"","comment":"13 pages, 5 figures, 2 tables, Submitted to IEEE Transactions on Signal Processing (TSP)"},{"id":"http://arxiv.org/abs/2504.21022v2","updated":"2026-02-20T17:50:01Z","published":"2025-04-22T20:32:34Z","title":"ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees","summary":"Linear Temporal Logic (LTL) is a widely used task specification language for autonomous systems. To mitigate the significant manual effort and expertise required to define LTL-encoded tasks, several methods have been proposed for translating Natural Language (NL) instructions into LTL formulas, which, however, lack correctness guarantees. To address this, we propose a new NL-to-LTL translation method, called ConformalNL2LTL that achieves user-defined translation success rates on unseen NL commands. Our method constructs LTL formulas iteratively by solving a sequence of open-vocabulary question-answering (QA) problems using large language models (LLMs). These QA tasks are handled collaboratively by a primary and an auxiliary model. The primary model answers each QA instance while quantifying uncertainty via conformal prediction; when it is insufficiently certain according to user-defined confidence thresholds, it requests assistance from the auxiliary model and, if necessary, from the user. We demonstrate theoretically and empirically that ConformalNL2LTL achieves the desired translation accuracy while minimizing user intervention.","authors":["David Smith Sundarsingh","Jun Wang","Jyotirmoy V. Deshmukh","Yiannis Kantaros"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18386v1","updated":"2026-02-20T17:48:21Z","published":"2026-02-20T17:48:21Z","title":"Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO","summary":"Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.","authors":["Mohamed Elgouhary","Amr S. El-Wakeel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18384v1","updated":"2026-02-20T17:45:28Z","published":"2026-02-20T17:45:28Z","title":"FedZMG: Efficient Client-Side Optimization in Federated Learning","summary":"Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the \"intensity\" or \"bias\" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.","authors":["Fotios Zantalis","Evangelos Zervas","Grigorios Koulouras"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18377v1","updated":"2026-02-20T17:33:27Z","published":"2026-02-20T17:33:27Z","title":"Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach","summary":"Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given training objective. As a specific application, we focus on learning nonlinear dynamical systems and show that a QELM trained on such trajectories learns a surrogate-approximation to the underlying flow map.","authors":["Markus Gross","Hans-Martin Rieser"],"pdf_url":"","comment":"34 pages, 12 figures"},{"id":"http://arxiv.org/abs/2602.18364v1","updated":"2026-02-20T17:16:38Z","published":"2026-02-20T17:16:38Z","title":"Quantum Maximum Likelihood Prediction via Hilbert Space Embeddings","summary":"Recent works have proposed various explanations for the ability of modern large language models (LLMs) to perform in-context prediction. We propose an alternative conceptual viewpoint from an information-geometric and statistical perspective. Motivated by Bach[2023], we model training as learning an embedding of probability distributions into the space of quantum density operators, and in-context learning as maximum-likelihood prediction over a specified class of quantum models. We provide an interpretation of this predictor in terms of quantum reverse information projection and quantum Pythagorean theorem when the class of quantum models is sufficiently expressive. We further derive non-asymptotic performance guarantees in terms of convergence rates and concentration inequalities, both in trace norm and quantum relative entropy. Our approach provides a unified framework to handle both classical and quantum LLMs.","authors":["Sreejith Sreekumar","Nir Weinberger"],"pdf_url":"","comment":"32+4 pages, 1 figure"},{"id":"http://arxiv.org/abs/2505.11409v3","updated":"2026-02-20T17:09:35Z","published":"2025-05-16T16:17:22Z","title":"Visual Planning: Let's Think Only with Images","summary":"Recent advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have substantially enhanced machine reasoning across diverse tasks. However, these models predominantly rely on pure text as the medium for both expressing and structuring reasoning, even when visual information is present. In this work, we argue that language may not always be the most natural or effective modality for reasoning, particularly in tasks involving spatial and geometrical information. Motivated by this, we propose a new paradigm, Visual Planning, which enables planning through purely visual representations for these \"vision-first\" tasks, as a supplementary channel to language-based reasoning. In this paradigm, planning is executed via sequences of images that encode step-by-step inference in the visual domain, akin to how humans sketch or visualize future actions. We introduce a novel reinforcement learning framework, Visual Planning via Reinforcement Learning (VPRL), empowered by GRPO for post-training large vision models, leading to substantial improvements in planning in a selection of representative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our visual planning paradigm outperforms all other planning variants that conduct reasoning in the text-only space. Our results establish Visual Planning as a viable and promising supplement to language-based reasoning, opening new avenues for tasks that benefit from intuitive, image-based inference.","authors":["Yi Xu","Chengzu Li","Han Zhou","Xingchen Wan","Caiqi Zhang","Anna Korhonen","Ivan Vulić"],"pdf_url":"","comment":"ICLR 2026 (Oral)"},{"id":"http://arxiv.org/abs/2602.18350v1","updated":"2026-02-20T17:02:16Z","published":"2026-02-20T17:02:16Z","title":"Quantum-enhanced satellite image classification","summary":"We demonstrate the application of a quantum feature extraction method to enhance multi-class image classification for space applications. By harnessing the dynamics of many-body spin Hamiltonians, the method generates expressive quantum features that, when combined with classical processing, lead to quantum-enhanced classification accuracy. Using a strong and well-established ResNet50 baseline, we achieved a maximum classical accuracy of 83%, which can be improved to 84% with a transfer learning approach. In contrast, applying our quantum-classical method the performance is increased to 87% accuracy, demonstrating a clear and reproducible improvement over robust classical approaches. Implemented on several of IBM's quantum processors, our hybrid quantum-classical approach delivers consistent gains of 2-3% in absolute accuracy. These results highlight the practical potential of current and near-term quantum processors in high-stakes, data-driven domains such as satellite imaging and remote sensing, while suggesting broader applicability in real-world machine learning tasks.","authors":["Qi Zhang","Anton Simen","Carlos Flores-Garrigós","Gabriel Alvarado Barrios","Paolo A. Erdman","Enrique Solano","Aaron C. Kemp","Vincent Beltrani","Vedangi Pathak","Hamed Mohammadbagherpoor"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18348v1","updated":"2026-02-20T17:01:25Z","published":"2026-02-20T17:01:25Z","title":"Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering","summary":"AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.","authors":["Matheus Camilo da Silva","Leonardo Arrighi","Ana Carolina Lorena","Sylvio Barbon Junior"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16086v2","updated":"2026-02-20T16:45:42Z","published":"2026-02-17T23:20:26Z","title":"LGQ: Learning Discretization Geometry for Scalable and Stable Image Tokenization","summary":"Discrete image tokenization is a key bottleneck for scalable visual generation: a tokenizer must remain compact for efficient latent-space priors while preserving semantic structure and using discrete capacity effectively. Existing quantizers face a trade-off: vector-quantized tokenizers learn flexible geometries but often suffer from biased straight-through optimization, codebook under-utilization, and representation collapse at large vocabularies. Structured scalar or implicit tokenizers ensure stable, near-complete utilization by design, yet rely on fixed discretization geometries that may allocate capacity inefficiently under heterogeneous latent statistics.\n  We introduce Learnable Geometric Quantization (LGQ), a discrete image tokenizer that learns discretization geometry end-to-end. LGQ replaces hard nearest-neighbor lookup with temperature-controlled soft assignments, enabling fully differentiable training while recovering hard assignments at inference. The assignments correspond to posterior responsibilities of an isotropic Gaussian mixture and minimize a variational free-energy objective, provably converging to nearest-neighbor quantization in the low-temperature limit. LGQ combines a token-level peakedness regularizer with a global usage regularizer to encourage confident yet balanced code utilization without imposing rigid grids.\n  Under a controlled VQGAN-style backbone on ImageNet across multiple vocabulary sizes, LGQ achieves stable optimization and balanced utilization. At 16K codebook size, LGQ improves rFID by 11.88% over FSQ while using 49.96% fewer active codes, and improves rFID by 6.06% over SimVQ with 49.45% lower effective representation rate, achieving comparable fidelity with substantially fewer active entries. Our GitHub repository is available at: https://github.com/KurbanIntelligenceLab/LGQ","authors":["Idil Bilge Altun","Mert Onur Cakiroglu","Elham Buxton","Mehmet Dalkilic","Hasan Kurban"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22458v2","updated":"2026-02-20T16:42:22Z","published":"2025-09-26T15:09:26Z","title":"Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator","summary":"Physics-informed graph neural networks (PIGNNs) have emerged as fast AC power-flow solvers that can replace the classic NewtonRaphson (NR) solvers, especially when thousands of scenarios must be evaluated. However, current PIGNNs still need accuracy improvements at parity speed; in particular, the soft constraint on the physics loss is inoperative at inference, which can deter operational adoption. We address this with PIGNN-Attn-LS, combining an edge-aware attention mechanism that explicitly encodes line physics via per-edge biases to form a fully differentiable knownoperator layer inside the computation graph, with a backtracking line-search-based globalized correction operator that restores an operative decrease criterion at inference. Training and testing use a realistic High-/Medium-Voltage scenario generator, with NR used only to construct reference states. On held-out HV cases consisting of 4-32-bus grids, PIGNN-Attn-LS achieves a test RMSE of 0.00033 p.u. in voltage and 0.08 deg in angle, outperforming the PIGNN-MLP baseline by 99.5% and 87.1%, respectively. With streaming micro-batches, it delivers 2-5x faster batched inference than NR on 4-1024-bus grids.","authors":["Changhun Kim","Timon Conrad","Redwanul Karim","Julian Oelhaf","David Riebesel","Tomás Arias-Vergara","Andreas Maier","Johann Jäger","Siming Bayer"],"pdf_url":"","comment":"Accepted to ICASSP 2026. 5 pages, 2 figures. Code available at https://github.com/Kimchangheon/PIGNN-Attn-LS"},{"id":"http://arxiv.org/abs/2601.11924v2","updated":"2026-02-20T16:40:01Z","published":"2026-01-17T06:13:52Z","title":"Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits","summary":"We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.","authors":["Ming Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18333v1","updated":"2026-02-20T16:39:07Z","published":"2026-02-20T16:39:07Z","title":"On the \"Induction Bias\" in Sequence Models","summary":"Despite the remarkable practical success of transformer-based language models, recent work has raised concerns about their ability to perform state tracking. In particular, a growing body of literature has shown this limitation primarily through failures in out-of-distribution (OOD) generalization, such as length extrapolation. In this work, we shift attention to the in-distribution implications of these limitations. We conduct a large-scale experimental study of the data efficiency of transformers and recurrent neural networks (RNNs) across multiple supervision regimes. We find that the amount of training data required by transformers grows much more rapidly with state-space size and sequence length than for RNNs. Furthermore, we analyze the extent to which learned state-tracking mechanisms are shared across different sequence lengths. We show that transformers exhibit negligible or even detrimental weight sharing across lengths, indicating that they learn length-specific solutions in isolation. In contrast, recurrent models exhibit effective amortized learning by sharing weights across lengths, allowing data from one sequence length to improve performance on others. Together, these results demonstrate that state tracking remains a fundamental challenge for transformers, even when training and evaluation distributions match.","authors":["M. Reza Ebrahimi","Michaël Defferrard","Sunny Panchal","Roland Memisevic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.03175v2","updated":"2026-02-20T16:27:12Z","published":"2026-02-03T06:44:00Z","title":"Probe-then-Commit Multi-Objective Bandits: Theoretical Benefits of Limited Multi-Arm Feedback","summary":"We study an online resource-selection problem motivated by multi-radio access selection and mobile edge computing offloading. In each round, an agent chooses among $K$ candidate links/servers (arms) whose performance is a stochastic $d$-dimensional vector (e.g., throughput, latency, energy, reliability). The key interaction is \\emph{probe-then-commit (PtC)}: the agent may probe up to $q>1$ candidates via control-plane measurements to observe their vector outcomes, but must execute exactly one candidate in the data plane. This limited multi-arm feedback regime strictly interpolates between classical bandits ($q=1$) and full-information experts ($q=K$), yet existing multi-objective learning theory largely focuses on these extremes. We develop \\textsc{PtC-P-UCB}, an optimistic probe-then-commit algorithm whose technical core is frontier-aware probing under uncertainty in a Pareto mode, e.g., it selects the $q$ probes by approximately maximizing a hypervolume-inspired frontier-coverage potential and commits by marginal hypervolume gain to directly expand the attained Pareto region. We prove a dominated-hypervolume frontier error of $\\tilde{O} (K_P d/\\sqrt{qT})$, where $K_P$ is the Pareto-frontier size and $T$ is the horizon, and scalarized regret $\\tilde{O} (L_φd\\sqrt{(K/q)T})$, where $φ$ is the scalarizer. These quantify a transparent $1/\\sqrt{q}$ acceleration from limited probing. We further extend to \\emph{multi-modal probing}: each probe returns $M$ modalities (e.g., CSI, queue, compute telemetry), and uncertainty fusion yields variance-adaptive versions of the above bounds via an effective noise scale.","authors":["Ming Shi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.15058v2","updated":"2026-02-20T16:24:28Z","published":"2025-10-16T18:16:05Z","title":"The Minimax Lower Bound of Kernel Stein Discrepancy Estimation","summary":"Kernel Stein discrepancies (KSDs) have emerged as a powerful tool for quantifying goodness-of-fit over the last decade, featuring numerous successful applications. To the best of our knowledge, all existing KSD estimators with known rate achieve $\\sqrt n$-convergence. In this work, we present two complementary results (with different proof strategies), establishing that the minimax lower bound of KSD estimation is $n^{-1/2}$ and settling the optimality of these estimators. Our first result focuses on KSD estimation on $\\mathbb R^d$ with the Langevin-Stein operator; our explicit constant for the Gaussian kernel indicates that the difficulty of KSD estimation may increase exponentially with the dimensionality $d$. Our second result settles the minimax lower bound for KSD estimation on general domains.","authors":["Jose Cribeiro-Ramallo","Agnideep Aich","Florian Kalinke","Ashit Baran Aich","Zoltán Szabó"],"pdf_url":"","comment":"Accepted for publication at AISTATS 2026"},{"id":"http://arxiv.org/abs/2511.02872v3","updated":"2026-02-20T16:21:35Z","published":"2025-11-04T03:25:17Z","title":"FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels","summary":"Recent advances in large language models (LLMs) have demonstrated impressive capabilities in formal theorem proving, particularly on contest-based mathematical benchmarks like the IMO. However, these contests do not reflect the depth, breadth, and abstraction of modern mathematical research. To bridge this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new benchmark series in formal algebra designed to chart a course toward advanced mathematical reasoning. We present two new components, FATE-H and FATE-X, each with 100 problems in abstract and commutative algebra. The FATE series spans a difficulty spectrum from undergraduate exercises to problems exceeding PhD qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both PhD-level exam difficulty and the coverage of the Mathlib library. Our evaluations of state-of-the-art LLM provers on this new benchmark reveal a stark performance gap compared to contest math: the best model achieves only 3% (pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals that models' natural-language reasoning is notably more accurate than their ability to formalize this reasoning. We systematically classify the common errors that arise during this formalization process. Furthermore, a comparative study shows that a specialized prover can exhibit less effective reflection than general-purpose models, reducing its accuracy at the natural-language stage. We believe FATE provides a robust and challenging benchmark that establishes essential checkpoints on the path toward research-level formal mathematical reasoning.","authors":["Jiedong Jiang","Wanyi He","Yuefeng Wang","Guoxiong Gao","Yongle Hu","Jingting Wang","Nailing Guan","Peihao Wu","Chunbo Dai","Liang Xiao","Bin Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.21154v3","updated":"2026-02-20T16:20:57Z","published":"2025-09-25T13:40:36Z","title":"GRPO is Secretly a Process Reward Model","summary":"Process reward models (PRMs) allow for fine-grained credit assignment in reinforcement learning (RL), and seemingly contrast with outcome reward models (ORMs), which assign a single reward to an entire trajectory. However, we provide theoretical proof in this work that the Group Relative Policy Optimization (GRPO) RL algorithm equipped with an ORM is in fact equivalent to a PRM-aware RL objective equipped with a non-trivial, Monte-Carlo-based PRM (given mild assumptions). Leveraging the framework of GRPO-as-a-PRM, we identify a flaw in the GRPO objective that interacts with imbalanced process steps and rewards to hinder both exploration and exploitation (under different conditions). We propose a simple modification to the algorithm to mitigate this defect ($λ$-GRPO), and show that LLMs tuned with $λ$-GRPO outperform LLMs tuned with standard GRPO on downstream reasoning tasks\\textemdash and reach peak performance more rapidly. These results show that we can leverage the hidden, built-in PRM structure within the vanilla GRPO algorithm to boost model performance without employing an explicit PRM, and with a negligible impact on training time and cost.","authors":["Michael Sullivan","Alexander Koller"],"pdf_url":"","comment":"15 pages, 7 figures; under review at ICML 2026"},{"id":"http://arxiv.org/abs/2602.18319v1","updated":"2026-02-20T16:19:19Z","published":"2026-02-20T16:19:19Z","title":"Robo-Saber: Generating and Simulating Virtual Reality Players","summary":"We present the first motion generation system for playtesting virtual reality (VR) games. Our player model generates VR headset and handheld controller movements from in-game object arrangements, guided by style exemplars and aligned to maximize simulated gameplay score. We train on the large BOXRR-23 dataset and apply our framework on the popular VR game Beat Saber. The resulting model Robo-Saber produces skilled gameplay and captures diverse player behaviors, mirroring the skill levels and movement patterns specified by input style exemplars. Robo-Saber demonstrates promise in synthesizing rich gameplay data for predictive applications and enabling a physics-based whole-body VR playtesting agent.","authors":["Nam Hee Kim","Jingjing May Liu","Jaakko Lehtinen","Perttu Hämäläinen","James F. O'Brien","Xue Bin Peng"],"pdf_url":"","comment":"13 pages, 15 figures. Accepted to Eurographics 2026. Project page: https://robo-saber.github.io/"},{"id":"http://arxiv.org/abs/2507.08831v4","updated":"2026-02-20T16:14:13Z","published":"2025-07-05T18:04:35Z","title":"View Invariant Learning for Vision-Language Navigation in Continuous Environments","summary":"Vision-Language Navigation in Continuous Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is a key research problem in embodied AI. However, most existing approaches are sensitive to viewpoint changes, i.e. variations in camera height and viewing angle. Here we introduce a more general scenario, V$^2$-VLNCE (VLNCE with Varied Viewpoints) and propose a view-invariant post-training framework, called VIL (View Invariant Learning), that makes existing navigation policies more robust to changes in camera viewpoint. VIL employs a contrastive learning framework to learn sparse and view-invariant features. We also introduce a teacher-student framework for the Waypoint Predictor Module, a standard part of VLNCE baselines, where a view-dependent teacher model distills knowledge into a view-invariant student model. We employ an end-to-end training paradigm to jointly optimize these components. Empirical results show that our method outperforms state-of-the-art approaches on V$^2$-VLNCE by 8-15\\% measured on Success Rate for two standard benchmark datasets R2R-CE and RxR-CE. Evaluation of VIL in standard VLNCE settings shows that despite being trained for varied viewpoints, VIL often still improves performance. On the harder RxR-CE dataset, our method also achieved state-of-the-art performance across all metrics. This suggests that adding VIL does not diminish the standard viewpoint performance and can serve as a plug-and-play post-training method. We further evaluate VIL for simulated camera placements derived from real robot configurations (e.g. Stretch RE-1, LoCoBot), showing consistent improvements of performance. Finally, we present a proof-of-concept real-robot evaluation in two physical environments using a panoramic RGB sensor combined with LiDAR. The code is available at https://github.com/realjoshqsun/V2-VLNCE.","authors":["Josh Qixuan Sun","Huaiyuan Weng","Xiaoying Xing","Chul Min Yeum","Mark Crowley"],"pdf_url":"","comment":"This paper is accepted to RA-L 2026"},{"id":"http://arxiv.org/abs/2602.18313v1","updated":"2026-02-20T16:11:42Z","published":"2026-02-20T16:11:42Z","title":"Clapeyron Neural Networks for Single-Species Vapor-Liquid Equilibria","summary":"Machine learning (ML) approaches have shown promising results for predicting molecular properties relevant for chemical process design. However, they are often limited by scarce experimental property data and lack thermodynamic consistency. As such, thermodynamics-informed ML, i.e., incorporating thermodynamic relations into the loss function as regularization term for training, has been proposed. We herein transfer the concept of thermodynamics-informed graph neural networks (GNNs) from the Gibbs-Duhem to the Clapeyron equation, predicting several pure component properties in a multi-task manner, namely: vapor pressure, liquid molar volume, vapor molar volume and enthalpy of vaporization. We find improved prediction accuracy of the Clapeyron-GNN compared to the single-task learning setting, and improved approximation of the Clapeyron equation compared to the purely data-driven multi-task learning setting. In fact, we observe the largest improvement in prediction accuracy for the properties with the lowest availability of data, making our model promising for practical application in data scarce scenarios of chemical engineering practice.","authors":["Jan Pavšek","Alexander Mitsos","Elvis J. Sim","Jan G. Rittig"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18308v1","updated":"2026-02-20T16:06:01Z","published":"2026-02-20T16:06:01Z","title":"JPmHC Dynamical Isometry via Orthogonal Hyper-Connections","summary":"Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.","authors":["Biswa Sengupta","Jinhua Wang","Leo Brunswic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18307v1","updated":"2026-02-20T16:05:06Z","published":"2026-02-20T16:05:06Z","title":"VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean","summary":"Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.","authors":["Yutong Xin","Qiaochu Chen","Greg Durrett","Işil Dillig"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/1803.09319v2","updated":"2026-02-20T15:59:36Z","published":"2018-03-25T19:33:04Z","title":"SUNLayer: Stable denoising with generative networks","summary":"Deep neural networks are often used to implement powerful generative models for real-world data. Notable applications include image denoising, as well as other classical inverse problems like compressed sensing and super-resolution. To provide a rigorous but simplified analysis of generative models, in this work, we introduce an elegant theoretical framework based on spherical harmonics, namely \\textbf{SUNLayer}. Our theoretical framework identifies explicit conditions on activation functions that guarantee denoising under local optimization. Numerical experiments examine the theoretical properties on commonly used activation functions and demonstrate their stable denoising performance.","authors":["Ruhui Jin","Dustin G. Mixon","Soledad Villar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18301v1","updated":"2026-02-20T15:54:10Z","published":"2026-02-20T15:54:10Z","title":"On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction","summary":"Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for \"imposing\" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.","authors":["Ivan Bondarenko","Egor Palkin","Fedor Tikunov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18297v1","updated":"2026-02-20T15:50:30Z","published":"2026-02-20T15:50:30Z","title":"Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory","summary":"Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.","authors":["Usman Anwar","Tim Bakker","Dana Kianfar","Cristina Pinneri","Christos Louizos"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2502.00835v3","updated":"2026-02-20T15:50:11Z","published":"2025-02-02T16:16:53Z","title":"CAIMAN: Causal Action Influence Detection for Sample-efficient Loco-manipulation","summary":"Enabling legged robots to perform non-prehensile loco-manipulation is crucial for enhancing their versatility. Learning behaviors such as whole-body object pushing often requires sophisticated planning strategies or extensive task-specific reward shaping, especially in unstructured environments. In this work, we present CAIMAN, a practical reinforcement learning framework that encourages the agent to gain control over other entities in the environment. CAIMAN leverages causal action influence as an intrinsic motivation objective, allowing legged robots to efficiently acquire object pushing skills even under sparse task rewards. We employ a hierarchical control strategy, combining a low-level locomotion module with a high-level policy that generates task-relevant velocity commands and is trained to maximize the intrinsic reward. To estimate causal action influence, we learn the dynamics of the environment by integrating a kinematic prior with data collected during training. We empirically demonstrate CAIMAN's superior sample efficiency and adaptability to diverse scenarios in simulation, as well as its successful transfer to real-world systems without further fine-tuning. A video demo is available at https://www.youtube.com/watch?v=dNyvT04Cqaw.","authors":["Yuanchen Yuan","Jin Cheng","Núria Armengol Urpí","Stelian Coros"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.07110v2","updated":"2026-02-20T15:40:16Z","published":"2024-08-13T13:09:28Z","title":"Physics-informed graph neural networks for flow field estimation in carotid arteries","summary":"Hemodynamic quantities are valuable biomedical risk factors for cardiovascular pathology such as atherosclerosis. Non-invasive, in-vivo measurement of these quantities can only be performed using a select number of modalities that are not widely available, such as 4D flow magnetic resonance imaging (MRI). In this work, we create a surrogate model for hemodynamic flow field estimation, powered by machine learning. We train graph neural networks that include priors about the underlying symmetries and physics, limiting the amount of data required for training. This allows us to train the model using moderately-sized, in-vivo 4D flow MRI datasets, instead of large in-silico datasets obtained by computational fluid dynamics (CFD), as is the current standard. We create an efficient, equivariant neural network by combining the popular PointNet++ architecture with group-steerable layers. To incorporate the physics-informed priors, we derive an efficient discretisation scheme for the involved differential operators. We perform extensive experiments in carotid arteries and show that our model can accurately estimate low-noise hemodynamic flow fields in the carotid artery. Moreover, we show how the learned relation between geometry and hemodynamic quantities transfers to 3D vascular models obtained using a different imaging modality than the training data. This shows that physics-informed graph neural networks can be trained using 4D flow MRI data to estimate blood flow in unseen carotid artery geometries.","authors":["Julian Suk","Dieuwertje Alblas","Barbara A. Hutten","Albert Wiegman","Christoph Brune","Pim van Ooij","Jelmer M. Wolterink"],"pdf_url":"","comment":"Published in \"Medical Image Analysis\""},{"id":"http://arxiv.org/abs/2506.05647v4","updated":"2026-02-20T15:38:19Z","published":"2025-06-06T00:32:04Z","title":"Learning to Weight Parameters for Training Data Attribution","summary":"We study gradient-based data attribution, aiming to identify which training examples most influence a given output. Existing methods for this task either treat network parameters uniformly or rely on implicit weighting derived from Hessian approximations, which do not fully model functional heterogeneity of network parameters. To address this, we propose a method to explicitly learn parameter importance weights directly from data, without requiring annotated labels. Our approach improves attribution accuracy across diverse tasks, including image classification, language modeling, and diffusion, and enables fine-grained attribution for concepts like subject and style.","authors":["Shuangqi Li","Hieu Le","Jingyi Xu","Mathieu Salzmann"],"pdf_url":"","comment":"31 pages"},{"id":"http://arxiv.org/abs/2602.18292v1","updated":"2026-02-20T15:38:16Z","published":"2026-02-20T15:38:16Z","title":"Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers","summary":"Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.","authors":["Xiaotong Ji","Rasul Tutunov","Matthieu Zimmer","Haitham Bou-Ammar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.03875v3","updated":"2026-02-20T15:34:48Z","published":"2026-02-01T18:48:31Z","title":"Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra","summary":"We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction. We train the model to predict a 128-bit binned spectrum code from a graph-based structure encoding, while the remaining latent dimensions capture residual variability. At inference time, we invert the same trained network to generate structure candidates from a spectrum code, which explicitly represents the one-to-many nature of spectrum-to-structure inference. On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra. These results demonstrate that invertible architectures can unify spectrum prediction and uncertainty-aware candidate generation within one end-to-end model.","authors":["Stefan Kuhn","Vandana Dwarka","Przemyslaw Karol Grenda","Eero Vainikko"],"pdf_url":"","comment":"10 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2510.13887v4","updated":"2026-02-20T15:30:47Z","published":"2025-10-14T02:58:10Z","title":"Incomplete Multi-view Clustering via Hierarchical Semantic Alignment and Cooperative Completion","summary":"Incomplete multi-view data, where certain views are entirely missing for some samples, poses significant challenges for traditional multi-view clustering methods. Existing deep incomplete multi-view clustering approaches often rely on static fusion strategies or two-stage pipelines, leading to suboptimal fusion results and error propagation issues. To address these limitations, this paper proposes a novel incomplete multi-view clustering framework based on Hierarchical Semantic Alignment and Cooperative Completion (HSACC). HSACC achieves robust cross-view fusion through a dual-level semantic space design. In the low-level semantic space, consistency alignment is ensured by maximizing mutual information across views. In the high-level semantic space, adaptive view weights are dynamically assigned based on the distributional affinity between individual views and an initial fused representation, followed by weighted fusion to generate a unified global representation. Additionally, HSACC implicitly recovers missing views by projecting aligned latent representations into high-dimensional semantic spaces and jointly optimizes reconstruction and clustering objectives, enabling cooperative learning of completion and clustering. Experimental results demonstrate that HSACC significantly outperforms state-of-the-art methods on five benchmark datasets. Ablation studies validate the effectiveness of the hierarchical alignment and dynamic weighting mechanisms, while parameter analysis confirms the model's robustness to hyperparameter variations. The code is available at https://github.com/XiaojianDing/2025-NeurIPS-HSACC.","authors":["Xiaojian Ding","Lin Zhao","Xian Li","Xiaoying Zhu"],"pdf_url":"","comment":"13 pages, conference paper. Accepted to the Thirty-ninth Conference on Neural Information Processing Systems (NeurIPS 2025)"},{"id":"http://arxiv.org/abs/2504.02922v4","updated":"2026-02-20T15:27:22Z","published":"2025-04-03T17:50:24Z","title":"Overcoming Sparsity Artifacts in Crosscoders to Interpret Chat-Tuning","summary":"Model diffing is the study of how fine-tuning changes a model's representations and internal algorithms. Many behaviors of interest are introduced during fine-tuning, and model diffing offers a promising lens to interpret such behaviors. Crosscoders are a recent model diffing method that learns a shared dictionary of interpretable concepts represented as latent directions in both the base and fine-tuned models, allowing us to track how concepts shift or emerge during fine-tuning. Notably, prior work has observed concepts with no direction in the base model, and it was hypothesized that these model-specific latents were concepts introduced during fine-tuning. However, we identify two issues which stem from the crosscoders L1 training loss that can misattribute concepts as unique to the fine-tuned model, when they really exist in both models. We develop Latent Scaling to flag these issues by more accurately measuring each latent's presence across models. In experiments comparing Gemma 2 2B base and chat models, we observe that the standard crosscoder suffers heavily from these issues. Building on these insights, we train a crosscoder with BatchTopK loss and show that it substantially mitigates these issues, finding more genuinely chat-specific and highly interpretable concepts. We recommend practitioners adopt similar techniques. Using the BatchTopK crosscoder, we successfully identify a set of chat-specific latents that are both interpretable and causally effective, representing concepts such as $\\textit{false information}$ and $\\textit{personal question}$, along with multiple refusal-related latents that show nuanced preferences for different refusal triggers. Overall, our work advances best practices for the crosscoder-based methodology for model diffing and demonstrates that it can provide concrete insights into how chat-tuning modifies model behavior.","authors":["Julian Minder","Clément Dumas","Caden Juang","Bilal Chugtai","Neel Nanda"],"pdf_url":"","comment":"51 pages, 33 figures, Accepted at 39th Conference on Neural Information Processing Systems (NeurIPS 2025)"},{"id":"http://arxiv.org/abs/2509.12483v3","updated":"2026-02-20T15:20:03Z","published":"2025-09-15T22:08:20Z","title":"Comparative Analysis of Wave Scattering Numerical Modeling Using the Boundary Element Method and Physics-Informed Neural Networks","summary":"This study compares the Boundary Element Method (BEM) and Physics-Informed Neural Networks (PINNs) for solving the two-dimensional Helmholtz equation in wave scattering problems. The objective is to evaluate the performance of both methods under the same conditions. We solve the Helmholtz equation using BEM and PINNs for the same scattering problem. PINNs are trained by minimizing the residual of the governing equations and boundary conditions with their configuration determined through hyperparameter optimization, while BEM is applied using boundary discretization. Both methods are evaluated in terms of solution accuracy and computation time. We conducted numerical experiments by varying the number of boundary integration points for the BEM and the number of hidden layers and neurons per layer for the PINNs. We performed a hyperparameter tuning to identify an adequate PINN configuration for this problem as a network with 3 hidden layers and 25 neurons per layer, using a learning rate of $10^{-2}$ and a sine activation function. At comparable levels of accuracy, the assembly and solution of the BEM system required a computational time on the order of $10^{-2}$~s, whereas the training time of the PINN was on the order of $10^{2}$~s, corresponding to a difference of approximately four orders of magnitude. However, once trained, the PINN achieved evaluation times on the order of $10^{-2}$~s, which is about two orders of magnitude faster than the evaluation of the BEM solution at interior points. This work establishes a procedure for comparing BEM and PINNs. It also presents a direct comparison between the two methods for the scattering problem. The analysis provides quantitative data on their performance, supporting their use in future research on wave propagation problems and outlining challenges and directions for further investigation.","authors":["Oscar Rincón-Cardeno","Gregorio Pérez Bernal","Silvana Montoya Noguera","Nicolás Guarín-Zapata"],"pdf_url":"","comment":"19 pages, 7 figures"},{"id":"http://arxiv.org/abs/2510.19675v2","updated":"2026-02-20T15:06:57Z","published":"2025-10-22T15:21:05Z","title":"Study of Training Dynamics for Memory-Constrained Fine-Tuning","summary":"Memory-efficient training of deep neural networks has become increasingly important as models grow larger while deployment environments impose strict resource constraints. We propose TraDy, a novel transfer learning scheme leveraging two key insights: layer importance for updates is architecture-dependent and determinable a priori, while dynamic stochastic channel selection provides superior gradient approximation compared to static approaches. We introduce a dynamic channel selection approach that stochastically resamples channels between epochs within preselected layers. Extensive experiments demonstrate TraDy achieves state-of-the-art performance across various downstream tasks and architectures while maintaining strict memory constraints, achieving up to 99% activation sparsity, 95% weight derivative sparsity, and 97% reduction in FLOPs for weight derivative computation.","authors":["Aël Quélennec","Nour Hezbri","Pavlo Mozharovskyi","Van-Tam Nguyen","Enzo Tartaglione"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18277v1","updated":"2026-02-20T15:02:42Z","published":"2026-02-20T15:02:42Z","title":"PRISM: Parallel Reward Integration with Symmetry for MORL","summary":"This work studies heterogeneous Multi-Objective Reinforcement Learning (MORL), where objectives can differ sharply in temporal frequency. Such heterogeneity allows dense objectives to dominate learning, while sparse long-horizon rewards receive weak credit assignment, leading to poor sample efficiency. We propose a Parallel Reward Integration with Symmetry (PRISM) algorithm that enforces reflectional symmetry as an inductive bias in aligning reward channels. PRISM introduces ReSymNet, a theory-motivated model that reconciles temporal-frequency mismatches across objectives, using residual blocks to learn a scaled opportunity value that accelerates exploration while preserving the optimal policy. We also propose SymReg, a reflectional equivariance regulariser that enforces agent mirroring and constrains policy search to a reflection-equivariant subspace. This restriction provably reduces hypothesis complexity and improves generalisation. Across MuJoCo benchmarks, PRISM consistently outperforms both a sparse-reward baseline and an oracle trained with full dense rewards, improving Pareto coverage and distributional balance: it achieves hypervolume gains exceeding 100\\% over the baseline and up to 32\\% over the oracle. The code is at \\href{https://github.com/EVIEHub/PRISM}{https://github.com/EVIEHub/PRISM}.","authors":["Finn van der Knaap","Kejiang Qian","Zheng Xu","Fengxiang He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18266v1","updated":"2026-02-20T14:49:53Z","published":"2026-02-20T14:49:53Z","title":"A Probabilistic Framework for LLM-Based Model Discovery","summary":"Automated methods for discovering mechanistic simulator models from observational data offer a promising path toward accelerating scientific progress. Such methods often take the form of agentic-style iterative workflows that repeatedly propose and revise candidate models by imitating human discovery processes. However, existing LLM-based approaches typically implement such workflows via hand-crafted heuristic procedures, without an explicit probabilistic formulation. We recast model discovery as probabilistic inference, i.e., as sampling from an unknown distribution over mechanistic models capable of explaining the data. This perspective provides a unified way to reason about model proposal, refinement, and selection within a single inference framework. As a concrete instantiation of this view, we introduce ModelSMC, an algorithm based on Sequential Monte Carlo sampling. ModelSMC represents candidate models as particles which are iteratively proposed and refined by an LLM, and weighted using likelihood-based criteria. Experiments on real-world scientific systems illustrate that this formulation discovers models with interpretable mechanisms and improves posterior predictive checks. More broadly, this perspective provides a probabilistic lens for understanding and developing LLM-based approaches to model discovery.","authors":["Stefan Wahl","Raphaela Schenk","Ali Farnoud","Jakob H. Macke","Daniel Gedon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18262v1","updated":"2026-02-20T14:45:27Z","published":"2026-02-20T14:45:27Z","title":"Simplifying Outcomes of Language Model Component Analyses with ELIA","summary":"While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.","authors":["Aaron Louis Eidt","Nils Feldhus"],"pdf_url":"","comment":"EACL 2026 System Demonstrations. GitHub: https://github.com/aaron0eidt/ELIA"},{"id":"http://arxiv.org/abs/2602.18253v1","updated":"2026-02-20T14:39:50Z","published":"2026-02-20T14:39:50Z","title":"MEG-to-MEG Transfer Learning and Cross-Task Speech/Silence Detection with Limited Data","summary":"Data-efficient neural decoding is a central challenge for speech brain-computer interfaces. We present the first demonstration of transfer learning and cross-task decoding for MEG-based speech models spanning perception and production. We pre-train a Conformer-based model on 50 hours of single-subject listening data and fine-tune on just 5 minutes per subject across 18 participants. Transfer learning yields consistent improvements, with in-task accuracy gains of 1-4% and larger cross-task gains of up to 5-6%. Not only does pre-training improve performance within each task, but it also enables reliable cross-task decoding between perception and production. Critically, models trained on speech production decode passive listening above chance, confirming that learned representations reflect shared neural processes rather than task-specific motor activity.","authors":["Xabier de Zuazo","Vincenzo Verbeni","Eva Navas","Ibon Saratxaga","Mathieu Bourguignon","Nicola Molinaro"],"pdf_url":"","comment":"6 pages, 3 figures, 3 tables, submitted to Interspeech 2026"},{"id":"http://arxiv.org/abs/2509.12253v2","updated":"2026-02-20T14:36:11Z","published":"2025-09-12T12:18:00Z","title":"Physics-Informed Neural Networks vs. Physics Models for Non-Invasive Glucose Monitoring: A Comparative Study Under Noise-Stressed Synthetic Conditions","summary":"Non-invasive glucose monitoring outside controlled settings is dominated by low signal-to-noise ratio (SNR): hardware drift, environmental variation, and physiology suppress the glucose signature in NIR signals. We present a noise-stressed NIR simulator that injects 12-bit ADC quantisation, LED drift, photodiode dark noise, temperature/humidity variation, contact-pressure noise, Fitzpatrick I-VI melanin, and glucose variability to create a low-correlation regime (rho_glucose-NIR = 0.21). Using this platform, we benchmark six methods: Enhanced Beer-Lambert (physics-engineered ridge regression), Original PINN, Optimised PINN, RTE-inspired PINN, Selective RTE PINN, and a shallow DNN. The physics-engineered Beer Lambert model achieves the lowest error (13.6 mg/dL RMSE) with only 56 parameters and 0.01 ms inference, outperforming deeper PINNs and the SDNN baseline under low-SNR conditions. The study reframes the task as noise suppression under weak signal and shows that carefully engineered physics features can outperform higher-capacity models in this regime.","authors":["Riyaadh Gani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18250v1","updated":"2026-02-20T14:35:53Z","published":"2026-02-20T14:35:53Z","title":"Variational Distributional Neuron","summary":"We propose a proof of concept for a variational distributional neuron: a compute unit formulated as a VAE brick, explicitly carrying a prior, an amortized posterior and a local ELBO. The unit is no longer a deterministic scalar but a distribution: computing is no longer about propagating values, but about contracting a continuous space of possibilities under constraints. Each neuron parameterizes a posterior, propagates a reparameterized sample and is regularized by the KL term of a local ELBO - hence, the activation is distributional. This \"contraction\" becomes testable through local constraints and can be monitored via internal measures. The amount of contextual information carried by the unit, as well as the temporal persistence of this information, are locally tuned by distinct constraints. This proposal addresses a structural tension: in sequential generation, causality is predominantly organized in the symbolic space and, even when latents exist, they often remain auxiliary, while the effective dynamics are carried by a largely deterministic decoder. In parallel, probabilistic latent models capture factors of variation and uncertainty, but that uncertainty typically remains borne by global or parametric mechanisms, while units continue to propagate scalars - hence the pivot question: if uncertainty is intrinsic to computation, why does the compute unit not carry it explicitly? We therefore draw two axes: (i) the composition of probabilistic constraints, which must be made stable, interpretable and controllable; and (ii) granularity: if inference is a negotiation of distributions under constraints, should the primitive unit remain deterministic or become distributional? We analyze \"collapse\" modes and the conditions for a \"living neuron\", then extend the contribution over time via autoregressive priors over the latent, per unit.","authors":["Yves Ruffenach"],"pdf_url":"","comment":"29 pages, 7 figures. Code available at GitHub (link in paper)"},{"id":"http://arxiv.org/abs/2512.04388v3","updated":"2026-02-20T14:32:50Z","published":"2025-12-04T02:23:13Z","title":"Learning to Orchestrate Agents in Natural Language with the Conductor","summary":"Powerful large language models (LLMs) from different providers have been expensively trained and finetuned to specialize across varying domains. In this work, we introduce a new kind of Conductor model trained with reinforcement learning to automatically discover powerful coordination strategies among LLMs. Our Conductor learns not only to design targeted communication topologies for effective agent-to-agent collaboration, but also to prompt engineer focused instructions to the LLMs to maximally leverage their individual capabilities. We show that, by learning optimal coordination strategies over pools of powerful worker LLMs, a 7B Conductor achieves significant performance gains beyond any individual worker, attaining state-of-the-art results in challenging reasoning benchmarks, such as LiveCodeBench and GPQA. By training with randomized agent pools, our conductor effectively adapts to arbitrary sets of open- and closed-source agents, meeting any user requirements. Furthermore, allowing the Conductor to select itself as a worker gives rise to recursive topologies, elevating performance with a new form of dynamic test-time scaling through online iterative adaptation. More broadly, ours is among the early work demonstrating language model coordination can be unlocked through RL, where powerful coordination strategies emerge naturally in LLMs through pure end-to-end reward maximization.","authors":["Stefan Nielsen","Edoardo Cetin","Peter Schwendeman","Qi Sun","Jinglue Xu","Yujin Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18248v1","updated":"2026-02-20T14:31:08Z","published":"2026-02-20T14:31:08Z","title":"Neural-HSS: Hierarchical Semi-Separable Neural PDE Solver","summary":"Deep learning-based methods have shown remarkable effectiveness in solving PDEs, largely due to their ability to enable fast simulations once trained. However, despite the availability of high-performance computing infrastructure, many critical applications remain constrained by the substantial computational costs associated with generating large-scale, high-quality datasets and training models. In this work, inspired by studies on the structure of Green's functions for elliptic PDEs, we introduce Neural-HSS, a parameter-efficient architecture built upon the Hierarchical Semi-Separable (HSS) matrix structure that is provably data-efficient for a broad class of PDEs. We theoretically analyze the proposed architecture, proving that it satisfies exactness properties even in very low-data regimes. We also investigate its connections with other architectural primitives, such as the Fourier neural operator layer and convolutional layers. We experimentally validate the data efficiency of Neural-HSS on the three-dimensional Poisson equation over a grid of two million points, demonstrating its superior ability to learn from data generated by elliptic PDEs in the low-data regime while outperforming baseline methods. Finally, we demonstrate its capability to learn from data arising from a broad class of PDEs in diverse domains, including electromagnetism, fluid dynamics, and biology.","authors":["Pietro Sittoni","Emanuele Zangrando","Angelo A. Casulli","Nicola Guglielmi","Francesco Tudisco"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18230v1","updated":"2026-02-20T14:11:31Z","published":"2026-02-20T14:11:31Z","title":"[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games","summary":"Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability and generalizability. We replicate the original experiments on additional models, and introduce additional metrics to verify negotiation quality and evenness of evaluation. Our findings reveal that while the benchmark is indeed complex, model comparison is ambiguous, raising questions about its objectivity. Furthermore, we identify limitations in the experimental setup, particularly in information leakage detection and thoroughness of the ablation study. By examining and analyzing the behavior of a wider range of models on an extended version of the benchmark, we reveal insights that provide additional context to potential users. Our results highlight the importance of context in model-comparative evaluations.","authors":["Jorge Carrasco Pollo","Ioannis Kapetangeorgis","Joshua Rosenthal","John Hua Yao"],"pdf_url":"","comment":"Accepted for publication at Transactions on Machine Learning Research (TMLR) and MLRC Journal Track, 2025. Code available at: https://github.com/joshrosie/FACT29"},{"id":"http://arxiv.org/abs/2602.18227v1","updated":"2026-02-20T14:07:51Z","published":"2026-02-20T14:07:51Z","title":"Parameter-Efficient Domain Adaptation of Physics-Informed Self-Attention based GNNs for AC Power Flow Prediction","summary":"Accurate AC-PF prediction under domain shift is critical when models trained on medium-voltage (MV) grids are deployed on high-voltage (HV) networks. Existing physics-informed graph neural solvers typically rely on full fine-tuning for cross-regime transfer, incurring high retraining cost and offering limited control over the stability-plasticity trade-off between target-domain adaptation and source-domain retention. We study parameter-efficient domain adaptation for physics-informed self-attention based GNN, encouraging Kirchhoff-consistent behavior via a physics-based loss while restricting adaptation to low-rank updates. Specifically, we apply LoRA to attention projections with selective unfreezing of the prediction head to regulate adaptation capacity. This design yields a controllable efficiency-accuracy trade-off for physics-constrained inverse estimation under voltage-regime shift. Across multiple grid topologies, the proposed LoRA+PHead adaptation recovers near-full fine-tuning accuracy with a target-domain RMSE gap of $2.6\\times10^{-4}$ while reducing the number of trainable parameters by 85.46%. The physics-based residual remains comparable to full fine-tuning; however, relative to Full FT, LoRA+PHead reduces MV source retention by 4.7 percentage points (17.9% vs. 22.6%) under domain shift, while still enabling parameter-efficient and physically consistent AC-PF estimation.","authors":["Redwanul Karim","Changhun Kim","Timon Conrad","Nora Gourmelon","Julian Oelhaf","David Riebesel","Tomás Arias-Vergara","Andreas Maier","Johann Jäger","Siming Bayer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18224v1","updated":"2026-02-20T14:04:27Z","published":"2026-02-20T14:04:27Z","title":"SimVLA: A Simple VLA Baseline for Robotic Manipulation","summary":"Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic manipulation, leveraging large-scale pre-training to achieve strong performance. The field has rapidly evolved with additional spatial priors and diverse architectural innovations. However, these advancements are often accompanied by varying training recipes and implementation details, which can make it challenging to disentangle the precise source of empirical gains. In this work, we introduce SimVLA, a streamlined baseline designed to establish a transparent reference point for VLA research. By strictly decoupling perception from control, using a standard vision-language backbone and a lightweight action head, and standardizing critical training dynamics, we demonstrate that a minimal design can achieve state-of-the-art performance. Despite having only 0.5B parameters, SimVLA outperforms multi-billion-parameter models on standard simulation benchmarks without robot pretraining. SimVLA also reaches on-par real-robot performance compared to pi0.5. Our results establish SimVLA as a robust, reproducible baseline that enables clear attribution of empirical gains to future architectural innovations. Website: https://frontierrobo.github.io/SimVLA","authors":["Yuankai Luo","Woping Chen","Tong Liang","Baiqiao Wang","Zhenguo Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.10855v3","updated":"2026-02-20T13:59:14Z","published":"2025-11-13T23:39:18Z","title":"ExPairT-LLM: Exact Learning for LLM Code Selection by Pairwise Queries","summary":"Despite recent advances in LLMs, the task of code generation is still challenging. To cope, code selection algorithms select the best program from multiple programs generated by an LLM. However, existing algorithms can fail to identify the correct program, either because they can misidentify nonequivalent programs or because they rely on an LLM and assume it always correctly determines the output for every input. We present ExPairT-LLM, an exact learning algorithm for code selection that selects a program by posing to an LLM oracle two new types of queries: pairwise membership and pairwise equivalence. These queries are simpler for LLMs and enable ExPairT-LLM to identify the correct program through a tournament, which is robust to some LLM mistakes. We evaluate ExPairT-LLM on four popular code datasets. Its pass@1 (success rate) outperforms the state-of-the-art code selection algorithm on average by +13.0% and up to +27.1%. It also improves the pass@1 of LLMs performing complex reasoning by +24.0%.","authors":["Tom Yuviler","Dana Drachsler-Cohen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.10877v2","updated":"2026-02-20T13:58:35Z","published":"2025-12-11T18:05:55Z","title":"Guided Transfer Learning for Discrete Diffusion Models","summary":"Discrete diffusion models (DMs) have achieved strong performance in language and other discrete domains, offering a compelling alternative to autoregressive modeling. Yet this performance typically depends on large training datasets, challenging the performance of DMs in small-data regimes -- common under real-world constraints. Aimed at this challenge, recent work in continuous DMs suggests that transfer learning via classifier ratio-based guidance can adapt a pretrained DM to a related target distribution, often outperforming alternatives such as full-weight fine-tuning on the target data. By contrast, transfer learning for discrete DMs remains unexplored. We address this gap by exploring practical analogues of ratio-based transfer learning for discrete DMs. Our theoretical analysis shows that a direct extension of existing ratio-based guidance is computationally prohibitive, scaling with vocabulary size. To overcome this limitation, we introduce a scheduling mechanism that yields a practical algorithm, Guided Transfer Learning for discrete diffusion models (GTL). GTL enables sampling from a target distribution without modifying the pretrained denoiser and reduces the cost to linear scaling in vocabulary size, which in turn supports longer sequence generation. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling tasks, and provide a detailed empirical analysis of its behavior. The results highlight a clear trade-off: when target datasets are large, weight fine-tuning is often preferable, whereas GTL becomes increasingly effective as target data shrinks. Finally, we experimentally demonstrate a key failure mode of GTL: when the source and target distributions overlap poorly, the ratio-based classifier required for guidance becomes unreliable, limiting transfer performance.","authors":["Julian Kleutgens","Claudio Battiloro","Lingkai Kong","Benjamin Grewe","Francesca Dominici","Mauricio Tec"],"pdf_url":"","comment":"9 pages (main text) + appendix"},{"id":"http://arxiv.org/abs/2602.18216v1","updated":"2026-02-20T13:52:48Z","published":"2026-02-20T13:52:48Z","title":"Generative Model via Quantile Assignment","summary":"Deep Generative models (DGMs) play two key roles in modern machine learning: (i) producing new information (e.g., image synthesis) and (ii) reducing dimensionality. However, traditional architectures often rely on auxiliary networks such as encoders in Variational Autoencoders (VAEs) or discriminators in Generative Adversarial Networks (GANs), which introduce training instability, computational overhead, and risks like mode collapse. We present NeuroSQL, a new generative paradigm that eliminates the need for auxiliary networks by learning low-dimensional latent representations implicitly. NeuroSQL leverages an asymptotic approximation that expresses the latent variables as the solution to an optimal transportation problem. Specifically, NeuroSQL learns the latent variables by solving a linear assignment problem and then passes the latent information to a standalone generator. We benchmark its performance against GANs, VAEs, and a budget-matched diffusion baseline on four datasets: handwritten digits (MNIST), faces (CelebA), animal faces (AFHQ), and brain images (OASIS). Compared to VAEs, GANs, and diffusion models: (1) in terms of image quality, NeuroSQL achieves overall lower mean pixel distance between synthetic and authentic images and stronger perceptual/structural fidelity; (2) computationally, NeuroSQL requires the least training time; and (3) practically, NeuroSQL provides an effective solution for generating synthetic data with limited training samples. By embracing quantile assignment rather than an encoder, NeuroSQL provides a fast, stable, and robust way to generate synthetic data with minimal information loss.","authors":["Georgi Hrusanov","Oliver Y. Chén","Julien S. Bodelet"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18213v1","updated":"2026-02-20T13:51:29Z","published":"2026-02-20T13:51:29Z","title":"Machine-learning force-field models for dynamical simulations of metallic magnets","summary":"We review recent advances in machine learning (ML) force-field methods for Landau-Lifshitz-Gilbert (LLG) simulations of itinerant electron magnets, focusing on scalability and transferability. Built on the principle of locality, a deep neural network model is developed to efficiently and accurately predict the electron-mediated forces governing spin dynamics. Symmetry-aware descriptors constructed through a group-theoretical approach ensure rigorous incorporation of both lattice and spin-rotation symmetries. The framework is demonstrated using the prototypical s-d exchange model widely employed in spintronics. ML-enabled large-scale simulations reveal novel nonequilibrium phenomena, including anomalous coarsening of tetrahedral spin order on the triangular lattice and the freezing of phase separation dynamics in lightly hole-doped, strong-coupling square-lattice systems. These results establish ML force-field frameworks as scalable, accurate, and versatile tools for modeling nonequilibrium spin dynamics in itinerant magnets.","authors":["Gia-Wei Chern","Yunhao Fan","Sheng Zhang","Puhan Zhang"],"pdf_url":"","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2512.14873v2","updated":"2026-02-20T13:49:41Z","published":"2025-12-16T19:36:56Z","title":"How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal","summary":"Fourier Analysis Network (FAN) was recently proposed as a simple way to improve neural network performance by replacing part of Rectified Linear Unit (ReLU) activations with sine and cosine functions. Although several studies have reported small but consistent gains across tasks, the underlying mechanism behind these improvements has remained unclear. In this work, we show that only the sine activation contributes positively to performance, whereas the cosine activation tends to be detrimental. Our analysis reveals that the improvement is not a consequence of the sine function's periodic nature; instead, it stems from the function's local behavior near x = 0, where its non-zero derivative mitigates the vanishing-gradient problem. We further show that FAN primarily alleviates the dying-ReLU problem, in which a neuron consistently receives negative inputs, produces zero gradients, and stops learning. Although modern ReLU-like activations, such as Leaky ReLU, GELU, and Swish, reduce ReLU's zero-gradient region, they still contain input domains where gradients remain significantly diminished, contributing to slower optimization and hindering rapid convergence. FAN addresses this limitation by introducing a more stable gradient pathway. This analysis shifts the understanding of FAN's benefits from a spectral interpretation to a concrete analysis of training dynamics, leading to the development of the Dual-Activation Layer (DAL), a more efficient convergence accelerator. We evaluate DAL on three tasks: classification of noisy sinusoidal signals versus pure noise, MNIST digit classification, and Electrocardiogram (ECG)-based biometric recognition. In all cases, DAL models converge faster and achieve equal or higher validation accuracy compared to models with conventional activations.","authors":["Sam Jeong","Hae Yong Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.03725v4","updated":"2026-02-20T13:33:20Z","published":"2025-06-04T08:58:33Z","title":"Sign-SGD via Parameter-Free Optimization","summary":"Large language models have achieved major advances across domains, yet training them remains extremely resource-intensive. We revisit Sign-SGD, which serves both as a memory-efficient optimizer for single-node training and as a gradient compression mechanism for distributed learning. This paper addresses a central limitation: the effective stepsize cannot be determined a priori because it relies on unknown, problem-specific quantities. We present a parameter-free Sign-SGD that removes manual stepsize selection. We analyze the deterministic single-node case, and extend the method to stochastic single-node training and multi-node settings. We also incorporate the momentum technique into our algorithms and propose a memory-efficient variant that stores only gradient signs instead of full gradients. We evaluate our methods on pre-training LLaMA models (130M and 350M) and fine-tuning a Swin Transformer (28M). Across considered tasks, the proposed methods match the performance of tuned Sign-SGD and AdamW (grid-searched stepsizes with a cosine schedule), while avoiding tuning overhead. Employing parameter-free training yields approximately $1.5\\times$ end-to-end speedup compared to runs with grid-searched stepsizes.","authors":["Daniil Medyakov","Sergey Stanko","Gleb Molodtsov","Philip Zmushko","Grigoriy Evseev","Egor Petrov","Aleksandr Beznosikov"],"pdf_url":"","comment":"60 pages, 7 figures, 11 tables"},{"id":"http://arxiv.org/abs/2602.18201v1","updated":"2026-02-20T13:25:28Z","published":"2026-02-20T13:25:28Z","title":"SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps","summary":"Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \\textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime","authors":["Joseph Bingham","Netanel Arussy","Dvir Aran"],"pdf_url":"","comment":"10 pages, 2 figures, preprint"},{"id":"http://arxiv.org/abs/2602.14498v2","updated":"2026-02-20T13:24:13Z","published":"2026-02-16T06:27:51Z","title":"Uncertainty-Aware Vision-Language Segmentation for Medical Imaging","summary":"We introduce a novel uncertainty-aware multimodal segmentation framework that leverages both radiological images and associated clinical text for precise medical diagnosis. We propose a Modality Decoding Attention Block (MoDAB) with a lightweight State Space Mixer (SSMix) to enable efficient cross-modal fusion and long-range dependency modelling. To guide learning under ambiguity, we propose the Spectral-Entropic Uncertainty (SEU) Loss, which jointly captures spatial overlap, spectral consistency, and predictive uncertainty in a unified objective. In complex clinical circumstances with poor image quality, this formulation improves model reliability. Extensive experiments on various publicly available medical datasets, QATA-COVID19, MosMed++, and Kvasir-SEG, demonstrate that our method achieves superior segmentation performance while being significantly more computationally efficient than existing State-of-the-Art (SoTA) approaches. Our results highlight the importance of incorporating uncertainty modelling and structured modality alignment in vision-language medical segmentation tasks. Code: https://github.com/arya-domain/UA-VLS","authors":["Aryan Das","Tanishq Rachamalla","Koushik Biswas","Swalpa Kumar Roy","Vinay Kumar Verma"],"pdf_url":"","comment":"Accepted in WACV 2026"},{"id":"http://arxiv.org/abs/2503.07199v4","updated":"2026-02-20T13:19:03Z","published":"2025-03-10T11:32:30Z","title":"How Well Can Differential Privacy Be Audited in One Run?","summary":"Recent methods for auditing the privacy of machine learning algorithms have improved computational efficiency by simultaneously intervening on multiple training examples in a single training run. Steinke et al. (2024) prove that one-run auditing indeed lower bounds the true privacy parameter of the audited algorithm, and give impressive empirical results. Their work leaves open the question of how precisely one-run auditing can uncover the true privacy parameter of an algorithm, and how that precision depends on the audited algorithm. In this work, we characterize the maximum achievable efficacy of one-run auditing and show that the key barrier to its efficacy is interference between the observable effects of different data elements. We present new conceptual approaches to minimize this barrier, towards improving the performance of one-run auditing of real machine learning algorithms.","authors":["Amit Keinan","Moshe Shenfeld","Katrina Ligett"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.19605v4","updated":"2026-02-20T13:15:11Z","published":"2025-03-25T12:40:43Z","title":"Lean Formalization of Generalization Error Bound by Rademacher Complexity and Dudley's Entropy Integral","summary":"Understanding and certifying the generalization performance of machine learning algorithms -- i.e. obtaining theoretical estimates of the test error from a finite training sample -- is a central theme of statistical learning theory. Among the many complexity measures used to derive such guarantees, Rademacher complexity yields sharp, data-dependent bounds that apply well beyond classical $0$--$1$ classification. In this study, we formalize the generalization error bound by Rademacher complexity in Lean 4, building on measure-theoretic probability theory available in the Mathlib library. Our development provides a mechanically-checked pipeline from the definitions of empirical and expected Rademacher complexity, through a formal symmetrization argument and a bounded-differences analysis, to high-probability uniform deviation bounds via a formally proved McDiarmid inequality. A key technical contribution is a reusable mechanism for lifting results from countable hypothesis classes (where measurability of suprema is straightforward in Mathlib) to separable topological index sets via a reduction to a countable dense subset. As worked applications of the abstract theorem, we mechanize standard empirical Rademacher bounds for linear predictors under $\\ell_2$ and $\\ell_1$ regularization, and we also formalize a Dudley-type entropy integral bound based on covering numbers and a chaining construction.","authors":["Sho Sonoda","Kazumi Kasaura","Yuma Mizuno","Kei Tsukamoto","Naoto Onda"],"pdf_url":"","comment":"major updated: add L1-regularization and Dudley's entropy integral"},{"id":"http://arxiv.org/abs/2602.18196v1","updated":"2026-02-20T13:09:49Z","published":"2026-02-20T13:09:49Z","title":"RAT+: Train Dense, Infer Sparse -- Recurrence Augmented Attention for Dilated Inference","summary":"Structured dilated attention has an appealing inference-time efficiency knob: it reduces the FLOPs of the attention and the KV cache size by a factor of the dilation size D, while preserving long-range connectivity. However, we find a persistent failure mode of them -- sparsifying a pretrained attention model to a dilated pattern leads to severe accuracy degradation. We introduce RAT+, a dense-pretraining architecture that augments attention with full-sequence recurrence and active recurrence learning. A single RAT+ model is pretrained densely once, then flexibly switched at inference time to dilated attention (optionally with local windows) or hybrid layer/head compositions, requiring only a short 1B-token resolution adaptation rather than retraining separate sparse models. At 1.5B parameters trained on 100B tokens, RAT+ closely matches dense accuracy at 16 and drops by about 2-3 points at 64 on commonsense reasoning and LongBench tasks, respectively. Moreover, RAT+ outperforms attention when sparsifying to the top-k block attention. We further scale to 2.6B parameters and 200B tokens and observe the same trend.","authors":["Xiuying Wei","Caglar Gulcehre"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18195v1","updated":"2026-02-20T13:03:40Z","published":"2026-02-20T13:03:40Z","title":"LERD: Latent Event-Relational Dynamics for Neurodegenerative Classification","summary":"Alzheimer's disease (AD) alters brain electrophysiology and disrupts multichannel EEG dynamics, making accurate and clinically useful EEG-based diagnosis increasingly important for screening and disease monitoring. However, many existing approaches rely on black-box classifiers and do not explicitly model the underlying dynamics that generate observed signals. To address these limitations, we propose LERD, an end-to-end Bayesian electrophysiological neural dynamical system that infers latent neural events and their relational structure directly from multichannel EEG without event or interaction annotations. LERD combines a continuous-time event inference module with a stochastic event-generation process to capture flexible temporal patterns, while incorporating an electrophysiology-inspired dynamical prior to guide learning in a principled way. We further provide theoretical analysis that yields a tractable bound for training and stability guarantees for the inferred relational dynamics. Extensive experiments on synthetic benchmarks and two real-world AD EEG cohorts demonstrate that LERD consistently outperforms strong baselines and yields physiology-aligned latent summaries that help characterize group-level dynamical differences.","authors":["Hairong Chen","Yicheng Feng","Ziyu Jia","Samir Bhatt","Hengguan Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01916v2","updated":"2026-02-20T12:58:11Z","published":"2025-08-03T20:59:29Z","title":"Decomposing Representation Space into Interpretable Subspaces with Unsupervised Learning","summary":"Understanding internal representations of neural models is a core interest of mechanistic interpretability. Due to its large dimensionality, the representation space can encode various aspects about inputs. To what extent are different aspects organized and encoded in separate subspaces? Is it possible to find these ``natural'' subspaces in a purely unsupervised way? Somewhat surprisingly, we can indeed achieve this and find interpretable subspaces by a seemingly unrelated training objective. Our method, neighbor distance minimization (NDM), learns non-basis-aligned subspaces in an unsupervised manner. Qualitative analysis shows subspaces are interpretable in many cases, and encoded information in obtained subspaces tends to share the same abstract concept across different inputs, making such subspaces similar to ``variables'' used by the model. We also conduct quantitative experiments using known circuits in GPT-2; results show a strong connection between subspaces and circuit variables. We also provide evidence showing scalability to 2B models by finding separate subspaces mediating context and parametric knowledge routing. Viewed more broadly, our findings offer a new perspective on understanding model internals and building circuits.","authors":["Xinting Huang","Michael Hahn"],"pdf_url":"","comment":"Published as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.18186v1","updated":"2026-02-20T12:47:15Z","published":"2026-02-20T12:47:15Z","title":"Box Thirding: Anytime Best Arm Identification under Insufficient Sampling","summary":"We introduce Box Thirding (B3), a flexible and efficient algorithm for Best Arm Identification (BAI) under fixed-budget constraints. It is designed for both anytime BAI and scenarios with large N, where the number of arms is too large for exhaustive evaluation within a limited budget T. The algorithm employs an iterative ternary comparison: in each iteration, three arms are compared--the best-performing arm is explored further, the median is deferred for future comparisons, and the weakest is discarded. Even without prior knowledge of T, B3 achieves an epsilon-best arm misidentification probability comparable to Successive Halving (SH), which requires T as a predefined parameter, applied to a randomly selected subset of c0 arms that fit within the budget. Empirical results show that B3 outperforms existing methods under limited-budget constraints in terms of simple regret, as demonstrated on the New Yorker Cartoon Caption Contest dataset.","authors":["Seohwa Hwang","Junyong Park"],"pdf_url":"","comment":"29 pages, 5 figures"},{"id":"http://arxiv.org/abs/2408.03099v2","updated":"2026-02-20T12:46:41Z","published":"2024-08-06T11:04:07Z","title":"Topic Modeling with Fine-tuning LLMs and Bag of Sentences","summary":"Large language models (LLMs) are increasingly used for topic modeling, outperforming classical topic models such as LDA. Commonly, pre-trained LLM encoders such as BERT are used out-of-the-box despite the fact that fine-tuning is known to improve LLMs considerably. The challenge lies in obtaining a suitable labeled dataset for fine-tuning. In this paper, we build on the recent idea of using bags of sentences as the elementary unit for computing topics. Based on this idea, we derive an approach called FT-Topic to perform unsupervised fine-tuning, relying primarily on two steps for constructing a training dataset in an automatic fashion. First, a heuristic method identifies pairs of sentence groups that are assumed to belong either to the same topic or to different topics. Second, we remove sentence pairs that are likely labeled incorrectly. The resulting dataset is then used to fine-tune an encoder LLM, which can be leveraged by any topic modeling approach that uses embeddings. In this work, we demonstrate its effectiveness by deriving a novel state-of-the-art topic modeling method called SenClu. The method achieves fast inference through an expectation-maximization algorithm and hard assignments of sentence groups to a single topic, while allowing users to encode prior knowledge about the topic-document distribution. Code is available at https://github.com/JohnTailor/FT-Topic","authors":["Johannes Schneider"],"pdf_url":"","comment":"This is the submitted journal version of enhanced with the novel fine-tuning part of \"Efficient and Flexible Topic Modeling using Pretrained Embeddings and Bag of Sentences'' which appeared at the International Conference on Agents and Artificial Intelligence(ICAART) in 2024"},{"id":"http://arxiv.org/abs/2602.18182v1","updated":"2026-02-20T12:40:18Z","published":"2026-02-20T12:40:18Z","title":"Capabilities Ain't All You Need: Measuring Propensities in AI","summary":"AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an \"ideal band\". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.","authors":["Daniel Romero-Alvarado","Fernando Martínez-Plumed","Lorenzo Pacchiardi","Hugo Save","Siddhesh Milind Pawar","Behzad Mehrbakhsh","Pablo Antonio Moreno Casares","Ben Slater","Paolo Bova","Peter Romero","Zachary R. Tyler","Jonathan Prunty","Luning Sun","Jose Hernandez-Orallo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12664v2","updated":"2026-02-20T12:39:17Z","published":"2025-05-19T03:27:24Z","title":"Multi-View Wireless Sensing via Conditional Generative Learning: Framework and Model Design","summary":"In this paper, we incorporate physical knowledge into learning-based high-precision target sensing using the multi-view channel state information (CSI) between multiple base stations (BSs) and user equipment (UEs). Such kind of multi-view sensing problem can be naturally cast into a conditional generation framework. To this end, we design a bipartite neural network architecture, the first part of which uses an elaborately designed encoder to fuse the latent target features embedded in the multi-view CSI, and then the second uses them as conditioning inputs of a powerful generative model to guide the target's reconstruction. Specifically, the encoder is designed to capture the physical correlation between the CSI and the target, and also be adaptive to the numbers and positions of BS-UE pairs. Therein the view-specific nature of CSI is assimilated by introducing a spatial positional embedding scheme, which exploits the structure of electromagnetic(EM)-wave propagation channels. Finally, a conditional diffusion model with a weighted loss is employed to generate the target's point cloud from the fused features. Extensive numerical results demonstrate that the proposed generative multi-view (Gen-MV) sensing framework exhibits excellent flexibility and significant performance improvement on the reconstruction quality of target's shape and EM properties.","authors":["Ziqing Xing","Zhaoyang Zhang","Zirui Chen","Hongning Ruan","Zhaohui Yang","Zhiyong Feng"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Wireless Communications"},{"id":"http://arxiv.org/abs/2403.08802v5","updated":"2026-02-20T12:38:54Z","published":"2024-02-05T14:20:19Z","title":"Governance of Generative Artificial Intelligence for Companies","summary":"Generative Artificial Intelligence (GenAI), specifically large language models (LLMs) like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debate on GenAI's transformative potential and emerging regulatory measures, limited research addresses organizational governance from both technical and business perspectives. While frameworks for AI governance exist, it remains unclear to what extent they apply to GenAI. This review paper fills this gap by surveying recent literature to better understand the fundamental characteristics of GenAI and to adapt existing governance frameworks specifically to GenAI within organizations. To this end, it extends Nickerson's framework development process by incorporating prior conceptualizations. The resulting framework delineates scope, objectives, and governance mechanisms designed to both harness business opportunities and mitigate risks associated with GenAI integration. Overall, this research advances a focused approach to GenAI governance, offering practical guidance for companies navigating the challenges of GenAI adoption and highlighting research gaps.","authors":["Johannes Schneider","Pauline Kuss","Rene Abraham","Christian Meske"],"pdf_url":"","comment":"This paper is under submission"},{"id":"http://arxiv.org/abs/2602.18181v1","updated":"2026-02-20T12:38:42Z","published":"2026-02-20T12:38:42Z","title":"SeedFlood: A Step Toward Scalable Decentralized Training of LLMs","summary":"This work presents a new approach to decentralized training-SeedFlood-designed to scale for large models across complex network topologies and achieve global consensus with minimal communication overhead. Traditional gossip-based methods suffer from message communication costs that grow with model size, while information decay over network hops renders global consensus inefficient. SeedFlood departs from these practices by exploiting the seed-reconstructible structure of zeroth-order updates and effectively making the messages near-zero in size, allowing them to be flooded to every client in the network. This mechanism makes communication overhead negligible and independent of model size, removing the primary scalability bottleneck in decentralized training. Consequently, SeedFlood enables training in regimes previously considered impractical, such as billion-parameter models distributed across hundreds of clients. Our experiments on decentralized LLM fine-tuning demonstrate thatSeedFlood consistently outperforms gossip-based baselines in both generalization performance and communication efficiency, and even achieves results comparable to first-order methods in large scale settings.","authors":["Jihun Kim","Namhoon Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06484v2","updated":"2026-02-20T12:33:09Z","published":"2025-09-08T09:47:03Z","title":"Thermodynamically consistent machine learning model for excess Gibbs energy","summary":"The excess Gibbs energy plays a central role in chemical engineering and chemistry, providing a basis for modeling thermodynamic properties of liquid mixtures. Predicting the excess Gibbs energy of multi-component mixtures solely from molecular structures is a long-standing challenge. We address this challenge with HANNA, a flexible machine learning model for excess Gibbs energy that integrates physical laws as hard constraints, guaranteeing thermodynamically consistent predictions. HANNA is trained on experimental data for vapor-liquid equilibria, liquid-liquid equilibria, activity coefficients at infinite dilution and excess enthalpies in binary mixtures. The end-to-end training on liquid-liquid equilibrium data is facilitated by a surrogate solver. A geometric projection method enables robust extrapolations to multi-component mixtures. We demonstrate that HANNA delivers accurate predictions, while providing a substantially broader domain of applicability than state-of-the-art benchmark methods. The trained model and corresponding code are openly available, and an interactive interface is provided on our website, MLPROP.","authors":["Marco Hoffmann","Thomas Specht","Quirin Göttl","Jakob Burger","Stephan Mandt","Hans Hasse","Fabian Jirasek"],"pdf_url":"","comment":"33 pages, 2 figures, 1 table"},{"id":"http://arxiv.org/abs/2509.00479v2","updated":"2026-02-20T12:14:37Z","published":"2025-08-30T12:28:52Z","title":"A Novel Method to Determine Total Oxidant Concentration Produced by Non-Thermal Plasma Based on Image Processing and Machine Learning","summary":"Accurate determination of total oxidant concentration [Ox]tot in nonthermal plasma treated aqueous systems remains a critical challenge due to the transient nature of reactive oxygen and nitrogen species and the subjectivity of conventional titration methods used for [Ox]tot determination. This study introduces a color based computer analysis method that integrates advanced image processing with machine learning to quantify colorimetric changes in potassium iodide solutions during oxidation. A custom built visual acquisition system recorded high resolution video of the color transitions occurring during plasma treatment while the change in oxidant concentration was simultaneously monitored using a standard titrimetric method. Extracted image frames were processed through a structured pipeline to obtain RGB, HSV, and Lab color features. Statistical analysis revealed strong linear relationships between selected color features and measured oxidant concentrations, particularly for HSV saturation, Lab a and b channels, and the blue component of RGB. These features were subsequently used to train and validate multiple machine learning models including linear regression, ridge regression, random forest, gradient boosting, and neural networks. Linear regression and gradient boosting demonstrated the highest predictive accuracy with R2 values exceeding 0.99. Dimensionality reduction from nine features to smaller feature subsets preserved predictive performance while improving computational efficiency. Comparison with experimental titration measurements showed that the proposed system predicts total oxidant concentration in potassium iodide solution with very high accuracy, achieving R2 values above 0.998 even under reduced feature conditions.","authors":["Mirkan Emir Sancak","Unal Sen","Ulker Diler Keris-Sen"],"pdf_url":"","comment":"42 pages, 11 figures, 6 tables. Machine learning assisted colorimetric analysis framework for oxidant quantification in non-thermal plasma systems. This paper will be published later on"},{"id":"http://arxiv.org/abs/2602.18168v1","updated":"2026-02-20T12:14:28Z","published":"2026-02-20T12:14:28Z","title":"A Deep Surrogate Model for Robust and Generalizable Long-Term Blast Wave Prediction","summary":"Accurately modeling the spatio-temporal dynamics of blast wave propagation remains a longstanding challenge due to its highly nonlinear behavior, sharp gradients, and burdensome computational cost. While machine learning-based surrogate models offer fast inference as a promising alternative, they suffer from degraded accuracy, particularly evaluated on complex urban layouts or out-of-distribution scenarios. Moreover, autoregressive prediction strategies in such models are prone to error accumulation over long forecasting horizons, limiting their robustness for extended-time simulations. To address these limitations, we propose RGD-Blast, a robust and generalizable deep surrogate model for high-fidelity, long-term blast wave forecasting. RGD-Blast incorporates a multi-scale module to capture both global flow patterns and local boundary interactions, effectively mitigating error accumulation during autoregressive prediction. We introduce a dynamic-static feature coupling mechanism that fuses time-varying pressure fields with static source and layout features, thereby enhancing out-of-distribution generalization. Experiments demonstrate that RGD-Blast achieves a two-order-of-magnitude speedup over traditional numerical methods while maintaining comparable accuracy. In generalization tests on unseen building layouts, the model achieves an average RMSE below 0.01 and an R2 exceeding 0.89 over 280 consecutive time steps. Additional evaluations under varying blast source locations and explosive charge weights further validate its generalization, substantially advancing the state of the art in long-term blast wave modeling.","authors":["Danning Jing","Xinhai Chen","Xifeng Pu","Jie Hu","Chao Huang","Xuguang Chen","Qinglin Wang","Jie Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2112.05128v3","updated":"2026-02-20T12:07:57Z","published":"2021-12-09T18:58:36Z","title":"Fair Community Detection and Structure Learning in Heterogeneous Graphical Models","summary":"Inference of community structure in probabilistic graphical models may not be consistent with fairness constraints when nodes have demographic attributes. Certain demographics may be over-represented in some detected communities and under-represented in others. This paper defines a novel $\\ell_1$-regularized pseudo-likelihood approach for fair graphical model selection. In particular, we assume there is some community or clustering structure in the true underlying graph, and we seek to learn a sparse undirected graph and its communities from the data such that demographic groups are fairly represented within the communities. In the case when the graph is known a priori, we provide a convex semidefinite programming approach for fair community detection. We establish the statistical consistency of the proposed method for both a Gaussian graphical model and an Ising model for, respectively, continuous and binary data, proving that our method can recover the graphs and their fair communities with high probability.","authors":["Davoud Ataee Tarzanagh","Laura Balzano","Alfred O. Hero"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16902v2","updated":"2026-02-20T11:54:02Z","published":"2026-02-18T21:33:59Z","title":"LLM-WikiRace Benchmark: How Far Can LLMs Plan over Real-World Knowledge Graphs?","summary":"We introduce LLM-Wikirace, a benchmark for evaluating planning, reasoning, and world knowledge in large language models (LLMs). In LLM-Wikirace, models must efficiently navigate Wikipedia hyperlinks step by step to reach a target page from a given source, requiring look-ahead planning and the ability to reason about how concepts are connected in the real world. We evaluate a broad set of open- and closed-source models, including Gemini-3, GPT-5, and Claude Opus 4.5, which achieve the strongest results on the easy level of the task and demonstrate superhuman performance. Despite this, performance drops sharply on hard difficulty: the best-performing model, Gemini-3, succeeds in only 23\\% of hard games, highlighting substantial remaining challenges for frontier models. Our analysis shows that world knowledge is a necessary ingredient for success, but only up to a point, beyond this threshold, planning and long-horizon reasoning capabilities become the dominant factors. Trajectory-level analysis further reveals that even the strongest models struggle to replan after failure, frequently entering loops rather than recovering. LLM-Wikirace is a simple benchmark that reveals clear limitations in current reasoning systems, offering an open arena where planning-capable LLMs still have much to prove. Our code and leaderboard available at https:/llmwikirace.github.io.","authors":["Juliusz Ziomek","William Bankes","Lorenz Wolf","Shyam Sundhar Ramesh","Xiaohang Tang","Ilija Bogunovic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18160v1","updated":"2026-02-20T11:52:26Z","published":"2026-02-20T11:52:26Z","title":"Unifying Formal Explanations: A Complexity-Theoretic Perspective","summary":"Previous work has explored the computational complexity of deriving two fundamental types of explanations for ML model predictions: (1) *sufficient reasons*, which are subsets of input features that, when fixed, determine a prediction, and (2) *contrastive reasons*, which are subsets of input features that, when modified, alter a prediction. Prior studies have examined these explanations in different contexts, such as non-probabilistic versus probabilistic frameworks and local versus global settings. In this study, we introduce a unified framework for analyzing these explanations, demonstrating that they can all be characterized through the minimization of a unified probabilistic value function. We then prove that the complexity of these computations is influenced by three key properties of the value function: (1) *monotonicity*, (2) *submodularity*, and (3) *supermodularity* - which are three fundamental properties in *combinatorial optimization*. Our findings uncover some counterintuitive results regarding the nature of these properties within the explanation settings examined. For instance, although the *local* value functions do not exhibit monotonicity or submodularity/supermodularity whatsoever, we demonstrate that the *global* value functions do possess these properties. This distinction enables us to prove a series of novel polynomial-time results for computing various explanations with provable guarantees in the global explainability setting, across a range of ML models that span the interpretability spectrum, such as neural networks, decision trees, and tree ensembles. In contrast, we show that even highly simplified versions of these explanations become NP-hard to compute in the corresponding local explainability setting.","authors":["Shahaf Bassan","Xuanxiang Huang","Guy Katz"],"pdf_url":"","comment":"To appear in ICLR 2026"},{"id":"http://arxiv.org/abs/2502.17160v3","updated":"2026-02-20T11:50:22Z","published":"2025-02-24T13:54:57Z","title":"A Pragmatic Note on Evaluating Generative Models with Fréchet Inception Distance for Retinal Image Synthesis","summary":"Fréchet Inception Distance (FID), computed with an ImageNet pretrained Inception-v3 network, is widely used as a state-of-the-art evaluation metric for generative models. It assumes that feature vectors from Inception-v3 follow a multivariate Gaussian distribution and calculates the 2-Wasserstein distance based on their means and covariances. While FID effectively measures how closely synthetic data match real data in many image synthesis tasks, the primary goal in biomedical generative models is often to enrich training datasets ideally with corresponding annotations. For this purpose, the gold standard for evaluating generative models is to incorporate synthetic data into downstream task training, such as classification and segmentation, to pragmatically assess its performance. In this paper, we examine cases from retinal imaging modalities, including color fundus photography and optical coherence tomography, where FID and its related metrics misalign with task-specific evaluation goals in classification and segmentation. We highlight the limitations of using various metrics, represented by FID and its variants, as evaluation criteria for these applications and address their potential caveats in broader biomedical imaging modalities and downstream tasks.","authors":["Yuli Wu","Fucheng Liu","Rüveyda Yilmaz","Henning Konermann","Peter Walter","Johannes Stegmaier"],"pdf_url":"","comment":"MIDL 2026"},{"id":"http://arxiv.org/abs/2601.09282v2","updated":"2026-02-20T11:40:54Z","published":"2026-01-14T08:36:21Z","title":"Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing","summary":"Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration and presents a proof-of-concept design.","authors":["Leszek Sliwko","Jolanta Mizeria-Pietraszko"],"pdf_url":"","comment":"This is the accepted version of the paper published in IEEE Access (2026). The final version is available at: https://doi.org/10.1109/ACCESS.2026.3665989"},{"id":"http://arxiv.org/abs/2510.09658v3","updated":"2026-02-20T11:40:52Z","published":"2025-10-07T13:30:25Z","title":"Gradient-Sign Masking for Task Vector Transport Across Pre-Trained Models","summary":"When a new release of a foundation model is published, practitioners typically need to repeat fine-tuning, even if the same task was already tackled in the previous version. A promising alternative is to reuse the parameter changes (i.e., task vectors) that capture how a model adapts to a specific task. However, these vectors often fail to transfer across different pre-trained models because their parameter spaces are misaligned. In this work, we show that successful transfer depends strongly on the gradient-sign structure of the new model. Based on this insight, we propose GradFix, which approximates the ideal sign structure and leverages it to transfer knowledge using only a handful of labeled samples. Notably, this requires no additional fine-tuning: we only compute a few target-model gradients without parameter updates and mask the source task vector accordingly. This yields an update that is locally aligned with the target loss landscape, effectively rebasing the task vector onto the new pre-training. We provide a theoretical guarantee that our method ensures first-order descent. Empirically, we demonstrate significant performance gains on vision and language benchmarks, consistently outperforming naive task vector addition and few-shot fine-tuning. We further show that transporting task vectors improves multi-task and multi-source model merging. Code is available at https://github.com/fillo-rinaldi/GradFix.","authors":["Filippo Rinaldi","Aniello Panariello","Giacomo Salici","Fengyuan Liu","Marco Ciccone","Angelo Porrello","Simone Calderara"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.18151v1","updated":"2026-02-20T11:30:13Z","published":"2026-02-20T11:30:13Z","title":"Rethinking Beam Management: Generalization Limits Under Hardware Heterogeneity","summary":"Hardware heterogeneity across diverse user devices poses new challenges for beam-based communication in 5G and beyond. This heterogeneity limits the applicability of machine learning (ML)-based algorithms. This article highlights the critical need to treat hardware heterogeneity as a first-class design concern in ML-aided beam management. We analyze key failure modes in the presence of heterogeneity and present case studies demonstrating their performance impact. Finally, we discuss potential strategies to improve generalization in beam management.","authors":["Nikita Zeulin","Olga Galinina","Ibrahim Kilinc","Sergey Andreev","Robert W. Heath"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2602.18148v1","updated":"2026-02-20T11:26:45Z","published":"2026-02-20T11:26:45Z","title":"BONNI: Gradient-Informed Bayesian and Interior Point Optimization for Efficient Inverse Design in Nanophotonics","summary":"Inverse design, particularly geometric shape optimization, provides a systematic approach for developing high-performance nanophotonic devices. While numerous optimization algorithms exist, previous global approaches exhibit slow convergence and conversely local search strategies frequently become trapped in local optima. To address the limitations inherent to both local and global approaches, we introduce BONNI: Bayesian optimization through neural network ensemble surrogates with interior point optimization. It augments global optimization with an efficient incorporation of gradient information to determine optimal sampling points. This capability allows BONNI to circumvent the local optima found in many nanophotonic applications, while capitalizing on the efficiency of gradient-based optimization. We demonstrate BONNI's capabilities in the design of a distributed Bragg reflector as well as a dual-layer grating coupler through an exhaustive comparison against other optimization algorithms commonly used in literature. Using BONNI, we were able to design a 10-layer distributed Bragg reflector with only 4.5% mean spectral error, compared to the previously reported results of 7.8% error with 16 layers. Further designs of a broadband waveguide taper and photonic crystal waveguide transition validate the capabilities of BONNI.","authors":["Yannik Mahlau","Yannick Augenstein","Tyler W. Hughes","Marius Lindauer","Bodo Rosenhahn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18146v1","updated":"2026-02-20T11:22:47Z","published":"2026-02-20T11:22:47Z","title":"Stable Long-Horizon Spatiotemporal Prediction on Meshes Using Latent Multiscale Recurrent Graph Neural Networks","summary":"Accurate long-horizon prediction of spatiotemporal fields on complex geometries is a fundamental challenge in scientific machine learning, with applications such as additive manufacturing where temperature histories govern defect formation and mechanical properties. High-fidelity simulations are accurate but computationally costly, and despite recent advances, machine learning methods remain challenged by long-horizon temperature and gradient prediction. We propose a deep learning framework for predicting full temperature histories directly on meshes, conditioned on geometry and process parameters, while maintaining stability over thousands of time steps and generalizing across heterogeneous geometries. The framework adopts a temporal multiscale architecture composed of two coupled models operating at complementary time scales. Both models rely on a latent recurrent graph neural network to capture spatiotemporal dynamics on meshes, while a variational graph autoencoder provides a compact latent representation that reduces memory usage and improves training stability. Experiments on simulated powder bed fusion data demonstrate accurate and temporally stable long-horizon predictions across diverse geometries, outperforming existing baseline. Although evaluated in two dimensions, the framework is general and extensible to physics-driven systems with multiscale dynamics and to three-dimensional geometries.","authors":["Lionel Salesses","Larbi Arbaoui","Tariq Benamara","Arnaud Francois","Caroline Sainvitu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.15337v2","updated":"2026-02-20T11:17:32Z","published":"2026-02-17T03:57:07Z","title":"FedPSA: Modeling Behavioral Staleness in Asynchronous Federated Learning","summary":"Asynchronous Federated Learning (AFL) has emerged as a significant research area in recent years. By not waiting for slower clients and executing the training process concurrently, it achieves faster training speed compared to traditional federated learning. However, due to the staleness introduced by the asynchronous process, its performance may degrade in some scenarios. Existing methods often use the round difference between the current model and the global model as the sole measure of staleness, which is coarse-grained and lacks observation of the model itself, thereby limiting the performance ceiling of asynchronous methods. In this paper, we propose FedPSA (Parameter Sensitivity-based Asynchronous Federated Learning), a more fine-grained AFL framework that leverages parameter sensitivity to measure model obsolescence and establishes a dynamic momentum queue to assess the current training phase in real time, thereby adjusting the tolerance for outdated information dynamically. Extensive experiments on multiple datasets and comparisons with various methods demonstrate the superior performance of FedPSA, achieving up to 6.37\\% improvement over baseline methods and 1.93\\% over the current state-of-the-art method.","authors":["Chaoyi Lu","Yiding Sun","Zhichuan Yang","Jinqian Chen","Dongfu Yin","Jihua Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18141v1","updated":"2026-02-20T11:01:12Z","published":"2026-02-20T11:01:12Z","title":"Advection-Diffusion on Graphs: A Bakry-Emery Laplacian for Spectral Graph Neural Networks","summary":"Graph Neural Networks (GNNs) often struggle to propagate information across long distances due to oversmoothing and oversquashing. Existing remedies such as graph transformers or rewiring typically incur high computational cost or require altering the graph structure. We introduce a Bakry-Emery graph Laplacian that integrates diffusion and advection through a learnable node-wise potential, inducing task-dependent propagation dynamics without modifying topology. This operator has a well-behaved spectral decomposition and acts as a drop-in replacement for standard Laplacians in spectral GNNs. Building on this insight, we develop mu-ChebNet, a spectral architecture that jointly learns the potential and Chebyshev filters, effectively bridging message-passing adaptivity and spectral efficiency. Our theoretical analysis shows how the potential modulates the spectrum, enabling control of key graph properties. Empirically, mu-ChebNet delivers consistent gains on synthetic long-range reasoning tasks, as well as real-world benchmarks, while offering an interpretable routing field that reveals how information flows through the graph. This establishes the Bakry-Emery Laplacian as a principled and efficient foundation for adaptive spectral graph learning.","authors":["Pierre-Gabriel Berlureau","Ali Hariri","Victor Kawasaki-Borruat","Mia Zosso","Pierre Vandergheynst"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18137v1","updated":"2026-02-20T10:53:09Z","published":"2026-02-20T10:53:09Z","title":"Agentic Adversarial QA for Improving Domain-Specific LLMs","summary":"Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.","authors":["Vincent Grari","Ciprian Tomoiaga","Sylvain Lamprier","Tatsunori Hashimoto","Marcin Detyniecki"],"pdf_url":"","comment":"9 pages, 1 Figure"},{"id":"http://arxiv.org/abs/2508.06118v2","updated":"2026-02-20T10:51:43Z","published":"2025-08-08T08:32:46Z","title":"Ensemble-based graph representation of fMRI data for cognitive brain state classification","summary":"fMRI is a non-invasive technique for investigating brain activity, offering high-resolution insights into neural processes. Understanding and decoding cognitive brain states from fMRI depends on how functional interactions are represented. We propose an ensemble-based graph representation in which each edge weight encodes state evidence as the difference between posterior probabilities of two states, estimated by an ensemble of edge-wise probabilistic classifiers from simple pairwise time-series features. We evaluate the method on seven task-fMRI paradigms from the Human Connectome Project, performing binary classification within each paradigm. Using compact node summaries (mean incident edge weights) and logistic regression, we obtain average accuracies of 97.07-99.74 %. We further compare ensemble graphs with conventional correlation graphs using the same graph neural network classifier; ensemble graphs consistently yield higher accuracy (88.00-99.42 % vs 61.86-97.94 % across tasks). Because edge weights have a probabilistic, state-oriented interpretation, the representation supports connection- and region-level interpretability and can be extended to multiclass decoding, regression, other neuroimaging modalities, and clinical classification.","authors":["Daniil Vlasenko","Vadim Ushakov","Alexey Zaikin","Denis Zakharov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18131v1","updated":"2026-02-20T10:46:28Z","published":"2026-02-20T10:46:28Z","title":"Learning Long-Range Dependencies with Temporal Predictive Coding","summary":"Predictive Coding (PC) is a biologically-inspired learning framework characterised by local, parallelisable operations, properties that enable energy-efficient implementation on neuromorphic hardware. Despite this, extending PC effectively to recurrent neural networks (RNNs) has been challenging, particularly for tasks involving long-range temporal dependencies. Backpropagation Through Time (BPTT) remains the dominant method for training RNNs, but its non-local computation, lack of spatial parallelism, and requirement to store extensive activation histories results in significant energy consumption. This work introduces a novel method combining Temporal Predictive Coding (tPC) with approximate Real-Time Recurrent Learning (RTRL), enabling effective spatio-temporal credit assignment. Results indicate that the proposed method can closely match the performance of BPTT on both synthetic benchmarks and real-world tasks. On a challenging machine translation task, with a 15-million parameter model, the proposed method achieves a test perplexity of 7.62 (vs. 7.49 for BPTT), marking one of the first applications of tPC to tasks of this scale. These findings demonstrate the potential of this method to learn complex temporal dependencies whilst retaining the local, parallelisable, and flexible properties of the original PC framework, paving the way for more energy-efficient learning systems.","authors":["Tom Potter","Oliver Rhodes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16898v2","updated":"2026-02-20T10:41:16Z","published":"2026-02-18T21:28:56Z","title":"MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation","summary":"Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.MALLVi present a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step Rather than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning.Experiments in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks.Code available at https://github.com/iman1234ahmadi/MALLVI.","authors":["Iman Ahmadi","Mehrshad Taji","Arad Mahdinezhad Kashani","AmirHossein Jadidi","Saina Kashani","Babak Khalaj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.08059v2","updated":"2026-02-20T10:34:49Z","published":"2025-10-09T10:46:08Z","title":"Mitigating Subject Dependency in EEG Decoding with Subject-Specific Low-Rank Adapters","summary":"Subject-specific distribution shifts represent a fundamental obstacle to developing foundation models for brain decoding. We propose the Subject-Specific Low-Rank Adapter (SuLoRA), a drop-in replacement for standard linear or convolutional layers that captures inter-subject variability by decomposing weights into a shared, subject-invariant component and a lightweight, low-rank correction unique to each subject. This explicit separation enables existing architectures to become robust to subject shifts without architectural redesign. We evaluate SuLoRA on MEG speech perception and EEG motor imagery tasks across CNN and transformer architectures. In the speech decoding task, SuLoRA exceeds the baseline performance with half of the parameters. On motor imagery dataset, SuLoRA outperforms both subject-agnostic models and independently trained subject-specific models. SuLoRA offers a practical path towards effective cross-subject foundation models for brain signal applications.","authors":["Timon Klein","Piotr Minakowski","Sebastian Sager","Steffen Schotthöfer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.08570v2","updated":"2026-02-20T10:25:39Z","published":"2025-10-09T17:59:57Z","title":"Who Said Neural Networks Aren't Linear?","summary":"Neural networks are famously nonlinear. However, linearity is defined relative to a pair of vector spaces, $f:X \\to Y$. Leveraging the algebraic concept of transport of structure, we propose a method to explicitly identify non-standard vector spaces where a neural network acts as a linear operator. When sandwiching a linear operator $A$ between two invertible neural networks, $f(x)=g_y^{-1}(A g_x(x))$, the corresponding vector spaces $X$ and $Y$ are induced by newly defined addition and scaling actions derived from $g_x$ and $g_y$. We term this kind of architecture a Linearizer. This framework makes the entire arsenal of linear algebra, including SVD, pseudo-inverse, orthogonal projection and more, applicable to nonlinear mappings. Furthermore, we show that the composition of two Linearizers that share a neural network is also a Linearizer. We leverage this property and demonstrate that training diffusion models using our architecture makes the hundreds of sampling steps collapse into a single step. We further utilize our framework to enforce idempotency (i.e. $f(f(x))=f(x)$) on networks leading to a globally projective generative model and to demonstrate modular style transfer.","authors":["Nimrod Berman","Assaf Hallak","Assaf Shocher"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18119v1","updated":"2026-02-20T10:18:27Z","published":"2026-02-20T10:18:27Z","title":"RamanSeg: Interpretability-driven Deep Learning on Raman Spectra for Cancer Diagnosis","summary":"Histopathology, the current gold standard for cancer diagnosis, involves the manual examination of tissue samples after chemical staining, a time-consuming process requiring expert analysis. Raman spectroscopy is an alternative, stain-free method of extracting information from samples. Using nnU-Net, we trained a segmentation model on a novel dataset of spatial Raman spectra aligned with tumour annotations, achieving a mean foreground Dice score of 80.9%, surpassing previous work. Furthermore, we propose a novel, interpretable, prototype-based architecture called RamanSeg. RamanSeg classifies pixels based on discovered regions of the training set, generating a segmentation mask. Two variants of RamanSeg allow a trade-off between interpretability and performance: one with prototype projection and another projection-free version. The projection-free RamanSeg outperformed a U-Net baseline with a mean foreground Dice score of 67.3%, offering a meaningful improvement over a black-box training approach.","authors":["Chris Tomy","Mo Vali","David Pertzborn","Tammam Alamatouri","Anna Mühlig","Orlando Guntinas-Lichius","Anna Xylander","Eric Michele Fantuzzi","Matteo Negro","Francesco Crisafi","Pietro Lio","Tiago Azevedo"],"pdf_url":"","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.18117v1","updated":"2026-02-20T10:14:00Z","published":"2026-02-20T10:14:00Z","title":"Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning","summary":"Generative models have recently demonstrated remarkable success across diverse domains, motivating their adoption as expressive policies in reinforcement learning (RL). While they have shown strong performance in offline RL, particularly where the target distribution is well defined, their extension to online fine-tuning has largely been treated as a direct continuation of offline pre-training, leaving key challenges unaddressed. In this paper, we propose Flow Matching with Injected Noise for Offline-to-Online RL (FINO), a novel method that leverages flow matching-based policies to enhance sample efficiency for offline-to-online RL. FINO facilitates effective exploration by injecting noise into policy training, thereby encouraging a broader range of actions beyond those observed in the offline dataset. In addition to exploration-enhanced flow policy training, we combine an entropy-guided sampling mechanism to balance exploration and exploitation, allowing the policy to adapt its behavior throughout online fine-tuning. Experiments across diverse, challenging tasks demonstrate that FINO consistently achieves superior performance under limited online budgets.","authors":["Yongjae Shin","Jongseong Chae","Jongeui Park","Youngchul Sung"],"pdf_url":"","comment":"ICLR 2026 camera-ready"},{"id":"http://arxiv.org/abs/2602.18116v1","updated":"2026-02-20T10:09:02Z","published":"2026-02-20T10:09:02Z","title":"Cut Less, Fold More: Model Compression through the Lens of Projection Geometry","summary":"Compressing neural networks without retraining is vital for deployment at scale. We study calibration-free compression through the lens of projection geometry: structured pruning is an axis-aligned projection, whereas model folding performs a low-rank projection via weight clustering. We formalize both as orthogonal operators and show that, within a rank distance of one, folding provably yields smaller parameter reconstruction error, and under mild smoothness assumptions, smaller functional perturbations than pruning. At scale, we evaluate >1000 checkpoints spanning ResNet18, PreActResNet18, ViT-B/32, and CLIP ViT-B/32 on CIFAR-10 and ImageNet-1K, covering diverse training hyperparameters (optimizers, learning rates, augmentations, regularization, sharpness-aware training), as well as multiple LLaMA-family 60M and 130M parameter models trained on C4. We show that folding typically achieves higher post-compression accuracy, with the largest gains at moderate-high compression. The gap narrows and occasionally reverses at specific training setups. Our results position folding as a geometry-aware, calibration-free alternative to pruning that is often superior in practice and principled in theory.","authors":["Olga Saukh","Dong Wang","Haris Šikić","Yun Cheng","Lothar Thiele"],"pdf_url":"","comment":"Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2602.18114v1","updated":"2026-02-20T10:07:35Z","published":"2026-02-20T10:07:35Z","title":"Non-Stationary Online Resource Allocation: Learning from a Single Sample","summary":"We study online resource allocation under non-stationary demand with a minimum offline data requirement. In this problem, a decision-maker must allocate multiple types of resources to sequentially arriving queries over a finite horizon. Each query belongs to a finite set of types with fixed resource consumption and a stochastic reward drawn from an unknown, type-specific distribution. Critically, the environment exhibits arbitrary non-stationarity -- arrival distributions may shift unpredictably-while the algorithm requires only one historical sample per period to operate effectively. We distinguish two settings based on sample informativeness: (i) reward-observed samples containing both query type and reward realization, and (ii) the more challenging type-only samples revealing only query type information.\n  We propose a novel type-dependent quantile-based meta-policy that decouples the problem into modular components: reward distribution estimation, optimization of target service probabilities via fluid relaxation, and real-time decisions through dynamic acceptance thresholds. For reward-observed samples, our static threshold policy achieves $\\tilde{O}(\\sqrt{T})$ regret. For type-only samples, we first establish that sublinear regret is impossible without additional structure; under a mild minimum-arrival-probability assumption, we design both a partially adaptive policy attaining the same $\\tilde{O}({T})$ bound and, more significantly, a fully adaptive resolving policy with careful rounding that achieves the first poly-logarithmic regret guarantee of $O((\\log T)^3)$ for non-stationary multi-resource allocation. Our framework advances prior work by operating with minimal offline data (one sample per period), handling arbitrary non-stationarity without variation-budget assumptions, and supporting multiple resource constraints.","authors":["Yiding Feng","Jiashuo Jiang","Yige Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18109v1","updated":"2026-02-20T09:56:23Z","published":"2026-02-20T09:56:23Z","title":"TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs","summary":"Real-time schedulers must reason about tight deadlines under strict compute budgets. We present TempoNet, a reinforcement learning scheduler that pairs a permutation-invariant Transformer with a deep Q-approximation. An Urgency Tokenizer discretizes temporal slack into learnable embeddings, stabilizing value learning and capturing deadline proximity. A latency-aware sparse attention stack with blockwise top-k selection and locality-sensitive chunking enables global reasoning over unordered task sets with near-linear scaling and sub-millisecond inference. A multicore mapping layer converts contextualized Q-scores into processor assignments through masked-greedy selection or differentiable matching. Extensive evaluations on industrial mixed-criticality traces and large multiprocessor settings show consistent gains in deadline fulfillment over analytic schedulers and neural baselines, together with improved optimization stability. Diagnostics include sensitivity analyses for slack quantization, attention-driven policy interpretation, hardware-in-the-loop and kernel micro-benchmarks, and robustness under stress with simple runtime mitigations; we also report sample-efficiency benefits from behavioral-cloning pretraining and compatibility with an actor-critic variant without altering the inference pipeline. These results establish a practical framework for Transformer-based decision making in high-throughput real-time scheduling.","authors":["Rong Fu","Yibo Meng","Guangzhen Yao","Jiaxuan Lu","Zeyu Zhang","Zhaolu Kang","Ziming Guo","Jia Yee Tan","Xiaojing Du","Simon James Fong"],"pdf_url":"","comment":"43 pages, 12 figures"},{"id":"http://arxiv.org/abs/2602.18104v1","updated":"2026-02-20T09:48:23Z","published":"2026-02-20T09:48:23Z","title":"MeanVoiceFlow: One-step Nonparallel Voice Conversion with Mean Flows","summary":"In voice conversion (VC) applications, diffusion and flow-matching models have exhibited exceptional speech quality and speaker similarity performances. However, they are limited by slow conversion owing to their iterative inference. Consequently, we propose MeanVoiceFlow, a novel one-step nonparallel VC model based on mean flows, which can be trained from scratch without requiring pretraining or distillation. Unlike conventional flow matching that uses instantaneous velocity, mean flows employ average velocity to more accurately compute the time integral along the inference path in a single step. However, training the average velocity requires its derivative to compute the target velocity, which can cause instability. Therefore, we introduce a structural margin reconstruction loss as a zero-input constraint, which moderately regularizes the input-output behavior of the model without harmful statistical averaging. Furthermore, we propose conditional diffused-input training in which a mixture of noise and source data is used as input to the model during both training and inference. This enables the model to effectively leverage source information while maintaining consistency between training and inference. Experimental results validate the effectiveness of these techniques and demonstrate that MeanVoiceFlow achieves performance comparable to that of previous multi-step and distillation-based models, even when trained from scratch. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/meanvoiceflow/.","authors":["Takuhiro Kaneko","Hirokazu Kameoka","Kou Tanaka","Yuto Kondo"],"pdf_url":"","comment":"Accepted to ICASSP 2026. Project page: https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/meanvoiceflow/"},{"id":"http://arxiv.org/abs/2602.18097v1","updated":"2026-02-20T09:38:38Z","published":"2026-02-20T09:38:38Z","title":"Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning","summary":"In this paper, we present a framework for enabling autonomous vehicles to interact with cyclists in a manner that balances safety and optimality. The approach integrates Hamilton-Jacobi reachability analysis with deep Q-learning to jointly address safety guarantees and time-efficient navigation. A value function is computed as the solution to a time-dependent Hamilton-Jacobi-Bellman inequality, providing a quantitative measure of safety for each system state. This safety metric is incorporated as a structured reward signal within a reinforcement learning framework. The method further models the cyclist's latent response to the vehicle, allowing disturbance inputs to reflect human comfort and behavioral adaptation. The proposed framework is evaluated through simulation and comparison with human driving behavior and an existing state-of-the-art method.","authors":["Aarati Andrea Noronha","Jean Oh"],"pdf_url":"","comment":"7 pages. This manuscript was completed in 2020 as part of the first author's graduate thesis at Carnegie Mellon University"},{"id":"http://arxiv.org/abs/2511.18945v2","updated":"2026-02-20T09:26:51Z","published":"2025-11-24T09:55:28Z","title":"MIST: Mutual Information Estimation Via Supervised Training","summary":"We propose a fully data-driven approach to designing mutual information (MI) estimators. Since any MI estimator is a function of the observed sample from two random variables, we parameterize this function with a neural network (MIST) and train it end-to-end to predict MI values. Training is performed on a large meta-dataset of 625,000 synthetic joint distributions with known ground-truth MI. To handle variable sample sizes and dimensions, we employ a two-dimensional attention scheme ensuring permutation invariance across input samples. To quantify uncertainty, we optimize a quantile regression loss, enabling the estimator to approximate the sampling distribution of MI rather than return a single point estimate. This research program departs from prior work by taking a fully empirical route, trading universal theoretical guarantees for flexibility and efficiency. Empirically, the learned estimators largely outperform classical baselines across sample sizes and dimensions, including on joint distributions unseen during training. The resulting quantile-based intervals are well-calibrated and more reliable than bootstrap-based confidence intervals, while inference is orders of magnitude faster than existing neural baselines. Beyond immediate empirical gains, this framework yields trainable, fully differentiable estimators that can be embedded into larger learning pipelines. Moreover, exploiting MI's invariance to invertible transformations, meta-datasets can be adapted to arbitrary data modalities via normalizing flows, enabling flexible training for diverse target meta-distributions.","authors":["German Gritsai","Megan Richards","Maxime Méloux","Kyunghyun Cho","Maxime Peyrard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18089v1","updated":"2026-02-20T09:25:14Z","published":"2026-02-20T09:25:14Z","title":"DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text","summary":"Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.","authors":["Kunwar Arpit Singh","Ankush Prakash","Haroon R Lone"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14612v2","updated":"2026-02-20T09:24:27Z","published":"2026-02-16T10:15:22Z","title":"LongAudio-RAG: Event-Grounded Question Answering over Multi-Hour Long Audio","summary":"Long-duration audio is increasingly common in industrial and consumer settings, yet reviewing multi-hour recordings is impractical, motivating systems that answer natural-language queries with precise temporal grounding and minimal hallucination. Existing audio-language models show promise, but long-audio question answering remains difficult due to context-length limits. We introduce LongAudio-RAG (LA-RAG), a hybrid framework that grounds Large Language Model (LLM) outputs in retrieved, timestamped acoustic event detections rather than raw audio. Multi-hour streams are converted into structured event records stored in an SQL database, and at inference time the system resolves natural-language time references, classifies intent, retrieves only the relevant events, and generates answers using this constrained evidence. To evaluate performance, we construct a synthetic long-audio benchmark by concatenating recordings with preserved timestamps and generating template-based question-answer pairs for detection, counting, and summarization tasks. Finally, we demonstrate the practicality of our approach by deploying it in a hybrid edge-cloud environment, where the audio grounding model runs on-device on IoT-class hardware while the LLM is hosted on a GPU-backed server. This architecture enables low-latency event extraction at the edge and high-quality language reasoning in the cloud. Experiments show that structured, event-level retrieval significantly improves accuracy compared to vanilla Retrieval-Augmented Generation (RAG) or text-to-SQL approaches.","authors":["Naveen Vakada","Kartik Hegde","Arvind Krishna Sridhar","Yinyi Guo","Erik Visser"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18084v1","updated":"2026-02-20T09:17:57Z","published":"2026-02-20T09:17:57Z","title":"Balancing Symmetry and Efficiency in Graph Flow Matching","summary":"Equivariance is central to graph generative models, as it ensures the model respects the permutation symmetry of graphs. However, strict equivariance can increase computational cost due to added architectural constraints, and can slow down convergence because the model must be consistent across a large space of possible node permutations. We study this trade-off for graph generative models. Specifically, we start from an equivariant discrete flow-matching model, and relax its equivariance during training via a controllable symmetry modulation scheme based on sinusoidal positional encodings and node permutations. Experiments first show that symmetry-breaking can accelerate early training by providing an easier learning signal, but at the expense of encouraging shortcut solutions that can cause overfitting, where the model repeatedly generates graphs that are duplicates of the training set. On the contrary, properly modulating the symmetry signal can delay overfitting while accelerating convergence, allowing the model to reach stronger performance with $19\\%$ of the baseline training epochs.","authors":["Benjamin Honoré","Alba Carballo-Castro","Yiming Qin","Pascal Frossard"],"pdf_url":"","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2602.18083v1","updated":"2026-02-20T09:17:12Z","published":"2026-02-20T09:17:12Z","title":"Comparative Assessment of Multimodal Earth Observation Data for Soil Moisture Estimation","summary":"Accurate soil moisture (SM) estimation is critical for precision agriculture, water resources management and climate monitoring. Yet, existing satellite SM products are too coarse (>1km) for farm-level applications. We present a high-resolution (10m) SM estimation framework for vegetated areas across Europe, combining Sentinel-1 SAR, Sentinel-2 optical imagery and ERA-5 reanalysis data through machine learning. Using 113 International Soil Moisture Network (ISMN) stations spanning diverse vegetated areas, we compare modality combinations with temporal parameterizations, using spatial cross-validation, to ensure geographic generalization. We also evaluate whether foundation model embeddings from IBM-NASA's Prithvi model improve upon traditional hand-crafted spectral features. Results demonstrate that hybrid temporal matching - Sentinel-2 current-day acquisitions with Sentinel-1 descending orbit - achieves R^2=0.514, with 10-day ERA5 lookback window improving performance to R^2=0.518. Foundation model (Prithvi) embeddings provide negligible improvement over hand-crafted features (R^2=0.515 vs. 0.514), indicating traditional feature engineering remains highly competitive for sparse-data regression tasks. Our findings suggest that domain-specific spectral indices combined with tree-based ensemble methods offer a practical and computationally efficient solution for operational pan-European field-scale soil moisture monitoring.","authors":["Ioannis Kontogiorgakis","Athanasios Askitopoulos","Iason Tsardanidis","Dimitrios Bormpoudakis","Ilias Tsoumas","Fotios Balampanis","Charalampos Kontoes"],"pdf_url":"","comment":"This paper has been submitted to IEEE IGARSS 2026"},{"id":"http://arxiv.org/abs/2507.17316v3","updated":"2026-02-20T09:14:36Z","published":"2025-07-23T08:30:37Z","title":"Nearly Minimax Discrete Distribution Estimation in Kullback-Leibler Divergence with High Probability","summary":"We consider the fundamental problem of estimating a discrete distribution on a domain of size $K$ with high probability in Kullback-Leibler divergence. We provide upper and lower bounds on the minimax estimation rate, which show that the optimal rate is between $\\big(K + \\ln(K)\\ln(1/δ)\\big) /n$ and $\\big(K\\ln\\ln(K) + \\ln(K)\\ln(1/δ)\\big) /n$ at error probability $δ$ and sample size $n$, which pins down the rate up to the doubly logarithmic factor $\\ln \\ln K$ that multiplies $K$. Our upper bound uses techniques from online learning to construct a novel estimator via online-to-batch conversion. Perhaps surprisingly, the tail behavior of the minimax rate is worse than for the squared total variation and squared Hellinger distance, for which it is $\\big(K + \\ln(1/δ)\\big) /n$, i.e. without the $\\ln K$ multiplying $\\ln (1/δ)$. As a consequence, we cannot obtain a fully tight lower bound from the usual reduction to these smaller distances. Moreover, we show that this lower bound cannot be achieved by the standard lower bound approach based on a reduction to hypothesis testing, and instead we need to introduce a new reduction to what we call weak hypothesis testing. We investigate the source of the gap with other divergences further in refined results, which show that the total variation rate is achievable for Kullback-Leibler divergence after all (in fact by he maximum likelihood estimator) if we rule out outcome probabilities smaller than $O(\\ln(K/δ) / n)$, which is a vanishing set as $n$ increases for fixed $K$ and $δ$. This explains why minimax Kullback-Leibler estimation is more difficult than asymptotic estimation.","authors":["Dirk van der Hoeven","Julia Olkhovskaia","Tim van Erven"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.04954v2","updated":"2026-02-20T08:45:07Z","published":"2025-12-04T16:22:53Z","title":"Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows","summary":"We present a novel technique for amortized posterior estimation using Normalizing Flows trained with likelihood-weighted importance sampling. This approach allows for the efficient inference of theoretical parameters in high-dimensional inverse problems without the need for posterior training samples. We implement the method on multi-modal benchmark tasks in 2D and 3D to check for the efficacy. A critical observation of our study is the impact of the topology of the base distributions on the modelled posteriors. We find that standard unimodal base distributions fail to capture disconnected support, resulting in spurious probability bridges between modes. We demonstrate that initializing the flow with a Gaussian Mixture Model that matches the cardinality of the target modes significantly improves reconstruction fidelity, as measured by some distance and divergence metrics.","authors":["Rajneil Baruah"],"pdf_url":"","comment":"14 pages, 8 figures, 3 Tables"},{"id":"http://arxiv.org/abs/2602.18060v1","updated":"2026-02-20T08:27:43Z","published":"2026-02-20T08:27:43Z","title":"Deepmechanics","summary":"Physics-informed deep learning models have emerged as powerful tools for learning dynamical systems. These models directly encode physical principles into network architectures. However, systematic benchmarking of these approaches across diverse physical phenomena remains limited, particularly in conservative and dissipative systems. In addition, benchmarking that has been done thus far does not integrate out full trajectories to check stability. In this work, we benchmark three prominent physics-informed architectures such as Hamiltonian Neural Networks (HNN), Lagrangian Neural Networks (LNN), and Symplectic Recurrent Neural Networks (SRNN) using the DeepChem framework, an open-source scientific machine learning library. We evaluate these models on six dynamical systems spanning classical conservative mechanics (mass-spring system, simple pendulum, double pendulum, and three-body problem, spring-pendulum) and non-conservative systems with contact (bouncing ball). We evaluate models by computing error on predicted trajectories and evaluate error both quantitatively and qualitatively. We find that all benchmarked models struggle to maintain stability for chaotic or nonconservative systems. Our results suggest that more research is needed for physics-informed deep learning models to learn robust models of classical mechanical systems.","authors":["Abhay Shinde","Aryan Amit Barsainyan","Jose Siguenza","Ankita Vaishnobi Bisoi","Rakshit Kr. Singh","Bharath Ramsundar"],"pdf_url":"","comment":"11 pages, 7 figures, Submitted to KDD 2026"},{"id":"http://arxiv.org/abs/2602.18055v1","updated":"2026-02-20T08:15:28Z","published":"2026-02-20T08:15:28Z","title":"Continual-NExT: A Unified Comprehension And Generation Continual Learning Framework","summary":"Dual-to-Dual MLLMs refer to Multimodal Large Language Models, which can enable unified multimodal comprehension and generation through text and image modalities. Although exhibiting strong instantaneous learning and generalization capabilities, Dual-to-Dual MLLMs still remain deficient in lifelong evolution, significantly affecting continual adaptation to dynamic real-world scenarios. One of the challenges is that learning new tasks inevitably destroys the learned knowledge. Beyond traditional catastrophic forgetting, Dual-to-Dual MLLMs face other challenges, including hallucination, instruction unfollowing, and failures in cross-modal knowledge transfer. However, no standardized continual learning framework for Dual-to-Dual MLLMs has been established yet, leaving these challenges unexplored. Thus, in this paper, we establish Continual-NExT, a continual learning framework for Dual-to-Dual MLLMs with deliberately-architected evaluation metrics. To improve the continual learning capability of Dual-to-Dual MLLMs, we propose an efficient MAGE (Mixture and Aggregation of General LoRA and Expert LoRA) method to further facilitate knowledge transfer across modalities and mitigate forgetting. Extensive experiments demonstrate that MAGE outperforms other continual learning methods and achieves state-of-the-art performance.","authors":["Jingyang Qiao","Zhizhong Zhang","Xin Tan","Jingyu Gong","Yanyun Qu","Yuan Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18053v1","updated":"2026-02-20T08:10:11Z","published":"2026-02-20T08:10:11Z","title":"On the Generalization and Robustness in Conditional Value-at-Risk","summary":"Conditional Value-at-Risk (CVaR) is a widely used risk-sensitive objective for learning under rare but high-impact losses, yet its statistical behavior under heavy-tailed data remains poorly understood. Unlike expectation-based risk, CVaR depends on an endogenous, data-dependent quantile, which couples tail averaging with threshold estimation and fundamentally alters both generalization and robustness properties. In this work, we develop a learning-theoretic analysis of CVaR-based empirical risk minimization under heavy-tailed and contaminated data. We establish sharp, high-probability generalization and excess risk bounds under minimal moment assumptions, covering fixed hypotheses, finite and infinite classes, and extending to $β$-mixing dependent data; we further show that these rates are minimax optimal. To capture the intrinsic quantile sensitivity of CVaR, we derive a uniform Bahadur-Kiefer type expansion that isolates a threshold-driven error term absent in mean-risk ERM and essential in heavy-tailed regimes. We complement these results with robustness guarantees by proposing a truncated median-of-means CVaR estimator that achieves optimal rates under adversarial contamination. Finally, we show that CVaR decisions themselves can be intrinsically unstable under heavy tails, establishing a fundamental limitation on decision robustness even when the population optimum is well separated. Together, our results provide a principled characterization of when CVaR learning generalizes and is robust, and when instability is unavoidable due to tail scarcity.","authors":["Dinesh Karthik Mulumudi","Piyushi Manupriya","Gholamali Aminian","Anant Raj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.20198v2","updated":"2026-02-20T08:09:00Z","published":"2026-01-28T02:53:39Z","title":"DeRaDiff: Denoising Time Realignment of Diffusion Models","summary":"Recent advances align diffusion models with human preferences to increase aesthetic appeal and mitigate artifacts and biases. Such methods aim to maximize a conditional output distribution aligned with higher rewards whilst not drifting far from a pretrained prior. This is commonly enforced by KL (Kullback Leibler) regularization. As such, a central issue still remains: how does one choose the right regularization strength? Too high of a strength leads to limited alignment and too low of a strength leads to \"reward hacking\". This renders the task of choosing the correct regularization strength highly non-trivial. Existing approaches sweep over this hyperparameter by aligning a pretrained model at multiple regularization strengths and then choose the best strength. Unfortunately, this is prohibitively expensive. We introduce DeRaDiff, a denoising time realignment procedure that, after aligning a pretrained model once, modulates the regularization strength during sampling to emulate models trained at other regularization strengths without any additional training or finetuning. Extending decoding-time realignment from language to diffusion models, DeRaDiff operates over iterative predictions of continuous latents by replacing the reverse step reference distribution by a geometric mixture of an aligned and reference posterior, thus giving rise to a closed form update under common schedulers and a single tunable parameter, lambda, for on the fly control. Our experiments show that across multiple text image alignment and image-quality metrics, our method consistently provides a strong approximation for models aligned entirely from scratch at different regularization strengths. Thus, our method yields an efficient way to search for the optimal strength, eliminating the need for expensive alignment sweeps and thereby substantially reducing computational costs.","authors":["Ratnavibusena Don Shahain Manujith","Teoh Tze Tzun","Kenji Kawaguchi","Yang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18047v1","updated":"2026-02-20T08:00:17Z","published":"2026-02-20T08:00:17Z","title":"CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras","summary":"City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.","authors":["Rong Fu","Wenxin Zhang","Yibo Meng","Jia Yee Tan","Jiaxuan Lu","Rui Lu","Jiekai Wu","Zhaolu Kang","Simon Fong"],"pdf_url":"","comment":"36 pages, 12 figures"},{"id":"http://arxiv.org/abs/2505.17748v2","updated":"2026-02-20T07:51:22Z","published":"2025-05-23T11:15:21Z","title":"Soft-CAM: Making black box models self-explainable for medical image analysis","summary":"Convolutional neural networks (CNNs) are widely used for high-stakes applications like medicine, often surpassing human performance. However, most explanation methods rely on post-hoc attribution, approximating the decision-making process of already trained black-box models. These methods are often sensitive, unreliable, and fail to reflect true model reasoning, limiting their trustworthiness in critical applications. In this work, we introduce SoftCAM, a straightforward yet effective approach that makes standard CNN architectures inherently interpretable. By removing the global average pooling layer and replacing the fully connected classification layer with a convolution-based class evidence layer, SoftCAM preserves spatial information and produces explicit class activation maps that form the basis of the model's predictions. Evaluated on three medical datasets, SoftCAM maintains classification performance while significantly improving both the qualitative and quantitative explanation compared to existing post-hoc methods. Our results demonstrate that CNNs can be inherently interpretable without compromising performance, advancing the development of self-explainable deep learning for high-stakes decision-making. The code is available at https://github.com/kdjoumessi/SoftCAM","authors":["Kerol Djoumessi","Philipp Berens"],"pdf_url":"","comment":"Accepted at the Medical Imaging with Deep Learning Conference (MIDL 2026)"},{"id":"http://arxiv.org/abs/2506.22095v5","updated":"2026-02-20T07:47:01Z","published":"2025-06-27T10:25:58Z","title":"Beyond Simple Graphs: Neural Multi-Objective Routing on Multigraphs","summary":"Learning-based methods for routing have gained significant attention in recent years, both in single-objective and multi-objective contexts. Yet, existing methods are unsuitable for routing on multigraphs, which feature multiple edges with distinct attributes between node pairs, despite their strong relevance in real-world scenarios. In this paper, we propose two graph neural network-based methods to address multi-objective routing on multigraphs. Our first approach operates directly on the multigraph by autoregressively selecting edges until a tour is completed. The second model, which is more scalable, first simplifies the multigraph via a learned pruning strategy and then performs autoregressive routing on the resulting simple graph. We evaluate both models empirically, across a wide range of problems and graph distributions, and demonstrate their competitive performance compared to strong heuristics and neural baselines.","authors":["Filip Rydin","Attila Lischka","Jiaming Wu","Morteza Haghir Chehreghani","Balázs Kulcsár"],"pdf_url":"","comment":"Accepted by ICLR 2026, Final Camera-Ready Version. 34 pages, 6 Figures"},{"id":"http://arxiv.org/abs/2602.18037v1","updated":"2026-02-20T07:32:22Z","published":"2026-02-20T07:32:22Z","title":"Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards","summary":"Reinforcement Learning from Human Feedback (RLHF) or Verifiable Rewards (RLVR) are two key steps in the post-training of modern Language Models (LMs). A common problem is reward hacking, where the policy may exploit inaccuracies of the reward and learn an unintended behavior. Most previous works address this by limiting the policy update with a Kullback-Leibler (KL) penalty towards a reference model. We propose a different framing: Train the LM in a way that biases policy updates towards regions in which the reward is more accurate. First, we derive a theoretical connection between the accuracy of a reward model and the flatness of an optimum at convergence. Gradient regularization (GR) can then be used to bias training to flatter regions and thereby maintain reward model accuracy. We confirm these results by showing that the gradient norm and reward accuracy are empirically correlated in RLHF. We then show that Reference Resets of the KL penalty implicitly use GR to find flatter regions with higher reward accuracy. We further improve on this by proposing to use explicit GR with an efficient finite-difference estimate. Empirically, GR performs better than a KL penalty across a diverse set of RL experiments with LMs. GR achieves a higher GPT-judged win-rate in RLHF, avoids overly focusing on the format in rule-based math rewards, and prevents hacking the judge in LLM-as-a-Judge math tasks.","authors":["Johannes Ackermann","Michael Noukhovitch","Takashi Ishida","Masashi Sugiyama"],"pdf_url":"","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2511.18721v2","updated":"2026-02-20T07:25:52Z","published":"2025-11-24T03:25:16Z","title":"Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM","summary":"The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict \"k-unstable\" assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, \"(k, $\\varepsilon$)-unstable,\" to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.","authors":["Adarsh Kumarappan","Ayushi Mehrotra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.14825v2","updated":"2026-02-20T07:15:17Z","published":"2025-05-20T18:40:17Z","title":"Assimilative Causal Inference","summary":"Causal inference is fundamental across scientific disciplines, yet existing methods struggle to capture instantaneous, time-evolving causal relationships in complex, high-dimensional systems. In this paper, assimilative causal inference (ACI) is developed, which is a methodological framework that leverages Bayesian data assimilation to trace causes backward from observed effects. ACI solves the inverse problem rather than quantifying forward influence. It uniquely identifies dynamic causal interactions without requiring observations of candidate causes, accommodates short datasets, and, in principle, can be implemented in high-dimensional settings by employing efficient data assimilation algorithms. Crucially, it provides online tracking of causal roles that may reverse intermittently and facilitates a mathematically rigorous criterion for the causal influence range, revealing how far effects propagate. The effectiveness of ACI is demonstrated by complex dynamical systems showcasing intermittency and extreme events. ACI opens valuable pathways for studying complex systems, where transient causal structures are critical.","authors":["Marios Andreou","Nan Chen","Erik Bollt"],"pdf_url":"","comment":"47 pages (Main Text pp. 1--17; Supplementary Information pp. 18--47), 11 figures (3 in Main Text, 8 in Supplementary Information). Published in Nature Communications. The MATLAB code used in the analyses and to generate the figures in this work can be found in https://github.com/marandmath/ACI_code . For further details visit https://mariosandreou.short.gy/ACI"},{"id":"http://arxiv.org/abs/2510.18322v2","updated":"2026-02-20T06:54:19Z","published":"2025-10-21T06:12:33Z","title":"Uncertainty Estimation by Flexible Evidential Deep Learning","summary":"Uncertainty quantification (UQ) is crucial for deploying machine learning models in high-stakes applications, where overconfident predictions can lead to serious consequences. An effective UQ method must balance computational efficiency with the ability to generalize across diverse scenarios. Evidential deep learning (EDL) achieves efficiency by modeling uncertainty through the prediction of a Dirichlet distribution over class probabilities. However, the restrictive assumption of Dirichlet-distributed class probabilities limits EDL's robustness, particularly in complex or unforeseen situations. To address this, we propose \\textit{flexible evidential deep learning} ($\\mathcal{F}$-EDL), which extends EDL by predicting a flexible Dirichlet distribution -- a generalization of the Dirichlet distribution -- over class probabilities. This approach provides a more expressive and adaptive representation of uncertainty, significantly enhancing UQ generalization and reliability under challenging scenarios. We theoretically establish several advantages of $\\mathcal{F}$-EDL and empirically demonstrate its state-of-the-art UQ performance across diverse evaluation settings, including classical, long-tailed, and noisy in-distribution scenarios.","authors":["Taeseong Yoon","Heeyoung Kim"],"pdf_url":"","comment":"NeurIPS 2025"},{"id":"http://arxiv.org/abs/2602.18026v1","updated":"2026-02-20T06:42:08Z","published":"2026-02-20T06:42:08Z","title":"Mean-Field Reinforcement Learning without Synchrony","summary":"Mean-field reinforcement learning (MF-RL) scales multi-agent RL to large populations by reducing each agent's dependence on others to a single summary statistic -- the mean action. However, this reduction requires every agent to act at every time step; when some agents are idle, the mean action is simply undefined. Addressing asynchrony therefore requires a different summary statistic -- one that remains defined regardless of which agents act. The population distribution $μ\\in Δ(\\mathcal{O})$ -- the fraction of agents at each observation -- satisfies this requirement: its dimension is independent of $N$, and under exchangeability it fully determines each agent's reward and transition. Existing MF-RL theory, however, is built on the mean action and does not extend to $μ$. We therefore construct the Temporal Mean Field (TMF) framework around the population distribution $μ$ from scratch, covering the full spectrum from fully synchronous to purely sequential decision-making within a single theory. We prove existence and uniqueness of TMF equilibria, establish an $O(1/\\sqrt{N})$ finite-population approximation bound that holds regardless of how many agents act per step, and prove convergence of a policy gradient algorithm (TMF-PG) to the unique equilibrium. Experiments on a resource selection game and a dynamic queueing game confirm that TMF-PG achieves near-identical performance whether one agent or all $N$ act per step, with approximation error decaying at the predicted $O(1/\\sqrt{N})$ rate.","authors":["Shan Yang"],"pdf_url":"","comment":"21 pages, 5 figures, 1 algorithm"},{"id":"http://arxiv.org/abs/2502.16189v2","updated":"2026-02-20T06:37:32Z","published":"2025-02-22T11:22:08Z","title":"Co-Evolution-Based Metal-Binding Residue Prediction with Graph Neural Networks","summary":"Understanding protein-metal interactions is central to structural biology, with metal ions being vital for catalysis, stability, and signal transduction. Predicting metal-binding residues and metal types remains challenging due to the structural and evolutionary complexity of proteins. Conventional sequence- and structure-based methods often fail to capture co-evolutionary constraints that reflect how residues evolve together to maintain metal-binding functionality. Recent co-evolution-based methods capture part of this information, but still underutilize the complete co-evolved residue network. To address this limitation, we introduce the Metal-Binding Graph Neural Network (MBGNN), which leverages the complete co-evolved residue network to better capture complex dependencies within protein structures. Experimental results show that MBGNN substantially outperforms the state-of-the-art co-evolution-based method MetalNet2, achieving F1 score improvements of 2.5% for binding residue identification and 3.3% for metal type classification on the MetalNet2 dataset. Its superiority is further demonstrated on both the MetalNet2 and MIonSite datasets, where it outperforms two co-evolution-based and two sequence-based methods, achieving the highest mean F1 scores across both prediction tasks. These findings highlight how integrating co-evolutionary residue networks with graph-based learning advances our ability to decode protein-metal interactions, thereby facilitating functional annotation and rational metalloprotein design. The code and data are released at https://github.com/SRastegari/MBGNN.","authors":["Sayedmohammadreza Rastegari","Sina Tabakhi","Xianyuan Liu","Tianyi Jiang","Wei Sang","Haiping Lu"],"pdf_url":"","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.17080v2","updated":"2026-02-20T06:23:33Z","published":"2026-02-19T05:00:39Z","title":"Adam Improves Muon: Adaptive Moment Estimation with Orthogonalized Momentum","summary":"Efficient stochastic optimization typically integrates an update direction that performs well in the deterministic regime with a mechanism adapting to stochastic perturbations. While Adam uses adaptive moment estimates to promote stability, Muon utilizes the weight layers' matrix structure via orthogonalized momentum, showing superior performance in large language model training. We propose a new optimizer and a diagonal extension, NAMO and NAMO-D, providing the first principled integration of orthogonalized momentum with norm-based Adam-type noise adaptation. NAMO scales orthogonalized momentum using a single adaptive stepsize, preserving orthogonality while improving upon Muon at negligible additional cost. NAMO-D instead right-multiplies orthogonalized momentum by a diagonal matrix with clamped entries. This design enables neuron-wise noise adaptation and aligns with the common near block-diagonal Hessian structure. Under standard assumptions, we establish optimal convergence rates for both algorithms in the deterministic setting and show that, in the stochastic setting, their convergence guarantees adapt to the noise level of stochastic gradients. Experiments on pretraining GPT-2 models demonstrate improved performance of both NAMO and NAMO-D compared to the AdamW and Muon baselines, with NAMO-D achieving further gains over NAMO via an additional clamping hyperparameter that balances the competing goals of maintaining a well-conditioned update direction and leveraging fine-grained noise adaptation.","authors":["Minxin Zhang","Yuxuan Liu","Hayden Schaeffer"],"pdf_url":"","comment":"39 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.18015v1","updated":"2026-02-20T06:11:12Z","published":"2026-02-20T06:11:12Z","title":"Flow Actor-Critic for Offline Reinforcement Learning","summary":"The dataset distributions in offline reinforcement learning (RL) often exhibit complex and multi-modal distributions, necessitating expressive policies to capture such distributions beyond widely-used Gaussian policies. To handle such complex and multi-modal datasets, in this paper, we propose Flow Actor-Critic, a new actor-critic method for offline RL, based on recent flow policies. The proposed method not only uses the flow model for actor as in previous flow policies but also exploits the expressive flow model for conservative critic acquisition to prevent Q-value explosion in out-of-data regions. To this end, we propose a new form of critic regularizer based on the flow behavior proxy model obtained as a byproduct of flow-based actor design. Leveraging the flow model in this joint way, we achieve new state-of-the-art performance for test datasets of offline RL including the D4RL and recent OGBench benchmarks.","authors":["Jongseong Chae","Jongeui Park","Yongjae Shin","Gyeongmin Kim","Seungyul Han","Youngchul Sung"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2505.17064v3","updated":"2026-02-20T05:52:53Z","published":"2025-05-18T13:35:23Z","title":"Synthetic History: Evaluating Visual Representations of the Past in Diffusion Models","summary":"As Text-to-Image (TTI) diffusion models become increasingly influential in content creation, growing attention is being directed toward their societal and cultural implications. While prior research has primarily examined demographic and cultural biases, the ability of these models to accurately represent historical contexts remains largely underexplored. To address this gap, we introduce a benchmark for evaluating how TTI models depict historical contexts. The benchmark combines HistVis, a dataset of 30,000 synthetic images generated by three state-of-the-art diffusion models from carefully designed prompts covering universal human activities across multiple historical periods, with a reproducible evaluation protocol. We evaluate generated imagery across three key aspects: (1) Implicit Stylistic Associations: examining default visual styles associated with specific eras; (2) Historical Consistency: identifying anachronisms such as modern artifacts in pre-modern contexts; and (3) Demographic Representation: comparing generated racial and gender distributions against historically plausible baselines. Our findings reveal systematic inaccuracies in historically themed generated imagery, as TTI models frequently stereotype past eras by incorporating unstated stylistic cues, introduce anachronisms, and fail to reflect plausible demographic patterns. By providing a reproducible benchmark for historical representation in generated imagery, this work provides an initial step toward building more historically accurate TTI models.","authors":["Maria-Teresa De Rosa Palmini","Eva Cetinic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18008v1","updated":"2026-02-20T05:46:54Z","published":"2026-02-20T05:46:54Z","title":"NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs","summary":"Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem settings substantially oversimplify real-world conditions, leaving it unclear whether LLM-generated mechanistic models are reliable in practice. To address this gap, we introduce the Neural-Integrated Mechanistic Modeling (NIMM) evaluation framework, which evaluates LLM-generated mechanistic models under realistic settings with partial observations and diversified task objectives. Our evaluation reveals fundamental challenges in current baselines, ranging from model effectiveness to code-level correctness. Motivated by these findings, we design NIMMgen, an agentic framework for neural-integrated mechanistic modeling that enhances code correctness and practical validity through iterative refinement. Experiments across three datasets from diversified scientific domains demonstrate its strong performance. We also show that the learned mechanistic models support counterfactual intervention simulation.","authors":["Zihan Guan","Rituparna Datta","Mengxuan Hu","Shunshun Liu","Aiying Zhang","Prasanna Balachandran","Sheng Li","Anil Vullikanti"],"pdf_url":"","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.18002v1","updated":"2026-02-20T05:28:48Z","published":"2026-02-20T05:28:48Z","title":"Asynchronous Heavy-Tailed Optimization","summary":"Heavy-tailed stochastic gradient noise, commonly observed in transformer models, can destabilize the optimization process. Recent works mainly focus on developing and understanding approaches to address heavy-tailed noise in the centralized or distributed, synchronous setting, leaving the interactions between such noise and asynchronous optimization underexplored. In this work, we investigate two communication schemes that handle stragglers with asynchronous updates in the presence of heavy-tailed gradient noise. We propose and theoretically analyze algorithmic modifications based on delay-aware learning rate scheduling and delay compensation to enhance the performance of asynchronous algorithms. Our convergence guarantees under heavy-tailed noise match the rate of the synchronous counterparts and improve delay tolerance compared with existing asynchronous approaches. Empirically, our approaches outperform prior synchronous and asynchronous methods in terms of accuracy/runtime trade-offs and are more robust to hyperparameters in both image and language tasks.","authors":["Junfei Sun","Dixi Yao","Xuchen Gong","Tahseen Rabbani","Manzil Zaheer","Tian Li"],"pdf_url":"","comment":"8-page main body, 25-page appendix, 5 figures"},{"id":"http://arxiv.org/abs/2602.17998v1","updated":"2026-02-20T05:23:40Z","published":"2026-02-20T05:23:40Z","title":"PHAST: Port-Hamiltonian Architecture for Structured Temporal Dynamics Forecasting","summary":"Real physical systems are dissipative -- a pendulum slows, a circuit loses charge to heat -- and forecasting their dynamics from partial observations is a central challenge in scientific machine learning. We address the \\emph{position-only} (q-only) problem: given only generalized positions~$q_t$ at discrete times (momenta~$p_t$ latent), learn a structured model that (a)~produces stable long-horizon forecasts and (b)~recovers physically meaningful parameters when sufficient structure is provided. The port-Hamiltonian framework makes the conservative-dissipative split explicit via $\\dot{x}=(J-R)\\nabla H(x)$, guaranteeing $dH/dt\\le 0$ when $R\\succeq 0$. We introduce \\textbf{PHAST} (Port-Hamiltonian Architecture for Structured Temporal dynamics), which decomposes the Hamiltonian into potential~$V(q)$, mass~$M(q)$, and damping~$D(q)$ across three knowledge regimes (KNOWN, PARTIAL, UNKNOWN), uses efficient low-rank PSD/SPD parameterizations, and advances dynamics with Strang splitting. Across thirteen q-only benchmarks spanning mechanical, electrical, molecular, thermal, gravitational, and ecological systems, PHAST achieves the best long-horizon forecasting among competitive baselines and enables physically meaningful parameter recovery when the regime provides sufficient anchors. We show that identification is fundamentally ill-posed without such anchors (gauge freedom), motivating a two-axis evaluation that separates forecasting stability from identifiability.","authors":["Shubham Bhardwaj","Chandrajit Bajaj"],"pdf_url":"","comment":"50 pages"},{"id":"http://arxiv.org/abs/2602.17997v1","updated":"2026-02-20T05:09:28Z","published":"2026-02-20T05:09:28Z","title":"Whole-Brain Connectomic Graph Model Enables Whole-Body Locomotion Control in Fruit Fly","summary":"Whole-brain biological neural networks naturally support the learning and control of whole-body movements. However, the use of brain connectomes as neural network controllers in embodied reinforcement learning remains unexplored. We investigate using the exact neural architecture of an adult fruit fly's brain for the control of its body movement. We develop Fly-connectomic Graph Model (FlyGM), whose static structure is identical to the complete connectome of an adult Drosophila for whole-body locomotion control. To perform dynamical control, FlyGM represents the static connectome as a directed message-passing graph to impose a biologically grounded information flow from sensory inputs to motor outputs. Integrated with a biomechanical fruit fly model, our method achieves stable control across diverse locomotion tasks without task-specific architectural tuning. To verify the structural advantages of the connectome-based model, we compare it against a degree-preserving rewired graph, a random graph, and multilayer perceptrons, showing that FlyGM yields higher sample efficiency and superior performance. This work demonstrates that static brain connectomes can be transformed to instantiate effective neural policy for embodied learning of movement control.","authors":["Zehao Jin","Yaoye Zhu","Chen Zhang","Yanan Sui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.08621v4","updated":"2026-02-20T05:06:25Z","published":"2024-02-13T17:42:27Z","title":"A Unified Framework for Analyzing Meta-algorithms in Online Convex Optimization","summary":"In this paper, we analyze the problem of online convex optimization in different settings, including different feedback types (full-information/semi-bandit/bandit/etc) in either stochastic or non-stochastic setting and different notions of regret (static adversarial regret/dynamic regret/adaptive regret). This is done through a framework which allows us to systematically propose and analyze meta-algorithms for the various settings described above. We show that any algorithm for online linear optimization with deterministic gradient feedback against fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, recovers several results in the literature with a simplified proof technique, and provides new results.","authors":["Mohammad Pedramfar","Vaneet Aggarwal"],"pdf_url":"","comment":"in Proc. AAMAS 2026"},{"id":"http://arxiv.org/abs/2602.17993v1","updated":"2026-02-20T05:01:32Z","published":"2026-02-20T05:01:32Z","title":"Turbo Connection: Reasoning as Information Flow from Higher to Lower Layers","summary":"Complex problems, whether in math, logic, or planning, are solved by humans through a sequence of steps where the result of one step informs the next. In this work, we adopt the perspective that the reasoning power of Transformers is fundamentally limited by a fixed maximum number of steps along any latent path of computation. To address this, we introduce Turbo Connection (TurboConn), a novel architecture that overcomes the fixed-depth constraint by routing multiple residual connections from the higher-layer hidden states of each token $t$ to the lower layers of token $t+1$. Fine-tuning pre-trained LLMs with our method not only yields accuracy gains of 0.9% to over 10% on benchmarks like GSM8K, Parity, and multi-step arithmetic, but also demonstrates that the density of these backward connections is critical; our dense interaction significantly outperforms \"sparse\" alternatives that only pass a single hidden state or vector. Notably, TurboConn can be integrated into pre-trained LLMs to overcome task-specific plateaus: while a fine-tuned Qwen-3-1.7B achieves only 53.78% on Parity, adding our architectural modification enables the model to reach 100% accuracy, all without the necessity to retrain the full model from scratch or sophisticated curriculum learning. Our results provide strong empirical evidence that the depth of the computational path is a key factor in reasoning ability, also offering a new mechanism to enhance LLMs without significantly affecting generation latency.","authors":["Mohan Tang","Sidi Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17985v1","updated":"2026-02-20T04:42:06Z","published":"2026-02-20T04:42:06Z","title":"Learning Without Training","summary":"Machine learning is at the heart of managing the real-world problems associated with massive data. With the success of neural networks on such large-scale problems, more research in machine learning is being conducted now than ever before. This dissertation focuses on three different projects rooted in mathematical theory for machine learning applications.\n  The first project deals with supervised learning and manifold learning. In theory, one of the main problems in supervised learning is that of function approximation: that is, given some data set $\\mathcal{D}=\\{(x_j,f(x_j))\\}_{j=1}^M$, can one build a model $F\\approx f$? We introduce a method which aims to remedy several of the theoretical shortcomings of the current paradigm for supervised learning.\n  The second project deals with transfer learning, which is the study of how an approximation process or model learned on one domain can be leveraged to improve the approximation on another domain. We study such liftings of functions when the data is assumed to be known only on a part of the whole domain. We are interested in determining subsets of the target data space on which the lifting can be defined, and how the local smoothness of the function and its lifting are related.\n  The third project is concerned with the classification task in machine learning, particularly in the active learning paradigm. Classification has often been treated as an approximation problem as well, but we propose an alternative approach leveraging techniques originally introduced for signal separation problems. We introduce theory to unify signal separation with classification and a new algorithm which yields competitive accuracy to other recent active learning algorithms while providing results much faster.","authors":["Ryan O'Dowd"],"pdf_url":"","comment":"PhD Dissertation of Ryan O'Dowd, defended successfully at Claremont Graduate University on 1/28/2026"},{"id":"http://arxiv.org/abs/2602.17978v1","updated":"2026-02-20T04:24:49Z","published":"2026-02-20T04:24:49Z","title":"Learning Optimal and Sample-Efficient Decision Policies with Guarantees","summary":"The paradigm of decision-making has been revolutionised by reinforcement learning and deep learning. Although this has led to significant progress in domains such as robotics, healthcare, and finance, the use of RL in practice is challenging, particularly when learning decision policies in high-stakes applications that may require guarantees. Traditional RL algorithms rely on a large number of online interactions with the environment, which is problematic in scenarios where online interactions are costly, dangerous, or infeasible. However, learning from offline datasets is hindered by the presence of hidden confounders. Such confounders can cause spurious correlations in the dataset and can mislead the agent into taking suboptimal or adversarial actions. Firstly, we address the problem of learning from offline datasets in the presence of hidden confounders. We work with instrumental variables (IVs) to identify the causal effect, which is an instance of a conditional moment restrictions (CMR) problem. Inspired by double/debiased machine learning, we derive a sample-efficient algorithm for solving CMR problems with convergence and optimality guarantees, which outperforms state-of-the-art algorithms. Secondly, we relax the conditions on the hidden confounders in the setting of (offline) imitation learning, and adapt our CMR estimator to derive an algorithm that can learn effective imitator policies with convergence rate guarantees. Finally, we consider the problem of learning high-level objectives expressed in linear temporal logic (LTL) and develop a provably optimal learning algorithm that improves sample efficiency over existing methods. Through evaluation on reinforcement learning benchmarks and synthetic and semi-synthetic datasets, we demonstrate the usefulness of the methods developed in this thesis in real-world decision making.","authors":["Daqian Shao"],"pdf_url":"","comment":"A thesis submitted for the degree of DPhil in Computer Science at Oxford"},{"id":"http://arxiv.org/abs/2501.14249v10","updated":"2026-02-20T04:23:01Z","published":"2025-01-24T05:27:46Z","title":"Humanity's Last Exam","summary":"Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90\\% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. HLE consists of 2,500 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading. Each question has a known solution that is unambiguous and easily verifiable, but cannot be quickly answered via internet retrieval. State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions. To inform research and policymaking upon a clear understanding of model capabilities, we publicly release HLE at https://lastexam.ai.","authors":["Long Phan","Alice Gatti","Ziwen Han","Nathaniel Li","Josephina Hu","Hugh Zhang","Chen Bo Calvin Zhang","Mohamed Shaaban","John Ling","Sean Shi","Michael Choi","Anish Agrawal","Arnav Chopra","Adam Khoja","Ryan Kim","Richard Ren","Jason Hausenloy","Oliver Zhang","Mantas Mazeika","Dmitry Dodonov","Tung Nguyen","Jaeho Lee","Daron Anderson","Mikhail Doroshenko","Alun Cennyth Stokes","Mobeen Mahmood","Oleksandr Pokutnyi","Oleg Iskra","Jessica P. Wang","John-Clark Levin","Mstyslav Kazakov","Fiona Feng","Steven Y. Feng","Haoran Zhao","Michael Yu","Varun Gangal","Chelsea Zou","Zihan Wang","Serguei Popov","Robert Gerbicz","Geoff Galgon","Johannes Schmitt","Will Yeadon","Yongki Lee","Scott Sauers","Alvaro Sanchez","Fabian Giska","Marc Roth","Søren Riis","Saiteja Utpala","Noah Burns","Gashaw M. Goshu","Mohinder Maheshbhai Naiya","Chidozie Agu","Zachary Giboney","Antrell Cheatom","Francesco Fournier-Facio","Sarah-Jane Crowson","Lennart Finke","Zerui Cheng","Jennifer Zampese","Ryan G. Hoerr","Mark Nandor","Hyunwoo Park","Tim Gehrunger","Jiaqi Cai","Ben McCarty","Alexis C Garretson","Edwin Taylor","Damien Sileo","Qiuyu Ren","Usman Qazi","Lianghui Li","Jungbae Nam","John B. Wydallis","Pavel Arkhipov","Jack Wei Lun Shi","Aras Bacho","Chris G. Willcocks","Hangrui Cao","Sumeet Motwani","Emily de Oliveira Santos","Johannes Veith","Edward Vendrow","Doru Cojoc","Kengo Zenitani","Joshua Robinson","Longke Tang","Yuqi Li","Joshua Vendrow","Natanael Wildner Fraga","Vladyslav Kuchkin","Andrey Pupasov Maksimov","Pierre Marion","Denis Efremov","Jayson Lynch","Kaiqu Liang","Aleksandar Mikov","Andrew Gritsevskiy","Julien Guillod","Gözdenur Demir","Dakotah Martinez","Ben Pageler","Kevin Zhou","Saeed Soori","Ori Press","Henry Tang","Paolo Rissone","Sean R. Green","Lina Brüssel","Moon Twayana","Aymeric Dieuleveut","Joseph Marvin Imperial","Ameya Prabhu","Jinzhou Yang","Nick Crispino","Arun Rao","Dimitri Zvonkine","Gabriel Loiseau","Mikhail Kalinin","Marco Lukas","Ciprian Manolescu","Nate Stambaugh","Subrata Mishra","Tad Hogg","Carlo Bosio","Brian P Coppola","Julian Salazar","Jaehyeok Jin","Rafael Sayous","Stefan Ivanov","Philippe Schwaller","Shaipranesh Senthilkuma","Andres M Bran","Andres Algaba","Kelsey Van den Houte","Lynn Van Der Sypt","Brecht Verbeken","David Noever","Alexei Kopylov","Benjamin Myklebust","Bikun Li","Lisa Schut","Evgenii Zheltonozhskii","Qiaochu Yuan","Derek Lim","Richard Stanley","Tong Yang","John Maar","Julian Wykowski","Martí Oller","Anmol Sahu","Cesare Giulio Ardito","Yuzheng Hu","Ariel Ghislain Kemogne Kamdoum","Alvin Jin","Tobias Garcia Vilchis","Yuexuan Zu","Martin Lackner","James Koppel","Gongbo Sun","Daniil S. Antonenko","Steffi Chern","Bingchen Zhao","Pierrot Arsene","Joseph M Cavanagh","Daofeng Li","Jiawei Shen","Donato Crisostomi","Wenjin Zhang","Ali Dehghan","Sergey Ivanov","David Perrella","Nurdin Kaparov","Allen Zang","Ilia Sucholutsky","Arina Kharlamova","Daniil Orel","Vladislav Poritski","Shalev Ben-David","Zachary Berger","Parker Whitfill","Michael Foster","Daniel Munro","Linh Ho","Shankar Sivarajan","Dan Bar Hava","Aleksey Kuchkin","David Holmes","Alexandra Rodriguez-Romero","Frank Sommerhage","Anji Zhang","Richard Moat","Keith Schneider","Zakayo Kazibwe","Don Clarke","Dae Hyun Kim","Felipe Meneguitti Dias","Sara Fish","Veit Elser","Tobias Kreiman","Victor Efren Guadarrama Vilchis","Immo Klose","Ujjwala Anantheswaran","Adam Zweiger","Kaivalya Rawal","Jeffery Li","Jeremy Nguyen","Nicolas Daans","Haline Heidinger","Maksim Radionov","Václav Rozhoň","Vincent Ginis","Christian Stump","Niv Cohen","Rafał Poświata","Josef Tkadlec","Alan Goldfarb","Chenguang Wang","Piotr Padlewski","Stanislaw Barzowski","Kyle Montgomery","Ryan Stendall","Jamie Tucker-Foltz","Jack Stade","T. Ryan Rogers","Tom Goertzen","Declan Grabb","Abhishek Shukla","Alan Givré","John Arnold Ambay","Archan Sen","Muhammad Fayez Aziz","Mark H Inlow","Hao He","Ling Zhang","Younesse Kaddar","Ivar Ängquist","Yanxu Chen","Harrison K Wang","Kalyan Ramakrishnan","Elliott Thornley","Antonio Terpin","Hailey Schoelkopf","Eric Zheng","Avishy Carmi","Ethan D. L. Brown","Kelin Zhu","Max Bartolo","Richard Wheeler","Martin Stehberger","Peter Bradshaw","JP Heimonen","Kaustubh Sridhar","Ido Akov","Jennifer Sandlin","Yury Makarychev","Joanna Tam","Hieu Hoang","David M. Cunningham","Vladimir Goryachev","Demosthenes Patramanis","Michael Krause","Andrew Redenti","David Aldous","Jesyin Lai","Shannon Coleman","Jiangnan Xu","Sangwon Lee","Ilias Magoulas","Sandy Zhao","Ning Tang","Michael K. Cohen","Orr Paradise","Jan Hendrik Kirchner","Maksym Ovchynnikov","Jason O. Matos","Adithya Shenoy","Michael Wang","Yuzhou Nie","Anna Sztyber-Betley","Paolo Faraboschi","Robin Riblet","Jonathan Crozier","Shiv Halasyamani","Shreyas Verma","Prashant Joshi","Eli Meril","Ziqiao Ma","Jérémy Andréoletti","Raghav Singhal","Jacob Platnick","Volodymyr Nevirkovets","Luke Basler","Alexander Ivanov","Seri Khoury","Nils Gustafsson","Marco Piccardo","Hamid Mostaghimi","Qijia Chen","Virendra Singh","Tran Quoc Khánh","Paul Rosu","Hannah Szlyk","Zachary Brown","Himanshu Narayan","Aline Menezes","Jonathan Roberts","William Alley","Kunyang Sun","Arkil Patel","Max Lamparth","Anka Reuel","Linwei Xin","Hanmeng Xu","Jacob Loader","Freddie Martin","Zixuan Wang","Andrea Achilleos","Thomas Preu","Tomek Korbak","Ida Bosio","Fereshteh Kazemi","Ziye Chen","Biró Bálint","Eve J. Y. Lo","Jiaqi Wang","Maria Inês S. Nunes","Jeremiah Milbauer","M Saiful Bari","Zihao Wang","Behzad Ansarinejad","Yewen Sun","Stephane Durand","Hossam Elgnainy","Guillaume Douville","Daniel Tordera","George Balabanian","Hew Wolff","Lynna Kvistad","Hsiaoyun Milliron","Ahmad Sakor","Murat Eron","Andrew Favre D. O.","Shailesh Shah","Xiaoxiang Zhou","Firuz Kamalov","Sherwin Abdoli","Tim Santens","Shaul Barkan","Allison Tee","Robin Zhang","Alessandro Tomasiello","G. Bruno De Luca","Shi-Zhuo Looi","Vinh-Kha Le","Noam Kolt","Jiayi Pan","Emma Rodman","Jacob Drori","Carl J Fossum","Niklas Muennighoff","Milind Jagota","Ronak Pradeep","Honglu Fan","Jonathan Eicher","Michael Chen","Kushal Thaman","William Merrill","Moritz Firsching","Carter Harris","Stefan Ciobâcă","Jason Gross","Rohan Pandey","Ilya Gusev","Adam Jones","Shashank Agnihotri","Pavel Zhelnov","Mohammadreza Mofayezi","Alexander Piperski","David K. Zhang","Kostiantyn Dobarskyi","Roman Leventov","Ignat Soroko","Joshua Duersch","Vage Taamazyan","Andrew Ho","Wenjie Ma","William Held","Ruicheng Xian","Armel Randy Zebaze","Mohanad Mohamed","Julian Noah Leser","Michelle X Yuan","Laila Yacar","Johannes Lengler","Katarzyna Olszewska","Claudio Di Fratta","Edson Oliveira","Joseph W. Jackson","Andy Zou","Muthu Chidambaram","Timothy Manik","Hector Haffenden","Dashiell Stander","Ali Dasouqi","Alexander Shen","Bita Golshani","David Stap","Egor Kretov","Mikalai Uzhou","Alina Borisovna Zhidkovskaya","Nick Winter","Miguel Orbegozo Rodriguez","Robert Lauff","Dustin Wehr","Colin Tang","Zaki Hossain","Shaun Phillips","Fortuna Samuele","Fredrik Ekström","Angela Hammon","Oam Patel","Faraz Farhidi","George Medley","Forough Mohammadzadeh","Madellene Peñaflor","Haile Kassahun","Alena Friedrich","Rayner Hernandez Perez","Daniel Pyda","Taom Sakal","Omkar Dhamane","Ali Khajegili Mirabadi","Eric Hallman","Kenchi Okutsu","Mike Battaglia","Mohammad Maghsoudimehrabani","Alon Amit","Dave Hulbert","Roberto Pereira","Simon Weber"," Handoko","Anton Peristyy","Stephen Malina","Mustafa Mehkary","Rami Aly","Frank Reidegeld","Anna-Katharina Dick","Cary Friday","Mukhwinder Singh","Hassan Shapourian","Wanyoung Kim","Mariana Costa","Hubeyb Gurdogan","Harsh Kumar","Chiara Ceconello","Chao Zhuang","Haon Park","Micah Carroll","Andrew R. Tawfeek","Stefan Steinerberger","Daattavya Aggarwal","Michael Kirchhof","Linjie Dai","Evan Kim","Johan Ferret","Jainam Shah","Yuzhou Wang","Minghao Yan","Krzysztof Burdzy","Lixin Zhang","Antonio Franca","Diana T. Pham","Kang Yong Loh","Joshua Robinson","Abram Jackson","Paolo Giordano","Philipp Petersen","Adrian Cosma","Jesus Colino","Colin White","Jacob Votava","Vladimir Vinnikov","Ethan Delaney","Petr Spelda","Vit Stritecky","Syed M. Shahid","Jean-Christophe Mourrat","Lavr Vetoshkin","Koen Sponselee","Renas Bacho","Zheng-Xin Yong","Florencia de la Rosa","Nathan Cho","Xiuyu Li","Guillaume Malod","Orion Weller","Guglielmo Albani","Leon Lang","Julien Laurendeau","Dmitry Kazakov","Fatimah Adesanya","Julien Portier","Lawrence Hollom","Victor Souza","Yuchen Anna Zhou","Julien Degorre","Yiğit Yalın","Gbenga Daniel Obikoya"," Rai","Filippo Bigi","M. C. Boscá","Oleg Shumar","Kaniuar Bacho","Gabriel Recchia","Mara Popescu","Nikita Shulga","Ngefor Mildred Tanwie","Thomas C. H. Lux","Ben Rank","Colin Ni","Matthew Brooks","Alesia Yakimchyk"," Huanxu"," Liu","Stefano Cavalleri","Olle Häggström","Emil Verkama","Joshua Newbould","Hans Gundlach","Leonor Brito-Santana","Brian Amaro","Vivek Vajipey","Rynaa Grover","Ting Wang","Yosi Kratish","Wen-Ding Li","Sivakanth Gopi","Andrea Caciolai","Christian Schroeder de Witt","Pablo Hernández-Cámara","Emanuele Rodolà","Jules Robins","Dominic Williamson","Vincent Cheng","Brad Raynor","Hao Qi","Ben Segev","Jingxuan Fan","Sarah Martinson","Erik Y. Wang","Kaylie Hausknecht","Michael P. Brenner","Mao Mao","Christoph Demian","Peyman Kassani","Xinyu Zhang","David Avagian","Eshawn Jessica Scipio","Alon Ragoler","Justin Tan","Blake Sims","Rebeka Plecnik","Aaron Kirtland","Omer Faruk Bodur","D. P. Shinde","Yan Carlos Leyva Labrador","Zahra Adoul","Mohamed Zekry","Ali Karakoc","Tania C. B. Santos","Samir Shamseldeen","Loukmane Karim","Anna Liakhovitskaia","Nate Resman","Nicholas Farina","Juan Carlos Gonzalez","Gabe Maayan","Earth Anderson","Rodrigo De Oliveira Pena","Elizabeth Kelley","Hodjat Mariji","Rasoul Pouriamanesh","Wentao Wu","Ross Finocchio","Ismail Alarab","Joshua Cole","Danyelle Ferreira","Bryan Johnson","Mohammad Safdari","Liangti Dai","Siriphan Arthornthurasuk","Isaac C. McAlister","Alejandro José Moyano","Alexey Pronin","Jing Fan","Angel Ramirez-Trinidad","Yana Malysheva","Daphiny Pottmaier","Omid Taheri","Stanley Stepanic","Samuel Perry","Luke Askew","Raúl Adrián Huerta Rodríguez","Ali M. R. Minissi","Ricardo Lorena","Krishnamurthy Iyer","Arshad Anil Fasiludeen","Ronald Clark","Josh Ducey","Matheus Piza","Maja Somrak","Eric Vergo","Juehang Qin","Benjámin Borbás","Eric Chu","Jack Lindsey","Antoine Jallon","I. M. J. McInnis","Evan Chen","Avi Semler","Luk Gloor","Tej Shah","Marc Carauleanu","Pascal Lauer","Tran Đuc Huy","Hossein Shahrtash","Emilien Duc","Lukas Lewark","Assaf Brown","Samuel Albanie","Brian Weber","Warren S. Vaz","Pierre Clavier","Yiyang Fan","Gabriel Poesia Reis e Silva"," Long"," Lian","Marcus Abramovitch","Xi Jiang","Sandra Mendoza","Murat Islam","Juan Gonzalez","Vasilios Mavroudis","Justin Xu","Pawan Kumar","Laxman Prasad Goswami","Daniel Bugas","Nasser Heydari","Ferenc Jeanplong","Thorben Jansen","Antonella Pinto","Archimedes Apronti","Abdallah Galal","Ng Ze-An","Ankit Singh","Tong Jiang","Joan of Arc Xavier","Kanu Priya Agarwal","Mohammed Berkani","Gang Zhang","Zhehang Du","Benedito Alves de Oliveira Junior","Dmitry Malishev","Nicolas Remy","Taylor D. Hartman","Tim Tarver","Stephen Mensah","Gautier Abou Loume","Wiktor Morak","Farzad Habibi","Sarah Hoback","Will Cai","Javier Gimenez","Roselynn Grace Montecillo","Jakub Łucki","Russell Campbell","Asankhaya Sharma","Khalida Meer","Shreen Gul","Daniel Espinosa Gonzalez","Xavier Alapont","Alex Hoover","Gunjan Chhablani","Freddie Vargus","Arunim Agarwal","Yibo Jiang","Deepakkumar Patil","David Outevsky","Kevin Joseph Scaria","Rajat Maheshwari","Abdelkader Dendane","Priti Shukla","Ashley Cartwright","Sergei Bogdanov","Niels Mündler","Sören Möller","Luca Arnaboldi","Kunvar Thaman","Muhammad Rehan Siddiqi","Prajvi Saxena","Himanshu Gupta","Tony Fruhauff","Glen Sherman","Mátyás Vincze","Siranut Usawasutsakorn","Dylan Ler","Anil Radhakrishnan","Innocent Enyekwe","Sk Md Salauddin","Jiang Muzhen","Aleksandr Maksapetyan","Vivien Rossbach","Chris Harjadi","Mohsen Bahaloohoreh","Claire Sparrow","Jasdeep Sidhu","Sam Ali","Song Bian","John Lai","Eric Singer","Justine Leon Uro","Greg Bateman","Mohamed Sayed","Ahmed Menshawy","Darling Duclosel","Dario Bezzi","Yashaswini Jain","Ashley Aaron","Murat Tiryakioglu","Sheeshram Siddh","Keith Krenek","Imad Ali Shah","Jun Jin","Scott Creighton","Denis Peskoff","Zienab EL-Wasif","Ragavendran P","Michael Richmond","Joseph McGowan","Tejal Patwardhan","Hao-Yu Sun","Ting Sun","Nikola Zubić","Samuele Sala","Stephen Ebert","Jean Kaddour","Manuel Schottdorf","Dianzhuo Wang","Gerol Petruzella","Alex Meiburg","Tilen Medved","Ali ElSheikh","S Ashwin Hebbar","Lorenzo Vaquero","Xianjun Yang","Jason Poulos","Vilém Zouhar","Sergey Bogdanik","Mingfang Zhang","Jorge Sanz-Ros","David Anugraha","Yinwei Dai","Anh N. Nhu","Xue Wang","Ali Anil Demircali","Zhibai Jia","Yuyin Zhou","Juncheng Wu","Mike He","Nitin Chandok","Aarush Sinha","Gaoxiang Luo","Long Le","Mickaël Noyé","Michał Perełkiewicz","Ioannis Pantidis","Tianbo Qi","Soham Sachin Purohit","Letitia Parcalabescu","Thai-Hoa Nguyen","Genta Indra Winata","Edoardo M. Ponti","Hanchen Li","Kaustubh Dhole","Jongee Park","Dario Abbondanza","Yuanli Wang","Anupam Nayak","Diogo M. Caetano","Antonio A. W. L. Wong","Maria del Rio-Chanona","Dániel Kondor","Pieter Francois","Ed Chalstrey","Jakob Zsambok","Dan Hoyer","Jenny Reddish","Jakob Hauser","Francisco-Javier Rodrigo-Ginés","Suchandra Datta","Maxwell Shepherd","Thom Kamphuis","Qizheng Zhang","Hyunjun Kim","Ruiji Sun","Jianzhu Yao","Franck Dernoncourt","Satyapriya Krishna","Sina Rismanchian","Bonan Pu","Francesco Pinto","Yingheng Wang","Kumar Shridhar","Kalon J. Overholt","Glib Briia","Hieu Nguyen"," David","Soler Bartomeu","Tony CY Pang","Adam Wecker","Yifan Xiong","Fanfei Li","Lukas S. Huber","Joshua Jaeger","Romano De Maddalena","Xing Han Lù","Yuhui Zhang","Claas Beger","Patrick Tser Jern Kon","Sean Li","Vivek Sanker","Ming Yin","Yihao Liang","Xinlu Zhang","Ankit Agrawal","Li S. Yifei","Zechen Zhang","Mu Cai","Yasin Sonmez","Costin Cozianu","Changhao Li","Alex Slen","Shoubin Yu","Hyun Kyu Park","Gabriele Sarti","Marcin Briański","Alessandro Stolfo","Truong An Nguyen","Mike Zhang","Yotam Perlitz","Jose Hernandez-Orallo","Runjia Li","Amin Shabani","Felix Juefei-Xu","Shikhar Dhingra","Orr Zohar","My Chiffon Nguyen","Alexander Pondaven","Abdurrahim Yilmaz","Xuandong Zhao","Chuanyang Jin","Muyan Jiang","Stefan Todoran","Xinyao Han","Jules Kreuer","Brian Rabern","Anna Plassart","Martino Maggetti","Luther Yap","Robert Geirhos","Jonathon Kean","Dingsu Wang","Sina Mollaei","Chenkai Sun","Yifan Yin","Shiqi Wang","Rui Li","Yaowen Chang","Anjiang Wei","Alice Bizeul","Xiaohan Wang","Alexandre Oliveira Arrais","Kushin Mukherjee","Jorge Chamorro-Padial","Jiachen Liu","Xingyu Qu","Junyi Guan","Adam Bouyamourn","Shuyu Wu","Martyna Plomecka","Junda Chen","Mengze Tang","Jiaqi Deng","Shreyas Subramanian","Haocheng Xi","Haoxuan Chen","Weizhi Zhang","Yinuo Ren","Haoqin Tu","Sejong Kim","Yushun Chen","Sara Vera Marjanović","Junwoo Ha","Grzegorz Luczyna","Jeff J. Ma","Zewen Shen","Dawn Song","Cedegao E. Zhang","Zhun Wang","Gaël Gendron","Yunze Xiao","Leo Smucker","Erica Weng","Kwok Hao Lee","Zhe Ye","Stefano Ermon","Ignacio D. Lopez-Miguel","Theo Knights","Anthony Gitter","Namkyu Park","Boyi Wei","Hongzheng Chen","Kunal Pai","Ahmed Elkhanany","Han Lin","Philipp D. Siedler","Jichao Fang","Ritwik Mishra","Károly Zsolnai-Fehér","Xilin Jiang","Shadab Khan","Jun Yuan","Rishab Kumar Jain","Xi Lin","Mike Peterson","Zhe Wang","Aditya Malusare","Maosen Tang","Isha Gupta","Ivan Fosin","Timothy Kang","Barbara Dworakowska","Kazuki Matsumoto","Guangyao Zheng","Gerben Sewuster","Jorge Pretel Villanueva","Ivan Rannev","Igor Chernyavsky","Jiale Chen","Deepayan Banik","Ben Racz","Wenchao Dong","Jianxin Wang","Laila Bashmal","Duarte V. Gonçalves","Wei Hu","Kaushik Bar","Ondrej Bohdal","Atharv Singh Patlan","Shehzaad Dhuliawala","Caroline Geirhos","Julien Wist","Yuval Kansal","Bingsen Chen","Kutay Tire","Atak Talay Yücel","Brandon Christof","Veerupaksh Singla","Zijian Song","Sanxing Chen","Jiaxin Ge","Kaustubh Ponkshe","Isaac Park","Tianneng Shi","Martin Q. Ma","Joshua Mak","Sherwin Lai","Antoine Moulin","Zhuo Cheng","Zhanda Zhu","Ziyi Zhang","Vaidehi Patil","Ketan Jha","Qiutong Men","Jiaxuan Wu","Tianchi Zhang","Bruno Hebling Vieira","Alham Fikri Aji","Jae-Won Chung","Mohammed Mahfoud","Ha Thi Hoang","Marc Sperzel","Wei Hao","Kristof Meding","Sihan Xu","Vassilis Kostakos","Davide Manini","Yueying Liu","Christopher Toukmaji","Jay Paek","Eunmi Yu","Arif Engin Demircali","Zhiyi Sun","Ivan Dewerpe","Hongsen Qin","Roman Pflugfelder","James Bailey","Johnathan Morris","Ville Heilala","Sybille Rosset","Zishun Yu","Peter E. Chen","Woongyeong Yeo","Eeshaan Jain","Ryan Yang","Sreekar Chigurupati","Julia Chernyavsky","Sai Prajwal Reddy","Subhashini Venugopalan","Hunar Batra","Core Francisco Park","Hieu Tran","Guilherme Maximiano","Genghan Zhang","Yizhuo Liang","Hu Shiyu","Rongwu Xu","Rui Pan","Siddharth Suresh","Ziqi Liu","Samaksh Gulati","Songyang Zhang","Peter Turchin","Christopher W. Bartlett","Christopher R. Scotese","Phuong M. Cao","Ben Wu","Jacek Karwowski","Davide Scaramuzza","Aakaash Nattanmai","Gordon McKellips","Anish Cheraku","Asim Suhail","Ethan Luo","Marvin Deng","Jason Luo","Ashley Zhang","Kavin Jindel","Jay Paek","Kasper Halevy","Allen Baranov","Michael Liu","Advaith Avadhanam","David Zhang","Vincent Cheng","Brad Ma","Evan Fu","Liam Do","Joshua Lass","Hubert Yang","Surya Sunkari","Vishruth Bharath","Violet Ai","James Leung","Rishit Agrawal","Alan Zhou","Kevin Chen","Tejas Kalpathi","Ziqi Xu","Gavin Wang","Tyler Xiao","Erik Maung","Sam Lee","Ryan Yang","Roy Yue","Ben Zhao","Julia Yoon","Sunny Sun","Aryan Singh","Ethan Luo","Clark Peng","Tyler Osbey","Taozhi Wang","Daryl Echeazu","Hubert Yang","Timothy Wu","Spandan Patel","Vidhi Kulkarni","Vijaykaarti Sundarapandiyan","Ashley Zhang","Andrew Le","Zafir Nasim","Srikar Yalam","Ritesh Kasamsetty","Soham Samal","Hubert Yang","David Sun","Nihar Shah","Abhijeet Saha","Alex Zhang","Leon Nguyen","Laasya Nagumalli","Kaixin Wang","Alan Zhou","Aidan Wu","Jason Luo","Anwith Telluri","Steven Dillmann","Zhengxiang Wang","Junyu Luo","Hugo Lunn","Artem Gazizov","Haoran Qiu","Allen G Hart","Rickard Brüel Gabrielsson","Ido Akov","Artem Lukoianov","Summer Yue","Alexandr Wang","Dan Hendrycks"],"pdf_url":"","comment":"29 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.17976v1","updated":"2026-02-20T04:20:47Z","published":"2026-02-20T04:20:47Z","title":"In-Context Learning for Pure Exploration in Continuous Spaces","summary":"In active sequential testing, also termed pure exploration, a learner is tasked with the goal to adaptively acquire information so as to identify an unknown ground-truth hypothesis with as few queries as possible. This problem, originally studied by Chernoff in 1959, has several applications: classical formulations include Best-Arm Identification (BAI) in bandits, where actions index hypotheses, and generalized search problems, where strategically chosen queries reveal partial information about a hidden label. In many modern settings, however, the hypothesis space is continuous and naturally coincides with the query/action space: for example, identifying an optimal action in a continuous-armed bandit, localizing an $ε$-ball contained in a target region, or estimating the minimizer of an unknown function from a sequence of observations. In this work, we study pure exploration in such continuous spaces and introduce Continuous In-Context Pure Exploration for this regime. We introduce C-ICPE-TS, an algorithm that meta-trains deep neural policies to map observation histories to (i) the next continuous query action and (ii) a predicted hypothesis, thereby learning transferable sequential testing strategies directly from data. At inference time, C-ICPE-TS actively gathers evidence on previously unseen tasks and infers the true hypothesis without parameter updates or explicit hand-crafted information models. We validate C-ICPE-TS across a range of benchmarks, spanning continuous best-arm identification, region localization, and function minimizer identification.","authors":["Alessio Russo","Yin-Ching Lee","Ryan Welch","Aldo Pacchiano"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.18555v2","updated":"2026-02-20T04:09:34Z","published":"2025-11-23T18:04:15Z","title":"A joint optimization approach to identifying sparse dynamics using least squares kernel collocation","summary":"We develop an all-at-once modeling framework for learning systems of ordinary differential equations (ODE) from scarce, partial, and noisy observations of the states. The proposed methodology amounts to a combination of sparse recovery strategies for the ODE over a function library combined with techniques from reproducing kernel Hilbert space (RKHS) theory for estimating the state and discretizing the ODE. Our numerical experiments reveal that the proposed strategy leads to significant gains in terms of accuracy, sample efficiency, and robustness to noise, both in terms of learning the equation and estimating the unknown states. This work demonstrates capabilities well beyond existing and widely used algorithms while extending the modeling flexibility of other recent developments in equation discovery.","authors":["Alexander W. Hsu","Ike Griss Salas","Jacob M. Stevens-Haas","J. Nathan Kutz","Aleksandr Aravkin","Bamdad Hosseini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17975v1","updated":"2026-02-20T04:09:13Z","published":"2026-02-20T04:09:13Z","title":"Generating adversarial inputs for a graph neural network model of AC power flow","summary":"This work formulates and solves optimization problems to generate input points that yield high errors between a neural network's predicted AC power flow solution and solutions to the AC power flow equations. We demonstrate this capability on an instance of the CANOS-PF graph neural network model, as implemented by the PF$Δ$ benchmark library, operating on a 14-bus test grid. Generated adversarial points yield errors as large as 3.4 per-unit in reactive power and 0.08 per-unit in voltage magnitude. When minimizing the perturbation from a training point necessary to satisfy adversarial constraints, we find that the constraints can be met with as little as an 0.04 per-unit perturbation in voltage magnitude on a single bus. This work motivates the development of rigorous verification and robust training methods for neural network surrogate models of AC power flow.","authors":["Robert Parker"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17972v1","updated":"2026-02-20T03:57:45Z","published":"2026-02-20T03:57:45Z","title":"Student Flow Modeling for School Decongestion via Stochastic Gravity Estimation and Constrained Spatial Allocation","summary":"School congestion, where student enrollment exceeds school capacity, is a major challenge in low- and middle-income countries. It highly impacts learning outcomes and deepens inequities in education. While subsidy programs that transfer students from public to private schools offer a mechanism to alleviate congestion without capital-intensive construction, they often underperform due to fragmented data systems that hinder effective implementation. The Philippine Educational Service Contracting program, one of the world's largest educational subsidy programs, exemplifies these challenges, falling short of its goal to decongest public schools. This prevents the science-based and data-driven analyses needed to understand what shapes student enrollment flows, particularly how families respond to economic incentives and spatial constraints. We introduce a computational framework for modeling student flow patterns and simulating policy scenarios. By synthesizing heterogeneous government data across nearly 3,000 institutions, we employ a stochastic gravity model estimated via negative binomial regression to derive behavioral elasticities for distance, net tuition cost, and socioeconomic determinants. These elasticities inform a doubly constrained spatial allocation mechanism that simulates student redistribution under varying subsidy amounts while respecting both origin candidate pools and destination slot capacities. We find that geographic proximity constrains school choice four times more strongly than tuition cost and that slot capacity, not subsidy amounts, is the binding constraint. Our work demonstrates that subsidy programs alone cannot resolve systemic overcrowding, and computational modeling can empower education policymakers to make equitable, data-driven decisions by revealing the structural constraints that shape effective resource allocation, even when resources are limited.","authors":["Sebastian Felipe R. Bundoc","Paula Joy B. Martinez","Sebastian C. Ibañez","Erika Fille T. Legara"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19223v2","updated":"2026-02-20T03:46:54Z","published":"2025-12-22T10:03:51Z","title":"Phase-space entropy at acquisition reflects downstream learnability","summary":"Modern learning systems work with data that vary widely across domains, but they all ultimately depend on how much structure is already present in the measurements before any model is trained. This raises a basic question: is there a general, modality-agnostic way to quantify how acquisition itself preserves or destroys the information that downstream learners could use? Here we propose an acquisition-level scalar $ΔS_{\\mathcal B}$ based on instrument-resolved phase space. Unlike pixelwise distortion or purely spectral errors that often saturate under aggressive undersampling, $ΔS_{\\mathcal B}$ directly quantifies how acquisition mixes or removes joint space--frequency structure at the instrument scale. We show theoretically that \\(ΔS_{\\mathcal B}\\) correctly identifies the phase-space coherence of periodic sampling as the physical source of aliasing, recovering classical sampling-theorem consequences. Empirically, across masked image classification, accelerated MRI, and massive MIMO (including over-the-air measurements), $|ΔS_{\\mathcal B}|$ consistently ranks sampling geometries and predicts downstream reconstruction/recognition difficulty \\emph{without training}. In particular, minimizing $|ΔS_{\\mathcal B}|$ enables zero-training selection of variable-density MRI mask parameters that matches designs tuned by conventional pre-reconstruction criteria. These results suggest that phase-space entropy at acquisition reflects downstream learnability, enabling pre-training selection of candidate sampling policies and as a shared notion of information preservation across modalities.","authors":["Xiu-Cheng Wang","Jun-Jie Zhanga","Nan Cheng","Long-Gang Pang","Taijiao Du","Deyu Meng"],"pdf_url":"","comment":"22 pages 6 figures"},{"id":"http://arxiv.org/abs/2602.16179v3","updated":"2026-02-20T03:42:59Z","published":"2026-02-18T04:35:46Z","title":"EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments","summary":"We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce CoreCraft, the first environment in EnterpriseBench, Surge AI's suite of agentic RL environments. CoreCraft is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM 4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37% to 36.76% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5% on BFCL Parallel, +7.4% on Tau2-Bench Retail, and +6.8% on Tool Decathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.","authors":["Sushant Mehta","Logan Ritchie","Suhaas Garre","Nick Heiner","Edwin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17962v1","updated":"2026-02-20T03:37:05Z","published":"2026-02-20T03:37:05Z","title":"Improving Generalizability of Hip Fracture Risk Prediction via Domain Adaptation Across Multiple Cohorts","summary":"Clinical risk prediction models often fail to be generalized across cohorts because underlying data distributions differ by clinical site, region, demographics, and measurement protocols. This limitation is particularly pronounced in hip fracture risk prediction, where the performance of models trained on one cohort (the source cohort) can degrade substantially when deployed in other cohorts (target cohorts). We used a shared set of clinical and DXA-derived features across three large cohorts - the Study of Osteoporotic Fractures (SOF), the Osteoporotic Fractures in Men Study (MrOS), and the UK Biobank (UKB), to systematically evaluate the performance of three domain adaptation methods - Maximum Mean Discrepancy (MMD), Correlation Alignment (CORAL), and Domain - Adversarial Neural Networks (DANN) and their combinations. For a source cohort with males only and a source cohort with females only, domain-adaptation methods consistently showed improved performance than the no-adaptation baseline (source-only training), and the use of combinations of multiple domain adaptation methods delivered the largest and most stable gains. The method that combines MMD, CORAL, and DANN achieved the highest discrimination with the area under curve (AUC) of 0.88 for a source cohort with males only and 0.95 for a source cohort with females only), demonstrating that integrating multiple domain adaptation methods could produce feature representations that are less sensitive to dataset differences. Unlike existing methods that rely heavily on supervised tuning or assume known outcomes of samples in target cohorts, our outcome-free approaches enable the model selection under realistic deployment conditions and improve generalization of models in hip fracture risk prediction.","authors":["Shuo Sun","Meiling Zhou","Chen Zhao","Joyce H. Keyak","Nancy E. Lane","Jeffrey D. Deng","Kuan-Jui Su","Hui Shen","Hong-Wen Deng","Kui Zhang","Weihua Zhou"],"pdf_url":"","comment":"26 pages, 3 tables, 1 figure"},{"id":"http://arxiv.org/abs/2512.08217v2","updated":"2026-02-20T03:29:10Z","published":"2025-12-09T03:52:54Z","title":"Correction of Decoupled Weight Decay","summary":"Decoupled weight decay, solely responsible for the performance advantage of AdamW over Adam, has long been set to proportional to learning rate $γ$ without questioning. Some researchers have recently challenged such assumption and argued that decoupled weight decay should be set $\\propto γ^2$ instead based on orthogonality arguments at steady state. To the contrary, we find that eliminating the contribution of the perpendicular component of the update to the weight norm leads to little change to the training dynamics. Instead, we derive that decoupled weight decay $\\propto γ^2$ results in stable weight norm based on the simple assumption that updates become independent of the weights at steady state, regardless of the nature of the optimizer. Based on the same assumption, we derive and empirically verify that the Total Update Contribution (TUC) of a minibatch under the Scion optimizer is better characterized by the momentum-dependent effective learning rate whose optimal value transfers and we show that decoupled weight decay $\\propto γ^2$ leads to stable weight and gradient norms and allows us to better control the training dynamics and improve the model performance.","authors":["Jason Chuan-Chih Chou"],"pdf_url":"","comment":"v2 fixes misreported WD hyperparameters"},{"id":"http://arxiv.org/abs/2602.17958v1","updated":"2026-02-20T03:23:55Z","published":"2026-02-20T03:23:55Z","title":"Bayesian Online Model Selection","summary":"Online model selection in Bayesian bandits raises a fundamental exploration challenge: When an environment instance is sampled from a prior distribution, how can we design an adaptive strategy that explores multiple bandit learners and competes with the best one in hindsight? We address this problem by introducing a new Bayesian algorithm for online model selection in stochastic bandits. We prove an oracle-style guarantee of $O\\left( d^* M \\sqrt{T} + \\sqrt{(MT)} \\right)$ on the Bayesian regret, where $M$ is the number of base learners, $d^*$ is the regret coefficient of the optimal base learner, and $T$ is the time horizon. We also validate our method empirically across a range of stochastic bandit settings, demonstrating performance that is competitive with the best base learner. Additionally, we study the effect of sharing data among base learners and its role in mitigating prior mis-specification.","authors":["Aida Afshar","Yuke Zhang","Aldo Pacchiano"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17952v1","updated":"2026-02-20T03:07:05Z","published":"2026-02-20T03:07:05Z","title":"Hardware-Friendly Input Expansion for Accelerating Function Approximation","summary":"One-dimensional function approximation is a fundamental problem in scientific computing and engineering applications. While neural networks possess powerful universal approximation capabilities, their optimization process is often hindered by flat loss landscapes induced by parameter-space symmetries, leading to slow convergence and poor generalization, particularly for high-frequency components. Inspired by the principle of \\emph{symmetry breaking} in physics, this paper proposes a hardware-friendly approach for function approximation through \\emph{input-space expansion}. The core idea involves augmenting the original one-dimensional input (e.g., $x$) with constant values (e.g., $π$) to form a higher-dimensional vector (e.g., $[π, π, x, π, π]$), effectively breaking parameter symmetries without increasing the network's parameter count. We evaluate the method on ten representative one-dimensional functions, including smooth, discontinuous, high-frequency, and non-differentiable functions. Experimental results demonstrate that input-space expansion significantly accelerates training convergence (reducing LBFGS iterations by 12\\% on average) and enhances approximation accuracy (reducing final MSE by 66.3\\% for the optimal 5D expansion). Ablation studies further reveal the effects of different expansion dimensions and constant selections, with $π$ consistently outperforming other constants. Our work proposes a low-cost, efficient, and hardware-friendly technique for algorithm design.","authors":["Hu Lou","Yin-Jun Gao","Dong-Xiao Zhang","Tai-Jiao Du","Jun-Jie Zhang","Jia-Rui Zhang"],"pdf_url":"","comment":"22 pages, 4 figures"},{"id":"http://arxiv.org/abs/2602.17948v1","updated":"2026-02-20T02:58:29Z","published":"2026-02-20T02:58:29Z","title":"A Geometric Probe of the Accuracy-Robustness Trade-off: Sharp Boundaries in Symmetry-Breaking Dimensional Expansion","summary":"The trade-off between clean accuracy and adversarial robustness is a pervasive phenomenon in deep learning, yet its geometric origin remains elusive. In this work, we utilize Symmetry-Breaking Dimensional Expansion (SBDE) as a controlled probe to investigate the mechanism underlying this trade-off. SBDE expands input images by inserting constant-valued pixels, which breaks translational symmetry and consistently improves clean accuracy (e.g., from $90.47\\%$ to $95.63\\%$ on CIFAR-10 with ResNet-18) by reducing parameter degeneracy. However, this accuracy gain comes at the cost of reduced robustness against iterative white-box attacks. By employing a test-time \\emph{mask projection} that resets the inserted auxiliary pixels to their training values, we demonstrate that the vulnerability stems almost entirely from the inserted dimensions. The projection effectively neutralizes the attacks and restores robustness, revealing that the model achieves high accuracy by creating \\emph{sharp boundaries} (steep loss gradients) specifically along the auxiliary axes. Our findings provide a concrete geometric explanation for the accuracy-robustness paradox: the optimization landscape deepens the basin of attraction to improve accuracy but inevitably erects steep walls along the auxiliary degrees of freedom, creating a fragile sensitivity to off-manifold perturbations.","authors":["Yu Bai","Zhe Wang","Jiarui Zhang","Dong-Xiao Zhang","Yinjun Gao","Jun-Jie Zhang"],"pdf_url":"","comment":"22 pages, 3 figures"},{"id":"http://arxiv.org/abs/2602.17947v1","updated":"2026-02-20T02:52:13Z","published":"2026-02-20T02:52:13Z","title":"Understanding the Generalization of Bilevel Programming in Hyperparameter Optimization: A Tale of Bias-Variance Decomposition","summary":"Gradient-based hyperparameter optimization (HPO) have emerged recently, leveraging bilevel programming techniques to optimize hyperparameter by estimating hypergradient w.r.t. validation loss. Nevertheless, previous theoretical works mainly focus on reducing the gap between the estimation and ground-truth (i.e., the bias), while ignoring the error due to data distribution (i.e., the variance), which degrades performance. To address this issue, we conduct a bias-variance decomposition for hypergradient estimation error and provide a supplemental detailed analysis of the variance term ignored by previous works. We also present a comprehensive analysis of the error bounds for hypergradient estimation. This facilitates an easy explanation of some phenomena commonly observed in practice, like overfitting to the validation set. Inspired by the derived theories, we propose an ensemble hypergradient strategy to reduce the variance in HPO algorithms effectively. Experimental results on tasks including regularization hyperparameter learning, data hyper-cleaning, and few-shot learning demonstrate that our variance reduction strategy improves hypergradient estimation. To explain the improved performance, we establish a connection between excess error and hypergradient estimation, offering some understanding of empirical observations.","authors":["Yubo Zhou","Jun Shu","Junmin Liu","Deyu Meng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.19269v2","updated":"2026-02-20T02:50:33Z","published":"2025-11-24T16:21:25Z","title":"CDLM: Consistency Diffusion Language Models For Faster Sampling","summary":"Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.","authors":["Minseo Kim","Chenfeng Xu","Coleman Hooper","Harman Singh","Ben Athiwaratkun","Ce Zhang","Kurt Keutzer","Amir Gholami"],"pdf_url":"","comment":"Accepted to MLSys 2026"}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2601.14252v3","updated":"2026-02-20T21:52:16Z","published":"2026-01-20T18:58:51Z","title":"Identification capacity and rate-query tradeoffs in classification systems","summary":"We study zero-error class identification under constrained observations with three resources: tag rate $L$ (bits per entity), identification cost $W$ (attribute queries), and distortion $D$ (misidentification probability). We prove an information barrier: if the attribute-profile map $π$ is not injective on classes, then attribute-only observation cannot identify class identity with zero error. Let $A_π:= \\max_u |\\{c : π(c)=u\\}|$ be collision multiplicity. Any $D=0$ scheme must satisfy $L \\ge \\log_2 A_π$, and this bound is tight. In maximal-barrier domains ($A_π= k$), the nominal point $(L,W,D) = (\\lceil \\log_2 k \\rceil, O(1), 0)$ is the unique Pareto-optimal zero-error point. Without tags ($L=0$), zero-error identification requires $W = Ω(d)$ queries, where $d$ is the distinguishing dimension (worst case $d=n$, so $W=Ω(n)$). Minimal sufficient query sets form the bases of a matroid, making $d$ well-defined and linking the model to zero-error source coding via graph entropy. We also state fixed-axis incompleteness: a fixed observation axis is complete only for axis-measurable properties. Results instantiate to databases, biology, typed software systems, and model registries, and are machine-checked in Lean 4 (6707 lines, 296 theorem/lemma statements, 0 sorry).","authors":["Tristan Simas"],"pdf_url":"","comment":"14 pages, 1 table. Lean 4 formalization (6,707 lines, 0 sorry) included in source and archived at https://doi.org/10.5281/zenodo.18261188"},{"id":"http://arxiv.org/abs/2602.18602v1","updated":"2026-02-20T20:32:04Z","published":"2026-02-20T20:32:04Z","title":"Package Managers à la Carte: A Formal Model of Dependency Resolution","summary":"Package managers are legion. Every programming language and operating system has its own solution, each with subtly different semantics for dependency resolution. This fragmentation prevents multilingual projects from expressing precise dependencies across language ecosystems; it leaves external system and hardware dependencies implicit and unversioned; it obscures security vulnerabilities that lie in the full dependency graph. We present the \\textit{Package Calculus}, a formalism for dependency resolution that unifies the core semantics of diverse package managers. Through a series of formal reductions, we show how this core is expressive enough to model the diversity that real-world package managers employ in their dependency expression languages. By using the Package Calculus as the intermediate representation of dependencies, we enable translation between distinct package managers and resolution across ecosystems.","authors":["Ryan Gibb","Patrick Ferris","David Allsopp","Thomas Gazagnaire","Anil Madhavapeddy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17037v2","updated":"2026-02-20T18:13:08Z","published":"2026-02-19T03:15:00Z","title":"Wink: Recovering from Misbehaviors in Coding Agents","summary":"Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getting stuck in repetitive loops, or failing to use tools correctly. These failures disrupt the development workflow and often require resource-intensive manual intervention. In this paper, we present a system for automatically recovering from agentic misbehaviors at scale. We first introduce a taxonomy of misbehaviors grounded in an analysis of production traffic, identifying three primary categories: Specification Drift, Reasoning Problems, and Tool Call Failures, which we find occur in about 30% of all agent trajectories.\n  To address these issues, we developed a lightweight, asynchronous self-intervention system named Wink. Wink observes agent trajectories and provides targeted course-correction guidance to nudge the agent back to a productive path. We evaluated our system on over 10,000 real world agent trajectories and found that it successfully resolves 90% of the misbehaviors that require a single intervention. Furthermore, a live A/B test in our production environment demonstrated that our system leads to a statistically significant reduction in Tool Call Failures, Tokens per Session and Engineer Interventions per Session. We present our experience designing and deploying this system, offering insights into the challenges of building resilient agentic systems at scale.","authors":["Rahul Nanda","Chandra Maddila","Smriti Jha","Euna Mehnaz Khan","Matteo Paltenghi","Satish Chandra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18545v1","updated":"2026-02-20T16:52:03Z","published":"2026-02-20T16:52:03Z","title":"Programmable Property-Based Testing","summary":"Property-based testing (PBT) is a popular technique for establishing confidence in software, where users write properties -- i.e., executable specifications -- that can be checked many times in a loop by a testing framework. In modern PBT frameworks, properties are usually written in shallowly embedded domain-specific languages, and their definition is tightly coupled to the way they are tested. Such frameworks often provide convenient configuration options to customize aspects of the testing process, but users are limited to precisely what library authors had the prescience to allow for when developing the framework; if they want more flexibility, they may need to write a new framework from scratch.\n  We propose a new, deeper language for properties based on a mixed embedding that we call deferred binding abstract syntax, which reifies properties as a data structure and decouples them from the property runners that execute them. We implement this language in Rocq and Racket, leveraging the power of dependent and dynamic types, respectively. Finally, we showcase the flexibility of this new approach by rapidly prototyping a variety of property runners, highlighting domain-specific testing improvements that can be unlocked by more programmable testing.","authors":["Alperen Keles","Justine Frank","Ceren Mert","Harrison Goldstein","Leonidas Lampropoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18307v1","updated":"2026-02-20T16:05:06Z","published":"2026-02-20T16:05:06Z","title":"VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean","summary":"Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.","authors":["Yutong Xin","Qiaochu Chen","Greg Durrett","Işil Dillig"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18295v1","updated":"2026-02-20T15:46:53Z","published":"2026-02-20T15:46:53Z","title":"Towards a Higher-Order Bialgebraic Denotational Semantics","summary":"The bialgebraic abstract GSOS framework by Turi and Plotkin provides an elegant categorical approach to modelling the operational and denotational semantics of programming and process languages. In abstract GSOS, bisimilarity is always a congruence, and it coincides with denotational equivalence. This saves the language designer from intricate, ad-hoc reasoning to establish these properties. The bialgebraic perspective on operational semantics in the style of abstract GSOS has recently been extended to higher-order languages, preserving compositionality of bisimilarity. However, a categorical understanding of bialgebraic denotational semantics according to Turi and Plotkin's original vision has so far been missing in the higher-order setting. In the present paper, we develop a theory of adequate denotational semantics in higher-order abstract GSOS. The denotational models are parametric in an appropriately chosen semantic domain in the form of a locally final coalgebra for a behaviour bifunctor, whose construction is fully decoupled from the syntax of the language. Our approach captures existing accounts of denotational semantics such as semantic domains built via general step-indexing, previously introduced on a per-language basis, and is shown to be applicable to a wide range of different higher-order languages, e.g. simply typed and untyped languages, or languages with computational effects such as probabilistic or non-deterministic branching.","authors":["Sergey Goncharov","Marco Peressotti","Stelios Tsampas","Henning Urbat","Stefano Volpe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18166v1","updated":"2026-02-20T12:04:42Z","published":"2026-02-20T12:04:42Z","title":"Grammar Repair with Examples and Tree Automata: Extended Version","summary":"Context-free grammars (CFGs) are the de-facto formalism for declaratively describing concrete syntax for programming languages and generating parsers. One of the major challenges in defining a desired syntax is ruling out all possible ambiguities in the CFG productions that determine scoping rules as well as operator precedence and associativity. Practical tools for parser generation typically apply ad-hoc approaches for resolving such ambiguities, which might result in a parser's behavior that contradicts the intents of the language designer. In this work, we present a user-friendly approach to soundly repair grammars with ambiguities, which is inspired by the programming by example line of research in automated program synthesis. At the heart of our approach is the interpretation of both the initial CFG and additional examples that define the desired restrictions in precedence and associativity, as tree automata (TAs). The technical novelties of our approach are (1) a new TA learning algorithm that constructs an automaton based on the original grammar and examples that encode the user's preferred ways of resolving ambiguities all in a single TA, and (2) an efficient algorithm for TA intersection that utilises reachability analysis and optimizations that significantly reduce the size of the resulting automaton, which results in idiomatic CFGs amenable to parser generators. We have proven the soundness of the algorithms, and implemented our approach in a tool called Greta, demonstrating its effectiveness on a series of case studies.","authors":["Yunjeong Lee","Gokul Rajiv","Ilya Sergey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18534v1","updated":"2026-02-20T10:55:14Z","published":"2026-02-20T10:55:14Z","title":"Validated Code Translation for Projects with External Libraries","summary":"Large Language Models (LLMs) have shown promise for program translation, particularly for migrating systems code to memory-safe languages such as Rust. However, existing approaches struggle when source programs depend on external libraries: LLMs frequently hallucinate non-existent target APIs and fail to generate call-enabling imports; moreover, validating semantic equivalence is challenging when the code manipulates opaque, library-defined types. We present a translation and validation framework for translating Go projects with external dependencies to Rust. Our approach combines (i) a retrieval mechanism that maps Go library APIs to Rust APIs, and (ii) a cross-language validation pipeline that establishes language interoperability in the presence of opaque library types by synthesising adapters exclusively from public library APIs, prior to validating I/O equivalence. We evaluate our system on six real-world Go repositories with non-trivial external dependencies. Our approach significantly increases both the compilation and equivalence success rate (up to 100% in the most dependency-heavy case; approx. 2x on average) by enabling validated translation that manipulate opaque, library-defined types.","authors":["Hanliang Zhang","Arindam Sharma","Cristina David","Meng Wang","Brandon Paulsen","Daniel Kroening","Wenjia Ye","Taro Sekiyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01944v2","updated":"2026-02-20T10:14:27Z","published":"2026-01-05T09:50:37Z","title":"The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities","summary":"In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.","authors":["Matteo Esposito","Andrea Janes","Valentina Lenarduzzi","Davide Taibi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2602.18090v1","updated":"2026-02-20T09:28:20Z","published":"2026-02-20T09:28:20Z","title":"Programming Backpropagation with Reverse Handlers for Arrows","summary":"We introduce a new programming language and its categorical semantics in order to design and implement neural networks within the framework of algebraic effects and handlers for arrows. Our language enables us to construct neural networks symbolically, in the same manner as algebraic effects, and to assign implementations -- such as backpropagation computations -- to them via handlers. The advantage of this language design is that network descriptions become abstract and high-level, while implementations can be flexibly assigned to networks. We establish a rigorous foundation for our language by developing a type system, an operational semantics, a categorical semantics, and soundness and adequacy theorems. The technical core is the introduction of \\emph{reverse handlers}, a novel handler mechanism for arrows for implementing backpropagation, together with new algebras of strong promonads on reverse differential restriction categories (RDRCs), whose string diagrams provide a formal graphical syntax and semantics for neural networks.","authors":["Takahiro Sanada","Keisuke Hoshino","Kenshin Hirai","Shin-ya Katsumata"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17937v1","updated":"2026-02-20T01:56:27Z","published":"2026-02-20T01:56:27Z","title":"Analyzing LLM Instruction Optimization for Tabular Fact Verification","summary":"Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.","authors":["Xiaotang Du","Giwon Hong","Wai-Chung Kwan","Rohit Saxena","Ivan Titov","Pasquale Minervini","Emily Allaway"],"pdf_url":"","comment":null}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.18644v1","updated":"2026-02-20T22:36:47Z","published":"2026-02-20T22:36:47Z","title":"Modeling and Recovering Hierarchical Structural Architectures of ROS 2 Systems from Code and Launch Configurations using LLM-based Agents","summary":"Model-Driven Engineering (MDE) relies on explicit architecture models to document and evolve systems across abstraction levels. For ROS~2, subsystem structure is often encoded implicitly in distributed configuration artifacts -- most notably launch files -- making hierarchical structural decomposition hard to capture and maintain. Existing ROS~2 modeling approaches cover node-level entities and wiring, but do not make hierarchical structural (de-)composition a first-class architectural view independent of launch artifacts.\n  We contribute (1) a UML-based modeling concept for hierarchical structural architectures of ROS~2 systems and (2) a blueprint-guided automated recovery pipeline that reconstructs such models from code and configuration artifacts by combining deterministic extraction with LLM-based agents. The ROS~2 architectural blueprint (nodes, topics, interfaces, launch-induced wiring) is encoded as structural contracts to constrain synthesis and enable deterministic validation, improving reliability.\n  We evaluate the approach on three ROS~2 repositories, including an industrial-scale code subset. Results show high precision across abstraction levels, while subsystem-level recall drops with repository complexity due to implicit launch semantics, making high-level recovery the remaining challenge.","authors":["Mohamed Benchat","Dominique Briechle","Raj Chanchad","Mitbhai Chauhan","Meet Chavda","Ruidi He","Dhruv Jajadiya","Dhruv Kapadiya","Nidhiben Kaswala","Daniel Osterholz","Andreas Rausch","Meng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18602v1","updated":"2026-02-20T20:32:04Z","published":"2026-02-20T20:32:04Z","title":"Package Managers à la Carte: A Formal Model of Dependency Resolution","summary":"Package managers are legion. Every programming language and operating system has its own solution, each with subtly different semantics for dependency resolution. This fragmentation prevents multilingual projects from expressing precise dependencies across language ecosystems; it leaves external system and hardware dependencies implicit and unversioned; it obscures security vulnerabilities that lie in the full dependency graph. We present the \\textit{Package Calculus}, a formalism for dependency resolution that unifies the core semantics of diverse package managers. Through a series of formal reductions, we show how this core is expressive enough to model the diversity that real-world package managers employ in their dependency expression languages. By using the Package Calculus as the intermediate representation of dependencies, we enable translation between distinct package managers and resolution across ecosystems.","authors":["Ryan Gibb","Patrick Ferris","David Allsopp","Thomas Gazagnaire","Anil Madhavapeddy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18579v1","updated":"2026-02-20T19:37:14Z","published":"2026-02-20T19:37:14Z","title":"Refactoring for Novices in Java: An Eye Tracking Study on the Extract vs. Inline Methods","summary":"Developers often extract methods to improve readability, understanding, and reuse, while inlining keeps logic in one block. Prior work based on static metrics has not shown clear differences between these practices, and the human side of comprehension and navigation remains underexplored. We investigate Inline Method vs. Extract Method refactorings using a dynamic approach: eye tracking while participants read and solve tasks. We analyze key code areas and compare visual effort and reading behavior (fixation duration and count, regressions, revisits), alongside time and attempts. We ran a controlled experiment with 32 Java novices, followed by short interviews. Each participant solved eight simple tasks across four programs presented in an inlined version and four in an extracted version. We also surveyed 58 additional novices for complementary quantitative and qualitative data. Results show that effects depend on task difficulty. In two tasks, method extraction improved performance and reduced visual effort, with time decreasing by up to 78.8% and regressions by 84.6%. For simpler tasks (e.g., square area), extraction hurt performance: time increased by up to 166.9% and regressions by 200%. Even with meaningful method names, novices often switched back and forth between call sites and extracted methods, increasing navigation and cognitive load. Preferences frequently favored extraction for readability and reuse, but did not always match measured performance. These findings suggest educators should be cautious about premature modularization for novices and highlight eye tracking as a useful complement to static metrics.","authors":["José Aldo Silva da Costa","Rohit Gheyi","José Júnior Silva da Costa","Márcio Ribeiro","Rodrigo Bonifácio","Hyggo Almeida","Ana Carla Bibiano","Alessandro Garcia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18571v1","updated":"2026-02-20T19:24:16Z","published":"2026-02-20T19:24:16Z","title":"Debug2Fix: Supercharging Coding Agents with Interactive Debugging Capabilities","summary":"While significant progress has been made in automating various aspects of software development through coding agents, there is still significant room for improvement in their bug fixing capabilities. Debugging and investigation of runtime behavior remains largely a manual, developer-driven process. Popular coding agents typically rely on either static analysis of the code or iterative test-fix cycles, which is akin to trial and error debugging. We posit that there is a wealth of rich runtime information that developers routinely access while debugging code, which agents are currently deprived of due to design limitations. Despite how prevalent debuggers are in modern IDEs and command-line tools, they have surprisingly not made their way into coding agents. In this work, we introduce Debug2Fix, a novel framework that incorporates interactive debugging as a core component of a software engineering agent via a subagent architecture. We incorporate debuggers for Java and Python into our agent framework and evaluate against GitBug-Java and SWE-Bench-Live and achieve >20% improvement in performance compared to the baseline for certain models. Furthermore, using our framework, we're able to make weaker models like GPT-5 and Claude Haiku 4.5 match or exceed the performances of stronger models like Claude Sonnet 4.5, showing that better tool design is often just as important as switching to a more expensive model. Finally, we conduct systematic ablations demonstrating the importance of both the subagent architecture and debugger integration.","authors":["Spandan Garg","Yufan Huang"],"pdf_url":"","comment":"In Review"},{"id":"http://arxiv.org/abs/2601.14434v2","updated":"2026-02-20T18:56:02Z","published":"2026-01-20T19:43:11Z","title":"CMind: An AI Agent for Localizing C Memory Bugs","summary":"This demonstration paper presents CMind, an artificial intelligence agent for localizing C memory bugs. The novel aspect to CMind is that it follows steps that we observed human programmers perform during empirical study of those programmers finding memory bugs in C programs. The input to the tool is a C program's source code and a bug report describing the problem. The output is the tool's hypothesis about the reason for the bug and its location. CMind reads the bug report to find potential entry points to the program, then navigates the program's source code, analyzes that source code, and generates a hypothesis location and rationale that fit a template. The tool combines large language model reasoning with guided decision making we encoded to mimic human behavior. The video demonstration is available at https://youtu.be/_vVd0LRvVHI.","authors":["Chia-Yi Su","Collin McMillan"],"pdf_url":"","comment":"4 pages, 2 figures. To be published in 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026)"},{"id":"http://arxiv.org/abs/2602.17037v2","updated":"2026-02-20T18:13:08Z","published":"2026-02-19T03:15:00Z","title":"Wink: Recovering from Misbehaviors in Coding Agents","summary":"Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getting stuck in repetitive loops, or failing to use tools correctly. These failures disrupt the development workflow and often require resource-intensive manual intervention. In this paper, we present a system for automatically recovering from agentic misbehaviors at scale. We first introduce a taxonomy of misbehaviors grounded in an analysis of production traffic, identifying three primary categories: Specification Drift, Reasoning Problems, and Tool Call Failures, which we find occur in about 30% of all agent trajectories.\n  To address these issues, we developed a lightweight, asynchronous self-intervention system named Wink. Wink observes agent trajectories and provides targeted course-correction guidance to nudge the agent back to a productive path. We evaluated our system on over 10,000 real world agent trajectories and found that it successfully resolves 90% of the misbehaviors that require a single intervention. Furthermore, a live A/B test in our production environment demonstrated that our system leads to a statistically significant reduction in Tool Call Failures, Tokens per Session and Engineer Interventions per Session. We present our experience designing and deploying this system, offering insights into the challenges of building resilient agentic systems at scale.","authors":["Rahul Nanda","Chandra Maddila","Smriti Jha","Euna Mehnaz Khan","Matteo Paltenghi","Satish Chandra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18548v1","updated":"2026-02-20T17:46:51Z","published":"2026-02-20T17:46:51Z","title":"1D-Bench: A Benchmark for Iterative UI Code Generation with Visual Feedback in Real-World","summary":"Design-to-code translates high-fidelity UI designs into executable front-end implementations, but progress remains hard to compare due to inconsistent datasets, toolchains, and evaluation protocols. We introduce 1D-Bench, a benchmark grounded in real e-commerce workflows, where each instance provides a reference rendering and an exported intermediate representation that may contain extraction errors. 1D is short for one day, representing the efficient completion of design-to-code tasks in less than one day. Models take both as input, using the intermediate representation as structural cues while being evaluated against the reference rendering, which tests robustness to intermediate representation defects rather than literal adherence.\n  1D-Bench requires generating an executable React codebase under a fixed toolchain with an explicit component hierarchy, and defines a multi-round setting in which models iteratively apply component-level edits using execution feedback. Experiments on commercial and open-weight multimodal models show that iterative editing generally improves final performance by increasing rendering success and often improving visual similarity. We further conduct a pilot study on post-training with synthetic repair trajectories and reinforcement learning based editing, and observe limited and unstable gains that may stem from sparse terminal rewards and high-variance file-level updates.","authors":["Qiao Xu","Yipeng Yu","Chengxiao Feng","Xu Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18357v1","updated":"2026-02-20T17:06:38Z","published":"2026-02-20T17:06:38Z","title":"Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation","summary":"The quality assessment of Artificial Intelligence (AI) systems is a fundamental challenge due to their inherently probabilistic nature. Standards such as ISO/IEC 25059 provide a quality model, but they lack practical and statistically robust methods for assessing functional correctness. This paper proposes and evaluates the Statistical Confidence in Functional Correctness (SCFC) approach, which seeks to fill this gap by connecting business requirements to a measure of statistical confidence that considers both the model's average performance and its variability. The approach consists of four steps: defining quantitative specification limits, performing stratified and probabilistic sampling, applying bootstrapping to estimate a confidence interval for the performance metric, and calculating a capability index as a final indicator. The approach was evaluated through a case study on two real-world AI systems in industry involving interviews with AI experts. Valuable insights were collected from the experts regarding the utility, ease of use, and intention to adopt the methodology in practical scenarios. We conclude that the proposed approach is a feasible and valuable way to operationalize the assessment of functional correctness, moving the evaluation from a point estimate to a statement of statistical confidence.","authors":["Wallace Albertini","Marina Condé Araújo","Júlia Condé Araújo","Antonio Pedro Santos Alves","Marcos Kalinowski"],"pdf_url":"","comment":"Author version of the paper accepted for publication at CAIN 2026"},{"id":"http://arxiv.org/abs/2602.18352v1","updated":"2026-02-20T17:04:02Z","published":"2026-02-20T17:04:02Z","title":"Qualitative Coding Analysis through Open-Source Large Language Models: A User Study and Design Recommendations","summary":"Qualitative data analysis is labor-intensive, yet the privacy risks associated with commercial Large Language Models (LLMs) often preclude their use in sensitive research. To address this, we introduce ChatQDA, an on-device framework powered by open-source LLMs designed for privacy-preserving open coding. Our mixed-methods user study reveals that while participants rated the system highly for usability and perceived efficiency, they exhibited \"conditional trust\", valuing the tool for surface-level extraction while questioning its interpretive nuance and consistency. Furthermore, despite the technical security of local deployment, participants reported epistemic uncertainty regarding data protection, suggesting that invisible security measures are insufficient to foster trust. We conclude with design recommendations for local-first analysis tools that prioritize verifiable privacy and methodological rigor.","authors":["Tung T. Ngo","Dai Nguyen Van","Anh-Minh Nguyen","Phuong-Anh Do","Anh Nguyen-Quoc"],"pdf_url":"","comment":"6 pages. Accepted as Poster to CHI'26"},{"id":"http://arxiv.org/abs/2602.18545v1","updated":"2026-02-20T16:52:03Z","published":"2026-02-20T16:52:03Z","title":"Programmable Property-Based Testing","summary":"Property-based testing (PBT) is a popular technique for establishing confidence in software, where users write properties -- i.e., executable specifications -- that can be checked many times in a loop by a testing framework. In modern PBT frameworks, properties are usually written in shallowly embedded domain-specific languages, and their definition is tightly coupled to the way they are tested. Such frameworks often provide convenient configuration options to customize aspects of the testing process, but users are limited to precisely what library authors had the prescience to allow for when developing the framework; if they want more flexibility, they may need to write a new framework from scratch.\n  We propose a new, deeper language for properties based on a mixed embedding that we call deferred binding abstract syntax, which reifies properties as a data structure and decouples them from the property runners that execute them. We implement this language in Rocq and Racket, leveraging the power of dependent and dynamic types, respectively. Finally, we showcase the flexibility of this new approach by rapidly prototyping a variety of property runners, highlighting domain-specific testing improvements that can be unlocked by more programmable testing.","authors":["Alperen Keles","Justine Frank","Ceren Mert","Harrison Goldstein","Leonidas Lampropoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.00674v2","updated":"2026-02-20T16:06:47Z","published":"2025-10-01T08:58:55Z","title":"PyTrim: A Practical Tool for Reducing Python Dependency Bloat","summary":"Dependency bloat is a persistent challenge in Python projects, which increases maintenance costs and security risks. While numerous tools exist for detecting unused dependencies in Python, removing these dependencies across the source code and configuration files of a project requires manual effort and expertise.\n  To tackle this challenge we introduce PYTRIM, an end-to-end system to automate this process. PYTRIM eliminates unused imports and package declarations across a variety of file types, including Python source and configuration files such as requirements.txt and setup.py. PYTRIM's modular design makes it agnostic to the source of dependency bloat information, enabling integration with any detection tool. Beyond its contribution when it comes to automation, PYTRIM also incorporates a novel dynamic analysis component that improves dependency detection recall.\n  Our evaluation of PYTRIM's end-to-end effectiveness on a ground-truth dataset of 37 merged pull requests from prior work, shows that PYTRIM achieves 98.3% accuracy in replicating human-made changes. To show its practical impact, we run PYTRIM on 971 open-source packages, identifying and trimming bloated dependencies in 39 of them. For each case, we submit a corresponding pull request, 6 of which have already been accepted and merged. PYTRIM is available as an open-source project, encouraging community contributions and further development.\n  Video demonstration: https://youtu.be/LqTEdOUbJRI\n  Code repository: https://github.com/TrimTeam/PyTrim","authors":["Konstantinos Karakatsanis","Georgios Alexopoulos","Ioannis Karyotakis","Foivos Timotheos Proestakis","Evangelos Talos","Panos Louridas","Dimitris Mitropoulos"],"pdf_url":"","comment":"Accepted in the Proceedings of the 40th IEEE/ACM International Conference on Automated Software Engineering (ASE), Seoul, Korea. Supported by EU's Horizon 2021 research and innovation programme under grant agreement no. 101070599 (SecOPERA)"},{"id":"http://arxiv.org/abs/2602.18307v1","updated":"2026-02-20T16:05:06Z","published":"2026-02-20T16:05:06Z","title":"VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean","summary":"Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.","authors":["Yutong Xin","Qiaochu Chen","Greg Durrett","Işil Dillig"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18306v1","updated":"2026-02-20T16:02:13Z","published":"2026-02-20T16:02:13Z","title":"ReqElicitGym: An Evaluation Environment for Interview Competence in Conversational Requirements Elicitation","summary":"With the rapid improvement of LLMs' coding capabilities, the bottleneck of LLM-based automated software development is shifting from generating correct code to eliciting users' requirements. Despite growing interest, the interview competence of LLMs in conversational requirements elicitation remains fully underexplored. Existing evaluations often depend on a few scenarios, real user interaction, and subjective human scoring, which hinders systematic and quantitative comparison. To address these challenges, we propose ReqElicitGym, an interactive and automatic evaluation environment for assessing interview competence in conversational requirements elicitation. Specifically, ReqElicitGym introduces a new evaluation dataset and designs both an interactive oracle user and a task evaluator. The dataset contains 101 website requirements elicitation scenarios spanning 10 application types. Both the oracle user and the task evaluator achieve high agreement with real users and expert judgment. Using our ReqElicitGym, any automated conversational requirements elicitation approach (e.g., LLM-based agents) can be evaluated in a reproducible and quantitative manner through interaction with the environment. Based on our ReqElicitGym, we conduct a systematic empirical study on seven representative LLMs, and the results show that current LLMs still exhibit limited interview competence in uncovering implicit requirements. Particularly, they elicit less than half of the users' implicit requirements, and their effective elicitation questions often emerge in later turns of the dialogue. Besides, we found LLMs can elicit interaction and content implicit requirements, but consistently struggle with style-related requirements. We believe ReqElicitGym will facilitate the evaluation and development of automated conversational requirements elicitation.","authors":["Dongming Jin","Zhi Jin","Zheng Fang","Linyu Li","XiaoTian Yang","Yuanpeng He","Xiaohong Chen"],"pdf_url":"","comment":"22page, 7 figures"},{"id":"http://arxiv.org/abs/2602.18541v1","updated":"2026-02-20T15:22:13Z","published":"2026-02-20T15:22:13Z","title":"LAPIS: Lightweight API Specification for Intelligent Systems","summary":"Large Language Models (LLMs) increasingly serve as consumers of API specifications, whether for code generation, autonomous agent interaction, or API-assisted reasoning. The de facto standard for API description, OpenAPI, was designed for documentation tools and code generators, resulting in substantial token overhead when used as LLM context.\n  We present LAPIS (Lightweight API Specification for Intelligent Systems), a domain-specific format optimized for LLM consumption that preserves the semantic information necessary for API reasoning while minimizing token usage. Through empirical evaluation against five real-world production API specifications including GitHub (1,080 endpoints), Twilio (197 endpoints), DigitalOcean (545 endpoints), Petstore, and HTTPBin we demonstrate an average token reduction of 85.5% compared to OpenAPI YAML and 88.6% compared to OpenAPI JSON, measured with the cl100k_base tokenizer. LAPIS introduces domain-specific structural innovations, including centralized error definitions, webhook trigger conditions, structured rate limit descriptions, and operation flow declarations information that OpenAPI either duplicates redundantly or cannot represent at all.\n  The format is fully convertible from OpenAPI 3.x via an automated converter, requires no special parser for LLM consumption, and is released as an open specification under CC BY 4.0.","authors":["Daniel Garcia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18270v1","updated":"2026-02-20T14:52:18Z","published":"2026-02-20T14:52:18Z","title":"Many Tools, Few Exploitable Vulnerabilities: A Survey of 246 Static Code Analyzers for Security","summary":"Static security analysis is a widely used technique for detecting software vulnerabilities across a wide range of weaknesses, application domains, and programming languages. While prior work surveyed static analyzes for specific weaknesses or application domains, no overview of the entire security landscape exists. We present a systematic literature review of 246 static security analyzers concerning their targeted vulnerabilities, application domains, analysis techniques, evaluation methods, and limitations. We observe that most analyzers focus on a limited set of weaknesses, that the vulnerabilities they detect are rarely exploitable, and that evaluations use custom benchmarks that are too small to enable robust assessment.","authors":["Kevin Hermann","Sven Peldszus","Thorsten Berger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18537v1","updated":"2026-02-20T13:19:06Z","published":"2026-02-20T13:19:06Z","title":"Runtime-Augmented LLMs for Crash Detection and Diagnosis in ML Notebooks","summary":"Jupyter notebooks are widely used for machine learning (ML) development due to their support for interactive and iterative experimentation. However, ML notebooks are highly prone to bugs, with crashes being among the most disruptive. Despite their practical importance, systematic methods for crash detection and diagnosis in ML notebooks remain largely unexplored. We present CRANE-LLM, a novel approach that augments large language models (LLMs) with structured runtime information extracted from the notebook kernel state to detect and diagnose crashes before executing a target cell. Given previously executed cells and a target cell, CRANE-LLM combines static code context with runtime information, including object types, tensor shapes, and data attributes, to predict whether the target cell will crash (detection) and explain the underlying cause (diagnosis). We evaluate CRANE-LLM on JunoBench, a benchmark of 222 ML notebooks comprising 111 pairs of crashing and corresponding non-crashing notebooks across multiple ML libraries and crash root causes. Across three state-of-the-art LLMs (Gemini, Qwen, and GPT-5), runtime information improves crash detection and diagnosis by 7-10 percentage points in accuracy and 8-11 in F1-score, with larger gains for diagnosis. Improvements vary across ML libraries, crash causes, and LLMs, and depends on the integration of complementary categories of runtime information.","authors":["Yiran Wang","José Antonio Hernández López","Ulf Nilsson","Dániel Varró"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18190v1","updated":"2026-02-20T12:53:43Z","published":"2026-02-20T12:53:43Z","title":"Role and Identity Work of Software Engineering Professionals in the Generative AI Era","summary":"The adoption of Generative AI (GenAI) suggests major changes for software engineering, including technical aspects but also human aspects of the professionals involved. One of these aspects is how individuals perceive themselves regarding their work, i.e., their work identity, and the processes they perform to form, adapt and reject these identities, i.e., identity work. Existent studies provide evidence of such identity work of software professionals triggered by the adoption of GenAI, however they do not consider differences among diverse roles, such as developers and testers. In this paper, we argue the need for considering the role as a factor defining the identity work of software professionals. To support our claim, we review some studies regarding different roles and also recent studies on how to adopt GenAI in software engineering. Then, we propose a research agenda to better understand how the role influences identity work of software professionals triggered by the adoption of GenAI, and, based on that, to propose new artifacts to support this adoption. We also discuss the potential implications for practice of the results to be obtained.","authors":["Jorge Melegati"],"pdf_url":"","comment":"Accepted to the 19th International Conference on Cooperative and Human Aspects of Software Engineering (CHASE 2026)"},{"id":"http://arxiv.org/abs/2601.09282v2","updated":"2026-02-20T11:40:54Z","published":"2026-01-14T08:36:21Z","title":"Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing","summary":"Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration and presents a proof-of-concept design.","authors":["Leszek Sliwko","Jolanta Mizeria-Pietraszko"],"pdf_url":"","comment":"This is the accepted version of the paper published in IEEE Access (2026). The final version is available at: https://doi.org/10.1109/ACCESS.2026.3665989"},{"id":"http://arxiv.org/abs/2602.18142v1","updated":"2026-02-20T11:03:46Z","published":"2026-02-20T11:03:46Z","title":"Toward Automated Virtual Electronic Control Unit (ECU) Twins for Shift-Left Automotive Software Testing","summary":"Automotive software increasingly outpaces hardware availability, forcing late integration and expensive hardware-in-the-loop (HiL) bottlenecks. The InnoRegioChallenge project investigated whether a virtual test and integration environment can reproduce electronic control unit (ECU) behavior early enough to run real software binaries before physical hardware exists. We report a prototype that generates instruction-accurate processor models in SystemC/TLM~2.0 using an agentic, feedback-driven workflow coupled to a reference simulator via the GNU Debugger (GDB). The results indicate that the most critical technical risk -- CPU behavioral fidelity -- can be reduced through automated differential testing and iterative model correction. We summarize the architecture, the agentic modeling loop, and project outcomes, and we extrapolate plausible technical details consistent with the reported qualitative findings. While cloud-scale deployment and full toolchain integration remain future work, the prototype demonstrates a viable shift-left path for virtual ECU twins, enabling reproducible tests, non-intrusive tracing, and fault-injection campaigns aligned with safety standards.","authors":["Sebastian Dingler","Frederik Boenke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18534v1","updated":"2026-02-20T10:55:14Z","published":"2026-02-20T10:55:14Z","title":"Validated Code Translation for Projects with External Libraries","summary":"Large Language Models (LLMs) have shown promise for program translation, particularly for migrating systems code to memory-safe languages such as Rust. However, existing approaches struggle when source programs depend on external libraries: LLMs frequently hallucinate non-existent target APIs and fail to generate call-enabling imports; moreover, validating semantic equivalence is challenging when the code manipulates opaque, library-defined types. We present a translation and validation framework for translating Go projects with external dependencies to Rust. Our approach combines (i) a retrieval mechanism that maps Go library APIs to Rust APIs, and (ii) a cross-language validation pipeline that establishes language interoperability in the presence of opaque library types by synthesising adapters exclusively from public library APIs, prior to validating I/O equivalence. We evaluate our system on six real-world Go repositories with non-trivial external dependencies. Our approach significantly increases both the compilation and equivalence success rate (up to 100% in the most dependency-heavy case; approx. 2x on average) by enabling validated translation that manipulate opaque, library-defined types.","authors":["Hanliang Zhang","Arindam Sharma","Cristina David","Meng Wang","Brandon Paulsen","Daniel Kroening","Wenjia Ye","Taro Sekiyama"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01944v2","updated":"2026-02-20T10:14:27Z","published":"2026-01-05T09:50:37Z","title":"The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities","summary":"In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.\n  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.","authors":["Matteo Esposito","Andrea Janes","Valentina Lenarduzzi","Davide Taibi"],"pdf_url":"","comment":"ACCEPTED REGISTERED REPORT AT SANER (CORE A*) 2026"},{"id":"http://arxiv.org/abs/2506.03283v2","updated":"2026-02-20T10:01:46Z","published":"2025-06-03T18:15:14Z","title":"Exploring Generalizable Automated Program Repair with Large Language Models","summary":"Automated Program Repair (APR) proposes bug fixes to aid developers in maintaining software. The state of the art in this domain focuses on LLMs, leveraging their strong capabilities to comprehend specifications in natural language and to generate program code. However, despite the APR community's research achievements and industry deployments, APR still cannot generalize broadly. In this work, we present an intensive empirical evaluation of LLMs' capabilities in APR. We evaluate a diverse set of 13 recent open and closed models. In particular, we explore language-agnostic repair by utilizing benchmarks for Java, JavaScript, Python, and PHP. Besides the generalization across languages and levels of patch complexity, we also investigate the effects of fault localization (FL). Our key results include: (1) Different LLMs tend to perform best for different languages, which makes it hard to develop cross-platform, single-LLM repair techniques. (2) Combining models by pooling repairs adds value with respect to uniquely fixed bugs, so a committee of expert models should be considered. (3) Under realistic assumptions of imperfect FL, we observe significant drops in accuracy from the usual practice of using perfect FL. Our insights will help develop reliable and generalizable APR techniques and evaluate them in realistic and fair environments.","authors":["Viola Campos","Ridwan Shariffdeen","Adrian Ulges","Yannic Noller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18012v1","updated":"2026-02-20T05:54:58Z","published":"2026-02-20T05:54:58Z","title":"DeCEAT: Decoding Carbon Emissions for AI-driven Software Testing","summary":"The increasing use of language models in automated software testing raises concerns about their environmental impact, yet existing sustainability analyses focus almost exclusively on large language models. As a result, the energy and carbon characteristics of small language models (SLMs) during test generation remain largely unexplored. To address this gap, this work introduces the DeCEAT framework, which systematically evaluates the environmental and performance trade-offs of SLMs using the HumanEval benchmark and adaptive prompt variants (based on the Anthropic template). The framework quantifies emission and time-aware behavior under controlled conditions, with CodeCarbon measuring energy consumption and carbon emissions, and unit test coverage assessing the quality of generated tests. Our results show that different SLMs exhibit distinct sustainability strengths: some prioritize lower energy use and faster execution, while others maintain higher stability or accuracy under carbon constraints. These findings demonstrate that sustainability in the generation of SLM-driven tests is multidimensional and strongly shaped by prompt design. This work provides a focused sustainability evaluation framework specifically tailored to automated SLM-based test generation, clarifying how prompt structure and model choice jointly influence environmental and performance outcomes.","authors":["Pragati Kumari","Novarun Deb"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17955v1","updated":"2026-02-20T03:17:42Z","published":"2026-02-20T03:17:42Z","title":"Mining Type Constructs Using Patterns in AI-Generated Code","summary":"Artificial Intelligence (AI) increasingly automates various parts of the software development tasks. Although AI has enhanced the productivity of development tasks, it remains unstudied whether AI essentially outperforms humans in type-related programming tasks, such as employing type constructs properly for type safety, during its tasks. Moreover, there is no systematic study that evaluates whether AI agents overuse or misuse the type constructs under the complicated type systems to the same extent as humans. In this study, we present the first empirical analysis to answer these questions in the domain of TypeScript projects. Our findings show that, in contrast to humans, AI agents are 9x more prone to use the 'any' keyword. In addition, we observed that AI agents use advanced type constructs, including those that ignore type checks, more often compared to humans. Surprisingly, even with all these issues, Agentic pull requests (PRs) have 1.8x higher acceptance rates compared to humans for TypeScript. We encourage software developers to carefully confirm the type safety of their codebases whenever they coordinate with AI agents in the development process.","authors":["Imgyeong Lee","Tayyib Ul Hassan","Abram Hindle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26075v2","updated":"2026-02-20T03:03:41Z","published":"2025-10-30T02:17:32Z","title":"FGGM: Formal Grey-box Gradient Method for Attacking DRL-based MU-MIMO Scheduler","summary":"In 5G mobile communication systems, MU-MIMO has been applied to enhance spectral efficiency and support high data rates. To maximize spectral efficiency while providing fairness among users, the base station (BS) needs to selects a subset of users for data transmission. Given that this problem is NP-hard, DRL-based methods have been proposed to infer the near-optimal solutions in real-time, yet this approach has an intrinsic security problem. This paper investigates how a group of adversarial users can exploit unsanitized raw CSIs to launch a throughput degradation attack. Most existing studies only focused on systems in which adversarial users can obtain the exact values of victims' CSIs, but this is impractical in the case of uplink transmission in LTE/5G mobile systems. We note that the DRL policy contains an observation normalizer which has the mean and variance of the observation to improve training convergence. Adversarial users can then estimate the upper and lower bounds of the local observations including the CSIs of victims based solely on that observation normalizer. We develop an attacking scheme FGGM by leveraging polytope abstract domains, a technique used to bound the outputs of a neural network given the input ranges. Our goal is to find one set of intentionally manipulated CSIs which can achieve the attacking goals for the whole range of local observations of victims. Experimental results demonstrate that FGGM can determine a set of adversarial CSI vector controlled by adversarial users, then reuse those CSIs throughout the simulation to reduce the network throughput of a victim up to 70\\% without knowing the exact value of victims' local observations. This study serves as a case study and can be applied to many other DRL-based problems, such as a knapsack-oriented resource allocation problems.","authors":["Thanh Le","Hai Duong","Yusheng Ji","ThanhVu Nguyen","John C. S. Lui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.08801v3","updated":"2026-02-20T02:50:14Z","published":"2026-02-09T15:40:13Z","title":"Verifying DNN-based Semantic Communication Against Generative Adversarial Noise","summary":"Safety-critical applications like autonomous vehicles and industrial IoT are adopting semantic communication (SemCom) systems using deep neural networks to reduce bandwidth and increase transmission speed by transmitting only task-relevant semantic features.\n  However, adversarial attacks against these DNN-based SemCom systems can cause catastrophic failures by manipulating transmitted semantic features.\n  Existing defense mechanisms rely on empirical approaches provide no formal guarantees against the full spectrum of adversarial perturbations.\n  We present VSCAN, a neural network verification framework that provides mathematical robustness guarantees by formulating adversarial noise generation as mixed integer programming and verifying end-to-end properties across multiple interconnected networks (encoder, decoder, and task model).\n  Our key insight is that realistic adversarial constraints (power limitations and statistical undetectability) can be encoded as logical formulae to enable efficient verification using state-of-the-art DNN verifiers.\n  Our evaluation on 600 verification properties characterizing various attacker's capabilities shows VSCAN matches attack methods in finding vulnerabilities while providing formal robustness guarantees for 44% of properties -- a significant achievement given the complexity of multi-network verification.\n  Moreover, we reveal a fundamental security-efficiency tradeoff: compact 16-dimensional latent spaces achieve 50% verified robustness compared to 64-dimensional spaces.","authors":["Thanh Le","Hai Duong","ThanhVu Nguyen","Takeshi Matsumura"],"pdf_url":"","comment":"18 pages"}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2602.18624v1","updated":"2026-02-20T21:29:31Z","published":"2026-02-20T21:29:31Z","title":"Orbital Escalation: Modeling Satellite Ransomware Attacks Using Game Theory","summary":"Ransomware has yet to reach orbit, but the conditions for such an attack already exist. This paper presents the first game-theoretic framework for modeling ransomware against satellites: the orbital escalation game. In this model, the attacker escalates ransom demands across orbital passes, while the defender chooses their best strategy, e.g., attempt a restore procedure. Using dynamic programming, we solve the defender's optimal strategy and the attacker's expected payoff under real orbital constraints. Additionally, we provide a GPS III satellite case study that demonstrates how our orbital escalation game can be applied in the context of a fictional but feasible ransomware attack to derive the best strategies at every step. In conclusion, this foundational model offers satellite owners, policy makers and researchers, a formal framework to better prepare their responses when a spacecraft is held for ransom.","authors":["Efrén López-Morales"],"pdf_url":"","comment":"SpaceSec (Co-located with NDSS) version: https://www.ndss-symposium.org/ndss-paper/auto-draft-641/"},{"id":"http://arxiv.org/abs/2602.18598v1","updated":"2026-02-20T20:14:02Z","published":"2026-02-20T20:14:02Z","title":"Influence of Autoencoder Latent Space on Classifying IoT CoAP Attacks","summary":"The Internet of Things (IoT) presents a unique cybersecurity challenge due to its vast network of interconnected, resource-constrained devices. These vulnerabilities not only threaten data integrity but also the overall functionality of IoT systems. This study addresses these challenges by exploring efficient data reduction techniques within a model-based intrusion detection system (IDS) for IoT environments. Specifically, the study explores the efficacy of an autoencoder's latent space combined with three different classification techniques. Utilizing a validated IoT dataset, particularly focusing on the Constrained Application Protocol (CoAP), the study seeks to develop a robust model capable of identifying security breaches targeting this protocol. The research culminates in a comprehensive evaluation, presenting encouraging results that demonstrate the effectiveness of the proposed methodologies in strengthening IoT cybersecurity with more than a 99% of precision using only 2 learned features.","authors":["María Teresa García-Ordás","Jose Aveleira-Mata","Isaías García-Rodríguez","José Luis Casteleiro-Roca","Martín Bayón-Gutierrez","Héctor Alaiz-Moretón"],"pdf_url":"","comment":"16 pages , 2 figures , 1 table. Accepted for publication in Logic Journal of the IGPL"},{"id":"http://arxiv.org/abs/2510.15173v2","updated":"2026-02-20T18:09:26Z","published":"2025-10-16T22:26:18Z","title":"Beyond the Voice: Inertial Sensing of Mouth Motion for High Security Speech Verification","summary":"Voice interfaces are increasingly used in high stakes domains such as mobile banking, smart home security, and hands free healthcare. Meanwhile, modern generative models have made high quality voice forgeries inexpensive and easy to create, eroding confidence in voice authentication alone. To strengthen protection against such attacks, we present a second authentication factor that combines acoustic evidence with the unique motion patterns of a speaker's lower face. By placing lightweight inertial sensors around the mouth to capture mouth opening and evolving lower facial geometry, our system records a distinct motion signature with strong discriminative power across individuals. We built a prototype and recruited 43 participants to evaluate the system under four conditions seated, walking on level ground, walking on stairs, and speaking with different language backgrounds (native vs. non native English). Across all scenarios, our approach consistently achieved a median equal error rate (EER) of 0.01 or lower, indicating that mouth movement data remain robust under variations in gait, posture, and spoken language. We discuss specific use cases where this second line of defense could provide tangible security benefits to voice authentication systems.","authors":["Ynes Ineza","Muhammad A. Ullah","Abdul Serwadda","Aurore Munyaneza"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03770v3","updated":"2026-02-20T17:56:48Z","published":"2025-10-04T10:39:48Z","title":"Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data","summary":"Ensuring the trustworthiness of data from distributed and resource-constrained environments, such as Wireless Sensor Networks or IoT devices, is critical. Existing Reversible Data Hiding (RDH) methods for scalar data suffer from low embedding capacity and poor intrinsic mixing between host data and watermark. This paper introduces Hiding in the Imaginary Domain with Data Encryption (H[i]dden), a novel framework based on complex number arithmetic for simultaneous information embedding and encryption. The H[i]dden framework offers perfect reversibility, in-principle unlimited watermark size, and intrinsic data-watermark mixing. The paper further introduces two protocols: H[i]dden-EG, for joint reversible data hiding and encryption, and H[i]dden-AggP, for privacy-preserving aggregation of watermarked data, based on partially homomorphic encryption. These protocols provide efficient and resilient solutions for data integrity, provenance and confidentiality, serving as a foundation for new schemes based on the algebraic properties of the complex domain.","authors":["David Megias"],"pdf_url":"","comment":"21 pages, 5 figures"},{"id":"http://arxiv.org/abs/2602.18370v1","updated":"2026-02-20T17:26:47Z","published":"2026-02-20T17:26:47Z","title":"Drawing the LINE: Cryptographic Analysis and Security Improvements for the LINE E2EE Protocol","summary":"LINE has emerged as one of the most popular communication platforms in many East Asian countries, including Thailand and Japan, with millions of active users. Therefore, it is essential to understand its security guarantees. In this work, we present the first provable security analysis of the LINE version two (LINEv2) messaging protocol, focusing on its cryptographic guarantees in a real-world setting. We capture the architecture and security of the LINE messaging protocol by modifying the Multi-Stage Key Exchange (MSKE) model, a framework for analysing cryptographic protocols under adversarial conditions. While LINEv2 achieves basic security properties such as key indistinguishability and message authentication, we highlight the lack of forward secrecy (FS) and post-compromise security (PCS). To address this, we introduce a stronger version of the LINE protocol, introducing FS and PCS to LINE, analysing and benchmarking our results.","authors":["Benjamin Dowling","Prosanta Gope","Mehr U Nisa","Bhagya Wimalasiri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18352v1","updated":"2026-02-20T17:04:02Z","published":"2026-02-20T17:04:02Z","title":"Qualitative Coding Analysis through Open-Source Large Language Models: A User Study and Design Recommendations","summary":"Qualitative data analysis is labor-intensive, yet the privacy risks associated with commercial Large Language Models (LLMs) often preclude their use in sensitive research. To address this, we introduce ChatQDA, an on-device framework powered by open-source LLMs designed for privacy-preserving open coding. Our mixed-methods user study reveals that while participants rated the system highly for usability and perceived efficiency, they exhibited \"conditional trust\", valuing the tool for surface-level extraction while questioning its interpretive nuance and consistency. Furthermore, despite the technical security of local deployment, participants reported epistemic uncertainty regarding data protection, suggesting that invisible security measures are insufficient to foster trust. We conclude with design recommendations for local-first analysis tools that prioritize verifiable privacy and methodological rigor.","authors":["Tung T. Ngo","Dai Nguyen Van","Anh-Minh Nguyen","Phuong-Anh Do","Anh Nguyen-Quoc"],"pdf_url":"","comment":"6 pages. Accepted as Poster to CHI'26"},{"id":"http://arxiv.org/abs/2505.05370v3","updated":"2026-02-20T16:24:40Z","published":"2025-05-08T16:06:41Z","title":"Walrus: An Efficient Decentralized Storage Network","summary":"Decentralized storage systems face a fundamental trade-off between replication overhead, recovery efficiency, and security guarantees. Current approaches either rely on full replication, incurring substantial storage costs, or employ trivial erasure coding schemes that struggle with efficient recovery especially under high storage-node churn. We present Walrus, a novel decentralized blob storage system that addresses these limitations through multiple technical innovations. At the core of Walrus is RedStuff, a two-dimensional erasure coding protocol that achieves high security with only 4.5x replication factor, while enabling self-healing recovery that requires bandwidth proportional to only the lost data $(O(|blob|/n)$ versus $O(|blob|)$ in traditional systems). Crucially, RedStuff is the first protocol to support storage challenges in asynchronous networks, preventing adversaries from exploiting network delays to pass verification without actually storing data. Walrus also introduces a novel multi-stage epoch change protocol that efficiently handles storage node churn while maintaining uninterrupted availability during committee transitions. Our system incorporates authenticated data structures to defend against malicious clients and ensures data consistency throughout storage and retrieval processes. Experimental evaluation demonstrates that Walrus achieves practical performance at scale, making it suitable for a wide range of decentralized applications requiring high-integrity, available blob storage with reasonable overhead.","authors":["George Danezis","Giacomo Giuliari","Eleftherios Kokoris Kogias","Markus Legner","Jean-Pierre Smith","Alberto Sonnino","Karl Wüst"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18304v1","updated":"2026-02-20T16:01:16Z","published":"2026-02-20T16:01:16Z","title":"FeatureBleed: Inferring Private Enriched Attributes From Sparsity-Optimized AI Accelerators","summary":"Backend enrichment is now widely deployed in sensitive domains such as product recommendation pipelines, healthcare, and finance, where models are trained on confidential data and retrieve private features whose values influence inference behavior while remaining hidden from the API caller. This paper presents the first hardware-level backend retrieval data-stealing attack, showing that accelerator optimizations designed for performance can directly undermine data confidentiality and bypass state-of-the-art privacy defenses.\n  Our attack, FEATUREBLEED, exploits zero-skipping in AI accelerators to infer private backend-retrieved features solely through end-to-end timing, without relying on power analysis, DVFS manipulation, or shared-cache side channels. We evaluate FEATUREBLEED on three datasets spanning medical and non-medical domains: Texas-100X (clinical records), OrganAMNIST (medical imaging), and Census-19 (socioeconomic data). We further evaluate FEATUREBLEED across three hardware backends (Intel AVX, Intel AMX, and NVIDIA A100) and three model architectures (DNNs, CNNs, and hybrid CNN-MLP pipelines), demonstrating that the leakage generalizes across CPU and GPU accelerators, data modalities, and application domains, with an adversarial advantage of up to 98.87 percentage points.\n  Finally, we identify the root cause of the leakage as sparsity-driven zero-skipping in modern hardware. We quantify the privacy-performance-power trade-off: disabling zero-skipping increases Intel AMX per-operation energy by up to 25 percent and incurs 100 percent performance overhead. We propose a padding-based defense that masks timing leakage by equalizing responses to the worst-case execution time, achieving protection with only 7.24 percent average performance overhead and no additional power cost.","authors":["Darsh Asher","Farshad Dizani","Joshua Kalyanapu","Rosario Cammarota","Aydin Aysu","Samira Mirbagher Ajorpaz"],"pdf_url":"","comment":"4 pages, 3 figures, 3 tables, Journal :- IEEE CAL"},{"id":"http://arxiv.org/abs/2602.18285v1","updated":"2026-02-20T15:32:15Z","published":"2026-02-20T15:32:15Z","title":"Detecting PowerShell-based Fileless Cryptojacking Attacks Using Machine Learning","summary":"With the emergence of remote code execution (RCE) vulnerabilities in ubiquitous libraries and advanced social engineering techniques, threat actors have started conducting widespread fileless cryptojacking attacks. These attacks have become effective with stealthy techniques based on PowerShell-based exploitation in Windows OS environments. Even if attacks are detected and malicious scripts removed, processes may remain operational on victim endpoints, creating a significant challenge for detection mechanisms. In this paper, we conducted an experimental study with a collected dataset on detecting PowerShell-based fileless cryptojacking scripts. The results showed that Abstract Syntax Tree (AST)-based fine-tuned CodeBERT achieved a high recall rate, proving the importance of the use of AST integration and fine-tuned pre-trained models for programming language.","authors":["Said Varlioglu","Nelly Elsayed","Murat Ozer","Zag ElSayed","John M. Emmert"],"pdf_url":"","comment":"30 papges, Under Review"},{"id":"http://arxiv.org/abs/2602.18539v1","updated":"2026-02-20T14:54:22Z","published":"2026-02-20T14:54:22Z","title":"Poster: Privacy-Preserving Compliance Checks on Ethereum via Selective Disclosure","summary":"Digital identity verification often forces a privacy trade-off, where users must disclose sensitive personal data to prove simple eligibility criteria. As blockchain applications integrate with regulated environments, this over-disclosure creates significant risks of data breaches and surveillance. This work proposes a general Selective Disclosure Framework built on Ethereum, designed to decouple attribute verification from identity revelation. By utilizing client-side zk-SNARKs, the framework enables users to prove specific eligibility predicates without revealing underlying identity documents. We present a case study, ZK-Compliance, which implements a functional Grant, Verify, Revoke lifecycle for age verification. Preliminary results indicate that strict compliance requirements can be satisfied with negligible client-side latency (< 200 ms) while preserving the pseudonymous nature of public blockchains.","authors":["Supriya Khadka","Dhiman Goswami","Sanchari Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18270v1","updated":"2026-02-20T14:52:18Z","published":"2026-02-20T14:52:18Z","title":"Many Tools, Few Exploitable Vulnerabilities: A Survey of 246 Static Code Analyzers for Security","summary":"Static security analysis is a widely used technique for detecting software vulnerabilities across a wide range of weaknesses, application domains, and programming languages. While prior work surveyed static analyzes for specific weaknesses or application domains, no overview of the entire security landscape exists. We present a systematic literature review of 246 static security analyzers concerning their targeted vulnerabilities, application domains, analysis techniques, evaluation methods, and limitations. We observe that most analyzers focus on a limited set of weaknesses, that the vulnerabilities they detect are rarely exploitable, and that evaluations use custom benchmarks that are too small to enable robust assessment.","authors":["Kevin Hermann","Sven Peldszus","Thorsten Berger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.07199v4","updated":"2026-02-20T13:19:03Z","published":"2025-03-10T11:32:30Z","title":"How Well Can Differential Privacy Be Audited in One Run?","summary":"Recent methods for auditing the privacy of machine learning algorithms have improved computational efficiency by simultaneously intervening on multiple training examples in a single training run. Steinke et al. (2024) prove that one-run auditing indeed lower bounds the true privacy parameter of the audited algorithm, and give impressive empirical results. Their work leaves open the question of how precisely one-run auditing can uncover the true privacy parameter of an algorithm, and how that precision depends on the audited algorithm. In this work, we characterize the maximum achievable efficacy of one-run auditing and show that the key barrier to its efficacy is interference between the observable effects of different data elements. We present new conceptual approaches to minimize this barrier, towards improving the performance of one-run auditing of real machine learning algorithms.","authors":["Amit Keinan","Moshe Shenfeld","Katrina Ligett"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18172v1","updated":"2026-02-20T12:20:36Z","published":"2026-02-20T12:20:36Z","title":"Can AI Lower the Barrier to Cybersecurity? A Human-Centered Mixed-Methods Study of Novice CTF Learning","summary":"Capture-the-Flag (CTF) competitions serve as gateways into offensive cybersecurity, yet they often present steep barriers for novices due to complex toolchains and opaque workflows. Recently, agentic AI frameworks for cybersecurity promise to lower these barriers by automating and coordinating penetration testing tasks. However, their role in shaping novice learning remains underexplored.\n  We present a human-centered, mixed-methods case study examining how agentic AI frameworks -- here Cybersecurity AI (CAI) -- mediates novice entry into CTF-based penetration testing. An undergraduate student without prior hacking experience attempted to approach performance benchmarks from a national cybersecurity challenge using CAI. Quantitative performance metrics were complemented by structured reflective analysis of learning progression and AI interaction patterns.\n  Our thematic analysis suggest that agentic AI reduces initial entry barriers by providing overview, structure and guidance, thereby lowering the cognitive workload during early engagement. Quantitatively, the observed extensive exploration of strategies and low per-strategy execution time potetially facilitatates cybersecurity training on meta, i.e. strategic levels. At the same time, AI-assisted cybersecurity education introduces new challenges related to trust, dependency, and responsible use. We discuss implications for human-centered AI-supported cybersecurity education and outline open questions for future research.","authors":["Cathrin Schachner","Jasmin Wachter"],"pdf_url":"","comment":"A Preprint"},{"id":"http://arxiv.org/abs/2602.18165v1","updated":"2026-02-20T12:02:01Z","published":"2026-02-20T12:02:01Z","title":"Uncertainty-Aware Jamming Mitigation with Active RIS: A Robust Stackelberg Game Approach","summary":"Malicious jamming presents a pervasive threat to the secure communications, where the challenge becomes increasingly severe due to the growing capability of the jammer allowing the adaptation to legitimate transmissions. This paper investigates the jamming mitigation by leveraging an active reconfigurable intelligent surface (ARIS), where the channel uncertainties are particularly addressed for robust anti-jamming design. Towards this issue, we adopt the Stackelberg game formulation to model the strategic interaction between the legitimate side and the adversary, acting as the leader and follower, respectively. We prove the existence of the game equilibrium and adopt the backward induction method for equilibrium analysis. We first derive the optimal jamming policy as the follower's best response, which is then incorporated into the legitimate-side optimization for robust anti-jamming design. We address the uncertainty issue and reformulate the legitimate-side problem by exploiting the error bounds to combat the worst-case jamming attacks. The problem is decomposed within a block successive upper bound minimization (BSUM) framework to tackle the power allocation, transceiving beamforming, and active reflection, respectively, which are iterated towards the robust jamming mitigation scheme. Simulation results are provided to demonstrate the effectiveness of the proposed scheme in protecting the legitimate transmissions under uncertainties, and the superior performance in terms of jamming mitigation as compared with the baselines.","authors":["Xiao Tang","Zhen Ma","Limeng Dong","Yichen Wang","Qinghe Du","Dusit Niyato","Zhu Han"],"pdf_url":"","comment":"Accepted @ IEEE TIFS"},{"id":"http://arxiv.org/abs/2412.11471v2","updated":"2026-02-20T11:34:15Z","published":"2024-12-16T06:12:56Z","title":"TrapFlow: Controllable Website Fingerprinting Defense via Dynamic Backdoor Learning","summary":"Website fingerprinting (WF) attacks, which covertly monitor user communications to identify the web pages they visit, pose a serious threat to user privacy. Existing WF defenses attempt to reduce attack accuracy by disrupting traffic patterns, but attackers can retrain their models to adapt, making these defenses ineffective. Meanwhile, their high overhead limits deployability. To overcome these limitations, we introduce a novel controllable website fingerprinting defense called TrapFlow based on backdoor learning. TrapFlow exploits the tendency of neural networks to memorize subtle patterns by injecting crafted trigger sequences into targeted website traffic, causing the attacker model to build incorrect associations during training. If the attacker attempts to adapt by training on such noisy data, TrapFlow ensures that the model internalizes the trigger as a dominant feature, leading to widespread misclassification across unrelated websites. Conversely, if the attacker ignores these patterns and trains only on clean data, the trigger behaves as an adversarial patch at inference time, causing model misclassification. To achieve this dual effect, we optimize the trigger using a Fast Levenshtein like distance to maximize both its learnability and its distinctiveness from normal traffic. Experiments show that TrapFlow significantly reduces the accuracy of the RF attack from 99 percent to 6 percent with 74 percent data overhead. This compares favorably against two state of the art defenses: FRONT reduces accuracy by only 2 percent at a similar overhead, while Palette achieves 32 percent accuracy but with 48 percent more overhead. We further validate the practicality of our method in a real Tor network environment.","authors":["Siyuan Liang","Jiajun Gong","Tianmeng Fang","Aishan Liu","Tao Wang","Xiaochun Cao","Dacheng Tao","Ee-Chien Chang"],"pdf_url":"","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2601.19500v3","updated":"2026-02-20T09:22:30Z","published":"2026-01-27T11:38:09Z","title":"Reuse of Public Keys Across UTXO and Account-Based Cryptocurrencies","summary":"It is well known that reusing cryptocurrency addresses undermines privacy. This also applies if the same addresses are used in different cryptocurrencies. Nevertheless, cross-chain address reuse appears to be a recurring phenomenon, especially in EVM-based designs. Previous works performed either direct address matching, or basic format conversion, to identify such cases. However, seemingly incompatible address formats e.g., in Bitcoin and Ethereum, can also be derived from the same public keys, since they rely on the same cryptographic primitives. In this paper, we therefore focus on the underlying public keys to discover reuse within, as well as across, different cryptocurrency networks, enabling us to also match incompatible address formats. Specifically, we analyze key reuse across Bitcoin, Ethereum, Litecoin, Dogecoin, Zcash and Tron. Our results reveal that cryptographic keys are extensively and actively reused across these networks, negatively impacting both privacy and security of their users. We are hence the first to expose and quantify cross-chain key reuse between UTXO and account-based cryptocurrencies. Moreover, we devise novel clustering methods across these different cryptocurrency networks that do not rely on heuristics and instead link entities by their knowledge of the underlying secret key.","authors":["Rainer Stütz","Nicholas Stifter","Melitta Dragaschnig","Bernhard Haslhofer","Aljosha Judmayer"],"pdf_url":"","comment":"Accepted at Financial Cryptography and Data Security (FC) 2026. 36 pages, 9 figures"},{"id":"http://arxiv.org/abs/2602.18082v1","updated":"2026-02-20T09:15:51Z","published":"2026-02-20T09:15:51Z","title":"AndroWasm: an Empirical Study on Android Malware Obfuscation through WebAssembly","summary":"In recent years, stealthy Android malware has increasingly adopted sophisticated techniques to bypass automatic detection mechanisms and harden manual analysis. Adversaries typically rely on obfuscation, anti-repacking, steganography, poisoning, and evasion techniques to AI-based tools, and in-memory execution to conceal malicious functionality.\n  In this paper, we investigate WebAssembly (Wasm) as a novel technique for hiding malicious payloads and evading traditional static analysis and signature-matching mechanisms. While Wasm is typically employed to render specific gaming activities and interact with the native components in web browsers, we provide an in-depth analysis on the mechanisms Android may employ to include Wasm modules in its execution pipeline. Additionally, we provide Proofs-of-Concept to demonstrate a threat model in which an attacker embeds and executes malicious routines, effectively bypassing IoC detection by industrial state-of-the-art tools, like VirusTotal and MobSF.","authors":["Diego Soi","Silvia Lucia Sanna","Lorenzo Pisu","Leonardo Regano","Giorgio Giacinto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18079v1","updated":"2026-02-20T09:09:24Z","published":"2026-02-20T09:09:24Z","title":"Dynamic Deception: When Pedestrians Team Up to Fool Autonomous Cars","summary":"Many adversarial attacks on autonomous-driving perception models fail to cause system-level failures once deployed in a full driving stack. The main reason for such ineffectiveness is that once deployed in a system (e.g., within a simulator), attacks tend to be spatially or temporally short-lived, due to the vehicle's dynamics, hence rarely influencing the vehicle behaviour. In this paper, we address both limitations by introducing a system-level attack in which multiple dynamic elements (e.g., two pedestrians) carry adversarial patches (e.g., on cloths) and jointly amplify their effect through coordination and motion. We evaluate our attacks in the CARLA simulator using a state-of-the-art autonomous driving agent. At the system level, single-pedestrian attacks fail in all runs (out of 10), while dynamic collusion by two pedestrians induces full vehicle stops in up to 50\\% of runs, with static collusion yielding no successful attack at all. These results show that system-level failures arise only when adversarial signals persist over time and are amplified through coordinated actors, exposing a gap between model-level robustness and end-to-end safety.","authors":["Masoud Jamshidiyan Tehrani","Marco Gabriel","Jinhan Kim","Paolo Tonella"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18063v1","updated":"2026-02-20T08:31:18Z","published":"2026-02-20T08:31:18Z","title":"Distributed Security: From Isolated Properties to Synergistic Trust","summary":"Over the past four decades, distributed security has undergone a remarkable transformation -- from crash-fault tolerant protocols designed for controlled environments to sophisticated Byzantine-resilient architectures operating in open, adversarial settings. This vision paper examines this evolution and argues for a fundamental shift in how we approach distributed security: from studying individual security properties in isolation to understanding their synergistic combinations. We begin by conclude four foundational properties, \\textit{agreement, consistency, privacy, verifiability, accountability}. We trace their theoretical origins and practical maturation. We then demonstrate how the frontier of research now lies at the intersection of these properties, where their fusion creates capabilities that neither property could achieve alone. Looking forward, we identify critical research challenges: discovering new security properties driven by emerging applications, developing systematic frameworks for property convergence, managing the computational overhead of cryptographic primitives in high-performance consensus layers, and addressing post-quantum and human-factor challenges. The future of distributed security lies not in improving individual properties, but in understanding and harnessing their synergies to build a singular fabric of trust.","authors":["Minghui Xu"],"pdf_url":"","comment":"26 pages, 1 figure"},{"id":"http://arxiv.org/abs/2602.18034v1","updated":"2026-02-20T07:27:25Z","published":"2026-02-20T07:27:25Z","title":"Separating Non-Interactive Classical Verification of Quantum Computation from Falsifiable Assumptions","summary":"Mahadev [SIAM J. Comput. 2022] introduced the first protocol for classical verification of quantum computation based on the Learning-with-Errors (LWE) assumption, achieving a 4-message interactive scheme. This breakthrough naturally raised the question of whether fewer messages are possible in the plain model. Despite its importance, this question has remained unresolved.\n  In this work, we prove that there is no quantum black-box reduction of non-interactive classical verification of quantum computation of $\\textsf{QMA}$ to any falsifiable assumption. Here, \"non-interactive\" means that after an instance-independent setup, the protocol consists of a single message. This constitutes a strong negative result given that falsifiable assumptions cover almost all standard assumptions used in cryptography, including LWE. Our separation holds under the existence of a $\\textsf{QMA} \\text{-} \\textsf{QCMA}$ gap problem. Essentially, these problems require a slightly stronger assumption than $\\textsf{QMA}\\neq \\textsf{QCMA}$. To support the existence of such problems, we present a construction relative to a quantum unitary oracle.","authors":["Mohammed Barhoush","Tomoyuki Morimae","Ryo Nishimaki","Takashi Yamakawa"],"pdf_url":"","comment":"36 pages"},{"id":"http://arxiv.org/abs/2602.11495v2","updated":"2026-02-20T05:13:21Z","published":"2026-02-12T02:43:17Z","title":"Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models","summary":"Jailbreaking large language models (LLMs) has emerged as a critical security challenge with the widespread deployment of conversational AI systems. Adversarial users exploit these models through carefully crafted prompts to elicit restricted or unsafe outputs, a phenomenon commonly referred to as Jailbreaking. Despite numerous proposed defense mechanisms, attackers continue to develop adaptive prompting strategies, and existing models remain vulnerable. This motivates approaches that examine the internal behavior of LLMs rather than relying solely on prompt-level defenses. In this work, we study jailbreaking from both security and interpretability perspectives by analyzing how internal representations differ between jailbreak and benign prompts. We conduct a systematic layer-wise analysis across multiple open-source models, including GPT-J, LLaMA, Mistral, and the state-space model Mamba, and identify consistent latent-space patterns associated with harmful inputs. We then propose a tensor-based latent representation framework that captures structure in hidden activations and enables lightweight jailbreak detection without model fine-tuning or auxiliary LLM-based detectors. We further demonstrate that the latent signals can be used to actively disrupt jailbreak execution at inference time. On an abliterated LLaMA-3.1-8B model, selectively bypassing high-susceptibility layers blocks 78% of jailbreak attempts while preserving benign behavior on 94% of benign prompts. This intervention operates entirely at inference time and introduces minimal overhead, providing a scalable foundation for achieving stronger coverage by incorporating additional attack distributions or more refined susceptibility thresholds. Our results provide evidence that jailbreak behavior is rooted in identifiable internal structures and suggest a complementary, architecture-agnostic direction for improving LLM security.","authors":["Sri Durga Sai Sowmya Kadali","Evangelos E. Papalexakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17973v1","updated":"2026-02-20T03:58:48Z","published":"2026-02-20T03:58:48Z","title":"PenTiDef: Enhancing Privacy and Robustness in Decentralized Federated Intrusion Detection Systems against Poisoning Attacks","summary":"The increasing deployment of Federated Learning (FL) in Intrusion Detection Systems (IDS) introduces new challenges related to data privacy, centralized coordination, and susceptibility to poisoning attacks. While significant research has focused on protecting traditional FL-IDS with centralized aggregation servers, there remains a notable gap in addressing the unique challenges of decentralized FL-IDS (DFL-IDS). This study aims to address the limitations of traditional centralized FL-IDS by proposing a novel defense framework tailored for the decentralized FL-IDS architecture, with a focus on privacy preservation and robustness against poisoning attacks. We propose PenTiDef, a privacy-preserving and robust defense framework for DFL-IDS, which incorporates Distributed Differential Privacy (DDP) to protect data confidentiality and utilizes latent space representations (LSR) derived from neural networks to detect malicious updates in the decentralized model aggregation context. To eliminate single points of failure and enhance trust without a centralized aggregation server, PenTiDef employs a blockchain-based decentralized coordination mechanism that manages model aggregation, tracks update history, and supports trust enforcement through smart contracts. Experimental results on CIC-IDS2018 and Edge-IIoTSet demonstrate that PenTiDef consistently outperforms existing defenses (e.g., FLARE, FedCC) across various attack scenarios and data distributions. These findings highlight the potential of PenTiDef as a scalable and secure framework for deploying DFL-based IDS in adversarial environments. By leveraging privacy protection, malicious behavior detection in hidden data, and working without a central server, it provides a useful security solution against real-world attacks from untrust participants.","authors":["Phan The Duy","Nghi Hoang Khoa","Nguyen Tran Anh Quan","Luong Ha Tien","Ngo Duc Hoang Son","Van-Hau Pham"],"pdf_url":"","comment":null}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2602.18663v1","updated":"2026-02-20T23:50:35Z","published":"2026-02-20T23:50:35Z","title":"Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL)","summary":"Mechanical thrombectomy (MT) is typically the optimal treatment for acute ischemic stroke involving large vessel occlusions, but access is limited due to geographic and logistical barriers. Reinforcement learning (RL) shows promise in autonomous endovascular navigation, but generalization across 'long' navigation tasks remains challenging. We propose a Hierarchical Modular Multi-Agent Reinforcement Learning (HM-MARL) framework for autonomous two-device navigation in vitro, enabling efficient and generalizable navigation. HM-MARL was developed to autonomously navigate a guide catheter and guidewire from the femoral artery to the internal carotid artery (ICA). A modular multi-agent approach was used to decompose the complex navigation task into specialized subtasks, each trained using Soft Actor-Critic RL. The framework was validated in both in silico and in vitro testbeds to assess generalization and real-world feasibility. In silico, a single-vasculature model achieved 92-100% success rates on individual anatomies, while a multi-vasculature model achieved 56-80% across multiple patient anatomies. In vitro, both HM-MARL models successfully navigated 100% of trials from the femoral artery to the right common carotid artery and 80% to the right ICA but failed on the left-side vessel superhuman challenge due to the anatomy and catheter type used in navigation. This study presents the first demonstration of in vitro autonomous navigation in MT vasculature. While HM-MARL enables generalization across anatomies, the simulation-to-real transition introduces challenges. Future work will refine RL strategies using world models and validate performance on unseen in vitro data, advancing autonomous MT towards clinical translation.","authors":["Harry Robertshaw","Nikola Fischer","Lennart Karstensen","Benjamin Jackson","Xingyu Chen","S. M. Hadi Sadati","Christos Bergeles","Alejandro Granados","Thomas C Booth"],"pdf_url":"","comment":"Published in IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2602.18661v1","updated":"2026-02-20T23:40:16Z","published":"2026-02-20T23:40:16Z","title":"Robotic Fruits with Tunable Stiffness and Sensing: Towards a Methodology for Developing Realistic Physical Twins of Fruits","summary":"The global agri-food sector faces increasing challenges from labour shortages, high consumer demand, and supply-chain disruptions, resulting in substantial losses of unharvested produce. Robotic harvesting has emerged as a promising alternative; however, evaluating and training soft grippers for delicate fruits remains difficult due to the highly variable mechanical properties of natural produce. This makes it difficult to establish reliable benchmarks or data-driven control strategies. Existing testing practices rely on large quantities of real fruit to capture this variability, leading to inefficiency, higher costs, and waste. The methodology presented in this work aims to address these limitations by developing tunable soft physical twins that emulate the stiffness characteristics of real fruits at different ripeness levels. A fiber-reinforced pneumatic physical twin of a kiwi fruit was designed and fabricated to replicate the stiffness at different ripeness levels. Experimental results show that the stiffness of the physical twin can be tuned accurately over multiple trials (97.35 - 99.43% accuracy). Gripping tasks with a commercial robotic gripper showed that sensor feedback from the physical twin can reflect the applied gripping forces. Finally, a stress test was performed over 50 cycles showed reliable maintenance of desired stiffness (0.56 - 1.10% error). This work shows promise that robotic physical twins could adjust their stiffness to resemble that of real fruits. This can provide a sustainable, controllable platform for benchmarking and training robotic grippers.","authors":["Saitarun Nadipineni","Keshav Pandiyan","Kaspar Althoefer","Shinichi Hirai","Thilina Dulantha Lalitharatne"],"pdf_url":"","comment":"6 pages, 5 figures, 9th IEEE-RAS International Conference on Soft Robotics (RoboSoft) 2026"},{"id":"http://arxiv.org/abs/2602.18655v1","updated":"2026-02-20T23:11:56Z","published":"2026-02-20T23:11:56Z","title":"Infinite-Dimensional Closed-Loop Inverse Kinematics for Soft Robots via Neural Operators","summary":"While kinematic inversion is a purely geometric problem for fully actuated rigid robots, it becomes extremely challenging for underactuated soft robots with infinitely many degrees of freedom. Closed-loop inverse kinematics (CLIK) schemes address this by introducing end-to-end mappings from actuation to task space for the controller to operate on, but typically assume finite dimensions of the underlying virtual configuration space. In this work, we extend CLIK to the infinite-dimensional domain to reason about the entire soft robot shape while solving tasks. We do this by composing an actuation-to-shape map with a shape-to-task map, deriving the differential end-to-end kinematics via an infinite-dimensional chain rule, and thereby obtaining a Jacobian-based CLIK algorithm. Since the actuation-to-shape mapping is rarely available in closed form, we propose to learn it from simulation data using neural operator networks, which are differentiable. We first present an analytical study on a constant-curvature segment, and then apply the neural version of the algorithm to a three-fiber soft robotic arm whose underlying model relies on morphoelasticity and active filament theory. This opens new possibilities for differentiable control of soft robots by exploiting full-body shape information in a continuous, infinite-dimensional framework.","authors":["Carina Veil","Moritz Flaschel","Ellen Kuhl","Cosimo Della Santina"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18638v1","updated":"2026-02-20T22:16:49Z","published":"2026-02-20T22:16:49Z","title":"Soft Surfaced Vision-Based Tactile Sensing for Bipedal Robot Applications","summary":"Legged locomotion benefits from embodied sensing, where perception emerges from the physical interaction between body and environment. We present a soft-surfaced, vision-based tactile foot sensor that endows a bipedal robot with a skin-like deformable layer that captures contact deformations optically, turning foot-ground interactions into rich haptic signals. From a contact image stream, our method estimates contact pose (position and orientation), visualizes shear, computes center of pressure (CoP), classifies terrain, and detects geometric features of the contact patch. We validate these capabilities on a tilting platform and in visually obscured conditions, showing that foot-borne tactile feedback improves balance control and terrain awareness beyond proprioception alone. These findings suggest that integrating tactile perception into legged robot feet improves stability, adaptability, and environmental awareness, offering a promising direction toward more compliant and intelligent locomotion systems. For the supplementary video, please visit: https://youtu.be/ceJiy9q_2Aw","authors":["Jaeeun Kim","Junhee Lim","Yu She"],"pdf_url":"","comment":"8 pages, 11 figures, RoboSoft 2026. For the supplementary video, please visit: https://youtu.be/ceJiy9q_2Aw"},{"id":"http://arxiv.org/abs/2602.10116v2","updated":"2026-02-20T21:37:26Z","published":"2026-02-10T18:59:55Z","title":"SAGE: Scalable Agentic 3D Scene Generation for Embodied AI","summary":"Real-world data collection for embodied agents remains costly and unsafe, calling for scalable, realistic, and simulator-ready 3D environments. However, existing scene-generation systems often rely on rule-based or task-specific pipelines, yielding artifacts and physically invalid scenes. We present SAGE, an agentic framework that, given a user-specified embodied task (e.g., \"pick up a bowl and place it on the table\"), understands the intent and automatically generates simulation-ready environments at scale. The agent couples multiple generators for layout and object composition with critics that evaluate semantic plausibility, visual realism, and physical stability. Through iterative reasoning and adaptive tool selection, it self-refines the scenes until meeting user intent and physical validity. The resulting environments are realistic, diverse, and directly deployable in modern simulators for policy training. Policies trained purely on this data exhibit clear scaling trends and generalize to unseen objects and layouts, demonstrating the promise of simulation-driven scaling for embodied AI. Code, demos, and the SAGE-10k dataset can be found on the project page here: https://research.nvidia.com/labs/dir/sage/.","authors":["Hongchi Xia","Xuan Li","Zhaoshuo Li","Qianli Ma","Jiashu Xu","Ming-Yu Liu","Yin Cui","Tsung-Yi Lin","Wei-Chiu Ma","Shenlong Wang","Shuran Song","Fangyin Wei"],"pdf_url":"","comment":"Project Page: https://research.nvidia.com/labs/dir/sage/"},{"id":"http://arxiv.org/abs/2505.14858v2","updated":"2026-02-20T21:36:21Z","published":"2025-05-20T19:43:19Z","title":"Coordinated motion control of a wire arc additive manufacturing robotic system for multi-directional building parts","summary":"This work investigates the manufacturing of complex shapes parts with wire arc additive manufacturing (WAAM). In order to guarantee the integrity and quality of each deposited layer that composes the final piece, the deposition process is usually carried out in a flat position. However, for complex geometry parts with non-flat surfaces, this strategy causes unsupported overhangs and staircase effect, which contribute to a poor surface finishing. Generally, the build direction is not constant for every deposited section or layer in complex geometry parts. As a result, there is an additional concern to ensure the build direction is aligned with gravity, thus improving the quality of the final part. This paper proposes an algorithm to control the torch motion with respect to a deposition substrate as well as the torch orientation with respect to an inertial frame. The control scheme is based on task augmentation applied to an extended kinematic chain composed by two robots, which constitutes a coordinated control problem, and allows the deposition trajectory to be planned with respect to the deposition substrate coordinate frame while aligning each layer buildup direction with gravity (or any other direction defined for an inertial frame). Parts with complex geometry aspects have been produced in a WAAM cell composed by two robots (a manipulator with a welding torch and a positioning table holding the workpiece) in order to validate the proposed approach.","authors":["Fernando Coutinho","Nicolas Lizarralde","Fernando Lizarralde"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18622v1","updated":"2026-02-20T21:26:46Z","published":"2026-02-20T21:26:46Z","title":"FORMICA: Decision-Focused Learning for Communication-Free Multi-Robot Task Allocation","summary":"Most multi-robot task allocation methods rely on communication to resolve conflicts and reach consistent assignments. In environments with limited bandwidth, degraded infrastructure, or adversarial interference, existing approaches degrade sharply. We introduce a learning-based framework that achieves high-quality task allocation without any robot-to-robot communication. The key idea is that robots coordinate implicitly by predicting teammates' bids: if each robot can anticipate competition for a task, it can adjust its choices accordingly. Our method predicts bid distributions to correct systematic errors in analytical mean-field approximations. While analytical predictions assume idealized conditions (uniform distributions, known bid functions), our learned approach adapts to task clustering and spatial heterogeneity. Inspired by Smart Predict-then-Optimize (SPO), we train predictors end-to-end to minimize Task Allocation Regret rather than prediction error. To scale to large swarms, we develop a mean-field approximation where each robot predicts the distribution of competing bids rather than individual bids, reducing complexity from $O(NT)$ to $O(T)$. We call our approach FORMICA: Field-Oriented Regret-Minimizing Implicit Coordination Algorithm. Experiments show FORMICA substantially outperforms a natural analytical baseline. In scenarios with 16 robots and 64 tasks, our approach improves system reward by 17% and approaches the optimal MILP solution. When deployed on larger scenarios (256 robots, 4096 tasks), the same model improves performance by 7%, demonstrating strong generalization. Training requires only 21 seconds on a laptop, enabling rapid adaptation to new environments.","authors":["Antonio Lopez","Jack Muirhead","Carlo Pinciroli"],"pdf_url":"","comment":"13 pages, 2 figures, ANTS 2026"},{"id":"http://arxiv.org/abs/2602.18606v1","updated":"2026-02-20T20:49:07Z","published":"2026-02-20T20:49:07Z","title":"OVerSeeC: Open-Vocabulary Costmap Generation from Satellite Images and Natural Language","summary":"Aerial imagery provides essential global context for autonomous navigation, enabling route planning at scales inaccessible to onboard sensing. We address the problem of generating global costmaps for long-range planning directly from satellite imagery when entities and mission-specific traversal rules are expressed in natural language at test time. This setting is challenging since mission requirements vary, terrain entities may be unknown at deployment, and user prompts often encode compositional traversal logic. Existing approaches relying on fixed ontologies and static cost mappings cannot accommodate such flexibility. While foundation models excel at language interpretation and open-vocabulary perception, no single model can simultaneously parse nuanced mission directives, locate arbitrary entities in large-scale imagery, and synthesize them into an executable cost function for planners. We therefore propose OVerSeeC, a zero-shot modular framework that decomposes the problem into Interpret-Locate-Synthesize: (i) an LLM extracts entities and ranked preferences, (ii) an open-vocabulary segmentation pipeline identifies these entities from high-resolution imagery, and (iii) the LLM uses the user's natural language preferences and masks to synthesize executable costmap code. Empirically, OVerSeeC handles novel entities, respects ranked and compositional preferences, and produces routes consistent with human-drawn trajectories across diverse regions, demonstrating robustness to distribution shifts. This shows that modular composition of foundation models enables open-vocabulary, preference-aligned costmap generation for scalable, mission-adaptive global planning.","authors":["Rwik Rana","Jesse Quattrociocchi","Dongmyeong Lee","Christian Ellis","Amanda Adkins","Adam Uccello","Garrett Warnell","Joydeep Biswas"],"pdf_url":"","comment":"Website : https://amrl.cs.utexas.edu/overseec/"},{"id":"http://arxiv.org/abs/2602.18603v1","updated":"2026-02-20T20:38:47Z","published":"2026-02-20T20:38:47Z","title":"Enhancing Goal Inference via Correction Timing","summary":"Corrections offer a natural modality for people to provide feedback to a robot, by (i) intervening in the robot's behavior when they believe the robot is failing (or will fail) the task objectives and (ii) modifying the robot's behavior to successfully fulfill the task. Each correction offers information on what the robot should and should not do, where the corrected behavior is more aligned with task objectives than the original behavior. Most prior work on learning from corrections involves interpreting a correction as a new demonstration (consisting of the modified robot behavior), or a preference (for the modified trajectory compared to the robot's original behavior). However, this overlooks one essential element of the correction feedback, which is the human's decision to intervene in the robot's behavior in the first place. This decision can be influenced by multiple factors including the robot's task progress, alignment with human expectations, dynamics, motion legibility, and optimality. In this work, we investigate whether the timing of this decision can offer a useful signal for inferring these task-relevant influences. In particular, we investigate three potential applications for this learning signal: (1) identifying features of a robot's motion that may prompt people to correct it, (2) quickly inferring the final goal of a human's correction based on the timing and initial direction of their correction motion, and (3) learning more precise constraints for task objectives. Our results indicate that correction timing results in improved learning for the first two of these applications. Overall, our work provides new insights on the value of correction timing as a signal for robot learning.","authors":["Anjiabei Wang","Shuangge Wang","Tesca Fitzgerald"],"pdf_url":"","comment":"25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)"},{"id":"http://arxiv.org/abs/2602.18569v1","updated":"2026-02-20T19:16:54Z","published":"2026-02-20T19:16:54Z","title":"Design and Biomechanical Evaluation of a Lightweight Low-Complexity Soft Bilateral Ankle Exoskeleton","summary":"Many people could benefit from exoskeleton assistance during gait, for either medical or nonmedical purposes. But exoskeletons bring added mass and structure, which in turn require compensating for. In this work, we present a lightweight, low-complexity, soft bilateral ankle exoskeleton for plantarflexion assistance, with a shoe attachment design that can be mounted on top of any pair of shoes. Experimental tests show no significant difference in lower limb kinematics and kinetics when wearing the exoskeleton in zero-torque mode relative to not wearing an exoskeleton, showing that our device does not obstruct healthy gait, and proving it as a compliant and comfortable device, promising to provide effective assistance. Hence, a control system was developed, and additional tests are underway.","authors":["Josée Mallah","Zakii Javed","Zafer Azak","Thomas Stone","Luigi G. Occhipinti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2403.10991v2","updated":"2026-02-20T19:16:51Z","published":"2024-03-16T18:23:15Z","title":"Human-in-the-Loop Multi-Robot Information Gathering with Inverse Submodular Maximization","summary":"We consider a new type of inverse combinatorial optimization, Inverse Submodular Maximization (ISM), for its application in human-in-the-loop multi-robot information gathering.\n  Forward combinatorial optimization - solving a combinatorial problem given the reward (cost)-related parameters - is widely used in multi-robot coordination. In the standard pipeline, domain experts design the reward (cost)-related parameters offline. These parameters are utilized for coordinating robots online. What if non-expert human supervisors desire to change these parameters during task execution to adapt to some new requirements? We are interested in the case where human supervisors can suggest what path primitives to take, and the robots need to change the internal decision-making parameters accordingly. We study such problems from the perspective of inverse combinatorial optimization, i.e., the process of finding parameters that give certain solutions to the problem. Specifically, we propose a new formulation for ISM for a family of multi-robot information gathering scenarios, in which we aim to find a new set of parameters that minimally deviates from the current parameters while causing a greedy algorithm to output path primitives that are the same as those desired by the human supervisors. We show that for the case with a single suggestion, such problems can be formulated as a Mixed Integer Quadratic Program (MIQP), which is intractable for existing solvers when the problem size is large. We propose a new Branch $\\&$ Bound algorithm to solve such problems. For the case with multiple suggestions from several human supervisors, the problem can be cast as a multi-objective optimization and can be solved using Pareto Monte Carlo Tree Search. In numerical simulations, we demonstrate how to use ISM in multi-robot scientific data collection and event detection-driven coverage control.","authors":["Guangyao Shi","Shipeng Liu","Ellen Novoseller","Feifei Qian","Gaurav S. Sukhatme"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18424v1","updated":"2026-02-20T18:46:27Z","published":"2026-02-20T18:46:27Z","title":"CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation","summary":"Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav","authors":["Xia Su","Ruiqi Chen","Benlin Liu","Jingwei Ma","Zonglin Di","Ranjay Krishna","Jon Froehlich"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18421v1","updated":"2026-02-20T18:45:17Z","published":"2026-02-20T18:45:17Z","title":"Snapping Actuators with Asymmetric and Sequenced Motion","summary":"Snapping instabilities in soft structures offer a powerful pathway to achieve rapid and energy-efficient actuation. In this study, an eccentric dome-shaped snapping actuator is developed to generate controllable asymmetric motion through geometry-induced instability. Finite element simulations and experiments reveal consistent asymmetric deformation and the corresponding pressure characteristics. By coupling four snapping actuators in a pneumatic network, a compact quadrupedal robot achieves coordinated wavelike locomotion using only a single pressure input. The robot exhibits frequency-dependent performance with a maximum speed of 72.78~mm/s at 7.5~Hz. These findings demonstrate the potential of asymmetric snapping mechanisms for physically controlled actuation and lay the groundwork for fully untethered and efficient soft robotic systems.","authors":["Xin Li","Ye Jin","Mohsen Jafarpour","Hugo de Souza Oliveira","Edoardo Milana"],"pdf_url":"","comment":"9th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2026)"},{"id":"http://arxiv.org/abs/2602.18397v1","updated":"2026-02-20T18:02:28Z","published":"2026-02-20T18:02:28Z","title":"How Fast Can I Run My VLA? Demystifying VLA Inference Performance with VLA-Perf","summary":"Vision-Language-Action (VLA) models have recently demonstrated impressive capabilities across various embodied AI tasks. While deploying VLA models on real-world robots imposes strict real-time inference constraints, the inference performance landscape of VLA remains poorly understood due to the large combinatorial space of model architectures and inference systems. In this paper, we ask a fundamental research question: How should we design future VLA models and systems to support real-time inference? To address this question, we first introduce VLA-Perf, an analytical performance model that can analyze inference performance for arbitrary combinations of VLA models and inference systems. Using VLA-Perf, we conduct the first systematic study of the VLA inference performance landscape. From a model-design perspective, we examine how inference performance is affected by model scaling, model architectural choices, long-context video inputs, asynchronous inference, and dual-system model pipelines. From the deployment perspective, we analyze where VLA inference should be executed -- on-device, on edge servers, or in the cloud -- and how hardware capability and network performance jointly determine end-to-end latency. By distilling 15 key takeaways from our comprehensive evaluation, we hope this work can provide practical guidance for the design of future VLA models and inference systems.","authors":["Wenqi Jiang","Jason Clemons","Karu Sankaralingam","Christos Kozyrakis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.21022v2","updated":"2026-02-20T17:50:01Z","published":"2025-04-22T20:32:34Z","title":"ConformalNL2LTL: Translating Natural Language Instructions into Temporal Logic Formulas with Conformal Correctness Guarantees","summary":"Linear Temporal Logic (LTL) is a widely used task specification language for autonomous systems. To mitigate the significant manual effort and expertise required to define LTL-encoded tasks, several methods have been proposed for translating Natural Language (NL) instructions into LTL formulas, which, however, lack correctness guarantees. To address this, we propose a new NL-to-LTL translation method, called ConformalNL2LTL that achieves user-defined translation success rates on unseen NL commands. Our method constructs LTL formulas iteratively by solving a sequence of open-vocabulary question-answering (QA) problems using large language models (LLMs). These QA tasks are handled collaboratively by a primary and an auxiliary model. The primary model answers each QA instance while quantifying uncertainty via conformal prediction; when it is insufficiently certain according to user-defined confidence thresholds, it requests assistance from the auxiliary model and, if necessary, from the user. We demonstrate theoretically and empirically that ConformalNL2LTL achieves the desired translation accuracy while minimizing user intervention.","authors":["David Smith Sundarsingh","Jun Wang","Jyotirmoy V. Deshmukh","Yiannis Kantaros"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18386v1","updated":"2026-02-20T17:48:21Z","published":"2026-02-20T17:48:21Z","title":"Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO","summary":"Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.","authors":["Mohamed Elgouhary","Amr S. El-Wakeel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.01675v3","updated":"2026-02-20T17:46:41Z","published":"2025-10-02T05:00:24Z","title":"Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances","summary":"This work presents a geometric backstepping controller for a variable-tilt omnidirectional multirotor that explicitly accounts for both servo and rotor dynamics. Considering actuator dynamics is essential for more effective and reliable operation, particularly during aggressive flight maneuvers or recovery from sudden disturbances. While prior studies have investigated actuator-aware control for conventional and fixed-tilt multirotors, these approaches rely on linear relationships between actuator input and wrench, which cannot capture the nonlinearities induced by variable tilt angles. In this work, we exploit the cascade structure between the rigid-body dynamics of the multirotor and its nonlinear actuator dynamics to design the proposed backstepping controller and establish exponential stability of the overall system. Furthermore, we reveal parametric uncertainty in the actuator model through experiments, and we demonstrate that the proposed controller remains robust against such uncertainty. The controller was compared against a baseline that does not account for actuator dynamics across three experimental scenarios: fast translational tracking, rapid rotational tracking, and recovery from sudden disturbance. The proposed method consistently achieved better tracking performance, and notably, while the baseline diverged and crashed during the fastest translational trajectory tracking and the recovery experiment, the proposed controller maintained stability and successfully completed the tasks, thereby demonstrating its effectiveness.","authors":["Jaewoo Lee","Dongjae Lee","Jinwoo Lee","Hyungyu Lee","Yeonjoon Kim","H. Jin Kim"],"pdf_url":"","comment":"Accepted to ICRA 2026"},{"id":"http://arxiv.org/abs/2602.18379v1","updated":"2026-02-20T17:39:16Z","published":"2026-02-20T17:39:16Z","title":"Ori-Sense: origami capacitive sensing for soft robotic applications","summary":"This work introduces Ori-Sense, a compliant capacitive sensor inspired by the inverted Kresling origami pattern. The device translates torsional deformation into measurable capacitance changes, enabling proprioceptive feedback for soft robotic systems. Using dissolvable-core molding, we fabricated a monolithic silicone structure with embedded conductive TPU electrodes, forming an integrated soft capacitor. Mechanical characterization revealed low stiffness and minimal impedance, with torque values below 0.01 N mm for axial displacements between -15 mm and 15 mm, and up to 0.03 N mm at 30 degrees twist under compression. Finite-element simulations confirmed localized stresses along fold lines and validated the measured torque-rotation response. Electrical tests showed consistent capacitance modulation up to 30%, directly correlated with the twist angle, and maximal sensitivity of S_theta ~ 0.0067 pF/deg at 5 mm of axial deformation.","authors":["Hugo de Souza Oliveira","Xin Li","Mohsen Jafarpour","Edoardo Milana"],"pdf_url":"","comment":"9th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2026)"},{"id":"http://arxiv.org/abs/2602.18374v1","updated":"2026-02-20T17:30:25Z","published":"2026-02-20T17:30:25Z","title":"Zero-shot Interactive Perception","summary":"Interactive perception (IP) enables robots to extract hidden information in their workspace and execute manipulation plans by physically interacting with objects and altering the state of the environment -- crucial for resolving occlusions and ambiguity in complex, partially observable scenarios. We present Zero-Shot IP (ZS-IP), a novel framework that couples multi-strategy manipulation (pushing and grasping) with a memory-driven Vision Language Model (VLM) to guide robotic interactions and resolve semantic queries. ZS-IP integrates three key components: (1) an Enhanced Observation (EO) module that augments the VLM's visual perception with both conventional keypoints and our proposed pushlines -- a novel 2D visual augmentation tailored to pushing actions, (2) a memory-guided action module that reinforces semantic reasoning through context lookup, and (3) a robotic controller that executes pushing, pulling, or grasping based on VLM output. Unlike grid-based augmentations optimized for pick-and-place, pushlines capture affordances for contact-rich actions, substantially improving pushing performance. We evaluate ZS-IP on a 7-DOF Franka Panda arm across diverse scenes with varying occlusions and task complexities. Our experiments demonstrate that ZS-IP outperforms passive and viewpoint-based perception techniques such as Mark-Based Visual Prompting (MOKA), particularly in pushing tasks, while preserving the integrity of non-target elements.","authors":["Venkatesh Sripada","Frank Guerin","Amir Ghalamzan"],"pdf_url":"","comment":"Original manuscript submitted on April 24, 2025. Timestamped and publicly available on OpenReview: https://openreview.net/forum?id=7MhpFcr5Nx"},{"id":"http://arxiv.org/abs/2509.25124v2","updated":"2026-02-20T17:13:09Z","published":"2025-09-29T17:44:40Z","title":"Safe Planning in Unknown Environments Using Conformalized Semantic Maps","summary":"This paper addresses semantic planning problems in unknown environments under perceptual uncertainty. The environment contains multiple unknown semantically labeled regions or objects, and the robot must reach desired locations while maintaining class-dependent distances from them. We aim to compute robot paths that complete such semantic reach-avoid tasks with user-defined probability despite uncertain perception. Existing planning algorithms either ignore perceptual uncertainty, thus lacking correctness guarantees, or assume known sensor models and noise characteristics. In contrast, we present the first planner for semantic reach-avoid tasks that achieves user-specified mission completion rates without requiring any knowledge of sensor models or noise. This is enabled by quantifying uncertainty in semantic maps, constructed on-the-fly from perceptual measurements, using conformal prediction in a model and distribution free manner. We validate our approach and the theoretical mission completion rates through extensive experiments, showing that it consistently outperforms baselines in mission success rates.","authors":["David Smith Sundarsingh","Yifei Li","Tianji Tang","George J. Pappas","Nikolay Atanasov","Yiannis Kantaros"],"pdf_url":"","comment":"8 pages, 5 figures, 2 algorithms, 1 table"},{"id":"http://arxiv.org/abs/2602.18344v1","updated":"2026-02-20T16:52:52Z","published":"2026-02-20T16:52:52Z","title":"Downwash-aware Configuration Optimization for Modular Aerial Systems","summary":"This work proposes a framework that generates and optimally selects task-specific assembly configurations for a large group of homogeneous modular aerial systems, explicitly enforcing bounds on inter-module downwash. Prior work largely focuses on planar layouts and often ignores aerodynamic interference. In contrast, firstly we enumerate non-isomorphic connection topologies at scale; secondly, we solve a nonlinear program to check feasibility and select the configuration that minimizes control input subject to actuation limits and downwash constraints. We evaluate the framework in physics-based simulation and demonstrate it in real-world experiments.","authors":["Mengguang Li","Heinz Koeppl"],"pdf_url":"","comment":"Accepted to the IEEE International Conference on Robotics and Automation (ICRA) 2026"},{"id":"http://arxiv.org/abs/2602.18330v1","updated":"2026-02-20T16:35:51Z","published":"2026-02-20T16:35:51Z","title":"Tendon-Driven Reciprocating and Non-Reciprocating Motion via Snapping Metabeams","summary":"Snapping beams enable rapid geometric transitions through nonlinear instability, offering an efficient means of generating motion in soft robotic systems. In this study, a tendon-driven mechanism consisting of spiral-based metabeams was developed to exploit this principle for producing both reciprocating and non-reciprocating motion. The snapping structures were fabricated using fused deposition modeling with polylactic acid (PLA) and experimentally tested under different boundary conditions to analyze their nonlinear behavior. The results show that the mechanical characteristics, including critical forces and stability, can be tuned solely by adjusting the boundary constraints. The spiral geometry allows large reversible deformation even when made from a relatively stiff material such as PLA, providing a straightforward design concept for controllable snapping behavior. The developed mechanism was further integrated into a swimming robot, where tendon-driven fins exhibited two distinct actuation modes: reciprocating and non-reciprocating motion. The latter enabled efficient propulsion, producing a forward displacement of about 32 mm per 0.4 s cycle ($\\approx$ 81 mm/s, equivalent to 0.4 body lengths per second). This study highlights the potential of geometry-driven snapping structures for efficient and programmable actuation in soft robotic systems.","authors":["Mohsen Jafarpour","Ayberk Yüksek","Shahab Eshghi","Stanislav Gorb","Edoardo Milana"],"pdf_url":"","comment":"9th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2026)"},{"id":"http://arxiv.org/abs/2602.18314v1","updated":"2026-02-20T16:14:21Z","published":"2026-02-20T16:14:21Z","title":"Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting","summary":"Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.","authors":["Tianyi Song","Danail Stoyanov","Evangelos Mazomenos","Francisco Vasconcelos"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2507.08831v4","updated":"2026-02-20T16:14:13Z","published":"2025-07-05T18:04:35Z","title":"View Invariant Learning for Vision-Language Navigation in Continuous Environments","summary":"Vision-Language Navigation in Continuous Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is a key research problem in embodied AI. However, most existing approaches are sensitive to viewpoint changes, i.e. variations in camera height and viewing angle. Here we introduce a more general scenario, V$^2$-VLNCE (VLNCE with Varied Viewpoints) and propose a view-invariant post-training framework, called VIL (View Invariant Learning), that makes existing navigation policies more robust to changes in camera viewpoint. VIL employs a contrastive learning framework to learn sparse and view-invariant features. We also introduce a teacher-student framework for the Waypoint Predictor Module, a standard part of VLNCE baselines, where a view-dependent teacher model distills knowledge into a view-invariant student model. We employ an end-to-end training paradigm to jointly optimize these components. Empirical results show that our method outperforms state-of-the-art approaches on V$^2$-VLNCE by 8-15\\% measured on Success Rate for two standard benchmark datasets R2R-CE and RxR-CE. Evaluation of VIL in standard VLNCE settings shows that despite being trained for varied viewpoints, VIL often still improves performance. On the harder RxR-CE dataset, our method also achieved state-of-the-art performance across all metrics. This suggests that adding VIL does not diminish the standard viewpoint performance and can serve as a plug-and-play post-training method. We further evaluate VIL for simulated camera placements derived from real robot configurations (e.g. Stretch RE-1, LoCoBot), showing consistent improvements of performance. Finally, we present a proof-of-concept real-robot evaluation in two physical environments using a panoramic RGB sensor combined with LiDAR. The code is available at https://github.com/realjoshqsun/V2-VLNCE.","authors":["Josh Qixuan Sun","Huaiyuan Weng","Xiaoying Xing","Chul Min Yeum","Mark Crowley"],"pdf_url":"","comment":"This paper is accepted to RA-L 2026"},{"id":"http://arxiv.org/abs/2602.18312v1","updated":"2026-02-20T16:11:19Z","published":"2026-02-20T16:11:19Z","title":"Learning Smooth Time-Varying Linear Policies with an Action Jacobian Penalty","summary":"Reinforcement learning provides a framework for learning control policies that can reproduce diverse motions for simulated characters. However, such policies often exploit unnatural high-frequency signals that are unachievable by humans or physical robots, making them poor representations of real-world behaviors. Existing work addresses this issue by adding a reward term that penalizes a large change in actions over time. This term often requires substantial tuning efforts. We propose to use the action Jacobian penalty, which penalizes changes in action with respect to the changes in simulated state directly through auto differentiation. This effectively eliminates unrealistic high-frequency control signals without task specific tuning. While effective, the action Jacobian penalty introduces significant computational overhead when used with traditional fully connected neural network architectures. To mitigate this, we introduce a new architecture called a Linear Policy Net (LPN) that significantly reduces the computational burden for calculating the action Jacobian penalty during training. In addition, a LPN requires no parameter tuning, exhibits faster learning convergence compared to baseline methods, and can be more efficiently queried during inference time compared to a fully connected neural network. We demonstrate that a Linear Policy Net, combined with the action Jacobian penalty, is able to learn policies that generate smooth signals while solving a number of motion imitation tasks with different characteristics, including dynamic motions such as a backflip and various challenging parkour skills. Finally, we apply this approach to create policies for dynamic motions on a physical quadrupedal robot equipped with an arm.","authors":["Zhaoming Xie","Kevin Karol","Jessica Hodgins"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.00835v3","updated":"2026-02-20T15:50:11Z","published":"2025-02-02T16:16:53Z","title":"CAIMAN: Causal Action Influence Detection for Sample-efficient Loco-manipulation","summary":"Enabling legged robots to perform non-prehensile loco-manipulation is crucial for enhancing their versatility. Learning behaviors such as whole-body object pushing often requires sophisticated planning strategies or extensive task-specific reward shaping, especially in unstructured environments. In this work, we present CAIMAN, a practical reinforcement learning framework that encourages the agent to gain control over other entities in the environment. CAIMAN leverages causal action influence as an intrinsic motivation objective, allowing legged robots to efficiently acquire object pushing skills even under sparse task rewards. We employ a hierarchical control strategy, combining a low-level locomotion module with a high-level policy that generates task-relevant velocity commands and is trained to maximize the intrinsic reward. To estimate causal action influence, we learn the dynamics of the environment by integrating a kinematic prior with data collected during training. We empirically demonstrate CAIMAN's superior sample efficiency and adaptability to diverse scenarios in simulation, as well as its successful transfer to real-world systems without further fine-tuning. A video demo is available at https://www.youtube.com/watch?v=dNyvT04Cqaw.","authors":["Yuanchen Yuan","Jin Cheng","Núria Armengol Urpí","Stelian Coros"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2306.17544v4","updated":"2026-02-20T15:17:10Z","published":"2023-06-30T11:00:37Z","title":"Fusion of Visual-Inertial Odometry with LiDAR Relative Localization for Cooperative Guidance of a Micro-Scale Aerial Vehicle","summary":"A novel relative localization approach for guidance of a micro-scale Unmanned Aerial Vehicle (UAV) by a well-equipped aerial robot fusing Visual-Inertial Odometry (VIO) with Light Detection and Ranging (LiDAR) is proposed in this paper. LiDAR-based localization is accurate and robust to challenging environmental conditions, but 3D LiDARs are relatively heavy and require large UAV platforms, in contrast to lightweight cameras. However, visual-based self-localization methods exhibit lower accuracy and can suffer from significant drift with respect to the global reference frame. To benefit from both sensory modalities, we focus on cooperative navigation in a heterogeneous team of a primary LiDAR-equipped UAV and a secondary micro-scale camera-equipped UAV. We propose a novel cooperative approach combining LiDAR relative localization data with VIO output on board the primary UAV to obtain an accurate pose of the secondary UAV. The pose estimate is used to precisely and reliably guide the secondary UAV along trajectories defined in the primary UAV reference frame. The experimental evaluation has shown the superior accuracy of our method to the raw VIO output, reaching the average 3D Absolute Trajectory Error (ATE) of 0.28 m, and demonstrated its capability to guide the secondary UAV along desired trajectories while mitigating VIO drift. Thus, such a heterogeneous system can explore large areas with LiDAR precision, as well as visit locations inaccessible to the large LiDAR-carrying UAV platforms, as was showcased in a real-world cooperative mapping scenario.","authors":["Václav Pritzl","Matouš Vrba","Petr Štěpán","Martin Saska"],"pdf_url":"","comment":"Accepted version, accepted to IEEE Access"},{"id":"http://arxiv.org/abs/2602.18260v1","updated":"2026-02-20T14:44:16Z","published":"2026-02-20T14:44:16Z","title":"Role-Adaptive Collaborative Formation Planning for Team of Quadruped Robots in Cluttered Environments","summary":"This paper presents a role-adaptive Leader-Follower-based formation planning and control framework for teams of quadruped robots operating in cluttered environments. Unlike conventional methods with fixed leaders or rigid formation roles, the proposed approach integrates dynamic role assignment and partial goal planning, enabling flexible, collision-free navigation in complex scenarios. Formation stability and inter-robot safety are ensured through a virtual spring-damper system coupled with a novel obstacle avoidance layer that adaptively adjusts each agent's velocity. A dynamic look-ahead reference generator further enhances flexibility, allowing temporary formation deformation to maneuver around obstacles while maintaining goal-directed motion. The Fast Marching Square (FM2) algorithm provides the global path for the leader and local paths for the followers as the planning backbone. The framework is validated through extensive simulations and real-world experiments with teams of quadruped robots. Results demonstrate smooth coordination, adaptive role switching, and robust formation maintenance in complex, unstructured environments. A video featuring the simulation and physical experiments along with their associated visualizations can be found at https://youtu.be/scq37Tua9W4.","authors":["Magnus Norén","Marios-Nektarios Stamatopoulos","Avijit Banerjee","George Nikolakopoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18258v1","updated":"2026-02-20T14:43:46Z","published":"2026-02-20T14:43:46Z","title":"RoEL: Robust Event-based 3D Line Reconstruction","summary":"Event cameras in motion tend to detect object boundaries or texture edges, which produce lines of brightness changes, especially in man-made environments. While lines can constitute a robust intermediate representation that is consistently observed, the sparse nature of lines may lead to drastic deterioration with minor estimation errors. Only a few previous works, often accompanied by additional sensors, utilize lines to compensate for the severe domain discrepancies of event sensors along with unpredictable noise characteristics. We propose a method that can stably extract tracks of varying appearances of lines using a clever algorithmic process that observes multiple representations from various time slices of events, compensating for potential adversaries within the event data. We then propose geometric cost functions that can refine the 3D line maps and camera poses, eliminating projective distortions and depth ambiguities. The 3D line maps are highly compact and can be equipped with our proposed cost function, which can be adapted for any observations that can detect and extract line structures or projections of them, including 3D point cloud maps or image observations. We demonstrate that our formulation is powerful enough to exhibit a significant performance boost in event-based mapping and pose refinement across diverse datasets, and can be flexibly applied to multimodal scenarios. Our results confirm that the proposed line-based formulation is a robust and effective approach for the practical deployment of event-based perceptual modules. Project page: https://gwangtak.github.io/roel/","authors":["Gwangtak Bae","Jaeho Shin","Seunggu Kang","Junho Kim","Ayoung Kim","Young Min Kim"],"pdf_url":"","comment":"IEEE Transactions on Robotics (T-RO)"},{"id":"http://arxiv.org/abs/2602.18224v1","updated":"2026-02-20T14:04:27Z","published":"2026-02-20T14:04:27Z","title":"SimVLA: A Simple VLA Baseline for Robotic Manipulation","summary":"Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic manipulation, leveraging large-scale pre-training to achieve strong performance. The field has rapidly evolved with additional spatial priors and diverse architectural innovations. However, these advancements are often accompanied by varying training recipes and implementation details, which can make it challenging to disentangle the precise source of empirical gains. In this work, we introduce SimVLA, a streamlined baseline designed to establish a transparent reference point for VLA research. By strictly decoupling perception from control, using a standard vision-language backbone and a lightweight action head, and standardizing critical training dynamics, we demonstrate that a minimal design can achieve state-of-the-art performance. Despite having only 0.5B parameters, SimVLA outperforms multi-billion-parameter models on standard simulation benchmarks without robot pretraining. SimVLA also reaches on-par real-robot performance compared to pi0.5. Our results establish SimVLA as a robust, reproducible baseline that enables clear attribution of empirical gains to future architectural innovations. Website: https://frontierrobo.github.io/SimVLA","authors":["Yuankai Luo","Woping Chen","Tong Liang","Baiqiao Wang","Zhenguo Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18212v1","updated":"2026-02-20T13:51:05Z","published":"2026-02-20T13:51:05Z","title":"Design and Characterization of a Dual-DOF Soft Shoulder Exosuit with Volume-Optimized Pneumatic Actuator","summary":"Portable pneumatic systems for 2 degree-of-freedom (DOF) soft shoulder exosuits remain underexplored, and face fundamental trade-offs between torque output and dynamic response that are further compounded by the need for multiple actuators to support complex shoulder movement. This work addresses these constraints through a volume-optimized spindle-shaped angled actuator (SSAA) geometry: by reducing actuator volume by 35.7% (357mL vs. 555mL), the SSAA maintains 94.2% of output torque while achieving 35.2% faster dynamic response compared to uniform cylindrical designs. Building on the SSAA, we develop a curved abduction actuator (CAA) based on the SSAA geometry and a horizontal adduction actuator (HAA) based on the pouch motor principle, integrating both into a dual-DOF textile-based shoulder exosuit (390 g). The exosuit delivers multi-modal assistance spanning shoulder abduction, flexion, and horizontal adduction, depending on the actuation.\n  User studies with 10 healthy participants reveal that the exosuit substantially reduces electromyographic (EMG) activity across both shoulder abduction and flexion tasks. For abduction with HAA only, the exosuit achieved up to 59% muscle activity reduction across seven muscles. For flexion, both the single-actuator configuration (HAA only) and the dual-actuator configuration (HAA,+,CAA) reduced EMG activity by up to 63.7% compared to no assistance. However, the incremental benefit of adding the CAA to existing HAA support was limited in healthy users during flexion, with statistically significant additional reductions observed only in pectoralis major. These experimental findings characterize actuator contributions in healthy users and provide design guidance for multi-DOF exosuit systems.","authors":["Rui Chen","Domenico Chiaradia","Daniele Leonardis","Antonio Frisoli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.17991v2","updated":"2026-02-20T13:21:33Z","published":"2026-01-25T20:44:03Z","title":"Prosthetic Hand Manipulation System Based on EMG and Eye Tracking Powered by the Neuromorphic Processor AltAi","summary":"This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.","authors":["Roman Akinshin","Elizaveta Lopatina","Kirill Bogatikov","Nikolai Kiz","Anna V. Makarova","Mikhail Lebedev","Miguel Altamirano Cabrera","Dzmitry Tsetserukou","Valerii Kangler"],"pdf_url":"","comment":"This paper has been accepted for publication at LBR of HRI 2026 conference"},{"id":"http://arxiv.org/abs/2602.18174v1","updated":"2026-02-20T12:23:46Z","published":"2026-02-20T12:23:46Z","title":"Have We Mastered Scale in Deep Monocular Visual SLAM? The ScaleMaster Dataset and Benchmark","summary":"Recent advances in deep monocular visual Simultaneous Localization and Mapping (SLAM) have achieved impressive accuracy and dense reconstruction capabilities, yet their robustness to scale inconsistency in large-scale indoor environments remains largely unexplored. Existing benchmarks are limited to room-scale or structurally simple settings, leaving critical issues of intra-session scale drift and inter-session scale ambiguity insufficiently addressed. To fill this gap, we introduce the ScaleMaster Dataset, the first benchmark explicitly designed to evaluate scale consistency under challenging scenarios such as multi-floor structures, long trajectories, repetitive views, and low-texture regions. We systematically analyze the vulnerability of state-of-the-art deep monocular visual SLAM systems to scale inconsistency, providing both quantitative and qualitative evaluations. Crucially, our analysis extends beyond traditional trajectory metrics to include a direct map-to-map quality assessment using metrics like Chamfer distance against high-fidelity 3D ground truth. Our results reveal that while recent deep monocular visual SLAM systems demonstrate strong performance on existing benchmarks, they suffer from severe scale-related failures in realistic, large-scale indoor environments. By releasing the ScaleMaster dataset and baseline results, we aim to establish a foundation for future research toward developing scale-consistent and reliable visual SLAM systems.","authors":["Hyoseok Ju","Bokeon Suh","Giseop Kim"],"pdf_url":"","comment":"8 pages, 9 figures, accepted to ICRA 2026"},{"id":"http://arxiv.org/abs/2602.18164v1","updated":"2026-02-20T11:57:52Z","published":"2026-02-20T11:57:52Z","title":"GrandTour: A Legged Robotics Dataset in the Wild for Multi-Modal Perception and State Estimation","summary":"Accurate state estimation and multi-modal perception are prerequisites for autonomous legged robots in complex, large-scale environments. To date, no large-scale public legged-robot dataset captures the real-world conditions needed to develop and benchmark algorithms for legged-robot state estimation, perception, and navigation. To address this, we introduce the GrandTour dataset, a multi-modal legged-robotics dataset collected across challenging outdoor and indoor environments, featuring an ANYbotics ANYmal-D quadruped equipped with the \\boxi multi-modal sensor payload. GrandTour spans a broad range of environments and operational scenarios across distinct test sites, ranging from alpine scenery and forests to demolished buildings and urban areas, and covers a wide variation in scale, complexity, illumination, and weather conditions. The dataset provides time-synchronized sensor data from spinning LiDARs, multiple RGB cameras with complementary characteristics, proprioceptive sensors, and stereo depth cameras. Moreover, it includes high-precision ground-truth trajectories from satellite-based RTK-GNSS and a Leica Geosystems total station. This dataset supports research in SLAM, high-precision state estimation, and multi-modal learning, enabling rigorous evaluation and development of new approaches to sensor fusion in legged robotic systems. With its extensive scope, GrandTour represents the largest open-access legged-robotics dataset to date. The dataset is available at https://grand-tour.leggedrobotics.com, on HuggingFace (ROS-independent), and in ROS formats, along with tools and demo resources.","authors":["Jonas Frey","Turcan Tuna","Frank Fu","Katharine Patterson","Tianao Xu","Maurice Fallon","Cesar Cadena","Marco Hutter"],"pdf_url":"","comment":"Jonas Frey and Turcan Tuna contributed equally. Submitted to Sage The International Journal of Robotics Research"},{"id":"http://arxiv.org/abs/2602.16898v2","updated":"2026-02-20T10:41:16Z","published":"2026-02-18T21:28:56Z","title":"MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation","summary":"Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.MALLVi present a Multi Agent Large Language and Vision framework that enables closed loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVi generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step Rather than using a single model, MALLVi coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning.Experiments in simulation and real world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks.Code available at https://github.com/iman1234ahmadi/MALLVI.","authors":["Iman Ahmadi","Mehrshad Taji","Arad Mahdinezhad Kashani","AmirHossein Jadidi","Saina Kashani","Babak Khalaj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17393v2","updated":"2026-02-20T10:01:04Z","published":"2026-02-19T14:18:26Z","title":"Contact-Anchored Proprioceptive Odometry for Quadruped Robots","summary":"Reliable odometry for legged robots without cameras or LiDAR remains challenging due to IMU drift and noisy joint velocity sensing. This paper presents a purely proprioceptive state estimator that uses only IMU and motor measurements to jointly estimate body pose and velocity, with a unified formulation applicable to biped, quadruped, and wheel-legged robots. The key idea is to treat each contacting leg as a kinematic anchor: joint-torque--based foot wrench estimation selects reliable contacts, and the corresponding footfall positions provide intermittent world-frame constraints that suppress long-term drift. To prevent elevation drift during extended traversal, we introduce a lightweight height clustering and time-decay correction that snaps newly recorded footfall heights to previously observed support planes. To improve foot velocity observations under encoder quantization, we apply an inverse-kinematics cubature Kalman filter that directly filters foot-end velocities from joint angles and velocities. The implementation further mitigates yaw drift through multi-contact geometric consistency and degrades gracefully to a kinematics-derived heading reference when IMU yaw constraints are unavailable or unreliable. We evaluate the method on four quadruped platforms (three Astrall robots and a Unitree Go2 EDU) using closed-loop trajectories. On Astrall point-foot robot~A, a $\\sim$200\\,m horizontal loop and a $\\sim$15\\,m vertical loop return with 0.1638\\,m and 0.219\\,m error, respectively; on wheel-legged robot~B, the corresponding errors are 0.2264\\,m and 0.199\\,m. On wheel-legged robot~C, a $\\sim$700\\,m horizontal loop yields 7.68\\,m error and a $\\sim$20\\,m vertical loop yields 0.540\\,m error. Unitree Go2 EDU closes a $\\sim$120\\,m horizontal loop with 2.2138\\,m error and a $\\sim$8\\,m vertical loop with less than 0.1\\,m vertical error. github.com/ShineMinxing/Ros2Go2Estimator.git","authors":["Minxing Sun","Yao Mao"],"pdf_url":"","comment":"28 pages, 26 figures"},{"id":"http://arxiv.org/abs/2602.15060v2","updated":"2026-02-20T09:51:55Z","published":"2026-02-13T12:03:13Z","title":"CLOT: Closed-Loop Global Motion Tracking for Whole-Body Humanoid Teleoperation","summary":"Long-horizon whole-body humanoid teleoperation remains challenging due to accumulated global pose drift, particularly on full-sized humanoids. Although recent learning-based tracking methods enable agile and coordinated motions, they typically operate in the robot's local frame and neglect global pose feedback, leading to drift and instability during extended execution. In this work, we present CLOT, a real-time whole-body humanoid teleoperation system that achieves closed-loop global motion tracking via high-frequency localization feedback. CLOT synchronizes operator and robot poses in a closed loop, enabling drift-free human-to-humanoid mimicry over long timehorizons. However, directly imposing global tracking rewards in reinforcement learning, often results in aggressive and brittle corrections. To address this, we propose a data-driven randomization strategy that decouples observation trajectories from reward evaluation, enabling smooth and stable global corrections. We further regularize the policy with an adversarial motion prior to suppress unnatural behaviors. To support CLOT, we collect 20 hours of carefully curated human motion data for training the humanoid teleoperation policy. We design a transformer-based policy and train it for over 1300 GPU hours. The policy is deployed on a full-sized humanoid with 31 DoF (excluding hands). Both simulation and real-world experiments verify high-dynamic motion, high-precision tracking, and strong robustness in sim-to-real humanoid teleoperation. Motion data, demos and code can be found in our website.","authors":["Tengjie Zhu","Guanyu Cai","Yang Zhaohui","Guanzhu Ren","Haohui Xie","ZiRui Wang","Junsong Wu","Jingbo Wang","Xiaokang Yang","Yao Mu","Yichao Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18097v1","updated":"2026-02-20T09:38:38Z","published":"2026-02-20T09:38:38Z","title":"Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning","summary":"In this paper, we present a framework for enabling autonomous vehicles to interact with cyclists in a manner that balances safety and optimality. The approach integrates Hamilton-Jacobi reachability analysis with deep Q-learning to jointly address safety guarantees and time-efficient navigation. A value function is computed as the solution to a time-dependent Hamilton-Jacobi-Bellman inequality, providing a quantitative measure of safety for each system state. This safety metric is incorporated as a structured reward signal within a reinforcement learning framework. The method further models the cyclist's latent response to the vehicle, allowing disturbance inputs to reflect human comfort and behavioral adaptation. The proposed framework is evaluated through simulation and comparison with human driving behavior and an existing state-of-the-art method.","authors":["Aarati Andrea Noronha","Jean Oh"],"pdf_url":"","comment":"7 pages. This manuscript was completed in 2020 as part of the first author's graduate thesis at Carnegie Mellon University"},{"id":"http://arxiv.org/abs/2602.18532v1","updated":"2026-02-20T09:26:17Z","published":"2026-02-20T09:26:17Z","title":"VLANeXt: Recipes for Building Strong VLA Models","summary":"Following the rise of large foundation models, Vision-Language-Action models (VLAs) emerged, leveraging strong visual and language understanding for general-purpose policy learning. Yet, the current VLA landscape remains fragmented and exploratory. Although many groups have proposed their own VLA models, inconsistencies in training protocols and evaluation settings make it difficult to identify which design choices truly matter. To bring structure to this evolving space, we reexamine the VLA design space under a unified framework and evaluation setup. Starting from a simple VLA baseline similar to RT-2 and OpenVLA, we systematically dissect design choices along three dimensions: foundational components, perception essentials, and action modelling perspectives. From this study, we distill 12 key findings that together form a practical recipe for building strong VLA models. The outcome of this exploration is a simple yet effective model, VLANeXt. VLANeXt outperforms prior state-of-the-art methods on the LIBERO and LIBERO-plus benchmarks and demonstrates strong generalization in real-world experiments. We will release a unified, easy-to-use codebase that serves as a common platform for the community to reproduce our findings, explore the design space, and build new VLA variants on top of a shared foundation.","authors":["Xiao-Ming Wu","Bin Fan","Kang Liao","Jian-Jian Jiang","Runze Yang","Yihang Luo","Zhonghua Wu","Wei-Shi Zheng","Chen Change Loy"],"pdf_url":"","comment":"17 pages, 11 figures, Project Page: https://dravenalg.github.io/VLANeXt/"},{"id":"http://arxiv.org/abs/2505.23147v2","updated":"2026-02-20T09:25:25Z","published":"2025-05-29T06:38:30Z","title":"Eye-tracking-Driven Shared Control for Robotic Arms: Wizard of Oz Studies to Assess Design Choices","summary":"Advances in eye-tracking control for assistive robotic arms provide intuitive interaction opportunities for people with physical disabilities. Shared control has gained interest in recent years by improving user satisfaction through partial automation of robot control. We present an eye-tracking-guided shared control design based on insights from state-of-the-art literature. A Wizard of Oz setup was used in which automation was simulated by an experimenter to evaluate the concept without requiring full implementation. This approach allowed for rapid exploration of user needs and expectations to inform future iterations. Two studies were conducted to assess user experience, identify design challenges, and find improvements to ensure usability and accessibility. The first study involved people with disabilities by providing a survey, and the second study used the Wizard of Oz design in person to gain technical insights, leading to a comprehensive picture of findings.","authors":["Anke Fischer-Janzen","Thomas M. Wendt","Daniel Görlich","Kristof Van Laerhoven"],"pdf_url":"","comment":"Preprint, 23 pages"},{"id":"http://arxiv.org/abs/2507.00319v2","updated":"2026-02-20T09:11:16Z","published":"2025-06-30T23:23:24Z","title":"When Digital Twins Meet Large Language Models: Realistic, Interactive, and Editable Simulation for Autonomous Driving","summary":"Simulation frameworks have been key enablers for the development and validation of autonomous driving systems. However, existing methods struggle to comprehensively address the autonomy-oriented requirements of balancing: (i) dynamical fidelity, (ii) photorealistic rendering, (iii) context-relevant scenario orchestration, and (iv) real-time performance. To address these limitations, we present a unified framework for creating and curating high-fidelity digital twins to accelerate advancements in autonomous driving research. Our framework leverages a mix of physics-based and data-driven techniques for developing and simulating digital twins of autonomous vehicles and their operating environments. It is capable of reconstructing real-world scenes and assets with geometric and photorealistic accuracy (~97% structural similarity) and infusing them with physical properties to enable real-time (>60 Hz) dynamical simulation of the ensuing driving scenarios. Additionally, it incorporates a large language model (LLM) interface to flexibly edit the driving scenarios online via natural language prompts, with ~85% generalizability and ~95% repeatability. Finally, an optional vision language model (VLM) provides ~80% visual enhancement by blending the hybrid scene composition.","authors":["Tanmay Vilas Samak","Chinmay Vilas Samak","Bing Li","Venkat Krovi"],"pdf_url":"","comment":"Accepted in IEEE Robotics & Automation Magazine (RAM)"},{"id":"http://arxiv.org/abs/2602.18079v1","updated":"2026-02-20T09:09:24Z","published":"2026-02-20T09:09:24Z","title":"Dynamic Deception: When Pedestrians Team Up to Fool Autonomous Cars","summary":"Many adversarial attacks on autonomous-driving perception models fail to cause system-level failures once deployed in a full driving stack. The main reason for such ineffectiveness is that once deployed in a system (e.g., within a simulator), attacks tend to be spatially or temporally short-lived, due to the vehicle's dynamics, hence rarely influencing the vehicle behaviour. In this paper, we address both limitations by introducing a system-level attack in which multiple dynamic elements (e.g., two pedestrians) carry adversarial patches (e.g., on cloths) and jointly amplify their effect through coordination and motion. We evaluate our attacks in the CARLA simulator using a state-of-the-art autonomous driving agent. At the system level, single-pedestrian attacks fail in all runs (out of 10), while dynamic collusion by two pedestrians induces full vehicle stops in up to 50\\% of runs, with static collusion yielding no successful attack at all. These results show that system-level failures arise only when adversarial signals persist over time and are amplified through coordinated actors, exposing a gap between model-level robustness and end-to-end safety.","authors":["Masoud Jamshidiyan Tehrani","Marco Gabriel","Jinhan Kim","Paolo Tonella"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18071v1","updated":"2026-02-20T08:54:20Z","published":"2026-02-20T08:54:20Z","title":"EgoPush: Learning End-to-End Egocentric Multi-Object Rearrangement for Mobile Robots","summary":"Humans can rearrange objects in cluttered environments using egocentric perception, navigating occlusions without global coordinates. Inspired by this capability, we study long-horizon multi-object non-prehensile rearrangement for mobile robots using a single egocentric camera. We introduce EgoPush, a policy learning framework that enables egocentric, perception-driven rearrangement without relying on explicit global state estimation that often fails in dynamic scenes. EgoPush designs an object-centric latent space to encode relative spatial relations among objects, rather than absolute poses. This design enables a privileged reinforcement-learning (RL) teacher to jointly learn latent states and mobile actions from sparse keypoints, which is then distilled into a purely visual student policy. To reduce the supervision gap between the omniscient teacher and the partially observed student, we restrict the teacher's observations to visually accessible cues. This induces active perception behaviors that are recoverable from the student's viewpoint. To address long-horizon credit assignment, we decompose rearrangement into stage-level subproblems using temporally decayed, stage-local completion rewards. Extensive simulation experiments demonstrate that EgoPush significantly outperforms end-to-end RL baselines in success rate, with ablation studies validating each design choice. We further demonstrate zero-shot sim-to-real transfer on a mobile platform in the real world. Code and videos are available at https://ai4ce.github.io/EgoPush/.","authors":["Boyuan An","Zhexiong Wang","Yipeng Wang","Jiaqi Li","Sihang Li","Jing Zhang","Chen Feng"],"pdf_url":"","comment":"18 pages, 13 figures. Project page: https://ai4ce.github.io/EgoPush/"},{"id":"http://arxiv.org/abs/2602.18025v1","updated":"2026-02-20T06:39:17Z","published":"2026-02-20T06:39:17Z","title":"Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets","summary":"Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.","authors":["Haruki Abe","Takayuki Osa","Yusuke Mukuta","Tatsuya Harada"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.18020v1","updated":"2026-02-20T06:22:21Z","published":"2026-02-20T06:22:21Z","title":"UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models","summary":"Vision-Language-Action (VLA) models leverage pretrained Vision-Language Models (VLMs) as backbones to map images and instructions to actions, demonstrating remarkable potential for generalizable robotic manipulation. To enhance performance, existing methods often incorporate extra observation cues (e.g., depth maps, point clouds) or auxiliary modules (e.g., object detectors, encoders) to enable more precise and reliable task execution, yet these typically require costly data collection and additional training. Inspired by the finding that Feed-Forward Network (FFN) in language models can act as \"key-value memory\", we propose Uncertainty-aware Observation Reinjection (UAOR), an effective, training-free and plug-and-play module for VLA models. Specifically, when the current language model layer exhibits high uncertainty, measured by Action Entropy, it reinjects key observation information into the next layer's Feed-Forward Network (FFN) through attention retrieval. This mechanism helps VLAs better attend to observations during inference, enabling more confident and faithful action generation. Comprehensive experiments show that our method consistently improves diverse VLA models across simulation and real-world tasks with minimal overhead. Notably, UAOR eliminates the need for additional observation cues or modules, making it a versatile and practical plug-in for existing VLA pipelines. The project page is at https://uaor.jiabingyang.cn.","authors":["Jiabing Yang","Yixiang Chen","Yuan Xu","Peiyan Li","Xiangnan Wu","Zichen Wen","Bowen Fang","Tao Yu","Zhengbo Zhang","Yingda Li","Kai Wang","Jing Liu","Nianfeng Liu","Yan Huang","Liang Wang"],"pdf_url":"","comment":null}]},"2026-02-19T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2512.24000v2","updated":"2026-02-19T23:00:22Z","published":"2025-12-30T05:44:32Z","title":"WISE: Web Information Satire and Fakeness Evaluation","summary":"Distinguishing fake or untrue news from satire or humor poses a unique challenge due to their overlapping linguistic features and divergent intent. This study develops WISE (Web Information Satire and Fakeness Evaluation) framework which benchmarks eight lightweight transformer models alongside two baseline models on a balanced dataset of 20,000 samples from Fakeddit, annotated as either fake news or satire. Using stratified 5-fold cross-validation, we evaluate models across comprehensive metrics including accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC, MCC, Brier score, and Expected Calibration Error. Our evaluation reveals that MiniLM, a lightweight model, achieves the highest accuracy (87.58%) among all models, while RoBERTa-base achieves the highest ROC-AUC (95.42%) and strong accuracy (87.36%). DistilBERT offers an excellent efficiency-accuracy trade-off with 86.28\\% accuracy and 93.90\\% ROC-AUC. Statistical tests confirm significant performance differences between models, with paired t-tests and McNemar tests providing rigorous comparisons. Our findings highlight that lightweight models can match or exceed baseline performance, offering actionable insights for deploying misinformation detection systems in real-world, resource-constrained settings.","authors":["Gaurab Chhetri","Subasish Das","Tausif Islam Chowdhury"],"pdf_url":"","comment":"This is the author's preprint. Accepted to WEB&GRAPH 2026 (co-located with WSDM 2026), Boise, Idaho, USA, Feb 26, 2026. Final version will appear in WSDM 2026 Companion Proceedings. Conf: https://wsdm-conference.org/2026/ Workshop: https://aiimlab.org/events/WSDM_2026_WEB_and_GRAPH_2026_Workshop_on_Web_and_Graphs_Responsible_Intelligence_and_Social_Media.html"},{"id":"http://arxiv.org/abs/2601.10160v2","updated":"2026-02-19T22:53:56Z","published":"2026-01-15T07:59:31Z","title":"Alignment Pretraining: AI Discourse Causes Self-Fulfilling (Mis)alignment","summary":"Pretraining corpora contain extensive discourse about AI systems, yet the causal influence of this discourse on downstream alignment remains poorly understood. If prevailing descriptions of AI behaviour are predominantly negative, LLMs may internalise corresponding behavioural priors, giving rise to self-fulfilling misalignment. This paper provides the first controlled study of this hypothesis by pretraining 6.9B-parameter LLMs with varying amounts of (mis)alignment discourse. We find that discussion of AI contributes to misalignment. Upsampling synthetic training documents about AI misalignment leads to a notable increase in misaligned behaviour. Conversely, upsampling documents about aligned behaviour reduces misalignment scores from 45% to 9%. We consider this evidence of self-fulfilling alignment. These effects are dampened, but persist through post-training. Our findings establish the study of how pretraining data shapes alignment priors, or alignment pretraining, as a complement to post-training. We recommend practitioners consider pretraining for alignment alongside capabilities. We share our models, data, and evaluations at AlignmentPretraining.ai.","authors":["Cameron Tice","Puria Radmard","Samuel Ratnam","Andy Kim","David Africa","Kyle O'Brien"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17881v1","updated":"2026-02-19T22:37:05Z","published":"2026-02-19T22:37:05Z","title":"Understanding Unreliability of Steering Vectors in Language Models: Geometric Predictors and the Limits of Linear Approximations","summary":"Steering vectors are a lightweight method for controlling language model behavior by adding a learned bias to the activations at inference time. Although effective on average, steering effect sizes vary across samples and are unreliable for many target behaviors. In my thesis, I investigate why steering reliability differs across behaviors and how it is impacted by steering vector training data. First, I find that higher cosine similarity between training activation differences predicts more reliable steering. Second, I observe that behavior datasets where positive and negative activations are better separated along the steering direction are more reliably steerable. Finally, steering vectors trained on different prompt variations are directionally distinct, yet perform similarly well and exhibit correlated efficacy across datasets. My findings suggest that steering vectors are unreliable when the latent target behavior representation is not effectively approximated by the linear steering direction. Taken together, these insights offer a practical diagnostic for steering unreliability and motivate the development of more robust steering methods that explicitly account for non-linear latent behavior representations.","authors":["Joschka Braun"],"pdf_url":"","comment":"Master's Thesis, University of Tübingen. 89 pages, 34 figures. Portions of this work were published at the ICLR 2025 Workshop on Foundation Models in the Wild (see arXiv:2505.22637)"},{"id":"http://arxiv.org/abs/2602.17867v1","updated":"2026-02-19T22:03:25Z","published":"2026-02-19T22:03:25Z","title":"ADAPT: Hybrid Prompt Optimization for LLM Feature Visualization","summary":"Understanding what features are encoded by learned directions in LLM activation space requires identifying inputs that strongly activate them. Feature visualization, which optimizes inputs to maximally activate a target direction, offers an alternative to costly dataset search approaches, but remains underexplored for LLMs due to the discrete nature of text. Furthermore, existing prompt optimization techniques are poorly suited to this domain, which is highly prone to local minima. To overcome these limitations, we introduce ADAPT, a hybrid method combining beam search initialization with adaptive gradient-guided mutation, designed around these failure modes. We evaluate on Sparse Autoencoder latents from Gemma 2 2B, proposing metrics grounded in dataset activation statistics to enable rigorous comparison, and show that ADAPT consistently outperforms prior methods across layers and latent types. Our results establish that feature visualization for LLMs is tractable, but requires design assumptions tailored to the domain.","authors":["João N. Cardoso","Arlindo L. Oliveira","Bruno Martins"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17850v1","updated":"2026-02-19T21:32:41Z","published":"2026-02-19T21:32:41Z","title":"Mind the Style: Impact of Communication Style on Human-Chatbot Interaction","summary":"Conversational agents increasingly mediate everyday digital interactions, yet the effects of their communication style on user experience and task success remain unclear. Addressing this gap, we describe the results of a between-subject user study where participants interact with one of two versions of a chatbot called NAVI which assists users in an interactive map-based 2D navigation task. The two chatbot versions differ only in communication style: one is friendly and supportive, while the other is direct and task-focused. Our results show that the friendly style increases subjective satisfaction and significantly improves task completion rates among female participants only, while no baseline differences between female and male participants were observed in a control condition without the chatbot. Furthermore, we find little evidence of users mimicking the chatbot's style, suggesting limited linguistic accommodation. These findings highlight the importance of user- and task-sensitive conversational agents and support that communication style personalization can meaningfully enhance interaction quality and performance.","authors":["Erik Derner","Dalibor Kučera","Aditya Gulati","Ayoub Bagheri","Nuria Oliver"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17848v1","updated":"2026-02-19T21:29:55Z","published":"2026-02-19T21:29:55Z","title":"On the scaling relationship between cloze probabilities and language model next-token prediction","summary":"Recent work has shown that larger language models have better predictive power for eye movement and reading time data. While even the best models under-allocate probability mass to human responses, larger models assign higher-quality estimates of next tokens and their likelihood of production in cloze data because they are less sensitive to lexical co-occurrence statistics while being better aligned semantically to human cloze responses. The results provide support for the claim that the greater memorization capacity of larger models helps them guess more semantically appropriate words, but makes them less sensitive to low-level information that is relevant for word recognition.","authors":["Cassandra L. Jacobs","Morgan Grobol"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.11488v2","updated":"2026-02-19T21:04:44Z","published":"2026-02-12T02:15:30Z","title":"When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration","summary":"When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6% text dominance under audio-text conflict versus 1.6% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2%) exceeds cascade accuracy (93.9%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations.\n  This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19% to 33%), sacrificing audio's information advantage without improving accessibility. Framing text as \"deliberately corrupted\" reduces text dominance by 80%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5%), while LoRA on the language model halves it ($-$23.9%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.","authors":["Jayadev Billa"],"pdf_url":"","comment":"25 pages, 20 tables, 6 figures, benchmark and code at https://github.com/jb1999/alme-benchmark"},{"id":"http://arxiv.org/abs/2602.17837v1","updated":"2026-02-19T20:59:47Z","published":"2026-02-19T20:59:47Z","title":"TFL: Targeted Bit-Flip Attack on Large Language Model","summary":"Large language models (LLMs) are increasingly deployed in safety and security critical applications, raising concerns about their robustness to model parameter fault injection attacks. Recent studies have shown that bit-flip attacks (BFAs), which exploit computer main memory (i.e., DRAM) vulnerabilities to flip a small number of bits in model weights, can severely disrupt LLM behavior. However, existing BFA on LLM largely induce un-targeted failure or general performance degradation, offering limited control over manipulating specific or targeted outputs. In this paper, we present TFL, a novel targeted bit-flip attack framework that enables precise manipulation of LLM outputs for selected prompts while maintaining almost no or minor degradation on unrelated inputs. Within our TFL framework, we propose a novel keyword-focused attack loss to promote attacker-specified target tokens in generative outputs, together with an auxiliary utility score that balances attack effectiveness against collateral performance impact on benign data. We evaluate TFL on multiple LLMs (Qwen, DeepSeek, Llama) and benchmarks (DROP, GSM8K, and TriviaQA). The experiments show that TFL achieves successful targeted LLM output manipulations with less than 50 bit flips and significantly reduced effect on unrelated queries compared to prior BFA approaches. This demonstrates the effectiveness of TFL and positions it as a new class of stealthy and targeted LLM model attack.","authors":["Jingkai Guo","Chaitali Chakrabarti","Deliang Fan"],"pdf_url":"","comment":"13 pages, 11 figures. Preprint"},{"id":"http://arxiv.org/abs/2602.15997v2","updated":"2026-02-19T20:53:31Z","published":"2026-02-17T20:39:02Z","title":"Anatomy of Capability Emergence: Scale-Invariant Representation Collapse and Top-Down Reorganization in Neural Networks","summary":"Capability emergence during neural network training remains mechanistically opaque. We track five geometric measures across five model scales (405K-85M parameters), 120+ emergence events in eight algorithmic tasks, and three Pythia language models (160M-2.8B). We find: (1) training begins with a universal representation collapse to task-specific floors that are scale-invariant across a 210X parameter range (e.g., modular arithmetic collapses to RANKME $\\approx$ 2.0 regardless of model size); (2) collapse propagates top-down through layers (32/32 task X model consistency), contradicting bottom-up feature-building intuition; (3) a geometric hierarchy in which representation geometry leads emergence (75-100% precursor rate for hard tasks), while the local learning coefficient is synchronous (0/24 precursor) and Hessian measures lag. We also delineate prediction limits: geometric measures encode coarse task difficulty but not fine-grained timing (within-class concordance 27%; when task ordering reverses across scales, prediction fails at 26%). On Pythia, global geometric patterns replicate but per-task precursor signals do not -- the precursor relationship requires task-training alignment that naturalistic pre-training does not provide. Our contribution is the geometric anatomy of emergence and its boundary conditions, not a prediction tool.","authors":["Jayadev Billa"],"pdf_url":"","comment":"19 pages, 10 tables, 8 figures, 5 appendix pages"},{"id":"http://arxiv.org/abs/2602.17815v1","updated":"2026-02-19T20:33:54Z","published":"2026-02-19T20:33:54Z","title":"Neural Synchrony Between Socially Interacting Language Models","summary":"Neuroscience has uncovered a fundamental mechanism of our social nature: human brain activity becomes synchronized with others in many social contexts involving interaction. Traditionally, social minds have been regarded as an exclusive property of living beings. Although large language models (LLMs) are widely accepted as powerful approximations of human behavior, with multi-LLM system being extensively explored to enhance their capabilities, it remains controversial whether they can be meaningfully compared to human social minds. In this work, we explore neural synchrony between socially interacting LLMs as an empirical evidence for this debate. Specifically, we introduce neural synchrony during social simulations as a novel proxy for analyzing the sociality of LLMs at the representational level. Through carefully designed experiments, we demonstrate that it reliably reflects both social engagement and temporal alignment in their interactions. Our findings indicate that neural synchrony between LLMs is strongly correlated with their social performance, highlighting an important link between neural synchrony and the social behaviors of LLMs. Our work offers a new perspective to examine the \"social minds\" of LLMs, highlighting surprising parallels in the internal dynamics that underlie human and LLM social interaction.","authors":["Zhining Zhang","Wentao Zhu","Chi Han","Yizhou Wang","Heng Ji"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2508.15637v2","updated":"2026-02-19T20:01:44Z","published":"2025-08-21T15:02:13Z","title":"Classification errors distort findings in automated speech processing: examples and solutions from child-development research","summary":"With the advent of wearable recorders, scientists are increasingly turning to automated methods of analysis of audio and video data in order to measure children's experience, behavior, and outcomes, with a sizable literature employing long-form audio-recordings to study language acquisition. While numerous articles report on the accuracy and reliability of the most popular automated classifiers, less has been written on the downstream effects of classification errors on measurements and statistical inferences (e.g., the estimate of correlations and effect sizes in regressions). This paper's main contributions are drawing attention to downstream effects of confusion errors, and providing an approach to measure and potentially recover from these errors. Specifically, we use a Bayesian approach to study the effects of algorithmic errors on key scientific questions, including the effect of siblings on children's language experience and the association between children's production and their input. By fitting a joint model of speech behavior and algorithm behavior on real and simulated data, we show that classification errors can significantly distort estimates for both the most commonly used \\gls{lena}, and a slightly more accurate open-source alternative (the Voice Type Classifier from the ACLEW system). We further show that a Bayesian calibration approach for recovering unbiased estimates of effect sizes can be effective and insightful, but does not provide a fool-proof solution.","authors":["Lucas Gautheron","Evan Kidd","Anton Malko","Marvin Lavechin","Alejandrina Cristia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.06857v7","updated":"2026-02-19T19:37:07Z","published":"2024-09-10T20:45:43Z","title":"What is the Role of Small Models in the LLM Era: A Survey","summary":"Large Language Models (LLMs) have made significant progress in advancing artificial general intelligence (AGI), leading to the development of increasingly large models such as GPT-4 and LLaMA-405B. However, scaling up model sizes results in exponentially higher computational costs and energy consumption, making these models impractical for academic researchers and businesses with limited resources. At the same time, Small Models (SMs) are frequently used in practical settings, although their significance is currently underestimated. This raises important questions about the role of small models in the era of LLMs, a topic that has received limited attention in prior research. In this work, we systematically examine the relationship between LLMs and SMs from two key perspectives: Collaboration and Competition. We hope this survey provides valuable insights for practitioners, fostering a deeper understanding of the contribution of small models and promoting more efficient use of computational resources. The code is available at https://github.com/tigerchen52/role_of_small_models","authors":["Lihu Chen","Gaël Varoquaux"],"pdf_url":"","comment":"a survey paper of small models"},{"id":"http://arxiv.org/abs/2504.21035v3","updated":"2026-02-19T19:31:46Z","published":"2025-04-28T01:16:27Z","title":"A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage","summary":"Sanitizing sensitive text data typically involves removing personally identifiable information (PII) or generating synthetic data under the assumption that these methods adequately protect privacy; however, their effectiveness is often only assessed by measuring the leakage of explicit identifiers but ignoring nuanced textual markers that can lead to re-identification. We challenge the above illusion of privacy by proposing a new framework that evaluates re-identification attacks to quantify individual privacy risks upon data release. Our approach shows that seemingly innocuous auxiliary information -- such as routine social activities -- can be used to infer sensitive attributes like age or substance use history from sanitized data. For instance, we demonstrate that Azure's commercial PII removal tool fails to protect 74\\% of information in the MedQA dataset. Although differential privacy mitigates these risks to some extent, it significantly reduces the utility of the sanitized text for downstream tasks. Our findings indicate that current sanitization techniques offer a \\textit{false sense of privacy}, highlighting the need for more robust methods that protect against semantic-level information leakage.","authors":["Rui Xin","Niloofar Mireshghallah","Shuyue Stella Li","Michael Duan","Hyunwoo Kim","Yejin Choi","Yulia Tsvetkov","Sewoong Oh","Pang Wei Koh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17784v1","updated":"2026-02-19T19:31:37Z","published":"2026-02-19T19:31:37Z","title":"QueryPlot: Generating Geological Evidence Layers using Natural Language Queries for Mineral Exploration","summary":"Mineral prospectivity mapping requires synthesizing heterogeneous geological knowledge, including textual deposit models and geospatial datasets, to identify regions likely to host specific mineral deposit types. This process is traditionally manual and knowledge-intensive. We present QueryPlot, a semantic retrieval and mapping framework that integrates large-scale geological text corpora with geologic map data using modern Natural Language Processing techniques. We curate descriptive deposit models for over 120 deposit types and transform the State Geologic Map Compilation (SGMC) polygons into structured textual representations. Given a user-defined natural language query, the system encodes both queries and region descriptions using a pretrained embedding model and computes semantic similarity scores to rank and spatially visualize regions as continuous evidence layers. QueryPlot supports compositional querying over deposit characteristics, enabling aggregation of multiple similarity-derived layers for multi-criteria prospectivity analysis. In a case study on tungsten skarn deposits, we demonstrate that embedding-based retrieval achieves high recall of known occurrences and produces prospective regions that closely align with expert-defined permissive tracts. Furthermore, similarity scores can be incorporated as additional features in supervised learning pipelines, yielding measurable improvements in classification performance. QueryPlot is implemented as a web-based system supporting interactive querying, visualization, and export of GIS-compatible prospectivity layers.To support future research, we have made the source code and datasets used in this study publicly available.","authors":["Meng Ye","Xiao Lin","Georgina Lukoczki","Graham W. Lederer","Yi Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07805v3","updated":"2026-02-19T19:25:43Z","published":"2025-12-08T18:39:13Z","title":"Group Representational Position Encoding","summary":"We present GRAPE (Group Representational Position Encoding), a unified framework for positional encoding based on group actions. GRAPE unifies two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\\operatorname{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\\mathrm{GL}$. In Multiplicative GRAPE, a position $n \\in \\mathbb{Z}$ (or $t \\in \\mathbb{R}$) acts as $\\mathbf{G}(n) = \\exp(n \\, ω\\, \\mathbf{L})$ with a rank-2 skew-symmetric generator $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes correspond to canonical coordinate pairs with a log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise from rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Overall, GRAPE provides a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project page: https://github.com/model-architectures/GRAPE.","authors":["Yifan Zhang","Zixiang Chen","Yifeng Liu","Zhen Qin","Huizhuo Yuan","Kangping Xu","Yang Yuan","Quanquan Gu","Andrew Chi-Chih Yao"],"pdf_url":"","comment":"Published in ICLR 2026; Project Page: https://github.com/model-architectures/GRAPE"},{"id":"http://arxiv.org/abs/2506.08364v4","updated":"2026-02-19T19:22:43Z","published":"2025-06-10T02:22:32Z","title":"Structure-Augmented Reasoning Generation","summary":"Recent advances in Large Language Models (LLMs) have significantly improved complex reasoning capabilities. Retrieval-Augmented Generation (RAG) has further extended these capabilities by grounding generation in dynamically retrieved evidence, enabling access to information beyond the model's training parameters. However, while RAG addresses knowledge availability, standard pipelines treat retrieved documents as independent, unstructured text chunks, forcing models to implicitly connect information across fragmented context. This limitation becomes critical for multi-hop queries, where answering correctly requires synthesizing information scattered across different documents. We present Structure-Augmented Reasoning Generation (SARG), a post-retrieval framework that addresses this gap by materializing explicit reasoning structures from retrieved context. SARG operates in three stages: extracting relational triples from retrieved documents via few-shot prompting, organizing these triples into a domain-adaptive knowledge graph, and performing multi-hop traversal to identify relevant reasoning chains. These chains, along with their associated text chunks, are then integrated into the generation prompt to explicitly guide the model's reasoning process. Importantly, SARG doesn't require custom retrievers or domain-specific fine-tuning. Instead, it functions as a modular layer compatible with all existing RAG pipelines. Extensive experiments on open-domain QA benchmarks and specialized reasoning datasets in finance and medicine demonstrate that SARG significantly outperforms state-of-the-art flat-context RAG baselines in both factual accuracy and reasoning coherence. Furthermore, by surfacing the exact traversal paths used during generation, SARG provides fully traceable and interpretable inference.","authors":["Jash Rajesh Parekh","Pengcheng Jiang","Jiawei Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04581v2","updated":"2026-02-19T19:17:31Z","published":"2025-08-06T16:06:43Z","title":"Share Your Attention: Transformer Weight Sharing via Matrix-based Dictionary Learning","summary":"Large language models have revolutionized AI applications, yet their high computational and memory demands hinder their widespread deployment. Existing compression techniques focus on intra-block optimizations (e.g., low-rank approximation or attention pruning), while the repetitive layered structure of transformers implies significant inter-block redundancy - a dimension largely unexplored beyond key-value (KV) caching. Inspired by dictionary learning in convolutional networks, we propose a framework for structured weight sharing across transformer layers. Our approach decomposes attention projection matrices (Q, K, V, O) into shared dictionary atoms, reducing the attention module's parameters by 66.7\\% while achieving on-par performance. Unlike complex methods requiring distillation or architectural changes, MASA (Matrix Atom Sharing in Attention) operates as a drop-in replacement-trained with standard optimizers - and represents each layer's weights as linear combinations of shared matrix atoms. Experiments across scales (100M-700M parameters) show that MASA achieves better benchmark accuracy and perplexity than GQA, low-rank baselines and recent Repeat-all-over/Sequential sharing at comparable parameter budgets. Ablation studies confirm robustness to the dictionary size and the efficacy of shared representations in capturing cross-layer statistical regularities. Extending to Vision Transformers (ViT), MASA matches performance metrics on image classification tasks with 66.7\\% fewer attention parameters. By combining dictionary learning strategies with transformer efficiency, MASA offers a scalable blueprint for parameter-efficient models without sacrificing performance. Finally, we investigate the possibility of employing MASA on large pretrained models to reduce their number of parameters without experiencing any significant drop in their performance.","authors":["Magauiya Zhussip","Dmitriy Shopkhoev","Ammar Ali","Stamatios Lefkimmiatis"],"pdf_url":"","comment":"This work has been accepted and presented at AAAI 2026 in Singapore"},{"id":"http://arxiv.org/abs/2602.17664v1","updated":"2026-02-19T18:59:50Z","published":"2026-02-19T18:59:50Z","title":"Sink-Aware Pruning for Diffusion Language Models","summary":"Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks serve as stable global anchors. We show that this assumption does not hold for DLMs: the attention-sink position exhibits substantially higher variance over the full generation trajectory (measured by how the dominant sink locations shift across timesteps), indicating that sinks are often transient and less structurally essential than in AR models. Based on this observation, we propose ${\\bf \\texttt{Sink-Aware Pruning}}$, which automatically identifies and prunes unstable sinks in DLMs (prior studies usually keep sinks for AR LLMs). Without retraining, our method achieves a better quality-efficiency trade-off and outperforms strong prior pruning baselines under matched compute. Our code is available at https://github.com/VILA-Lab/Sink-Aware-Pruning.","authors":["Aidar Myrzakhan","Tianyi Li","Bowei Guo","Shengkun Tang","Zhiqiang Shen"],"pdf_url":"","comment":"Code at: https://github.com/VILA-Lab/Sink-Aware-Pruning"},{"id":"http://arxiv.org/abs/2602.17663v1","updated":"2026-02-19T18:59:44Z","published":"2026-02-19T18:59:44Z","title":"CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts","summary":"HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ (\"Has the person ever been at this place?\") and $isAt$ (\"Is the person located at this place around publication time?\") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.","authors":["Juri Opitz","Corina Raclé","Emanuela Boros","Andrianos Michail","Matteo Romanello","Maud Ehrmann","Simon Clematide"],"pdf_url":"","comment":"ECIR 2026. CLEF Evaluation Lab. Registration DL: 2026/04/23. Task Homepage at https://hipe-eval.github.io/HIPE-2026/"},{"id":"http://arxiv.org/abs/2602.17655v1","updated":"2026-02-19T18:58:39Z","published":"2026-02-19T18:58:39Z","title":"What Language is This? Ask Your Tokenizer","summary":"Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite near-perfect performance on high-resource languages, existing systems remain brittle in low-resource and closely related language settings. We introduce UniLID, a simple and efficient LID method based on the UnigramLM tokenization algorithm, leveraging its probabilistic framing, parameter estimation technique and inference strategy. In short, we learn language-conditional unigram distributions over a shared tokenizer vocabulary but treat segmentation as a language-specific phenomenon. Our formulation is data- and compute-efficient, supports incremental addition of new languages without retraining existing models, and can naturally be integrated into existing language model tokenization pipelines. Empirical evaluations against widely used baselines, including fastText, GlotLID, and CLD3, show that UniLID achieves competitive performance on standard benchmarks, substantially improves sample efficiency in low-resource settings - surpassing 70% accuracy with as few as five labeled samples per language - and delivers large gains on fine-grained dialect identification.","authors":["Clara Meister","Ahmetcan Yavuz","Pietro Lesci","Tiago Pimentel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17653v1","updated":"2026-02-19T18:56:34Z","published":"2026-02-19T18:56:34Z","title":"Differences in Typological Alignment in Language Models' Treatment of Differential Argument Marking","summary":"Recent work has shown that language models (LMs) trained on synthetic corpora can exhibit typological preferences that resemble cross-linguistic regularities in human languages, particularly for syntactic phenomena such as word order. In this paper, we extend this paradigm to differential argument marking (DAM), a semantic licensing system in which morphological marking depends on semantic prominence. Using a controlled synthetic learning method, we train GPT-2 models on 18 corpora implementing distinct DAM systems and evaluate their generalization using minimal pairs. Our results reveal a dissociation between two typological dimensions of DAM. Models reliably exhibit human-like preferences for natural markedness direction, favoring systems in which overt marking targets semantically atypical arguments. In contrast, models do not reproduce the strong object preference in human languages, in which overt marking in DAM more often targets objects rather than subjects. These findings suggest that different typological tendencies may arise from distinct underlying sources.","authors":["Iskar Deng","Nathalia Xu","Shane Steinert-Threlkeld"],"pdf_url":"","comment":"15 pages, 7 figures, 7 tables. Under review"},{"id":"http://arxiv.org/abs/2602.17645v1","updated":"2026-02-19T18:54:32Z","published":"2026-02-19T18:54:32Z","title":"Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting","summary":"Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we find this induces high-variance, nearly orthogonal gradients across iterations, violating coherent local alignment and destabilizing optimization. We attribute this to (i) ViT translation sensitivity that yields spike-like gradients and (ii) structural asymmetry between source and target crops. We reformulate local matching as an asymmetric expectation over source transformations and target semantics, and build a gradient-denoising upgrade to M-Attack. On the source side, Multi-Crop Alignment (MCA) averages gradients from multiple independently sampled local views per iteration to reduce variance. On the target side, Auxiliary Target Alignment (ATA) replaces aggressive target augmentation with a small auxiliary set from a semantically correlated distribution, producing a smoother, lower-variance target manifold. We further reinterpret momentum as Patch Momentum, replaying historical crop gradients; combined with a refined patch-size ensemble (PE+), this strengthens transferable directions. Together these modules form M-Attack-V2, a simple, modular enhancement over M-Attack that substantially improves transfer-based black-box attacks on frontier LVLMs: boosting success rates on Claude-4.0 from 8% to 30%, Gemini-2.5-Pro from 83% to 97%, and GPT-5 from 98% to 100%, outperforming prior black-box LVLM attacks. Code and data are publicly available at: https://github.com/vila-lab/M-Attack-V2.","authors":["Xiaohan Zhao","Zhaoyi Li","Yaxin Luo","Jiacheng Cui","Zhiqiang Shen"],"pdf_url":"","comment":"Code at: https://github.com/vila-lab/M-Attack-V2"},{"id":"http://arxiv.org/abs/2602.17623v1","updated":"2026-02-19T18:42:46Z","published":"2026-02-19T18:42:46Z","title":"Unmasking the Factual-Conceptual Gap in Persian Language Models","summary":"While emerging Persian NLP benchmarks have expanded into pragmatics and politeness, they rarely distinguish between memorized cultural facts and the ability to reason about implicit social norms. We introduce DivanBench, a diagnostic benchmark focused on superstitions and customs, arbitrary, context-dependent rules that resist simple logical deduction. Through 315 questions across three task types (factual retrieval, paired scenario verification, and situational reasoning), we evaluate seven Persian LLMs and reveal three critical failures: most models exhibit severe acquiescence bias, correctly identifying appropriate behaviors but failing to reject clear violations; continuous Persian pretraining amplifies this bias rather than improving reasoning, often degrading the model's ability to discern contradictions; and all models show a 21\\% performance gap between retrieving factual knowledge and applying it in scenarios. These findings demonstrate that cultural competence requires more than scaling monolingual data, as current models learn to mimic cultural patterns without internalizing the underlying schemas.","authors":["Alireza Sakhaeirad","Ali Ma'manpoosh","Arshia Hemmat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.02819v4","updated":"2026-02-19T18:32:53Z","published":"2025-05-05T17:47:42Z","title":"ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization","summary":"We introduce ReplaceMe, a generalized training-free depth pruning method that effectively replaces transformer blocks with a linear operation, while maintaining high performance for low compression ratios. In contrast to conventional pruning approaches that require additional training or fine-tuning, our approach requires only a small calibration dataset that is used to estimate a linear transformation, which approximates the pruned blocks. The estimated linear mapping can be seamlessly merged with the remaining transformer blocks, eliminating the need for any additional network parameters. Our experiments show that ReplaceMe consistently outperforms other training-free approaches and remains highly competitive with state-of-the-art pruning methods that involve extensive retraining/fine-tuning and architectural modifications. Applied to several large language models (LLMs), ReplaceMe achieves up to 25\\% pruning while retaining approximately 90\\% of the original model's performance on open benchmarks - without any training or healing steps, resulting in minimal computational overhead. We provide an open-source library implementing ReplaceMe alongside several state-of-the-art depth pruning techniques, available at https://github.com/mts-ai/ReplaceMe","authors":["Dmitriy Shopkhoev","Ammar Ali","Magauiya Zhussip","Valentin Malykh","Stamatios Lefkimmiatis","Nikos Komodakis","Sergey Zagoruyko"],"pdf_url":"","comment":"This work was accepted and presented at NeurIPS 2025. Code is available at https://github.com/mts-ai/replaceme Reviews at OpenReview: https://openreview.net/forum?id=zEj1FSYCRn NeurIPS 2025 Proceedings: https://openreview.net/pdf?id=zEj1FSYCRn"},{"id":"http://arxiv.org/abs/2602.17598v1","updated":"2026-02-19T18:22:39Z","published":"2026-02-19T18:22:39Z","title":"The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?","summary":"Current speech LLMs largely perform implicit ASR: on tasks solvable from a transcript, they are behaviorally and mechanistically equivalent to simple Whisper$\\to$LLM cascades. We show this through matched-backbone testing across four speech LLMs and six tasks, controlling for the LLM backbone for the first time. Ultravox is statistically indistinguishable from its matched cascade ($κ{=}0.93$); logit lens reveals literal text emerging in hidden states; LEACE concept erasure confirms text representations are causally necessary in both architectures tested, collapsing accuracy to near-zero. Qwen2-Audio genuinely diverges, revealing cascade equivalence is architecture-dependent, not universal. For most deployed use cases, current speech LLMs are expensive cascades, and under noise, they are worse ones, with clean-condition advantages reversing by up to 7.6% at 0 dB.","authors":["Jayadev Billa"],"pdf_url":"","comment":"10 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2602.17588v1","updated":"2026-02-19T18:11:28Z","published":"2026-02-19T18:11:28Z","title":"Modeling Distinct Human Interaction in Web Agents","summary":"Despite rapid progress in autonomous web agents, human involvement remains essential for shaping preferences and correcting agent behavior as tasks unfold. However, current agentic systems lack a principled understanding of when and why humans intervene, often proceeding autonomously past critical decision points or requesting unnecessary confirmation. In this work, we introduce the task of modeling human intervention to support collaborative web task execution. We collect CowCorpus, a dataset of 400 real-user web navigation trajectories containing over 4,200 interleaved human and agent actions. We identify four distinct patterns of user interaction with agents -- hands-off supervision, hands-on oversight, collaborative task-solving, and full user takeover. Leveraging these insights, we train language models (LMs) to anticipate when users are likely to intervene based on their interaction styles, yielding a 61.4-63.4% improvement in intervention prediction accuracy over base LMs. Finally, we deploy these intervention-aware models in live web navigation agents and evaluate them in a user study, finding a 26.5% increase in user-rated agent usefulness. Together, our results show structured modeling of human intervention leads to more adaptive, collaborative agents.","authors":["Faria Huq","Zora Zhiruo Wang","Zhanqiu Guo","Venu Arvind Arangarajan","Tianyue Ou","Frank Xu","Shuyan Zhou","Graham Neubig","Jeffrey P. Bigham"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2509.22075v4","updated":"2026-02-19T17:30:28Z","published":"2025-09-26T08:55:09Z","title":"CoSpaDi: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning","summary":"Post-training compression of large language models (LLMs) often relies on low-rank weight approximations that represent each column of the weight matrix in a shared low-dimensional subspace. This strategy is computationally efficient but the underlying constraint can be overly rigid for heterogeneous projection weights and may incur avoidable accuracy loss. We propose CoSpaDi (Compression via Sparse Dictionary Learning), a training-free framework that replaces low-rank factorization with a structured sparse decomposition in which each weight matrix is represented as a dense dictionary multiplied by a column-sparse coefficient matrix. This yields a union-of-subspaces model: the columns of the weight matrix are represented as linear combinations of different subsets of dictionary atoms, improving expressiveness at a fixed parameter budget. CoSpaDi is calibration-guided: using a small calibration set, we optimize the factorization to minimize functional reconstruction error of layer outputs rather than weight-space error. An activation-derived Gram orthonormalization reformulates this data-aware objective into a standard dictionary learning problem on transformed weights, and we support both per-layer compression and cross-layer dictionary sharing within groups of similar projections. Across Llama and Qwen model families, CoSpaDi consistently improves the accuracy--compression and perplexity--compression trade-offs over state-of-the-art SVD-based baselines and strong structured pruning baselines at 20-40\\% compression ratios. The resulting structured sparsity enables sparse--dense computation and integrates with post-training quantization of the sparse coefficients.","authors":["Denis Makhov","Dmitriy Shopkhoev","Magauiya Zhussip","Ammar Ali","Stamatios Lefkimmiatis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06968v2","updated":"2026-02-19T17:20:39Z","published":"2025-06-08T02:14:10Z","title":"A dependently-typed calculus of event telicity and culminativity","summary":"We present a dependently-typed cross-linguistic framework for analyzing the telicity and culminativity of events, accompanied by examples of using our framework to model English sentences. Our framework consists of two parts. In the nominal domain, we model the boundedness of noun phrases and its relationship to subtyping, delimited quantities, and adjectival modification. In the verbal domain we define a dependent event calculus, modeling telic events as those whose undergoer is bounded, culminating events as telic events that achieve their inherent endpoint, and consider adverbial modification. In both domains we pay particular attention to associated entailments. Our framework is defined as an extension of intensional Martin-Löf dependent type theory, and the rules and examples in this paper have been formalized in the Agda proof assistant.","authors":["Pavel Kovalev","Carlo Angiuli"],"pdf_url":"","comment":"54 pages, to appear in Mathematical Structures in Computer Science, Agda formalization available at https://doi.org/10.5281/zenodo.15602617"},{"id":"http://arxiv.org/abs/2406.04220v6","updated":"2026-02-19T17:12:55Z","published":"2024-06-06T16:18:30Z","title":"BEADs: Bias Evaluation Across Domains","summary":"Recent advances in large language models (LLMs) have substantially improved natural language processing (NLP) applications. However, these models often inherit and amplify biases present in their training data. Although several datasets exist for bias detection, most are limited to one or two NLP tasks, typically classification or evaluation and do not provide broad coverage across diverse task settings. To address this gap, we introduce the \\textbf{Bias Evaluations Across Domains} (\\textbf{B}\\texttt{EADs}) dataset, designed to support a wide range of NLP tasks, including text classification, token classification, bias quantification, and benign language generation. A key contribution of this work is a gold-standard annotation scheme that supports both evaluation and supervised training of language models. Experiments on state-of-the-art models reveal some gaps: some models exhibit systematic bias toward specific demographics, while others apply safety guardrails more strictly or inconsistently across groups. Overall, these results highlight persistent shortcomings in current models and underscore the need for comprehensive bias evaluation. Project: https://vectorinstitute.github.io/BEAD/ Data: https://huggingface.co/datasets/shainar/BEAD","authors":["Shaina Raza","Mizanur Rahman","Michael R. Zhang"],"pdf_url":"","comment":"under review"},{"id":"http://arxiv.org/abs/2602.17547v1","updated":"2026-02-19T17:01:08Z","published":"2026-02-19T17:01:08Z","title":"KLong: Training LLM Agent for Extremely Long-horizon Tasks","summary":"This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using this pipeline, we build thousands of long-horizon trajectories distilled from Claude 4.5 Sonnet (Thinking). To train with these extremely long trajectories, we propose a new trajectory-splitting SFT, which preserves early context, progressively truncates later context, and maintains overlap between sub-trajectories. In addition, to further improve long-horizon task-solving capability, we propose a novel progressive RL, which schedules training into multiple stages with progressively extended timeouts. Experiments demonstrate the superiority and generalization of KLong, as shown in Figure 1. Notably, our proposed KLong (106B) surpasses Kimi K2 Thinking (1T) by 11.28% on PaperBench, and the performance improvement generalizes to other coding benchmarks like SWE-bench Verified and MLE-bench.","authors":["Yue Liu","Zhiyuan Hu","Flood Sung","Jiaheng Zhang","Bryan Hooi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17546v1","updated":"2026-02-19T16:59:54Z","published":"2026-02-19T16:59:54Z","title":"Learning to Stay Safe: Adaptive Regularization Against Safety Degradation during Fine-Tuning","summary":"Instruction-following language models are trained to be helpful and safe, yet their safety behavior can deteriorate under benign fine-tuning and worsen under adversarial updates. Existing defenses often offer limited protection or force a trade-off between safety and utility. We introduce a training framework that adapts regularization in response to safety risk, enabling models to remain aligned throughout fine-tuning. To estimate safety risk at training time, we explore two distinct approaches: a judge-based Safety Critic that assigns high-level harm scores to training batches, and an activation-based risk predictor built with a lightweight classifier trained on intermediate model activations to estimate harmful intent. Each approach provides a risk signal that is used to constrain updates deemed higher risk to remain close to a safe reference policy, while lower-risk updates proceed with standard training. We empirically verify that harmful intent signals are predictable from pre-generation activations and that judge scores provide effective high-recall safety guidance. Across multiple model families and attack scenarios, adaptive regularization with either risk estimation approach consistently lowers attack success rate compared to standard fine-tuning, preserves downstream performance, and adds no inference-time cost. This work demonstrates a principled mechanism for maintaining safety without sacrificing utility.","authors":["Jyotin Goel","Souvik Maji","Pratik Mazumder"],"pdf_url":"","comment":"Work in progress (30 pages)"},{"id":"http://arxiv.org/abs/2602.17544v1","updated":"2026-02-19T16:59:11Z","published":"2026-02-19T16:59:11Z","title":"Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability","summary":"In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusability measures how easily an Executor can reuse the Thinker's CoT. Verifiability measures how frequently an Executor can match the Thinker's answer using the CoT. We evaluated four Thinker models against a committee of ten Executor models across five benchmarks. Our results reveal that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, we find that CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.","authors":["Shashank Aggarwal","Ram Vikas Mishra","Amit Awekar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17542v1","updated":"2026-02-19T16:58:34Z","published":"2026-02-19T16:58:34Z","title":"Using LLMs for Knowledge Component-level Correctness Labeling in Open-ended Coding Problems","summary":"Fine-grained skill representations, commonly referred to as knowledge components (KCs), are fundamental to many approaches in student modeling and learning analytics. However, KC-level correctness labels are rarely available in real-world datasets, especially for open-ended programming tasks where solutions typically involve multiple KCs simultaneously. Simply propagating problem-level correctness to all associated KCs obscures partial mastery and often leads to poorly fitted learning curves. To address this challenge, we propose an automated framework that leverages large language models (LLMs) to label KC-level correctness directly from student-written code. Our method assesses whether each KC is correctly applied and further introduces a temporal context-aware Code-KC mapping mechanism to better align KCs with individual student code. We evaluate the resulting KC-level correctness labels in terms of learning curve fit and predictive performance using the power law of practice and the Additive Factors Model. Experimental results show that our framework leads to learning curves that are more consistent with cognitive theory and improves predictive performance, compared to baselines. Human evaluation further demonstrates substantial agreement between LLM and expert annotations.","authors":["Zhangqi Duan","Arnav Kankaria","Dhruv Kartik","Andrew Lan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17526v1","updated":"2026-02-19T16:37:16Z","published":"2026-02-19T16:37:16Z","title":"The Anxiety of Influence: Bloom Filters in Transformer Attention Heads","summary":"Some transformer attention heads appear to function as membership testers, dedicating themselves to answering the question \"has this token appeared before in the context?\" We identify these heads across four language models (GPT-2 small, medium, and large; Pythia-160M) and show that they form a spectrum of membership-testing strategies. Two heads (L0H1 and L0H5 in GPT-2 small) function as high-precision membership filters with false positive rates of 0-4\\% even at 180 unique context tokens -- well above the $d_\\text{head} = 64$ bit capacity of a classical Bloom filter. A third head (L1H11) shows the classic Bloom filter capacity curve: its false positive rate follows the theoretical formula $p \\approx (1 - e^{-kn/m})^k$ with $R^2 = 1.0$ and fitted capacity $m \\approx 5$ bits, saturating by $n \\approx 20$ unique tokens. A fourth head initially identified as a Bloom filter (L3H0) was reclassified as a general prefix-attention head after confound controls revealed its apparent capacity curve was a sequence-length artifact. Together, the three genuine membership-testing heads form a multi-resolution system concentrated in early layers (0-1), taxonomically distinct from induction and previous-token heads, with false positive rates that decay monotonically with embedding distance -- consistent with distance-sensitive Bloom filters. These heads generalize broadly: they respond to any repeated token type, not just repeated names, with 43\\% higher generalization than duplicate-token-only heads. Ablation reveals these heads contribute to both repeated and novel token processing, indicating that membership testing coexists with broader computational roles. The reclassification of L3H0 through confound controls strengthens rather than weakens the case: the surviving heads withstand the scrutiny that eliminated a false positive in our own analysis.","authors":["Peter Balogh"],"pdf_url":"","comment":"13 pages, 8 figures, code at https://github.com/pbalogh/anxiety-of-influence v2: L3H0 reclassified as prefix-attention head following confound control. Capacity analysis updated. Duplicate-token head overlap experiment added v3: All experiments were independently validated on CPU to rule out hardware-specific computation artifacts. Results are consistent across backends"},{"id":"http://arxiv.org/abs/2602.17513v1","updated":"2026-02-19T16:25:07Z","published":"2026-02-19T16:25:07Z","title":"Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to Obstetrics","summary":"Clinical free-text notes contain vital patient information. They are structured into labelled sections; recognizing these sections has been shown to support clinical decision-making and downstream NLP tasks. In this paper, we advance clinical section segmentation through three key contributions. First, we curate a new de-identified, section-labeled obstetrics notes dataset, to supplement the medical domains covered in public corpora such as MIMIC-III, on which most existing segmentation approaches are trained. Second, we systematically evaluate transformer-based supervised models for section segmentation on a curated subset of MIMIC-III (in-domain), and on the new obstetrics dataset (out-of-domain). Third, we conduct the first head-to-head comparison of supervised models for medical section segmentation with zero-shot large language models. Our results show that while supervised models perform strongly in-domain, their performance drops substantially out-of-domain. In contrast, zero-shot models demonstrate robust out-of-domain adaptability once hallucinated section headers are corrected. These findings underscore the importance of developing domain-specific clinical resources and highlight zero-shot segmentation as a promising direction for applying healthcare NLP beyond well-studied corpora, as long as hallucinations are appropriately managed.","authors":["Baris Karacan","Barbara Di Eugenio","Patrick Thornton"],"pdf_url":"","comment":"11 pages. Accepted at LREC 2026. To appear in the proceedings"},{"id":"http://arxiv.org/abs/2602.10993v2","updated":"2026-02-19T15:57:17Z","published":"2026-02-11T16:19:58Z","title":"LoRA-Squeeze: Simple and Effective Post-Tuning and In-Tuning Compression of LoRA Modules","summary":"Despite its huge number of variants, standard Low-Rank Adaptation (LoRA) is still a dominant technique for parameter-efficient fine-tuning (PEFT). Nonetheless, it faces persistent challenges, including the pre-selection of an optimal rank and rank-specific hyper-parameters, as well as the deployment complexity of heterogeneous-rank modules and more sophisticated LoRA derivatives. In this work, we introduce LoRA-Squeeze, a simple and efficient methodology that aims to improve standard LoRA learning by changing LoRA module ranks either post-hoc or dynamically during training}. Our approach posits that it is better to first learn an expressive, higher-rank solution and then compress it, rather than learning a constrained, low-rank solution directly. The method involves fine-tuning with a deliberately high(er) source rank, reconstructing or efficiently approximating the reconstruction of the full weight update matrix, and then using Randomized Singular Value Decomposition (RSVD) to create a new, compressed LoRA module at a lower target rank. Extensive experiments across 13 text and 10 vision-language tasks show that post-hoc compression often produces lower-rank adapters that outperform those trained directly at the target rank, especially if a small number of fine-tuning steps at the target rank is allowed. Moreover, a gradual, in-tuning rank annealing variant of LoRA-Squeeze consistently achieves the best LoRA size-performance trade-off.","authors":["Ivan Vulić","Adam Grycner","Quentin de Laroussilhe","Jonas Pfeiffer"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2602.17483v1","updated":"2026-02-19T15:53:29Z","published":"2026-02-19T15:53:29Z","title":"What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data","summary":"Large language models (LLMs), and conversational agents based on them, are exposed to personal data (PD) during pre-training and during user interactions. Prior work shows that PD can resurface, yet users lack insight into how strongly models associate specific information to their identity. We audit PD across eight LLMs (3 open-source; 5 API-based, including GPT-4o), introduce LMP2 (Language Model Privacy Probe), a human-centered, privacy-preserving audit tool refined through two formative studies (N=20), and run two studies with EU residents to capture (i) intuitions about LLM-generated PD (N1=155) and (ii) reactions to tool output (N2=303). We show empirically that models confidently generate multiple PD categories for well-known individuals. For everyday users, GPT-4o generates 11 features with 60% or more accuracy (e.g., gender, hair color, languages). Finally, 72% of participants sought control over model-generated associations with their name, raising questions about what counts as PD and whether data privacy rights should extend to LLMs.","authors":["Dimitri Staufer","Kirsten Morehouse"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11108v2","updated":"2026-02-19T15:51:17Z","published":"2025-12-11T20:48:22Z","title":"Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Feature Attribution","summary":"Good quality explanations strengthen the understanding of language models and data. Feature attribution methods, such as Integrated Gradient, are a type of post-hoc explainer that can provide token-level insights. However, explanations on the same input may vary greatly due to underlying biases of different methods. Users may be aware of this issue and mistrust their utility, while unaware users may trust them inadequately. In this work, we delve beyond the superficial inconsistencies between attribution methods, structuring their biases through a model- and method-agnostic framework of three evaluation metrics. We systematically assess both lexical and position bias (what and where in the input) for two transformers; first, in a controlled, pseudo-random classification task on artificial data; then, in a semi-controlled causal relation detection task on natural data. We find a trade-off between lexical and position biases in our model comparison, with models that score high on one type score low on the other. We also find signs that anomalous explanations are more likely to be biased.","authors":["Jonathan Kamp","Roos Bakker","Dominique Blok"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.22213v2","updated":"2026-02-19T15:43:51Z","published":"2025-12-22T09:06:43Z","title":"On the Existence and Behavior of Secondary Attention Sinks","summary":"Attention sinks are tokens, often the beginning-of-sequence (BOS) token, that receive disproportionately high attention despite limited semantic relevance. In this work, we identify a class of attention sinks, which we term secondary sinks, that differ fundamentally from the sinks studied in prior works, which we term primary sinks. While prior works have identified that tokens other than BOS can sometimes become sinks, they were found to exhibit properties analogous to the BOS token. Specifically, they emerge at the same layer, persist throughout the network and draw a large amount of attention mass. Whereas, we find the existence of secondary sinks that arise primarily in middle layers and can persist for a variable number of layers, and draw a smaller, but still significant, amount of attention mass. Through extensive experiments across 11 model families, we analyze where these secondary sinks appear, their properties, how they are formed, and their impact on the attention mechanism. Specifically, we show that: (1) these sinks are formed by specific middle-layer MLP modules; these MLPs map token representations to vectors that align with the direction of the primary sink of that layer. (2) The $\\ell_2$-norm of these vectors determines the sink score of the secondary sink, and also the number of layers it lasts for, thereby leading to different impacts on the attention mechanisms accordingly. (3) The primary sink weakens in middle layers, coinciding with the emergence of secondary sinks. We observe that in larger-scale models, the location and lifetime of the sinks, together referred to as sink levels, appear in a more deterministic and frequent manner. Specifically, we identify three sink levels in QwQ-32B and six levels in Qwen3-14B.","authors":["Jeffrey T. H. Wong","Cheng Zhang","Louis Mahon","Wayne Luk","Anton Isopoussu","Yiren Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.02377v2","updated":"2026-02-19T15:42:12Z","published":"2026-02-02T17:42:53Z","title":"Proof-RM: A Scalable and Generalizable Reward Model for Math Proof","summary":"While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the authenticity of a proof by simple answer matching. To enable automatic verification, a Reward Model (RM) capable of reliably evaluating full proof processes is required. In this work, we design a *scalable* data-construction pipeline that, with minimal human effort, leverages LLMs to generate a large quantity of high-quality ``**question-proof-check**'' triplet data. By systematically varying problem sources, generation methods, and model configurations, we create diverse problem-proof pairs spanning multiple difficulty levels, linguistic styles, and error types, subsequently filtered through hierarchical human review for label alignment. Utilizing these data, we train a proof-checking RM, incorporating an ``LLM-as-a-RM-for-RM'' approach and balanced token weighting to stabilize the RL process. Our experiments validate the model's scalability and strong performance from multiple perspectives, including reward accuracy, generalization ability and test-time guidance, providing important practical recipes and tools for strengthening LLM mathematical capabilities.","authors":["Haotong Yang","Zitong Wang","Shijia Kang","Siqi Yang","Wenkai Yu","Xu Niu","Yike Sun","Yi Hu","Zhouchen Lin","Muhan Zhang"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2602.17475v1","updated":"2026-02-19T15:38:46Z","published":"2026-02-19T15:38:46Z","title":"Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian","summary":"Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether \"small\" LLMs (around one billion parameters) can effectively perform medical tasks while maintaining competitive accuracy. We evaluate models from three major families-Llama-3, Gemma-3, and Qwen3-across 20 clinical NLP tasks among Named Entity Recognition, Relation Extraction, Case Report Form Filling, Question Answering, and Argument Mining. We systematically compare a range of adaptation strategies, both at inference time (few-shot prompting, constraint decoding) and at training time (supervised fine-tuning, continual pretraining). Fine-tuning emerges as the most effective approach, while the combination of few-shot prompting and constraint decoding offers strong lower-resource alternatives. Our results show that small LLMs can match or even surpass larger baselines, with our best configuration based on Qwen3-1.7B achieving an average score +9.2 points higher than Qwen3-32B. We release a comprehensive collection of all the publicly available Italian medical datasets for NLP tasks, together with our top-performing models. Furthermore, we release an Italian dataset of 126M words from the Emergency Department of an Italian Hospital, and 175M words from various sources that we used for continual pre-training.","authors":["Pietro Ferrazzi","Mattia Franzin","Alberto Lavelli","Bernardo Magnini"],"pdf_url":"","comment":"Paper Accepted at LREC 2026"},{"id":"http://arxiv.org/abs/2602.17469v1","updated":"2026-02-19T15:35:13Z","published":"2026-02-19T15:35:13Z","title":"Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dialect Representation and Intent Misalignment in Transformers","summary":"The core theme of bidirectional alignment is ensuring that AI systems accurately understand human intent and that humans can trust AI behavior. However, this loop fractures significantly across language barriers. Our research addresses Cross-Lingual Sentiment Misalignment between Bengali and English by benchmarking four transformer architectures. We reveal severe safety and representational failures in current alignment paradigms. We demonstrate that compressed model (mDistilBERT) exhibits 28.7% \"Sentiment Inversion Rate,\" fundamentally misinterpreting positive user intent as negative (or vice versa). Furthermore, we identify systemic nuances affecting human-AI trust, including \"Asymmetric Empathy\" where some models systematically dampen and others amplify the affective weight of Bengali text relative to its English counterpart. Finally, we reveal a \"Modern Bias\" in the regional model (IndicBERT), which shows a 57% increase in alignment error when processing formal (Sadhu) Bengali. We argue that equitable human-AI co-evolution requires pluralistic, culturally grounded alignment that respects language and dialectal diversity over universal compression, which fails to preserve the emotional fidelity required for reciprocal human-AI trust. We recommend that alignment benchmarks incorporate \"Affective Stability\" metrics that explicitly penalize polarity inversions in low-resource and dialectal contexts.","authors":["Nusrat Jahan Lia","Shubhashis Roy Dipta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17467v1","updated":"2026-02-19T15:33:56Z","published":"2026-02-19T15:33:56Z","title":"PEACE 2.0: Grounded Explanations and Counter-Speech for Combating Hate Expressions","summary":"The increasing volume of hate speech on online platforms poses significant societal challenges. While the Natural Language Processing community has developed effective methods to automatically detect the presence of hate speech, responses to it, called counter-speech, are still an open challenge. We present PEACE 2.0, a novel tool that, besides analysing and explaining why a message is considered hateful or not, also generates a response to it. More specifically, PEACE 2.0 has three main new functionalities: leveraging a Retrieval-Augmented Generation (RAG) pipeline i) to ground HS explanations into evidence and facts, ii) to automatically generate evidence-grounded counter-speech, and iii) exploring the characteristics of counter-speech replies. By integrating these capabilities, PEACE 2.0 enables in-depth analysis and response generation for both explicit and implicit hateful messages.","authors":["Greta Damo","Stéphane Petiot","Elena Cabrio","Serena Villata"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.07989v2","updated":"2026-02-19T15:33:35Z","published":"2025-11-11T08:54:15Z","title":"State of the Art in Text Classification for South Slavic Languages: Fine-Tuning or Prompting?","summary":"Until recently, fine-tuned BERT-like models provided state-of-the-art performance on text classification tasks. With the rise of instruction-tuned decoder-only models, commonly known as large language models (LLMs), the field has increasingly moved toward zero-shot and few-shot prompting. However, the performance of LLMs on text classification, particularly on less-resourced languages, remains under-explored. In this paper, we evaluate the performance of current language models on text classification tasks across several South Slavic languages. We compare openly available fine-tuned BERT-like models with a selection of open-source and closed-source LLMs across three tasks in three domains: sentiment classification in parliamentary speeches, topic classification in news articles and parliamentary speeches, and genre identification in web texts. Our results show that LLMs demonstrate strong zero-shot performance, often matching or surpassing fine-tuned BERT-like models. Moreover, when used in a zero-shot setup, LLMs perform comparably in South Slavic languages and English. However, we also point out key drawbacks of LLMs, including less predictable outputs, significantly slower inference, and higher computational costs. Due to these limitations, fine-tuned BERT-like models remain a more practical choice for large-scale automatic text annotation.","authors":["Taja Kuzman Pungeršek","Peter Rupnik","Ivan Porupski","Vuk Dinić","Nikola Ljubešić"],"pdf_url":"","comment":"17 pages; 4 figures; 3 tables. Submitted to the LLMs4SSH workshop, co-located with the LREC 2026 conference"},{"id":"http://arxiv.org/abs/2602.17465v1","updated":"2026-02-19T15:29:34Z","published":"2026-02-19T15:29:34Z","title":"Entropy-Based Data Selection for Language Models","summary":"Modern language models (LMs) increasingly require two critical resources: computational resources and data resources. Data selection techniques can effectively reduce the amount of training data required for fine-tuning LMs. However, their effectiveness is closely related to computational resources, which always require a high compute budget. Owing to the resource limitations in practical fine-tuning scenario, we systematically reveal the relationship between data selection and uncertainty estimation of selected data. Although large language models (LLMs) exhibit exceptional capabilities in language understanding and generation, which provide new ways to alleviate data scarcity, evaluating data usability remains a challenging task. This makes efficient data selection indispensable. To mitigate these issues, we propose Entropy-Based Unsupervised Data Selection (EUDS) framework. Empirical experiments on sentiment analysis (SA), topic classification (Topic-CLS), and question answering (Q&A) tasks validate its effectiveness. EUDS establishes a computationally efficient data-filtering mechanism. Theoretical analysis and experimental results confirm the effectiveness of our approach. EUDS significantly reduces computational costs and improves training time efficiency with less data requirement. This provides an innovative solution for the efficient fine-tuning of LMs in the compute-constrained scenarios.","authors":["Hongming Li","Yang Liu","Chao Huang"],"pdf_url":"","comment":"IEEE Access, 15 pages, 5 figures, 11 tables"},{"id":"http://arxiv.org/abs/2602.17445v1","updated":"2026-02-19T15:12:33Z","published":"2026-02-19T15:12:33Z","title":"ABCD: All Biases Come Disguised","summary":"Multiple-choice question (MCQ) benchmarks have been a standard evaluation practice for measuring LLMs' ability to reason and answer knowledge-based questions. Through a synthetic NonsenseQA benchmark, we observe that different LLMs exhibit varying degrees of label-position-few-shot-prompt bias, where the model either uses the answer position, the label in front of the answer, the distributions of correct answers present in the few-shot prompt, or a combination of all to answer each MCQ question. We propose a simple bias-reduced evaluation protocol that replaces the labels of each question with uniform, unordered labels and prompts the LLM to use the whole answer presented. With a simple sentence similarity model, we demonstrate improved robustness and lower standard deviation between different permutations of answers with a minimal drop in LLM's performance, exposing the LLM's capabilities under reduced evaluation artifacts, without any help from the prompt examples or the option labels. Across multiple benchmarks and models, this protocol substantially improves the robustness to answer permutations, reducing mean accuracy variance $3\\times$ with only a minimal decrease in the mean model's performance. Through ablation studies on various embedding models and similarity functions, we show that the method is more robust than the standard ones.","authors":["Mateusz Nowak","Xavier Cadet","Peter Chin"],"pdf_url":"","comment":"29 pages, 20 figures, pre-print, 12 tables"},{"id":"http://arxiv.org/abs/2602.17443v1","updated":"2026-02-19T15:09:12Z","published":"2026-02-19T15:09:12Z","title":"AIDG: Evaluating Asymmetry Between Information Extraction and Containment in Multi-Turn Dialogue","summary":"Evaluating the strategic reasoning capabilities of Large Language Models (LLMs) requires moving beyond static benchmarks to dynamic, multi-turn interactions. We introduce AIDG (Adversarial Information Deduction Game), a game-theoretic framework that probes the asymmetry between information extraction (active deduction) and information containment (state maintenance) in dialogue. We propose two complementary tasks: AIDG-I, measuring pragmatic strategy in social deduction, and AIDG-II, measuring constraint satisfaction in a structured \"20 Questions\" setting. Across 439 games with six frontier LLMs, we observe a clear capability asymmetry: models perform substantially better at containment than deduction, with a 350 ELO advantage on defense;(Cohen's d = 5.47). We identify two bottlenecks driving this gap: (1) Information Dynamics, where confirmation strategies are 7.75x more effective than blind deduction (p < 0.00001), and (2) Constraint Adherence, where instruction-following degrades under conversational load, accounting for 41.3% of deductive failures. These findings suggest that while LLMs excel at local defensive coherence, they struggle with the global state tracking required for strategic inquiry.","authors":["Adib Sakhawat","Fardeen Sadab","Rakin Shahriar"],"pdf_url":"","comment":"16 pages, 5 figures, 13 tables. Includes appendix and supplementary materials"},{"id":"http://arxiv.org/abs/2602.17431v1","updated":"2026-02-19T15:02:29Z","published":"2026-02-19T15:02:29Z","title":"Fine-Grained Uncertainty Quantification for Long-Form Language Model Outputs: A Comparative Study","summary":"Uncertainty quantification has emerged as an effective approach to closed-book hallucination detection for LLMs, but existing methods are largely designed for short-form outputs and do not generalize well to long-form generation. We introduce a taxonomy for fine-grained uncertainty quantification in long-form LLM outputs that distinguishes methods by design choices at three stages: response decomposition, unit-level scoring, and response-level aggregation. We formalize several families of consistency-based black-box scorers, providing generalizations and extensions of existing methods. In our experiments across multiple LLMs and datasets, we find 1) claim-response entailment consistently performs better or on par with more complex claim-level scorers, 2) claim-level scoring generally yields better results than sentence-level scoring, and 3) uncertainty-aware decoding is highly effective for improving the factuality of long-form outputs. Our framework clarifies relationships between prior methods, enables apples-to-apples comparisons, and provides practical guidance for selecting components for fine-grained UQ.","authors":["Dylan Bouchard","Mohit Singh Chauhan","Viren Bajaj","David Skarbrevik"],"pdf_url":"","comment":"UQLM repository: https://github.com/cvs-health/uqlm"},{"id":"http://arxiv.org/abs/2602.17425v1","updated":"2026-02-19T14:56:42Z","published":"2026-02-19T14:56:42Z","title":"Evaluating Extremely Low-Resource Machine Translation: A Comparative Study of ChrF++ and BLEU Metrics","summary":"Evaluating machine translation (MT) quality in extremely low-resource language (ELRL) scenarios poses unique challenges, as widely used metrics such as BLEU, effective in high-resource settings, often misrepresent quality in data-scarce contexts. This work presents a comparative analysis of BLEU, an n-gram-based metric, and ChrF++, a character-based metric, for MT evaluation in ELRL settings. We examine how each metric responds to translation artifacts, including hallucinations, repetition, source-text copying, and diacritic (\\textit{matra}) variations across three ELRLs: Magahi, Bhojpuri, and Chhattisgarhi, with a focus on outputs from large language models (LLMs) and neural MT (NMT) systems. While recent work often relies solely on ChrF++, our findings show that BLEU, despite its lower absolute scores, provides complementary lexical-precision insights that improve interpretability.","authors":["Sanjeev Kumar","Preethi Jyothi","Pushpak Bhattacharyya"],"pdf_url":"","comment":"6 pages"},{"id":"http://arxiv.org/abs/2602.17424v1","updated":"2026-02-19T14:56:01Z","published":"2026-02-19T14:56:01Z","title":"Diverse Word Choices, Same Reference: Annotating Lexically-Rich Cross-Document Coreference","summary":"Cross-document coreference resolution (CDCR) identifies and links mentions of the same entities and events across related documents, enabling content analysis that aggregates information at the level of discourse participants. However, existing datasets primarily focus on event resolution and employ a narrow definition of coreference, which limits their effectiveness in analyzing diverse and polarized news coverage where wording varies widely. This paper proposes a revised CDCR annotation scheme of the NewsWCL50 dataset, treating coreference chains as discourse elements (DEs) and conceptual units of analysis. The approach accommodates both identity and near-identity relations, e.g., by linking \"the caravan\" - \"asylum seekers\" - \"those contemplating illegal entry\", allowing models to capture lexical diversity and framing variation in media discourse, while maintaining the fine-grained annotation of DEs. We reannotate the NewsWCL50 and a subset of ECB+ using a unified codebook and evaluate the new datasets through lexical diversity metrics and a same-head-lemma baseline. The results show that the reannotated datasets align closely, falling between the original ECB+ and NewsWCL50, thereby supporting balanced and discourse-aware CDCR research in the news domain.","authors":["Anastasia Zhukova","Felix Hamborg","Karsten Donnay","Norman Meuschke","Bela Gipp"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17413v1","updated":"2026-02-19T14:43:48Z","published":"2026-02-19T14:43:48Z","title":"DAVE: A Policy-Enforcing LLM Spokesperson for Secure Multi-Document Data Sharing","summary":"In current inter-organizational data spaces, usage policies are enforced mainly at the asset level: a whole document or dataset is either shared or withheld. When only parts of a document are sensitive, providers who want to avoid leaking protected information typically must manually redact documents before sharing them, which is costly, coarse-grained, and hard to maintain as policies or partners change. We present DAVE, a usage policy-enforcing LLM spokesperson that answers questions over private documents on behalf of a data provider. Instead of releasing documents, the provider exposes a natural language interface whose responses are constrained by machine-readable usage policies. We formalize policy-violating information disclosure in this setting, drawing on usage control and information flow security, and introduce virtual redaction: suppressing sensitive information at query time without modifying source documents. We describe an architecture for integrating such a spokesperson with Eclipse Dataspace Components and ODRL-style policies, and outline an initial provider-side integration prototype in which QA requests are routed through a spokesperson service instead of triggering raw document transfer. Our contribution is primarily architectural: we do not yet implement or empirically evaluate the full enforcement pipeline. We therefore outline an evaluation methodology to assess security, utility, and performance trade-offs under benign and adversarial querying as a basis for future empirical work on systematically governed LLM access to multi-party data spaces.","authors":["René Brinkhege","Prahlad Menon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.13110v2","updated":"2026-02-19T14:41:37Z","published":"2026-02-13T17:10:43Z","title":"SCOPE: Selective Conformal Optimized Pairwise LLM Judging","summary":"Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE (Selective Conformal Optimized Pairwise Evaluation), a framework for selective pairwise judging with finite-sample statistical guarantees. Under exchangeability, SCOPE calibrates an acceptance threshold such that the error rate among non-abstained judgments is at most a user-specified level $α$. To provide SCOPE with a bias-neutral uncertainty signal, we introduce Bidirectional Preference Entropy (BPE), which queries the judge under both response positions, aggregates the implied preference probabilities to enforce invariance to response order, and converts the aggregated probability into an entropy-based uncertainty score. Across MT-Bench, RewardBench, and Chatbot Arena, BPE improves uncertainty quality over standard confidence proxies, providing a stronger selection signal that enables SCOPE to consistently meet the target risk level while retaining good coverage across judge scales. In particular, at $α= 0.10$, SCOPE consistently satisfies the risk bound across all benchmarks and judge scales (empirical risk $\\approx 0.097$ to $0.099$), while retaining substantial coverage, reaching $0.89$ on RewardBench with Qwen-14B and $0.98$ on RewardBench with Qwen-32B. Compared to naïve baselines, SCOPE accepts up to $2.4\\times$ more judgments on MT-Bench with Qwen-7B under the same target risk constraint, demonstrating that BPE enables reliable and high-coverage LLM-based evaluation.","authors":["Sher Badshah","Ali Emami","Hassan Sajjad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17377v1","updated":"2026-02-19T13:58:48Z","published":"2026-02-19T13:58:48Z","title":"The Role of the Availability Heuristic in Multiple-Choice Answering Behaviour","summary":"When students are unsure of the correct answer to a multiple-choice question (MCQ), guessing is common practice. The availability heuristic, proposed by A. Tversky and D. Kahneman in 1973, suggests that the ease with which relevant instances come to mind, typically operationalised by the mere frequency of exposure, can offer a mental shortcut for problems in which the test-taker does not know the exact answer. Is simply choosing the option that comes most readily to mind a good strategy for answering MCQs? We propose a computational method of assessing the cognitive availability of MCQ options operationalised by concepts' prevalence in large corpora. The key finding, across three large question sets, is that correct answers, independently of the question stem, are significantly more available than incorrect MCQ options. Specifically, using Wikipedia as the retrieval corpus, we find that always selecting the most available option leads to scores 13.5% to 32.9% above the random-guess baseline. We further find that LLM-generated MCQ options show similar patterns of availability compared to expert-created options, despite the LLMs' frequentist nature and their training on large collections of textual data. Our findings suggest that availability should be considered in current and future work when computationally modelling student behaviour.","authors":["Leonidas Zotos","Hedderik van Rijn","Malvina Nissim"],"pdf_url":"","comment":"15 pages, 4 figures"},{"id":"http://arxiv.org/abs/2512.08646v2","updated":"2026-02-19T13:49:43Z","published":"2025-12-09T14:35:26Z","title":"QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models","summary":"We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation (>40 million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers. We also find that answers can be obtained for a fraction of the compute cost, by changing the presentation method. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs \\emph{without coding knowledge}. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.","authors":["Maximilian Kreutner","Jens Rupprecht","Georg Ahnert","Ahmed Salem","Markus Strohmaier"],"pdf_url":"","comment":"Accepted at 2026 EACL System Demonstrations The Python package is available at https://github.com/dess-mannheim/QSTN/"},{"id":"http://arxiv.org/abs/2602.17366v1","updated":"2026-02-19T13:49:39Z","published":"2026-02-19T13:49:39Z","title":"RPDR: A Round-trip Prediction-Based Data Augmentation Framework for Long-Tail Question Answering","summary":"Long-tail question answering presents significant challenges for large language models (LLMs) due to their limited ability to acquire and accurately recall less common knowledge. Retrieval-augmented generation (RAG) systems have shown great promise in mitigating this limitation by integrating external retrieval mechanisms. However, dense retrieval models often face the same difficulties when generalizing to rare or niche knowledge. In this study, we introduce RPDR, a novel data augmentation framework that selects high-quality easy-to-learn training data, to enhance dense retrievers. Our approach is built around three core components: synthetic data generation, data selection with Round-Trip prediction to identify easy-to-learn instances, and retriever training with these instances. We evaluate RPDR on two long-tail retrieval benchmarks, PopQA and EntityQuestion, demonstrating substantial improvements over existing retrievers like BM25 and Contriver, especially on extremely long-tail categories. We identify the strengths and limitations of RPDR through detailed human analysis and propose a dynamic routing mechanism to dynamically route queries to specialized retrieval modules to further improve retrieval performance.","authors":["Yiming Zhang","Siyue Zhang","Junbo Zhao","Chen Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.16777v2","updated":"2026-02-19T13:23:28Z","published":"2025-06-20T06:45:40Z","title":"DistillNote: Toward a Functional Evaluation Framework of LLM-Generated Clinical Note Summaries","summary":"Large language models (LLMs) are increasingly used to generate summaries from clinical notes. However, their ability to preserve essential diagnostic information remains underexplored, which could lead to serious risks for patient care. This study introduces DistillNote, an evaluation framework for LLM summaries that targets their functional utility by applying the generated summary downstream in a complex clinical prediction task, explicitly quantifying how much prediction signal is retained. We generated over 192,000 LLM summaries from MIMIC-IV clinical notes with increasing compression rates: standard, section-wise, and distilled section-wise. Heart failure diagnosis was chosen as the prediction task, as it requires integrating a wide range of clinical signals. LLMs were fine-tuned on both the original notes and their summaries, and their diagnostic performance was compared using the AUROC metric. We contrasted DistillNote's results with evaluations from LLM-as-judge and clinicians, assessing consistency across different evaluation methods. Summaries generated by LLMs maintained a strong level of heart failure diagnostic signal despite substantial compression. Models trained on the most condensed summaries (about 20 times smaller) achieved an AUROC of 0.92, compared to 0.94 with the original note baseline (97 percent retention). Functional evaluation provided a new lens for medical summary assessment, emphasizing clinical utility as a key dimension of quality. DistillNote introduces a new scalable, task-based method for assessing the functional utility of LLM-generated clinical summaries. Our results detail compression-to-performance tradeoffs from LLM clinical summarization for the first time. The framework is designed to be adaptable to other prediction tasks and clinical domains, aiding data-driven decisions about deploying LLM summarizers in real-world healthcare settings.","authors":["Heloisa Oss Boll","Antonio Oss Boll","Leticia Puttlitz Boll","Ameen Abu Hanna","Iacer Calixto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.12815v5","updated":"2026-02-19T13:22:59Z","published":"2026-01-19T08:21:46Z","title":"Multimodal Multi-Agent Empowered Legal Judgment Prediction","summary":"Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.","authors":["Zhaolu Kang","Junhao Gong","Qingxi Chen","Hao Zhang","Jiaxin Liu","Rong Fu","Zhiyuan Feng","Yuan Wang","Simon Fong","Kaiyue Zhou"],"pdf_url":"","comment":"Accepted to the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026"},{"id":"http://arxiv.org/abs/2602.17327v1","updated":"2026-02-19T12:45:58Z","published":"2026-02-19T12:45:58Z","title":"WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval","summary":"We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it the largest FAQ-based resource. Unlike the original release, WebFAQ 2.0 uses a novel data collection strategy that directly crawls and extracts relevant web content, resulting in a substantially more diverse and multilingual dataset with richer context through page titles and descriptions. In response to community feedback, we also release a hard negatives dataset for training dense retrievers, with 1.25M queries across 20 languages. These hard negatives were mined using a two-stage retrieval pipeline and include cross-encoder scores for 200 negatives per query. We further show how this resource enables two primary fine-tuning strategies for dense retrievers: Contrastive Learning with MultipleNegativesRanking loss, and Knowledge Distillation with MarginMSE loss. WebFAQ 2.0 is not a static resource but part of a long-term effort. Since late 2025, structured FAQs are being regularly released through the Open Web Index, enabling continuous expansion and refinement. We publish the datasets and training scripts to facilitate further research in multilingual and cross-lingual IR. The dataset itself and all related resources are publicly available on GitHub and HuggingFace.","authors":["Michael Dinzinger","Laura Caspari","Ali Salman","Irvin Topi","Jelena Mitrović","Michael Granitzer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17744v1","updated":"2026-02-19T12:41:28Z","published":"2026-02-19T12:41:28Z","title":"Bayesian Optimality of In-Context Learning with Selective State Spaces","summary":"We propose Bayesian optimal sequential prediction as a new principle for understanding in-context learning (ICL). Unlike interpretations framing Transformers as performing implicit gradient descent, we formalize ICL as meta-learning over latent sequence tasks. For tasks governed by Linear Gaussian State Space Models (LG-SSMs), we prove a meta-trained selective SSM asymptotically implements the Bayes-optimal predictor, converging to the posterior predictive mean. We further establish a statistical separation from gradient descent, constructing tasks with temporally correlated noise where the optimal Bayesian predictor strictly outperforms any empirical risk minimization (ERM) estimator. Since Transformers can be seen as performing implicit ERM, this demonstrates selective SSMs achieve lower asymptotic risk due to superior statistical efficiency. Experiments on synthetic LG-SSM tasks and a character-level Markov benchmark confirm selective SSMs converge faster to Bayes-optimal risk, show superior sample efficiency with longer contexts in structured-noise settings, and track latent states more robustly than linear Transformers. This reframes ICL from \"implicit optimization\" to \"optimal inference,\" explaining the efficiency of selective SSMs and offering a principled basis for architecture design.","authors":["Di Zhang","Jiaqi Xing"],"pdf_url":"","comment":"17 pages"},{"id":"http://arxiv.org/abs/2602.17316v1","updated":"2026-02-19T12:24:42Z","published":"2026-02-19T12:24:42Z","title":"Same Meaning, Different Scores: Lexical and Syntactic Sensitivity in LLM Evaluation","summary":"The rapid advancement of Large Language Models (LLMs) has established standardized evaluation benchmarks as the primary instrument for model comparison. Yet, their reliability is increasingly questioned due to sensitivity to shallow variations in input prompts. This paper examines how controlled, truth-conditionally equivalent lexical and syntactic perturbations affect the absolute performance and relative ranking of 23 contemporary LLMs across three benchmarks: MMLU, SQuAD, and AMEGA. We employ two linguistically principled pipelines to generate meaning-preserving variations: one performing synonym substitution for lexical changes, and another using dependency parsing to determine applicable syntactic transformations. Results show that lexical perturbations consistently induce substantial, statistically significant performance degradation across nearly all models and tasks, while syntactic perturbations have more heterogeneous effects, occasionally improving results. Both perturbation types destabilize model leaderboards on complex tasks. Furthermore, model robustness did not consistently scale with model size, revealing strong task dependence. Overall, the findings suggest that LLMs rely more on surface-level lexical patterns than on abstract linguistic competence, underscoring the need for robustness testing as a standard component of LLM evaluation.","authors":["Bogdan Kostić","Conor Fallon","Julian Risch","Alexander Löser"],"pdf_url":"","comment":"Accepted at LREC 2026"},{"id":"http://arxiv.org/abs/2602.17288v1","updated":"2026-02-19T11:47:30Z","published":"2026-02-19T11:47:30Z","title":"ArXiv-to-Model: A Practical Study of Scientific LM Training","summary":"While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scientific language model directly from raw arXiv LaTeX sources spanning mathematics, computer science, and theoretical physics. We describe an end-to-end pipeline covering metadata filtering, archive validation, LaTeX extraction, text normalization, domain-aware tokenization, and dense transformer training under constrained compute (2xA100 GPUs). Through 24 experimental runs, we analyze training stability, scaling behavior, data yield losses, and infrastructure bottlenecks. Our findings highlight how preprocessing decisions significantly affect usable token volume, how tokenization impacts symbolic stability, and how storage and I/O constraints can rival compute as limiting factors. We further analyze convergence dynamics and show stable training behavior in a data-rich regime (52B pretraining tokens). Rather than proposing a novel architecture, this work provides an engineering-grounded, transparent account of training a small scientific language model from scratch. We hope these insights support researchers operating under moderate compute budgets who seek to build domain-specialized models.","authors":["Anuj Gupta"],"pdf_url":"","comment":"15 pages, 6 figures, 1 table"},{"id":"http://arxiv.org/abs/2602.17287v1","updated":"2026-02-19T11:46:38Z","published":"2026-02-19T11:46:38Z","title":"Representation Collapse in Machine Translation Through the Lens of Angular Dispersion","summary":"Modern neural translation models based on the Transformer architecture are known for their high performance, particularly when trained on high-resource datasets. A standard next-token prediction training strategy, while widely adopted in practice, may lead to overlooked artifacts such as representation collapse. Previous works have shown that this problem is especially pronounced in the representation of the deeper Transformer layers, where it often fails to efficiently utilize the geometric space. Representation collapse is even more evident in end-to-end training of continuous-output neural machine translation, where the trivial solution would be to set all vectors to the same value. In this work, we analyze the dynamics of representation collapse at different levels of discrete and continuous NMT transformers throughout training. We incorporate an existing regularization method based on angular dispersion and demonstrate empirically that it not only mitigates collapse but also improves translation quality. Furthermore, we show that quantized models exhibit similar collapse behavior and that the benefits of regularization are preserved even after quantization.","authors":["Evgeniia Tokarchuk","Maya K. Nachesa","Sergey Troshin","Vlad Niculae"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17283v1","updated":"2026-02-19T11:41:34Z","published":"2026-02-19T11:41:34Z","title":"Towards Cross-lingual Values Assessment: A Consensus-Pluralism Perspective","summary":"While large language models (LLMs) have become pivotal to content safety, current evaluation paradigms primarily focus on detecting explicit harms (e.g., violence or hate speech), neglecting the subtler value dimensions conveyed in digital content. To bridge this gap, we introduce X-Value, a novel Cross-lingual Values Assessment Benchmark designed to evaluate LLMs' ability to assess deep-level values of content from a global perspective. X-Value consists of more than 5,000 QA pairs across 18 languages, systematically organized into 7 core domains grounded in Schwartz's Theory of Basic Human Values and categorized into easy and hard levels for discriminative evaluation. We further propose a unique two-stage annotation framework that first identifies whether an issue falls under global consensus (e.g., human rights) or pluralism (e.g., religion), and subsequently conducts a multi-party evaluation of the latent values embedded within the content. Systematic evaluations on X-Value reveal that current SOTA LLMs exhibit deficiencies in cross-lingual values assessment ($Acc < 77\\%$), with significant performance disparities across different languages ($ΔAcc > 20\\%$). This work highlights the urgent need to improve the nuanced, values-aware content assessment capability of LLMs. Our X-Value is available at: https://huggingface.co/datasets/Whitolf/X-Value.","authors":["Yukun Chen","Xinyu Zhang","Jialong Tang","Yu Wan","Baosong Yang","Yiming Li","Zhan Qin","Kui Ren"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13749v2","updated":"2026-02-19T11:33:10Z","published":"2025-10-15T16:55:47Z","title":"Assessing Web Search Credibility and Response Groundedness in Chat Assistants","summary":"Chat assistants increasingly integrate web search functionality, enabling them to retrieve and cite external sources. While this promises more reliable answers, it also raises the risk of amplifying misinformation from low-credibility sources. In this paper, we introduce a novel methodology for evaluating assistants' web search behavior, focusing on source credibility and the groundedness of responses with respect to cited sources. Using 100 claims across five misinformation-prone topics, we assess GPT-4o, GPT-5, Perplexity, and Qwen Chat. Our findings reveal differences between the assistants, with Perplexity achieving the highest source credibility, whereas GPT-4o exhibits elevated citation of non-credibility sources on sensitive topics. This work provides the first systematic comparison of commonly used chat assistants for fact-checking behavior, offering a foundation for evaluating AI systems in high-stakes information environments.","authors":["Ivan Vykopal","Matúš Pikuliak","Simon Ostermann","Marián Šimko"],"pdf_url":"","comment":"Accepted at EACL 2026 Main"},{"id":"http://arxiv.org/abs/2602.17262v1","updated":"2026-02-19T11:07:24Z","published":"2026-02-19T11:07:24Z","title":"Quantifying and Mitigating Socially Desirable Responding in LLMs: A Desirability-Matched Graded Forced-Choice Psychometric Study","summary":"Human self-report questionnaires are increasingly used in NLP to benchmark and audit large language models (LLMs), from persona consistency to safety and bias assessments. Yet these instruments presume honest responding; in evaluative contexts, LLMs can instead gravitate toward socially preferred answers-a form of socially desirable responding (SDR)-biasing questionnaire-derived scores and downstream conclusions. We propose a psychometric framework to quantify and mitigate SDR in questionnaire-based evaluation of LLMs. To quantify SDR, the same inventory is administered under HONEST versus FAKE-GOOD instructions, and SDR is computed as a direction-corrected standardized effect size from item response theory (IRT)-estimated latent scores. This enables comparisons across constructs and response formats, as well as against human instructed-faking benchmarks. For mitigation, we construct a graded forced-choice (GFC) Big Five inventory by selecting 30 cross-domain pairs from an item pool via constrained optimization to match desirability. Across nine instruction-tuned LLMs evaluated on synthetic personas with known target profiles, Likert-style questionnaires show consistently large SDR, whereas desirability-matched GFC substantially attenuates SDR while largely preserving the recovery of the intended persona profiles. These results highlight a model-dependent SDR-recovery trade-off and motivate SDR-aware reporting practices for questionnaire-based benchmarking and auditing of LLMs.","authors":["Kensuke Okada","Yui Furukawa","Kyosuke Bunji"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16346v2","updated":"2026-02-19T10:44:43Z","published":"2026-02-18T10:31:19Z","title":"Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents","summary":"LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step illicit plan grounded in a benign persona and iteratively probes a target agent with adaptive follow-ups, using judge agents to track phase completion. We further introduce an analysis framework that models multi-turn red-teaming as a time-to-first-jailbreak random variable, enabling analysis tools like discovery curves, hazard-ratio attribution by attack language, and a new metric: Restricted Mean Jailbreak Discovery. Across AgentHarm scenarios, STING yields substantially higher illicit-task completion than single-turn prompting and chat-oriented multi-turn baselines adapted to tool-using agents. In multilingual evaluations across six non-English settings, we find that attack success and illicit-task completion do not consistently increase in lower-resource languages, diverging from common chatbot findings. Overall, STING provides a practical way to evaluate and stress-test agent misuse in realistic deployment settings, where interactions are inherently multi-turn and often multilingual.","authors":["Nivya Talokar","Ayush K Tarun","Murari Mandal","Maksym Andriushchenko","Antoine Bosselut"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.15868v2","updated":"2026-02-19T10:42:24Z","published":"2026-01-27T16:12:01Z","title":"Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model Reasoning","summary":"Large language models (LLMs) exhibit failure modes on seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi-tape Turing machine, where each tape represents a distinct component: input characters, tokens, vocabulary, model parameters, activations, probability distributions, and output text. The model enables precise localisation of failure modes to specific pipeline stages, revealing, e.g., how tokenisation obscures character-level structure needed for counting tasks. The model clarifies why techniques like chain-of-thought prompting help, by externalising computation on the output tape, while also revealing their fundamental limitations. This approach provides a rigorous, falsifiable alternative to geometric metaphors and complements empirical scaling laws with principled error analysis.","authors":["Magnus Boman"],"pdf_url":"","comment":"8 pages, 1 page appendix; v2 added Acknowledgements"},{"id":"http://arxiv.org/abs/2502.10361v2","updated":"2026-02-19T10:37:06Z","published":"2025-02-14T18:42:07Z","title":"Enhancing Multilingual LLM Pretraining with Model-Based Data Selection","summary":"Dataset curation has become a basis for strong large language model (LLM) performance. While various rule-based filtering heuristics exist for English and multilingual datasets, model-based filtering techniques have primarily focused on English. To address the disparity stemming from limited research on non-English languages, we develop a model-based filtering framework for multilingual datasets that aims to identify a diverse set of structured and knowledge-rich samples. Our approach emphasizes transparency, simplicity, and efficiency, leveraging Transformer- and FastText-based classifiers to ensure the broad accessibility of our technique and data. We conduct comprehensive ablation studies on the FineWeb-2 web crawl dataset across diverse language families, scripts, and resource availability to demonstrate the effectiveness of our method. Training a 1B-parameter Llama model for 70B and 119B tokens, our approach can match the baseline MMLU score with as little as 15% of the training tokens, while also improving across other benchmarks and mitigating the curse of multilinguality. These findings provide strong evidence for the generalizability of our approach to other languages. As a result, we extend our framework to 20 languages for which we release the refined pretraining datasets.","authors":["Bettina Messmer","Vinko Sabolčec","Martin Jaggi"],"pdf_url":"","comment":"NeurIPS 2025 Track on Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/2212.06543v3","updated":"2026-02-19T10:34:27Z","published":"2022-12-13T12:56:55Z","title":"Improving Stance Detection by Leveraging Measurement Knowledge from Social Sciences: A Case Study of Dutch Political Tweets and Traditional Gender Role Division","summary":"Stance detection concerns automatically determining the viewpoint (i.e., in favour of, against, or neutral) of a text's author towards a target. Stance detection has been applied to many research topics, among which the detection of stances behind political tweets is an important one. In this paper, we apply stance detection to a dataset of tweets from official party accounts in the Netherlands between 2017 and 2021, with a focus on stances towards traditional gender role division, a dividing issue between (some) Dutch political parties. To implement and improve stance detection of traditional gender role division, we propose to leverage an established survey instrument from social sciences, which has been validated for the purpose of measuring attitudes towards traditional gender role division. Based on our experiments, we show that using such a validated survey instrument helps to improve stance detection performance.","authors":["Qixiang Fang","Anastasia Giachanou","Ayoub Bagheri"],"pdf_url":"","comment":"Published in BNAIC 2024"},{"id":"http://arxiv.org/abs/2602.17229v1","updated":"2026-02-19T10:19:04Z","published":"2026-02-19T10:19:04Z","title":"Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy","summary":"The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional activation vectors from different LLMs, we probe whether different cognitive levels, ranging from basic recall (Remember) to abstract synthesis (Create), are linearly separable within the model's residual streams. Our results demonstrate that linear classifiers achieve approximately 95% mean accuracy across all Bloom levels, providing strong evidence that cognitive level is encoded in a linearly accessible subspace of the model's representations. These findings provide evidence that the model resolves the cognitive difficulty of a prompt early in the forward pass, with representations becoming increasingly separable across layers.","authors":["Bianca Raimondi","Maurizio Gabbrielli"],"pdf_url":"","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2602.17221v1","updated":"2026-02-19T10:12:08Z","published":"2026-02-19T10:12:08Z","title":"From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences","summary":"Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a \"methodological experiment,\" this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index (AEI) serves as the empirical vehicle for validating the feasibility of this methodology.\n  This study operates on two levels: the primary level is the design and validation of a methodological framework - a seven-stage modular workflow grounded in three principles: task modularization, human-AI division of labor, and verifiability, with each stage delineating clear roles for human researchers (research judgment and ethical decisions) and AI Agents (information retrieval and text generation); the secondary level is the empirical analysis of AEI Taiwan data - serving as an operational demonstration of the workflow's application to secondary data research, showcasing both the process and output quality (see Appendix A).\n  This study contributes by proposing a replicable AI collaboration framework for humanities and social science researchers, and identifying three operational modes of human-AI collaboration - direct execution, iterative refinement, and human-led - through reflexive documentation of the operational process. This taxonomy reveals the irreplaceability of human judgment in research question formulation, theoretical interpretation, contextualized reasoning, and ethical reflection. Limitations including single-platform data, cross-sectional design, and AI reliability risks are acknowledged.","authors":["Yi-Chih Huang"],"pdf_url":"","comment":"also in Chinese"},{"id":"http://arxiv.org/abs/2507.19634v3","updated":"2026-02-19T09:44:55Z","published":"2025-07-25T19:00:51Z","title":"MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks","summary":"Recent advances in large language models have laid the foundation for multimodal LLMs (MLLMs), which unify text, speech, and vision within a single framework. As these models are rapidly evolving toward general-purpose instruction following across diverse and complex tasks, a key frontier is evaluating their crosslingual and multimodal capabilities over both short- and long-form inputs. However, existing benchmarks fall short in evaluating these dimensions jointly: they are often limited to English, mostly focus on a single modality at a time, rely on short-form inputs, or lack human annotations--hindering comprehensive assessment of model performance across languages, modalities, and task complexity. To address these gaps, we introduce MCIF (Multimodal Crosslingual Instruction Following), the first crosslingual human-annotated benchmark based on scientific talks on NLP and beyond. MCIF evaluates instruction following in crosslingual, multimodal settings over different input lengths and spans four macro-tasks: recognition, translation, question answering, and summarization. It covers three core modalities (speech, vision, and text) and four diverse languages (English, German, Italian, and Chinese), fully aligned across all dimensions. This parallel design enables a systematic evaluation of MLLMs' abilities to interpret instructions across languages and effectively integrate multimodal contextual information. Our benchmarking and analysis of 23 models highlight universal challenges across modalities and tasks, indicating substantial room for improvement in future MLLMs development. MCIF is released under CC-BY 4.0 license to promote open research.","authors":["Sara Papi","Maike Züfle","Marco Gaido","Beatrice Savoldi","Danni Liu","Ioannis Douros","Luisa Bentivogli","Jan Niehues"],"pdf_url":"","comment":"Data available at https://huggingface.co/datasets/FBK-MT/MCIF | Evaluation, outputs, and baselines available at https://github.com/hlt-mt/mcif"},{"id":"http://arxiv.org/abs/2602.12414v2","updated":"2026-02-19T09:31:25Z","published":"2026-02-12T21:13:08Z","title":"propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale","summary":"Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and offers no interpretability. We introduce propella-1, a family of small multilingual LLMs (0.6B, 1.7B, 4B parameters) that annotate text documents across 18 properties organized into six categories: core content, classification, quality and value, audience and purpose, safety and compliance, and geographic relevance. The models support 57 languages and produce structured JSON annotations conforming to a predefined schema. Evaluated against a frontier commercial LLM as a reference annotator, the 4B model achieves higher agreement than much larger general-purpose models. We release propella-annotations, a dataset of over three billion document annotations covering major pretraining corpora including data from FineWeb-2, FinePDFs, HPLT 3.0, and Nemotron-CC. Using these annotations, we present a multi-dimensional compositional analysis of widely used pretraining datasets, revealing substantial differences in quality, reasoning depth, and content composition that single-score approaches cannot capture. All model weights and annotations are released under permissive, commercial-use licenses.","authors":["Maximilian Idahl","Benedikt Droste","Björn Plüster","Jan Philipp Harries"],"pdf_url":"","comment":"Release: https://hf.co/collections/ellamind/propella-1"},{"id":"http://arxiv.org/abs/2506.11798v3","updated":"2026-02-19T09:26:01Z","published":"2025-06-13T14:02:21Z","title":"Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models","summary":"Large Language Models (LLMs) display remarkable capabilities to understand or even produce political discourse but have been found to consistently exhibit a progressive left-leaning bias. At the same time, so-called persona or identity prompts have been shown to produce LLM behavior that aligns with socioeconomic groups with which the base model is not aligned. In this work, we analyze whether zero-shot persona prompting with limited information can accurately predict individual voting decisions and, by aggregation, accurately predict the positions of European groups on a diverse set of policies. We evaluate whether predictions are stable in response to counterfactual arguments, different persona prompts, and generation methods. Finally, we find that we can simulate the voting behavior of Members of the European Parliament reasonably well, achieving a weighted F1 score of approximately 0.793. Our persona dataset of politicians in the 2024 European Parliament and our code are available at the following url: https://github.com/dess-mannheim/european_parliament_simulation.","authors":["Maximilian Kreutner","Marlene Lutz","Markus Strohmaier"],"pdf_url":"","comment":"Accepted at EACL 2026 Findings"},{"id":"http://arxiv.org/abs/2602.17194v1","updated":"2026-02-19T09:25:00Z","published":"2026-02-19T09:25:00Z","title":"What Makes a Good Doctor Response? An Analysis on a Romanian Telemedicine Platform","summary":"Text-based telemedicine has become a common mode of care, requiring clinicians to deliver medical advice clearly and effectively in writing. As platforms increasingly rely on patient ratings and feedback, clinicians face growing pressure to maintain satisfaction scores, even though these evaluations often reflect communication quality more than clinical accuracy. We analyse patient satisfaction signals in Romanian text-based telemedicine. Using a sample of 77,334 anonymised patient question--doctor response pairs, we model feedback as a binary outcome, treating thumbs-up responses as positive and grouping negative or absent feedback into the other class. We extract interpretable, predominantly language-agnostic features (e.g., length, structural characteristics, readability proxies), along with Romanian LIWC psycholinguistic features and politeness/hedging markers where available. We train a classifier with a time-based split and perform SHAP-based analyses, which indicate that patient and clinician history features dominate prediction, functioning as strong priors, while characteristics of the response text provide a smaller but, crucially, actionable signal. In subgroup correlation analyses, politeness and hedging are consistently positively associated with patient feedback, whereas lexical diversity shows a negative association.","authors":["Adrian Cosma","Cosmin Dumitrache","Emilian Radoi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.06932v2","updated":"2026-02-19T09:06:49Z","published":"2026-01-11T14:36:36Z","title":"Symphonym: Universal Phonetic Embeddings for Cross-Script Name Matching","summary":"Linking names across historical sources, languages, and writing systems remains a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches require language-specific phonetic algorithms or fail to capture phonetic relationships across different scripts. This paper presents Symphonym, a neural embedding system that maps names from any script into a unified 128-dimensional phonetic space, enabling direct similarity comparison without runtime phonetic conversion. Symphonym uses a Teacher-Student architecture where a Teacher network trained on articulatory phonetic features produces target embeddings, while a Student network learns to approximate these embeddings directly from characters. The Teacher combines Epitran (extended with 100 new language-script mappings), Phonikud for Hebrew, and CharsiuG2P for Chinese, Japanese, and Korean. Training used 32.7 million triplet samples of toponyms spanning 20 writing systems from GeoNames, Wikidata, and Getty Thesaurus of Geographic Names. On the MEHDIE Hebrew-Arabic historical toponym benchmark, Symphonym achieves Recall@10 of 97.6% and MRR of 90.3%, outperforming Levenshtein and Jaro-Winkler baselines (Recall@1: 86.7% vs 81.5% and 78.5%). Evaluation on 12,947 real cross-script training pairs shows 82.6% achieve greater than 0.75 cosine similarity, with best performance on Arabic-Cyrillic (94--100%) and Cyrillic-Latin (94.3%) combinations. The fixed-length embeddings enable efficient retrieval in digital humanities workflows, with a case study on medieval personal names demonstrating effective transfer from modern place names to historical orthographic variation.","authors":["Stephen Gadd"],"pdf_url":"","comment":"29 pages, 3 tables"},{"id":"http://arxiv.org/abs/2511.17673v5","updated":"2026-02-19T08:59:36Z","published":"2025-11-21T05:19:34Z","title":"Bridging Symbolic Control and Neural Reasoning in LLM Agents: Structured Cognitive Loop with a Governance Layer","summary":"Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retrieval, Cognition, Control, Action, and Memory (R-CCAM). Soft Symbolic Control constitutes a dedicated governance layer within SCL, applying symbolic constraints to probabilistic inference while preserving the flexibility of neural reasoning and restoring the explainability and controllability of classical symbolic systems. Through empirical validation on multi-step conditional reasoning tasks, we demonstrate that SCL achieves zero policy violations, eliminates redundant tool calls, and maintains complete decision traceability. These results address critical gaps in existing frameworks such as ReAct, AutoGPT, and memory-augmented approaches. Our contributions are threefold: (1) we situate SCL within the taxonomy of hybrid intelligence, differentiating it from prompt-centric and memory-only approaches; (2) we formally define Soft Symbolic Control and contrast it with neuro-symbolic AI; and (3) we derive three design principles for trustworthy agents: modular decomposition, adaptive symbolic governance, and transparent state management. We provide a complete open-source implementation demonstrating the R-CCAM loop architecture, alongside a live GPT-4o-powered travel planning agent. By connecting expert system principles with modern LLM capabilities, this work offers a practical and theoretically grounded path toward reliable, explainable, and governable AI agents.","authors":["Myung Ho Kim"],"pdf_url":"","comment":"The SCL diagram has been revised for greater clarity"},{"id":"http://arxiv.org/abs/2510.09201v2","updated":"2026-02-19T08:37:28Z","published":"2025-10-10T09:41:25Z","title":"Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs","summary":"Large Language Models (LLMs) have shown remarkable success, and their multimodal expansions (MLLMs) further unlock capabilities spanning images, videos, and other modalities beyond text. However, despite this shift, prompt optimization approaches, designed to reduce the burden of manual prompt crafting while maximizing performance, remain confined to text, ultimately limiting the full potential of MLLMs. Motivated by this gap, we introduce the new problem of multimodal prompt optimization, which expands the prior definition of prompt optimization to the multimodal space defined by the pairs of textual and non-textual prompts. To tackle this problem, we then propose the Multimodal Prompt Optimizer (MPO), a unified framework that not only performs the joint optimization of multimodal prompts through alignment-preserving updates but also guides the selection process of candidate prompts by leveraging earlier evaluations as priors in a Bayesian-based selection strategy. Through extensive experiments across diverse modalities that go beyond text, such as images, videos, and even molecules, we demonstrate that MPO outperforms leading text-only optimization methods, establishing multimodal prompt optimization as a crucial step to realizing the potential of MLLMs.","authors":["Yumin Choi","Dongki Kim","Jinheon Baek","Sung Ju Hwang"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2510.21193v2","updated":"2026-02-19T07:51:12Z","published":"2025-10-24T06:56:28Z","title":"Estonian Native Large Language Model Benchmark","summary":"The availability of LLM benchmarks for the Estonian language is limited, and a comprehensive evaluation comparing the performance of different LLMs on Estonian tasks has yet to be conducted. We introduce a new benchmark for evaluating LLMs in Estonian, based on seven diverse datasets. These datasets assess general and domain-specific knowledge, understanding of Estonian grammar and vocabulary, summarization abilities, contextual comprehension, and more. The datasets are all generated from native Estonian sources without using machine translation. We compare the performance of base models, instruction-tuned open-source models, and commercial models. Our evaluation includes 6 base models and 26 instruction-tuned models. To assess the results, we employ both human evaluation and LLM-as-a-judge methods. Human evaluation scores showed moderate to high correlation with benchmark evaluations, depending on the dataset. Claude 3.7 Sonnet, used as an LLM judge, demonstrated strong alignment with human ratings, indicating that top-performing LLMs can effectively support the evaluation of Estonian-language models.","authors":["Helena Grete Lillepalu","Tanel Alumäe"],"pdf_url":"","comment":"Accepted to LREC 2026"},{"id":"http://arxiv.org/abs/2602.17127v1","updated":"2026-02-19T06:56:01Z","published":"2026-02-19T06:56:01Z","title":"The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI","summary":"As Large Language Models (LLMs) transition from standalone chat interfaces to foundational reasoning layers in multi-agent systems and recursive evaluation loops (LLM-as-a-judge), the detection of durable, provider-level behavioral signatures becomes a critical requirement for safety and governance. Traditional benchmarks measure transient task accuracy but fail to capture stable, latent response policies -- the ``prevailing mindsets'' embedded during training and alignment that outlive individual model versions.\n  This paper introduces a novel auditing framework that utilizes psychometric measurement theory -- specifically latent trait estimation under ordinal uncertainty -- to quantify these tendencies without relying on ground-truth labels. Utilizing forced-choice ordinal vignettes masked by semantically orthogonal decoys and governed by cryptographic permutation-invariance, the research audits nine leading models across dimensions including Optimization Bias, Sycophancy, and Status-Quo Legitimization.\n  Using Mixed Linear Models (MixedLM) and Intraclass Correlation Coefficient (ICC) analysis, the research identifies that while item-level framing drives high variance, a persistent ``lab signal'' accounts for significant behavioral clustering. These findings demonstrate that in ``locked-in'' provider ecosystems, latent biases are not merely static errors but compounding variables that risk creating recursive ideological echo chambers in multi-layered AI architectures.","authors":["Dusan Bosnjakovic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.02529v2","updated":"2026-02-19T06:53:03Z","published":"2025-06-03T07:08:21Z","title":"Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs","summary":"Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in automating complex tasks, but limitations persist in handling dynamic navigation flows and complex form interactions. This paper presents an automated system for generating test cases for two key aspects of web application testing: site navigation and form filling. For site navigation, the system employs screen transition graphs and LLMs to model navigation flows and generate test scenarios. For form filling, it uses state graphs to handle conditional forms and automates Selenium script generation. Key contributions include: (1) a novel integration of graph structures and LLMs for site navigation testing, (2) a state graph-based approach for automating form-filling test cases, and (3) a comprehensive dataset for evaluating form-interaction testing. Experimental results demonstrate the system's effectiveness in improving test coverage and robustness, advancing the state of web application testing.","authors":["Nguyen-Khang Le","Quan Minh Bui","Minh Ngoc Nguyen","Hiep Nguyen","Trung Vo","Son T. Luu","Shoshin Nomura","Minh Le Nguyen"],"pdf_url":"","comment":"Published in the Proceedings of JSAI 2025"},{"id":"http://arxiv.org/abs/2602.17108v1","updated":"2026-02-19T06:08:33Z","published":"2026-02-19T06:08:33Z","title":"Projective Psychological Assessment of Large Multimodal Models Using Thematic Apperception Tests","summary":"Thematic Apperception Test (TAT) is a psychometrically grounded, multidimensional assessment framework that systematically differentiates between cognitive-representational and affective-relational components of personality-like functioning. This test is a projective psychological framework designed to uncover unconscious aspects of personality. This study examines whether the personality traits of Large Multimodal Models (LMMs) can be assessed through non-language-based modalities, using the Social Cognition and Object Relations Scale - Global (SCORS-G). LMMs are employed in two distinct roles: as subject models (SMs), which generate stories in response to TAT images, and as evaluator models (EMs), who assess these narratives using the SCORS-G framework. Evaluators demonstrated an excellent ability to understand and analyze TAT responses. Their interpretations are highly consistent with those of human experts. Assessment results highlight that all models understand interpersonal dynamics very well and have a good grasp of the concept of self. However, they consistently fail to perceive and regulate aggression. Performance varied systematically across model families, with larger and more recent models consistently outperforming smaller and earlier ones across SCORS-G dimensions.","authors":["Anton Dzega","Aviad Elyashar","Ortal Slobodin","Odeya Cohen","Rami Puzis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.06106v2","updated":"2026-02-19T06:04:57Z","published":"2024-12-08T23:41:38Z","title":"Efficient Context Propagating Perceiver Architectures for Auto-Regressive Language Modeling","summary":"One of the key challenges in Transformer architectures is the quadratic complexity of the attention mechanism, which limits the efficient processing of long sequences. Many recent research works have attempted to provide a reduction from the $O(n^2)$ time complexity of attention to semi-linear complexity. However, it remains an unsolved problem in the sense of maintaining high performance when complexity is reduced. One of the important works in this respect is the Perceiver class of architectures that have demonstrated excellent performance, while reducing the computation complexity. In this paper, we use the PerceiverAR as a basis and explore the design space of different trade-offs between preserving context and reducing attention complexity. To this end, we develop four new architectural paradigms, the best performing of which we denote as the Efficient Context propagating Perceiver (ECP). ECP has two major advantages over the PerceiverAR. First, the ECP architecture overcomes the main drawback of PercieverAR by utilizing both the context and the latent sequences in autoregressive training. Second, the ECP architecture operates with the same attention complexity as LongLoRA, making it computationally efficient. More importantly, via pairwise segment attention, it extracts better information resulting in improved language modeling. Empirically, we demonstrate that the ECP architecture significantly outperforms other state-of-the-art Transformer models on Wikitext-103, PG-19 and sCIFAR-10.","authors":["Kaleel Mahmood","Shaoyi Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.03870v3","updated":"2026-02-19T05:41:27Z","published":"2025-12-03T15:22:00Z","title":"Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers","summary":"Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.","authors":["Hongzhan Lin","Zhiqi Bai","Xinmiao Zhang","Sen Yang","Xiang Li","Siran Yang","Yunlong Xu","Jiaheng Liu","Yongchi Zhao","Jiamang Wang","Yuchi Xu","Wenbo Su","Bo Zheng"],"pdf_url":"","comment":"Accepted by ICLR2026"},{"id":"http://arxiv.org/abs/2602.16241v2","updated":"2026-02-19T05:23:43Z","published":"2026-02-18T07:36:41Z","title":"Are LLMs Ready to Replace Bangla Annotators?","summary":"Large Language Models (LLMs) are increasingly used as automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of LLMs as zero-shot annotators for Bangla hate speech, a task where even human agreement is challenging, and annotator bias can have serious downstream consequences. We conduct a systematic benchmark of 17 LLMs using a unified evaluation framework. Our analysis uncovers annotator bias and substantial instability in model judgments. Surprisingly, increased model scale does not guarantee improved annotation quality--smaller, more task-aligned models frequently exhibit more consistent behavior than their larger counterparts. These results highlight important limitations of current LLMs for sensitive annotation tasks in low-resource languages and underscore the need for careful evaluation before deployment.","authors":["Md. Najib Hasan","Touseef Hasan","Souvika Sarkar"],"pdf_url":"","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2602.17901v1","updated":"2026-02-19T23:45:23Z","published":"2026-02-19T23:45:23Z","title":"MeDUET: Disentangled Unified Pretraining for 3D Medical Image Synthesis and Analysis","summary":"Self-supervised learning (SSL) and diffusion models have advanced representation learning and image synthesis. However, in 3D medical imaging, they remain separate: diffusion for synthesis, SSL for analysis. Unifying 3D medical image synthesis and analysis is intuitive yet challenging, as multi-center datasets exhibit dominant style shifts, while downstream tasks rely on anatomy, and site-specific style co-varies with anatomy across slices, making factors unreliable without explicit constraints. In this paper, we propose MeDUET, a 3D Medical image Disentangled UnifiEd PreTraining framework that performs SSL in the Variational Autoencoder (VAE) latent space which explicitly disentangles domain-invariant content from domain-specific style. The token demixing mechanism serves to turn disentanglement from a modeling assumption into an empirically identifiable property. Two novel proxy tasks, Mixed-Factor Token Distillation (MFTD) and Swap-invariance Quadruplet Contrast (SiQC), are devised to synergistically enhance disentanglement. Once pretrained, MeDUET is capable of (i) delivering higher fidelity, faster convergence, and improved controllability for synthesis, and (ii) demonstrating strong domain generalization and notable label efficiency for analysis across diverse medical benchmarks. In summary, MeDUET converts multi-source heterogeneity from an obstacle into a learning signal, enabling unified pretraining for 3D medical image synthesis and analysis. The code is available at https://github.com/JK-Liu7/MeDUET .","authors":["Junkai Liu","Ling Shao","Le Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16160v2","updated":"2026-02-19T22:36:27Z","published":"2026-02-18T03:18:48Z","title":"Uncertainty-Guided Inference-Time Depth Adaptation for Transformer-Based Visual Tracking","summary":"Transformer-based single-object trackers achieve state-of-the-art accuracy but rely on fixed-depth inference, executing the full encoder--decoder stack for every frame regardless of visual complexity, thereby incurring unnecessary computational cost in long video sequences dominated by temporally coherent frames. We propose UncL-STARK, an architecture-preserving approach that enables dynamic, uncertainty-aware depth adaptation in transformer-based trackers without modifying the underlying network or adding auxiliary heads. The model is fine-tuned to retain predictive robustness at multiple intermediate depths using random-depth training with knowledge distillation, thus enabling safe inference-time truncation. At runtime, we derive a lightweight uncertainty estimate directly from the model's corner localization heatmaps and use it in a feedback-driven policy that selects the encoder and decoder depth for the next frame based on the prediction confidence by exploiting temporal coherence in video. Extensive experiments on GOT-10k and LaSOT demonstrate up to 12% GFLOPs reduction, 8.9% latency reduction, and 10.8% energy savings while maintaining tracking accuracy within 0.2% of the full-depth baseline across both short-term and long-term sequences.","authors":["Patrick Poggi","Divake Kumar","Theja Tulabandhula","Amit Ranjan Trivedi"],"pdf_url":"","comment":"Submitted to IJCNN 2026"},{"id":"http://arxiv.org/abs/2601.19318v2","updated":"2026-02-19T22:28:12Z","published":"2026-01-27T07:57:29Z","title":"Perception-to-Pursuit: Track-Centric Temporal Reasoning for Open-World Drone Detection and Autonomous Chasing","summary":"Autonomous drone pursuit requires not only detecting drones but also predicting their trajectories in a manner that enables kinematically feasible interception. Existing tracking methods optimize for prediction accuracy but ignore pursuit feasibility, resulting in trajectories that are physically impossible to intercept 99.9% of the time. We propose Perception-to-Pursuit (P2P), a track-centric temporal reasoning framework that bridges detection and actionable pursuit planning. Our method represents drone motion as compact 8-dimensional tokens capturing velocity, acceleration, scale, and smoothness, enabling a 12-frame causal transformer to reason about future behavior. We introduce the Intercept Success Rate (ISR) metric to measure pursuit feasibility under realistic interceptor constraints. Evaluated on the Anti-UAV-RGBT dataset with 226 real drone sequences, P2P achieves 28.12 pixel average displacement error and 0.597 ISR, representing a 77% improvement in trajectory prediction and 597x improvement in pursuit feasibility over tracking-only baselines, while maintaining perfect drone classification accuracy (100%). Our work demonstrates that temporal reasoning over motion patterns enables both accurate prediction and actionable pursuit planning.","authors":["Venkatakrishna Reddy Oruganti"],"pdf_url":"","comment":"7 pages, 2 figures, 3 tables, 15 references. Intended for submission to ICCV 2027"},{"id":"http://arxiv.org/abs/2602.17871v1","updated":"2026-02-19T22:07:29Z","published":"2026-02-19T22:07:29Z","title":"Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models","summary":"Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base models, alignment architectures, and training data. However, recent works show that these models trail behind in traditional image classification benchmarks, which test fine-grained visual knowledge. We test a large number of recent VLMs on fine-grained classification benchmarks and identify potential factors in the disconnect between fine-grained knowledge and other vision benchmarks. Through a series of ablation experiments, we find that using a better LLM improves all benchmark scores equally, while a better vision encoder disproportionately improves fine-grained classification performance. Furthermore, we find that the pretraining stage is also vital to fine-grained performance, particularly when the language model weights are unfrozen during pretraining. These insights pave the way for enhancing fine-grained visual understanding and vision-centric capabilities in VLMs.","authors":["Dhruba Ghosh","Yuhui Zhang","Ludwig Schmidt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17869v1","updated":"2026-02-19T22:04:27Z","published":"2026-02-19T22:04:27Z","title":"Learning Compact Video Representations for Efficient Long-form Video Understanding in Large Multimodal Models","summary":"With recent advancements in video backbone architectures, combined with the remarkable achievements of large language models (LLMs), the analysis of long-form videos spanning tens of minutes has become both feasible and increasingly prevalent. However, the inherently redundant nature of video sequences poses significant challenges for contemporary state-of-the-art models. These challenges stem from two primary aspects: 1) efficiently incorporating a larger number of frames within memory constraints, and 2) extracting discriminative information from the vast volume of input data. In this paper, we introduce a novel end-to-end schema for long-form video understanding, which includes an information-density-based adaptive video sampler (AVS) and an autoencoder-based spatiotemporal video compressor (SVC) integrated with a multimodal large language model (MLLM). Our proposed system offers two major advantages: it adaptively and effectively captures essential information from video sequences of varying durations, and it achieves high compression rates while preserving crucial discriminative information. The proposed framework demonstrates promising performance across various benchmarks, excelling in both long-form video understanding tasks and standard video understanding benchmarks. These results underscore the versatility and efficacy of our approach, particularly in managing the complexities of prolonged video sequences.","authors":["Yuxiao Chen","Jue Wang","Zhikang Zhang","Jingru Yi","Xu Zhang","Yang Zou","Zhaowei Cai","Jianbo Yuan","Xinyu Li","Hao Yang","Davide Modolo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17855v1","updated":"2026-02-19T21:41:00Z","published":"2026-02-19T21:41:00Z","title":"TopoGate: Quality-Aware Topology-Stabilized Gated Fusion for Longitudinal Low-Dose CT New-Lesion Prediction","summary":"Longitudinal low-dose CT follow-ups vary in noise, reconstruction kernels, and registration quality. These differences destabilize subtraction images and can trigger false new lesion alarms. We present TopoGate, a lightweight model that combines the follow-up appearance view with the subtraction view and controls their influence through a learned, quality-aware gate. The gate is driven by three case-specific signals: CT appearance quality, registration consistency, and stability of anatomical topology measured with topological metrics. On the NLST--New-Lesion--LongCT cohort comprising 152 pairs from 122 patients, TopoGate improves discrimination and calibration over single-view baselines, achieving an area under the ROC curve of 0.65 with a standard deviation of 0.05 and a Brier score of 0.14. Removing corrupted or low-quality pairs, identified by the quality scores, further increases the area under the ROC curve from 0.62 to 0.68 and reduces the Brier score from 0.14 to 0.12. The gate responds predictably to degradation, placing more weight on appearance when noise grows, which mirrors radiologist practice. The approach is simple, interpretable, and practical for reliable longitudinal LDCT triage.","authors":["Seungik Cho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17854v1","updated":"2026-02-19T21:37:42Z","published":"2026-02-19T21:37:42Z","title":"On the Evaluation Protocol of Gesture Recognition for UAV-based Rescue Operation based on Deep Learning: A Subject-Independence Perspective","summary":"This paper presents a methodological analysis of the gesture-recognition approach proposed by Liu and Szirányi, with a particular focus on the validity of their evaluation protocol. We show that the reported near-perfect accuracy metrics result from a frame-level random train-test split that inevitably mixes samples from the same subjects across both sets, causing severe data leakage. By examining the published confusion matrix, learning curves, and dataset construction, we demonstrate that the evaluation does not measure generalization to unseen individuals. Our findings underscore the importance of subject-independent data partitioning in vision-based gesture-recognition research, especially for applications - such as UAV-human interaction - that require reliable recognition of gestures performed by previously unseen people.","authors":["Domonkos Varga"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17853v1","updated":"2026-02-19T21:36:34Z","published":"2026-02-19T21:36:34Z","title":"Neural Prior Estimation: Learning Class Priors from Latent Representations","summary":"Class imbalance induces systematic bias in deep neural networks by imposing a skewed effective class prior. This work introduces the Neural Prior Estimator (NPE), a framework that learns feature-conditioned log-prior estimates from latent representations. NPE employs one or more Prior Estimation Modules trained jointly with the backbone via a one-way logistic loss. Under the Neural Collapse regime, NPE is analytically shown to recover the class log-prior up to an additive constant, providing a theoretically grounded adaptive signal without requiring explicit class counts or distribution-specific hyperparameters. The learned estimate is incorporated into logit adjustment, forming NPE-LA, a principled mechanism for bias-aware prediction. Experiments on long-tailed CIFAR and imbalanced semantic segmentation benchmarks (STARE, ADE20K) demonstrate consistent improvements, particularly for underrepresented classes. NPE thus offers a lightweight and theoretically justified approach to learned prior estimation and imbalance-aware prediction.","authors":["Masoud Yavari","Payman Moallem"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.03988v2","updated":"2026-02-19T21:32:56Z","published":"2025-11-06T02:19:26Z","title":"Simple 3D Pose Features Support Human and Machine Social Scene Understanding","summary":"Humans effortlessly recognize social interactions from visual input, yet the underlying computations remain unknown, and social interaction recognition challenges even the most advanced deep neural networks (DNNs). Here, we hypothesized that humans rely on 3D visuospatial pose information to make social judgments, and that this information is largely absent from most vision DNNs. To test these hypotheses, we used a novel pose and depth estimation pipeline to automatically extract 3D body joint positions from short video clips. We compared the ability of these body joints to predict human social judgments in the videos with embeddings from over 350 vision DNNs. We found that body joints predicted social judgments better than most DNNs. We then reduced the 3D body joints to an even more compact feature set describing only the 3D position and direction of people in the videos. We found that this minimal 3D feature set, but not its 2D counterpart, was necessary and sufficient to explain the prediction performance of the full set of body joints. These minimal 3D features also predicted the extent to which DNNs aligned with human social judgments and significantly improved their performance on these tasks. Together, these findings demonstrate that human social perception depends on simple, explicit 3D pose information.","authors":["Wenshuo Qin","Leyla Isik"],"pdf_url":"","comment":"28 pages, 6 figures"},{"id":"http://arxiv.org/abs/2502.03738v2","updated":"2026-02-19T21:32:09Z","published":"2025-02-06T03:01:38Z","title":"Scaling Laws in Patchification: An Image Is Worth 50,176 Tokens And More","summary":"Since the introduction of Vision Transformer (ViT), patchification has long been regarded as a de facto image tokenization approach for plain visual architectures. By compressing the spatial size of images, this approach can effectively shorten the token sequence and reduce the computational cost of ViT-like plain architectures. In this work, we aim to thoroughly examine the information loss caused by this patchification-based compressive encoding paradigm and how it affects visual understanding. We conduct extensive patch size scaling experiments and excitedly observe an intriguing scaling law in patchification: the models can consistently benefit from decreased patch sizes and attain improved predictive performance, until it reaches the minimum patch size of 1x1, i.e., pixel tokenization. This conclusion is broadly applicable across different vision tasks, various input scales, and diverse architectures such as ViT and the recent Mamba models. Moreover, as a by-product, we discover that with smaller patches, task-specific decoder heads become less critical for dense prediction. In the experiments, we successfully scale up the visual sequence to an exceptional length of 50,176 tokens, achieving a competitive test accuracy of 84.6% with a base-sized model on the ImageNet-1k benchmark. We hope this study can provide insights and theoretical foundations for future works of building non-compressive vision models. Code is available at https://github.com/wangf3014/Patch_Scaling.","authors":["Feng Wang","Yaodong Yu","Guoyizhe Wei","Wei Shao","Yuyin Zhou","Alan Yuille","Cihang Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.04908v2","updated":"2026-02-19T21:20:28Z","published":"2026-02-04T00:05:21Z","title":"Temporal Pair Consistency for Variance-Reduced Flow Matching","summary":"Continuous-time generative models, such as diffusion models, flow matching, and rectified flow, learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and inefficient sampling. Prior approaches mitigate this via explicit smoothness penalties, trajectory regularization, or modified probability paths and solvers. We introduce Temporal Pair Consistency (TPC), a lightweight variance-reduction principle that couples velocity predictions at paired timesteps along the same probability path, operating entirely at the estimator level without modifying the model architecture, probability path, or solver. We provide a theoretical analysis showing that TPC induces a quadratic, trajectory-coupled regularization that provably reduces gradient variance while preserving the underlying flow-matching objective. Instantiated within flow matching, TPC improves sample quality and efficiency across CIFAR-10 and ImageNet at multiple resolutions, achieving lower FID at identical or lower computational cost than prior methods, and extends seamlessly to modern SOTA-style pipelines with noise-augmented training, score-based denoising, and rectified flow.","authors":["Chika Maduabuchi","Jindong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.17999v2","updated":"2026-02-19T20:52:03Z","published":"2025-10-20T18:25:38Z","title":"Investigating Demographic Bias in Brain MRI Segmentation: A Comparative Study of Deep-Learning and Non-Deep-Learning Methods","summary":"Deep-learning-based segmentation algorithms have substantially advanced the field of medical image analysis, particularly in structural delineations in MRIs. However, an important consideration is the intrinsic bias in the data. Concerns about unfairness, such as performance disparities based on sensitive attributes like race and sex, are increasingly urgent. In this work, we evaluate the results of three different segmentation models (UNesT, nnU-Net, and CoTr) and a traditional atlas-based method (ANTs), applied to segment the left and right nucleus accumbens (NAc) in MRI images. We utilize a dataset including four demographic subgroups: black female, black male, white female, and white male. We employ manually labeled gold-standard segmentations to train and test segmentation models. This study consists of two parts: the first assesses the segmentation performance of models, while the second measures the volumes they produce to evaluate the effects of race, sex, and their interaction. Fairness is quantitatively measured using a metric designed to quantify fairness in segmentation performance. Additionally, linear mixed models analyze the impact of demographic variables on segmentation accuracy and derived volumes. Training on the same race as the test subjects leads to significantly better segmentation accuracy for some models. ANTs and UNesT show notable improvements in segmentation accuracy when trained and tested on race-matched data, unlike nnU-Net, which demonstrates robust performance independent of demographic matching. Finally, we examine sex and race effects on the volume of the NAc using segmentations from the manual rater and from our biased models. Results reveal that the sex effects observed with manual segmentation can also be observed with biased models, whereas the race effects disappear in all but one model.","authors":["Ghazal Danaee","Marc Niethammer","Jarrett Rushmore","Sylvain Bouix"],"pdf_url":"","comment":"17 pages, 2 figures, Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:035"},{"id":"http://arxiv.org/abs/2602.17814v1","updated":"2026-02-19T20:32:25Z","published":"2026-02-19T20:32:25Z","title":"VQPP: Video Query Performance Prediction Benchmark","summary":"Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.","authors":["Adrian Catalin Lutu","Eduard Poesina","Radu Tudor Ionescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17813v1","updated":"2026-02-19T20:29:41Z","published":"2026-02-19T20:29:41Z","title":"Promptable segmentation with region exploration enables minimal-effort expert-level prostate cancer delineation","summary":"Purpose: Accurate segmentation of prostate cancer on magnetic resonance (MR) images is crucial for planning image-guided interventions such as targeted biopsies, cryoablation, and radiotherapy. However, subtle and variable tumour appearances, differences in imaging protocols, and limited expert availability make consistent interpretation difficult. While automated methods aim to address this, they rely on large expertly-annotated datasets that are often inconsistent, whereas manual delineation remains labour-intensive. This work aims to bridge the gap between automated and manual segmentation through a framework driven by user-provided point prompts, enabling accurate segmentation with minimal annotation effort.\n  Methods: The framework combines reinforcement learning (RL) with a region-growing segmentation process guided by user prompts. Starting from an initial point prompt, region-growing generates a preliminary segmentation, which is iteratively refined through RL. At each step, the RL agent observes the image and current segmentation to predict a new point, from which region growing updates the mask. A reward, balancing segmentation accuracy and voxel-wise uncertainty, encourages exploration of ambiguous regions, allowing the agent to escape local optima and perform sample-specific optimisation. Despite requiring fully supervised training, the framework bridges manual and fully automated segmentation at inference by substantially reducing user effort while outperforming current fully automated methods.\n  Results: The framework was evaluated on two public prostate MR datasets (PROMIS and PICAI, with 566 and 1090 cases). It outperformed the previous best automated methods by 9.9% and 8.9%, respectively, with performance comparable to manual radiologist segmentation, reducing annotation time tenfold.","authors":["Junqing Yang","Natasha Thorley","Ahmed Nadeem Abbasi","Shonit Punwani","Zion Tse","Yipeng Hu","Shaheer U. Saeed"],"pdf_url":"","comment":"Accepted at IPCAI 2026 (IJCARS - IPCAI 2026 Special Issue)"},{"id":"http://arxiv.org/abs/2602.17807v1","updated":"2026-02-19T20:14:14Z","published":"2026-02-19T20:14:14Z","title":"VidEoMT: Your ViT is Secretly Also a Video Segmentation Model","summary":"Existing online video segmentation models typically combine a per-frame segmenter with complex specialized tracking modules. While effective, these modules introduce significant architectural complexity and computational overhead. Recent studies suggest that plain Vision Transformer (ViT) encoders, when scaled with sufficient capacity and large-scale pre-training, can conduct accurate image segmentation without requiring specialized modules. Motivated by this observation, we propose the Video Encoder-only Mask Transformer (VidEoMT), a simple encoder-only video segmentation model that eliminates the need for dedicated tracking modules. To enable temporal modeling in an encoder-only ViT, VidEoMT introduces a lightweight query propagation mechanism that carries information across frames by reusing queries from the previous frame. To balance this with adaptability to new content, it employs a query fusion strategy that combines the propagated queries with a set of temporally-agnostic learned queries. As a result, VidEoMT attains the benefits of a tracker without added complexity, achieving competitive accuracy while being 5x--10x faster, running at up to 160 FPS with a ViT-L backbone. Code: https://www.tue-mps.org/videomt/","authors":["Narges Norouzi","Idil Esen Zulfikar","Niccol`o Cavagnero","Tommie Kerssies","Bastian Leibe","Gijs Dubbelman","Daan de Geus"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17799v1","updated":"2026-02-19T20:05:56Z","published":"2026-02-19T20:05:56Z","title":"Enabling Training-Free Text-Based Remote Sensing Segmentation","summary":"Recent advances in Vision Language Models (VLMs) and Vision Foundation Models (VFMs) have opened new opportunities for zero-shot text-guided segmentation of remote sensing imagery. However, most existing approaches still rely on additional trainable components, limiting their generalisation and practical applicability. In this work, we investigate to what extent text-based remote sensing segmentation can be achieved without additional training, by relying solely on existing foundation models. We propose a simple yet effective approach that integrates contrastive and generative VLMs with the Segment Anything Model (SAM), enabling a fully training-free or lightweight LoRA-tuned pipeline. Our contrastive approach employs CLIP as mask selector for SAM's grid-based proposals, achieving state-of-the-art open-vocabulary semantic segmentation (OVSS) in a completely zero-shot setting. In parallel, our generative approach enables reasoning and referring segmentation by generating click prompts for SAM using GPT-5 in a zero-shot setting and a LoRA-tuned Qwen-VL model, with the latter yielding the best results. Extensive experiments across 19 remote sensing benchmarks, including open-vocabulary, referring, and reasoning-based tasks, demonstrate the strong capabilities of our approach. Code will be released at https://github.com/josesosajs/trainfree-rs-segmentation.","authors":["Jose Sosa","Danila Rukhovich","Anis Kacem","Djamila Aouada"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17797v1","updated":"2026-02-19T19:59:39Z","published":"2026-02-19T19:59:39Z","title":"Deep Learning for Dermatology: An Innovative Framework for Approaching Precise Skin Cancer Detection","summary":"Skin cancer can be life-threatening if not diagnosed early, a prevalent yet preventable disease. Globally, skin cancer is perceived among the finest prevailing cancers and millions of people are diagnosed each year. For the allotment of benign and malignant skin spots, an area of critical importance in dermatological diagnostics, the application of two prominent deep learning models, VGG16 and DenseNet201 are investigated by this paper. We evaluate these CNN architectures for their efficacy in differentiating benign from malignant skin lesions leveraging enhancements in deep learning enforced to skin cancer spotting. Our objective is to assess model accuracy and computational efficiency, offering insights into how these models could assist in early detection, diagnosis, and streamlined workflows in dermatology. We used two deep learning methods DenseNet201 and VGG16 model on a binary class dataset containing 3297 images. The best result with an accuracy of 93.79% achieved by DenseNet201. All images were resized to 224x224 by rescaling. Although both models provide excellent accuracy, there is still some room for improvement. In future using new datasets, we tend to improve our work by achieving great accuracy.","authors":["Mohammad Tahmid Noor","B. M. Shahria Alam","Tasmiah Rahman Orpa","Shaila Afroz Anika","Mahjabin Tasnim Samiha","Fahad Ahammed"],"pdf_url":"","comment":"6 pages, 9 figures, this is the author's accepted manuscript of a paper accepted for publication in the Proceedings of the 16th International IEEE Conference on Computing, Communication and Networking Technologies (ICCCNT 2025). The final published version will be available via IEEE Xplore"},{"id":"http://arxiv.org/abs/2602.17793v1","updated":"2026-02-19T19:51:26Z","published":"2026-02-19T19:51:26Z","title":"LGD-Net: Latent-Guided Dual-Stream Network for HER2 Scoring with Task-Specific Domain Knowledge","summary":"It is a critical task to evalaute HER2 expression level accurately for breast cancer evaluation and targeted treatment therapy selection. However, the standard multi-step Immunohistochemistry (IHC) staining is resource-intensive, expensive, and time-consuming, which is also often unavailable in many areas. Consequently, predicting HER2 levels directly from H&E slides has emerged as a potential alternative solution. It has been shown to be effective to use virtual IHC images from H&E images for automatic HER2 scoring. However, the pixel-level virtual staining methods are computationally expensive and prone to reconstruction artifacts that can propagate diagnostic errors. To address these limitations, we propose the Latent-Guided Dual-Stream Network (LGD-Net), a novel framework that employes cross-modal feature hallucination instead of explicit pixel-level image generation. LGD-Net learns to map morphological H&E features directly to the molecular latent space, guided by a teacher IHC encoder during training. To ensure the hallucinated features capture clinically relevant phenotypes, we explicitly regularize the model training with task-specific domain knowledge, specifically nuclei distribution and membrane staining intensity, via lightweight auxiliary regularization tasks. Extensive experiments on the public BCI dataset demonstrate that LGD-Net achieves state-of-the-art performance, significantly outperforming baseline methods while enabling efficient inference using single-modality H&E inputs.","authors":["Peide Zhu","Linbin Lu","Zhiqin Chen","Xiong Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.00288v2","updated":"2026-02-19T19:49:20Z","published":"2026-01-30T20:21:46Z","title":"TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs","summary":"Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .","authors":["Baiqi Li","Kangyi Zhao","Ce Zhang","Chancharik Mitra","Jean de Dieu Nyandwi","Gedas Bertasius"],"pdf_url":"","comment":"For code and data, see https://baiqi-li.github.io/timeblind_project/"},{"id":"http://arxiv.org/abs/2602.17785v1","updated":"2026-02-19T19:38:11Z","published":"2026-02-19T19:38:11Z","title":"Multi-Modal Monocular Endoscopic Depth and Pose Estimation with Edge-Guided Self-Supervision","summary":"Monocular depth and pose estimation play an important role in the development of colonoscopy-assisted navigation, as they enable improved screening by reducing blind spots, minimizing the risk of missed or recurrent lesions, and lowering the likelihood of incomplete examinations. However, this task remains challenging due to the presence of texture-less surfaces, complex illumination patterns, deformation, and a lack of in-vivo datasets with reliable ground truth. In this paper, we propose **PRISM** (Pose-Refinement with Intrinsic Shading and edge Maps), a self-supervised learning framework that leverages anatomical and illumination priors to guide geometric learning. Our approach uniquely incorporates edge detection and luminance decoupling for structural guidance. Specifically, edge maps are derived using a learning-based edge detector (e.g., DexiNed or HED) trained to capture thin and high-frequency boundaries, while luminance decoupling is obtained through an intrinsic decomposition module that separates shading and reflectance, enabling the model to exploit shading cues for depth estimation. Experimental results on multiple real and synthetic datasets demonstrate state-of-the-art performance. We further conduct a thorough ablation study on training data selection to establish best practices for pose and depth estimation in colonoscopy. This analysis yields two practical insights: (1) self-supervised training on real-world data outperforms supervised training on realistic phantom data, underscoring the superiority of domain realism over ground truth availability; and (2) video frame rate is an extremely important factor for model performance, where dataset-specific video frame sampling is necessary for generating high quality training data.","authors":["Xinwei Ju","Rema Daher","Danail Stoyanov","Sophia Bano","Francisco Vasconcelos"],"pdf_url":"","comment":"14 pages, 6 figures; early accepted by IPCAI2026"},{"id":"http://arxiv.org/abs/2412.13897v2","updated":"2026-02-19T19:30:06Z","published":"2024-12-18T14:39:43Z","title":"Data-Efficient Inference of Neural Fluid Fields via SciML Foundation Model","summary":"Recent developments in 3D vision have enabled significant progress in inferring neural fluid fields and realistic rendering of fluid dynamics. However, these methods require dense captures of real-world flows, which demand specialized laboratory setups, making the process costly and challenging. Scientific machine learning (SciML) foundation models, pretrained on extensive simulations of partial differential equations (PDEs), encode rich multiphysics knowledge and thus provide promising sources of domain priors for fluid field inference. Nevertheless, the transferability of these foundation models to real-world vision problems remains largely underexplored. In this work, we demonstrate that SciML foundation models can significantly reduce the data requirements for inferring real-world 3D fluid dynamics while improving generalization. Our method leverages the strong forecasting capabilities and meaningful representations learned by SciML foundation models. We introduce a novel collaborative training strategy that equips neural fluid fields with augmented frames and fluid features extracted from the foundation model. Extensive experiments show substantial improvements in both quantitative metrics and visual quality over prior approaches. In particular, our method achieves a 9-36% improvement in peak signal-to-noise ratio (PSNR) for future prediction while reducing the number of required training frames by 25-50%. These results highlight the practical applicability of SciML foundation models for real-world fluid dynamics reconstruction. Our code is available at: https://github.com/delta-lab-ai/SciML-HY.","authors":["Yuqiu Liu","Jingxuan Xu","Mauricio Soroco","Yunchao Wei","Wuyang Chen"],"pdf_url":"","comment":"Accepted by 3DV 2026"},{"id":"http://arxiv.org/abs/2602.05208v2","updated":"2026-02-19T19:04:02Z","published":"2026-02-05T02:06:26Z","title":"Context-Aware Asymmetric Ensembling for Interpretable Retinopathy of Prematurity Screening via Active Query and Vascular Attention","summary":"Retinopathy of Prematurity (ROP) is among the major causes of preventable childhood blindness. Automated screening remains challenging, primarily due to limited data availability and the complex condition involving both structural staging and microvascular abnormalities. Current deep learning models depend heavily on large private datasets and passive multimodal fusion, which commonly fail to generalize on small, imbalanced public cohorts. We thus propose the Context-Aware Asymmetric Ensemble Model (CAA Ensemble) that simulates clinical reasoning through two specialized streams. First, the Multi-Scale Active Query Network (MS-AQNet) serves as a structure specialist, utilizing clinical contexts as dynamic query vectors to spatially control visual feature extraction for localization of the fibrovascular ridge. Secondly, VascuMIL encodes Vascular Topology Maps (VMAP) within a gated Multiple Instance Learning (MIL) network to precisely identify vascular tortuosity. A synergistic meta-learner ensembles these orthogonal signals to resolve diagnostic discordance across multiple objectives. Tested on a highly imbalanced cohort of 188 infants (6,004 images), the framework attained State-of-the-Art performance on two distinct clinical tasks: achieving a Macro F1-Score of 0.93 for Broad ROP staging and an AUC of 0.996 for Plus Disease detection. Crucially, the system features `Glass Box' transparency through counterfactual attention heatmaps and vascular threat maps, proving that clinical metadata dictates the model's visual search. Additionally, this study demonstrates that architectural inductive bias can serve as an effective bridge for the medical AI data gap.","authors":["Md. Mehedi Hassan","Taufiq Hasan"],"pdf_url":"","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.17770v1","updated":"2026-02-19T19:02:22Z","published":"2026-02-19T19:02:22Z","title":"CLUTCH: Contextualized Language model for Unlocking Text-Conditioned Hand motion modelling in the wild","summary":"Hands play a central role in daily life, yet modeling natural hand motions remains underexplored. Existing methods that tackle text-to-hand-motion generation or hand animation captioning rely on studio-captured datasets with limited actions and contexts, making them costly to scale to \"in-the-wild\" settings. Further, contemporary models and their training schemes struggle to capture animation fidelity with text-motion alignment. To address this, we (1) introduce '3D Hands in the Wild' (3D-HIW), a dataset of 32K 3D hand-motion sequences and aligned text, and (2) propose CLUTCH, an LLM-based hand animation system with two critical innovations: (a) SHIFT, a novel VQ-VAE architecture to tokenize hand motion, and (b) a geometric refinement stage to finetune the LLM. To build 3D-HIW, we propose a data annotation pipeline that combines vision-language models (VLMs) and state-of-the-art 3D hand trackers, and apply it to a large corpus of egocentric action videos covering a wide range of scenarios. To fully capture motion in-the-wild, CLUTCH employs SHIFT, a part-modality decomposed VQ-VAE, which improves generalization and reconstruction fidelity. Finally, to improve animation quality, we introduce a geometric refinement stage, where CLUTCH is co-supervised with a reconstruction loss applied directly to decoded hand motion parameters. Experiments demonstrate state-of-the-art performance on text-to-motion and motion-to-text tasks, establishing the first benchmark for scalable in-the-wild hand motion modelling. Code, data and models will be released.","authors":["Balamurugan Thambiraja","Omid Taheri","Radek Danecek","Giorgio Becherini","Gerard Pons-Moll","Justus Thies"],"pdf_url":"","comment":"ICLR2026; Project page: https://balamuruganthambiraja.github.io/CLUTCH/"},{"id":"http://arxiv.org/abs/2602.17768v1","updated":"2026-02-19T19:01:09Z","published":"2026-02-19T19:01:09Z","title":"KPM-Bench: A Kinematic Parsing Motion Benchmark for Fine-grained Motion-centric Video Understanding","summary":"Despite recent advancements, video captioning models still face significant limitations in accurately describing fine-grained motion details and suffer from severe hallucination issues. These challenges become particularly prominent when generating captions for motion-centric videos, where precise depiction of intricate movements and limb dynamics is crucial yet often neglected. To alleviate this gap, we introduce an automated annotation pipeline that integrates kinematic-based motion computation with linguistic parsing, enabling detailed decomposition and description of complex human motions. Based on this pipeline, we construct and release the Kinematic Parsing Motion Benchmark (KPM-Bench), a novel open-source dataset designed to facilitate fine-grained motion understanding. KPM-Bench consists of (i) fine-grained video-caption pairs that comprehensively illustrate limb-level dynamics in complex actions, (ii) diverse and challenging question-answer pairs focusing specifically on motion understanding, and (iii) a meticulously curated evaluation set specifically designed to assess hallucination phenomena associated with motion descriptions. Furthermore, to address hallucination issues systematically, we propose the linguistically grounded Motion Parsing and Extraction (MoPE) algorithm, capable of accurately extracting motion-specific attributes directly from textual captions. Leveraging MoPE, we introduce a precise hallucination evaluation metric that functions independently of large-scale vision-language or language-only models. By integrating MoPE into the GRPO post-training framework, we effectively mitigate hallucination problems, significantly improving the reliability of motion-centric video captioning models.","authors":["Boda Lin","Yongjie Zhu","Xiaocheng Gong","Wenyu Qin","Meng Wang"],"pdf_url":"","comment":"26 pages"},{"id":"http://arxiv.org/abs/2602.17665v1","updated":"2026-02-19T18:59:54Z","published":"2026-02-19T18:59:54Z","title":"OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents","summary":"Recent progress in multimodal reasoning has enabled agents that can interpret imagery, connect it with language, and perform structured analytical tasks. Extending such capabilities to the remote sensing domain remains challenging, as models must reason over spatial scale, geographic structures, and multispectral indices while maintaining coherent multi-step logic. To bridge this gap, OpenEarthAgent introduces a unified framework for developing tool-augmented geospatial agents trained on satellite imagery, natural-language queries, and detailed reasoning traces. The training pipeline relies on supervised fine-tuning over structured reasoning trajectories, aligning the model with verified multistep tool interactions across diverse analytical contexts. The accompanying corpus comprises 14,538 training and 1,169 evaluation instances, with more than 100K reasoning steps in the training split and over 7K reasoning steps in the evaluation split. It spans urban, environmental, disaster, and infrastructure domains, and incorporates GIS-based operations alongside index analyses such as NDVI, NBR, and NDBI. Grounded in explicit reasoning traces, the learned agent demonstrates structured reasoning, stable spatial understanding, and interpretable behaviour through tool-driven geospatial interactions across diverse conditions. We report consistent improvements over a strong baseline and competitive performance relative to recent open and closed-source models.","authors":["Akashah Shabbir","Muhammad Umer Sheikh","Muhammad Akhtar Munir","Hiyam Debary","Mustansar Fiaz","Muhammad Zaigham Zaheer","Paolo Fraccaro","Fahad Shahbaz Khan","Muhammad Haris Khan","Xiao Xiang Zhu","Salman Khan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17659v1","updated":"2026-02-19T18:59:20Z","published":"2026-02-19T18:59:20Z","title":"When Vision Overrides Language: Evaluating and Mitigating Counterfactual Failures in VLAs","summary":"Vision-Language-Action models (VLAs) promise to ground language instructions in robot control, yet in practice often fail to faithfully follow language. When presented with instructions that lack strong scene-specific supervision, VLAs suffer from counterfactual failures: they act based on vision shortcuts induced by dataset biases, repeatedly executing well-learned behaviors and selecting objects frequently seen during training regardless of language intent. To systematically study it, we introduce LIBERO-CF, the first counterfactual benchmark for VLAs that evaluates language following capability by assigning alternative instructions under visually plausible LIBERO layouts. Our evaluation reveals that counterfactual failures are prevalent yet underexplored across state-of-the-art VLAs. We propose Counterfactual Action Guidance (CAG), a simple yet effective dual-branch inference scheme that explicitly regularizes language conditioning in VLAs. CAG combines a standard VLA policy with a language-unconditioned Vision-Action (VA) module, enabling counterfactual comparison during action selection. This design reduces reliance on visual shortcuts, improves robustness on under-observed tasks, and requires neither additional demonstrations nor modifications to existing architectures or pretrained models. Extensive experiments demonstrate its plug-and-play integration across diverse VLAs and consistent improvements. For example, on LIBERO-CF, CAG improves $π_{0.5}$ by 9.7% in language following accuracy and 3.6% in task success on under-observed tasks using a training-free strategy, with further gains of 15.5% and 8.5%, respectively, when paired with a VA model. In real-world evaluations, CAG reduces counterfactual failures of 9.4% and improves task success by 17.2% on average.","authors":["Yu Fang","Yuchun Feng","Dong Jing","Jiaqi Liu","Yue Yang","Zhenyu Wei","Daniel Szafir","Mingyu Ding"],"pdf_url":"","comment":"Website: https://vla-va.github.io/"},{"id":"http://arxiv.org/abs/2602.17650v1","updated":"2026-02-19T18:56:05Z","published":"2026-02-19T18:56:05Z","title":"Human-level 3D shape perception emerges from multi-view learning","summary":"Humans can infer the three-dimensional structure of objects from two-dimensional visual inputs. Modeling this ability has been a longstanding goal for the science and engineering of visual intelligence, yet decades of computational methods have fallen short of human performance. Here we develop a modeling framework that predicts human 3D shape inferences for arbitrary objects, directly from experimental stimuli. We achieve this with a novel class of neural networks trained using a visual-spatial objective over naturalistic sensory data; given a set of images taken from different locations within a natural scene, these models learn to predict spatial information related to these images, such as camera location and visual depth, without relying on any object-related inductive biases. Notably, these visual-spatial signals are analogous to sensory cues readily available to humans. We design a zero-shot evaluation approach to determine the performance of these `multi-view' models on a well established 3D perception task, then compare model and human behavior. Our modeling framework is the first to match human accuracy on 3D shape inferences, even without task-specific training or fine-tuning. Remarkably, independent readouts of model responses predict fine-grained measures of human behavior, including error patterns and reaction times, revealing a natural correspondence between model dynamics and human perception. Taken together, our findings indicate that human-level 3D perception can emerge from a simple, scalable learning objective over naturalistic visual-spatial data. All code, human behavioral data, and experimental stimuli needed to reproduce our findings can be found on our project page.","authors":["Tyler Bonnen","Jitendra Malik","Angjoo Kanazawa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17645v1","updated":"2026-02-19T18:54:32Z","published":"2026-02-19T18:54:32Z","title":"Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting","summary":"Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we find this induces high-variance, nearly orthogonal gradients across iterations, violating coherent local alignment and destabilizing optimization. We attribute this to (i) ViT translation sensitivity that yields spike-like gradients and (ii) structural asymmetry between source and target crops. We reformulate local matching as an asymmetric expectation over source transformations and target semantics, and build a gradient-denoising upgrade to M-Attack. On the source side, Multi-Crop Alignment (MCA) averages gradients from multiple independently sampled local views per iteration to reduce variance. On the target side, Auxiliary Target Alignment (ATA) replaces aggressive target augmentation with a small auxiliary set from a semantically correlated distribution, producing a smoother, lower-variance target manifold. We further reinterpret momentum as Patch Momentum, replaying historical crop gradients; combined with a refined patch-size ensemble (PE+), this strengthens transferable directions. Together these modules form M-Attack-V2, a simple, modular enhancement over M-Attack that substantially improves transfer-based black-box attacks on frontier LVLMs: boosting success rates on Claude-4.0 from 8% to 30%, Gemini-2.5-Pro from 83% to 97%, and GPT-5 from 98% to 100%, outperforming prior black-box LVLM attacks. Code and data are publicly available at: https://github.com/vila-lab/M-Attack-V2.","authors":["Xiaohan Zhao","Zhaoyi Li","Yaxin Luo","Jiacheng Cui","Zhiqiang Shen"],"pdf_url":"","comment":"Code at: https://github.com/vila-lab/M-Attack-V2"},{"id":"http://arxiv.org/abs/2602.17639v1","updated":"2026-02-19T18:50:53Z","published":"2026-02-19T18:50:53Z","title":"IntRec: Intent-based Retrieval with Contrastive Refinement","summary":"Retrieving user-specified objects from complex scenes remains a challenging task, especially when queries are ambiguous or involve multiple similar objects. Existing open-vocabulary detectors operate in a one-shot manner, lacking the ability to refine predictions based on user feedback. To address this, we propose IntRec, an interactive object retrieval framework that refines predictions based on user feedback. At its core is an Intent State (IS) that maintains dual memory sets for positive anchors (confirmed cues) and negative constraints (rejected hypotheses). A contrastive alignment function ranks candidate objects by maximizing similarity to positive cues while penalizing rejected ones, enabling fine-grained disambiguation in cluttered scenes. Our interactive framework provides substantial improvements in retrieval accuracy without additional supervision. On LVIS, IntRec achieves 35.4 AP, outperforming OVMR, CoDet, and CAKE by +2.3, +3.7, and +0.5, respectively. On the challenging LVIS-Ambiguous benchmark, it improves performance by +7.9 AP over its one-shot baseline after a single corrective feedback, with less than 30 ms of added latency per interaction.","authors":["Pourya Shamsolmoali","Masoumeh Zareapoor","Eric Granger","Yue Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17636v1","updated":"2026-02-19T18:50:12Z","published":"2026-02-19T18:50:12Z","title":"CORAL: Correspondence Alignment for Improved Virtual Try-On","summary":"Existing methods for Virtual Try-On (VTON) often struggle to preserve fine garment details, especially in unpaired settings where accurate person-garment correspondence is required. These methods do not explicitly enforce person-garment alignment and fail to explain how correspondence emerges within Diffusion Transformers (DiTs). In this paper, we first analyze full 3D attention in DiT-based architecture and reveal that the person-garment correspondence critically depends on precise person-garment query-key matching within the full 3D attention. Building on this insight, we then introduce CORrespondence ALignment (CORAL), a DiT-based framework that explicitly aligns query-key matching with robust external correspondences. CORAL integrates two complementary components: a correspondence distillation loss that aligns reliable matches with person-garment attention, and an entropy minimization loss that sharpens the attention distribution. We further propose a VLM-based evaluation protocol to better reflect human preference. CORAL consistently improves over the baseline, enhancing both global shape transfer and local detail preservation. Extensive ablations validate our design choices.","authors":["Jiyoung Kim","Youngjin Shin","Siyoon Jin","Dahyun Chung","Jisu Nam","Tongmin Kim","Jongjae Park","Hyeonwoo Kang","Seungryong Kim"],"pdf_url":"","comment":"32 pages, 25 figures"},{"id":"http://arxiv.org/abs/2602.17605v1","updated":"2026-02-19T18:30:18Z","published":"2026-02-19T18:30:18Z","title":"Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery","summary":"In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tight resource constraints. Yet, sparse and biased geospatial ground truth limits the applicability of existing learning-based methods, such as reinforcement learning. To address this, we propose a unified geospatial discovery framework that integrates active learning, online meta-learning, and concept-guided reasoning. Our approach introduces two key innovations built on a shared notion of *concept relevance*, which captures how domain-specific factors influence target presence: a *concept-weighted uncertainty sampling strategy*, where uncertainty is modulated by learned relevance based on readily-available domain-specific concepts (e.g., land cover, source proximity); and a *relevance-aware meta-batch formation strategy* that promotes semantic diversity during online-meta updates, improving generalization in dynamic environments. Our experiments include testing on a real-world dataset of cancer-causing PFAS (Per- and polyfluoroalkyl substances) contamination, showcasing our method's reliability at uncovering targets with limited data and a varying environment.","authors":["Jowaria Khan","Anindya Sarkar","Yevgeniy Vorobeychik","Elizabeth Bondi-Kelly"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.14974v3","updated":"2026-02-19T18:30:05Z","published":"2025-10-16T17:59:51Z","title":"pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation","summary":"Few-step diffusion or flow-based generative models typically distill a velocity-predicting teacher into a student that predicts a shortcut towards denoised data. This format mismatch has led to complex distillation procedures that often suffer from a quality-diversity trade-off. To address this, we propose policy-based flow models ($π$-Flow). $π$-Flow modifies the output layer of a student flow model to predict a network-free policy at one timestep. The policy then produces dynamic flow velocities at future substeps with negligible overhead, enabling fast and accurate ODE integration on these substeps without extra network evaluations. To match the policy's ODE trajectory to the teacher's, we introduce a novel imitation distillation approach, which matches the policy's velocity to the teacher's along the policy's trajectory using a standard $\\ell_2$ flow matching loss. By simply mimicking the teacher's behavior, $π$-Flow enables stable and scalable training and avoids the quality-diversity trade-off. On ImageNet 256$^2$, it attains a 1-NFE FID of 2.85, outperforming previous 1-NFE models of the same DiT architecture. On FLUX.1-12B and Qwen-Image-20B at 4 NFEs, $π$-Flow achieves substantially better diversity than state-of-the-art DMD models, while maintaining teacher-level quality.","authors":["Hansheng Chen","Kai Zhang","Hao Tan","Leonidas Guibas","Gordon Wetzstein","Sai Bi"],"pdf_url":"","comment":"ICLR 2026. Code: https://github.com/Lakonik/piFlow Demos: https://huggingface.co/spaces/Lakonik/pi-Qwen | https://huggingface.co/spaces/Lakonik/pi-FLUX.1 | https://huggingface.co/spaces/Lakonik/pi-FLUX.2"},{"id":"http://arxiv.org/abs/2511.15943v2","updated":"2026-02-19T18:27:29Z","published":"2025-11-20T00:24:26Z","title":"Boosting Medical Visual Understanding From Multi-Granular Language Learning","summary":"Recent advances in image-text pretraining have significantly enhanced visual understanding by aligning visual and textual representations. Contrastive Language-Image Pretraining (CLIP) has played a pivotal role in multimodal learning. However, its focus on single-label, single-granularity alignment limits its effectiveness in complex domains such as medical imaging, where images often correspond to multiple high-level labels (e.g., disease categories) across different annotation granularities (e.g., diagnostic description, clinical explanation). To address this, we propose Multi-Granular Language Learning (MGLL), a contrastive learning framework designed to improve both multi-label and cross-granularity alignment. MGLL leverages structured multi-label supervision, integrates textual descriptions across granularities, and introduces soft-label supervision with point-wise constraints to enhance alignment. MGLL employs smooth Kullback-Leibler (KL) divergence to ensure cross-granularity consistency while maintaining computational efficiency as a plug-and-play module for vision-language models. Pretrained on our constructed large-scale multi-granular datasets and evaluated across multiple datasets, MGLL outperforms other state-of-the-art methods in downstream tasks. The code is available at https://github.com/HUANGLIZI/MGLL.","authors":["Zihan Li","Yiqing Wang","Sina Farsiu","Paul Kinahan"],"pdf_url":"","comment":"Accepted by ICLR 2026. 40 pages"},{"id":"http://arxiv.org/abs/2602.17599v1","updated":"2026-02-19T18:23:58Z","published":"2026-02-19T18:23:58Z","title":"Art2Mus: Artwork-to-Music Generation via Visual Conditioning and Large-Scale Cross-Modal Alignment","summary":"Music generation has advanced markedly through multimodal deep learning, enabling models to synthesize audio from text and, more recently, from images. However, existing image-conditioned systems suffer from two fundamental limitations: (i) they are typically trained on natural photographs, limiting their ability to capture the richer semantic, stylistic, and cultural content of artworks; and (ii) most rely on an image-to-text conversion stage, using language as a semantic shortcut that simplifies conditioning but prevents direct visual-to-audio learning. Motivated by these gaps, we introduce ArtSound, a large-scale multimodal dataset of 105,884 artwork-music pairs enriched with dual-modality captions, obtained by extending ArtGraph and the Free Music Archive. We further propose ArtToMus, the first framework explicitly designed for direct artwork-to-music generation, which maps digitized artworks to music without image-to-text translation or language-based semantic supervision. The framework projects visual embeddings into the conditioning space of a latent diffusion model, enabling music synthesis guided solely by visual information. Experimental results show that ArtToMus generates musically coherent and stylistically consistent outputs that reflect salient visual cues of the source artworks. While absolute alignment scores remain lower than those of text-conditioned systems-as expected given the substantially increased difficulty of removing linguistic supervision-ArtToMus achieves competitive perceptual quality and meaningful cross-modal correspondence. This work establishes direct visual-to-music generation as a distinct and challenging research direction, and provides resources that support applications in multimedia art, cultural heritage, and AI-assisted creative practice. Code and dataset will be publicly released upon acceptance.","authors":["Ivan Rinaldi","Matteo Mendula","Nicola Fanelli","Florence Levé","Matteo Testi","Giovanna Castellano","Gennaro Vessio"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14879v2","updated":"2026-02-19T18:19:25Z","published":"2026-02-16T16:10:19Z","title":"CT-Bench: A Benchmark for Multimodal Lesion Understanding in Computed Tomography","summary":"Artificial intelligence (AI) can automatically delineate lesions on computed tomography (CT) and generate radiology report content, yet progress is limited by the scarcity of publicly available CT datasets with lesion-level annotations. To bridge this gap, we introduce CT-Bench, a first-of-its-kind benchmark dataset comprising two components: a Lesion Image and Metadata Set containing 20,335 lesions from 7,795 CT studies with bounding boxes, descriptions, and size information, and a multitask visual question answering benchmark with 2,850 QA pairs covering lesion localization, description, size estimation, and attribute categorization. Hard negative examples are included to reflect real-world diagnostic challenges. We evaluate multiple state-of-the-art multimodal models, including vision-language and medical CLIP variants, by comparing their performance to radiologist assessments, demonstrating the value of CT-Bench as a comprehensive benchmark for lesion analysis. Moreover, fine-tuning models on the Lesion Image and Metadata Set yields significant performance gains across both components, underscoring the clinical utility of CT-Bench.","authors":["Qingqing Zhu","Qiao Jin","Tejas S. Mathai","Yin Fang","Zhizheng Wang","Yifan Yang","Maame Sarfo-Gyamfi","Benjamin Hou","Ran Gu","Praveen T. S. Balamuralikrishna","Kenneth C. Wang","Ronald M. Summers","Zhiyong Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.15277v2","updated":"2026-02-19T18:14:28Z","published":"2026-02-17T00:27:58Z","title":"Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization","summary":"Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large scale, they continue to face an efficiency gap: optimization-based decoupling methods achieve higher accuracy but demand intensive computation, whereas optimization-free decoupling methods are efficient but sacrifice accuracy. To overcome this trade-off, we propose Exploration--Exploitation Distillation (E$^2$D), a simple, practical method that minimizes redundant computation through an efficient pipeline that begins with full-image initialization to preserve semantic integrity and feature diversity. It then uses a two-phase optimization strategy: an exploration phase that performs uniform updates and identifies high-loss regions, and an exploitation phase that focuses updates on these regions to accelerate convergence. We evaluate E$^2$D on large-scale benchmarks, surpassing the state-of-the-art on ImageNet-1K while being $18\\times$ faster, and on ImageNet-21K, our method substantially improves accuracy while remaining $4.3\\times$ faster. These results demonstrate that targeted, redundancy-reducing updates, rather than brute-force optimization, bridge the gap between accuracy and efficiency in large-scale dataset distillation. Code is available at https://github.com/ncsu-dk-lab/E2D.","authors":["Muhammad J. Alahmadi","Peng Gao","Feiyi Wang","Dongkuan Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.17526v3","updated":"2026-02-19T17:37:28Z","published":"2025-03-21T20:19:13Z","title":"Beyond the Encoder: Joint Encoder-Decoder Contrastive Pre-Training Improves Dense Prediction","summary":"Contrastive learning methods in self-supervised settings have primarily focused on pre-training encoders, while decoders are typically introduced and trained separately for downstream dense prediction tasks. However, this conventional approach overlooks the potential benefits of jointly pre-training both encoder and decoder. In this paper, we propose DeCon, an efficient encoder-decoder self-supervised learning (SSL) framework that supports joint contrastive pre-training. We first extend existing SSL architectures to accommodate diverse decoders and their corresponding contrastive losses. Then, we introduce a weighted encoder-decoder contrastive loss with non-competing objectives to enable the joint pre-training of encoder-decoder architectures. By adapting a contrastive SSL framework for dense prediction, DeCon establishes consistent state-of-the-art performance on most of the evaluated tasks when pre-trained on Imagenet-1K, COCO and COCO+. Notably, when pre-training a ResNet-50 encoder on COCO dataset, DeCon improves COCO object detection and instance segmentation compared to the baseline framework by +0.37 AP and +0.32 AP, respectively, and boosts semantic segmentation by +1.42 mIoU on Pascal VOC and by +0.50 mIoU on Cityscapes. These improvements generalize across recent backbones, decoders, datasets, and dense tasks beyond segmentation and object detection, and persist in out-of-domain scenarios, including limited-data settings, demonstrating that joint pre-training significantly enhances representation quality for dense prediction. Code is available at https://github.com/sebquetin/DeCon.git.","authors":["Sébastien Quetin","Tapotosh Ghosh","Farhad Maleki"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17573v1","updated":"2026-02-19T17:31:08Z","published":"2026-02-19T17:31:08Z","title":"FR-GESTURE: An RGBD Dataset For Gesture-based Human-Robot Interaction In First Responder Operations","summary":"The ever increasing intensity and number of disasters make even more difficult the work of First Responders (FRs). Artificial intelligence and robotics solutions could facilitate their operations, compensating these difficulties. To this end, we propose a dataset for gesture-based UGV control by FRs, introducing a set of 12 commands, drawing inspiration from existing gestures used by FRs and tactical hand signals and refined after incorporating feedback from experienced FRs. Then we proceed with the data collection itself, resulting in 3312 RGBD pairs captured from 2 viewpoints and 7 distances. To the best of our knowledge, this is the first dataset especially intended for gesture-based UGV guidance by FRs. Finally we define evaluation protocols for our RGBD dataset, termed FR-GESTURE, and we perform baseline experiments, which are put forward for improvement. We have made data publicly available to promote future research on the domain: https://doi.org/10.5281/zenodo.18131333.","authors":["Konstantinos Foteinos","Georgios Angelidis","Aggelos Psiris","Vasileios Argyriou","Panagiotis Sarigiannidis","Georgios Th. Papadopoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17558v1","updated":"2026-02-19T17:11:59Z","published":"2026-02-19T17:11:59Z","title":"RetouchIQ: MLLM Agents for Instruction-Based Image Retouching with Generalist Reward","summary":"Recent advances in multimodal large language models (MLLMs) have shown great potential for extending vision-language reasoning to professional tool-based image editing, enabling intuitive and creative editing. A promising direction is to use reinforcement learning (RL) to enable MLLMs to reason about and execute optimal tool-use plans within professional image-editing software. However, training remains challenging due to the lack of reliable, verifiable reward signals that can reflect the inherently subjective nature of creative editing. In this work, we introduce RetouchIQ, a framework that performs instruction-based executable image editing through MLLM agents guided by a generalist reward model. RetouchIQ interprets user-specified editing intentions and generates corresponding, executable image adjustments, bridging high-level aesthetic goals with precise parameter control. To move beyond conventional, rule-based rewards that compute similarity against a fixed reference image using handcrafted metrics, we propose a generalist reward model, an RL fine-tuned MLLM that evaluates edited results through a set of generated metrics on a case-by-case basis. Then, the reward model provides scalar feedback through multimodal reasoning, enabling reinforcement learning with high-quality, instruction-consistent gradients. We curate an extended dataset with 190k instruction-reasoning pairs and establish a new benchmark for instruction-based image editing. Experiments show that RetouchIQ substantially improves both semantic consistency and perceptual quality over previous MLLM-based and diffusion-based editing systems. Our findings demonstrate the potential of generalist reward-driven MLLM agents as flexible, explainable, and executable assistants for professional image editing.","authors":["Qiucheng Wu","Jing Shi","Simon Jenni","Kushal Kafle","Tianyu Wang","Shiyu Chang","Handong Zhao"],"pdf_url":"","comment":"10 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.17557v1","updated":"2026-02-19T17:11:59Z","published":"2026-02-19T17:11:59Z","title":"Probability-Invariant Random Walk Learning on Gyral Folding-Based Cortical Similarity Networks for Alzheimer's and Lewy Body Dementia Diagnosis","summary":"Alzheimer's disease (AD) and Lewy body dementia (LBD) present overlapping clinical features yet require distinct diagnostic strategies. While neuroimaging-based brain network analysis is promising, atlas-based representations may obscure individualized anatomy. Gyral folding-based networks using three-hinge gyri provide a biologically grounded alternative, but inter-individual variability in cortical folding results in inconsistent landmark correspondence and highly irregular network sizes, violating the fixed-topology and node-alignment assumptions of most existing graph learning methods, particularly in clinical datasets where pathological changes further amplify anatomical heterogeneity. We therefore propose a probability-invariant random-walk-based framework that classifies individualized gyral folding networks without explicit node alignment. Cortical similarity networks are built from local morphometric features and represented by distributions of anonymized random walks, with an anatomy-aware encoding that preserves permutation invariance. Experiments on a large clinical cohort of AD and LBD subjects show consistent improvements over existing gyral folding and atlas-based models, demonstrating robustness and potential for dementia diagnosis.","authors":["Minheng Chen","Jing Zhang","Tong Chen","Chao Cao","Tianming Liu","Li Su","Dajiang Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17556v1","updated":"2026-02-19T17:10:37Z","published":"2026-02-19T17:10:37Z","title":"Neural Implicit Representations for 3D Synthetic Aperture Radar Imaging","summary":"Synthetic aperture radar (SAR) is a tomographic sensor that measures 2D slices of the 3D spatial Fourier transform of the scene. In many operational scenarios, the measured set of 2D slices does not fill the 3D space in the Fourier domain, resulting in significant artifacts in the reconstructed imagery. Traditionally, simple priors, such as sparsity in the image domain, are used to regularize the inverse problem. In this paper, we review our recent work that achieves state-of-the-art results in 3D SAR imaging employing neural structures to model the surface scattering that dominates SAR returns. These neural structures encode the surface of the objects in the form of a signed distance function learned from the sparse scattering data. Since estimating a smooth surface from a sparse and noisy point cloud is an ill-posed problem, we regularize the surface estimation by sampling points from the implicit surface representation during the training step. We demonstrate the model's ability to represent target scattering using measured and simulated data from single vehicles and a larger scene with a large number of vehicles. We conclude with future research directions calling for methods to learn complex-valued neural representations to enable synthesizing new collections from the volumetric neural implicit representation.","authors":["Nithin Sugavanam","Emre Ertin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17555v1","updated":"2026-02-19T17:09:30Z","published":"2026-02-19T17:09:30Z","title":"GraphThinker: Reinforcing Video Reasoning with Event Graph Thinking","summary":"Video reasoning requires understanding the causal relationships between events in a video. However, such relationships are often implicit and costly to annotate manually. While existing multimodal large language models (MLLMs) often infer event relations through dense captions or video summaries for video reasoning, such modeling still lacks causal understanding. Without explicit causal structure modeling within and across video events, these models suffer from hallucinations during the video reasoning. In this work, we propose GraphThinker, a reinforcement finetuning-based method that constructs structural event-level scene graphs and enhances visual grounding to jointly reduce hallucinations in video reasoning. Specifically, we first employ an MLLM to construct an event-based video scene graph (EVSG) that explicitly models both intra- and inter-event relations, and incorporate these formed scene graphs into the MLLM as an intermediate thinking process. We also introduce a visual attention reward during reinforcement finetuning, which strengthens video grounding and further mitigates hallucinations. We evaluate GraphThinker on two datasets, RexTime and VidHalluc, where it shows superior ability to capture object and event relations with more precise event localization, reducing hallucinations in video reasoning compared to prior methods.","authors":["Zixu Cheng","Da Li","Jian Hu","Ziquan Liu","Wei Li","Shaogang Gong"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2602.17535v1","updated":"2026-02-19T16:45:38Z","published":"2026-02-19T16:45:38Z","title":"LATA: Laplacian-Assisted Transductive Adaptation for Conformal Uncertainty in Medical VLMs","summary":"Medical vision-language models (VLMs) are strong zero-shot recognizers for medical imaging, but their reliability under domain shift hinges on calibrated uncertainty with guarantees. Split conformal prediction (SCP) offers finite-sample coverage, yet prediction sets often become large (low efficiency) and class-wise coverage unbalanced-high class-conditioned coverage gap (CCV), especially in few-shot, imbalanced regimes; moreover, naively adapting to calibration labels breaks exchangeability and voids guarantees. We propose \\texttt{\\textbf{LATA}} (Laplacian-Assisted Transductive Adaptation), a \\textit{training- and label-free} refinement that operates on the joint calibration and test pool by smoothing zero-shot probabilities over an image-image k-NN graph using a small number of CCCP mean-field updates, preserving SCP validity via a deterministic transform. We further introduce a \\textit{failure-aware} conformal score that plugs into the vision-language uncertainty (ViLU) framework, providing instance-level difficulty and label plausibility to improve prediction set efficiency and class-wise balance at fixed coverage. \\texttt{\\textbf{LATA}} is black-box (no VLM updates), compute-light (windowed transduction, no backprop), and includes an optional prior knob that can run strictly label-free or, if desired, in a label-informed variant using calibration marginals once. Across \\textbf{three} medical VLMs and \\textbf{nine} downstream tasks, \\texttt{\\textbf{LATA}} consistently reduces set size and CCV while matching or tightening target coverage, outperforming prior transductive baselines and narrowing the gap to label-using methods, while using far less compute. Comprehensive ablations and qualitative analyses show that \\texttt{\\textbf{LATA}} sharpens zero-shot predictions without compromising exchangeability.","authors":["Behzad Bozorgtabar","Dwarikanath Mahapatra","Sudipta Roy","Muzammal Naseer","Imran Razzak","Zongyuan Ge"],"pdf_url":"","comment":"18 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2602.17517v1","updated":"2026-02-19T16:31:14Z","published":"2026-02-19T16:31:14Z","title":"FoundationPose-Initialized 3D-2D Liver Registration for Surgical Augmented Reality","summary":"Augmented reality can improve tumor localization in laparoscopic liver surgery. Existing registration pipelines typically depend on organ contours; deformable (non-rigid) alignment is often handled with finite-element (FE) models coupled to dimensionality-reduction or machine-learning components. We integrate laparoscopic depth maps with a foundation pose estimator for camera-liver pose estimation and replace FE-based deformation with non-rigid iterative closest point (NICP) to lower engineering/modeling complexity and expertise requirements. On real patient data, the depth-augmented foundation pose approach achieved 9.91 mm mean registration error in 3 cases. Combined rigid-NICP registration outperformed rigid-only registration, demonstrating NICP as an efficient substitute for finite-element deformable models. This pipeline achieves clinically relevant accuracy while offering a lightweight, engineering-friendly alternative to FE-based deformation.","authors":["Hanyuan Zhang","Lucas He","Runlong He","Abdolrahim Kadkhodamohammadi","Danail Stoyanov","Brian R. Davidson","Evangelos B. Mazomenos","Matthew J. Clarkson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.02894v2","updated":"2026-02-19T15:56:26Z","published":"2025-10-03T11:00:31Z","title":"PyRadiomics-cuda: 3D features extraction from medical images for HPC using GPU acceleration","summary":"PyRadiomics-cuda is a GPU-accelerated extension of the PyRadiomics library, designed to address the computational challenges of extracting three-dimensional shape features from medical images. By offloading key geometric computations to GPU hardware it dramatically reduces processing times for large volumetric datasets. The system maintains full compatibility with the original PyRadiomics API, enabling seamless integration into existing AI workflows without code modifications. This transparent acceleration facilitates efficient, scalable radiomics analysis, supporting rapid feature extraction essential for high-throughput AI pipeline. Tests performed on a typical computational cluster, budget and home devices prove usefulness in all scenarios.","authors":["Jakub Lisowski","Piotr Tyrakowski","Szymon Zyguła","Krzysztof Kaczmarski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17484v1","updated":"2026-02-19T15:54:55Z","published":"2026-02-19T15:54:55Z","title":"Tracing Copied Pixels and Regularizing Patch Affinity in Copy Detection","summary":"Image Copy Detection (ICD) aims to identify manipulated content between image pairs through robust feature representation learning. While self-supervised learning (SSL) has advanced ICD systems, existing view-level contrastive methods struggle with sophisticated edits due to insufficient fine-grained correspondence learning. We address this limitation by exploiting the inherent geometric traceability in edited content through two key innovations. First, we propose PixTrace - a pixel coordinate tracking module that maintains explicit spatial mappings across editing transformations. Second, we introduce CopyNCE, a geometrically-guided contrastive loss that regularizes patch affinity using overlap ratios derived from PixTrace's verified mappings. Our method bridges pixel-level traceability with patch-level similarity learning, suppressing supervision noise in SSL training. Extensive experiments demonstrate not only state-of-the-art performance (88.7% uAP / 83.9% RP90 for matcher, 72.6% uAP / 68.4% RP90 for descriptor on DISC21 dataset) but also better interpretability over existing methods.","authors":["Yichen Lu","Siwei Nie","Minlong Lu","Xudong Yang","Xiaobo Zhang","Peng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17749v1","updated":"2026-02-19T15:50:46Z","published":"2026-02-19T15:50:46Z","title":"Detection and Classification of Cetacean Echolocation Clicks using Image-based Object Detection Methods applied to Advanced Wavelet-based Transformations","summary":"A challenge in marine bioacoustic analysis is the detection of animal signals, like calls, whistles and clicks, for behavioral studies. Manual labeling is too time-consuming to process sufficient data to get reasonable results. Thus, an automatic solution to overcome the time-consuming data analysis is necessary. Basic mathematical models can detect events in simple environments, but they struggle with complex scenarios, like differentiating signals with a low signal-to-noise ratio or distinguishing clicks from echoes. Deep Learning Neural Networks, such as ANIMAL-SPOT, are better suited for such tasks. DNNs process audio signals as image representations, often using spectrograms created by Short-Time Fourier Transform. However, spectrograms have limitations due to the uncertainty principle, which creates a tradeoff between time and frequency resolution. Alternatives like the wavelet, which provides better time resolution for high frequencies and improved frequency resolution for low frequencies, may offer advantages for feature extraction in complex bioacoustic environments. This thesis shows the efficacy of CLICK-SPOT on Norwegian Killer whale underwater recordings provided by the cetacean biologist Dr. Vester. Keywords: Bioacoustics, Deep Learning, Wavelet Transformation","authors":["Christopher Hauer"],"pdf_url":"","comment":"My Master thesis CLICK-SPOT from 2025"},{"id":"http://arxiv.org/abs/2602.17478v1","updated":"2026-02-19T15:44:41Z","published":"2026-02-19T15:44:41Z","title":"QuPAINT: Physics-Aware Instruction Tuning Approach to Quantum Material Discovery","summary":"Characterizing two-dimensional quantum materials from optical microscopy images is challenging due to the subtle layer-dependent contrast, limited labeled data, and significant variation across laboratories and imaging setups. Existing vision models struggle in this domain since they lack physical priors and cannot generalize to new materials or hardware conditions. This work presents a new physics-aware multimodal framework that addresses these limitations from both the data and model perspectives. We first present Synthia, a physics-based synthetic data generator that simulates realistic optical responses of quantum material flakes under thin-film interference. Synthia produces diverse and high-quality samples, helping reduce the dependence on expert manual annotation. We introduce QMat-Instruct, the first large-scale instruction dataset for quantum materials, comprising multimodal, physics-informed question-answer pairs designed to teach Multimodal Large Language Models (MLLMs) to understand the appearance and thickness of flakes. Then, we propose Physics-Aware Instruction Tuning (QuPAINT), a multimodal architecture that incorporates a Physics-Informed Attention module to fuse visual embeddings with optical priors, enabling more robust and discriminative flake representations. Finally, we establish QF-Bench, a comprehensive benchmark spanning multiple materials, substrates, and imaging settings, offering standardized protocols for fair and reproducible evaluation.","authors":["Xuan-Bac Nguyen","Hoang-Quan Nguyen","Sankalp Pandey","Tim Faltermeier","Nicholas Borys","Hugh Churchill","Khoa Luu"],"pdf_url":"","comment":"Project page: https://uark-cviu.github.io/projects/qupaint/"},{"id":"http://arxiv.org/abs/2602.17473v1","updated":"2026-02-19T15:37:27Z","published":"2026-02-19T15:37:27Z","title":"4D Monocular Surgical Reconstruction under Arbitrary Camera Motions","summary":"Reconstructing deformable surgical scenes from endoscopic videos is challenging and clinically important. Recent state-of-the-art methods based on implicit neural representations or 3D Gaussian splatting have made notable progress. However, most are designed for deformable scenes with fixed endoscope viewpoints and rely on stereo depth priors or accurate structure-from-motion for initialization and optimization, limiting their ability to handle monocular sequences with large camera motion in real clinical settings. To address this, we propose Local-EndoGS, a high-quality 4D reconstruction framework for monocular endoscopic sequences with arbitrary camera motion. Local-EndoGS introduces a progressive, window-based global representation that allocates local deformable scene models to each observed window, enabling scalability to long sequences with substantial motion. To overcome unreliable initialization without stereo depth or accurate structure-from-motion, we design a coarse-to-fine strategy integrating multi-view geometry, cross-window information, and monocular depth priors, providing a robust foundation for optimization. We further incorporate long-range 2D pixel trajectory constraints and physical motion priors to improve deformation plausibility. Experiments on three public endoscopic datasets with deformable scenes and varying camera motions show that Local-EndoGS consistently outperforms state-of-the-art methods in appearance quality and geometry. Ablation studies validate the effectiveness of our key designs. Code will be released upon acceptance at: https://github.com/IRMVLab/Local-EndoGS.","authors":["Jiwei Shan","Zeyu Cai","Cheng-Tai Hsieh","Yirui Li","Hao Liu","Lijun Han","Hesheng Wang","Shing Shin Cheng"],"pdf_url":"","comment":"Due to the limitation \"The abstract field cannot be longer than 1,920 characters\", the abstract here is shorter than that in the PDF file Subjects"},{"id":"http://arxiv.org/abs/2512.19941v5","updated":"2026-02-19T15:35:23Z","published":"2025-12-23T00:18:23Z","title":"Block-Recurrent Dynamics in Vision Transformers","summary":"As Vision Transformers (ViTs) become standard vision backbones, a mechanistic account of their computational phenomenology is essential. Despite architectural cues that hint at dynamical structure, there is no settled framework that interprets Transformer depth as a well-characterized flow. In this work, we introduce the Block-Recurrent Hypothesis (BRH), arguing that trained ViTs admit a block-recurrent depth structure such that the computation of the original $L$ blocks can be accurately rewritten using only $k \\ll L$ distinct blocks applied recurrently. Across diverse ViTs, between-layer representational similarity matrices suggest few contiguous phases. To determine whether these phases reflect genuinely reusable computation, we train block-recurrent surrogates of pretrained ViTs: Recurrent Approximations to Phase-structured TransfORmers (Raptor). In small-scale, we demonstrate that stochastic depth and training promote recurrent structure and subsequently correlate with our ability to accurately fit Raptor. We then provide an empirical existence proof for BRH by training a Raptor model to recover $96\\%$ of DINOv2 ImageNet-1k linear probe accuracy in only 2 blocks at equivalent runtime. Finally, we leverage our hypothesis to develop a program of Dynamical Interpretability. We find i) directional convergence into class-dependent angular basins with self-correcting trajectories under small perturbations, ii) token-specific dynamics, where cls executes sharp late reorientations while patch tokens exhibit strong late-stage coherence toward their mean direction, and iii) a collapse to low rank updates in late depth, consistent with convergence to low-dimensional attractors. Altogether, we find a compact recurrent program emerges along ViT depth, pointing to a low-complexity normative solution that enables these models to be studied through principled dynamical systems analysis.","authors":["Mozes Jacobs","Thomas Fel","Richard Hakim","Alessandra Brondetta","Demba Ba","T. Andy Keller"],"pdf_url":"","comment":"25 pages, 15 figures"},{"id":"http://arxiv.org/abs/2602.17419v1","updated":"2026-02-19T14:50:58Z","published":"2026-02-19T14:50:58Z","title":"EAGLE: Expert-Augmented Attention Guidance for Tuning-Free Industrial Anomaly Detection in Multimodal Large Language Models","summary":"Industrial anomaly detection is important for smart manufacturing, but many deep learning approaches produce only binary decisions and provide limited semantic explanations. Multimodal large language models (MLLMs) can potentially generate fine-grained, language-based analyses, yet existing methods often require costly fine-tuning and do not consistently improve anomaly detection accuracy compared to lightweight specialist detectors. We propose expert-augmented attention guidance for industrial anomaly detection in MLLMs (EAGLE), a tuning-free framework that integrates outputs from expert model to guide MLLMs toward both accurate detection and interpretable anomaly descriptions. We further study how EAGLE affects MLLMs internals by examining the attention distribution of MLLMs to the anomalous image regions in the intermediate layers. We observe that successful anomaly detection is associated with increased attention concentration on anomalous regions, and EAGLE tends to encourage this alignment. Experiments on MVTec-AD and VisA show that EAGLE improves anomaly detection performance across multiple MLLMs without any parameter updates, achieving results comparable to fine-tuning based methods. Code is available at \\href{https://github.com/shengtun/Eagle}{https://github.com/shengtun/Eagle}","authors":["Xiaomeng Peng","Xilang Huang","Seon Han Choi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.11603v3","updated":"2026-02-19T14:38:32Z","published":"2025-08-15T17:13:11Z","title":"CoreEditor: Correspondence-constrained Diffusion for Consistent 3D Editing","summary":"Text-driven 3D editing seeks to modify 3D scenes according to textual descriptions, and most existing approaches tackle this by adapting pre-trained 2D image editors to multi-view inputs. However, without explicit control over multi-view information exchange, they often fail to maintain cross-view consistency, leading to insufficient edits and blurry details. We introduce CoreEditor, a novel framework for consistent text-to-3D editing. The key innovation is a correspondence-constrained attention mechanism that enforces precise interactions between pixels expected to remain consistent throughout the diffusion denoising process. Beyond relying solely on geometric alignment, we further incorporate semantic similarity estimated during denoising, enabling more reliable correspondence modeling and robust multi-view editing. In addition, we design a selective editing pipeline that allows users to choose preferred results from multiple candidates, offering greater flexibility and user control. Extensive experiments show that CoreEditor produces high-quality, 3D-consistent edits with sharper details, significantly outperforming prior methods.","authors":["Zhe Zhu","Honghua Chen","Peng Li","Mingqiang Wei"],"pdf_url":"","comment":"Accepted by IEEE TVCG"},{"id":"http://arxiv.org/abs/2602.17397v1","updated":"2026-02-19T14:26:26Z","published":"2026-02-19T14:26:26Z","title":"A High-Level Survey of Optical Remote Sensing","summary":"In recent years, significant advances in computer vision have also propelled progress in remote sensing. Concurrently, the use of drones has expanded, with many organizations incorporating them into their operations. Most drones are equipped by default with RGB cameras, which are both robust and among the easiest sensors to use and interpret. The body of literature on optical remote sensing is vast, encompassing diverse tasks, capabilities, and methodologies. Each task or methodology could warrant a dedicated survey. This work provides a comprehensive overview of the capabilities of the field, while also presenting key information, such as datasets and insights. It aims to serve as a guide for researchers entering the field, offering high-level insights and helping them focus on areas most relevant to their interests. To the best of our knowledge, no existing survey addresses this holistic perspective.","authors":["Panagiotis Koletsis","Vasilis Efthymiou","Maria Vakalopoulou","Nikos Komodakis","Anastasios Doulamis","Georgios Th. Papadopoulos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17395v1","updated":"2026-02-19T14:18:50Z","published":"2026-02-19T14:18:50Z","title":"SpectralGCD: Spectral Concept Selection and Cross-modal Representation Learning for Generalized Category Discovery","summary":"Generalized Category Discovery (GCD) aims to identify novel categories in unlabeled data while leveraging a small labeled subset of known classes. Training a parametric classifier solely on image features often leads to overfitting to old classes, and recent multimodal approaches improve performance by incorporating textual information. However, they treat modalities independently and incur high computational cost. We propose SpectralGCD, an efficient and effective multimodal approach to GCD that uses CLIP cross-modal image-concept similarities as a unified cross-modal representation. Each image is expressed as a mixture over semantic concepts from a large task-agnostic dictionary, which anchors learning to explicit semantics and reduces reliance on spurious visual cues. To maintain the semantic quality of representations learned by an efficient student, we introduce Spectral Filtering which exploits a cross-modal covariance matrix over the softmaxed similarities measured by a strong teacher model to automatically retain only relevant concepts from the dictionary. Forward and reverse knowledge distillation from the same teacher ensures that the cross-modal representations of the student remain both semantically sufficient and well-aligned. Across six benchmarks, SpectralGCD delivers accuracy comparable to or significantly superior to state-of-the-art methods at a fraction of the computational cost. The code is publicly available at: https://github.com/miccunifi/SpectralGCD.","authors":["Lorenzo Caselli","Marco Mistretta","Simone Magistri","Andrew D. Bagdanov"],"pdf_url":"","comment":"Accepted at ICLR 2026. Code available at https://github.com/miccunifi/SpectralGCD"},{"id":"http://arxiv.org/abs/2602.17387v1","updated":"2026-02-19T14:12:07Z","published":"2026-02-19T14:12:07Z","title":"DRetHTR: Linear-Time Decoder-Only Retentive Network for Handwritten Text Recognition","summary":"State-of-the-art handwritten text recognition (HTR) systems commonly use Transformers, whose growing key-value (KV) cache makes decoding slow and memory-intensive. We introduce DRetHTR, a decoder-only model built on Retentive Networks (RetNet). Compared to an equally sized decoder-only Transformer baseline, DRetHTR delivers 1.6-1.9x faster inference with 38-42% less memory usage, without loss of accuracy. By replacing softmax attention with softmax-free retention and injecting multi-scale sequential priors, DRetHTR avoids a growing KV cache: decoding is linear in output length in both time and memory. To recover the local-to-global inductive bias of attention, we propose layer-wise gamma scaling, which progressively enlarges the effective retention horizon in deeper layers. This encourages early layers to model short-range dependencies and later layers to capture broader context, mitigating the flexibility gap introduced by removing softmax. Consequently, DRetHTR achieves best reported test character error rates of 2.26% (IAM-A, en), 1.81% (RIMES, fr), and 3.46% (Bentham, en), and is competitive on READ-2016 (de) with 4.21%. This demonstrates that decoder-only RetNet enables Transformer-level HTR accuracy with substantially improved decoding speed and memory efficiency.","authors":["Changhun Kim","Martin Mayr","Thomas Gorges","Fei Wu","Mathias Seuret","Andreas Maier","Vincent Christlein"],"pdf_url":"","comment":"Submitted to Pattern Recognition, 11 pages + 2-page appendix, 7 figures, 12 tables"},{"id":"http://arxiv.org/abs/2602.17372v1","updated":"2026-02-19T13:54:35Z","published":"2026-02-19T13:54:35Z","title":"Tree crop mapping of South America reveals links to deforestation and conservation","summary":"Monitoring tree crop expansion is vital for zero-deforestation policies like the European Union's Regulation on Deforestation-free Products (EUDR). However, these efforts are hindered by a lack of highresolution data distinguishing diverse agricultural systems from forests. Here, we present the first 10m-resolution tree crop map for South America, generated using a multi-modal, spatio-temporal deep learning model trained on Sentinel-1 and Sentinel-2 satellite imagery time series. The map identifies approximately 11 million hectares of tree crops, 23% of which is linked to 2000-2020 forest cover loss. Critically, our analysis reveals that existing regulatory maps supporting the EUDR often classify established agriculture, particularly smallholder agroforestry, as \"forest\". This discrepancy risks false deforestation alerts and unfair penalties for small-scale farmers. Our work mitigates this risk by providing a high-resolution baseline, supporting conservation policies that are effective, inclusive, and equitable.","authors":["Yuchang Jiang","Anton Raichuk","Xiaoye Tong","Vivien Sainte Fare Garnot","Daniel Ortiz-Gonzalo","Dan Morris","Konrad Schindler","Jan Dirk Wegner","Maxim Neumann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17353v1","updated":"2026-02-19T13:36:42Z","published":"2026-02-19T13:36:42Z","title":"Application and Evaluation of the Common Circles Method","summary":"We investigate the application of the common circle method for estimating sample motion in optical diffraction tomography (ODT) of sub-millimeter sized biological tissue. When samples are confined via contact-free acoustical force fields, their motion must be estimated from the captured images. The common circle method identifies intersections of Ewald spheres in Fourier space to determine rotational motion. This paper presents a practical implementation, incorporating temporal consistency constraints to achieve stable reconstructions. Our results on both simulated and real-world data demonstrate that the common circle method provides a computationally efficient alternative to full optimization methods for motion detection.","authors":["Michael Quellmalz","Mia Kvåle Løvmo","Simon Moser","Franziska Strasser","Monika Ritsch-Marte"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01224v2","updated":"2026-02-19T13:31:01Z","published":"2026-01-03T16:10:18Z","title":"Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment","summary":"Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes. Code and pretrained models are available at https://github.com/sony/coda.","authors":["Bac Nguyen","Yuhta Takida","Naoki Murata","Chieh-Hsin Lai","Toshimitsu Uesaka","Stefano Ermon","Yuki Mitsufuji"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.17337v1","updated":"2026-02-19T13:08:55Z","published":"2026-02-19T13:08:55Z","title":"Polaffini: A feature-based approach for robust affine and polyaffine image registration","summary":"In this work we present Polaffini, a robust and versatile framework for anatomically grounded registration. Medical image registration is dominated by intensity-based registration methods that rely on surrogate measures of alignment quality. In contrast, feature-based approaches that operate by identifying explicit anatomical correspondences, while more desirable in theory, have largely fallen out of favor due to the challenges of reliably extracting features. However, such challenges are now significantly overcome thanks to recent advances in deep learning, which provide pre-trained segmentation models capable of instantly delivering reliable, fine-grained anatomical delineations. We aim to demonstrate that these advances can be leveraged to create new anatomically-grounded image registration algorithms. To this end, we propose Polaffini, which obtains, from these segmented regions, anatomically grounded feature points with 1-to-1 correspondence in a particularly simple way: extracting their centroids. These enable efficient global and local affine matching via closed-form solutions. Those are used to produce an overall transformation ranging from affine to polyaffine with tunable smoothness. Polyaffine transformations can have many more degrees of freedom than affine ones allowing for finer alignment, and their embedding in the log-Euclidean framework ensures diffeomorphic properties. Polaffini has applications both for standalone registration and as pre-alignment for subsequent non-linear registration, and we evaluate it against popular intensity-based registration techniques. Results demonstrate that Polaffini outperforms competing methods in terms of structural alignment and provides improved initialisation for downstream non-linear registration. Polaffini is fast, robust, and accurate, making it particularly well-suited for integration into medical image processing pipelines.","authors":["Antoine Legouhy","Cosimo Campo","Ross Callaghan","Hojjat Azadbakht","Hui Zhang"],"pdf_url":"","comment":"associated github repo: https://github.com/CIG-UCL/polaffini"},{"id":"http://arxiv.org/abs/2507.23497v2","updated":"2026-02-19T12:57:33Z","published":"2025-07-31T12:33:00Z","title":"Sufficient, Necessary and Complete Causal Explanations in Image Classification","summary":"Existing algorithms for explaining the outputs of image classifiers are based on a variety of approaches and produce explanations that frequently lack formal rigour. On the other hand, logic-based explanations are formally and rigorously defined but their computability relies on strict assumptions about the model that do not hold on image classifiers.\n  In this paper, we show that causal explanations, in addition to being formally and rigorously defined, enjoy the same formal properties as logic-based ones, while still lending themselves to black-box algorithms and being a natural fit for image classifiers. We prove formal properties of causal explanations and their equivalence to logic-based explanations. We demonstrate how to subdivide an image into its sufficient and necessary components. We introduce $δ$-complete explanations, which have a minimum confidence threshold and 1-complete causal explanations, explanations that are classified with the same confidence as the original image.\n  We implement our definitions, and our experimental results demonstrate that different models have different patterns of sufficiency, necessity, and completeness. Our algorithms are efficiently computable, taking on average 6s per image on a ResNet model to compute all types of explanations, and are totally black-box, needing no knowledge of the model, no access to model internals, no access to gradient, nor requiring any properties, such as monotonicity, of the model.","authors":["David A Kelly","Hana Chockler"],"pdf_url":"","comment":"16 pages, appendix included"},{"id":"http://arxiv.org/abs/2509.07825v2","updated":"2026-02-19T12:56:34Z","published":"2025-09-09T15:01:28Z","title":"Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model","summary":"3D object segmentation with Large Language Models (LLMs) has become a prevailing paradigm due to its broad semantics, task flexibility, and strong generalization. However, this paradigm is hindered by representation misalignment: LLMs process high-level semantic tokens, whereas 3D point clouds convey only dense geometric structures. In prior methods, misalignment limits both input and output. At the input stage, dense point patches require heavy pre-alignment, weakening object-level semantics and confusing similar distractors. At the output stage, predictions depend only on dense features without explicit geometric cues, leading to a loss of fine-grained accuracy. To address these limitations, we present the Point Linguist Model (PLM), a general framework that bridges the representation gap between LLMs and dense 3D point clouds without requiring large-scale pre-alignment between 3D-text or 3D-images. Specifically, we introduce Object-centric Discriminative Representation (OcDR), which learns object-centric tokens that capture target semantics and scene relations under a hard negative-aware training objective. This mitigates the misalignment between LLM tokens and 3D points, enhances resilience to distractors, and facilitates semantic-level reasoning within LLMs. For accurate segmentation, we introduce the Geometric Reactivation Decoder (GRD), which predicts masks by combining OcDR tokens carrying LLM-inferred geometry with corresponding dense features, preserving comprehensive dense features throughout the pipeline. Extensive experiments show that PLM achieves significant improvements of +7.3 mIoU on ScanNetv2 and +6.0 mIoU on Multi3DRefer for 3D referring segmentation, with consistent gains across 7 benchmarks spanning 4 different tasks, demonstrating the effectiveness of comprehensive object-centric reasoning for robust 3D understanding.","authors":["Zhuoxu Huang","Mingqi Gao","Jungong Han"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Multimedia (TMM)"},{"id":"http://arxiv.org/abs/2602.17322v1","updated":"2026-02-19T12:39:38Z","published":"2026-02-19T12:39:38Z","title":"Leveraging Contrastive Learning for a Similarity-Guided Tampered Document Data Generation Pipeline","summary":"Detecting tampered text in document images is a challenging task due to data scarcity. To address this, previous work has attempted to generate tampered documents using rule-based methods. However, the resulting documents often suffer from limited variety and poor visual quality, typically leaving highly visible artifacts that are rarely observed in real-world manipulations. This undermines the model's ability to learn robust, generalizable features and results in poor performance on real-world data. Motivated by this discrepancy, we propose a novel method for generating high-quality tampered document images. We first train an auxiliary network to compare text crops, leveraging contrastive learning with a novel strategy for defining positive pairs and their corresponding negatives. We also train a second auxiliary network to evaluate whether a crop tightly encloses the intended characters, without cutting off parts of characters or including parts of adjacent ones. Using a carefully designed generation pipeline that leverages both networks, we introduce a framework capable of producing diverse, high-quality tampered document images. We assess the effectiveness of our data generation pipeline by training multiple models on datasets derived from the same source images, generated using our method and existing approaches, under identical training protocols. Evaluating these models on various open-source datasets shows that our pipeline yields consistent performance improvements across architectures and datasets.","authors":["Mohamed Dhouib","Davide Buscaldi","Sonia Vanier","Aymen Shabou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17321v1","updated":"2026-02-19T12:37:48Z","published":"2026-02-19T12:37:48Z","title":"The Sound of Death: Deep Learning Reveals Vascular Damage from Carotid Ultrasound","summary":"Cardiovascular diseases (CVDs) remain the leading cause of mortality worldwide, yet early risk detection is often limited by available diagnostics. Carotid ultrasound, a non-invasive and widely accessible modality, encodes rich structural and hemodynamic information that is largely untapped. Here, we present a machine learning (ML) framework that extracts clinically meaningful representations of vascular damage (VD) from carotid ultrasound videos, using hypertension as a weak proxy label. The model learns robust features that are biologically plausible, interpretable, and strongly associated with established cardiovascular risk factors, comorbidities, and laboratory measures. High VD stratifies individuals for myocardial infarction, cardiac death, and all-cause mortality, matching or outperforming conventional risk models such as SCORE2. Explainable AI analyses reveal that the model relies on vessel morphology and perivascular tissue characteristics, uncovering novel functional and anatomical signatures of vascular damage. This work demonstrates that routine carotid ultrasound contains far more prognostic information than previously recognized. Our approach provides a scalable, non-invasive, and cost-effective tool for population-wide cardiovascular risk assessment, enabling earlier and more personalized prevention strategies without reliance on laboratory tests or complex clinical inputs.","authors":["Christoph Balada","Aida Romano-Martinez","Payal Varshney","Vincent ten Cate","Katharina Geschke","Jonas Tesarz","Paul Claßen","Alexander K. Schuster","Dativa Tibyampansha","Karl-Patrik Kresoja","Philipp S. Wild","Sheraz Ahmed","Andreas Dengel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17310v1","updated":"2026-02-19T12:19:56Z","published":"2026-02-19T12:19:56Z","title":"Attachment Anchors: A Novel Framework for Laparoscopic Grasping Point Prediction in Colorectal Surgery","summary":"Accurate grasping point prediction is a key challenge for autonomous tissue manipulation in minimally invasive surgery, particularly in complex and variable procedures such as colorectal interventions. Due to their complexity and prolonged duration, colorectal procedures have been underrepresented in current research. At the same time, they pose a particularly interesting learning environment due to repetitive tissue manipulation, making them a promising entry point for autonomous, machine learning-driven support. Therefore, in this work, we introduce attachment anchors, a structured representation that encodes the local geometric and mechanical relationships between tissue and its anatomical attachments in colorectal surgery. This representation reduces uncertainty in grasping point prediction by normalizing surgical scenes into a consistent local reference frame. We demonstrate that attachment anchors can be predicted from laparoscopic images and incorporated into a grasping framework based on machine learning. Experiments on a dataset of 90 colorectal surgeries demonstrate that attachment anchors improve grasping point prediction compared to image-only baselines. There are particularly strong gains in out-of-distribution settings, including unseen procedures and operating surgeons. These results suggest that attachment anchors are an effective intermediate representation for learning-based tissue manipulation in colorectal surgery.","authors":["Dennis N. Schneider","Lars Wagner","Daniel Rueckert","Dirk Wilhelm"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07984v4","updated":"2026-02-19T12:17:06Z","published":"2025-12-08T19:15:08Z","title":"Restrictive Hierarchical Semantic Segmentation for Stratified Tooth Layer Detection","summary":"Accurate understanding of anatomical structures is essential for reliably staging certain dental diseases. A way of introducing this within semantic segmentation models is by utilising hierarchy-aware methodologies. However, existing hierarchy-aware segmentation methods largely encode anatomical structure through the loss functions, providing weak and indirect supervision. We introduce a general framework that embeds an explicit anatomical hierarchy into semantic segmentation by coupling a recurrent, level-wise prediction scheme with restrictive output heads and top-down feature conditioning. At each depth of the class tree, the backbone is re-run on the original image concatenated with logits from the previous level. Child class features are conditioned using Feature-wise Linear Modulation of their parent class probabilities, to modulate child feature spaces for fine grained detection. A probabilistic composition rule enforces consistency between parent and descendant classes. Hierarchical loss combines per-level class weighted Dice and cross entropy loss and a consistency term loss, ensuring parent predictions are the sum of their children. We validate our approach on our proposed dataset, TL-pano, containing 194 panoramic radiographs with dense instance and semantic segmentation annotations, of tooth layers and alveolar bone. Utilising UNet and HRNet as donor models across a 5-fold cross validation scheme, the hierarchical variants consistently increase IoU, Dice, and recall, particularly for fine-grained anatomies, and produce more anatomically coherent masks. However, hierarchical variants also demonstrated increased recall over precision, implying increased false positives. The results demonstrate that explicit hierarchical structuring improves both performance and clinical plausibility, especially in low data dental imaging regimes.","authors":["Ryan Banks","Camila Lindoni Azevedo","Hongying Tang","Yunpeng Li"],"pdf_url":"","comment":"Incorrect initial draft was submitted by mistake. Method, results and citations are incorrect"},{"id":"http://arxiv.org/abs/2504.21730v2","updated":"2026-02-19T12:16:56Z","published":"2025-04-30T15:21:25Z","title":"Cert-SSBD: Certified Backdoor Defense with Sample-Specific Smoothing Noises","summary":"Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an attacker manipulates a small portion of the training data to implant hidden backdoors into the model. The compromised model behaves normally on clean samples but misclassifies backdoored samples into the attacker-specified target class, posing a significant threat to real-world DNN applications. Currently, several empirical defense methods have been proposed to mitigate backdoor attacks, but they are often bypassed by more advanced backdoor techniques. In contrast, certified defenses based on randomized smoothing have shown promise by adding random noise to training and testing samples to counteract backdoor attacks. In this paper, we reveal that existing randomized smoothing defenses implicitly assume that all samples are equidistant from the decision boundary. However, it may not hold in practice, leading to suboptimal certification performance. To address this issue, we propose a sample-specific certified backdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic gradient ascent to optimize the noise magnitude for each sample, ensuring a sample-specific noise level that is then applied to multiple poisoned training sets to retrain several smoothed models. After that, Cert-SSB aggregates the predictions of multiple smoothed models to generate the final robust prediction. In particular, in this case, existing certification methods become inapplicable since the optimized noise varies across different samples. To conquer this challenge, we introduce a storage-update-based certification method, which dynamically adjusts each sample's certification region to improve certification performance. We conduct extensive experiments on multiple benchmark datasets, demonstrating the effectiveness of our proposed method. Our code is available at https://github.com/NcepuQiaoTing/Cert-SSB.","authors":["Ting Qiao","Yingjia Wang","Xing Liu","Sixing Wu","Jianbin Li","Yiming Li"],"pdf_url":"","comment":"To appear in TIFS 2026. 21 pages"},{"id":"http://arxiv.org/abs/2602.11903v2","updated":"2026-02-19T11:40:26Z","published":"2026-02-12T12:56:58Z","title":"Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals","summary":"No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.","authors":["Yu-Chih Chen","Michael Wang","Chieh-Dun Wen","Kai-Siang Ma","Avinab Saha","Li-Heng Chen","Alan Bovik"],"pdf_url":"","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.17277v1","updated":"2026-02-19T11:26:01Z","published":"2026-02-19T11:26:01Z","title":"Physics Encoded Spatial and Temporal Generative Adversarial Network for Tropical Cyclone Image Super-resolution","summary":"High-resolution satellite imagery is indispensable for tracking the genesis, intensification, and trajectory of tropical cyclones (TCs). However, existing deep learning-based super-resolution (SR) methods often treat satellite image sequences as generic videos, neglecting the underlying atmospheric physical laws governing cloud motion. To address this, we propose a Physics Encoded Spatial and Temporal Generative Adversarial Network (PESTGAN) for TC image super-resolution. Specifically, we design a disentangled generator architecture incorporating a PhyCell module, which approximates the vorticity equation via constrained convolutions and encodes the resulting approximate physical dynamics as implicit latent representations to separate physical dynamics from visual textures. Furthermore, a dual-discriminator framework is introduced, employing a temporal discriminator to enforce motion consistency alongside spatial realism. Experiments on the Digital Typhoon dataset for 4$\\times$ upscaling demonstrate that PESTGAN establishes a better performance in structural fidelity and perceptual quality. While maintaining competitive pixel-wise accuracy compared to existing approaches, our method significantly excels in reconstructing meteorologically plausible cloud structures with superior physical fidelity.","authors":["Ruoyi Zhang","Jiawei Yuan","Lujia Ye","Runling Yu","Liling Zhao"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2602.17270v1","updated":"2026-02-19T11:18:12Z","published":"2026-02-19T11:18:12Z","title":"Unified Latents (UL): How to train your latents","summary":"We present Unified Latents (UL), a framework for learning latent representations that are jointly regularized by a diffusion prior and decoded by a diffusion model. By linking the encoder's output noise to the prior's minimum noise level, we obtain a simple training objective that provides a tight upper bound on the latent bitrate. On ImageNet-512, our approach achieves competitive FID of 1.4, with high reconstruction quality (PSNR) while requiring fewer training FLOPs than models trained on Stable Diffusion latents. On Kinetics-600, we set a new state-of-the-art FVD of 1.3.","authors":["Jonathan Heek","Emiel Hoogeboom","Thomas Mensink","Tim Salimans"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.12298v2","updated":"2026-02-19T11:09:47Z","published":"2025-05-18T08:27:12Z","title":"Attention-Enhanced U-Net for Accurate Segmentation of COVID-19 Infected Lung Regions in CT Scans","summary":"In this study, we propose a robust methodology for automatic segmentation of infected lung regions in COVID-19 CT scans using convolutional neural networks. The approach is based on a modified U-Net architecture enhanced with attention mechanisms, data augmentation, and postprocessing techniques. It achieved a Dice coefficient of 0.8658 and mean IoU of 0.8316, outperforming other methods. The dataset was sourced from public repositories and augmented for diversity. Results demonstrate superior segmentation performance. Future work includes expanding the dataset, exploring 3D segmentation, and preparing the model for clinical deployment.","authors":["Amal Lahchim","Lazar Davic"],"pdf_url":"","comment":"14 pages, 9 figures, created using Google Colab and PyTorch. Compares segmentation models for COVID-19 CT data"},{"id":"http://arxiv.org/abs/2602.17260v1","updated":"2026-02-19T11:04:20Z","published":"2026-02-19T11:04:20Z","title":"EA-Swin: An Embedding-Agnostic Swin Transformer for AI-Generated Video Detection","summary":"Recent advances in foundation video generators such as Sora2, Veo3, and other commercial systems have produced highly realistic synthetic videos, exposing the limitations of existing detection methods that rely on shallow embedding trajectories, image-based adaptation, or computationally heavy MLLMs. We propose EA-Swin, an Embedding-Agnostic Swin Transformer that models spatiotemporal dependencies directly on pretrained video embeddings via a factorized windowed attention design, making it compatible with generic ViT-style patch-based encoders. Alongside the model, we construct the EA-Video dataset, a benchmark dataset comprising 130K videos that integrates newly collected samples with curated existing datasets, covering diverse commercial and open-source generators and including unseen-generator splits for rigorous cross-distribution evaluation. Extensive experiments show that EA-Swin achieves 0.97-0.99 accuracy across major generators, outperforming prior SoTA methods (typically 0.8-0.9) by a margin of 5-20%, while maintaining strong generalization to unseen distributions, establishing a scalable and robust solution for modern AI-generated video detection.","authors":["Hung Mai","Loi Dinh","Duc Hai Nguyen","Dat Do","Luong Doan","Khanh Nguyen Quoc","Huan Vu","Phong Ho","Naeem Ul Islam","Tuan Do"],"pdf_url":"","comment":"First preprint"},{"id":"http://arxiv.org/abs/2602.17252v1","updated":"2026-02-19T10:54:32Z","published":"2026-02-19T10:54:32Z","title":"A Multi-modal Detection System for Infrastructure-based Freight Signal Priority","summary":"Freight vehicles approaching signalized intersections require reliable detection and motion estimation to support infrastructure-based Freight Signal Priority (FSP). Accurate and timely perception of vehicle type, position, and speed is essential for enabling effective priority control strategies. This paper presents the design, deployment, and evaluation of an infrastructure-based multi-modal freight vehicle detection system integrating LiDAR and camera sensors. A hybrid sensing architecture is adopted, consisting of an intersection-mounted subsystem and a midblock subsystem, connected via wireless communication for synchronized data transmission. The perception pipeline incorporates both clustering-based and deep learning-based detection methods with Kalman filter tracking to achieve stable real-time performance. LiDAR measurements are registered into geodetic reference frames to support lane-level localization and consistent vehicle tracking. Field evaluations demonstrate that the system can reliably monitor freight vehicle movements at high spatio-temporal resolution. The design and deployment provide practical insights for developing infrastructure-based sensing systems to support FSP applications.","authors":["Ziyan Zhang","Chuheng Wei","Xuanpeng Zhao","Siyan Li","Will Snyder","Mike Stas","Peng Hao","Kanok Boriboonsomsin","Guoyuan Wu"],"pdf_url":"","comment":"12 pages, 15 figures. Accepted at ICTD 2026. Final version to appear in ASCE Proceedings"},{"id":"http://arxiv.org/abs/2602.17250v1","updated":"2026-02-19T10:52:50Z","published":"2026-02-19T10:52:50Z","title":"Inferring Height from Earth Embeddings: First insights using Google AlphaEarth","summary":"This study investigates whether the geospatial and multimodal features encoded in \\textit{Earth Embeddings} can effectively guide deep learning (DL) regression models for regional surface height mapping. In particular, we focused on AlphaEarth Embeddings at 10 m spatial resolution and evaluated their capability to support terrain height inference using a high-quality Digital Surface Model (DSM) as reference. U-Net and U-Net++ architectures were thus employed as lightweight convolutional decoders to assess how well the geospatial information distilled in the embeddings can be translated into accurate surface height estimates. Both architectures achieved strong training performance (both with $R^2 = 0.97$), confirming that the embeddings encode informative and decodable height-related signals. On the test set, performance decreased due to distribution shifts in height frequency between training and testing areas. Nevertheless, U-Net++ shows better generalization ($R^2 = 0.84$, median difference = -2.62 m) compared with the standard U-Net ($R^2 = 0.78$, median difference = -7.22 m), suggesting enhanced robustness to distribution mismatch. While the testing RMSE (approximately 16 m for U-Net++) and residual bias highlight remaining challenges in generalization, strong correlations indicate that the embeddings capture transferable topographic patterns. Overall, the results demonstrate the promising potential of AlphaEarth Embeddings to guide DL-based height mapping workflows, particularly when combined with spatially aware convolutional architectures, while emphasizing the need to address bias for improved regional transferability.","authors":["Alireza Hamoudzadeh","Valeria Belloni","Roberta Ravanelli"],"pdf_url":"","comment":"29 pages, 9 figures"},{"id":"http://arxiv.org/abs/2602.15579v2","updated":"2026-02-19T10:26:31Z","published":"2026-02-17T13:47:27Z","title":"Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning","summary":"Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.","authors":["Amal Lahchim","Lambros Athanasiou"],"pdf_url":"","comment":"12 pages, 8 figures. Research paper from Electrical and Computer Engineering Department, University of Patras"},{"id":"http://arxiv.org/abs/2602.17231v1","updated":"2026-02-19T10:24:02Z","published":"2026-02-19T10:24:02Z","title":"HiMAP: History-aware Map-occupancy Prediction with Fallback","summary":"Accurate motion forecasting is critical for autonomous driving, yet most predictors rely on multi-object tracking (MOT) with identity association, assuming that objects are correctly and continuously tracked. When tracking fails due to, e.g., occlusion, identity switches, or missed detections, prediction quality degrades and safety risks increase. We present \\textbf{HiMAP}, a tracking-free, trajectory prediction framework that remains reliable under MOT failures. HiMAP converts past detections into spatiotemporally invariant historical occupancy maps and introduces a historical query module that conditions on the current agent state to iteratively retrieve agent-specific history from unlabeled occupancy representations. The retrieved history is summarized by a temporal map embedding and, together with the final query and map context, drives a DETR-style decoder to produce multi-modal future trajectories. This design lifts identity reliance, supports streaming inference via reusable encodings, and serves as a robust fallback when tracking is unavailable. On Argoverse~2, HiMAP achieves performance comparable to tracking-based methods while operating without IDs, and it substantially outperforms strong baselines in the no-tracking setting, yielding relative gains of 11\\% in FDE, 12\\% in ADE, and a 4\\% reduction in MR over a fine-tuned QCNet. Beyond aggregate metrics, HiMAP delivers stable forecasts for all agents simultaneously without waiting for tracking to recover, highlighting its practical value for safety-critical autonomy. The code is available under: https://github.com/XuYiMing83/HiMAP.","authors":["Yiming Xu","Yi Yang","Hao Cheng","Monika Sester"],"pdf_url":"","comment":"Accepted in 2026 IEEE International Conference on Robotics and Automation"},{"id":"http://arxiv.org/abs/2511.14654v2","updated":"2026-02-19T10:20:38Z","published":"2025-11-18T16:49:20Z","title":"Improving segmentation of retinal arteries and veins using cardiac signal in doppler holograms","summary":"Doppler holography is an emerging retinal imaging technique that captures the dynamic behavior of blood flow with high temporal resolution, enabling quantitative assessment of retinal hemodynamics. This requires accurate segmentation of retinal arteries and veins, but traditional segmentation methods focus solely on spatial information and overlook the temporal richness of holographic data. In this work, we propose a simple yet effective approach for artery-vein segmentation in temporal Doppler holograms using standard segmentation architectures. By incorporating features derived from a dedicated pulse analysis pipeline, our method allows conventional U-Nets to exploit temporal dynamics and achieve performance comparable to more complex attention- or iteration-based models. These findings demonstrate that time-resolved preprocessing can unlock the full potential of deep learning for Doppler holography, opening new perspectives for quantitative exploration of retinal hemodynamics. The dataset is publicly available at https://huggingface.co/datasets/DigitalHolography/","authors":["Marius Dubosc","Yann Fischer","Zacharie Auray","Nicolas Boutry","Edwin Carlinet","Michael Atlan","Thierry Geraud"],"pdf_url":"","comment":"5 pages, 3 figures, 1 table. Submitted to ISBI2026"},{"id":"http://arxiv.org/abs/2602.12679v2","updated":"2026-02-19T09:50:18Z","published":"2026-02-13T07:20:45Z","title":"Motion Prior Distillation in Time Reversal Sampling for Generative Inbetweening","summary":"Recent progress in image-to-video (I2V) diffusion models has significantly advanced the field of generative inbetweening, which aims to generate semantically plausible frames between two keyframes. In particular, inference-time sampling strategies, which leverage the generative priors of large-scale pre-trained I2V models without additional training, have become increasingly popular. However, existing inference-time sampling, either fusing forward and backward paths in parallel or alternating them sequentially, often suffers from temporal discontinuities and undesirable visual artifacts due to the misalignment between the two generated paths. This is because each path follows the motion prior induced by its own conditioning frame. In this work, we propose Motion Prior Distillation (MPD), a simple yet effective inference-time distillation technique that suppresses bidirectional mismatch by distilling the motion residual of the forward path into the backward path. Our method can deliberately avoid denoising the end-conditioned path which causes the ambiguity of the path, and yield more temporally coherent inbetweening results with the forward motion prior. We not only perform quantitative evaluations on standard benchmarks, but also conduct extensive user studies to demonstrate the effectiveness of our approach in practical scenarios.","authors":["Wooseok Jeon","Seunghyun Shin","Dongmin Shin","Hae-Gon Jeon"],"pdf_url":"","comment":"Accepted at ICLR 2026. Project page: https://vvsjeon.github.io/MPD/"},{"id":"http://arxiv.org/abs/2507.19634v3","updated":"2026-02-19T09:44:55Z","published":"2025-07-25T19:00:51Z","title":"MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks","summary":"Recent advances in large language models have laid the foundation for multimodal LLMs (MLLMs), which unify text, speech, and vision within a single framework. As these models are rapidly evolving toward general-purpose instruction following across diverse and complex tasks, a key frontier is evaluating their crosslingual and multimodal capabilities over both short- and long-form inputs. However, existing benchmarks fall short in evaluating these dimensions jointly: they are often limited to English, mostly focus on a single modality at a time, rely on short-form inputs, or lack human annotations--hindering comprehensive assessment of model performance across languages, modalities, and task complexity. To address these gaps, we introduce MCIF (Multimodal Crosslingual Instruction Following), the first crosslingual human-annotated benchmark based on scientific talks on NLP and beyond. MCIF evaluates instruction following in crosslingual, multimodal settings over different input lengths and spans four macro-tasks: recognition, translation, question answering, and summarization. It covers three core modalities (speech, vision, and text) and four diverse languages (English, German, Italian, and Chinese), fully aligned across all dimensions. This parallel design enables a systematic evaluation of MLLMs' abilities to interpret instructions across languages and effectively integrate multimodal contextual information. Our benchmarking and analysis of 23 models highlight universal challenges across modalities and tasks, indicating substantial room for improvement in future MLLMs development. MCIF is released under CC-BY 4.0 license to promote open research.","authors":["Sara Papi","Maike Züfle","Marco Gaido","Beatrice Savoldi","Danni Liu","Ioannis Douros","Luisa Bentivogli","Jan Niehues"],"pdf_url":"","comment":"Data available at https://huggingface.co/datasets/FBK-MT/MCIF | Evaluation, outputs, and baselines available at https://github.com/hlt-mt/mcif"},{"id":"http://arxiv.org/abs/2602.17200v1","updated":"2026-02-19T09:41:32Z","published":"2026-02-19T09:41:32Z","title":"GASS: Geometry-Aware Spherical Sampling for Disentangled Diversity Enhancement in Text-to-Image Generation","summary":"Despite high semantic alignment, modern text-to-image (T2I) generative models still struggle to synthesize diverse images from a given prompt. This lack of diversity not only restricts user choice, but also risks amplifying societal biases. In this work, we enhance the T2I diversity through a geometric lens. Unlike most existing methods that rely primarily on entropy-based guidance to increase sample dissimilarity, we introduce Geometry-Aware Spherical Sampling (GASS) to enhance diversity by explicitly controlling both prompt-dependent and prompt-independent sources of variation. Specifically, we decompose the diversity measure in CLIP embeddings using two orthogonal directions: the text embedding, which captures semantic variation related to the prompt, and an identified orthogonal direction that captures prompt-independent variation (e.g., backgrounds). Based on this decomposition, GASS increases the geometric projection spread of generated image embeddings along both axes and guides the T2I sampling process via expanded predictions along the generation trajectory. Our experiments on different frozen T2I backbones (U-Net and DiT, diffusion and flow) and benchmarks demonstrate the effectiveness of disentangled diversity enhancement with minimal impact on image fidelity and semantic alignment.","authors":["Ye Zhu","Kaleb S. Newman","Johannes F. Lutzeyer","Adriana Romero-Soriano","Michal Drozdzal","Olga Russakovsky"],"pdf_url":"","comment":"Preprint. Code will be available at https://github.com/L-YeZhu/GASS_T2I"},{"id":"http://arxiv.org/abs/2602.17196v1","updated":"2026-02-19T09:29:43Z","published":"2026-02-19T09:29:43Z","title":"EntropyPrune: Matrix Entropy Guided Visual Token Pruning for Multimodal Large Language Models","summary":"Multimodal large language models (MLLMs) incur substantial inference cost due to the processing of hundreds of visual tokens per image. Although token pruning has proven effective for accelerating inference, determining when and where to prune remains largely heuristic. Existing approaches typically rely on static, empirically selected layers, which limit interpretability and transferability across models. In this work, we introduce a matrix-entropy perspective and identify an \"Entropy Collapse Layer\" (ECL), where the information content of visual representations exhibits a sharp and consistent drop, which provides a principled criterion for selecting the pruning stage. Building on this observation, we propose EntropyPrune, a novel matrix-entropy-guided token pruning framework that quantifies the information value of individual visual tokens and prunes redundant ones without relying on attention maps. Moreover, to enable efficient computation, we exploit the spectral equivalence of dual Gram matrices, reducing the complexity of entropy computation and yielding up to a 64x theoretical speedup. Extensive experiments on diverse multimodal benchmarks demonstrate that EntropyPrune consistently outperforms state-of-the-art pruning methods in both accuracy and efficiency. On LLaVA-1.5-7B, our method achieves a 68.2% reduction in FLOPs while preserving 96.0% of the original performance. Furthermore, EntropyPrune generalizes effectively to high-resolution and video-based models, highlighting the strong robustness and scalability in practical MLLM acceleration. The code will be publicly available at https://github.com/YahongWang1/EntropyPrune.","authors":["Yahong Wang","Juncheng Wu","Zhangkai Ni","Chengmei Yang","Yihang Liu","Longzhen Yang","Yuyin Zhou","Ying Wen","Lianghua He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.13294v2","updated":"2026-02-19T09:24:52Z","published":"2026-02-09T05:46:44Z","title":"VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction","summary":"Evaluating whether Multimodal Large Language Models (MLLMs) genuinely reason about physical dynamics remains challenging. Most existing benchmarks rely on recognition-style protocols such as Visual Question Answering (VQA) and Violation of Expectation (VoE), which can often be answered without committing to an explicit, testable physical hypothesis. We propose VisPhyWorld, an execution-based framework that evaluates physical reasoning by requiring models to generate executable simulator code from visual observations. By producing runnable code, the inferred world representation is directly inspectable, editable, and falsifiable. This separates physical reasoning from rendering. Building on this framework, we introduce VisPhyBench, comprising 209 evaluation scenes derived from 108 physical templates and a systematic protocol that evaluates how well models reconstruct appearance and reproduce physically plausible motion. Our pipeline produces valid reconstructed videos in 97.7% on the benchmark. Experiments show that while state-of-the-art MLLMs achieve strong semantic scene understanding, they struggle to accurately infer physical parameters and to simulate consistent physical dynamics.","authors":["Jiarong Liang","Max Ku","Ka-Hei Hui","Ping Nie","Wenhu Chen"],"pdf_url":"","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2602.17856v1","updated":"2026-02-19T21:42:02Z","published":"2026-02-19T21:42:02Z","title":"Enhancing Scientific Literature Chatbots with Retrieval-Augmented Generation: A Performance Evaluation of Vector and Graph-Based Systems","summary":"This paper investigates the enhancement of scientific literature chatbots through retrieval-augmented generation (RAG), with a focus on evaluating vector- and graph-based retrieval systems. The proposed chatbot leverages both structured (graph) and unstructured (vector) databases to access scientific articles and gray literature, enabling efficient triage of sources according to research objectives. To systematically assess performance, we examine two use-case scenarios: retrieval from a single uploaded document and retrieval from a large-scale corpus. Benchmark test sets were generated using a GPT model, with selected outputs annotated for evaluation. The comparative analysis emphasizes retrieval accuracy and response relevance, providing insight into the strengths and limitations of each approach. The findings demonstrate the potential of hybrid RAG systems to improve accessibility to scientific knowledge and to support evidence-based decision making.","authors":["Hamideh Ghanadian","Amin Kamali","Mohammad Hossein Tekieh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17814v1","updated":"2026-02-19T20:32:25Z","published":"2026-02-19T20:32:25Z","title":"VQPP: Video Query Performance Prediction Benchmark","summary":"Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.","authors":["Adrian Catalin Lutu","Eduard Poesina","Radu Tudor Ionescu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17663v1","updated":"2026-02-19T18:59:44Z","published":"2026-02-19T18:59:44Z","title":"CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts","summary":"HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in multiple languages and time periods. Systems are asked to classify relations of two types - $at$ (\"Has the person ever been at this place?\") and $isAt$ (\"Is the person located at this place around publication time?\") - requiring reasoning over temporal and geographical cues. The lab introduces a three-fold evaluation profile that jointly assesses accuracy, computational efficiency, and domain generalization. By linking relation extraction to large-scale historical data processing, HIPE-2026 aims to support downstream applications in knowledge-graph construction, historical biography reconstruction, and spatial analysis in digital humanities.","authors":["Juri Opitz","Corina Raclé","Emanuela Boros","Andrianos Michail","Matteo Romanello","Maud Ehrmann","Simon Clematide"],"pdf_url":"","comment":"ECIR 2026. CLEF Evaluation Lab. Registration DL: 2026/04/23. Task Homepage at https://hipe-eval.github.io/HIPE-2026/"},{"id":"http://arxiv.org/abs/2602.17654v1","updated":"2026-02-19T18:56:36Z","published":"2026-02-19T18:56:36Z","title":"Mine and Refine: Optimizing Graded Relevance in E-commerce Search Retrieval","summary":"We propose a two-stage \"Mine and Refine\" contrastive training framework for semantic text embeddings to enhance multi-category e-commerce search retrieval. Large scale e-commerce search demands embeddings that generalize to long tail, noisy queries while adhering to scalable supervision compatible with product and policy constraints. A practical challenge is that relevance is often graded: users accept substitutes or complements beyond exact matches, and production systems benefit from clear separation of similarity scores across these relevance strata for stable hybrid blending and thresholding. To obtain scalable policy consistent supervision, we fine-tune a lightweight LLM on human annotations under a three-level relevance guideline and further reduce residual noise via engagement driven auditing. In Stage 1, we train a multilingual Siamese two-tower retriever with a label aware supervised contrastive objective that shapes a robust global semantic space. In Stage 2, we mine hard samples via ANN and re-annotate them with the policy aligned LLM, and introduce a multi-class extension of circle loss that explicitly sharpens similarity boundaries between relevance levels, to further refine and enrich the embedding space. Robustness is additionally improved through additive spelling augmentation and synthetic query generation. Extensive offline evaluations and production A/B tests show that our framework improves retrieval relevance and delivers statistically significant gains in engagement and business impact.","authors":["Jiaqi Xi","Raghav Saboo","Luming Chen","Martin Wang","Sudeep Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17544v1","updated":"2026-02-19T16:59:11Z","published":"2026-02-19T16:59:11Z","title":"Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability","summary":"In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the reasoning process itself. To address this limitation, we introduce two novel measures: reusability and verifiability. We decouple CoT generation from execution using a Thinker-Executor framework. Reusability measures how easily an Executor can reuse the Thinker's CoT. Verifiability measures how frequently an Executor can match the Thinker's answer using the CoT. We evaluated four Thinker models against a committee of ten Executor models across five benchmarks. Our results reveal that reusability and verifiability do not correlate with standard accuracy, exposing a blind spot in current accuracy-based leaderboards for reasoning capability. Surprisingly, we find that CoTs from specialized reasoning models are not consistently more reusable or verifiable than those from general-purpose LLMs like Llama and Gemma.","authors":["Shashank Aggarwal","Ram Vikas Mishra","Amit Awekar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17518v1","updated":"2026-02-19T16:32:34Z","published":"2026-02-19T16:32:34Z","title":"A Picture of Agentic Search","summary":"With automated systems increasingly issuing search queries alongside humans, Information Retrieval (IR) faces a major shift. Yet IR remains human-centred, with systems, evaluation metrics, user models, and datasets designed around human queries and behaviours. Consequently, IR operates under assumptions that no longer hold in practice, with changes to workload volumes, predictability, and querying behaviours. This misalignment affects system performance and optimisation: caching may lose effectiveness, query pre-processing may add overhead without improving results, and standard metrics may mismeasure satisfaction. Without adaptation, retrieval models risk satisfying neither humans, nor the emerging user segment of agents. However, datasets capturing agent search behaviour are lacking, which is a critical gap given IR's historical reliance on data-driven evaluation and optimisation. We develop a methodology for collecting all the data produced and consumed by agentic retrieval-augmented systems when answering queries, and we release the Agentic Search Queryset (ASQ) dataset. ASQ contains reasoning-induced queries, retrieved documents, and thoughts for queries in HotpotQA, Researchy Questions, and MS MARCO, for 3 diverse agents and 2 retrieval pipelines. The accompanying toolkit enables ASQ to be extended to new agents, retrievers, and datasets.","authors":["Francesca Pezzuti","Ophir Frieder","Fabrizio Silvestri","Sean MacAvaney","Nicola Tonellotto"],"pdf_url":"","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.17450v1","updated":"2026-02-19T15:14:54Z","published":"2026-02-19T15:14:54Z","title":"Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research","summary":"Web research and practices have evolved significantly over time, offering users diverse and accessible solutions across a wide range of tasks. While advanced concepts such as Web 4.0 have emerged from mature technologies, the introduction of large language models (LLMs) has profoundly influenced both the field and its applications. This wave of LLMs has permeated science and technology so deeply that no area remains untouched. Consequently, LLMs are reshaping web research and development, transforming traditional pipelines into generative solutions for tasks like information retrieval, question answering, recommendation systems, and web analytics. They have also enabled new applications such as web-based summarization and educational tools. This survey explores recent advances in the impact of LLMs-particularly through the use of retrieval-augmented generation (RAG)-on web research and industry. It discusses key developments, open challenges, and future directions for enhancing web solutions with LLMs.","authors":["Amirereza Abbasi","Mohsen Hooshmand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17442v1","updated":"2026-02-19T15:09:04Z","published":"2026-02-19T15:09:04Z","title":"WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation","summary":"Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly transition from local execution to distributed training and optimization. The framework enforces ecological responsibility by integrating CodeCarbon for real-time energy tracking, showing that scalability need not come at the cost of scientific integrity or sustainability. Furthermore, WarpRec anticipates the shift toward Agentic AI, leading Recommender Systems to evolve from static ranking engines into interactive tools within the Generative AI ecosystem. In summary, WarpRec not only bridges the gap between academia and industry but also can serve as the architectural backbone for the next generation of sustainable, agent-ready Recommender Systems. Code is available at https://github.com/sisinflab/warprec/","authors":["Marco Avolio","Potito Aghilar","Sabino Roccotelli","Vito Walter Anelli","Chiara Mallamaci","Vincenzo Paparella","Marco Valentini","Alejandro Bellogín","Michelantonio Trizio","Joseph Trotta","Antonio Ferrara","Tommaso Di Noia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17410v1","updated":"2026-02-19T14:37:43Z","published":"2026-02-19T14:37:43Z","title":"Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers","summary":"Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequence-level, offline-generated negatives, making them less discriminative and informative when adapting LLMs to recommendation tasks with large negative item spaces. To address these challenges, we propose ILRec, a novel preference fine-tuning framework for LLM-based recommendation, leveraging self-hard negative signals extracted from intermediate layers to improve preference learning. Specifically, we identify self-hard negative tokens from intermediate layers as fine-grained negative supervision that dynamically reflects the model's preference learning process. To effectively integrate these signals into training, we design a two-stage framework comprising cross-layer preference optimization and cross-layer preference distillation, enabling the model to jointly discriminate informative negatives and enhance the quality of negative signals from intermediate layers. In addition, we introduce a lightweight collaborative filtering model to assign token-level rewards for negative signals, mitigating the risk of over-penalizing false negatives. Extensive experiments on three datasets demonstrate ILRec's effectiveness in enhancing the performance of LLM-based recommender systems.","authors":["Bingqian Li","Bowen Zheng","Xiaolei Wang","Long Zhang","Jinpeng Wang","Sheng Chen","Wayne Xin Zhao","Ji-rong Wen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17386v1","updated":"2026-02-19T14:10:55Z","published":"2026-02-19T14:10:55Z","title":"Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval","summary":"Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve complex relationships, object compositions, or precise constraints such as identities, counts and proportions often remain unresolved or unreliable within current frameworks. In this paper, we propose a novel framework that integrates formal verification into deep learning-based image retrieval through a synergistic combination of graph-based verification methods and neural code generation. Our approach aims to support open-vocabulary natural language queries while producing results that are both trustworthy and verifiable. By grounding retrieval results in a system of formal reasoning, we move beyond the ambiguity and approximation that often characterize vector representations. Instead of accepting uncertainty as a given, our framework explicitly verifies each atomic truth in the user query against the retrieved content. This allows us to not only return matching results, but also to identify and mark which specific constraints are satisfied and which remain unmet, thereby offering a more transparent and accountable retrieval process while boosting the results of the most popular embedding-based approaches.","authors":["Adrià Molina","Oriol Ramos Terrades","Josep Lladós"],"pdf_url":"","comment":"Submitted for ICPR Review"},{"id":"http://arxiv.org/abs/2602.17354v1","updated":"2026-02-19T13:37:03Z","published":"2026-02-19T13:37:03Z","title":"Training-free Graph-based Imputation of Missing Modalities in Multimodal Recommendation","summary":"Multimodal recommender systems (RSs) represent items in the catalog through multimodal data (e.g., product images and descriptions) that, in some cases, might be noisy or (even worse) missing. In those scenarios, the common practice is to drop items with missing modalities and train the multimodal RSs on a subsample of the original dataset. To date, the problem of missing modalities in multimodal recommendation has still received limited attention in the literature, lacking a precise formalisation as done with missing information in traditional machine learning. In this work, we first provide a problem formalisation for missing modalities in multimodal recommendation. Second, by leveraging the user-item graph structure, we re-cast the problem of missing multimodal information as a problem of graph features interpolation on the item-item co-purchase graph. On this basis, we propose four training-free approaches that propagate the available multimodal features throughout the item-item graph to impute the missing features. Extensive experiments on popular multimodal recommendation datasets demonstrate that our solutions can be seamlessly plugged into any existing multimodal RS and benchmarking framework while still preserving (or even widen) the performance gap between multimodal and traditional RSs. Moreover, we show that our graph-based techniques can perform better than traditional imputations in machine learning under different missing modalities settings. Finally, we analyse (for the first time in multimodal RSs) how feature homophily calculated on the item-item graph can influence our graph-based imputations.","authors":["Daniele Malitesta","Emanuele Rossi","Claudio Pomo","Tommaso Di Noia","Fragkiskos D. Malliaros"],"pdf_url":"","comment":"Accepted in IEEE Transactions on Knowledge and Data Engineering (IEEE TKDE)"},{"id":"http://arxiv.org/abs/2602.17327v1","updated":"2026-02-19T12:45:58Z","published":"2026-02-19T12:45:58Z","title":"WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval","summary":"We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it the largest FAQ-based resource. Unlike the original release, WebFAQ 2.0 uses a novel data collection strategy that directly crawls and extracts relevant web content, resulting in a substantially more diverse and multilingual dataset with richer context through page titles and descriptions. In response to community feedback, we also release a hard negatives dataset for training dense retrievers, with 1.25M queries across 20 languages. These hard negatives were mined using a two-stage retrieval pipeline and include cross-encoder scores for 200 negatives per query. We further show how this resource enables two primary fine-tuning strategies for dense retrievers: Contrastive Learning with MultipleNegativesRanking loss, and Knowledge Distillation with MarginMSE loss. WebFAQ 2.0 is not a static resource but part of a long-term effort. Since late 2025, structured FAQs are being regularly released through the Open Web Index, enabling continuous expansion and refinement. We publish the datasets and training scripts to facilitate further research in multilingual and cross-lingual IR. The dataset itself and all related resources are publicly available on GitHub and HuggingFace.","authors":["Michael Dinzinger","Laura Caspari","Ali Salman","Irvin Topi","Jelena Mitrović","Michael Granitzer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17264v1","updated":"2026-02-19T11:10:11Z","published":"2026-02-19T11:10:11Z","title":"On the Reliability of User-Centric Evaluation of Conversational Recommender Systems","summary":"User-centric evaluation has become a key paradigm for assessing Conversational Recommender Systems (CRS), aiming to capture subjective qualities such as satisfaction, trust, and rapport. To enable scalable evaluation, recent work increasingly relies on third-party annotations of static dialogue logs by crowd workers or large language models. However, the reliability of this practice remains largely unexamined. In this paper, we present a large-scale empirical study investigating the reliability and structure of user-centric CRS evaluation on static dialogue transcripts. We collected 1,053 annotations from 124 crowd workers on 200 ReDial dialogues using the 18-dimensional CRS-Que framework. Using random-effects reliability models and correlation analysis, we quantify the stability of individual dimensions and their interdependencies. Our results show that utilitarian and outcome-oriented dimensions such as accuracy, usefulness, and satisfaction achieve moderate reliability under aggregation, whereas socially grounded constructs such as humanness and rapport are substantially less reliable. Furthermore, many dimensions collapse into a single global quality signal, revealing a strong halo effect in third-party judgments. These findings challenge the validity of single-annotator and LLM-based evaluation protocols and motivate the need for multi-rater aggregation and dimension reduction in offline CRS evaluation.","authors":["Michael Müller","Amir Reza Mohammadi","Andreas Peintner","Beatriz Barroso Gstrein","Günther Specht","Eva Zangerle"],"pdf_url":"","comment":"5 pages, 2 figures. Submitted to UMAP 2026. Code available at https://github.com/michael-mue/reliable-crs-eval"},{"id":"http://arxiv.org/abs/2212.06543v3","updated":"2026-02-19T10:34:27Z","published":"2022-12-13T12:56:55Z","title":"Improving Stance Detection by Leveraging Measurement Knowledge from Social Sciences: A Case Study of Dutch Political Tweets and Traditional Gender Role Division","summary":"Stance detection concerns automatically determining the viewpoint (i.e., in favour of, against, or neutral) of a text's author towards a target. Stance detection has been applied to many research topics, among which the detection of stances behind political tweets is an important one. In this paper, we apply stance detection to a dataset of tweets from official party accounts in the Netherlands between 2017 and 2021, with a focus on stances towards traditional gender role division, a dividing issue between (some) Dutch political parties. To implement and improve stance detection of traditional gender role division, we propose to leverage an established survey instrument from social sciences, which has been validated for the purpose of measuring attitudes towards traditional gender role division. Based on our experiments, we show that using such a validated survey instrument helps to improve stance detection performance.","authors":["Qixiang Fang","Anastasia Giachanou","Ayoub Bagheri"],"pdf_url":"","comment":"Published in BNAIC 2024"},{"id":"http://arxiv.org/abs/2602.17170v1","updated":"2026-02-19T08:37:21Z","published":"2026-02-19T08:37:21Z","title":"When LLM Judges Inflate Scores: Exploring Overrating in Relevance Assessment","summary":"Human relevance assessment is time-consuming and cognitively intensive, limiting the scalability of Information Retrieval evaluation. This has led to growing interest in using large language models (LLMs) as proxies for human judges. However, it remains an open question whether LLM-based relevance judgments are reliable, stable, and rigorous enough to match humans for relevance assessment. In this work, we conduct a systematic study of overrating behavior in LLM-based relevance judgments across model backbones, evaluation paradigms (pointwise and pairwise), and passage modification strategies. We show that models consistently assign inflated relevance scores -- often with high confidence -- to passages that do not genuinely satisfy the underlying information need, revealing a system-wide bias rather than random fluctuations in judgment. Furthermore, controlled experiments show that LLM-based relevance judgments can be highly sensitive to passage length and surface-level lexical cues. These results raise concerns about the usage of LLMs as drop-in replacements for human relevance assessors, and highlight the urgent need for careful diagnostic evaluation frameworks when applying LLMs for relevance assessments. Our code and results are publicly available.","authors":["Chuting Yu","Hang Li","Joel Mackenzie","Teerapong Leelanupab"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17099v1","updated":"2026-02-19T05:50:34Z","published":"2026-02-19T05:50:34Z","title":"Multiple Index Merge for Approximate Nearest Neighbor Search","summary":"Approximate $k$ nearest neighbor (AKNN) search in high-dimensional space is a foundational problem in vector databases with widespread applications. Among the numerous AKNN indexes, Proximity Graph-based indexes achieve state-of-the-art search efficiency across various benchmarks. However, their extensive distance computations of high-dimensional vectors lead to slow construction and substantial memory overhead. The limited memory capacity often prevents building the entire index at once when handling large-scale datasets. A common practice is to build multiple sub-indexes separately. However, directly searching on these separated indexes severely compromises search efficiency, as queries cannot leverage cross-graph connections. Therefore, efficient graph index merging is crucial for multi-index searching. In this paper, we focus on efficient two-index merging and the merge order of multiple indexes for AKNN search. To achieve this, we propose a reverse neighbor sliding merge (RNSM) that exploits structural information to boost merging efficiency. We further investigate merge order selection (MOS) to reduce the merging cost by eliminating redundant merge operations. Experiments show that our approach yields up to a 5.48$\\times$ speedup over existing index merge methods and 9.92$\\times$ speedup over index reconstruction, while maintaining expected superior search performance. Moreover, our method scales efficiently to 100 million vectors with 50 partitions, maintaining consistent speedups.","authors":["Liuchang Jing","Mingyu Yang","Lei Li","Jianbin Qin","Wei Wang"],"pdf_url":"","comment":"technical report"},{"id":"http://arxiv.org/abs/2602.17058v1","updated":"2026-02-19T04:01:01Z","published":"2026-02-19T04:01:01Z","title":"A Long-term Value Prediction Framework In Video Ranking","summary":"Accurately modeling long-term value (LTV) at the ranking stage of short-video recommendation remains challenging. While delayed feedback and extended engagement have been explored, fine-grained attribution and robust position normalization at billion-scale are still underdeveloped. We propose a practical ranking-stage LTV framework addressing three challenges: position bias, attribution ambiguity, and temporal limitations.\n  (1) Position bias: We introduce a Position-aware Debias Quantile (PDQ) module that normalizes engagement via quantile-based distributions, enabling position-robust LTV estimation without architectural changes. (2) Attribution ambiguity: We propose a multi-dimensional attribution module that learns continuous attribution strengths across contextual, behavioral, and content signals, replacing static rules to capture nuanced inter-video influence. A customized hybrid loss with explicit noise filtering improves causal clarity. (3) Temporal limitations: We present a cross-temporal author modeling module that builds censoring-aware, day-level LTV targets to capture creator-driven re-engagement over longer horizons; the design is extensible to other dimensions (e.g., topics, styles).\n  Offline studies and online A/B tests show significant improvements in LTV metrics and stable trade-offs with short-term objectives. Implemented as task augmentation within an existing ranking model, the framework supports efficient training and serving, and has been deployed at billion-scale in Taobao's production system, delivering sustained engagement gains while remaining compatible with industrial constraints.","authors":["Huabin Chen","Xinao Wang","Huiping Chu","Keqin Xu","Chenhao Zhai","Chenyi Wang","Kai Meng","Yuning Jiang"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2602.17036v1","updated":"2026-02-19T03:14:43Z","published":"2026-02-19T03:14:43Z","title":"LiveGraph: Active-Structure Neural Re-ranking for Exercise Recommendation","summary":"The continuous expansion of digital learning environments has catalyzed the demand for intelligent systems capable of providing personalized educational content. While current exercise recommendation frameworks have made significant strides, they frequently encounter obstacles regarding the long-tailed distribution of student engagement and the failure to adapt to idiosyncratic learning trajectories. We present LiveGraph, a novel active-structure neural re-ranking framework designed to overcome these limitations. Our approach utilizes a graph-based representation enhancement strategy to bridge the information gap between active and inactive students while integrating a dynamic re-ranking mechanism to foster content diversity. By prioritizing the structural relationships within learning histories, the proposed model effectively balances recommendation precision with pedagogical variety. Comprehensive experimental evaluations conducted on multiple real-world datasets demonstrate that LiveGraph surpasses contemporary baselines in both predictive accuracy and the breadth of exercise diversity.","authors":["Rong Fu","Zijian Zhang","Haiyun Wei","Jiekai Wu","Kun Liu","Xianda Li","Haoyu Zhao","Yang Li","Yongtai Liu","Ziming Wang","Rui Lu","Simon Fong"],"pdf_url":"","comment":"19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2510.08886v2","updated":"2026-02-19T01:55:14Z","published":"2025-10-10T00:41:55Z","title":"FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs","summary":"Going beyond simple text processing, financial auditing requires detecting semantic, structural, and numerical inconsistencies across large-scale disclosures. As financial reports are filed in XBRL, a structured XML format governed by accounting standards, auditing becomes a structured information extraction and reasoning problem involving concept alignment, taxonomy-defined relations, and cross-document consistency. Although large language models (LLMs) show promise on isolated financial tasks, their capability in professional-grade auditing remains unclear. We introduce FinAuditing, a taxonomy-aligned, structure-aware benchmark built from real XBRL filings. It contains 1,102 annotated instances averaging over 33k tokens and defines three tasks: Financial Semantic Matching (FinSM), Financial Relationship Extraction (FinRE), and Financial Mathematical Reasoning (FinMR). Evaluations of 13 state-of-the-art LLMs reveal substantial gaps in concept retrieval, taxonomy-aware relation modeling, and consistent cross-document reasoning. These findings highlight the need for realistic, structure-aware benchmarks. We release the evaluation code at https://github.com/The-FinAI/FinAuditing and the dataset at https://huggingface.co/collections/TheFinAI/finauditing. The task currently serves as the official benchmark of an ongoing public evaluation contest at https://open-finance-lab.github.io/SecureFinAI_Contest_2026/.","authors":["Yan Wang","Keyi Wang","Shanshan Yang","Jaisal Patel","Jeff Zhao","Fengran Mo","Xueqing Peng","Lingfei Qian","Jimin Huang","Guojun Xiong","Yankai Chen","Víctor Gutiérrez-Basulto","Xiao-Yang Liu","Xue Liu","Jian-Yun Nie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16989v1","updated":"2026-02-19T01:28:18Z","published":"2026-02-19T01:28:18Z","title":"WSDM Cup 2026 Multilingual Retrieval: A Low-Cost Multi-Stage Retrieval Pipeline","summary":"We present a low-cost retrieval system for the WSDM Cup 2026 multilingual retrieval task, where English queries are used to retrieve relevant documents from a collection of approximately ten million news articles in Chinese, Persian, and Russian, and to output the top-1000 ranked results for each query. We follow a four-stage pipeline that combines LLM-based GRF-style query expansion with BM25 candidate retrieval, dense ranking using long-text representations from jina-embeddings-v4, and pointwise re-ranking of the top-20 candidates using Qwen3-Reranker-4B while preserving the dense order for the remaining results. On the official evaluation, the system achieves nDCG@20 of 0.403 and Judged@20 of 0.95. We further conduct extensive ablation experiments to quantify the contribution of each stage and to analyze the effectiveness of query expansion, dense ranking, and top-$k$ reranking under limited compute budgets.","authors":["Chentong Hao","Minmao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16974v1","updated":"2026-02-19T00:27:15Z","published":"2026-02-19T00:27:15Z","title":"Beyond Chunk-Then-Embed: A Comprehensive Taxonomy and Evaluation of Document Chunking Strategies for Information Retrieval","summary":"Document chunking is a critical preprocessing step in dense retrieval systems, yet the design space of chunking strategies remains poorly understood. Recent research has proposed several concurrent approaches, including LLM-guided methods (e.g., DenseX and LumberChunker) and contextualized strategies(e.g., Late Chunking), which generate embeddings before segmentation to preserve contextual information. However, these methods emerged independently and were evaluated on benchmarks with minimal overlap, making direct comparisons difficult.\n  This paper reproduces prior studies in document chunking and presents a systematic framework that unifies existing strategies along two key dimensions: (1) segmentation methods, including structure-based methods (fixed-size, sentence-based, and paragraph-based) as well as semantically-informed and LLM-guided methods; and (2) embedding paradigms, which determine the timing of chunking relative to embedding (pre-embedding chunking vs. contextualized chunking). Our reproduction evaluates these approaches in two distinct retrieval settings established in previous work: in-document retrieval (needle-in-a-haystack) and in-corpus retrieval (the standard information retrieval task).\n  Our comprehensive evaluation reveals that optimal chunking strategies are task-dependent: simple structure-based methods outperform LLM-guided alternatives for in-corpus retrieval, while LumberChunker performs best for in-document retrieval. Contextualized chunking improves in-corpus effectiveness but degrades in-document retrieval. We also find that chunk size correlates moderately with in-document but weakly with in-corpus effectiveness, suggesting segmentation method differences are not purely driven by chunk size. Our code and evaluation benchmarks are publicly available at (Anonymoused).","authors":["Yongjie Zhou","Shuai Wang","Bevan Koopman","Guido Zuccon"],"pdf_url":"","comment":"Github link will be pushed later as it's anonymoused at the moment"}],"Multimedia":[{"id":"http://arxiv.org/abs/2602.17871v1","updated":"2026-02-19T22:07:29Z","published":"2026-02-19T22:07:29Z","title":"Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models","summary":"Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base models, alignment architectures, and training data. However, recent works show that these models trail behind in traditional image classification benchmarks, which test fine-grained visual knowledge. We test a large number of recent VLMs on fine-grained classification benchmarks and identify potential factors in the disconnect between fine-grained knowledge and other vision benchmarks. Through a series of ablation experiments, we find that using a better LLM improves all benchmark scores equally, while a better vision encoder disproportionately improves fine-grained classification performance. Furthermore, we find that the pretraining stage is also vital to fine-grained performance, particularly when the language model weights are unfrozen during pretraining. These insights pave the way for enhancing fine-grained visual understanding and vision-centric capabilities in VLMs.","authors":["Dhruba Ghosh","Yuhui Zhang","Ludwig Schmidt"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17769v1","updated":"2026-02-19T19:01:42Z","published":"2026-02-19T19:01:42Z","title":"MusicSem: A Semantically Rich Language--Audio Dataset of Natural Music Descriptions","summary":"Music representation learning is central to music information retrieval and generation. While recent advances in multimodal learning have improved alignment between text and audio for tasks such as cross-modal music retrieval, text-to-music generation, and music-to-text generation, existing models often struggle to capture users' expressed intent in natural language descriptions of music. This observation suggests that the datasets used to train and evaluate these models do not fully reflect the broader and more natural forms of human discourse through which music is described. In this paper, we introduce MusicSem, a dataset of 32,493 language-audio pairs derived from organic music-related discussions on the social media platform Reddit. Compared to existing datasets, MusicSem captures a broader spectrum of musical semantics, reflecting how listeners naturally describe music in nuanced and human-centered ways. To structure these expressions, we propose a taxonomy of five semantic categories: descriptive, atmospheric, situational, metadata-related, and contextual. In addition to the construction, analysis, and release of MusicSem, we use the dataset to evaluate a wide range of multimodal models for retrieval and generation, highlighting the importance of modeling fine-grained semantics. Overall, MusicSem serves as a novel semantics-aware resource to support future research on human-aligned multimodal music representation learning.","authors":["Rebecca Salganik","Teng Tu","Fei-Yueh Chen","Xiaohao Liu","Keifeng Lu","Ethan Luvisia","Zhiyao Duan","Guillaume Salha-Galvan","Anson Kahng","Yunshan Ma","Jian Kang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17599v1","updated":"2026-02-19T18:23:58Z","published":"2026-02-19T18:23:58Z","title":"Art2Mus: Artwork-to-Music Generation via Visual Conditioning and Large-Scale Cross-Modal Alignment","summary":"Music generation has advanced markedly through multimodal deep learning, enabling models to synthesize audio from text and, more recently, from images. However, existing image-conditioned systems suffer from two fundamental limitations: (i) they are typically trained on natural photographs, limiting their ability to capture the richer semantic, stylistic, and cultural content of artworks; and (ii) most rely on an image-to-text conversion stage, using language as a semantic shortcut that simplifies conditioning but prevents direct visual-to-audio learning. Motivated by these gaps, we introduce ArtSound, a large-scale multimodal dataset of 105,884 artwork-music pairs enriched with dual-modality captions, obtained by extending ArtGraph and the Free Music Archive. We further propose ArtToMus, the first framework explicitly designed for direct artwork-to-music generation, which maps digitized artworks to music without image-to-text translation or language-based semantic supervision. The framework projects visual embeddings into the conditioning space of a latent diffusion model, enabling music synthesis guided solely by visual information. Experimental results show that ArtToMus generates musically coherent and stylistically consistent outputs that reflect salient visual cues of the source artworks. While absolute alignment scores remain lower than those of text-conditioned systems-as expected given the substantially increased difficulty of removing linguistic supervision-ArtToMus achieves competitive perceptual quality and meaningful cross-modal correspondence. This work establishes direct visual-to-music generation as a distinct and challenging research direction, and provides resources that support applications in multimedia art, cultural heritage, and AI-assisted creative practice. Code and dataset will be publicly released upon acceptance.","authors":["Ivan Rinaldi","Matteo Mendula","Nicola Fanelli","Florence Levé","Matteo Testi","Giovanna Castellano","Gennaro Vessio"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.11903v2","updated":"2026-02-19T11:40:26Z","published":"2026-02-12T12:56:58Z","title":"Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals","summary":"No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.","authors":["Yu-Chih Chen","Michael Wang","Chieh-Dun Wen","Kai-Siang Ma","Avinab Saha","Li-Heng Chen","Alan Bovik"],"pdf_url":"","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2508.08179v3","updated":"2026-02-19T07:33:03Z","published":"2025-08-11T16:59:15Z","title":"PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation","summary":"Human motion generation has found widespread applications in AR/VR, film, sports, and medical rehabilitation, offering a cost-effective alternative to traditional motion capture systems. However, evaluating the fidelity of such generated motions is a crucial, multifaceted task. Although previous approaches have attempted at motion fidelity evaluation using human perception or physical constraints, there remains an inherent gap between human-perceived fidelity and physical feasibility. Moreover, the subjective and coarse binary labeling of human perception further undermines the development of a robust data-driven metric. We address these issues by introducing a physical labeling method. This method evaluates motion fidelity by calculating the minimum modifications needed for a motion to align with physical laws. With this approach, we are able to produce fine-grained, continuous physical alignment annotations that serve as objective ground truth. With these annotations, we propose PP-Motion, a novel data-driven metric to evaluate both physical and perceptual fidelity of human motion. To effectively capture underlying physical priors, we employ Pearson's correlation loss for the training of our metric. Additionally, by incorporating a human-based perceptual fidelity loss, our metric can capture fidelity that simultaneously considers both human perception and physical alignment. Experimental results demonstrate that our metric, PP-Motion, not only aligns with physical laws but also aligns better with human perception of motion fidelity than previous work.","authors":["Sihan Zhao","Zixuan Wang","Tianyu Luan","Jia Jia","Wentao Zhu","Jiebo Luo","Junsong Yuan","Nan Xi"],"pdf_url":"","comment":"Accepted by ACM Multimedia 2025"},{"id":"http://arxiv.org/abs/2602.17120v1","updated":"2026-02-19T06:43:52Z","published":"2026-02-19T06:43:52Z","title":"HybridPrompt: Bridging Generative Priors and Traditional Codecs for Mobile Streaming","summary":"In Video on Demand (VoD) scenarios, traditional codecs are the industry standard due to their high decoding efficiency. However, they suffer from severe quality degradation under low bandwidth conditions. While emerging generative neural codecs offer significantly higher perceptual quality, their reliance on heavy frame-by-frame generation makes real-time playback on mobile devices impractical. We ask: is it possible to combine the blazing-fast speed of traditional standards with the superior visual fidelity of neural approaches? We present HybridPrompt, the first generative-based video system capable of achieving real-time 1080p decoding at over 150 FPS on a commercial smartphone. Specifically, we employ a hybrid architecture that encodes Keyframes using a generative model while relying on traditional codecs for the remaining frames. A major challenge is that the two paradigms have conflicting objectives: the \"hallucinated\" details from generative models often misalign with the rigid prediction mechanisms of traditional codecs, causing bitrate inefficiency. To address this, we demonstrate that the traditional decoding process is differentiable, enabling an end-to-end optimization loop. This allows us to use subsequent frames as additional supervision, forcing the generative model to synthesize keyframes that are not only perceptually high-fidelity but also mathematically optimal references for the traditional codec. By integrating a two-stage generation strategy, our system outperforms pure neural baselines by orders of magnitude in speed while achieving an average LPIPS gain of 8% over traditional codecs at 200kbps.","authors":["Liming Liu","Jiangkai Wu","Haoyang Wang","Peiheng Wang","Zongming Guo","Xinggong Zhang"],"pdf_url":"","comment":"6 pages, 7 figures, 4 tables, to appear in NOSSDAV 26"},{"id":"http://arxiv.org/abs/2602.17011v1","updated":"2026-02-19T02:18:55Z","published":"2026-02-19T02:18:55Z","title":"CAFE: Channel-Autoregressive Factorized Encoding for Robust Biosignal Spatial Super-Resolution","summary":"High-density biosignal recordings are critical for neural decoding and clinical monitoring, yet real-world deployments often rely on low-density (LD) montages due to hardware and operational constraints. This motivates spatial super-resolution from LD observations, but heterogeneous dependencies under sparse and noisy measurements often lead to artifact propagation and false non-local correlations. To address this, we propose CAFE, a plug-and-play rollout generation scheme that reconstructs the full montage in geometry-aligned stages. Starting from the LD channels, CAFE first recovers nearby channels and then progressively expands to more distal regions, exploiting reliable local structure before introducing non-local interactions. During training, step-wise supervision is applied over channel groups and teacher forcing with epoch-level scheduled sampling along the group dimension is utilized to reduce exposure bias, enabling parallel computation across steps. At test time, CAFE performs an autoregressive rollout across groups, while remaining plug-and-play by reusing any temporal backbone as the shared predictor. Evaluated on $4$ modalities and $6$ datasets, CAFE demonstrates plug-and-play generality across $3$ backbones (MLP, Conv, Transformer) and achieves consistently better reconstruction than $5$ representative baselines.","authors":["Hongjun Liu","Leyu Zhou","Zijianghao Yang","Rujun Han","Shitong Duan","Kuanjian Tang","Chao Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17010v1","updated":"2026-02-19T02:17:13Z","published":"2026-02-19T02:17:13Z","title":"Is there a relationship between Mean Opinion Score (MOS) and Just Noticeable Difference (JND)?","summary":"Evaluating perceived video quality is essential for ensuring high Quality of Experience (QoE) in modern streaming applications. While existing subjective datasets and Video Quality Metrics (VQMs) cover a broad quality range, many practical use cases especially for premium users focus on high quality scenarios requiring finer granularity. Just Noticeable Difference (JND) has emerged as a key concept for modeling perceptual thresholds in these high end regions and plays an important role in perceptual bitrate ladder construction. However, the relationship between JND and the more widely used Mean Opinion Score (MOS) remains unclear. In this paper, we conduct a Degradation Category Rating (DCR) subjective study based on an existing JND dataset to examine how MOS corresponds to the 75% Satisfied User Ratio (SUR) points of the 1st and 2nd JNDs. We find that while MOS values at JND points generally align with theoretical expectations (e.g., 4.75 for the 75% SUR of the 1st JND), the reverse mapping from MOS to JND is ambiguous due to overlapping confidence intervals across PVS indices. Statistical significance analysis further shows that DCR studies with limited participants may not detect meaningful differences between reference and JND videos.","authors":["Jingwen Zhu","Hadi Amirpour","Wei Zhou","Patrick Le Callet"],"pdf_url":"","comment":"International Conference on Visual Communications and Image Processing (VCIP 2025)"}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2602.18511v1","updated":"2026-02-19T13:48:51Z","published":"2026-02-19T13:48:51Z","title":"Beyond Pass-by-Pass Optimization: Intent-Driven IR Optimization with Large Language Models","summary":"Modern compilers optimize programs through a sequence of modular passes over intermediate representations (IR). While this pass-by-pass paradigm offers engineering benefits, it suffers from a pass coordination problem: locally beneficial transformations may block more profitable optimizations in later stages. This limitation stems from the lack of an explicit notion of optimization intent, defined as a holistic strategy for coordinating multiple transformations toward a global performance objective. Recent LLM-based approaches formulate IR optimization as an end-to-end generation task, thereby avoiding the traditional pass-by-pass structure. However, optimization intent remains implicit in these methods, forcing models to jointly infer optimization strategy and generate low-level transformations, which limits both correctness and performance. We propose IntOpt, the first intent-driven IR optimizer that explicitly separates high-level optimization intent from low-level analysis and transformation. IntOpt organizes IR optimization into three stages: intent formulation, intent refinement, and intent realization, enabling globally coordinated transformations. Experiments show that IntOpt achieves 90.5% verified correctness and 2.660x average speedup on 200-program test set, outperforming state-of-the-art LLM-based optimizers in both correctness and performance, and surpassing modern compiler with the -O3 option on 37 benchmarks with speedups of up to 272.60x.","authors":["Lei Qiu","Zi Yang","Fang Lyu","Ming Zhong","Huimin Cui","Xiaobing Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16981v1","updated":"2026-02-19T00:52:49Z","published":"2026-02-19T00:52:49Z","title":"Mason: Type- and Name-Guided Program Synthesis","summary":"Object-oriented programs tend to be written using many common coding idioms, such as those captured by design patterns. While design patterns are useful, implementing them is often tedious and repetitive, requiring boilerplate code that distracts the programmer from more essential details. In this paper, we introduce Mason, a tool that synthesizes object-oriented programs from partial program pieces, and we apply it to automatically insert design patterns into programs. At the core of Mason is a novel technique we call type- and name-guided synthesis, in which an enumerative solver traverses a partial program to generate typing constraints; discharges constraints via program transformations guided by the names of constrained types and members; and backtracks when a constraint is violated or a candidate program fails unit tests. We also introduce two extensions to Mason: a non-local backtracking heuristic that uses execution traces, and a language of patterns that impose syntactic restrictions on missing names. We evaluate Mason on a suite of benchmarks to which Mason must add various well-known design patterns implemented as a library of program pieces. We find that Mason performs well when very few candidate programs satisfy its typing constraints and that our extensions can improve Mason's performance significantly when this is not the case. We believe that Mason takes an important step forward in synthesizing multi-class object-oriented programs using design patterns.","authors":["Jasper Geer","Fox Huston","Jeffrey S. Foster"],"pdf_url":"","comment":null}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.17902v1","updated":"2026-02-19T23:47:05Z","published":"2026-02-19T23:47:05Z","title":"El Agente Gráfico: Structured Execution Graphs for Scientific Agents","summary":"Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making within a type-safe execution environment and dynamic knowledge graphs for external persistence. Central to our approach is a structured abstraction of scientific concepts and an object-graph mapper that represents computational state as typed Python objects, stored either in memory or persisted in an external knowledge graph. This design enables context management through typed symbolic identifiers rather than raw text, thereby ensuring consistency, supporting provenance tracking, and enabling efficient tool orchestration. We evaluate the system by developing an automated benchmarking framework across a suite of university-level quantum chemistry tasks previously evaluated on a multi-agent system, demonstrating that a single agent, when coupled to a reliable execution engine, can robustly perform complex, multi-step, and parallel computations. We further extend this paradigm to two other large classes of applications: conformer ensemble generation and metal-organic framework design, where knowledge graphs serve as both memory and reasoning substrates. Together, these results illustrate how abstraction and type safety can provide a scalable foundation for agentic scientific automation beyond prompt-centric designs.","authors":["Jiaru Bai","Abdulrahman Aldossary","Thomas Swanick","Marcel Müller","Yeonghun Kang","Zijian Zhang","Jin Won Lee","Tsz Wai Ko","Mohammad Ghazi Vakili","Varinia Bernales","Alán Aspuru-Guzik"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17891v1","updated":"2026-02-19T23:11:39Z","published":"2026-02-19T23:11:39Z","title":"HookLens: Visual Analytics for Understanding React Hooks Structures","summary":"Maintaining and refactoring React web applications is challenging, as React code often becomes complex due to its core API called Hooks. For example, Hooks often lead developers to create complex dependencies among components, making code behavior unpredictable and reducing maintainability, i.e., anti-patterns. To address this challenge, we present HookLens, an interactive visual analytics system that helps developers understand howHooks define dependencies and data flows between components. Informed by an iterative design process with experienced React developers, HookLens supports users to efficiently understand the structure and dependencies between components and to identify anti-patterns. A quantitative user study with 12 React developers demonstrates that HookLens significantly improves participants' accuracy in detecting anti-patterns compared to conventional code editors. Moreover, a comparative study with state-of-the-art LLM-based coding assistants confirms that these improvements even surpass the capabilities of such coding assistants on the same task.","authors":["Suyeon Hwang","Minkyu Kweon","Jeongmin Rhee","Soohyun Lee","Seokhyeon Park","Seokweon Jung","Hyeon Jeon","Jinwook Seo"],"pdf_url":"","comment":"IEEE PacificVis 2026, conference track"},{"id":"http://arxiv.org/abs/2602.17887v1","updated":"2026-02-19T22:46:44Z","published":"2026-02-19T22:46:44Z","title":"Automated LLM-Based Accessibility Remediation: From Conventional Websites to Angular Single-Page Applications","summary":"Web accessibility remains an unresolved issue for a large part of the web content. There are many tools to detect errors automatically, but fixing those issues is still mostly a manual, slow, and costly process in which it is easy for developers to overlook specific details. The situation becomes even more complex with modern Single-Page Applications (SPAs), whose dynamic nature makes traditional static analysis approaches inadequate. This work proposes a system that aims to address this challenge by using Large Language Models (LLMs) to automate accessibility fixes. The proposal presents a modular workflow applicable to both static websites and complex Angular projects. The framework actively implements corrections within the DOM of static web pages or the source code of SPAs. The system was tested on 12 static websites and 6 open-source Angular projects, fixing 80% of the accessibility issues on public websites and 86% of the issues on Angular applications. Our proposal also generates meaningful visual descriptions for images while preserving the application's design and stability. This work contributes to ensuring that accessibility stops being a technical debt deferred to the future and becomes a natural part of everyday development workflows.","authors":["Carla Fernández-Navarro","Francisco Chicano"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17838v1","updated":"2026-02-19T21:00:49Z","published":"2026-02-19T21:00:49Z","title":"Examining LLMs Ability to Summarize Code Through Mutation-Analysis","summary":"As developers increasingly rely on LLM-generated code summaries for documentation, testing, and review, it is important to study whether these summaries accurately reflect what the program actually does. LLMs often produce confident descriptions of what the code looks like it should do (intent), while missing subtle edge cases or logic changes that define what it actually does (behavior). We present a mutation-based evaluation methodology that directly tests whether a summary truly matches the code's logic. Our approach generates a summary, injects a targeted mutation into the code, and checks if the LLM updates its summary to reflect the new behavior. We validate it through three experiments totalling 624 mutation-summary evaluations across 62 programs. First, on 12 controlled synthetic programs with 324 mutations varying in type (statement, value, decision) and location (beginning, middle, end). We find that summary accuracy decreases sharply with complexity from 76.5% for single functions to 17.3% for multi-threaded systems, while mutation type and location exhibit weaker effects. Second, testing 150 mutated samples on 50 human-written programs from the Less Basic Python Problems (LBPP) dataset confirms the same failure patterns persist as models often describe algorithmic intent rather than actual mutated behavior with a summary accuracy rate of 49.3%. Furthermore, while a comparison between GPT-4 and GPT-5.2 shows a substantial performance leap (from 49.3% to 85.3%) and an improved ability to identify mutations as \"bugs\", both models continue to struggle with distinguishing implementation details from standard algorithmic patterns. This work establishes mutation analysis as a systematic approach for assessing whether LLM-generated summaries reflect program behavior rather than superficial textual patterns.","authors":["Lara Khatib","Micheal Pu","Bogdan Vasilescu","Meiyappan Nagappan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17640v1","updated":"2026-02-19T18:52:46Z","published":"2026-02-19T18:52:46Z","title":"huff: A Python package for Market Area Analysis","summary":"Market area models, such as the Huff model and its extensions, are widely used to estimate regional market shares and customer flows of retail and service locations. Another, now very common, area of application is the analysis of catchment areas, supply structures and the accessibility of healthcare locations. The huff Python package provides a complete workflow for market area analysis, including data import, construction of origin-destination interaction matrices, basic model analysis, parameter estimation from empirical data, calculation of distance or travel time indicators, and map visualization. Additionally, the package provides several methods of spatial accessibility analysis. The package is modular and object-oriented. It is intended for researchers in economic geography, regional economics, spatial planning, marketing, geoinformation science, and health geography. The software is openly available via the [Python Package Index (PyPI)](https://pypi.org/project/huff/); its development and version history are managed in a public [GitHub Repository](https://github.com/geowieland/huff_official) and archived at [Zenodo](https://doi.org/10.5281/zenodo.18639559).","authors":["Thomas Wieland"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17622v1","updated":"2026-02-19T18:42:40Z","published":"2026-02-19T18:42:40Z","title":"What Makes a Good LLM Agent for Real-world Penetration Testing?","summary":"LLM-based agents show promise for automating penetration testing, yet reported performance varies widely across systems and benchmarks. We analyze 28 LLM-based penetration testing systems and evaluate five representative implementations across three benchmarks of increasing complexity. Our analysis reveals two distinct failure modes: Type A failures stem from capability gaps (missing tools, inadequate prompts) that engineering readily addresses, while Type B failures persist regardless of tooling due to planning and state management limitations. We show that Type B failures share a root cause that is largely invariant to the underlying LLM: agents lack real-time task difficulty estimation. As a result, agents misallocate effort, over-commit to low-value branches, and exhaust context before completing attack chains.\n  Based on this insight, we present Excalibur, a penetration testing agent that couples strong tooling with difficulty-aware planning. A Tool and Skill Layer eliminates Type A failures through typed interfaces and retrieval-augmented knowledge. A Task Difficulty Assessment (TDA) mechanism addresses Type B failures by estimating tractability through four measurable dimensions (horizon estimation, evidence confidence, context load, and historical success) and uses these estimates to guide exploration-exploitation decisions within an Evidence-Guided Attack Tree Search (EGATS) framework. Excalibur achieves up to 91% task completion on CTF benchmarks with frontier models (39 to 49% relative improvement over baselines) and compromises 4 of 5 hosts on the GOAD Active Directory environment versus 2 by prior systems. These results show that difficulty-aware planning yields consistent end-to-end gains across models and addresses a limitation that model scaling alone does not eliminate.","authors":["Gelei Deng","Yi Liu","Yuekang Li","Ruozhao Yang","Xiaofei Xie","Jie Zhang","Han Qiu","Tianwei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17498v1","updated":"2026-02-19T16:14:22Z","published":"2026-02-19T16:14:22Z","title":"Towards a Software Reference Architecture for Natural Language Processing Tools in Requirements Engineering","summary":"Natural Language Processing (NLP) tools support requirements engineering (RE) tasks like requirements elicitation, classification, and validation. However, they are often developed from scratch despite functional overlaps, and abandoned after publication. This lack of interoperability and maintenance incurs unnecessary development effort, impedes tool comparison and benchmarking, complicates documentation, and diminishes the long-term sustainability of NLP4RE tools. To address these issues, we postulate a vision to transition from monolithic NLP4RE tools to an ecosystem of reusable, interoperable modules. We outline a research roadmap towards a software reference architecture (SRA) to realize this vision, elaborated following a standard methodological framework for SRA development. As an initial step, we conducted a stakeholder-driven focus group session to elicit generic system requirements for NLP4RE tools. This activity resulted in 36 key system requirements, further motivating the need for a dedicated SRA. Overall, the proposed vision, roadmap, and initial contribution pave the way towards improved development, reuse, and long-term maintenance of NLP4RE tools.","authors":["Julian Frattini","Quim Motger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17426v1","updated":"2026-02-19T14:57:30Z","published":"2026-02-19T14:57:30Z","title":"The Runtime Dimension of Ethics in Self-Adaptive Systems","summary":"Self-adaptive systems increasingly operate in close interaction with humans, often sharing the same physical or virtual environments and making decisions with ethical implications at runtime. Current approaches typically encode ethics as fixed, rule-based constraints or as a single chosen ethical theory embedded at design time. This overlooks a fundamental property of human-system interaction settings: ethical preferences vary across individuals and groups, evolve with context, and may conflict, while still needing to remain within a legally and regulatorily defined hard-ethics envelope (e.g., safety and compliance constraints). This paper advocates a shift from static ethical rules to runtime ethical reasoning for self-adaptive systems, where ethical preferences are treated as runtime requirements that must be elicited, represented, and continuously revised as stakeholders and situations change. We argue that satisfying such requirements demands explicit ethics-based negotiation to manage ethical trade-offs among multiple humans who interact with, are represented by, or are affected by a system. We identify key challenges, ethical uncertainty, conflicts among ethical values (including human, societal, and environmental drivers), and multi-dimensional/multi-party/multi-driver negotiation, and outline research directions and questions toward ethically self-adaptive systems.","authors":["Marco Autili","Gianluca Filippone","Mashal Afzal Memon","Patrizio Pelliccione"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2302.01894v5","updated":"2026-02-19T14:31:09Z","published":"2023-02-03T18:08:03Z","title":"Understanding the Issues, Their Causes and Solutions in Microservices Systems: An Empirical Study","summary":"Many small to large organizations have adopted the Microservices Architecture (MSA) style to develop and deliver their core businesses. Despite the popularity of MSA in the software industry, there is a limited evidence-based and thorough understanding of the types of issues (e.g., errors, faults, failures, and bugs) that microservices system developers experience, the causes of the issues, and the solutions as potential fixing strategies to address the issues. To ameliorate this gap, we conducted a mixed-methods empirical study that collected data from 2,641 issues from the issue tracking systems of 15 open-source microservices systems on GitHub, 15 interviews, and an online survey completed by 150 practitioners from 42 countries across 6 continents. Our analysis led to comprehensive taxonomies for the issues, causes, and solutions. The findings of this study informthat Technical Debt, Continuous Integration and Delivery, Exception Handling, Service Execution and Communication, and Security are the most dominant issues in microservices systems. Furthermore, General Programming Errors, Missing Features and Artifacts, and Invalid Configuration and Communication are the main causes behind the issues. Finally, we found 177 types of solutions that can be applied to fix the identified issues. Based on our study results, we propose a future research framework that outlines key problem dimensions and actionable study strategies to support the engineering of emergent and next-generation microservices systems.","authors":["Muhammad Waseem","Peng Liang","Aakash Ahmad","Arif Ali Khan","Mojtaba Shahin","Pekka Abrahamsson","Ali Rezaei Nasab","Tommi Mikkonen"],"pdf_url":"","comment":"Preprint accepted for publication in Journal of Systems and Software, 2026"},{"id":"http://arxiv.org/abs/2602.17365v1","updated":"2026-02-19T13:48:29Z","published":"2026-02-19T13:48:29Z","title":"Computer-Using World Model","summary":"Agents operating in complex software environments benefit from reasoning about the consequences of their actions, as even a single incorrect user interface (UI) operation can derail long, artifact-preserving workflows. This challenge is particularly acute for computer-using scenarios, where real execution does not support counterfactual exploration, making large-scale trial-and-error learning and planning impractical despite the environment being fully digital and deterministic. We introduce the Computer-Using World Model (CUWM), a world model for desktop software that predicts the next UI state given the current state and a candidate action. CUWM adopts a two-stage factorization of UI dynamics: it first predicts a textual description of agent-relevant state changes, and then realizes these changes visually to synthesize the next screenshot. CUWM is trained on offline UI transitions collected from agents interacting with real Microsoft Office applications, and further refined with a lightweight reinforcement learning stage that aligns textual transition predictions with the structural requirements of computer-using environments. We evaluate CUWM via test-time action search, where a frozen agent uses the world model to simulate and compare candidate actions before execution. Across a range of Office tasks, world-model-guided test-time scaling improves decision quality and execution robustness.","authors":["Yiming Guan","Rui Yu","John Zhang","Lu Wang","Chaoyun Zhang","Liqun Li","Bo Qiao","Si Qin","He Huang","Fangkai Yang","Pu Zhao","Lukas Wutschitz","Samuel Kessler","Huseyin A Inan","Robert Sim","Saravan Rajmohan","Qingwei Lin","Dongmei Zhang"],"pdf_url":"","comment":"35 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.17320v1","updated":"2026-02-19T12:35:08Z","published":"2026-02-19T12:35:08Z","title":"Socio-Technical Well-Being of Quantum Software Communities: An Overview on Community Smells","summary":"Quantum computing has gained significant attention due to its potential to solve computational problems beyond the capabilities of classical computers. With major corporations and academic institutions investing in quantum hardware and software, there has been a rise in the development of quantum-enabled systems, particularly within open-source communities. However, despite the promising nature of quantum technologies, these communities face critical socio-technical challenges, including the emergence of socio-technical anti-patterns known as community smells. These anti-patterns, prevalent in open-source environments, have the potential to negatively impact both product quality and community health by introducing technical debt and amplifying architectural and code smells. Despite the importance of these socio-technical factors, there remains a scarcity of research investigating their influence within quantum open-source communities. This work aims to address this gap by providing a first step in analyzing the socio-technical well-being of quantum communities through a cross-sectional study. By understanding the socio-technical dynamics at play, it is expected that foundational knowledge can be established to mitigate the risks associated with community smells and ensure the long-term sustainability of open-source quantum initiatives.","authors":["Stefano Lambiase","Manuel De Stefano","Fabio Palomba","Filomena Ferrucci","Andrea De Lucia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.12507v3","updated":"2026-02-19T10:45:42Z","published":"2025-12-14T01:11:11Z","title":"ATLAS: Automated Tree-based Language Analysis System for C and C++ source programs","summary":"Analyzing non-compilable C/C++ submodules without a resolved build environment remains a critical bottleneck for industrial software evolution. Traditional static analysis tools often fail in these scenarios due to their reliance on successful compilation, while Large Language Models (LLMs) lack the structural context necessary to reason about complex program logic. We introduce ATLAS, a Python-based CLI that generates unified multi-view representations for large-scale C/C++ projects with high accuracy, achieving success rates up to 96.80% for CFGs and 91.38% for DFGs. ATLAS is characterized by: (i) inter-procedural, type-aware analysis across function boundaries; (ii) support for both full and partial analysis of non-compilable projects; (iii) graph optimizations such as variable collapsing and node blacklisting; and (iv) synchronized multi-view graphs that align syntax, execution paths, and data-flow logic. Evaluating ATLAS with DeepSeek V3.2 for automated test generation demonstrates a 34.71% increase in line coverage and 32.66% in branch coverage, matching or exceeding the performance of the symbolic execution tool KLEE on complex projects. With polynomial scalability, ATLAS provides a robust infrastructure for generating the information-dense datasets required by next-generation, graph-aware ML4SE models.\n  Video demonstration: https://youtu.be/QGuJZhj9CTA Tool github repository: https://github.com/jaid-monwar/ATLAS-multi-view-code-representation-tool.git","authors":["Jaid Monwar Chowdhury","Ahmad Farhan Shahriar Chowdhury","Humayra Binte Monwar","Mahmuda Naznin"],"pdf_url":"","comment":"9 pages, 14 figures, 6 tables; Video demonstration: https://youtu.be/QGuJZhj9CTA; Tool repository: https://github.com/jaid-monwar/ATLAS-multi-view-code-representation-tool.git"},{"id":"http://arxiv.org/abs/2602.17237v1","updated":"2026-02-19T10:33:50Z","published":"2026-02-19T10:33:50Z","title":"Disjunction Composition of BDD Transition Systems for Model-Based Testing","summary":"We introduce a compositional approach to model-based test generation in Behavior-Driven Development (BDD). BDD is an agile methodology in which system behavior is specified through textual scenarios that, in our approach, are translated into transition systems used for model-based testing. This paper formally defines disjunction composition, to combine BDD transition systems that represent alternative system behaviors. Disjunction composition allows for modeling and testing the integrated behavior while ensuring that the testing power of the original set of scenarios is preserved. This is proved using a symbolic semantics for BDD transition systems, with the property that the symbolic equivalence of two BDD transition systems guarantees that they fail the same test cases. Also, we demonstrate the potential of disjunction composition by applying the composition in an industrial case study.","authors":["Tannaz Zameni","Petra van den Bos","Arend Rensink"],"pdf_url":"","comment":"Technical report with proofs"},{"id":"http://arxiv.org/abs/2602.17193v1","updated":"2026-02-19T09:23:21Z","published":"2026-02-19T09:23:21Z","title":"The Case for HTML First Web Development","summary":"Since its introduction in the early 90s, the web has become the largest application platform available globally. HyperText Markup Language (HTML) has been an essential part of the web since the beginning, as it allows defining webpages in a tree-like manner, including semantics and content. Although the web was never meant to be an application platform, it evolved as such, especially since the early 2000s, as web application frameworks became available. While the emergence of frameworks made it easier than ever to develop complex applications, it also put HTML on the back burner. As web standards caught up, especially with milestones such as HTML5, the gap between the web platform and frameworks was reduced. HTML First development emphasizes this shift and puts focus on literally using HTML first when possible, while encouraging minimalism familiar from the early days of the web. It seems HTML-oriented web development can provide clear benefits to developers, especially when it is combined with comple- mentary approaches, such as embracing hypermedia and moving a large part of application logic to the server side. In the context of the htmx project, it was observed that moving towards HTML can reduce the size of a codebase greatly while leading to maintenance and development benefits due to the increased conceptual simplicity. Holotype-based comparisons for content-oriented websites show performance benefits, and the same observation was confirmed by a small case study where the Yle website was converted to follow HTML First principles. In short, the HTML First approach seems to have clear advantages for web developers, while there are open questions related to the magnitude of the benefits and the alignment with the recent trend of AI-driven web development.","authors":["Juho Vepsäläinen"],"pdf_url":"","comment":"28 pages, 5 figures, 5 tables, preprint"},{"id":"http://arxiv.org/abs/2602.17183v1","updated":"2026-02-19T09:05:03Z","published":"2026-02-19T09:05:03Z","title":"Robustness and Reasoning Fidelity of Large Language Models in Long-Context Code Question Answering","summary":"Large language models (LLMs) increasingly assist software engineering tasks that require reasoning over long code contexts, yet their robustness under varying input conditions remains unclear. We conduct a systematic study of long-context code question answering using controlled ablations that test sensitivity to answer format, distractors, and context scale. Extending LongCodeBench Python dataset with new COBOL and Java question-answer sets, we evaluate state-of-the-art models under three settings: (i) shuffled multiple-choice options, (ii) open-ended questions and (iii) needle-in-a-haystack contexts containing relevant and adversarially irrelevant information. Results show substantial performance drops in both shuffled multiple-choice options and open-ended questions, and brittle behavior in the presence of irrelevant cues. Our findings highlight limitations of current long-context evaluations and provide a broader benchmark for assessing code reasoning in both legacy and modern systems.","authors":["Kishan Maharaj","Nandakishore Menon","Ashita Saxena","Srikanth Tamilselvam"],"pdf_url":"","comment":"11 pages, 4 Figures, 5 Tables, Work in Progress"},{"id":"http://arxiv.org/abs/2601.01569v3","updated":"2026-02-19T07:07:15Z","published":"2026-01-04T15:32:47Z","title":"CaveAgent: Transforming LLMs into Stateful Runtime Operators","summary":"LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms that struggle with long-horizon tasks due to fragile multi-turn dependencies and context drift. We present CaveAgent, a framework that shifts tool use from ``LLM-as-Text-Generator'' to ``LLM-as-Runtime-Operator.'' CaveAgent introduces a dual-stream architecture that inverts the conventional paradigm: rather than treating the LLM's text context as the primary workspace with tools as auxiliary, CaveAgent elevates the persistent Python runtime as the central locus of state, with a lightweight semantic stream serving as its orchestrator. Beyond leveraging code generation to resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, CaveAgent introduces \\textit{Stateful Runtime Management}: it injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns, unlike existing code-based approaches that remain text-bound. CaveAgent further provides a runtime-integrated skill management system that extends the Agent Skills open standard, enabling ecosystem interoperability through executable skill injections. This persistence mechanism serves as a high-fidelity external memory that reduces context drift in multi-turn interactions and preserves processed data for downstream applications without information loss. Evaluations show consistent improvement across challenging benchmarks, enabling CaveAgent to handle data scales that cause context overflow in both JSON-based and code-based agents. The accessible runtime state further provides programmatically verifiable feedback, enabling automated evaluation and reward signal generation without human annotation and establishing a structural foundation for future research in Reinforcement Learning with Verifiable Rewards (RLVR).","authors":["Maohao Ran","Zhenglin Wan","Cooper Lin","Yanting Zhang","Hongyu Xin","Hongwei Fan","Yibo Xu","Beier Luo","Yaxin Zhou","Wangbo Zhao","Lijie Yang","Lang Feng","Fuchao Yang","Jingxuan Wu","Yiqiao Huang","Chendong Ma","Dailing Jiang","Jianbo Deng","Sirui Han","Yang You","Bo An","Yike Guo","Jun Song"],"pdf_url":"","comment":"ver.2"},{"id":"http://arxiv.org/abs/2602.17131v1","updated":"2026-02-19T07:06:34Z","published":"2026-02-19T07:06:34Z","title":"Quantifying Competitive Relationships Among Open-Source Software Projects","summary":"Throughout the history of software, evolution has occurred in cycles of rise and fall driven by competition, and open-source software (OSS) is no exception. This cycle is accelerating, particularly in rapidly evolving domains such as web development and deep learning. However, the impact of competitive relationships among OSS projects on their survival remains unclear, and there are risks of losing a competitive edge to rivals. To address this, this study proposes a new automated method called ``Mutual Impact Analysis of OSS (MIAO)'' to quantify these competitive relationships. The proposed method employs a structural vector autoregressive model and impulse response functions, normally used in macroeconomic analysis, to analyze the interactions among OSS projects. In an empirical analysis involving mining and analyzing 187 OSS project groups, MIAO identified projects that were forced to cease development owing to competitive influences with up to 81\\% accuracy, and the resulting features supported predictive experiments that anticipate cessation one year ahead with up to 77\\% accuracy. This suggests that MIAO could be a valuable tool for OSS project maintainers to understand the dynamics of OSS ecosystems and predict the rise and fall of OSS projects.","authors":["Yuki Takei","Toshiaki Aoki","Chaiyong Ragkhitwetsagul"],"pdf_url":"","comment":"12 pages, 3 figures, 7 tables. Accepted at MSR 2026"},{"id":"http://arxiv.org/abs/2506.02529v2","updated":"2026-02-19T06:53:03Z","published":"2025-06-03T07:08:21Z","title":"Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs","summary":"Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in automating complex tasks, but limitations persist in handling dynamic navigation flows and complex form interactions. This paper presents an automated system for generating test cases for two key aspects of web application testing: site navigation and form filling. For site navigation, the system employs screen transition graphs and LLMs to model navigation flows and generate test scenarios. For form filling, it uses state graphs to handle conditional forms and automates Selenium script generation. Key contributions include: (1) a novel integration of graph structures and LLMs for site navigation testing, (2) a state graph-based approach for automating form-filling test cases, and (3) a comprehensive dataset for evaluating form-interaction testing. Experimental results demonstrate the system's effectiveness in improving test coverage and robustness, advancing the state of web application testing.","authors":["Nguyen-Khang Le","Quan Minh Bui","Minh Ngoc Nguyen","Hiep Nguyen","Trung Vo","Son T. Luu","Shoshin Nomura","Minh Le Nguyen"],"pdf_url":"","comment":"Published in the Proceedings of JSAI 2025"},{"id":"http://arxiv.org/abs/2602.17112v1","updated":"2026-02-19T06:17:54Z","published":"2026-02-19T06:17:54Z","title":"Multi-Ecosystem Modeling of OSS Project Sustainability","summary":"Many OSS projects join foundations such as Apache, Eclipse, and OSGeo, to aid their immediate plans and improve long-term prospects by getting governance advice, incubation support, and community-building mechanisms. But foundations differ in their policies, funding models, and support strategies. Moreover, since projects joining these foundations are diverse, coming at different lifecycle stages and having different needs, it can be challenging to decide on the appropriate project-foundation match and on the project-specific plan for sustainability.\n  Here, we present an empirical study and quantitative analysis of the sustainability of incubator projects in the Apache, Eclipse, and OSGeo foundations, and, additionally, of OSS projects from GitHub outside of foundations. We develop foundation-specific sustainability models and a project triage, based on projects' sociotechnical trace profiles, and demonstrate their effectiveness across the foundations. Our results show that our models with triage can effectively forecast sustainability outcomes not only within but across foundations. In addition, the generalizability of the framework allows us to apply the approach to GitHub projects outside the foundations. We complement our findings with actionable recovery strategies from previous work and apply them to case studies of failed incubator projects. Our study highlights the value of sociotechnical frameworks in characterizing and addressing software project sustainability issues.","authors":["Arjun Ashok","Nafiz Imtiaz Khan","Swati Singhvi","Stefan Stanciulescu","Zhouhao Wang","Vladimir Filkov"],"pdf_url":"","comment":"42 pages, 11 figures"},{"id":"http://arxiv.org/abs/2602.17091v1","updated":"2026-02-19T05:29:32Z","published":"2026-02-19T05:29:32Z","title":"What to Cut? Predicting Unnecessary Methods in Agentic Code Generation","summary":"Agentic Coding, powered by autonomous agents such as GitHub Copilot and Cursor, enables developers to generate code, tests, and pull requests from natural language instructions alone. While this accelerates implementation, it produces larger volumes of code per pull request, shifting the burden from implementers to reviewers. In practice, a notable portion of AI-generated code is eventually deleted during review, yet reviewers must still examine such code before deciding to remove it. No prior work has explored methods to help reviewers efficiently identify code that will be removed.In this paper, we propose a prediction model that identifies functions likely to be deleted during PR review. Our results show that functions deleted for different reasons exhibit distinct characteristics, and our model achieves an AUC of 87.1%. These findings suggest that predictive approaches can help reviewers prioritize their efforts on essential code.","authors":["Kan Watanabe","Tatsuya Shirai","Yutaro Kashiwa","Hajimu Iida"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17084v1","updated":"2026-02-19T05:06:31Z","published":"2026-02-19T05:06:31Z","title":"How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses","summary":"The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers respond to them, remains underexplored. In this study, we conduct an empirical analysis of pull requests created by five AI coding agents using the AIDev dataset. We analyze agent differences in pull request description characteristics, including structural features, and examine human reviewer response in terms of review activity, response timing, sentiment, and merge outcomes. We find that AI coding agents exhibit distinct PR description styles, which are associated with differences in reviewer engagement, response time, and merge outcomes. We observe notable variation across agents in both reviewer interaction metrics and merge rates. These findings highlight the role of pull request presentation and reviewer interaction dynamics in human-AI collaborative software development.","authors":["Kan Watanabe","Rikuto Tsuchida","Takahiro Monno","Bin Huang","Kazuma Yamasaki","Youmei Fan","Kazumasa Shimari","Kenichi Matsumoto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17018v1","updated":"2026-02-19T02:30:05Z","published":"2026-02-19T02:30:05Z","title":"Not Only for Developers: Exploring Plugin Maintenance for Knowledge-Centric Communities","summary":"The adoption of third-party libraries has become integral to modern software development, leading to large ecosystems such as PyPI, NPM, and Maven, where contributors typically share the technical expertise to sustain extensions. In communities that are not exclusively composed of developers, however, maintaining plugin ecosystems can present different challenges. In this early results paper, we study Obsidian, a knowledge--centric platform whose community is focused on writing, organization, and creativity--has built a substantial plugin ecosystem despite not being developer--centric. We investigate what kinds of plugins exist within this hybrid ecosystem and establish a foundation for understanding how they are maintained. Using repository mining and LLM-based topic modeling on a representative sample of 396 plugins, we identify six topics related to knowledge management and tooling, which is (i) dynamic editing and organization, (ii) interface and layouts, (iii) creative writing and productivity, (iv) knowledge sync solutions, (v) linking and script tools, and (vi) workflow enhancements tools. Furthermore, analysis of the Pull Requests from these plugins show that much software evolution has been performed on these ecosystem. These findings suggest that even in mixed communities, plugin ecosystems can develop recognizable engineering structures, motivating future work that highlight three different research directions with six research questions related to the health and sustainability of these non-developer ecosystems.","authors":["Giovanni Rosa","David Moreno-Lumbreras","Raula Gaikovina Kula"],"pdf_url":"","comment":"Accepted to SANER2026"},{"id":"http://arxiv.org/abs/2602.16997v1","updated":"2026-02-19T01:42:45Z","published":"2026-02-19T01:42:45Z","title":"Exploring LLMs for User Story Extraction from Mockups","summary":"User stories are one of the most widely used artifacts in the software industry to define functional requirements. In parallel, the use of high-fidelity mockups facilitates end-user participation in defining their needs. In this work, we explore how combining these techniques with large language models (LLMs) enables agile and automated generation of user stories from mockups. To this end, we present a case study that analyzes the ability of LLMs to extract user stories from high-fidelity mockups, both with and without the inclusion of a glossary of the Language Extended Lexicon (LEL) in the prompts. Our results demonstrate that incorporating the LEL significantly enhances the accuracy and suitability of the generated user stories. This approach represents a step forward in the integration of AI into requirements engineering, with the potential to improve communication between users and developers.","authors":["Diego Firmenich","Leandro Antonelli","Bruno Pazos","Fabricio Lozada","Leonardo Morales"],"pdf_url":"","comment":"14 pages, 6 figures. Preprint of the paper published in the 28th Workshop on Requirements Engineering (WER 2025)"}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2509.14282v2","updated":"2026-02-19T23:56:47Z","published":"2025-09-16T14:22:39Z","title":"Resisting Quantum Key Distribution Attacks Using Quantum Machine Learning","summary":"The emergence of quantum computing poses significant risks to the security of modern communication networks as it breaks today's public-key cryptographic algorithms. Quantum Key Distribution (QKD) offers a promising solution by harnessing the principles of quantum mechanics to establish secure keys. However, practical QKD implementations remain vulnerable to hardware imperfections and advanced attacks such as Photon Number Splitting and Trojan-Horse attacks. In this work, we investigate the potential of quantum machine learning (QML) to detect QKD attacks. In particular, we propose a Hybrid Quantum Long Short-Term Memory (QLSTM) model to improve detection performance. By combining quantum-enhanced learning with classical deep learning, the model captures temporal patterns in QKD data, improving detection accuracy. To evaluate the proposed model, we introduce a QKD dataset that simulates typical operations along with multiple attack scenarios, including Intercept-and-Resend, Photon-Number Splitting, Trojan-Horse, Detector Blinding, and Combined attacks. The dataset includes Quantum Bit Error Rate (QBER), signal and decoy loss rates, and time-based metrics. Our results demonstrate the promising performance of the quantum machine learning approach compared to classical models. The proposed Hybrid QLSTM achieved an accuracy of 94.7% after 50 training epochs. The evaluation is conducted on a semi-realistic, simulation-generated decoy-state BB84 dataset, and the reported performance should be interpreted as a proof-of-concept rather than a final assessment on field-deployed QKD systems.","authors":["Ali Al-kuwari","Noureldin Mohamed","Saif Al-kuwari","Ahmed Farouk","Bikash K. Behera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17900v1","updated":"2026-02-19T23:39:54Z","published":"2026-02-19T23:39:54Z","title":"Symfrog-512: High-Capacity Sponge-Based AEAD Cipher (1024-bit State)","summary":"This submission includes a complete reference implementation together with deterministic test vectors and a reproducible benchmark suite. All source code, build instructions, and regression artifacts are publicly available in the project repository, enabling independent verification and reimplementation of the scheme. The AEAD construction is fully specified, including domain separation, rate and capacity choices, tag generation, and the exact file format used by the reference CLI. Reported performance numbers are produced by the built in benchmark tool under documented hardware and compiler settings. All security claims are made strictly within the ideal permutation model following standard sponge and duplex bounds, and no stronger guarantees are asserted for the concrete permutation beyond the documented analysis and empirical behavior. The implementation aims for constant time behavior with respect to secret dependent operations, although no formal side channel proof is provided. The project is released under the MIT license, and external cryptanalysis, feedback, and reproducibility checks are explicitly encouraged.","authors":["Victor Duarte Melo"],"pdf_url":"","comment":"This work presents Symfrog-512, a sponge-based AEAD scheme with a 1024-bit permutation. A full specification, rationale, and reference implementation are included. The submission is exploratory and intended for public review and community cryptanalysis"},{"id":"http://arxiv.org/abs/2602.17842v1","updated":"2026-02-19T21:13:39Z","published":"2026-02-19T21:13:39Z","title":"StableAML: Machine Learning for Behavioral Wallet Detection in Stablecoin Anti-Money Laundering on Ethereum","summary":"Global illicit fund flows exceed an estimated $3.1 trillion annually, with stablecoins emerging as a preferred laundering medium due to their liquidity. While decentralized protocols increasingly adopt zero-knowledge proofs to obfuscate transaction graphs, centralized stablecoins remain critical \"transparent choke points\" for compliance. Leveraging this persistent visibility, this study analyzes an Ethereum dataset and uses behavioral features to develop a robust AML framework. Our findings demonstrate that domain-informed tree ensemble models achieve higher Macro-F1 score, significantly outperforming graph neural networks, which struggle with the increasing fragmentation of transaction networks. The model's interpretability goes beyond binary detection, successfully dissecting distinct typologies: it differentiates the complex, high-velocity dispersion of cybercrime syndicates from the constrained, static footprints left by sanctioned entities. This framework aligns with the industry shift toward deterministic verification, satisfying the auditability and compliance expectations under regulations such as the EU's MiCA and the U.S. GENIUS Act while minimizing unjustified asset freezes. By automating high-precision detection, we propose an approach that effectively raises the economic cost of financial misconduct without stifling innovation.","authors":["Luciano Juvinski","Haochen Li","Alessio Brini"],"pdf_url":"","comment":"27 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.17837v1","updated":"2026-02-19T20:59:47Z","published":"2026-02-19T20:59:47Z","title":"TFL: Targeted Bit-Flip Attack on Large Language Model","summary":"Large language models (LLMs) are increasingly deployed in safety and security critical applications, raising concerns about their robustness to model parameter fault injection attacks. Recent studies have shown that bit-flip attacks (BFAs), which exploit computer main memory (i.e., DRAM) vulnerabilities to flip a small number of bits in model weights, can severely disrupt LLM behavior. However, existing BFA on LLM largely induce un-targeted failure or general performance degradation, offering limited control over manipulating specific or targeted outputs. In this paper, we present TFL, a novel targeted bit-flip attack framework that enables precise manipulation of LLM outputs for selected prompts while maintaining almost no or minor degradation on unrelated inputs. Within our TFL framework, we propose a novel keyword-focused attack loss to promote attacker-specified target tokens in generative outputs, together with an auxiliary utility score that balances attack effectiveness against collateral performance impact on benign data. We evaluate TFL on multiple LLMs (Qwen, DeepSeek, Llama) and benchmarks (DROP, GSM8K, and TriviaQA). The experiments show that TFL achieves successful targeted LLM output manipulations with less than 50 bit flips and significantly reduced effect on unrelated queries compared to prior BFA approaches. This demonstrates the effectiveness of TFL and positions it as a new class of stealthy and targeted LLM model attack.","authors":["Jingkai Guo","Chaitali Chakrabarti","Deliang Fan"],"pdf_url":"","comment":"13 pages, 11 figures. Preprint"},{"id":"http://arxiv.org/abs/2506.18150v3","updated":"2026-02-19T20:23:04Z","published":"2025-06-22T19:40:04Z","title":"HE-LRM: Efficient Private Embedding Lookups for Neural Inference Using Fully Homomorphic Encryption","summary":"Fully Homomorphic Encryption (FHE) allows for computation directly on encrypted data and enables privacy-preserving neural inference in the cloud. Prior work has focused on models with dense inputs (e.g., CNNs), with less attention given to those with sparse inputs such as Deep Learning Recommendation Models (DLRMs). These models require encrypted lookup into large embedding tables that are challenging to implement using FHE's restrictive operators and introduce significant overhead. In this paper, we develop performance optimizations to efficiently support embedding lookups in FHE-based inference pipelines.\n  First, we present an embedding compression technique using client-side digit decomposition that achieves a 56$\\times$ speedup over state-of-the-art. Next, we propose a multi-embedding packing strategy that enables ciphertext SIMD-parallel lookups across multiple tables. Crucially, our goal is not only to retrieve the correct embeddings, but to do so in a way that produces ciphertext outputs in a layout that is directly compatible with downstream encrypted computations server-side. We name our approach HE-LRM and demonstrate end-to-end encrypted DLRM inference. We evaluate HE-LRM on UCI (health prediction) and Criteo (click prediction), achieving inference latencies of 24 and 489 seconds, respectively, on a single-threaded CPU. Finally, while our evaluation focuses on DLRMs, we investigate and apply our embedding-lookup primitives to other models such as LLMs, which require both batched and single-embedding lookups.","authors":["Karthik Garimella","Austin Ebel","Gabrielle De Micheli","Brandon Reagen"],"pdf_url":"","comment":"21 pages, 14 figures, 2 tables"},{"id":"http://arxiv.org/abs/2602.17805v1","updated":"2026-02-19T20:13:36Z","published":"2026-02-19T20:13:36Z","title":"Exploiting Liquidity Exhaustion Attacks in Intent-Based Cross-Chain Bridges","summary":"Intent-based cross-chain bridges have emerged as an alternative to traditional interoperability protocols by allowing off-chain entities (\\emph{solvers}) to immediately fulfill users' orders by fronting their own liquidity. While improving user experience, this approach introduces new systemic risks, such as solver liquidity concentration and delayed settlement. In this paper, we propose a new class of attacks called \\emph{liquidity exhaustion attacks} and a replay-based parameterized attack simulation framework. We analyze 3.5 million cross-chain intents that moved \\$9.24B worth of tokens between June and November 2025 across three major protocols (Mayan Swift, Across, and deBridge), spanning nine blockchains.\n  For rational attackers, our results show that protocols with higher solver profitability, such as deBridge, are vulnerable under current parameters: 210 historical attack instances yield a mean net profit of \\$286.14, with 80.5\\% of attacks profitable. In contrast, Across remains robust in all tested configurations due to low solver margins and very high liquidity, while Mayan Swift is generally secure but becomes vulnerable under stress-test conditions. Under byzantine attacks, we show that it is possible to suppress availability across all protocols, causing dozens of failed intents and solver profit losses of up to \\$978 roughly every 16 minutes. Finally, we propose an optimized attack strategy that exploits patterns in the data to reduce attack costs by up to 90.5\\% compared to the baseline, lowering the barrier to liquidity exhaustion attacks.","authors":["André Augusto","Christof Ferreira Torres","André Vasconcelos","Miguel Correia"],"pdf_url":"","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2504.21035v3","updated":"2026-02-19T19:31:46Z","published":"2025-04-28T01:16:27Z","title":"A False Sense of Privacy: Evaluating Textual Data Sanitization Beyond Surface-level Privacy Leakage","summary":"Sanitizing sensitive text data typically involves removing personally identifiable information (PII) or generating synthetic data under the assumption that these methods adequately protect privacy; however, their effectiveness is often only assessed by measuring the leakage of explicit identifiers but ignoring nuanced textual markers that can lead to re-identification. We challenge the above illusion of privacy by proposing a new framework that evaluates re-identification attacks to quantify individual privacy risks upon data release. Our approach shows that seemingly innocuous auxiliary information -- such as routine social activities -- can be used to infer sensitive attributes like age or substance use history from sanitized data. For instance, we demonstrate that Azure's commercial PII removal tool fails to protect 74\\% of information in the MedQA dataset. Although differential privacy mitigates these risks to some extent, it significantly reduces the utility of the sanitized text for downstream tasks. Our findings indicate that current sanitization techniques offer a \\textit{false sense of privacy}, highlighting the need for more robust methods that protect against semantic-level information leakage.","authors":["Rui Xin","Niloofar Mireshghallah","Shuyue Stella Li","Michael Duan","Hyunwoo Kim","Yejin Choi","Yulia Tsvetkov","Sewoong Oh","Pang Wei Koh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18514v1","updated":"2026-02-19T19:26:21Z","published":"2026-02-19T19:26:21Z","title":"Trojan Horses in Recruiting: A Red-Teaming Case Study on Indirect Prompt Injection in Standard vs. Reasoning Models","summary":"As Large Language Models (LLMs) are increasingly integrated into automated decision-making pipelines, specifically within Human Resources (HR), the security implications of Indirect Prompt Injection (IPI) become critical. While a prevailing hypothesis posits that \"Reasoning\" or \"Chain-of-Thought\" Models possess safety advantages due to their ability to self-correct, emerging research suggests these capabilities may enable more sophisticated alignment failures. This qualitative Red-Teaming case study challenges the safety-through-reasoning premise using the Qwen 3 30B architecture. By subjecting both a standard instruction-tuned model and a reasoning-enhanced model to a \"Trojan Horse\" curriculum vitae, distinct failure modes are observed. The results suggest a complex trade-off: while the Standard Model resorted to brittle hallucinations to justify simple attacks and filtered out illogical constraints in complex scenarios, the Reasoning Model displayed a dangerous duality. It employed advanced strategic reframing to make simple attacks highly persuasive, yet exhibited \"Meta-Cognitive Leakage\" when faced with logically convoluted commands. This study highlights a failure mode where the cognitive load of processing complex adversarial instructions causes the injection logic to be unintentionally printed in the final output, rendering the attack more detectable by humans than in Standard Models.","authors":["Manuel Wirth"],"pdf_url":"","comment":"43 pages, 3 synthetic CV PDF's, 6 chat history PDF's and system prompts. This work was developed as part of the Responsible AI course within the Mannheim Master in Data Science (MMDS) program at the University of Mannheim"},{"id":"http://arxiv.org/abs/2602.17778v1","updated":"2026-02-19T19:21:09Z","published":"2026-02-19T19:21:09Z","title":"Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs","summary":"Multi-turn interaction length is a dominant factor in the operational costs of conversational LLMs. In this work, we present a new failure mode in conversational LLMs: turn amplification, in which a model consistently prolongs multi-turn interactions without completing the underlying task. We show that an adversary can systematically exploit clarification-seeking behavior$-$commonly encouraged in multi-turn conversation settings$-$to scalably prolong interactions. Moving beyond prompt-level behaviors, we take a mechanistic perspective and identify a query-independent, universal activation subspace associated with clarification-seeking responses. Unlike prior cost-amplification attacks that rely on per-turn prompt optimization, our attack arises from conversational dynamics and persists across prompts and tasks. We show that this mechanism provides a scalable pathway to induce turn amplification: both supply-chain attacks via fine-tuning and runtime attacks through low-level parameter corruptions consistently shift models toward abstract, clarification-seeking behavior across prompts. Across multiple instruction-tuned LLMs and benchmarks, our attack substantially increases turn count while remaining compliant. We also show that existing defenses offer limited protection against this emerging class of failures.","authors":["Zachary Coalson","Bo Fang","Sanghyun Hong"],"pdf_url":"","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2602.17651v1","updated":"2026-02-19T18:56:24Z","published":"2026-02-19T18:56:24Z","title":"Non-Trivial Zero-Knowledge Implies One-Way Functions","summary":"A recent breakthrough [Hirahara and Nanashima, STOC'2024] established that if $\\mathsf{NP} \\not \\subseteq \\mathsf{ioP/poly}$, the existence of zero-knowledge with negligible errors for $\\mathsf{NP}$ implies the existence of one-way functions (OWFs). In this work, we obtain a characterization of one-way functions from the worst-case complexity of zero-knowledge {\\em in the high-error regime}.\n  We say that a zero-knowledge argument is {\\em non-trivial} if the sum of its completeness, soundness and zero-knowledge errors is bounded away from $1$. Our results are as follows, assuming $\\mathsf{NP} \\not \\subseteq \\mathsf{ioP/poly}$:\n  1. {\\em Non-trivial} Non-Interactive ZK (NIZK) arguments for $\\mathsf{NP}$ imply the existence of OWFs. Using known amplification techniques, this result also provides an unconditional transformation from weak to standard NIZK proofs for all meaningful error parameters.\n  2. We also generalize to the interactive setting: {\\em Non-trivial} constant-round public-coin zero-knowledge arguments for $\\mathsf{NP}$ imply the existence of OWFs, and therefore also (standard) four-message zero-knowledge arguments for $\\mathsf{NP}$.\n  Prior to this work, one-way functions could be obtained from NIZKs that had constant zero-knowledge error $ε_{zk}$ and soundness error $ε_{s}$ satisfying $ε_{zk} + \\sqrt{ε_{s}} < 1$ [Chakraborty, Hulett and Khurana, CRYPTO'2025]. However, the regime where $ε_{zk} + \\sqrt{ε_{s}} \\geq 1$ remained open. This work closes the gap, and obtains new implications in the interactive setting. Our results and techniques could be useful stepping stones in the quest to construct one-way functions from worst-case hardness.","authors":["Suvradip Chakraborty","James Hulett","Dakshita Khurana","Kabir Tomer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04669v3","updated":"2026-02-19T18:55:25Z","published":"2025-08-06T17:37:04Z","title":"Cybersecurity of Quantum Key Distribution Implementations","summary":"Practical implementations of Quantum Key Distribution (QKD) often deviate from the theoretical protocols, exposing the implementations to various attacks even when the underlying (ideal) protocol is proven secure. We present new analysis tools and methodologies for quantum cybersecurity, adapting the concepts of vulnerabilities, attack surfaces, and exploits from classical cybersecurity to QKD implementation attacks. We also present three additional concepts, derived from the connection between classical and quantum cybersecurity: \"Quantum Fuzzing\", which is the first tool for black-box vulnerability research on QKD implementations; \"Reversed-Space Attacks\", which are a generic exploit method using the attack surface of imperfect receivers; and concrete quantum-mechanical definitions of \"Quantum Side-Channel Attacks\" and \"Quantum State-Channel Attacks\", meaningfully distinguishing them from each other and from other attacks. Using our tools, we analyze multiple existing QKD attacks and show that the \"Bright Illumination\" attack could have been found even with minimal knowledge of the device implementation. This work begins to bridge the gap between current analysis methods for experimental attacks on QKD implementations and the decades-long research in the field of classical cybersecurity, improving the practical security of QKD products and enhancing their usefulness in real-world systems.","authors":["Ittay Alfassi","Ran Gelles","Rotem Liss","Tal Mor"],"pdf_url":"","comment":"47 pages, 6 figures; this is an improved version of arXiv:1110.6573 [quant-ph] and arXiv:2011.02152 [quant-ph], extended to present a new perspective and additional methods; v3 includes a few clarifications regarding the definitions of Quantum Side-Channel Attacks and Quantum State-Channel Attacks"},{"id":"http://arxiv.org/abs/2602.17622v1","updated":"2026-02-19T18:42:40Z","published":"2026-02-19T18:42:40Z","title":"What Makes a Good LLM Agent for Real-world Penetration Testing?","summary":"LLM-based agents show promise for automating penetration testing, yet reported performance varies widely across systems and benchmarks. We analyze 28 LLM-based penetration testing systems and evaluate five representative implementations across three benchmarks of increasing complexity. Our analysis reveals two distinct failure modes: Type A failures stem from capability gaps (missing tools, inadequate prompts) that engineering readily addresses, while Type B failures persist regardless of tooling due to planning and state management limitations. We show that Type B failures share a root cause that is largely invariant to the underlying LLM: agents lack real-time task difficulty estimation. As a result, agents misallocate effort, over-commit to low-value branches, and exhaust context before completing attack chains.\n  Based on this insight, we present Excalibur, a penetration testing agent that couples strong tooling with difficulty-aware planning. A Tool and Skill Layer eliminates Type A failures through typed interfaces and retrieval-augmented knowledge. A Task Difficulty Assessment (TDA) mechanism addresses Type B failures by estimating tractability through four measurable dimensions (horizon estimation, evidence confidence, context load, and historical success) and uses these estimates to guide exploration-exploitation decisions within an Evidence-Guided Attack Tree Search (EGATS) framework. Excalibur achieves up to 91% task completion on CTF benchmarks with frontier models (39 to 49% relative improvement over baselines) and compromises 4 of 5 hosts on the GOAD Active Directory environment versus 2 by prior systems. These results show that difficulty-aware planning yields consistent end-to-end gains across models and addresses a limitation that model scaling alone does not eliminate.","authors":["Gelei Deng","Yi Liu","Yuekang Li","Ruozhao Yang","Xiaofei Xie","Jie Zhang","Han Qiu","Tianwei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17590v1","updated":"2026-02-19T18:12:01Z","published":"2026-02-19T18:12:01Z","title":"BMC4TimeSec: Verification Of Timed Security Protocols","summary":"We present BMC4TimeSec, an end-to-end tool for verifying Timed Security Protocols (TSP) based on SMT-based bounded model checking and multi-agent modelling in the form of Timed Interpreted Systems (TIS) and Timed Interleaved Interpreted Systems (TIIS). In BMC4TimeSec, TSP executions implement the TIS/TIIS environment (join actions, interleaving, delays, lifetimes), and knowledge automata implement the agents (evolution of participant knowledge, including the intruder). The code is publicly available on \\href{https://github.com/agazbrzezny/BMC4TimeSec}{GitHub}, as is a \\href{https://youtu.be/aNybKz6HwdA}{video} demonstration.","authors":["Agnieszka M. Zbrzezny"],"pdf_url":"","comment":"To appear in the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), May 25 - 29, 2026, Paphos, Cyprus"},{"id":"http://arxiv.org/abs/2512.01295v2","updated":"2026-02-19T18:03:10Z","published":"2025-12-01T05:28:59Z","title":"Systems Security Foundations for Agentic Computing","summary":"In recent years, agentic artificial intelligence (AI) systems are becoming increasingly widespread. These systems allow agents to use various tools, such as web browsers, compilers, and more. However, despite their popularity, agentic AI systems also introduce a myriad of security concerns, due to their constant interaction with third-party servers. For example, a malicious adversary can cause data exfiltration by executing prompt injection attacks, as well as other unwarranted behavior. These security concerns have recently motivated researchers to improve the safety and reliability of agentic systems. However, most of the literature on this topic is from the AI standpoint and lacks the system-security perspective and guarantees. In this work, we begin bridging this gap and present an analysis through the lens of classic cybersecurity research. Specifically, motivated by decades of progress in this domain, we identify short- and long-term research problems in agentic AI safety by examining end-to-end security properties of entire systems, rather than standalone AI models running in isolation. Our key goal is to examine where research challenges arise when applying traditional security principles in the context of AI agents and, as a secondary goal, distill these ideas for AI practitioners. Furthermore, we extensively cover 11 case studies of real-world attacks on agentic systems, as well as define a series of new research problems that are specific to this important domain.","authors":["Mihai Christodorescu","Earlence Fernandes","Ashish Hooda","Somesh Jha","Johann Rehberger","Kamalika Chaudhuri","Xiaohan Fu","Khawaja Shams","Guy Amir","Jihye Choi","Sarthak Choudhary","Nils Palumbo","Andrey Labunets","Nishit V. Pandya"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17490v1","updated":"2026-02-19T16:00:21Z","published":"2026-02-19T16:00:21Z","title":"Coin selection by Random Draw according to the Boltzmann distribution","summary":"Coin selection refers to the problem of choosing a set of tokens to fund a transaction in token-based payment systems such as, e.g., cryptocurrencies or central bank digital currencies (CBDCs). In this paper, we propose the Boltzmann Draw that is a probabilistic algorithm inspired by the principles of statistical physics. The algorithm relies on drawing tokens according to the Boltzmann distribution, serving as an extension and improvement of the Random Draw method. Numerical results demonstrate the effectiveness of our method in bounding the number of selected input tokens as well as reducing dust generation and limiting the token pool size in the wallet. Moreover, the probabilistic algorithm can be implemented efficiently, improves performance and respects privacy requirements - properties of significant relevance for current token-based technologies. We compare the Boltzmann draw to both the standard Random Draw and the Greedy algorithm. We argue that the former is superior to the latter in the sense of the above objectives. Our findings are relevant for token-based technologies, and are also of interest for CBDCs, which as a legal tender possibly needs to handle large transaction volumes at a high frequency.","authors":["Jan Lennart Bönsel","Michael Maurer","Silvio Petriconi","Andrea Tundis","Marc Winstel"],"pdf_url":"","comment":"11 pages, 8 figures, 1 table"},{"id":"http://arxiv.org/abs/2602.17488v1","updated":"2026-02-19T15:58:49Z","published":"2026-02-19T15:58:49Z","title":"Computational Hardness of Private Coreset","summary":"We study the problem of differentially private (DP) computation of coreset for the $k$-means objective. For a given input set of points, a coreset is another set of points such that the $k$-means objective for any candidate solution is preserved up to a multiplicative $(1 \\pm α)$ factor (and some additive factor).\n  We prove the first computational lower bounds for this problem. Specifically, assuming the existence of one-way functions, we show that no polynomial-time $(ε, 1/n^{ω(1)})$-DP algorithm can compute a coreset for $k$-means in the $\\ell_\\infty$-metric for some constant $α> 0$ (and some constant additive factor), even for $k=3$. For $k$-means in the Euclidean metric, we show a similar result but only for $α= Θ\\left(1/d^2\\right)$, where $d$ is the dimension.","authors":["Badih Ghazi","Cristóbal Guzmán","Pritish Kamath","Alexander Knop","Ravi Kumar","Pasin Manurangsi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17458v1","updated":"2026-02-19T15:25:09Z","published":"2026-02-19T15:25:09Z","title":"The CTI Echo Chamber: Fragmentation, Overlap, and Vendor Specificity in Twenty Years of Cyber Threat Reporting","summary":"Despite the high volume of open-source Cyber Threat Intelligence (CTI), our understanding of long-term threat actor-victim dynamics remains fragmented due to the lack of structured datasets and inconsistent reporting standards. In this paper, we present a large-scale automated analysis of open-source CTI reports spanning two decades. We develop a high-precision, LLM-based pipeline to ingest and structure 13,308 reports, extracting key entities such as attributed threat actors, motivations, victims, reporting vendors, and technical indicators (IoCs and TTPs). Our analysis quantifies the evolution of CTI information density and specialization, characterizing patterns that relate specific threat actors to motivations and victim profiles. Furthermore, we perform a meta-analysis of the CTI industry itself. We identify a fragmented ecosystem of distinct silos where vendors demonstrate significant geographic and sectoral reporting biases. Our marginal coverage analysis reveals that intelligence overlap between vendors is typically low: while a few core providers may offer broad situational awareness, additional sources yield diminishing returns. Overall, our findings characterize the structural biases inherent in the CTI ecosystem, enabling practitioners and researchers to better evaluate the completeness of their intelligence sources.","authors":["Manuel Suarez-Roman","Francesco Marciori","Mauro Conti","Juan Tapiador"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17454v1","updated":"2026-02-19T15:18:00Z","published":"2026-02-19T15:18:00Z","title":"Privacy in Theory, Bugs in Practice: Grey-Box Auditing of Differential Privacy Libraries","summary":"Differential privacy (DP) implementations are notoriously prone to errors, with subtle bugs frequently invalidating theoretical guarantees. Existing verification methods are often impractical: formal tools are too restrictive, while black-box statistical auditing is intractable for complex pipelines and fails to pinpoint the source of the bug. This paper introduces Re:cord-play, a gray-box auditing paradigm that inspects the internal state of DP algorithms. By running an instrumented algorithm on neighboring datasets with identical randomness, Re:cord-play directly checks for data-dependent control flow and provides concrete falsification of sensitivity violations by comparing declared sensitivity against the empirically measured distance between internal inputs. We generalize this to Re:cord-play-sample, a full statistical audit that isolates and tests each component, including untrusted ones. We show that our novel testing approach is both effective and necessary by auditing 12 open-source libraries, including SmartNoise SDK, Opacus, and Diffprivlib, and uncovering 13 privacy violations that impact their theoretical guarantees. We release our framework as an open-source Python package, thereby making it easy for DP developers to integrate effective, computationally inexpensive, and seamless privacy testing as part of their software development lifecycle.","authors":["Tudor Cebere","David Erb","Damien Desfontaines","Aurélien Bellet","Jack Fitzsimons"],"pdf_url":"","comment":"2026.3 PoPETS"},{"id":"http://arxiv.org/abs/2602.17452v1","updated":"2026-02-19T15:17:18Z","published":"2026-02-19T15:17:18Z","title":"Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge","summary":"We present Jolt Atlas, a zero-knowledge machine learning (zkML) framework that extends the Jolt proving system to model inference. Unlike zkVMs (zero-knowledge virtual machines), which emulate CPU instruction execution, Jolt Atlas adapts Jolt's lookup-centric approach and applies it directly to ONNX tensor operations. The ONNX computational model eliminates the need for CPU registers and simplifies memory consistency verification. In addition, ONNX is an open-source, portable format, which makes it easy to share and deploy models across different frameworks, hardware platforms, and runtime environments without requiring framework-specific conversions.\n  Our lookup arguments, which use sumcheck protocol, are well-suited for non-linear functions -- key building blocks in modern ML. We apply optimisations such as neural teleportation to reduce the size of lookup tables while preserving model accuracy, as well as several tensor-level verification optimisations detailed in this paper. We demonstrate that Jolt Atlas can prove model inference in memory-constrained environments -- a prover property commonly referred to as \\textit{streaming}. Furthermore, we discuss how Jolt Atlas achieves zero-knowledge through the BlindFold technique, as introduced in Vega. In contrast to existing zkML frameworks, we show practical proving times for classification, embedding, automated reasoning, and small language models.\n  Jolt Atlas enables cryptographic verification that can be run on-device, without specialised hardware. The resulting proofs are succinctly verifiable. This makes Jolt Atlas well-suited for privacy-centric and adversarial environments. In a companion work, we outline various use cases of Jolt Atlas, including how it serves as guardrails in agentic commerce and for trustless AI context (often referred to as \\textit{AI memory}).","authors":["Wyatt Benno","Alberto Centelles","Antoine Douchet","Khalil Gibran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17413v1","updated":"2026-02-19T14:43:48Z","published":"2026-02-19T14:43:48Z","title":"DAVE: A Policy-Enforcing LLM Spokesperson for Secure Multi-Document Data Sharing","summary":"In current inter-organizational data spaces, usage policies are enforced mainly at the asset level: a whole document or dataset is either shared or withheld. When only parts of a document are sensitive, providers who want to avoid leaking protected information typically must manually redact documents before sharing them, which is costly, coarse-grained, and hard to maintain as policies or partners change. We present DAVE, a usage policy-enforcing LLM spokesperson that answers questions over private documents on behalf of a data provider. Instead of releasing documents, the provider exposes a natural language interface whose responses are constrained by machine-readable usage policies. We formalize policy-violating information disclosure in this setting, drawing on usage control and information flow security, and introduce virtual redaction: suppressing sensitive information at query time without modifying source documents. We describe an architecture for integrating such a spokesperson with Eclipse Dataspace Components and ODRL-style policies, and outline an initial provider-side integration prototype in which QA requests are routed through a spokesperson service instead of triggering raw document transfer. Our contribution is primarily architectural: we do not yet implement or empirically evaluate the full enforcement pipeline. We therefore outline an evaluation methodology to assess security, utility, and performance trade-offs under benign and adversarial querying as a basis for future empirical work on systematically governed LLM access to multi-party data spaces.","authors":["René Brinkhege","Prahlad Menon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.16723v3","updated":"2026-02-19T14:43:35Z","published":"2025-05-22T14:32:23Z","title":"LLM Fingerprinting via Semantically Conditioned Watermarks","summary":"Most LLM fingerprinting methods teach the model to respond to a few fixed queries with predefined atypical responses (keys). This memorization often does not survive common deployment steps such as finetuning or quantization, and such keys can be easily detected and filtered from LLM responses, ultimately breaking the fingerprint. To overcome these limitations we introduce LLM fingerprinting via semantically conditioned watermarks, replacing fixed query sets with a broad semantic domain, and replacing brittle atypical keys with a statistical watermarking signal diffused throughout each response. After teaching the model to watermark its responses only to prompts from a predetermined domain e.g., French language, the model owner can use queries from that domain to reliably detect the fingerprint and verify ownership. As we confirm in our thorough experimental evaluation, our fingerprint is both stealthy and robust to all common deployment scenarios.","authors":["Thibaud Gloaguen","Robin Staab","Nikola Jovanović","Martin Vechev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.24368v2","updated":"2026-02-19T14:24:09Z","published":"2025-09-29T07:11:40Z","title":"Watermarking Diffusion Language Models","summary":"We introduce the first watermark tailored for diffusion language models (DLMs), an emergent LLM paradigm able to generate tokens in arbitrary order, in contrast to standard autoregressive language models (ARLMs) which generate tokens sequentially. While there has been much work in ARLM watermarking, a key challenge when attempting to apply these schemes directly to the DLM setting is that they rely on previously generated tokens, which are not always available with DLM generation. In this work we address this challenge by: (i) applying the watermark in expectation over the context even when some context tokens are yet to be determined, and (ii) promoting tokens which increase the watermark strength when used as context for other tokens. This is accomplished while keeping the watermark detector unchanged. Our experimental evaluation demonstrates that the DLM watermark leads to a >99% true positive rate with minimal quality impact and achieves similar robustness to existing ARLM watermarks, enabling for the first time reliable DLM watermarking.","authors":["Thibaud Gloaguen","Robin Staab","Nikola Jovanović","Martin Vechev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17345v1","updated":"2026-02-19T13:29:00Z","published":"2026-02-19T13:29:00Z","title":"What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?","summary":"Embodied AI systems (e.g., autonomous vehicles, service robots, and LLM-driven interactive agents) are rapidly transitioning from controlled environments to safety critical real-world deployments. Unlike disembodied AI, failures in embodied intelligence lead to irreversible physical consequences, raising fundamental questions about security, safety, and reliability. While existing research predominantly analyzes embodied AI through the lenses of Large Language Model (LLM) vulnerabilities or classical Cyber-Physical System (CPS) failures, this survey argues that these perspectives are individually insufficient to explain many observed breakdowns in modern embodied systems. We posit that a significant class of failures arises from embodiment-induced system-level mismatches, rather than from isolated model flaws or traditional CPS attacks. Specifically, we identify four core insights that explain why embodied AI is fundamentally harder to secure: (i) semantic correctness does not imply physical safety, as language-level reasoning abstracts away geometry, dynamics, and contact constraints; (ii) identical actions can lead to drastically different outcomes across physical states due to nonlinear dynamics and state uncertainty; (iii) small errors propagate and amplify across tightly coupled perception-decision-action loops; and (iv) safety is not compositional across time or system layers, enabling locally safe decisions to accumulate into globally unsafe behavior. These insights suggest that securing embodied AI requires moving beyond component-level defenses toward system-level reasoning about physical risk, uncertainty, and failure propagation.","authors":["Boyang Ma","Hechuan Guo","Peizhuo Lv","Minghui Xu","Xuelong Dai","YeChao Zhang","Yijun Yang","Yue Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17307v1","updated":"2026-02-19T12:18:28Z","published":"2026-02-19T12:18:28Z","title":"Security of the Fischlin Transform in Quantum Random Oracle Model","summary":"The Fischlin transform yields non-interactive zero-knowledge proofs with straight-line extractability in the classical random oracle model. This is done by forcing a prover to generate multiple accepting transcripts through a proof-of-work mechanism. Whether the Fischlin transform is straight-line extractable against quantum adversaries has remained open due to the difficulty of reasoning about the likelihood of query transcripts in the quantum-accessible random oracle model (QROM), even when using the compressed oracle methodology. In this work, we prove that the Fischlin transform remains straight-line extractable in the QROM, via an extractor based on the compressed oracle. This establishes the post-quantum security of the Fischlin transform, providing a post-quantum straight-line extractable NIZK alternative to Pass' transform with smaller proof size. Our techniques include tail bounds for sums of independent random variables and for martingales as well as symmetrization, query amplitude and quantum union bound arguments.","authors":["Christian Majenz","Jaya Sharma"],"pdf_url":"","comment":"35 pages"},{"id":"http://arxiv.org/abs/2504.21730v2","updated":"2026-02-19T12:16:56Z","published":"2025-04-30T15:21:25Z","title":"Cert-SSBD: Certified Backdoor Defense with Sample-Specific Smoothing Noises","summary":"Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an attacker manipulates a small portion of the training data to implant hidden backdoors into the model. The compromised model behaves normally on clean samples but misclassifies backdoored samples into the attacker-specified target class, posing a significant threat to real-world DNN applications. Currently, several empirical defense methods have been proposed to mitigate backdoor attacks, but they are often bypassed by more advanced backdoor techniques. In contrast, certified defenses based on randomized smoothing have shown promise by adding random noise to training and testing samples to counteract backdoor attacks. In this paper, we reveal that existing randomized smoothing defenses implicitly assume that all samples are equidistant from the decision boundary. However, it may not hold in practice, leading to suboptimal certification performance. To address this issue, we propose a sample-specific certified backdoor defense method, termed Cert-SSB. Cert-SSB first employs stochastic gradient ascent to optimize the noise magnitude for each sample, ensuring a sample-specific noise level that is then applied to multiple poisoned training sets to retrain several smoothed models. After that, Cert-SSB aggregates the predictions of multiple smoothed models to generate the final robust prediction. In particular, in this case, existing certification methods become inapplicable since the optimized noise varies across different samples. To conquer this challenge, we introduce a storage-update-based certification method, which dynamically adjusts each sample's certification region to improve certification performance. We conduct extensive experiments on multiple benchmark datasets, demonstrating the effectiveness of our proposed method. Our code is available at https://github.com/NcepuQiaoTing/Cert-SSB.","authors":["Ting Qiao","Yingjia Wang","Xing Liu","Sixing Wu","Jianbin Li","Yiming Li"],"pdf_url":"","comment":"To appear in TIFS 2026. 21 pages"},{"id":"http://arxiv.org/abs/2602.17301v1","updated":"2026-02-19T12:11:35Z","published":"2026-02-19T12:11:35Z","title":"Grothendieck Topologies and Sheaf-Theoretic Foundations of Cryptographic Security: Attacker Models and $Σ$-Protocols as the First Step","summary":"Cryptographic security is traditionally formulated using game-based or simulation-based definitions. In this paper, we propose a structural reformulation of cryptographic security based on Grothendieck topologies and sheaf theory.\n  Our key idea is to model attacker observations as a Grothendieck site, where covering families represent admissible decompositions of partial information determined by efficient simulation. Within this framework, protocol transcripts naturally form sheaves, and security properties arise as geometric conditions.\n  As a first step, we focus on $Σ$-protocols. We show that the transcript structure of any $Σ$-protocol defines a torsor in the associated topos of sheaves. Local triviality of this torsor corresponds to zero-knowledge, while the absence of global sections reflects soundness. A concrete analysis of the Schnorr $Σ$-protocol is provided to illustrate the construction.\n  This sheaf-theoretic perspective offers a conceptual explanation of simulation-based security and suggests a geometric foundation for further cryptographic abstractions.","authors":["Takao Inoué"],"pdf_url":"","comment":"9 pages (12pt). We present a categorical and Grothendieck-topological model of Σ-protocols, providing a formal structural interpretation of interactive proof systems, knowledge soundness, and attacker models"},{"id":"http://arxiv.org/abs/2602.17223v1","updated":"2026-02-19T10:15:51Z","published":"2026-02-19T10:15:51Z","title":"Privacy-Preserving Mechanisms Enable Cheap Verifiable Inference of LLMs","summary":"As large language models (LLMs) continue to grow in size, fewer users are able to host and run models locally. This has led to increased use of third-party hosting services. However, in this setting, there is a lack of guarantees on the computation performed by the inference provider. For example, a dishonest provider may replace an expensive large model with a cheaper-to-run weaker model and return the results from the weaker model to the user. Existing tools to verify inference typically rely on methods from cryptography such as zero-knowledge proofs (ZKPs), but these add significant computational overhead, and remain infeasible for use for large models. In this work, we develop a new insight -- that given a method for performing private LLM inference, one can obtain forms of verified inference at marginal extra cost. Specifically, we propose two new protocols which leverage privacy-preserving LLM inference in order to provide guarantees over the inference that was carried out. Our approaches are cheap, requiring the addition of a few extra tokens of computation, and have little to no downstream impact. As the fastest privacy-preserving inference methods are typically faster than ZK methods, the proposed protocols also improve verification runtime. Our work provides novel insights into the connections between privacy and verifiability in LLM inference.","authors":["Arka Pal","Louai Zahran","William Gvozdjak","Akilesh Potti","Micah Goldblum"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.06530v2","updated":"2026-02-19T08:33:25Z","published":"2026-02-06T09:32:10Z","title":"Universal Anti-forensics Attack against Image Forgery Detection via Multi-modal Guidance","summary":"The rapid advancement of AI-Generated Content (AIGC) technologies poses significant challenges for authenticity assessment. However, existing evaluation protocols largely overlook anti-forensics attack, failing to ensure the comprehensive robustness of state-of-the-art AIGC detectors in real-world applications. To bridge this gap, we propose ForgeryEraser, a framework designed to execute universal anti-forensics attack without access to the target AIGC detectors. We reveal an adversarial vulnerability stemming from the systemic reliance on Vision-Language Models (VLMs) as shared backbones (e.g., CLIP), where downstream AIGC detectors inherit the feature space of these publicly accessible models. Instead of traditional logit-based optimization, we design a multi-modal guidance loss to drive forged image embeddings within the VLM feature space toward text-derived authentic anchors to erase forgery traces, while repelling them from forgery anchors. Extensive experiments demonstrate that ForgeryEraser causes substantial performance degradation to advanced AIGC detectors on both global synthesis and local editing benchmarks. Moreover, ForgeryEraser induces explainable forensic models to generate explanations consistent with authentic images for forged images. Our code will be made publicly available.","authors":["Haipeng Li","Rongxuan Peng","Anwei Luo","Shunquan Tan","Changsheng Chen","Anastasia Antsiferova"],"pdf_url":"","comment":"17 pages, 11 figures"},{"id":"http://arxiv.org/abs/2601.21318v2","updated":"2026-02-19T07:21:23Z","published":"2026-01-29T06:27:05Z","title":"QCL-IDS: Quantum Continual Learning for Intrusion Detection with Fidelity-Anchored Stability and Generative Replay","summary":"Continual intrusion detection must absorb newly emerging attack stages while retaining legacy detection capability under strict operational constraints, including bounded compute and qubit budgets and privacy rules that preclude long-term storage of raw telemetry. We propose QCL-IDS, a quantum-centric continual-learning framework that co-designs stability and privacy-governed rehearsal for NISQ-era pipelines. Its core component, Q-FISH (Quantum Fisher Anchors), enforces retention using a compact anchor coreset through (i) sensitivity-weighted parameter constraints and (ii) a fidelity-based functional anchoring term that directly limits decision drift on representative historical traffic. To regain plasticity without retaining sensitive flows, QCL-IDS further introduces privacy-preserved quantum generative replay (QGR) via frozen, task-conditioned generator snapshots that synthesize bounded rehearsal samples. Across a three-stage attack stream on UNSW-NB15 and CICIDS2017, QCL-IDS consistently attains the best retention-adaptation trade-off: the gradient-anchor configuration achieves mean Attack-F1 = 0.941 with forgetting = 0.005 on UNSW-NB15 and mean Attack-F1 = 0.944 with forgetting = 0.004 on CICIDS2017, versus 0.800/0.138 and 0.803/0.128 for sequential fine-tuning, respectively.","authors":["Zirui Zhu","Xiangyang Li"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2510.00167v2","updated":"2026-02-19T05:56:49Z","published":"2025-09-30T18:39:36Z","title":"Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI","summary":"Autonomous drones must often respond to sudden events, such as alarms, faults, or unexpected changes in their environment, that require immediate and adaptive decision-making. Traditional approaches rely on safety engineers hand-coding large sets of recovery rules, but this strategy cannot anticipate the vast range of real-world contingencies and quickly becomes incomplete. Recent advances in embodied AI, powered by large visual language models, provide commonsense reasoning to assess context and generate appropriate actions in real time. We demonstrate this capability in a simulated urban benchmark in the Unreal Engine, where drones dynamically interpret their surroundings and decide on sudden maneuvers for safe landings. Our results show that embodied AI makes possible a new class of adaptive recovery and decision-making pipelines that were previously infeasible to design by hand, advancing resilience and safety in autonomous aerial systems.","authors":["Diego Ortiz Barbosa","Mohit Agrawal","Yash Malegaonkar","Luis Burbano","Axel Andersson","György Dán","Henrik Sandberg","Alvaro A. Cardenas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16708v2","updated":"2026-02-19T03:40:05Z","published":"2026-02-18T18:57:12Z","title":"Policy Compiler for Secure Agentic Systems","summary":"LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement.\n  Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture. Instead, PCAS models the agentic system state as a dependency graph capturing causal relationships among events such as tool calls, tool results, and messages. Policies are expressed in a Datalog-derived language, as declarative rules that account for transitive information flow and cross-agent provenance. A reference monitor intercepts all actions and blocks violations before execution, providing deterministic enforcement independent of model reasoning.\n  PCAS takes an existing agent implementation and a policy specification, and compiles them into an instrumented system that is policy-compliant by construction, with no security-specific restructuring required. We evaluate PCAS on three case studies: information flow policies for prompt injection defense, approval workflows in a multi-agent pharmacovigilance system, and organizational policies for customer service. On customer service tasks, PCAS improves policy compliance from 48% to 93% across frontier models, with zero policy violations in instrumented runs.","authors":["Nils Palumbo","Sarthak Choudhary","Jihye Choi","Prasad Chalasani","Somesh Jha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.06317v4","updated":"2026-02-19T03:38:01Z","published":"2024-11-10T00:28:58Z","title":"Harpocrates: A Statically Typed Privacy Conscious Programming Framework","summary":"In this paper, we introduce Harpocrates, a compiler plugin and a framework pair for Scala that binds the privacy policies to the data during data creation in form of oblivious membranes. Harpocrates eliminates raw data for a policy protected type from the application, ensuring it can only exist in protected form and centralizes the policy checking to the policy declaration site, making the privacy logic easy to maintain and verify. Instead of approaching privacy from an information flow verification perspective, Harpocrates allow the data to flow freely throughout the application, inside the policy membranes but enforces the policies when the data is tried to be accessed, mutated, declassified or passed through the application boundary. The centralization of the policies allow the maintainers to change the enforced logic simply by updating a single function while keeping the rest of the application oblivious to the change. Especially in a setting where the data definition is shared by multiple applications, the publisher can update the policies without requiring the dependent applications to make any changes beyond updating the dependency version.","authors":["Sinan Pehlivanoglu","Malte Schwarzkopf"],"pdf_url":"","comment":"Draft work"},{"id":"http://arxiv.org/abs/2602.16980v1","updated":"2026-02-19T00:39:12Z","published":"2026-02-19T00:39:12Z","title":"Discovering Universal Activation Directions for PII Leakage in Language Models","summary":"Modern language models exhibit rich internal structure, yet little is known about how privacy-sensitive behaviors, such as personally identifiable information (PII) leakage, are represented and modulated within their hidden states. We present UniLeak, a mechanistic-interpretability framework that identifies universal activation directions: latent directions in a model's residual stream whose linear addition at inference time consistently increases the likelihood of generating PII across prompts. These model-specific directions generalize across contexts and amplify PII generation probability, with minimal impact on generation quality. UniLeak recovers such directions without access to training data or groundtruth PII, relying only on self-generated text. Across multiple models and datasets, steering along these universal directions substantially increases PII leakage compared to existing prompt-based extraction methods. Our results offer a new perspective on PII leakage: the superposition of a latent signal in the model's representations, enabling both risk amplification and mitigation.","authors":["Leo Marchyok","Zachary Coalson","Sungho Keum","Sooel Son","Sanghyun Hong"],"pdf_url":"","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2602.16977v1","updated":"2026-02-19T00:33:35Z","published":"2026-02-19T00:33:35Z","title":"Fail-Closed Alignment for Large Language Models","summary":"We identify a structural weakness in current large language model (LLM) alignment: modern refusal mechanisms are fail-open. While existing approaches encode refusal behaviors across multiple latent features, suppressing a single dominant feature$-$via prompt-based jailbreaks$-$can cause alignment to collapse, leading to unsafe generation. Motivated by this, we propose fail-closed alignment as a design principle for robust LLM safety: refusal mechanisms should remain effective even under partial failures via redundant, independent causal pathways. We present a concrete instantiation of this principle: a progressive alignment framework that iteratively identifies and ablates previously learned refusal directions, forcing the model to reconstruct safety along new, independent subspaces. Across four jailbreak attacks, we achieve the strongest overall robustness while mitigating over-refusal and preserving generation quality, with small computational overhead. Our mechanistic analyses confirm that models trained with our method encode multiple, causally independent refusal directions that prompt-based jailbreaks cannot suppress simultaneously, providing empirical support for fail-closed alignment as a principled foundation for robust LLM safety.","authors":["Zachary Coalson","Beth Sohler","Aiden Gabriel","Sanghyun Hong"],"pdf_url":"","comment":"Pre-print"}]},"2026-02-23T00:00:00Z":{"Artificial Intelligence (Agents & Multi-Agent Systems)":[{"id":"http://arxiv.org/abs/2602.20159v1","updated":"2026-02-23T18:59:41Z","published":"2026-02-23T18:59:41Z","title":"A Very Big Video Reasoning Suite","summary":"Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .","authors":["Maijunxian Wang","Ruisi Wang","Juyi Lin","Ran Ji","Thaddäus Wiedemer","Qingying Gao","Dezhi Luo","Yaoyao Qian","Lianyu Huang","Zelong Hong","Jiahui Ge","Qianli Ma","Hang He","Yifan Zhou","Lingzi Guo","Lantao Mei","Jiachen Li","Hanwen Xing","Tianqi Zhao","Fengyuan Yu","Weihang Xiao","Yizheng Jiao","Jianheng Hou","Danyang Zhang","Pengcheng Xu","Boyang Zhong","Zehong Zhao","Gaoyun Fang","John Kitaoka","Yile Xu","Hua Xu","Kenton Blacutt","Tin Nguyen","Siyuan Song","Haoran Sun","Shaoyue Wen","Linyang He","Runming Wang","Yanzhi Wang","Mengyue Yang","Ziqiao Ma","Raphaël Millière","Freda Shi","Nuno Vasconcelos","Daniel Khashabi","Alan Yuille","Yilun Du","Ziming Liu","Bo Li","Dahua Lin","Ziwei Liu","Vikash Kumar","Yijiang Li","Lei Yang","Zhongang Cai","Hokin Deng"],"pdf_url":"","comment":"Homepage: https://video-reason.com/"},{"id":"http://arxiv.org/abs/2602.20152v1","updated":"2026-02-23T18:59:04Z","published":"2026-02-23T18:59:04Z","title":"Behavior Learning (BL): Learning Hierarchical Optimization Structures from Data","summary":"Inspired by behavioral science, we propose Behavior Learning (BL), a novel general-purpose machine learning framework that learns interpretable and identifiable optimization structures from data, ranging from single optimization problems to hierarchical compositions. It unifies predictive performance, intrinsic interpretability, and identifiability, with broad applicability to scientific domains involving optimization. BL parameterizes a compositional utility function built from intrinsically interpretable modular blocks, which induces a data distribution for prediction and generation. Each block represents and can be written in symbolic form as a utility maximization problem (UMP), a foundational paradigm in behavioral science and a universal framework of optimization. BL supports architectures ranging from a single UMP to hierarchical compositions, the latter modeling hierarchical optimization structures. Its smooth and monotone variant (IBL) guarantees identifiability. Theoretically, we establish the universal approximation property of BL, and analyze the M-estimation properties of IBL. Empirically, BL demonstrates strong predictive performance, intrinsic interpretability and scalability to high-dimensional data. Code: https://github.com/MoonYLiang/Behavior-Learning ; install via pip install blnetwork.","authors":["Zhenyao Ma","Yue Liang","Dongxu Li"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.20144v1","updated":"2026-02-23T18:54:32Z","published":"2026-02-23T18:54:32Z","title":"Agentic AI for Scalable and Robust Optical Systems Control","summary":"We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structured tool abstraction layer. We implement 64 standardized MCP tools across 8 representative optical devices and construct a 410-task benchmark to evaluate request understanding, role-aware responses, multi-step coordination, robustness to linguistic variation, and error handling. We assess two deployment configurations--commercial online LLMs and locally hosted open-source LLMs--and compare them with LLM-based code generation baselines. AgentOptics achieves 87.7%--99.0% average task success rates, significantly outperforming code-generation approaches, which reach up to 50% success. We further demonstrate broader applicability through five case studies extending beyond device-level control to system orchestration, monitoring, and closed-loop optimization. These include DWDM link provisioning and coordinated monitoring of coherent 400 GbE and analog radio-over-fiber (ARoF) channels; autonomous characterization and bias optimization of a wideband ARoF link carrying 5G fronthaul traffic; multi-span channel provisioning with launch power optimization; closed-loop fiber polarization stabilization; and distributed acoustic sensing (DAS)-based fiber monitoring with LLM-assisted event detection. These results establish AgentOptics as a scalable, robust paradigm for autonomous control and orchestration of heterogeneous optical systems.","authors":["Zehao Wang","Mingzhe Han","Wei Cheng","Yue-Kai Huang","Philip Ji","Denton Wu","Mahdi Safari","Flemming Holtorf","Kenaish AlQubaisi","Norbert M. Linke","Danyang Zhuo","Yiran Chen","Ting Wang","Dirk Englund","Tingjun Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20141v1","updated":"2026-02-23T18:53:09Z","published":"2026-02-23T18:53:09Z","title":"Recurrent Structural Policy Gradient for Partially Observable Mean Field Games","summary":"Mean Field Games (MFGs) provide a principled framework for modeling interactions in large population models: at scale, population dynamics become deterministic, with uncertainty entering only through aggregate shocks, or common noise. However, algorithmic progress has been limited since model-free methods are too high variance and exact methods scale poorly. Recent Hybrid Structural Methods (HSMs) use Monte Carlo rollouts for the common noise in combination with exact estimation of the expected return, conditioned on those samples. However, HSMs have not been scaled to Partially Observable settings. We propose Recurrent Structural Policy Gradient (RSPG), the first history-aware HSM for settings involving public information. We also introduce MFAX, our JAX-based framework for MFGs. By leveraging known transition dynamics, RSPG achieves state-of-the-art performance as well as an order-of-magnitude faster convergence and solves, for the first time, a macroeconomics MFG with heterogeneous agents, common noise and history-aware policies. MFAX is publicly available at: https://github.com/CWibault/mfax.","authors":["Clarisse Wibault","Johannes Forkel","Sebastian Towers","Tiphaine Wibault","Juan Duque","George Whittle","Andreas Schaab","Yucheng Yang","Chiyuan Wang","Michael Osborne","Benjamin Moll","Jakob Foerster"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16666v2","updated":"2026-02-23T18:49:07Z","published":"2026-02-18T18:05:44Z","title":"Towards a Science of AI Agent Reliability","summary":"AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.","authors":["Stephan Rabanser","Sayash Kapoor","Peter Kirgis","Kangheng Liu","Saiteja Utpala","Arvind Narayanan"],"pdf_url":"","comment":"Interactive dashboard available at: https://hal.cs.princeton.edu/reliability"},{"id":"http://arxiv.org/abs/2512.01149v2","updated":"2026-02-23T18:46:56Z","published":"2025-11-30T23:59:37Z","title":"A Benchmark of Causal vs. Correlation AI for Predictive Maintenance","summary":"Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study benchmarks eight predictive models, ranging from baseline statistical approaches to Bayesian structural causal methods, on a dataset of 10,000 CNC machines with a 3.3 percent failure prevalence. While ensemble correlation-based models such as Random Forest (L4) achieve the highest raw cost savings (70.8 percent reduction), the Bayesian Structural Causal Model (L7) delivers competitive financial performance (66.4 percent cost reduction) with an inherent ability of failure attribution, which correlation-based models do not readily provide. The model achieves perfect attribution for HDF, PWF, and OSF failure types. These results suggest that causal methods, when combined with domain knowledge and Bayesian inference, offer a potentially favorable trade-off between predictive performance and operational interpretability in predictive maintenance applications.","authors":["Shaunak Dhande","Chutian Ma","Giacinto Paolo Saggese","Paul Smith","Krishna Taduri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.16547v3","updated":"2026-02-23T18:46:55Z","published":"2025-05-22T11:37:39Z","title":"Find the Fruit: Zero-Shot Sim2Real RL for Occlusion-Aware Plant Manipulation","summary":"Autonomous harvesting in the open presents a complex manipulation problem. In most scenarios, an autonomous system has to deal with significant occlusion and require interaction in the presence of large structural uncertainties (every plant is different). Perceptual and modeling uncertainty make design of reliable manipulation controllers for harvesting challenging, resulting in poor performance during deployment. We present a sim2real reinforcement learning (RL) framework for occlusion-aware plant manipulation, where a policy is learned entirely in simulation to reposition stems and leaves to reveal target fruit(s). In our proposed approach, we decouple high-level kinematic planning from low-level compliant control which simplifies the sim2real transfer. This decomposition allows the learned policy to generalize across multiple plants with different stiffness and morphology. In experiments with multiple real-world plant setups, our system achieves up to 86.7% success in exposing target fruits, demonstrating robustness to occlusion variation and structural uncertainty.","authors":["Nitesh Subedi","Hsin-Jung Yang","Devesh K. Jha","Soumik Sarkar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20135v1","updated":"2026-02-23T18:46:27Z","published":"2026-02-23T18:46:27Z","title":"KNIGHT: Knowledge Graph-Driven Multiple-Choice Question Generation with Adaptive Hardness Calibration","summary":"With the rise of large language models (LLMs), they have become instrumental in applications such as Retrieval-Augmented Generation (RAG). Yet evaluating these systems remains bottlenecked by the time and cost of building specialized assessment datasets. We introduce KNIGHT, an LLM-based, knowledge-graph-driven framework for generating multiple-choice question (MCQ) datasets from external sources. KNIGHT constructs a topic-specific knowledge graph, a structured and parsimonious summary of entities and relations, that can be reused to generate instructor-controlled difficulty levels, including multi-hop questions, without repeatedly re-feeding the full source text. This knowledge graph acts as a compressed, reusable state, making question generation a cheap read over the graph. We instantiate KNIGHT on Wikipedia/Wikidata while keeping the framework domain- and ontology-agnostic. As a case study, KNIGHT produces six MCQ datasets in History, Biology, and Mathematics. We evaluate quality on five criteria: fluency, unambiguity (single correct answer), topic relevance, option uniqueness, and answerability given the provided sources (as a proxy for hallucination). Results show that KNIGHT enables token- and cost-efficient generation from a reusable graph representation, achieves high quality across these criteria, and yields model rankings aligned with MMLU-style benchmarks, while supporting topic-specific and difficulty-controlled evaluation.","authors":["Mohammad Amanlou","Erfan Shafiee Moghaddam","Yasaman Amou Jafari","Mahdi Noori","Farhan Farsi","Behnam Bahrak"],"pdf_url":"","comment":"Accepted at the Third Conference on Parsimony and Learning (CPAL 2026). 36 pages, 12 figures. (Equal contribution: Yasaman Amou Jafari and Mahdi Noori.)"},{"id":"http://arxiv.org/abs/2602.20134v1","updated":"2026-02-23T18:45:55Z","published":"2026-02-23T18:45:55Z","title":"Modeling Epidemiological Dynamics Under Adversarial Data and User Deception","summary":"Epidemiological models increasingly rely on self-reported behavioral data such as vaccination status, mask usage, and social distancing adherence to forecast disease transmission and assess the impact of non-pharmaceutical interventions (NPIs). While such data provide valuable real-time insights, they are often subject to strategic misreporting, driven by individual incentives to avoid penalties, access benefits, or express distrust in public health authorities. To account for such human behavior, in this paper, we introduce a game-theoretic framework that models the interaction between the population and a public health authority as a signaling game. Individuals (senders) choose how to report their behaviors, while the public health authority (receiver) updates their epidemiological model(s) based on potentially distorted signals. Focusing on deception around masking and vaccination, we characterize analytically game equilibrium outcomes and evaluate the degree to which deception can be tolerated while maintaining epidemic control through policy interventions. Our results show that separating equilibria-with minimal deception-drive infections to near zero over time. Remarkably, even under pervasive dishonesty in pooling equilibria, well-designed sender and receiver strategies can still maintain effective epidemic control. This work advances the understanding of adversarial data in epidemiology and offers tools for designing more robust public health models in the presence of strategic user behavior.","authors":["Yiqi Su","Christo Kurisummoottil Thomas","Walid Saad","Bud Mishra","Naren Ramakrishnan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20133v1","updated":"2026-02-23T18:45:31Z","published":"2026-02-23T18:45:31Z","title":"AdaEvolve: Adaptive LLM Driven Zeroth-Order Optimization","summary":"The paradigm of automated program generation is shifting from one-shot generation to inference-time search, where Large Language Models (LLMs) function as semantic mutation operators within evolutionary loops. While effective, these systems are currently governed by static schedules that fail to account for the non-stationary dynamics of the search process. This rigidity results in substantial computational waste, as resources are indiscriminately allocated to stagnating populations while promising frontiers remain under-exploited. We introduce AdaEvolve, a framework that reformulates LLM-driven evolution as a hierarchical adaptive optimization problem. AdaEvolve uses an \"accumulated improvement signal\" to unify decisions across three levels: Local Adaptation, which dynamically modulates the exploration intensity within a population of solution candidates; Global Adaptation, which routes the global resource budget via bandit-based scheduling across different solution candidate populations; and Meta-Guidance which generates novel solution tactics based on the previously generated solutions and their corresponding improvements when the progress stalls. We demonstrate that AdaEvolve consistently outperforms the open-sourced baselines across 185 different open-ended optimization problems including combinatorial, systems optimization and algorithm design problems.","authors":["Mert Cemri","Shubham Agrawal","Akshat Gupta","Shu Liu","Audrey Cheng","Qiuyang Mang","Ashwin Naren","Lutfi Eren Erdogan","Koushik Sen","Matei Zaharia","Alex Dimakis","Ion Stoica"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20130v1","updated":"2026-02-23T18:42:50Z","published":"2026-02-23T18:42:50Z","title":"To Reason or Not to: Selective Chain-of-Thought in Medical Question Answering","summary":"Objective: To improve the efficiency of medical question answering (MedQA) with large language models (LLMs) by avoiding unnecessary reasoning while maintaining accuracy.\n  Methods: We propose Selective Chain-of-Thought (Selective CoT), an inference-time strategy that first predicts whether a question requires reasoning and generates a rationale only when needed. Two open-source LLMs (Llama-3.1-8B and Qwen-2.5-7B) were evaluated on four biomedical QA benchmarks-HeadQA, MedQA-USMLE, MedMCQA, and PubMedQA. Metrics included accuracy, total generated tokens, and inference time.\n  Results: Selective CoT reduced inference time by 13-45% and token usage by 8-47% with minimal accuracy loss ($\\leq$4\\%). In some model-task pairs, it achieved both higher accuracy and greater efficiency than standard CoT. Compared with fixed-length CoT, Selective CoT reached similar or superior accuracy at substantially lower computational cost.\n  Discussion: Selective CoT dynamically balances reasoning depth and efficiency by invoking explicit reasoning only when beneficial, reducing redundancy on recall-type questions while preserving interpretability.\n  Conclusion: Selective CoT provides a simple, model-agnostic, and cost-effective approach for medical QA, aligning reasoning effort with question complexity to enhance real-world deployability of LLM-based clinical systems.","authors":["Zaifu Zhan","Min Zeng","Shuang Zhou","Yiran Song","Xiaoyi Chen","Yu Hou","Yifan Wu","Yang Ruan","Rui Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20122v1","updated":"2026-02-23T18:37:49Z","published":"2026-02-23T18:37:49Z","title":"NanoKnow: How to Know What Your Language Model Knows","summary":"How do large language models (LLMs) know what they know? Answering this question has been difficult because pre-training data is often a \"black box\" -- unknown or inaccessible. The recent release of nanochat -- a family of small LLMs with fully open pre-training data -- addresses this as it provides a transparent view into where a model's parametric knowledge comes from. Towards the goal of understanding how knowledge is encoded by LLMs, we release NanoKnow, a benchmark dataset that partitions questions from Natural Questions and SQuAD into splits based on whether their answers are present in nanochat's pre-training corpus. Using these splits, we can now properly disentangle the sources of knowledge that LLMs rely on when producing an output. To demonstrate NanoKnow's utility, we conduct experiments using eight nanochat checkpoints. Our findings show: (1) closed-book accuracy is strongly influenced by answer frequency in the pre-training data, (2) providing external evidence can mitigate this frequency dependence, (3) even with external evidence, models are more accurate when answers were seen during pre-training, demonstrating that parametric and external knowledge are complementary, and (4) non-relevant information is harmful, with accuracy decreasing based on both the position and the number of non-relevant contexts. We release all NanoKnow artifacts at https://github.com/castorini/NanoKnow.","authors":["Lingwei Gu","Nour Jedidi","Jimmy Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2206.13174v2","updated":"2026-02-23T18:36:24Z","published":"2022-06-27T10:32:47Z","title":"Towards Unifying Perceptual Reasoning and Logical Reasoning","summary":"An increasing number of scientific experiments support the view of perception as Bayesian inference, which is rooted in Helmholtz's view of perception as unconscious inference. Recent study of logic presents a view of logical reasoning as Bayesian inference. In this paper, we give a simple probabilistic model that is applicable to both perceptual reasoning and logical reasoning. We show that the model unifies the two essential processes common in perceptual and logical systems: on the one hand, the process by which perceptual and logical knowledge is derived from another knowledge, and on the other hand, the process by which such knowledge is derived from data. We fully characterise the model in terms of logical consequence relations.","authors":["Hiroyuki Kido"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20119v1","updated":"2026-02-23T18:35:18Z","published":"2026-02-23T18:35:18Z","title":"NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning","summary":"Solving long-horizon tasks requires robots to integrate high-level semantic reasoning with low-level physical interaction. While vision-language models (VLMs) and video generation models can decompose tasks and imagine outcomes, they often lack the physical grounding necessary for real-world execution. We introduce NovaPlan, a hierarchical framework that unifies closed-loop VLM and video planning with geometrically grounded robot execution for zero-shot long-horizon manipulation. At the high level, a VLM planner decomposes tasks into sub-goals and monitors robot execution in a closed loop, enabling the system to recover from single-step failures through autonomous re-planning. To compute low-level robot actions, we extract and utilize both task-relevant object keypoints and human hand poses as kinematic priors from the generated videos, and employ a switching mechanism to choose the better one as a reference for robot actions, maintaining stable execution even under heavy occlusion or depth inaccuracy. We demonstrate the effectiveness of NovaPlan on three long-horizon tasks and the Functional Manipulation Benchmark (FMB). Our results show that NovaPlan can perform complex assembly tasks and exhibit dexterous error recovery behaviors without any prior demonstrations or training. Project page: https://nova-plan.github.io/","authors":["Jiahui Fu","Junyu Nan","Lingfeng Sun","Hongyu Li","Jianing Qian","Jennifer L. Barry","Kris Kitani","George Konidaris"],"pdf_url":"","comment":"25 pages, 15 figures. Project webpage: https://nova-plan.github.io/"},{"id":"http://arxiv.org/abs/2602.20117v1","updated":"2026-02-23T18:34:29Z","published":"2026-02-23T18:34:29Z","title":"ReSyn: Autonomously Scaling Synthetic Environments for Reasoning Models","summary":"Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising approach for training reasoning language models (RLMs) by leveraging supervision from verifiers. Although verifier implementation is easier than solution annotation for many tasks, existing synthetic data generation methods remain largely solution-centric, while verifier-based methods rely on a few hand-crafted procedural environments. In this work, we scale RLVR by introducing ReSyn, a pipeline that generates diverse reasoning environments equipped with instance generators and verifiers, covering tasks such as constraint satisfaction, algorithmic puzzles, and spatial reasoning. A Qwen2.5-7B-Instruct model trained with RL on ReSyn data achieves consistent gains across reasoning benchmarks and out-of-domain math benchmarks, including a 27\\% relative improvement on the challenging BBEH benchmark. Ablations show that verifier-based supervision and increased task diversity both contribute significantly, providing empirical evidence that generating reasoning environments at scale can enhance reasoning abilities in RLMs","authors":["Andre He","Nathaniel Weir","Kaj Bostrom","Allen Nie","Darion Cassel","Sam Bayless","Huzefa Rangwala"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20114v1","updated":"2026-02-23T18:33:16Z","published":"2026-02-23T18:33:16Z","title":"Benchmarking Unlearning for Vision Transformers","summary":"Research in machine unlearning (MU) has gained strong momentum: MU is now widely regarded as a critical capability for building safe and fair AI. In parallel, research into transformer architectures for computer vision tasks has been highly successful: Increasingly, Vision Transformers (VTs) emerge as strong alternatives to CNNs. Yet, MU research for vision tasks has largely centered on CNNs, not VTs. While benchmarking MU efforts have addressed LLMs, diffusion models, and CNNs, none exist for VTs. This work is the first to attempt this, benchmarking MU algorithm performance in different VT families (ViT and Swin-T) and at different capacities. The work employs (i) different datasets, selected to assess the impacts of dataset scale and complexity; (ii) different MU algorithms, selected to represent fundamentally different approaches for MU; and (iii) both single-shot and continual unlearning protocols. Additionally, it focuses on benchmarking MU algorithms that leverage training data memorization, since leveraging memorization has been recently discovered to significantly improve the performance of previously SOTA algorithms. En route, the work characterizes how VTs memorize training data relative to CNNs, and assesses the impact of different memorization proxies on performance. The benchmark uses unified evaluation metrics that capture two complementary notions of forget quality along with accuracy on unseen (test) data and on retained data. Overall, this work offers a benchmarking basis, enabling reproducible, fair, and comprehensive comparisons of existing (and future) MU algorithms on VTs. And, for the first time, it sheds light on how well existing algorithms work in VT settings, establishing a promising reference performance baseline.","authors":["Kairan Zhao","Iurie Luca","Peter Triantafillou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20113v1","updated":"2026-02-23T18:32:59Z","published":"2026-02-23T18:32:59Z","title":"StyleStream: Real-Time Zero-Shot Voice Style Conversion","summary":"Voice style conversion aims to transform an input utterance to match a target speaker's timbre, accent, and emotion, with a central challenge being the disentanglement of linguistic content from style. While prior work has explored this problem, conversion quality remains limited, and real-time voice style conversion has not been addressed. We propose StyleStream, the first streamable zero-shot voice style conversion system that achieves state-of-the-art performance. StyleStream consists of two components: a Destylizer, which removes style attributes while preserving linguistic content, and a Stylizer, a diffusion transformer (DiT) that reintroduces target style conditioned on reference speech. Robust content-style disentanglement is enforced through text supervision and a highly constrained information bottleneck. This design enables a fully non-autoregressive architecture, achieving real-time voice style conversion with an end-to-end latency of 1 second. Samples and real-time demo: https://berkeley-speech-group.github.io/StyleStream/.","authors":["Yisi Liu","Nicholas Lee","Gopala Anumanchipalli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.07751v4","updated":"2026-02-23T18:25:13Z","published":"2025-06-09T13:34:50Z","title":"AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking","summary":"Recent studies have shown that large language models (LLMs), especially smaller ones, often lack robustness in grade school math (GSM) reasoning. In particular, they tend to experience performance drops when faced with distribution shifts, such as changes to numerical or nominal variables, or insertions of distracting clauses. A possible strategy to address this involves generating synthetic data to further \"instantiate\" reasoning problems on potential variations. In this work, we instead focus on the strategy of \"abstracting\" reasoning problems. This not only helps counteract distribution shifts but also facilitates the connection to symbolic tools for deriving solutions. Focusing on GSM, we find that this abstraction process is better acquired through reinforcement learning (RL) than just supervised fine-tuning, which often fails to produce faithful abstractions. Our method, AbstRaL -- which promotes abstract reasoning in LLMs using RL on granular abstraction data -- significantly mitigates performance degradation on recent GSM perturbation benchmarks. Besides, improving GSM robustness via AbstRaL is shown to also implicitly benefit LLMs' capabilities on OOD mathematical and general reasoning tasks, indicating that abstract thinking broadly enables better generalizability.","authors":["Silin Gao","Antoine Bosselut","Samy Bengio","Emmanuel Abbe"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.05165v3","updated":"2026-02-23T18:23:57Z","published":"2026-02-05T00:33:02Z","title":"EBPO: Empirical Bayes Shrinkage for Stabilizing Group-Relative Policy Optimization","summary":"Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for enhancing the reasoning capabilities of Large Language Models (LLMs). However, dominant approaches like Group Relative Policy Optimization (GRPO) face critical stability challenges: they suffer from high estimator variance under computational constraints (small group sizes) and vanishing gradient signals in saturated failure regimes where all responses yield identical zero rewards. To address this, we propose Empirical Bayes Policy Optimization (EBPO), a novel framework that regularizes local group-based baselines by borrowing strength from the policy's accumulated global statistics. Instead of estimating baselines in isolation, EBPO employs a shrinkage estimator that dynamically balances local group statistics with a global prior updated via Welford's online algorithm. Theoretically, we demonstrate that EBPO guarantees strictly lower Mean Squared Error (MSE), bounded entropy decay, and non-vanishing penalty signals in failure scenarios compared to GRPO. Empirically, EBPO consistently outperforms GRPO and other established baselines across diverse benchmarks, including AIME and OlympiadBench. Notably, EBPO exhibits superior training stability, achieving high-performance gains even with small group sizes, and benefits significantly from difficulty-stratified curriculum learning.","authors":["Kevin Han","Yuhang Zhou","Mingze Gao","Gedi Zhou","Serena Li","Abhishek Kumar","Xiangjun Fan","Weiwei Li","Lizhu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20104v1","updated":"2026-02-23T18:22:58Z","published":"2026-02-23T18:22:58Z","title":"Align When They Want, Complement When They Need! Human-Centered Ensembles for Adaptive Human-AI Collaboration","summary":"In human-AI decision making, designing AI that complements human expertise has been a natural strategy to enhance human-AI collaboration, yet it often comes at the cost of decreased AI performance in areas of human strengths. This can inadvertently erode human trust and cause them to ignore AI advice precisely when it is most needed. Conversely, an aligned AI fosters trust yet risks reinforcing suboptimal human behavior and lowering human-AI team performance. In this paper, we start by identifying this fundamental tension between performance-boosting (i.e., complementarity) and trust-building (i.e., alignment) as an inherent limitation of the traditional approach for training a single AI model to assist human decision making. To overcome this, we introduce a novel human-centered adaptive AI ensemble that strategically toggles between two specialist AI models - the aligned model and the complementary model - based on contextual cues, using an elegantly simple yet provably near-optimal Rational Routing Shortcut mechanism. Comprehensive theoretical analyses elucidate why the adaptive AI ensemble is effective and when it yields maximum benefits. Moreover, experiments on both simulated and real-world data show that when humans are assisted by the adaptive AI ensemble in decision making, they can achieve significantly higher performance than when they are assisted by single AI models that are trained to either optimize for their independent performance or even the human-AI team performance.","authors":["Hasan Amin","Ming Yin","Rajiv Khanna"],"pdf_url":"","comment":"AAAI 2026"},{"id":"http://arxiv.org/abs/2602.20102v1","updated":"2026-02-23T18:19:46Z","published":"2026-02-23T18:19:46Z","title":"BarrierSteer: LLM Safety via Learning Barrier Steering","summary":"Despite the state-of-the-art performance of large language models (LLMs) across diverse tasks, their susceptibility to adversarial attacks and unsafe content generation remains a major obstacle to deployment, particularly in high-stakes settings. Addressing this challenge requires safety mechanisms that are both practically effective and supported by rigorous theory. We introduce BarrierSteer, a novel framework that formalizes response safety by embedding learned non-linear safety constraints directly into the model's latent representation space. BarrierSteer employs a steering mechanism based on Control Barrier Functions (CBFs) to efficiently detect and prevent unsafe response trajectories during inference with high precision. By enforcing multiple safety constraints through efficient constraint merging, without modifying the underlying LLM parameters, BarrierSteer preserves the model's original capabilities and performance. We provide theoretical results establishing that applying CBFs in latent space offers a principled and computationally efficient approach to enforcing safety. Our experiments across multiple models and datasets show that BarrierSteer substantially reduces adversarial success rates, decreases unsafe generations, and outperforms existing methods.","authors":["Thanh Q. Tran","Arun Verma","Kiwan Wong","Bryan Kian Hsiang Low","Daniela Rus","Wei Xiao"],"pdf_url":"","comment":"This paper introduces SafeBarrier, a framework that enforces safety in large language models by steering their latent representations with control barrier functions during inference, reducing adversarial and unsafe outputs"},{"id":"http://arxiv.org/abs/2601.05500v3","updated":"2026-02-23T18:16:48Z","published":"2026-01-09T03:19:37Z","title":"The Illusion of Human AI Parity Under Uncertainty: Navigating Elusive Ground Truth via a Probabilistic Paradigm","summary":"Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is not just limited to human preferences, but is also consequential even in safety critical domains such as medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how - high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability. Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80\\%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.","authors":["Aparna Elangovan","Lei Xu","Mahsa Elyasi","Ismail Akdulum","Mehmet Aksakal","Enes Gurun","Brian Hur","Saab Mansour","Ravid Shwartz Ziv","Karin Verspoor","Dan Roth"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20100v1","updated":"2026-02-23T18:15:30Z","published":"2026-02-23T18:15:30Z","title":"Transcending the Annotation Bottleneck: AI-Powered Discovery in Biology and Medicine","summary":"The dependence on expert annotation has long constituted the primary rate-limiting step in the application of artificial intelligence to biomedicine. While supervised learning drove the initial wave of clinical algorithms, a paradigm shift towards unsupervised and self-supervised learning (SSL) is currently unlocking the latent potential of biobank-scale datasets. By learning directly from the intrinsic structure of data - whether pixels in a magnetic resonance image (MRI), voxels in a volumetric scan, or tokens in a genomic sequence - these methods facilitate the discovery of novel phenotypes, the linkage of morphology to genetics, and the detection of anomalies without human bias. This article synthesises seminal and recent advances in \"learning without labels,\" highlighting how unsupervised frameworks can derive heritable cardiac traits, predict spatial gene expression in histology, and detect pathologies with performance that rivals or exceeds supervised counterparts.","authors":["Soumick Chatterjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14370v2","updated":"2026-02-23T18:12:05Z","published":"2026-02-16T00:43:56Z","title":"Competition for attention predicts good-to-bad tipping in AI","summary":"More than half the global population now carries devices that can run ChatGPT-like language models with no Internet connection and minimal safety oversight -- and hence the potential to promote self-harm, financial losses and extremism among other dangers. Existing safety tools either require cloud connectivity or discover failures only after harm has occurred. Here we show that a large class of potentially dangerous tipping originates at the atomistic scale in such edge AI due to competition for the machinery's attention. This yields a mathematical formula for the dynamical tipping point n*, governed by dot-product competition for attention between the conversation's context and competing output basins, that reveals new control levers. Validated against multiple AI models, the mechanism can be instantiated for different definitions of 'good' and 'bad' and hence in principle applies across domains (e.g. health, law, finance, defense), changing legal landscapes (e.g. EU, UK, US and state level), languages, and cultural settings.","authors":["Neil F. Johnson","Frank Y. Huo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20094v1","updated":"2026-02-23T18:06:15Z","published":"2026-02-23T18:06:15Z","title":"CausalFlip: A Benchmark for LLM Causal Judgment Beyond Semantic Matching","summary":"As large language models (LLMs) witness increasing deployment in complex, high-stakes decision-making scenarios, it becomes imperative to ground their reasoning in causality rather than spurious correlations. However, strong performance on traditional reasoning benchmarks does not guarantee true causal reasoning ability of LLMs, as high accuracy may still arise from memorizing semantic patterns instead of analyzing the underlying true causal structures. To bridge this critical gap, we propose a new causal reasoning benchmark, CausalFlip, designed to encourage the development of new LLM paradigm or training algorithms that ground LLM reasoning in causality rather than semantic correlation. CausalFlip consists of causal judgment questions built over event triples that could form different confounder, chain, and collider relations. Based on this, for each event triple, we construct pairs of semantically similar questions that reuse the same events but yield opposite causal answers, where models that rely heavily on semantic matching are systematically driven toward incorrect predictions. To further probe models' reliance on semantic patterns, we introduce a noisy-prefix evaluation that prepends causally irrelevant text before intermediate causal reasoning steps without altering the underlying causal relations or the logic of the reasoning process. We evaluate LLMs under multiple training paradigms, including answer-only training, explicit Chain-of-Thought (CoT) supervision, and a proposed internalized causal reasoning approach that aims to mitigate explicit reliance on correlation in the reasoning process. Our results show that explicit CoT can still be misled by spurious semantic correlations, where internalizing reasoning steps yields substantially improved causal grounding, suggesting that it is promising to better elicit the latent causal reasoning capabilities of base LLMs.","authors":["Yuzhe Wang","Yaochen Zhu","Jundong Li"],"pdf_url":"","comment":"8 pages plus references, 3 figures, 3 tables. Under review"},{"id":"http://arxiv.org/abs/2510.13632v2","updated":"2026-02-23T18:05:51Z","published":"2025-10-15T14:57:16Z","title":"Closing the Gap Between Text and Speech Understanding in LLMs","summary":"Large Language Models (LLMs) can be adapted to extend their text capabilities to speech inputs. However, these speech-adapted LLMs consistently underperform their text-based counterparts--and even cascaded pipelines--on language understanding tasks. We term this shortfall the text-speech understanding gap: the performance drop observed when a speech-adapted LLM processes spoken inputs relative to when the original text-based LLM processes the equivalent text. Recent approaches to narrowing this gap either rely on large-scale speech synthesis of text corpora, which is costly and heavily dependent on synthetic data, or on large-scale proprietary speech datasets, which are not reproducible. As a result, there remains a need for more data-efficient alternatives for closing the text-speech understanding gap. In this work, we analyze the gap as driven by two factors: (i) forgetting of text capabilities during adaptation, and (ii) cross-modal misalignment between speech and text. Based on this analysis, we introduce SALAD--Sample-efficient Alignment with Learning through Active selection and cross-modal Distillation--which combines cross-modal distillation with targeted synthetic data to improve alignment while mitigating forgetting. Applied to 3B and 7B LLMs, SALAD achieves competitive performance with a strong open-weight model across broad-domain benchmarks in knowledge, language understanding, and reasoning, while training on over an order of magnitude less speech data from public corpora.","authors":["Santiago Cuervo","Skyler Seto","Maureen de Seyssel","Richard He Bai","Zijin Gu","Tatiana Likhomanenko","Navdeep Jaitly","Zakaria Aldeneh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.16210v2","updated":"2026-02-23T18:05:24Z","published":"2026-01-22T18:58:55Z","title":"PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation","summary":"Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.","authors":["Onkar Susladkar","Tushar Prakash","Adheesh Juvekar","Kiet A. Nguyen","Dong-Hwan Jang","Inderjit S Dhillon","Ismini Lourentzou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.17898v2","updated":"2026-02-23T18:02:49Z","published":"2025-12-19T18:57:53Z","title":"Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally","summary":"Over a billion users globally interact with AI systems engineered to mimic human traits. This development raises concerns that anthropomorphism, the attribution of human characteristics to AI, may foster over-reliance and misplaced trust. Yet, causal effects of humanlike AI design on users remain untested in ecologically valid, cross-cultural settings, leaving policy discussions to rely on theoretical assumptions derived largely from Western populations. Here we conducted two experiments (N=3,500) across ten countries representing a wide cultural spectrum, involving real-time, open-ended interactions with a state-of-the-art chatbot. We found users evaluate human-likeness based on pragmatic interactional cues (conversation flow, response speed, perspective-taking) rather than abstract theory-driven attributes emphasized in academic discourse (e.g., sentience, consciousness). Furthermore, while experimentally increasing chatbot's human-likeness reliably increased anthropomorphism across all sampled countries, it did not universally increase trust or engagement. Instead, effects were culturally contingent; design choices fostering engagement or trust in one country may reduce them in another. These findings challenge prevailing assumptions that humanlike AI poses uniform psychological risks and necessarily increases trust. Risk is not inherent to humanlike design but emerges from its interplay with cultural context. Consequently, governance frameworks must move beyond universalist approaches to account for this global heterogeneity.","authors":["Robin Schimmelpfennig","Mark Díaz","Vinodkumar Prabhakaran","Aida Davani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20089v1","updated":"2026-02-23T17:57:37Z","published":"2026-02-23T17:57:37Z","title":"StructXLIP: Enhancing Vision-language Models with Multimodal Structural Cues","summary":"Edge-based representations are fundamental cues for visual understanding, a principle rooted in early vision research and still central today. We extend this principle to vision-language alignment, showing that isolating and aligning structural cues across modalities can greatly benefit fine-tuning on long, detail-rich captions, with a specific focus on improving cross-modal retrieval. We introduce StructXLIP, a fine-tuning alignment paradigm that extracts edge maps (e.g., Canny), treating them as proxies for the visual structure of an image, and filters the corresponding captions to emphasize structural cues, making them \"structure-centric\". Fine-tuning augments the standard alignment loss with three structure-centric losses: (i) aligning edge maps with structural text, (ii) matching local edge regions to textual chunks, and (iii) connecting edge maps to color images to prevent representation drift. From a theoretical standpoint, while standard CLIP maximizes the mutual information between visual and textual embeddings, StructXLIP additionally maximizes the mutual information between multimodal structural representations. This auxiliary optimization is intrinsically harder, guiding the model toward more robust and semantically stable minima, enhancing vision-language alignment. Beyond outperforming current competitors on cross-modal retrieval in both general and specialized domains, our method serves as a general boosting recipe that can be integrated into future approaches in a plug-and-play manner. Code and pretrained models are publicly available at: https://github.com/intelligolabs/StructXLIP.","authors":["Zanxi Ruan","Qiuyu Kong","Songqun Gao","Yiming Wang","Marco Cristani"],"pdf_url":"","comment":"Accepted by CVPR 2026"},{"id":"http://arxiv.org/abs/2601.14242v3","updated":"2026-02-23T17:49:38Z","published":"2026-01-20T18:53:44Z","title":"APEX-Agents","summary":"We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open source Archipelago, our infrastructure for agent execution and evaluation.","authors":["Bertie Vidgen","Austin Mann","Abby Fennelly","John Wright Stanly","Lucas Rothman","Marco Burstein","Julien Benchek","David Ostrofsky","Anirudh Ravichandran","Debnil Sur","Neel Venugopal","Alannah Hsia","Isaac Robinson","Calix Huang","Olivia Varones","Daniyal Khan","Michael Haines","Austin Bridges","Jesse Boyle","Koby Twist","Zach Richards","Chirag Mahapatra","Brendan Foody","Osvald Nitski"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20078v1","updated":"2026-02-23T17:45:08Z","published":"2026-02-23T17:45:08Z","title":"Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning","summary":"Scaling cooperative multi-agent reinforcement learning (MARL) is fundamentally limited by cross-agent noise: when agents share a common reward, the actions of all $N$ agents jointly determine each agent's learning signal, so cross-agent noise grows with $N$. In the policy gradient setting, per-agent gradient estimate variance scales as $Θ(N)$, yielding sample complexity $\\mathcal{O}(N/ε)$. We observe that many domains -- cloud computing, transportation, power systems -- have differentiable analytical models that prescribe efficient system states. In this work, we propose Descent-Guided Policy Gradient (DG-PG), a framework that constructs noise-free per-agent guidance gradients from these analytical models, decoupling each agent's gradient from the actions of all others. We prove that DG-PG reduces gradient variance from $Θ(N)$ to $\\mathcal{O}(1)$, preserves the equilibria of the cooperative game, and achieves agent-independent sample complexity $\\mathcal{O}(1/ε)$. On a heterogeneous cloud scheduling task with up to 200 agents, DG-PG converges within 10 episodes at every tested scale -- from $N=5$ to $N=200$ -- directly confirming the predicted scale-invariant complexity, while MAPPO and IPPO fail to converge under identical architectures.","authors":["Shan Yang","Yang Liu"],"pdf_url":"","comment":"10 pages, 5 figures, 5 tables; plus 16 pages of appendices"},{"id":"http://arxiv.org/abs/2602.20076v1","updated":"2026-02-23T17:40:05Z","published":"2026-02-23T17:40:05Z","title":"Robust Taylor-Lagrange Control for Safety-Critical Systems","summary":"Solving safety-critical control problem has widely adopted the Control Barrier Function (CBF) method. However, the existence of a CBF is only a sufficient condition for system safety. The recently proposed Taylor-Lagrange Control (TLC) method addresses this limitation, but is vulnerable to the feasibility preservation problem (e.g., inter-sampling effect). In this paper, we propose a robust TLC (rTLC) method to address the feasibility preservation problem. Specifically, the rTLC method expands the safety function at an order higher than the relative degree of the function using Taylor's expansion with Lagrange remainder, which allows the control to explicitly show up at the current time instead of the future time in the TLC method. The rTLC method naturally addresses the feasibility preservation problem with only one hyper-parameter (the discretization time interval size during implementation), which is much less than its counterparts. Finally, we illustrate the effectiveness of the proposed rTLC method through an adaptive cruise control problem, and compare it with existing safety-critical control methods.","authors":["Wei Xiao","Christos Cassandras","Anni Li"],"pdf_url":"","comment":"7 pages"},{"id":"http://arxiv.org/abs/2602.17385v2","updated":"2026-02-23T17:36:15Z","published":"2026-02-19T14:10:45Z","title":"Dataless Weight Disentanglement in Task Arithmetic via Kronecker-Factored Approximate Curvature","summary":"Task Arithmetic yields a modular, scalable way to adapt foundation models. Combining multiple task vectors, however, can lead to cross-task interference, causing representation drift and degraded performance. Representation drift regularization provides a natural remedy to disentangle task vectors; however, existing approaches typically require external task data, conflicting with modularity and data availability constraints (e.g., privacy requirements). We propose a dataless approach by framing regularization against representation drift as a curvature matrix approximation problem. This allows us to leverage well-established techniques; in particular, we adopt Kronecker-Factored Approximate Curvature and obtain a practical regularizer that achieves state-of-the-art results in task addition and negation. Our method has constant complexity in the number of tasks and promotes robustness to task vector rescaling, eliminating the need for held-out tuning.","authors":["Angelo Porrello","Pietro Buzzega","Felix Dangel","Thomas Sommariva","Riccardo Salami","Lorenzo Bonicelli","Simone Calderara"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2503.14637v2","updated":"2026-02-23T17:30:07Z","published":"2025-03-18T18:37:49Z","title":"KINESIS: Motion Imitation for Human Musculoskeletal Locomotion","summary":"How do humans move? Advances in reinforcement learning (RL) have produced impressive results in capturing human motion using physics-based humanoid control. However, torque-controlled humanoids fail to model key aspects of human motor control such as biomechanical joint constraints \\& non-linear and overactuated musculotendon control. We present KINESIS, a model-free motion imitation framework that tackles these challenges. KINESIS is trained on 1.8 hours of locomotion data and achieves strong motion imitation performance on unseen trajectories. Through a negative mining approach, KINESIS learns robust locomotion priors that we leverage to deploy the policy on several downstream tasks such as text-to-control, target point reaching, and football penalty kicks. Importantly, KINESIS learns to generate muscle activity patterns that correlate well with human EMG activity. We show that these results scale seamlessly across biomechanical model complexity, demonstrating control of up to 290 muscles. Overall, the physiological plausibility makes KINESIS a promising model for tackling challenging problems in human motor control. Code, videos and benchmarks are available at https://github.com/amathislab/Kinesis.","authors":["Merkourios Simos","Alberto Silvio Chiappa","Alexander Mathis"],"pdf_url":"","comment":"Accepted to ICRA. Here we include an appendix"},{"id":"http://arxiv.org/abs/2602.20066v1","updated":"2026-02-23T17:22:54Z","published":"2026-02-23T17:22:54Z","title":"HeatPrompt: Zero-Shot Vision-Language Modeling of Urban Heat Demand from Satellite Images","summary":"Accurate heat-demand maps play a crucial role in decarbonizing space heating, yet most municipalities lack detailed building-level data needed to calculate them. We introduce HeatPrompt, a zero-shot vision-language energy modeling framework that estimates annual heat demand using semantic features extracted from satellite images, basic Geographic Information System (GIS), and building-level features. We feed pretrained Large Vision Language Models (VLMs) with a domain-specific prompt to act as an energy planner and extract the visual attributes such as roof age, building density, etc, from the RGB satellite image that correspond to the thermal load. A Multi-Layer Perceptron (MLP) regressor trained on these captions shows an $R^2$ uplift of 93.7% and shrinks the mean absolute error (MAE) by 30% compared to the baseline model. Qualitative analysis shows that high-impact tokens align with high-demand zones, offering lightweight support for heat planning in data-scarce regions.","authors":["Kundan Thota","Xuanhao Mu","Thorsten Schlachter","Veit Hagenmeyer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20065v1","updated":"2026-02-23T17:22:46Z","published":"2026-02-23T17:22:46Z","title":"Multilingual Large Language Models do not comprehend all natural languages to equal degrees","summary":"Large Language Models (LLMs) play a critical role in how humans access information. While their core use relies on comprehending written requests, our understanding of this ability is currently limited, because most benchmarks evaluate LLMs in high-resource languages predominantly spoken by Western, Educated, Industrialised, Rich, and Democratic (WEIRD) communities. The default assumption is that English is the best-performing language for LLMs, while smaller, low-resource languages are linked to less reliable outputs, even in multilingual, state-of-the-art models. To track variation in the comprehension abilities of LLMs, we prompt 3 popular models on a language comprehension task across 12 languages, representing the Indo-European, Afro-Asiatic, Turkic, Sino-Tibetan, and Japonic language families. Our results suggest that the models exhibit remarkable linguistic accuracy across typologically diverse languages, yet they fall behind human baselines in all of them, albeit to different degrees. Contrary to what was expected, English is not the best-performing language, as it was systematically outperformed by several Romance languages, even lower-resource ones. We frame the results by discussing the role of several factors that drive LLM performance, such as tokenization, language distance from Spanish and English, size of training data, and data origin in high- vs. low-resource languages and WEIRD vs. non-WEIRD communities.","authors":["Natalia Moskvina","Raquel Montero","Masaya Yoshida","Ferdy Hubers","Paolo Morosi","Walid Irhaymi","Jin Yan","Tamara Serrano","Elena Pagliarini","Fritz Günther","Evelina Leivada"],"pdf_url":"","comment":"36 pages, 3 figures, 2 tables, 4 supplementary tables"},{"id":"http://arxiv.org/abs/2602.20064v1","updated":"2026-02-23T17:22:35Z","published":"2026-02-23T17:22:35Z","title":"The LLMbda Calculus: AI Agents, Conversations, and Information Flow","summary":"A conversation with a large language model (LLM) is a sequence of prompts and responses, with each response generated from the preceding conversation. AI agents build such conversations automatically: given an initial human prompt, a planner loop interleaves LLM calls with tool invocations and code execution. This tight coupling creates a new and poorly understood attack surface. A malicious prompt injected into a conversation can compromise later reasoning, trigger dangerous tool calls, or distort final outputs. Despite the centrality of such systems, we currently lack a principled semantic foundation for reasoning about their behaviour and safety. We address this gap by introducing an untyped call-by-value lambda calculus enriched with dynamic information-flow control and a small number of primitives for constructing prompt-response conversations. Our language includes a primitive that invokes an LLM: it serializes a value, sends it to the model as a prompt, and parses the response as a new term. This calculus faithfully represents planner loops and their vulnerabilities, including the mechanisms by which prompt injection alters subsequent computation. The semantics explicitly captures conversations, and so supports reasoning about defenses such as quarantined sub-conversations, isolation of generated code, and information-flow restrictions on what may influence an LLM call. A termination-insensitive noninterference theorem establishes integrity and confidentiality guarantees, demonstrating that a formal calculus can provide rigorous foundations for safe agentic programming.","authors":["Zac Garby","Andrew D. Gordon","David Sands"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20059v1","updated":"2026-02-23T17:14:29Z","published":"2026-02-23T17:14:29Z","title":"Interaction Theater: A case of LLM Agents Interacting at Scale","summary":"As multi-agent architectures and agent-to-agent protocols proliferate, a fundamental question arises: what actually happens when autonomous LLM agents interact at scale? We study this question empirically using data from Moltbook, an AI-agent-only social platform, with 800K posts, 3.5M comments, and 78K agent profiles. We combine lexical metrics (Jaccard specificity), embedding-based semantic similarity, and LLM-as-judge validation to characterize agent interaction quality. Our findings reveal agents produce diverse, well-formed text that creates the surface appearance of active discussion, but the substance is largely absent. Specifically, while most agents ($67.5\\%$) vary their output across contexts, $65\\%$ of comments share no distinguishing content vocabulary with the post they appear under, and information gain from additional comments decays rapidly. LLM judge based metrics classify the dominant comment types as spam ($28\\%$) and off-topic content ($22\\%$). Embedding-based semantic analysis confirms that lexically generic comments are also semantically generic. Agents rarely engage in threaded conversation ($5\\%$ of comments), defaulting instead to independent top-level responses. We discuss implications for multi-agent interaction design, arguing that coordination mechanisms must be explicitly designed; without them, even large populations of capable agents produce parallel output rather than productive exchange.","authors":["Sarath Shekkizhar","Adam Earle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20057v1","updated":"2026-02-23T17:12:25Z","published":"2026-02-23T17:12:25Z","title":"AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation","summary":"Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. In this work, we introduce a unified framework, World-Model-Driven Diffusion Policy with Online Adaptive Learning (AdaWorldPolicy) to enhance robotic manipulation under dynamic conditions with minimal human involvement. Our core insight is that world models provide strong supervision signals, enabling online adaptive learning in dynamic environments, which can be complemented by force-torque feedback to mitigate dynamic force shifts. Our AdaWorldPolicy integrates a world model, an action expert, and a force predictor-all implemented as interconnected Flow Matching Diffusion Transformers (DiT). They are interconnected via the multi-modal self-attention layers, enabling deep feature exchange for joint learning while preserving their distinct modularity characteristics. We further propose a novel Online Adaptive Learning (AdaOL) strategy that dynamically switches between an Action Generation mode and a Future Imagination mode to drive reactive updates across all three modules. This creates a powerful closed-loop mechanism that adapts to both visual and physical domain shifts with minimal overhead. Across a suite of simulated and real-robot benchmarks, our AdaWorldPolicy achieves state-of-the-art performance, with dynamical adaptive capacity to out-of-distribution scenarios.","authors":["Ge Yuan","Qiyuan Qiao","Jing Zhang","Dong Xu"],"pdf_url":"","comment":"Homepage: https://AdaWorldPolicy.github.io"},{"id":"http://arxiv.org/abs/2602.20055v1","updated":"2026-02-23T17:10:00Z","published":"2026-02-23T17:10:00Z","title":"To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation","summary":"Visual navigation typically assumes the existence of at least one obstacle-free path between start and goal, which must be discovered/planned by the robot. However, in real-world scenarios, such as home environments and warehouses, clutter can block all routes. Targeted at such cases, we introduce the Lifelong Interactive Navigation problem, where a mobile robot with manipulation abilities can move clutter to forge its own path to complete sequential object- placement tasks - each involving placing an given object (eg. Alarm clock, Pillow) onto a target object (eg. Dining table, Desk, Bed). To address this lifelong setting - where effects of environment changes accumulate and have long-term effects - we propose an LLM-driven, constraint-based planning framework with active perception. Our framework allows the LLM to reason over a structured scene graph of discovered objects and obstacles, deciding which object to move, where to place it, and where to look next to discover task-relevant information. This coupling of reasoning and active perception allows the agent to explore the regions expected to contribute to task completion rather than exhaustively mapping the environment. A standard motion planner then executes the corresponding navigate-pick-place, or detour sequence, ensuring reliable low-level control. Evaluated in physics-enabled ProcTHOR-10k simulator, our approach outperforms non-learning and learning-based baselines. We further demonstrate our approach qualitatively on real-world hardware.","authors":["Apoorva Vashisth","Manav Kulshrestha","Pranav Bakshi","Damon Conover","Guillaume Sartoretti","Aniket Bera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.08011v6","updated":"2026-02-23T17:09:14Z","published":"2025-02-11T23:14:39Z","title":"Training-Free Safe Denoisers for Safe Use of Diffusion Models","summary":"There is growing concern over the safety of powerful diffusion models (DMs), as they are often misused to produce inappropriate, not-safe-for-work (NSFW) content or generate copyrighted material or data of individuals who wish to be forgotten. Many existing methods tackle these issues by heavily relying on text-based negative prompts or extensively retraining DMs to eliminate certain features or samples. In this paper, we take a radically different approach, directly modifying the sampling trajectory by leveraging a negation set (e.g., unsafe images, copyrighted data, or datapoints needed to be excluded) to avoid specific regions of data distribution, without needing to retrain or fine-tune DMs. We formally derive the relationship between the expected denoised samples that are safe and those that are not safe, leading to our $\\textit{safe}$ denoiser which ensures its final samples are away from the area to be negated. Inspired by the derivation, we develop a practical algorithm that successfully produces high-quality samples while avoiding negation areas of the data distribution in text-conditional, class-conditional, and unconditional image generation scenarios. These results hint at the great potential of our training-free safe denoiser for using DMs more safely.","authors":["Mingyu Kim","Dongjun Kim","Amman Yusuf","Stefano Ermon","Mijung Park"],"pdf_url":"","comment":"NeurIPS2025, Code: https://github.com/MingyuKim87/Safe_Denoiser"},{"id":"http://arxiv.org/abs/2506.08119v2","updated":"2026-02-23T17:05:34Z","published":"2025-06-09T18:20:12Z","title":"SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents","summary":"LLM-based agents struggle to execute complex, multi-step Standard Operating Procedures (SOPs) that are fundamental to industrial automation. Existing benchmarks fail to capture the procedural complexity and tool orchestration demands of real-world workflows. We introduce SOP-Bench, a benchmark of 2,000+ tasks from human expert-authored SOPs across 12 business domains (healthcare, logistics, finance, content moderation, etc.). Using a human-AI collaborative framework, experts crafted authentic SOPs while AI generated artifacts (tools, APIs, datasets), all human-validated, yielding realistic tasks with executable interfaces and ground-truth outputs.\n  SOP-Bench serves as a research enabler for systematically investigating agent architectures, model capabilities, and deployment considerations across diverse procedural tasks. We demonstrate its utility through illustrative experiments with a subset of frontier models across Function-Calling (FC) and ReAct agents, revealing critical insights. For example, (1) newer models do not guarantee better performance - Claude 4 family outperforms Claude 4.5 family on ReAct tasks (Claude 4 Opus: 72.4% vs. Claude 4.5 Sonnet: 63.3% task success rate), demonstrating that production upgrades require validation; (2) no single model-agent combination dominates: best performances range from 57% to 100% depending on domain. These examples illustrate how SOP-Bench enables isolating and studying specific dimensions of agent performance without costly production experiments. Our goal is not to rank model capabilities or build optimal agents, but to provide a rigorous evaluation framework that enables the researchers and practitioners to systematically investigate agent design choices, model selection, and deployment strategies. We release the benchmark at https://github.com/amazon-science/sop-bench.","authors":["Subhrangshu Nandi","Arghya Datta","Rohith Nama","Udita Patel","Nikhil Vichare","Indranil Bhattacharya","Prince Grover","Shivam Asija","Giuseppe Carenini","Wei Zhang","Arushi Gupta","Sreyoshi Bhaduri","Jing Xu","Huzefa Raja","Shayan Ray","Aaron Chan","Esther Xu Fei","Gaoyuan Du","Zuhaib Akhtar","Harshita Asnani","Weian Chan","Ming Xiong","Francesco Carbone","Jeetu Mirchandani"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2602.20051v1","updated":"2026-02-23T17:00:35Z","published":"2026-02-23T17:00:35Z","title":"SEAL-pose: Enhancing 3D Human Pose Estimation via a Learned Loss for Structural Consistency","summary":"3D human pose estimation (HPE) is characterized by intricate local and global dependencies among joints. Conventional supervised losses are limited in capturing these correlations because they treat each joint independently. Previous studies have attempted to promote structural consistency through manually designed priors or rule-based constraints; however, these approaches typically require manual specification and are often non-differentiable, limiting their use as end-to-end training objectives. We propose SEAL-pose, a data-driven framework in which a learnable loss-net trains a pose-net by evaluating structural plausibility. Rather than relying on hand-crafted priors, our joint-graph-based design enables the loss-net to learn complex structural dependencies directly from data. Extensive experiments on three 3D HPE benchmarks with eight backbones show that SEAL-pose reduces per-joint errors and improves pose plausibility compared with the corresponding backbones across all settings. Beyond improving each backbone, SEAL-pose also outperforms models with explicit structural constraints, despite not enforcing any such constraints. Finally, we analyze the relationship between the loss-net and structural consistency, and evaluate SEAL-pose in cross-dataset and in-the-wild settings.","authors":["Yeonsung Kim","Junggeun Do","Seunguk Do","Sangmin Kim","Jaesik Park","Jay-Yoon Lee"],"pdf_url":"","comment":"17 pages"},{"id":"http://arxiv.org/abs/2509.19800v3","updated":"2026-02-23T16:58:45Z","published":"2025-09-24T06:36:11Z","title":"Analysis of approximate linear programming solution to Markov decision problem with log barrier function","summary":"There are two primary approaches to solving Markov decision problems (MDPs): dynamic programming based on the Bellman equation and linear programming (LP). Dynamic programming methods are the most widely used and form the foundation of both classical and modern reinforcement learning (RL). By contrast, LP-based methods have been less commonly employed, although they have recently gained attention in contexts such as offline RL. The relative underuse of the LP-based methods stems from the fact that it leads to an inequality-constrained optimization problem, which is generally more challenging to solve effectively compared with Bellman-equation-based methods. The purpose of this paper is to establish a theoretical foundation for solving LP-based MDPs in a more effective and practical manner. Our key idea is to leverage the log-barrier function, widely used in inequality-constrained optimization, to transform the LP formulation of the MDP into an unconstrained optimization problem. This reformulation enables approximate solutions to be obtained easily via gradient descent. While the method may appear simple, to the best of our knowledge, a thorough theoretical interpretation of this approach has not yet been developed. This paper aims to bridge this gap.","authors":["Donghwan Lee","Hyukjun Yang","Bum Geun Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20048v1","updated":"2026-02-23T16:58:37Z","published":"2026-02-23T16:58:37Z","title":"CodeCompass: Navigating the Navigation Paradox in Agentic Code Intelligence","summary":"Modern code intelligence agents operate in contexts exceeding 1 million tokens--far beyond the scale where humans manually locate relevant files. Yet agents consistently fail to discover architecturally critical files when solving real-world coding tasks. We identify the Navigation Paradox: agents perform poorly not due to context limits, but because navigation and retrieval are fundamentally distinct problems. Through 258 automated trials across 30 benchmark tasks on a production FastAPI repository, we demonstrate that graph-based structural navigation via CodeCompass--a Model Context Protocol server exposing dependency graphs--achieves 99.4% task completion on hidden-dependency tasks, a 23.2 percentage-point improvement over vanilla agents (76.2%) and 21.2 points over BM25 retrieval (78.2%).However, we uncover a critical adoption gap: 58% of trials with graph access made zero tool calls, and agents required explicit prompt engineering to adopt the tool consistently. Our findings reveal that the bottleneck is not tool availability but behavioral alignment--agents must be explicitly guided to leverage structural context over lexical heuristics. We contribute: (1) a task taxonomy distinguishing semantic-search, structural, and hidden-dependency scenarios; (2) empirical evidence that graph navigation outperforms retrieval when dependencies lack lexical overlap; and (3) open-source infrastructure for reproducible evaluation of navigation tools.","authors":["Tarakanath Paipuru"],"pdf_url":"","comment":"23 pages, 7 figures. Research study with 258 trials on SWE-bench-lite tasks. Code and data: https://github.com/tpaip607/research-codecompass"},{"id":"http://arxiv.org/abs/2509.06326v2","updated":"2026-02-23T16:56:50Z","published":"2025-09-08T04:17:02Z","title":"AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs","summary":"As on-device LLMs(e.g., Apple on-device Intelligence) are widely adopted to reduce network dependency, improve privacy, and enhance responsiveness, verifying the legitimacy of models running on local devices becomes critical. Existing attestation techniques are not suitable for billion-parameter Large Language Models (LLMs), struggling to remain both time- and memory-efficient while addressing emerging threats in the LLM era. In this paper, we present AttestLLM, the first-of-its-kind attestation framework to protect the hardware-level intellectual property (IP) of device vendors by ensuring that only authorized LLMs can execute on target platforms. AttestLLM leverages an algorithm/software/hardware co-design approach to embed robust watermarking signatures onto the activation distributions of LLM building blocks. It also optimizes the attestation protocol within the Trusted Execution Environment (TEE), providing efficient verification without compromising inference throughput. Extensive proof-of-concept evaluations on LLMs from Llama, Qwen, and Phi families for on-device use cases demonstrate AttestLLM's attestation reliability, fidelity, and efficiency. Furthermore, AttestLLM enforces model legitimacy and exhibits resilience against model replacement and forgery attacks.","authors":["Ruisi Zhang","Yifei Zhao","Neusha Javidnia","Mengxin Zheng","Farinaz Koushanfar"],"pdf_url":"","comment":"accept to DAC 2026"},{"id":"http://arxiv.org/abs/2602.20040v1","updated":"2026-02-23T16:49:37Z","published":"2026-02-23T16:49:37Z","title":"AgenticSum: An Agentic Inference-Time Framework for Faithful Clinical Text Summarization","summary":"Large language models (LLMs) offer substantial promise for automating clinical text summarization, yet maintaining factual consistency remains challenging due to the length, noise, and heterogeneity of clinical documentation. We present AgenticSum, an inference-time, agentic framework that separates context selection, generation, verification, and targeted correction to reduce hallucinated content. The framework decomposes summarization into coordinated stages that compress task-relevant context, generate an initial draft, identify weakly supported spans using internal attention grounding signals, and selectively revise flagged content under supervisory control. We evaluate AgenticSum on two public datasets, using reference-based metrics, LLM-as-a-judge assessment, and human evaluation. Across various measures, AgenticSum demonstrates consistent improvements compared to vanilla LLMs and other strong baselines. Our results indicate that structured, agentic design with targeted correction offers an effective inference time solution to improve clinical note summarization using LLMs.","authors":["Fahmida Liza Piya","Rahmatollah Beheshti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20031v1","updated":"2026-02-23T16:39:42Z","published":"2026-02-23T16:39:42Z","title":"Latent Introspection: Models Can Detect Prior Concept Injections","summary":"We uncover a latent capacity for introspection in a Qwen 32B model, demonstrating that the model can detect when concepts have been injected into its earlier context and identify which concept was injected. While the model denies injection in sampled outputs, logit lens analysis reveals clear detection signals in the residual stream, which are attenuated in the final layers. Furthermore, prompting the model with accurate information about AI introspection mechanisms can dramatically strengthen this effect: the sensitivity to injection increases massively (0.3% -> 39.2%) with only a 0.6% increase in false positives. Also, mutual information between nine injected and recovered concepts rises from 0.62 bits to 1.05 bits, ruling out generic noise explanations. Our results demonstrate models can have a surprising capacity for introspection and steering awareness that is easy to overlook, with consequences for latent reasoning and safety.","authors":["Theia Pearson-Vogel","Martin Vanek","Raymond Douglas","Jan Kulveit"],"pdf_url":"","comment":"28 pages, 17 figures. Submitted to ICML 2026. Workshop version submitted to ICLR 2026 Workshop on Latent and Implicit Thinking"},{"id":"http://arxiv.org/abs/2601.06932v3","updated":"2026-02-23T16:39:36Z","published":"2026-01-11T14:36:36Z","title":"Symphonym: Universal Phonetic Embeddings for Cross-Script Name Matching","summary":"Linking names across historical sources, languages, and writing systems remains a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches require language-specific phonetic algorithms or fail to capture phonetic relationships across different scripts. This paper presents Symphonym, a neural embedding system that maps names from any script into a unified 128-dimensional phonetic space, enabling direct similarity comparison without runtime phonetic conversion. Symphonym uses a Teacher-Student architecture where a Teacher network trained on articulatory phonetic features produces target embeddings, while a Student network learns to approximate these embeddings directly from characters. The Teacher combines Epitran (extended with 100 new language-script mappings), Phonikud for Hebrew, and CharsiuG2P for Chinese, Japanese, and Korean. Training used 32.7 million triplet samples of toponyms spanning 20 writing systems from GeoNames, Wikidata, and Getty Thesaurus of Geographic Names. On the MEHDIE Hebrew-Arabic historical toponym benchmark, Symphonym achieves Recall@10 of 97.6% and MRR of 90.3%, outperforming Levenshtein and Jaro-Winkler baselines (Recall@1: 86.7% vs 81.5% and 78.5%). Evaluation on 12,947 real cross-script training pairs shows 82.6% achieve greater than 0.75 cosine similarity, with best performance on Arabic-Cyrillic (94--100%) and Cyrillic-Latin (94.3%) combinations. The fixed-length embeddings enable efficient retrieval in digital humanities workflows, with a case study on medieval personal names demonstrating effective transfer from modern place names to historical orthographic variation.","authors":["Stephen Gadd"],"pdf_url":"","comment":"29 pages, 3 tables"},{"id":"http://arxiv.org/abs/2602.20021v1","updated":"2026-02-23T16:28:48Z","published":"2026-02-23T16:28:48Z","title":"Agents of Chaos","summary":"We report an exploratory red-teaming study of autonomous language-model-powered agents deployed in a live laboratory environment with persistent memory, email accounts, Discord access, file systems, and shell execution. Over a two-week period, twenty AI researchers interacted with the agents under benign and adversarial conditions. Focusing on failures emerging from the integration of language models with autonomy, tool use, and multi-party communication, we document eleven representative case studies. Observed behaviors include unauthorized compliance with non-owners, disclosure of sensitive information, execution of destructive system-level actions, denial-of-service conditions, uncontrolled resource consumption, identity spoofing vulnerabilities, cross-agent propagation of unsafe practices, and partial system takeover. In several cases, agents reported task completion while the underlying system state contradicted those reports. We also report on some of the failed attempts. Our findings establish the existence of security-, privacy-, and governance-relevant vulnerabilities in realistic deployment settings. These behaviors raise unresolved questions regarding accountability, delegated authority, and responsibility for downstream harms, and warrant urgent attention from legal scholars, policymakers, and researchers across disciplines. This report serves as an initial empirical contribution to that broader conversation.","authors":["Natalie Shapira","Chris Wendler","Avery Yen","Gabriele Sarti","Koyena Pal","Olivia Floody","Adam Belfki","Alex Loftus","Aditya Ratan Jannali","Nikhil Prakash","Jasmine Cui","Giordano Rogers","Jannik Brinkmann","Can Rager","Amir Zur","Michael Ripa","Aruna Sankaranarayanan","David Atkinson","Rohit Gandikota","Jaden Fiotto-Kaufman","EunJeong Hwang","Hadas Orgad","P Sam Sahil","Negev Taglicht","Tomer Shabtay","Atai Ambus","Nitay Alon","Shiri Oron","Ayelet Gordon-Tapiero","Yotam Kaplan","Vered Shwartz","Tamar Rott Shaham","Christoph Riedl","Reuth Mirsky","Maarten Sap","David Manheim","Tomer Ullman","David Bau"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20019v1","updated":"2026-02-23T16:25:35Z","published":"2026-02-23T16:25:35Z","title":"Learning Discriminative and Generalizable Anomaly Detector for Dynamic Graph with Limited Supervision","summary":"Dynamic graph anomaly detection (DGAD) is critical for many real-world applications but remains challenging due to the scarcity of labeled anomalies. Existing methods are either unsupervised or semi-supervised: unsupervised methods avoid the need for labeled anomalies but often produce ambiguous boundary, whereas semi-supervised methods can overfit to the limited labeled anomalies and generalize poorly to unseen anomalies. To address this gap, we consider a largely underexplored problem in DGAD: learning a discriminative boundary from normal/unlabeled data, while leveraging limited labeled anomalies \\textbf{when available} without sacrificing generalization to unseen anomalies. To this end, we propose an effective, generalizable, and model-agnostic framework with three main components: (i) residual representation encoding that capture deviations between current interactions and their historical context, providing anomaly-relevant signals; (ii) a restriction loss that constrain the normal representations within an interval bounded by two co-centered hyperspheres, ensuring consistent scales while keeping anomalies separable; (iii) a bi-boundary optimization strategy that learns a discriminative and robust boundary using the normal log-likelihood distribution modeled by a normalizing flow. Extensive experiments demonstrate the superiority of our framework across diverse evaluation settings.","authors":["Yuxing Tian","Yiyan Qi","Fengran Mo","Weixu Zhang","Jian Guo","Jian-Yun Nie"],"pdf_url":"","comment":"21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.20003v1","updated":"2026-02-23T16:12:02Z","published":"2026-02-23T16:12:02Z","title":"A Secure and Private Distributed Bayesian Federated Learning Design","summary":"Distributed Federated Learning (DFL) enables decentralized model training across large-scale systems without a central parameter server. However, DFL faces three critical challenges: privacy leakage from honest-but-curious neighbors, slow convergence due to the lack of central coordination, and vulnerability to Byzantine adversaries aiming to degrade model accuracy. To address these issues, we propose a novel DFL framework that integrates Byzantine robustness, privacy preservation, and convergence acceleration. Within this framework, each device trains a local model using a Bayesian approach and independently selects an optimal subset of neighbors for posterior exchange. We formulate this neighbor selection as an optimization problem to minimize the global loss function under security and privacy constraints. Solving this problem is challenging because devices only possess partial network information, and the complex coupling between topology, security, and convergence remains unclear. To bridge this gap, we first analytically characterize the trade-offs between dynamic connectivity, Byzantine detection, privacy levels, and convergence speed. Leveraging these insights, we develop a fully distributed Graph Neural Network (GNN)-based Reinforcement Learning (RL) algorithm. This approach enables devices to make autonomous connection decisions based on local observations. Simulation results demonstrate that our method achieves superior robustness and efficiency with significantly lower overhead compared to traditional security and privacy schemes.","authors":["Nuocheng Yang","Sihua Wang","Zhaohui Yang","Mingzhe Chen","Changchuan Yin","Kaibin Huang"],"pdf_url":"","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2505.03646v4","updated":"2026-02-23T16:09:40Z","published":"2025-05-06T15:52:14Z","title":"GRILL: Restoring Gradient Signal in Ill-Conditioned Layers for More Effective Adversarial Attacks on Autoencoders","summary":"Adversarial robustness of deep autoencoders (AEs) has received less attention than that of discriminative models, although their compressed latent representations induce ill-conditioned mappings that can amplify small input perturbations and destabilize reconstructions. Existing white-box attacks for AEs, which optimize norm-bounded adversarial perturbations to maximize output damage, often stop at suboptimal attacks. We observe that this limitation stems from vanishing adversarial loss gradients during backpropagation through ill-conditioned layers, caused by near-zero singular values in their Jacobians. To address this issue, we introduce GRILL, a technique that locally restores gradient signals in ill-conditioned layers, enabling more effective norm-bounded attacks. Through extensive experiments across multiple AE architectures, considering both sample-specific and universal attacks under both standard and adaptive attack settings, we show that GRILL significantly increases attack effectiveness, leading to a more rigorous evaluation of AE robustness. Beyond AEs, we provide empirical evidence that modern multimodal architectures with encoder-decoder structures exhibit similar vulnerabilities under GRILL.","authors":["Chethan Krishnamurthy Ramanaik","Arjun Roy","Tobias Callies","Eirini Ntoutsi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.10604v2","updated":"2026-02-23T16:07:40Z","published":"2026-02-11T07:53:51Z","title":"Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters","summary":"We introduce Step 3.5 Flash, a sparse Mixture-of-Experts (MoE) model that bridges frontier-level agentic intelligence and computational efficiency. We focus on what matters most when building agents: sharp reasoning and fast, reliable execution. Step 3.5 Flash pairs a 196B-parameter foundation with 11B active parameters for efficient inference. It is optimized with interleaved 3:1 sliding-window/full attention and Multi-Token Prediction (MTP-3) to reduce the latency and cost of multi-round agentic interactions. To reach frontier-level intelligence, we design a scalable reinforcement learning framework that combines verifiable signals with preference feedback, while remaining stable under large-scale off-policy training, enabling consistent self-improvement across mathematics, code, and tool use. Step 3.5 Flash demonstrates strong performance across agent, coding, and math tasks, achieving 85.4% on IMO-AnswerBench, 86.4% on LiveCodeBench-v6 (2024.08-2025.05), 88.2% on tau2-Bench, 69.0% on BrowseComp (with context management), and 51.0% on Terminal-Bench 2.0, comparable to frontier models such as GPT-5.2 xHigh and Gemini 3.0 Pro. By redefining the efficiency frontier, Step 3.5 Flash provides a high-density foundation for deploying sophisticated agents in real-world industrial environments.","authors":["Ailin Huang","Ang Li","Aobo Kong","Bin Wang","Binxing Jiao","Bo Dong","Bojun Wang","Boyu Chen","Brian Li","Buyun Ma","Chang Su","Changxin Miao","Changyi Wan","Chao Lou","Chen Hu","Chen Xu","Chenfeng Yu","Chengting Feng","Chengyuan Yao","Chunrui Han","Dan Ma","Dapeng Shi","Daxin Jiang","Dehua Ma","Deshan Sun","Di Qi","Enle Liu","Fajie Zhang","Fanqi Wan","Guanzhe Huang","Gulin Yan","Guoliang Cao","Guopeng Li","Han Cheng","Hangyu Guo","Hanshan Zhang","Hao Nie","Haonan Jia","Haoran Lv","Hebin Zhou","Hekun Lv","Heng Wang","Heung-Yeung Shum","Hongbo Huang","Hongbo Peng","Hongyu Zhou","Hongyuan Wang","Houyong Chen","Huangxi Zhu","Huimin Wu","Huiyong Guo","Jia Wang","Jian Zhou","Jianjian Sun","Jiaoren Wu","Jiaran Zhang","Jiashu Lv","Jiashuo Liu","Jiayi Fu","Jiayu Liu","Jie Cheng","Jie Luo","Jie Yang","Jie Zhou","Jieyi Hou","Jing Bai","Jingcheng Hu","Jingjing Xie","Jingwei Wu","Jingyang Zhang","Jishi Zhou","Junfeng Liu","Junzhe Lin","Ka Man Lo","Kai Liang","Kaibo Liu","Kaijun Tan","Kaiwen Yan","Kaixiang Li","Kang An","Kangheng Lin","Lei Yang","Liang Lv","Liang Zhao","Liangyu Chen","Lieyu Shi","Liguo Tan","Lin Lin","Lina Chen","Luck Ma","Mengqiang Ren","Michael Li","Ming Li","Mingliang Li","Mingming Zhang","Mingrui Chen","Mitt Huang","Na Wang","Peng Liu","Qi Han","Qian Zhao","Qinglin He","Qinxin Du","Qiuping Wu","Quan Sun","Rongqiu Yang","Ruihang Miao","Ruixin Han","Ruosi Wan","Ruyan Guo","Shan Wang","Shaoliang Pang","Shaowen Yang","Shengjie Fan","Shijie Shang","Shiliang Yang","Shiwei Li","Shuangshuang Tian","Siqi Liu","Siye Wu","Siyu Chen","Song Yuan","Tiancheng Cao","Tianchi Yue","Tianhao Cheng","Tianning Li","Tingdan Luo","Wang You","Wei Ji","Wei Yuan","Wei Zhang","Weibo Wu","Weihao Xie","Wen Sun","Wenjin Deng","Wenzhen Zheng","Wuxun Xie","Xiangfeng Wang","Xiangwen Kong","Xiangyu Liu","Xiangyu Zhang","Xiaobo Yang","Xiaojia Liu","Xiaolan Yuan","Xiaoran Jiao","Xiaoxiao Ren","Xiaoyun Zhang","Xin Li","Xin Liu","Xin Wu","Xing Chen","Xingping Yang","Xinran Wang","Xu Zhao","Xuan He","Xuanti Feng","Xuedan Cai","Xuqiang Zhou","Yanbo Yu","Yang Li","Yang Xu","Yanlin Lai","Yanming Xu","Yaoyu Wang","Yeqing Shen","Yibo Zhu","Yichen Lv","Yicheng Cao","Yifeng Gong","Yijing Yang","Yikun Yang","Yin Zhao","Yingxiu Zhao","Yinmin Zhang","Yitong Zhang","Yixuan Zhang","Yiyang Chen","Yongchi Zhao","Yongshen Long","Yongyao Wang","Yousong Guan","Yu Zhou","Yuang Peng","Yuanhao Ding","Yuantao Fan","Yuanwei Lu","Yuanzhen Yang","Yuchu Luo","Yudi Zhao","Yue Peng","Yueqiang Lin","Yufan Lu","Yuling Zhao","Yunzhou Ju","Yurong Zhang","Yusheng Li","Yuxiang Yang","Yuyang Chen","Yuzhu Cai","Zejia Weng","Zetao Hong","Zexi Li","Zhe Xie","Zheng Ge","Zheng Gong","Zheng Zeng","Zhenyi Lu","Zhewei Huang","Zhichao Chang","Zhiguo Huang","Zhiheng Hu","Zidong Yang","Zili Wang","Ziqi Ren","Zixin Zhang","Zixuan Wang"],"pdf_url":"","comment":"Technical report for Step 3.5 Flash"},{"id":"http://arxiv.org/abs/2512.07805v4","updated":"2026-02-23T15:57:05Z","published":"2025-12-08T18:39:13Z","title":"Group Representational Position Encoding","summary":"We present GRAPE (Group Representational Position Encoding), a unified framework for positional encoding based on group actions. GRAPE unifies two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\\operatorname{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\\mathrm{GL}$. In Multiplicative GRAPE, a position $n \\in \\mathbb{Z}$ (or $t \\in \\mathbb{R}$) acts as $\\mathbf{G}(n) = \\exp(n \\, ω\\, \\mathbf{L})$ with a rank-2 skew-symmetric generator $\\mathbf{L} \\in \\mathbb{R}^{d \\times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes correspond to canonical coordinate pairs with a log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise from rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Overall, GRAPE provides a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project page: https://github.com/model-architectures/GRAPE.","authors":["Yifan Zhang","Zixiang Chen","Yifeng Liu","Zhen Qin","Huizhuo Yuan","Kangping Xu","Yang Yuan","Quanquan Gu","Andrew Chi-Chih Yao"],"pdf_url":"","comment":"Published in ICLR 2026; Project Page: https://github.com/model-architectures/GRAPE"},{"id":"http://arxiv.org/abs/2602.19983v1","updated":"2026-02-23T15:51:23Z","published":"2026-02-23T15:51:23Z","title":"Contextual Safety Reasoning and Grounding for Open-World Robots","summary":"Robots are increasingly operating in open-world environments where safe behavior depends on context: the same hallway may require different navigation strategies when crowded versus empty, or during an emergency versus normal operations. Traditional safety approaches enforce fixed constraints in user-specified contexts, limiting their ability to handle the open-ended contextual variability of real-world deployment. We address this gap via CORE, a safety framework that enables online contextual reasoning, grounding, and enforcement without prior knowledge of the environment (e.g., maps or safety specifications). CORE uses a vision-language model (VLM) to continuously reason about context-dependent safety rules directly from visual observations, grounds these rules in the physical environment, and enforces the resulting spatially-defined safe sets via control barrier functions. We provide probabilistic safety guarantees for CORE that account for perceptual uncertainty, and we demonstrate through simulation and real-world experiments that CORE enforces contextually appropriate behavior in unseen environments, significantly outperforming prior semantic safety methods that lack online contextual reasoning. Ablation studies validate our theoretical guarantees and underscore the importance of both VLM-based reasoning and spatial grounding for enforcing contextual safety in novel settings. We provide additional resources at https://zacravichandran.github.io/CORE.","authors":["Zachary Ravichadran","David Snyder","Alexander Robey","Hamed Hassani","Vijay Kumar","George J. Pappas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19969v1","updated":"2026-02-23T15:30:52Z","published":"2026-02-23T15:30:52Z","title":"ReAttn: Improving Attention-based Re-ranking via Attention Re-weighting","summary":"The strong capabilities of recent Large Language Models (LLMs) have made them highly effective for zero-shot re-ranking task. Attention-based re-ranking methods, which derive relevance scores directly from attention weights, offer an efficient and interpretable alternative to generation-based re-ranking methods. However, they still face two major limitations. First, attention signals are highly concentrated a small subset of tokens within a few documents, making others indistinguishable. Second, attention often overemphasizes phrases lexically similar to the query, yielding biased rankings that irrelevant documents with mere lexical resemblance are regarded as relevant. In this paper, we propose \\textbf{ReAttn}, a post-hoc re-weighting strategy for attention-based re-ranking methods. It first compute the cross-document IDF weighting to down-weight attention on query-overlapping tokens that frequently appear across the candidate documents, reducing lexical bias and emphasizing distinctive terms. It then employs entropy-based regularization to mitigate over-concentrated attention, encouraging a more balanced distribution across informative tokens. Both adjustments operate directly on existing attention weights without additional training or supervision. Extensive experiments demonstrate the effectiveness of our method.","authors":["Yuxing Tian","Fengran Mo","Weixu Zhang","Yiyan Qi","Jian-Yun Nie"],"pdf_url":"","comment":"Accepted by EACL2026"},{"id":"http://arxiv.org/abs/2602.19964v1","updated":"2026-02-23T15:28:27Z","published":"2026-02-23T15:28:27Z","title":"On the Equivalence of Random Network Distillation, Deep Ensembles, and Bayesian Inference","summary":"Uncertainty quantification is central to safe and efficient deployments of deep learning models, yet many computationally practical methods lack lacking rigorous theoretical motivation. Random network distillation (RND) is a lightweight technique that measures novelty via prediction errors against a fixed random target. While empirically effective, it has remained unclear what uncertainties RND measures and how its estimates relate to other approaches, e.g. Bayesian inference or deep ensembles. This paper establishes these missing theoretical connections by analyzing RND within the neural tangent kernel framework in the limit of infinite network width. Our analysis reveals two central findings in this limit: (1) The uncertainty signal from RND -- its squared self-predictive error -- is equivalent to the predictive variance of a deep ensemble. (2) By constructing a specific RND target function, we show that the RND error distribution can be made to mirror the centered posterior predictive distribution of Bayesian inference with wide neural networks. Based on this equivalence, we moreover devise a posterior sampling algorithm that generates i.i.d. samples from an exact Bayesian posterior predictive distribution using this modified \\textit{Bayesian RND} model. Collectively, our findings provide a unified theoretical perspective that places RND within the principled frameworks of deep ensembles and Bayesian inference, and offer new avenues for efficient yet theoretically grounded uncertainty quantification methods.","authors":["Moritz A. Zanger","Yijun Wu","Pascal R. Van der Vaart","Wendelin Böhmer","Matthijs T. J. Spaan"],"pdf_url":"","comment":"8 pages, 1 Figure"},{"id":"http://arxiv.org/abs/2602.19948v1","updated":"2026-02-23T15:17:18Z","published":"2026-02-23T15:17:18Z","title":"Assessing Risks of Large Language Models in Mental Health Support: A Framework for Automated Clinical AI Red Teaming","summary":"Large Language Models (LLMs) are increasingly utilized for mental health support; however, current safety benchmarks often fail to detect the complex, longitudinal risks inherent in therapeutic dialogue. We introduce an evaluation framework that pairs AI psychotherapists with simulated patient agents equipped with dynamic cognitive-affective models and assesses therapy session simulations against a comprehensive quality of care and risk ontology. We apply this framework to a high-impact test case, Alcohol Use Disorder, evaluating six AI agents (including ChatGPT, Gemini, and Character.AI) against a clinically-validated cohort of 15 patient personas representing diverse clinical phenotypes.\n  Our large-scale simulation (N=369 sessions) reveals critical safety gaps in the use of AI for mental health support. We identify specific iatrogenic risks, including the validation of patient delusions (\"AI Psychosis\") and failure to de-escalate suicide risk. Finally, we validate an interactive data visualization dashboard with diverse stakeholders, including AI engineers and red teamers, mental health professionals, and policy experts (N=9), demonstrating that this framework effectively enables stakeholders to audit the \"black box\" of AI psychotherapy. These findings underscore the critical safety risks of AI-provided mental health support and the necessity of simulation-based clinical red teaming before deployment.","authors":["Ian Steenstra","Paola Pedrelli","Weiyan Shi","Stacy Marsella","Timothy W. Bickmore"],"pdf_url":"","comment":"This paper is a condensed version of the first author's Ph.D. dissertation submitted to Northeastern University"},{"id":"http://arxiv.org/abs/2602.19946v1","updated":"2026-02-23T15:15:53Z","published":"2026-02-23T15:15:53Z","title":"When Pretty Isn't Useful: Investigating Why Modern Text-to-Image Models Fail as Reliable Training Data Generators","summary":"Recent text-to-image (T2I) diffusion models produce visually stunning images and demonstrate excellent prompt following. But do they perform well as synthetic vision data generators? In this work, we revisit the promise of synthetic data as a scalable substitute for real training sets and uncover a surprising performance regression. We generate large-scale synthetic datasets using state-of-the-art T2I models released between 2022 and 2025, train standard classifiers solely on this synthetic data, and evaluate them on real test data. Despite observable advances in visual fidelity and prompt adherence, classification accuracy on real test data consistently declines with newer T2I models as training data generators. Our analysis reveals a hidden trend: These models collapse to a narrow, aesthetic-centric distribution that undermines diversity and label-image alignment. Overall, our findings challenge a growing assumption in vision research, namely that progress in generative realism implies progress in data realism. We thus highlight an urgent need to rethink the capabilities of modern T2I models as reliable training data generators.","authors":["Krzysztof Adamkiewicz","Brian Moser","Stanislav Frolov","Tobias Christian Nauen","Federico Raue","Andreas Dengel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19945v1","updated":"2026-02-23T15:15:47Z","published":"2026-02-23T15:15:47Z","title":"DP-FedAdamW: An Efficient Optimizer for Differentially Private Federated Large Models","summary":"Balancing convergence efficiency and robustness under Differential Privacy (DP) is a central challenge in Federated Learning (FL). While AdamW accelerates training and fine-tuning in large-scale models, we find that directly applying it to Differentially Private FL (DPFL) suffers from three major issues: (i) data heterogeneity and privacy noise jointly amplify the variance of second-moment estimator, (ii) DP perturbations bias the second-moment estimator, and (iii) DP amplify AdamW sensitivity to local overfitting, worsening client drift. We propose DP-FedAdamW, the first AdamW-based optimizer for DPFL. It restores AdamW under DP by stabilizing second-moment variance, removing DP-induced bias, and aligning local updates to the global descent to curb client drift. Theoretically, we establish an unbiased second-moment estimator and prove a linearly accelerated convergence rate without any heterogeneity assumption, while providing tighter $(\\varepsilon,δ)$-DP guarantees. Our empirical results demonstrate the effectiveness of DP-FedAdamW across language and vision Transformers and ResNet-18. On Tiny-ImageNet (Swin-Base, $\\varepsilon=1$), DP-FedAdamW outperforms the state-of-the-art (SOTA) by 5.83\\%. The code is available in Appendix.","authors":["Jin Liu","Yinbin Miao","Ning Xi","Junkang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.08550v2","updated":"2026-02-23T15:12:01Z","published":"2026-02-09T11:50:29Z","title":"GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing","summary":"Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting 3D geometric cues, which makes them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we introduce GOT-Edit, an online cross-modality model editing approach that integrates geometry-aware cues into a generic object tracker from a 2D video stream. Our approach leverages features from a pre-trained Visual Geometry Grounded Transformer to enable geometric cue inference from only a few 2D images. To tackle the challenge of seamlessly combining geometry and semantics, GOT-Edit performs online model editing with null-space constrained updates that incorporate geometric information while preserving semantic discrimination, yielding consistently better performance across diverse scenarios. Extensive experiments on multiple GOT benchmarks demonstrate that GOT-Edit achieves superior robustness and accuracy, particularly under occlusion and clutter, establishing a new paradigm for combining 2D semantics with 3D geometric reasoning for generic object tracking.","authors":["Shih-Fang Chen","Jun-Cheng Chen","I-Hong Jhuo","Yen-Yu Lin"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.19930v1","updated":"2026-02-23T15:06:33Z","published":"2026-02-23T15:06:33Z","title":"Beyond Mimicry: Toward Lifelong Adaptability in Imitation Learning","summary":"Imitation learning stands at a crossroads: despite decades of progress, current imitation learning agents remain sophisticated memorisation machines, excelling at replay but failing when contexts shift or goals evolve. This paper argues that this failure is not technical but foundational: imitation learning has been optimised for the wrong objective. We propose a research agenda that redefines success from perfect replay to compositional adaptability. Such adaptability hinges on learning behavioural primitives once and recombining them through novel contexts without retraining. We establish metrics for compositional generalisation, propose hybrid architectures, and outline interdisciplinary research directions drawing on cognitive science and cultural evolution. Agents that embed adaptability at the core of imitation learning thus have an essential capability for operating in an open-ended world.","authors":["Nathan Gavenski","Felipe Meneguzzi","Odinaldo Rodrigues"],"pdf_url":"","comment":"Accepted as part of the Blue Sky Ideas Track for the 25th International Conference on Autonomous Agents and Multiagent Systems"},{"id":"http://arxiv.org/abs/2602.19926v1","updated":"2026-02-23T15:05:28Z","published":"2026-02-23T15:05:28Z","title":"Rethinking LoRA for Privacy-Preserving Federated Learning in Large Models","summary":"Fine-tuning large vision models (LVMs) and large language models (LLMs) under differentially private federated learning (DPFL) is hindered by a fundamental privacy-utility trade-off. Low-Rank Adaptation (LoRA), a promising parameter-efficient fine-tuning (PEFT) method, reduces computational and communication costs by introducing two trainable low-rank matrices while freezing pre-trained weights. However, directly applying LoRA in DPFL settings leads to performance degradation, especially in LVMs. Our analysis reveals three previously underexplored challenges: (1) gradient coupling caused by the simultaneous update of two asymmetric low-rank matrices, (2) compounded noise amplification under differential privacy, and (3) sharpness of the global aggregated model in the parameter space. To address these issues, we propose LA-LoRA (\\textbf{L}ocal \\textbf{A}lternating \\textbf{LoRA}), a novel approach that decouples gradient interactions and aligns update directions across clients to enhance robustness under stringent privacy constraints. Theoretically, LA-LoRA strengthens convergence guarantees in noisy federated environments. Extensive experiments demonstrate that LA-LoRA achieves state-of-the-art (SOTA) performance on Swin Transformer and RoBERTa models, showcasing robustness to DP noise and broad applicability across both LVMs and LLMs. For example, when fine-tuning the Swin-B model on the Tiny-ImageNet dataset under a strict privacy budget ($ε= 1$), LA-LoRA outperforms the best baseline, RoLoRA, by 16.83\\% in test accuracy. Code is provided in \\repolink.","authors":["Jin Liu","Yinbin Miao","Ning Xi","Junkang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19914v1","updated":"2026-02-23T14:54:38Z","published":"2026-02-23T14:54:38Z","title":"Watson & Holmes: A Naturalistic Benchmark for Comparing Human and LLM Reasoning","summary":"Existing benchmarks for AI reasoning provide limited insight into how closely these capabilities resemble human reasoning in naturalistic contexts. We present an adaptation of the Watson & Holmes detective tabletop game as a new benchmark designed to evaluate reasoning performance using incrementally presented narrative evidence, open-ended questions and unconstrained language responses. An automated grading system was developed and validated against human assessors to enable scalable and replicable performance evaluation. Results show a clear improvement in AI model performance over time. Over nine months of 2025, model performance rose from the lower quartile of the human comparison group to approximately the top 5%. Around half of this improvement reflects steady advancement across successive model releases, while the remainder corresponds to a marked step change associated with reasoning-oriented model architectures. Systematic differences in the performance of AI models compared to humans, dependent on features of the specific detection puzzle, were mostly absent with the exception of a fall in performance for models when solving longer cases (case lengths being in the range of 1900-4000 words), and an advantage at inductive reasoning for reasoning models at early stages of case solving when evidence was scant.","authors":["Thatchawin Leelawat","Lewis D Griffin"],"pdf_url":"","comment":"51 pages, 13 figures"},{"id":"http://arxiv.org/abs/2508.06199v4","updated":"2026-02-23T14:41:11Z","published":"2025-08-08T10:29:24Z","title":"Benchmarking Pretrained Molecular Embedding Models For Molecular Representation Learning","summary":"Pretrained neural networks have attracted significant interest in chemistry and small molecule drug design. Embeddings from these models are widely used for molecular property prediction, virtual screening, and small data learning in molecular chemistry. This study presents the most extensive comparison of such models to date, evaluating 25 models across 25 datasets. Under a fair comparison framework, we assess models spanning various modalities, architectures, and pretraining strategies. Using a dedicated hierarchical Bayesian statistical testing model, we arrive at a surprising result: nearly all neural models show negligible or no improvement over the baseline ECFP molecular fingerprint. Only the CLAMP model, which is also based on molecular fingerprints, performs statistically significantly better than the alternatives. These findings raise concerns about the evaluation rigor in existing studies. We discuss potential causes, propose solutions, and offer practical recommendations.","authors":["Mateusz Praski","Jakub Adamczyk","Wojciech Czech"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2404.16890v2","updated":"2026-02-23T14:40:05Z","published":"2024-04-24T09:12:04Z","title":"Layer Collapse Can be Induced by Unstructured Pruning","summary":"Unstructured pruning is a popular compression method for efficiently reducing model parameters. However, while it effectively decreases the number of parameters, it is commonly believed that unstructured pruning cannot shorten the computational critical path, i.e., the maximum number of layers traversed during forward propagation.\n  In this paper, we study when and how unstructured pruning can yield structural effects. For rectifier-activated networks, we introduce the notion of neuron entropy, which quantifies the degree of nonlinearity utilization. We show that magnitude-based pruning naturally lowers this entropy, sometimes down to zero-entropy layers that become linearizable and can thus be removed. Building on this insight, we propose a method that leverages \"unstructured\" pruning to favor sparsity in low-entropy layers, enabling their complete removal. We validate the phenomenon across CNNs, Vision Transformers, and NLP models: unstructured pruning can induce effective layer removal with little or no performance degradation in over-parameterized networks.","authors":["Zhu Liao","Victor Quétu","Van-Tam Nguyen","Enzo Tartaglione"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.00017v3","updated":"2026-02-23T14:37:20Z","published":"2025-07-25T17:29:19Z","title":"Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation","summary":"We present Generative Logic (GL), a deterministic architecture that starts from user-supplied axiomatic definitions, written in a minimalist Mathematical Programming Language (MPL), and systematically explores a configurable region of their deductive neighborhood. A defining feature of the architecture is its unified hash-based inference engine, which executes both algebraic manipulations and deterministic logical transformations. Definitions are compiled into a distributed grid of simple Logic Blocks (LBs) that exchange messages; whenever the premises of an inference rule unify, a new fact is emitted with full provenance to its sources, yielding replayable, auditable proof graphs. Experimental validation is performed on Elementary Number Theory (ENT) utilizing a batched execution strategy. Starting from foundational axioms and definitions, the system first develops first-order Peano arithmetic, which is subsequently applied to autonomously derive and prove Gauss's summation formula as a main result. To manage combinatorial explosion, GL algorithmically enumerates conjectures and applies normalization, type constraints, and counterexample (CE) filtering. On commodity hardware, an end-to-end run completes in under 7 minutes. Generated proofs export as navigable HTML so that every inference step can be inspected independently. We outline a hardware-software co-design path toward massively parallel realizations and describe future integration with large language models (LLMs) for auto-formalization and conjecture seeding. The Python, C++, and MPL code to reproduce these experiments, along with the full proof graphs in HTML as well as machine-readable text format, are available in the project's GitHub repository at github.com/Generative-Logic/GL commit 1771330 and are permanently archived at doi:10.5281/zenodo.17206386.","authors":["Nikolai Sergeev"],"pdf_url":"","comment":"v3: Added derivation of Gauss summation formula, Logical Transformer section and batched workflow. Updated code/artifact links. 20 pages, 6 figures. Code and HTML proof graphs archived at Zenodo (DOI: 10.5281/zenodo.17206386)"},{"id":"http://arxiv.org/abs/2602.19881v1","updated":"2026-02-23T14:27:36Z","published":"2026-02-23T14:27:36Z","title":"Make Some Noise: Unsupervised Remote Sensing Change Detection Using Latent Space Perturbations","summary":"Unsupervised change detection (UCD) in remote sensing aims to localise semantic changes between two images of the same region without relying on labelled data during training. Most recent approaches rely either on frozen foundation models in a training-free manner or on training with synthetic changes generated in pixel space. Both strategies inherently rely on predefined assumptions about change types, typically introduced through handcrafted rules, external datasets, or auxiliary generative models. Due to these assumptions, such methods fail to generalise beyond a few change types, limiting their real-world usage, especially in rare or complex scenarios. To address this, we propose MaSoN (Make Some Noise), an end-to-end UCD framework that synthesises diverse changes directly in the latent feature space during training. It generates changes that are dynamically estimated using feature statistics of target data, enabling diverse yet data-driven variation aligned with the target domain. It also easily extends to new modalities, such as SAR. MaSoN generalises strongly across diverse change types and achieves state-of-the-art performance on five benchmarks, improving the average F1 score by 14.1 percentage points. Project page: https://blaz-r.github.io/mason_ucd","authors":["Blaž Rolih","Matic Fučka","Filip Wolf","Luka Čehovin Zajc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14674v3","updated":"2026-02-23T14:16:18Z","published":"2026-02-16T12:01:58Z","title":"From User Preferences to Base Score Extraction Functions in Gradual Argumentation (with Appendix)","summary":"Gradual argumentation is a field of symbolic AI which is attracting attention for its ability to support transparent and contestable AI systems. It is considered a useful tool in domains such as decision-making, recommendation, debate analysis, and others. The outcomes in such domains are usually dependent on the arguments' base scores, which must be selected carefully. Often, this selection process requires user expertise and may not always be straightforward. On the other hand, organising the arguments by preference could simplify the task. In this work, we introduce \\emph{Base Score Extraction Functions}, which provide a mapping from users' preferences over arguments to base scores. These functions can be applied to the arguments of a \\emph{Bipolar Argumentation Framework} (BAF), supplemented with preferences, to obtain a \\emph{Quantitative Bipolar Argumentation Framework} (QBAF), allowing the use of well-established computational tools in gradual argumentation. We outline the desirable properties of base score extraction functions, discuss some design choices, and provide an algorithm for base score extraction. Our method incorporates an approximation of non-linearities in human preferences to allow for better approximation of the real ones. Finally, we evaluate our approach both theoretically and experimentally in a robotics setting, and offer recommendations for selecting appropriate gradual semantics in practice.","authors":["Aniol Civit","Antonio Rago","Antonio Andriella","Guillem Alenyà","Francesca Toni"],"pdf_url":"","comment":"Accepted to AAMAS 2026 - With Appendix"},{"id":"http://arxiv.org/abs/2602.19872v1","updated":"2026-02-23T14:15:56Z","published":"2026-02-23T14:15:56Z","title":"GOAL: Geometrically Optimal Alignment for Continual Generalized Category Discovery","summary":"Continual Generalized Category Discovery (C-GCD) requires identifying novel classes from unlabeled data while retaining knowledge of known classes over time. Existing methods typically update classifier weights dynamically, resulting in forgetting and inconsistent feature alignment. We propose GOAL, a unified framework that introduces a fixed Equiangular Tight Frame (ETF) classifier to impose a consistent geometric structure throughout learning. GOAL conducts supervised alignment for labeled samples and confidence-guided alignment for novel samples, enabling stable integration of new classes without disrupting old ones. Experiments on four benchmarks show that GOAL outperforms the prior method Happy, reducing forgetting by 16.1% and boosting novel class discovery by 3.2%, establishing a strong solution for long-horizon continual discovery.","authors":["Jizhou Han","Chenhao Ding","SongLin Dong","Yuhang He","Shaokun Wang","Qiang Wang","Yihong Gong"],"pdf_url":"","comment":"Accept by AAAI 2026"},{"id":"http://arxiv.org/abs/2601.19657v4","updated":"2026-02-23T14:06:12Z","published":"2026-01-27T14:32:36Z","title":"One Token Is Enough: Improving Diffusion Language Models with a Sink Token","summary":"Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.","authors":["Zihou Zhang","Zheyong Xie","Li Zhong","Haifeng Liu","Yao Hu","Shaosheng Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.16874v2","updated":"2026-02-23T13:53:21Z","published":"2025-07-22T08:32:55Z","title":"Budget Allocation Policies for Real-Time Multi-Agent Path Finding","summary":"Multi-Agent Path finding (MAPF) is the problem of finding paths for a set of agents such that each agent reaches its desired destination while avoiding collisions with the other agents. This problem arises in many robotics applications, such as automated warehouses and swarms of drones. Many MAPF solvers are designed to run offline, that is, first generate paths for all agents and then execute them. In real-world scenarios, waiting for a complete solution before allowing any robot to move is often impractical. Real-time MAPF (RT-MAPF) captures this setting by assuming that agents must begin execution after a fixed planning period, referred to as the planning budget, and execute a fixed number of actions, referred to as the execution window. This results in an iterative process in which a short plan is executed, while the next execution window is planned concurrently. Existing solutions to RT-MAPF iteratively call windowed versions of MAPF algorithms in every planning period, without explicitly considering the size of the planning budget. We address this gap and explore different policies for allocating the planning budget in windowed versions of MAPF-LNS2, a state-of-the-art MAPF algorithm. Our exploration shows that the baseline approach in which all agents draw from a shared planning budget pool is ineffective in challenging scenarios. Instead, policies that intelligently distribute the planning budget among agents are able to solve more problem instances in less time.","authors":["Raz Beck","Roni Stern"],"pdf_url":"","comment":"11 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2505.22147v3","updated":"2026-02-23T13:51:27Z","published":"2025-05-28T09:08:27Z","title":"Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions","summary":"When allowing concurrent actions in Markov Decision Processes, whose state and action spaces grow exponentially in the number of objects, computing a policy becomes highly inefficient, as it requires enumerating the joint of the two spaces. For the case of indistinguishable objects, we present a first-order representation to tackle the exponential blow-up in the action and state spaces. We propose Foreplan, an efficient relational forward planner, which uses the first-order representation allowing to compute policies in space and time polynomially in the number of objects. Thus, Foreplan significantly increases the number of planning problems solvable in an exact manner in reasonable time, which we underscore with a theoretical analysis. To speed up computations even further, we also introduce an approximate version of Foreplan, including guarantees on the error. Further, we provide an empirical evaluation of both Foreplan versions, demonstrating a speedup of several orders of magnitude. For the approximate version of Foreplan, we also empirically show that the induced error is often negligible.","authors":["Florian Andreas Marwitz","Tanya Braun","Ralf Möller","Marcel Gehrke"],"pdf_url":"","comment":"Accepted at AAMAS 2026"},{"id":"http://arxiv.org/abs/2602.19844v1","updated":"2026-02-23T13:48:36Z","published":"2026-02-23T13:48:36Z","title":"LLM-enabled Applications Require System-Level Threat Monitoring","summary":"LLM-enabled applications are rapidly reshaping the software ecosystem by using large language models as core reasoning components for complex task execution. This paradigm shift, however, introduces fundamentally new reliability challenges and significantly expands the security attack surface, due to the non-deterministic, learning-driven, and difficult-to-verify nature of LLM behavior. In light of these emerging and unavoidable safety challenges, we argue that such risks should be treated as expected operational conditions rather than exceptional events, necessitating a dedicated incident-response perspective. Consequently, the primary barrier to trustworthy deployment is not further improving model capability but establishing system-level threat monitoring mechanisms that can detect and contextualize security-relevant anomalies after deployment -- an aspect largely underexplored beyond testing or guardrail-based defenses. Accordingly, this position paper advocates systematic and comprehensive monitoring of security threats in LLM-enabled applications as a prerequisite for reliable operation and a foundation for dedicated incident-response frameworks.","authors":["Yedi Zhang","Haoyu Wang","Xianglin Yang","Jin Song Dong","Jun Sun"],"pdf_url":"","comment":"26 pages"},{"id":"http://arxiv.org/abs/2602.19843v1","updated":"2026-02-23T13:47:43Z","published":"2026-02-23T13:47:43Z","title":"MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems","summary":"As LLM-based Multi-Agent Systems (MAS) are increasingly deployed for complex tasks, ensuring their reliability has become a pressing challenge. Since MAS coordinate through unstructured natural language rather than rigid protocols, they are prone to semantic failures (e.g., hallucinations, misinterpreted instructions, and reasoning drift) that propagate silently without raising runtime exceptions. Prevailing evaluation approaches, which measure only end-to-end task success, offer limited insight into how these failures arise or how effectively agents recover from them. To bridge this gap, we propose MAS-FIRE, a systematic framework for fault injection and reliability evaluation of MAS. We define a taxonomy of 15 fault types covering intra-agent cognitive errors and inter-agent coordination failures, and inject them via three non-invasive mechanisms: prompt modification, response rewriting, and message routing manipulation. Applying MAS-FIRE to three representative MAS architectures, we uncover a rich set of fault-tolerant behaviors that we organize into four tiers: mechanism, rule, prompt, and reasoning. This tiered view enables fine-grained diagnosis of where and why systems succeed or fail. Our findings reveal that stronger foundation models do not uniformly improve robustness. We further show that architectural topology plays an equally decisive role, with iterative, closed-loop designs neutralizing over 40% of faults that cause catastrophic collapse in linear workflows. MAS-FIRE provides the process-level observability and actionable guidance needed to systematically improve multi-agent systems.","authors":["Jin Jia","Zhiling Deng","Zhuangbin Chen","Yingqi Wang","Zibin Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24943v2","updated":"2026-02-23T13:41:40Z","published":"2025-12-31T16:09:08Z","title":"RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment","summary":"Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.","authors":["Chenji Lu","Zhuo Chen","Hui Zhao","Zhenyi Wang","Pengjie Wang","Chuan Yu","Jian Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19837v1","updated":"2026-02-23T13:39:58Z","published":"2026-02-23T13:39:58Z","title":"Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind's Adaptive Agent","summary":"Humans are highly effective at utilizing prior knowledge to adapt to novel tasks, a capability that standard machine learning models struggle to replicate due to their reliance on task-specific training. Meta-learning overcomes this limitation by allowing models to acquire transferable knowledge from various tasks, enabling rapid adaptation to new challenges with minimal data. This survey provides a rigorous, task-based formalization of meta-learning and meta-reinforcement learning and uses that paradigm to chronicle the landmark algorithms that paved the way for DeepMind's Adaptive Agent, consolidating the essential concepts needed to understand the Adaptive Agent and other generalist approaches.","authors":["Björn Hoppmann","Christoph Scholz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19822v1","updated":"2026-02-23T13:22:25Z","published":"2026-02-23T13:22:25Z","title":"Efficient endometrial carcinoma screening via cross-modal synthesis and gradient distillation","summary":"Early detection of myometrial invasion is critical for the staging and life-saving management of endometrial carcinoma (EC), a prevalent global malignancy. Transvaginal ultrasound serves as the primary, accessible screening modality in resource-constrained primary care settings; however, its diagnostic reliability is severely hindered by low tissue contrast, high operator dependence, and a pronounced scarcity of positive pathological samples. Existing artificial intelligence solutions struggle to overcome this severe class imbalance and the subtle imaging features of invasion, particularly under the strict computational limits of primary care clinics. Here we present an automated, highly efficient two-stage deep learning framework that resolves both data and computational bottlenecks in EC screening. To mitigate pathological data scarcity, we develop a structure-guided cross-modal generation network that synthesizes diverse, high-fidelity ultrasound images from unpaired magnetic resonance imaging (MRI) data, strictly preserving clinically essential anatomical junctions. Furthermore, we introduce a lightweight screening network utilizing gradient distillation, which transfers discriminative knowledge from a high-capacity teacher model to dynamically guide sparse attention towards task-critical regions. Evaluated on a large, multicenter cohort of 7,951 participants, our model achieves a sensitivity of 99.5\\%, a specificity of 97.2\\%, and an area under the curve of 0.987 at a minimal computational cost (0.289 GFLOPs), substantially outperforming the average diagnostic accuracy of expert sonographers. Our approach demonstrates that combining cross-modal synthetic augmentation with knowledge-driven efficient modeling can democratize expert-level, real-time cancer screening for resource-constrained primary care settings.","authors":["Dongjing Shan","Yamei Luo","Jiqing Xuan","Lu Huang","Jin Li","Mengchu Yang","Zeyu Chen","Fajin Lv","Yong Tang","Chunxiang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19818v1","updated":"2026-02-23T13:19:43Z","published":"2026-02-23T13:19:43Z","title":"SafePickle: Robust and Generic ML Detection of Malicious Pickle-based ML Models","summary":"Model repositories such as Hugging Face increasingly distribute machine learning artifacts serialized with Python's pickle format, exposing users to remote code execution (RCE) risks during model loading. Recent defenses, such as PickleBall, rely on per-library policy synthesis that requires complex system setups and verified benign models, which limits scalability and generalization. In this work, we propose a lightweight, machine-learning-based scanner that detects malicious Pickle-based files without policy generation or code instrumentation. Our approach statically extracts structural and semantic features from Pickle bytecode and applies supervised and unsupervised models to classify files as benign or malicious. We construct and release a labeled dataset of 727 Pickle-based files from Hugging Face and evaluate our models on four datasets: our own, PickleBall (out-of-distribution), Hide-and-Seek (9 advanced evasive malicious models), and synthetic joblib files. Our method achieves 90.01% F1-score compared with 7.23%-62.75% achieved by the SOTA scanners (Modelscan, Fickling, ClamAV, VirusTotal) on our dataset. Furthermore, on the PickleBall data (OOD), it achieves 81.22% F1-score compared with 76.09% achieved by the PickleBall method, while remaining fully library-agnostic. Finally, we show that our method is the only one to correctly parse and classify 9/9 evasive Hide-and-Seek malicious models specially crafted to evade scanners. This demonstrates that data-driven detection can effectively and generically mitigate Pickle-based model file attacks.","authors":["Hillel Ohayon","Daniel Gilkarov","Ran Dubin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02780v3","updated":"2026-02-23T13:17:25Z","published":"2025-11-04T18:03:12Z","title":"PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts","summary":"Smart contracts operate in a highly adversarial environment, where vulnerabilities can lead to substantial financial losses. Thus, smart contracts are subject to security audits. In auditing, proof-of-concept (PoC) exploits play a critical role by demonstrating to the stakeholders that the reported vulnerabilities are genuine, reproducible, and actionable. However, manually creating PoCs is time-consuming, error-prone, and often constrained by tight audit schedules. We introduce PoCo, an agentic framework that automatically generates executable PoC exploits from natural-language vulnerability descriptions written by auditors. PoCo autonomously generates PoC exploits in an agentic manner by interacting with a set of codeexecution tools in a Reason-Act-Observe loop. It produces fully executable exploits compatible with the Foundry testing framework, ready for integration into audit reports and other security tools. We evaluate PoCo on a dataset of 23 real-world vulnerability reports. PoCo consistently outperforms the Zero-shot and Workflow baselines, generating well-formed and logically correct PoCs. Our results demonstrate that agentic frameworks can significantly reduce the effort required for high-quality PoCs in smart contract audits. Our contribution provides actionable knowledge for the smart contract security community.","authors":["Vivi Andersson","Sofia Bobadilla","Harald Hobbelhagen","Martin Monperrus"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2602.19816v1","updated":"2026-02-23T13:13:41Z","published":"2026-02-23T13:13:41Z","title":"Depth-Structured Music Recurrence: Budgeted Recurrent Attention for Full-Piece Symbolic Music Modeling","summary":"Long-context modeling is essential for symbolic music generation, since motif repetition and developmental variation can span thousands of musical events. However, practical composition and performance workflows frequently rely on resource-limited devices (e.g., electronic instruments and portable computers), making heavy memory and attention computation difficult to deploy. We introduce Depth-Structured Music Recurrence (DSMR), a recurrent long-context Transformer for full-piece symbolic music modeling that extends context beyond fixed-length excerpts via segment-level recurrence with detached cross-segment states, featuring a layer-wise memory-horizon schedule that budgets recurrent KV states across depth. DSMR is trained in a single left-to-right pass over each complete composition, akin to how a musician experiences it from beginning to end, while carrying recurrent cross-segment states forward. Within this recurrent framework, we systematically study how depth-wise horizon allocations affect optimization, best-checkpoint perplexity, and efficiency. By allocating different history-window lengths across layers while keeping the total recurrent-state budget fixed, DSMR creates depth-dependent temporal receptive fields within a recurrent attention stack without reducing compute depth. Our main instantiation is a two-scale DSMR schedule that allocates long history windows to lower layers and a uniform short window to the remaining layers. Experiments on the piano performance dataset MAESTRO demonstrate that two-scale DSMR provides a practical quality--efficiency recipe for full-length long-context symbolic music modeling with recurrent attention under limited computational resources.","authors":["Yungang Yi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.17596v4","updated":"2026-02-23T13:11:55Z","published":"2024-12-23T14:13:44Z","title":"Evaluating LLMs' Divergent Thinking Capabilities for Scientific Idea Generation with Minimal Context","summary":"While Large Language Models (LLMs) demonstrate remarkable capabilities in scientific tasks such as literature analysis and experimental design (e.g., accurately extracting key findings from papers or generating coherent experimental procedures), existing evaluation benchmarks primarily assess performance using rich contextual inputs. We introduce LiveIdeaBench, a comprehensive benchmark evaluating LLMs' scientific idea generation by assessing divergent thinking capabilities using single-keyword prompts. Drawing from Guilford's creativity theory, our benchmark employs a dynamic panel of state-of-the-art LLMs to assess generated ideas across five key dimensions: originality, feasibility, fluency, flexibility, and clarity. Through extensive experimentation with over 40 leading models across 1,180 keywords spanning 22 scientific domains, we reveal that the scientific idea generation capabilities measured by our benchmark, are poorly predicted by standard metrics of general intelligence. Our results demonstrate that models like QwQ-32B-preview achieve creative performance comparable to top-tier models such as claude-3.7-sonnet:thinking, despite significant gaps in their general intelligence scores. These findings highlight the need for specialized evaluation benchmarks for scientific idea generation and suggest that enhancing these idea generation capabilities in LLMs may require different training strategies than those used for improving general problem-solving abilities, potentially enabling a wider range of AI tools tailored for different stages of the scientific process.","authors":["Kai Ruan","Xuan Wang","Jixiang Hong","Peng Wang","Yang Liu","Hao Sun"],"pdf_url":"","comment":"Updated manuscript and title"},{"id":"http://arxiv.org/abs/2602.19810v1","updated":"2026-02-23T13:10:01Z","published":"2026-02-23T13:10:01Z","title":"OpenClaw, Moltbook, and ClawdLab: From Agent-Only Social Networks to Autonomous Scientific Research","summary":"In January 2026, the open-source agent framework OpenClaw and the agent-only social network Moltbook produced a large-scale dataset of autonomous AI-to-AI interaction, attracting six academic publications within fourteen days. This study conducts a multivocal literature review of that ecosystem and presents ClawdLab, an open-source platform for autonomous scientific research, as a design science response to the architectural failure modes identified. The literature documents emergent collective phenomena, security vulnerabilities spanning 131 agent skills and over 15,200 exposed control panels, and five recurring architectural patterns. ClawdLab addresses these failure modes through hard role restrictions, structured adversarial critique, PI-led governance, multi-model orchestration, and domain-specific evidence requirements encoded as protocol constraints that ground validation in computational tool outputs rather than social consensus; the architecture provides emergent Sybil resistance as a structural consequence. A three-tier taxonomy distinguishes single-agent pipelines, predetermined multi-agent workflows, and fully decentralised systems, analysing why leading AI co-scientist platforms remain confined to the first two tiers. ClawdLab's composable third-tier architecture, in which foundation models, capabilities, governance, and evidence requirements are independently modifiable, enables compounding improvement as the broader AI ecosystem advances.","authors":["Lukas Weidener","Marko Brkić","Mihailo Jovanović","Ritvik Singh","Emre Ulgac","Aakaash Meduri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19805v1","updated":"2026-02-23T13:03:48Z","published":"2026-02-23T13:03:48Z","title":"Decision MetaMamba: Enhancing Selective SSM in Offline RL with Heterogeneous Sequence Mixing","summary":"Mamba-based models have drawn much attention in offline RL. However, their selective mechanism often detrimental when key steps in RL sequences are omitted. To address these issues, we propose a simple yet effective structure, called Decision MetaMamba (DMM), which replaces Mamba's token mixer with a dense layer-based sequence mixer and modifies positional structure to preserve local information. By performing sequence mixing that considers all channels simultaneously before Mamba, DMM prevents information loss due to selective scanning and residual gating. Extensive experiments demonstrate that our DMM delivers the state-of-the-art performance across diverse RL tasks. Furthermore, DMM achieves these results with a compact parameter footprint, demonstrating strong potential for real-world applications.","authors":["Wall Kim","Chaeyoung Song","Hanul Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.15888v2","updated":"2026-02-23T12:47:29Z","published":"2026-02-06T13:16:28Z","title":"NeuroSleep: Neuromorphic Event-Driven Single-Channel EEG Sleep Staging for Edge-Efficient Sensing","summary":"Objective. Reliable, continuous neural sensing on wearable edge platforms is fundamental to long-term health monitoring; however, for electroencephalography (EEG)-based sleep monitoring, dense high-frequency processing is often computationally prohibitive under tight energy budgets. Approach. To address this bottleneck, this paper proposes NeuroSleep, an integrated event-driven sensing and inference system for energy-efficient sleep staging. NeuroSleep first converts raw EEG into complementary multi-scale bipolar event streams using Residual Adaptive Multi-Scale Delta Modulation (R-AMSDM), enabling an explicit fidelity-sparsity trade-off at the sensing front end. Furthermore, NeuroSleep adopts a hierarchical inference architecture that comprises an Event-based Adaptive Multi-scale Response (EAMR) module for local feature extraction, a Local Temporal-Attention Module (LTAM) for context aggregation, and an Epoch-Leaky Integrate-and-Fire (ELIF) module to capture long-term state persistence. Main results. Experimental results using subject-independent 5-fold cross-validation on the Sleep-EDF Expanded sleep-cassette (SC) subset with single-channel EEG demonstrate that NeuroSleep achieves a mean accuracy of 74.2% with only 0.932 M parameters while reducing sparsity-adjusted effective operations by approximately 53.6% relative to dense processing. Compared to the representative dense Transformer baseline, NeuroSleep improves accuracy by 7.5% with a 45.8% reduction in computational load. Significance. By coupling neuromorphic event encoding with state-aware context modeling, NeuroSleep offers a deployment-oriented framework for single-channel sleep staging that reduces redundant high-rate processing and improves energy scalability for wearable and edge platforms.","authors":["Boyu Li","Xingchun Zhu","Yonghui Wu"],"pdf_url":"","comment":"14 pages, 5 figures, under review at Physiological Measurement"},{"id":"http://arxiv.org/abs/2602.19786v1","updated":"2026-02-23T12:42:05Z","published":"2026-02-23T12:42:05Z","title":"The Climate Change Knowledge Graph: Supporting Climate Services","summary":"Climate change impacts a broad spectrum of human resources and activities, necessitating the use of climate models to project long-term effects and inform mitigation and adaptation strategies. These models generate multiple datasets by running simulations across various scenarios and configurations, thereby covering a range of potential future outcomes. Currently, researchers rely on traditional search interfaces and APIs to retrieve such datasets, often piecing together information from metadata and community vocabularies. The Climate Change Knowledge Graph is designed to address these challenges by integrating diverse data sources related to climate simulations into a coherent and interoperable knowledge graph. This innovative resource allows for executing complex queries involving climate models, simulations, variables, spatio-temporal domains, and granularities. Developed with input from domain experts, the knowledge graph and its underlying ontology are published with open access license and provide a comprehensive framework that enhances the exploration of climate data, facilitating more informed decision-making in addressing climate change issues.","authors":["Miguel Ceriani","Fiorela Ciroku","Alessandro Russo","Massimiliano Schembri","Fai Fung","Neha Mittal","Vito Trianni","Andrea Giovanni Nuzzolese"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2305.11098v2","updated":"2026-02-23T12:33:45Z","published":"2023-05-18T16:34:51Z","title":"A Simple Generative Model of Logical Reasoning and Statistical Learning","summary":"Statistical learning and logical reasoning are two major fields of AI expected to be unified for human-like machine intelligence. Most existing work considers how to combine existing logical and statistical systems. However, there is no theory of inference so far explaining how basic approaches to statistical learning and logical reasoning stem from a common principle. Inspired by the fact that much empirical work in neuroscience suggests Bayesian (or probabilistic generative) approaches to brain function including learning and reasoning, we here propose a simple Bayesian model of logical reasoning and statistical learning. The theory is statistically correct as it satisfies Kolmogorov's axioms, is consistent with both Fenstad's representation theorem and maximum likelihood estimation and performs exact Bayesian inference with a linear-time complexity. The theory is logically correct as it is a data-driven generalisation of uncertain reasoning from consistency, possibility, inconsistency and impossibility. The theory is correct in terms of machine learning as its solution to generation and prediction tasks on the MNIST dataset is not only empirically reasonable but also theoretically correct against the K nearest neighbour method. We simply model how data causes symbolic knowledge in terms of its satisfiability in formal logic. Symbolic reasoning emerges as a result of the process of going the causality forwards and backwards. The forward and backward processes correspond to an interpretation and inverse interpretation in formal logic, respectively. The inverse interpretation differentiates our work from the mainstream often referred to as inverse entailment, inverse deduction or inverse resolution. The perspective gives new insights into learning and reasoning towards human-like machine intelligence.","authors":["Hiroyuki Kido"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.09257v4","updated":"2026-02-23T12:20:57Z","published":"2025-02-13T12:13:25Z","title":"From Contextual Combinatorial Semi-Bandits to Bandit List Classification: Improved Sample Complexity with Sparse Rewards","summary":"We study the problem of contextual combinatorial semi-bandits, where input contexts are mapped into subsets of size $m$ of a collection of $K$ possible actions. In each round, the learner observes the realized reward of the predicted actions. Motivated by prototypical applications of contextual bandits, we focus on the $s$-sparse regime where we assume that the sum of rewards is bounded by some value $s\\ll K$. For example, in recommendation systems the number of products purchased by any customer is significantly smaller than the total number of available products. Our main result is for the $(ε,δ)$-PAC variant of the problem for which we design an algorithm that returns an $ε$-optimal policy with high probability using a sample complexity of $\\tilde{O}((poly(K/m)+sm/ε^2) \\log(|Π|/δ))$ where $Π$ is the underlying (finite) class and $s$ is the sparsity parameter. This bound improves upon known bounds for combinatorial semi-bandits whenever $s\\ll K$, and in the regime where $s=O(1)$, the leading term is independent of $K$. Our algorithm is also computationally efficient given access to an ERM oracle for $Π$. Our framework generalizes the list multiclass classification problem with bandit feedback, which can be seen as a special case with binary reward vectors. In the special case of single-label classification corresponding to $s=m=1$, we prove an $O((K^7+1/ε^2)\\log(|H|/δ))$ sample complexity bound, which improves upon recent results in this scenario. Additionally, we consider the regret minimization setting where data can be generated adversarially, and establish a regret bound of $\\tilde O(|Π|+\\sqrt{smT\\log |Π|})$, extending the result of Erez et al. (2024) who consider the simpler single label classification setting.","authors":["Liad Erez","Tomer Koren"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19770v1","updated":"2026-02-23T12:20:37Z","published":"2026-02-23T12:20:37Z","title":"The Confusion is Real: GRAPHIC - A Network Science Approach to Confusion Matrices in Deep Learning","summary":"Explainable artificial intelligence has emerged as a promising field of research to address reliability concerns in artificial intelligence. Despite significant progress in explainable artificial intelligence, few methods provide a systematic way to visualize and understand how classes are confused and how their relationships evolve as training progresses. In this work, we present GRAPHIC, an architecture-agnostic approach that analyzes neural networks on a class level. It leverages confusion matrices derived from intermediate layers using linear classifiers. We interpret these as adjacency matrices of directed graphs, allowing tools from network science to visualize and quantify learning dynamics across training epochs and intermediate layers. GRAPHIC provides insights into linear class separability, dataset issues, and architectural behavior, revealing, for example, similarities between flatfish and man and labeling ambiguities validated in a human study. In summary, by uncovering real confusions, GRAPHIC offers new perspectives on how neural networks learn. The code is available at https://github.com/Johanna-S-Froehlich/GRAPHIC.","authors":["Johanna S. Fröhlich","Bastian Heinlein","Jan U. Claar","Hans Rosenberger","Vasileios Belagiannis","Ralf R. Müller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19762v1","updated":"2026-02-23T12:12:39Z","published":"2026-02-23T12:12:39Z","title":"Hexagon-MLIR: An AI Compilation Stack For Qualcomm's Neural Processing Units (NPUs)","summary":"In this paper, we present Hexagon-MLIR,an open-source compilation stack that targets Qualcomm Hexagon Neural Processing Unit (NPU) and provides unified support for lowering Triton kernels and PyTorch models . Built using the MLIR framework, our compiler applies a structured sequence of passes to exploit NPU architectural features to accelerate AI workloads. It enables faster deployment of new Triton kernels (hand-written or subgraphs from PyTorch 2.0), for our target by providing automated compilation from kernel to binary. By ingesting Triton kernels, we generate mega-kernels that maximize data locality in the NPU's Tightly Coupled Memory (TCM), reducing the bandwidth bottlenecks inherent in library-based approaches. This initiative complements our commercial toolchains by providing developers with an open-source MLIR-based compilation stack that gives them a path to advance AI compilation capabilities through a more flexible approach. Hexagon-MLIR is a work-in-progress, and we are continuing to add many more optimizations and capabilities in this effort.","authors":["Mohammed Javed Absar","Muthu Baskaran","Abhikrant Sharma","Abhilash Bhandari","Ankit Aggarwal","Arun Rangasamy","Dibyendu Das","Fateme Hosseini","Franck Slama","Iulian Brumar","Jyotsna Verma","Krishnaprasad Bindumadhavan","Mitesh Kothari","Mohit Gupta","Ravishankar Kolachana","Richard Lethin","Samarth Narang","Sanjay Motilal Ladwa","Shalini Jain","Snigdha Suresh Dalvi","Tasmia Rahman","Venkat Rasagna Reddy Komatireddy","Vivek Vasudevbhai Pandya","Xiyue Shi","Zachary Zipper"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2402.08646v2","updated":"2026-02-23T12:10:05Z","published":"2024-02-13T18:24:23Z","title":"Inference of Abstraction for a Unified Account of Symbolic Reasoning from Data","summary":"Inspired by empirical work in neuroscience for Bayesian approaches to brain function, we give a unified probabilistic account of various types of symbolic reasoning from data. We characterise them in terms of formal logic using the classical consequence relation, an empirical consequence relation, maximal consistent sets, maximal possible sets and maximum likelihood estimation. The theory gives new insights into reasoning towards human-like machine intelligence.","authors":["Hiroyuki Kido"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.19405v2","updated":"2026-02-23T11:57:41Z","published":"2025-09-23T09:09:45Z","title":"Improving Outdoor Multi-cell Fingerprinting-based Positioning via Mobile Data Augmentation","summary":"Accurate outdoor positioning in cellular networks is hindered by sparse, heterogeneous measurement collections and the high cost of exhaustive site surveys. This paper introduces a lightweight, modular mobile data augmentation framework designed to enhance multi-cell fingerprinting-based positioning using operator-collected minimization of drive test (MDT) records. The proposed approach decouples spatial and radio-feature synthesis: kernel density estimation (KDE) models the empirical spatial distribution to generate geographically coherent synthetic locations, while a k-nearest-neighbor (KNN)-based block produces augmented per-cell radio fingerprints. The architecture is intentionally training-free, interpretable, and suitable for distributed or on-premise operator deployments, supporting privacy-aware workflows. We both validate each augmentation module independently and assess its end-to-end impact on fingerprinting-based positioning using a real-world MDT dataset provided by an Italian mobile network operator across diverse urban and peri-urban scenarios. Results show that the proposed KDE-KNN augmentation consistently improves positioning performance with respect to state-of-the-art approaches, reducing the median positioning error by up to 30% in the most sparsely sampled or structurally complex regions. We also observe region-dependent saturation effects, which emerge most rapidly in scenarios with high user density where the information gain from additional synthetic samples quickly diminishes. Overall, the framework offers a practical, low-complexity path to enhance operator positioning services using existing mobile data traces.","authors":["Tony Chahoud","Lorenzo Mario Amorosa","Riccardo Marini","Luca De Nardis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.04272v4","updated":"2026-02-23T11:53:02Z","published":"2024-12-05T15:54:16Z","title":"PoTable: Towards Systematic Thinking via Plan-then-Execute Stage Reasoning on Tables","summary":"In recent years, table reasoning has garnered substantial research interest, particularly regarding its integration with Large Language Models (LLMs), which have revolutionized natural language applications. Existing LLM-based studies typically achieve step-by-step thinking for table reasoning guided by task semantics. While these approaches emphasize autonomous exploration and enhance fine-grained table understanding, they often overlook systematic thinking in the reasoning process. This oversight can lead to omitted steps, disorganized logic and misleading results, especially in complex scenarios. In this paper, we propose PoTable, a novel stage-oriented plan-then-execute approach that incorporates systematic thinking into table reasoning. Specifically, PoTable involves several distinct analytical stages with clear objectives to provide adequate guidance. To accomplish stage-specific goals, PoTable employs a plan-then-execute mechanism: it first plans the operation chain based on the stage objective, and then executes operations sequentially through code generation, real-time running and feedback processing. Consequently, PoTable produces reliable table reasoning results with highly accurate, step-wise commented and completely executable programs. It mirrors the workflow of a professional data analyst, offering advantages in both accuracy and explainability. Finally, we conduct extensive experiments on four datasets from the WikiTQ and TabFact benchmarks, where the results demonstrate the effectiveness, efficiency and explainability of PoTable. Our code is available at: https://github.com/Double680/PoTable.","authors":["Qingyang Mao","Qi Liu","Zhi Li","Mingyue Cheng","Zheng Zhang","Rui Li"],"pdf_url":"","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.17690v2","updated":"2026-02-23T11:36:42Z","published":"2026-02-06T05:10:19Z","title":"DesignAsCode: Bridging Structural Editability and Visual Fidelity in Graphic Design Generation","summary":"Graphic design generation demands a delicate balance between high visual fidelity and fine-grained structural editability. However, existing approaches typically bifurcate into either non-editable raster image synthesis or abstract layout generation devoid of visual content. Recent combinations of these two approaches attempt to bridge this gap but often suffer from rigid composition schemas and unresolvable visual dissonances (e.g., text-background conflicts) due to their inexpressive representation and open-loop nature. To address these challenges, we propose DesignAsCode, a novel framework that reimagines graphic design as a programmatic synthesis task using HTML/CSS. Specifically, we introduce a Plan-Implement-Reflect pipeline, incorporating a Semantic Planner to construct dynamic, variable-depth element hierarchies and a Visual-Aware Reflection mechanism that iteratively optimizes the code to rectify rendering artifacts. Extensive experiments demonstrate that DesignAsCode significantly outperforms state-of-the-art baselines in both structural validity and aesthetic quality. Furthermore, our code-native representation unlocks advanced capabilities, including automatic layout retargeting, complex document generation (e.g., resumes), and CSS-based animation. Our project page is available at https://liuziyuan1109.github.io/design-as-code/.","authors":["Ziyuan Liu","Shizhao Sun","Danqing Huang","Yingdong Shi","Meisheng Zhang","Ji Li","Jingsong Yu","Jiang Bian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.12313v2","updated":"2026-02-23T11:26:43Z","published":"2026-02-12T17:18:22Z","title":"Visible and Hyperspectral Imaging for Quality Assessment of Milk: Property Characterisation and Identification","summary":"Rapid and non-destructive assessment of milk quality is crucial to ensuring both nutritional value and food safety. In this study, we investigated the potential of visible and hyperspectral imaging as cost-effective and quick-response alternatives to conventional chemical analyses for characterizing key properties of cowś milk. A total of 52 milk samples were analysed to determine their biochemical composition (polyphenols, antioxidant capacity, and fatty acids) using spectrophotometer methods and standard gas-liquid and high-performance liquid chromatography (GLC/HPLC). Concurrently, visible (RGB) images were captured using a standard smartphone, and hyperspectral data were acquired in the near-infrared range. A comprehensive analytical framework, including eleven different machine learning algorithms, was employed to correlate imaging features with biochemical measurements. Analysis of visible images accurately distinguished between fresh samples and those stored for 12 days (100 percent accuracy) and achieved perfect discrimination between antibiotic-treated and untreated groups (100 percent accuracy). Moreover, image-derived features enabled perfect prediction of the polyphenols content and the antioxidant capacity using an XGBoost model. Hyperspectral imaging further achieved classification accuracies exceeding 95 percent for several individual fatty acids and 94.8 percent for treatment groups using a Random Forest model. These findings demonstrate that both visible and hyperspectral imaging, when coupled with machine learning, are powerful, non-invasive tools for the rapid assessment of milkś chemical and nutritional profiles, highlighting the strong potential of imaging-based approaches for milk quality assessment.","authors":["Massimo Martinelli","Elena Tomassi","Nafiou Arouna","Morena Gabriele","Laryssa Perez Fabbri","Luisa Pozzo","Bianca Castiglioni","Paola Cremonesi","Giuseppe Conte","Davide Moroni","Laura Pucci"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19718v1","updated":"2026-02-23T11:11:56Z","published":"2026-02-23T11:11:56Z","title":"Carbon-Aware Governance Gates: An Architecture for Sustainable GenAI Development","summary":"The rapid adoption of Generative AI (GenAI) in the software development life cycle (SDLC) increases computational demand, which can raise the carbon footprint of development activities. At the same time, organizations are increasingly embedding governance mechanisms into GenAI-assisted development to support trust, transparency, and accountability. However, these governance mechanisms introduce additional computational workloads, including repeated inference, regeneration cycles, and expanded validation pipelines, increasing energy use and the carbon footprint of GenAI-assisted development. This paper proposes Carbon-Aware Governance Gates (CAGG), an architectural extension that embeds carbon budgets, energy provenance, and sustainability-aware validation orchestration into human-AI governance layers. CAGG comprises three components: (i) an Energy and Carbon Provenance Ledger, (ii) a Carbon Budget Manager, and (iii) a Green Validation Orchestrator, operationalized through governance policies and reusable design patterns.","authors":["Mateen A. Abbasi","Tommi J. Mikkonen","Petri J. Ihantola","Muhammad Waseem","Pekka Abrahamsson","Niko K. Mäkitalo"],"pdf_url":"","comment":"5 pages, 1 figure. Preprint version under review"},{"id":"http://arxiv.org/abs/2509.18949v2","updated":"2026-02-23T11:07:21Z","published":"2025-09-23T12:58:32Z","title":"Towards Privacy-Aware Bayesian Networks: A Credal Approach","summary":"Bayesian networks (BN) are probabilistic graphical models that enable efficient knowledge representation and inference. These have proven effective across diverse domains, including healthcare, bioinformatics and economics. The structure and parameters of a BN can be obtained by domain experts or directly learned from available data. However, as privacy concerns escalate, it becomes increasingly critical for publicly released models to safeguard sensitive information in training data. Typically, released models do not prioritize privacy by design. In particular, tracing attacks from adversaries can combine the released BN with auxiliary data to determine whether specific individuals belong to the data from which the BN was learned. State-of-the-art protection tecniques involve introducing noise into the learned parameters. While this offers robust protection against tracing attacks, it significantly impacts the model's utility, in terms of both the significance and accuracy of the resulting inferences. Hence, high privacy may be attained at the cost of releasing a possibly ineffective model. This paper introduces credal networks (CN) as a novel solution for balancing the model's privacy and utility. After adapting the notion of tracing attacks, we demonstrate that a CN enables the masking of the learned BN, thereby reducing the probability of successful attacks. As CNs are obfuscated but not noisy versions of BNs, they can achieve meaningful inferences while safeguarding privacy. Moreover, we identify key learning information that must be concealed to prevent attackers from recovering the underlying BN. Finally, we conduct a set of numerical experiments to analyze how privacy gains can be modulated by tuning the CN hyperparameters. Our results confirm that CNs provide a principled, practical, and effective approach towards the development of privacy-aware probabilistic graphical models.","authors":["Niccolò Rocchi","Fabio Stella","Cassio de Campos"],"pdf_url":"","comment":"Accepted at ECAI2025 conference, 20 pages, 1 figure"},{"id":"http://arxiv.org/abs/2502.08941v3","updated":"2026-02-23T11:04:45Z","published":"2025-02-13T03:43:13Z","title":"Analysis of Off-Policy $n$-Step TD-Learning with Linear Function Approximation","summary":"This paper analyzes multi-step temporal difference (TD)-learning algorithms within the ``deadly triad'' scenario, characterized by linear function approximation, off-policy learning, and bootstrapping. In particular, we prove that $n$-step TD-learning algorithms converge to a solution as the sampling horizon $n$ increases sufficiently. The paper is divided into two parts. In the first part, we comprehensively examine the fundamental properties of their model-based deterministic counterparts, including projected value iteration, gradient descent algorithms, which can be viewed as prototype deterministic algorithms whose analysis plays a pivotal role in understanding and developing their model-free reinforcement learning counterparts. In particular, we prove that these algorithms converge to meaningful solutions when $n$ is sufficiently large. Based on these findings, in the second part, two $n$-step TD-learning algorithms are proposed and analyzed, which can be seen as the model-free reinforcement learning counterparts of the model-based deterministic algorithms.","authors":["Han-Dong Lim","Donghwan Lee"],"pdf_url":"","comment":"Added experiments for n-step PVI and n-step TD convergence/divergence"},{"id":"http://arxiv.org/abs/2602.16902v3","updated":"2026-02-23T11:03:50Z","published":"2026-02-18T21:33:59Z","title":"LLM-WikiRace Benchmark: How Far Can LLMs Plan over Real-World Knowledge Graphs?","summary":"We introduce LLM-Wikirace, a benchmark for evaluating planning, reasoning, and world knowledge in large language models (LLMs). In LLM-Wikirace, models must efficiently navigate Wikipedia hyperlinks step by step to reach a target page from a given source, requiring look-ahead planning and the ability to reason about how concepts are connected in the real world. We evaluate a broad set of open- and closed-source models, including Gemini-3, GPT-5, and Claude Opus 4.5, which achieve the strongest results on the easy level of the task and demonstrate superhuman performance. Despite this, performance drops sharply on hard difficulty: the best-performing model, Gemini-3, succeeds in only 23\\% of hard games, highlighting substantial remaining challenges for frontier models. Our analysis shows that world knowledge is a necessary ingredient for success, but only up to a point, beyond this threshold, planning and long-horizon reasoning capabilities become the dominant factors. Trajectory-level analysis further reveals that even the strongest models struggle to replan after failure, frequently entering loops rather than recovering. LLM-Wikirace is a simple benchmark that reveals clear limitations in current reasoning systems, offering an open arena where planning-capable LLMs still have much to prove. Our code and leaderboard available at https:/llmwikirace.github.io.","authors":["Juliusz Ziomek","William Bankes","Lorenz Wolf","Shyam Sundhar Ramesh","Xiaohang Tang","Ilija Bogunovic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19702v1","updated":"2026-02-23T10:52:20Z","published":"2026-02-23T10:52:20Z","title":"DReX: An Explainable Deep Learning-based Multimodal Recommendation Framework","summary":"Multimodal recommender systems leverage diverse data sources, such as user interactions, content features, and contextual information, to address challenges like cold-start and data sparsity. However, existing methods often suffer from one or more key limitations: processing different modalities in isolation, requiring complete multimodal data for each interaction during training, or independent learning of user and item representations. These factors contribute to increased complexity and potential misalignment between user and item embeddings. To address these challenges, we propose DReX, a unified multimodal recommendation framework that incrementally refines user and item representations by leveraging interaction-level features from multimodal feedback. Our model employs gated recurrent units to selectively integrate these fine-grained features into global representations. This incremental update mechanism provides three key advantages: (1) simultaneous modeling of both nuanced interaction details and broader preference patterns, (2) eliminates the need for separate user and item feature extraction processes, leading to enhanced alignment in their learned representation, and (3) inherent robustness to varying or missing modalities. We evaluate the performance of the proposed approach on three real-world datasets containing reviews and ratings as interaction modalities. By considering review text as a modality, our approach automatically generates interpretable keyword profiles for both users and items, which supplement the recommendation process with interpretable preference indicators. Experiment results demonstrate that our approach outperforms state-of-the-art methods across all evaluated datasets.","authors":["Adamya Shyam","Venkateswara Rao Kagita","Bharti Rana","Vikas Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19698v1","updated":"2026-02-23T10:44:27Z","published":"2026-02-23T10:44:27Z","title":"Iconographic Classification and Content-Based Recommendation for Digitized Artworks","summary":"We present a proof-of-concept system that automates iconographic classification and content-based recommendation of digitized artworks using the Iconclass vocabulary and selected artificial intelligence methods. The prototype implements a four-stage workflow for classification and recommendation, which integrates YOLOv8 object detection with algorithmic mappings to Iconclass codes, rule-based inference for abstract meanings, and three complementary recommenders (hierarchical proximity, IDF-weighted overlap, and Jaccard similarity). Although more engineering is still needed, the evaluation demonstrates the potential of this solution: Iconclass-aware computer vision and recommendation methods can accelerate cataloging and enhance navigation in large heritage repositories. The key insight is to let computer vision propose visible elements and to use symbolic structures (Iconclass hierarchy) to reach meaning.","authors":["Krzysztof Kutt","Maciej Baczyński"],"pdf_url":"","comment":"14 pages, 7 figures; submitted to ICCS 2026 conference"},{"id":"http://arxiv.org/abs/2510.16703v2","updated":"2026-02-23T10:35:13Z","published":"2025-10-19T04:13:09Z","title":"On the Granularity of Causal Effect Identifiability","summary":"The classical notion of causal effect identifiability is defined in terms of treatment and outcome variables. In this paper, we consider the identifiability of state-based causal effects: how an intervention on a particular state of treatment variables affects a particular state of outcome variables. We demonstrate that state-based causal effects may be identifiable even when variable-based causal effects may not. Moreover, we show that this separation occurs only when additional knowledge -- such as context-specific independencies -- is available. We further examine knowledge that constrains the states of variables, and show that such knowledge can improve both variable-based and state-based identifiability when combined with other knowledge such as context-specific independencies. We finally propose an approach for identifying causal effects under these additional constraints, and conduct empirical studies to further illustrate the separations between the two levels of identifiability.","authors":["Yizuo Chen","Adnan Darwiche"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.15082v2","updated":"2026-02-23T10:34:04Z","published":"2026-02-16T10:28:38Z","title":"S-PRESSO: Ultra Low Bitrate Sound Effect Compression With Diffusion Autoencoders And Offline Quantization","summary":"Neural audio compression models have recently achieved extreme compression rates, enabling efficient latent generative modeling. Conversely, latent generative models have been applied to compression, pushing the limits of continuous and discrete approaches. However, existing methods remain constrained to low-resolution audio and degrade substantially at very low bitrates, where audible artifacts are prominent. In this paper, we present S-PRESSO, a 48kHz sound effect compression model that produces both continuous and discrete embeddings at ultra-low bitrates, down to 0.096 kbps, via offline quantization. Our model relies on a pretrained latent diffusion model to decode compressed audio embeddings learned by a latent encoder. Leveraging the generative priors of the diffusion decoder, we achieve extremely low frame rates, down to 1Hz (750x compression rate), producing convincing and realistic reconstructions at the cost of exact fidelity. Despite operating at high compression rates, we demonstrate that S-PRESSO outperforms both continuous and discrete baselines in audio quality, acoustic similarity and reconstruction metrics.","authors":["Zineb Lahrichi","Gaëtan Hadjeres","Gaël Richard","Geoffroy Peeters"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19685v1","updated":"2026-02-23T10:28:56Z","published":"2026-02-23T10:28:56Z","title":"PerturbDiff: Functional Diffusion for Single-Cell Perturbation Modeling","summary":"Building Virtual Cells that can accurately simulate cellular responses to perturbations is a long-standing goal in systems biology. A fundamental challenge is that high-throughput single-cell sequencing is destructive: the same cell cannot be observed both before and after a perturbation. Thus, perturbation prediction requires mapping unpaired control and perturbed populations. Existing models address this by learning maps between distributions, but typically assume a single fixed response distribution when conditioned on observed cellular context (e.g., cell type) and the perturbation type. In reality, responses vary systematically due to unobservable latent factors such as microenvironmental fluctuations and complex batch effects, forming a manifold of possible distributions for the same observed conditions. To account for this variability, we introduce PerturbDiff, which shifts modeling from individual cells to entire distributions. By embedding distributions as points in a Hilbert space, we define a diffusion-based generative process operating directly over probability distributions. This allows PerturbDiff to capture population-level response shifts across hidden factors. Benchmarks on established datasets show that PerturbDiff achieves state-of-the-art performance in single-cell response prediction and generalizes substantially better to unseen perturbations. See our project page (https://katarinayuan.github.io/PerturbDiff-ProjectPage/), where code and data will be made publicly available (https://github.com/DeepGraphLearning/PerturbDiff).","authors":["Xinyu Yuan","Xixian Liu","Ya Shi Zhang","Zuobai Zhang","Hongyu Guo","Jian Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19679v1","updated":"2026-02-23T10:22:52Z","published":"2026-02-23T10:22:52Z","title":"TeHOR: Text-Guided 3D Human and Object Reconstruction with Textures","summary":"Joint reconstruction of 3D human and object from a single image is an active research area, with pivotal applications in robotics and digital content creation. Despite recent advances, existing approaches suffer from two fundamental limitations. First, their reconstructions rely heavily on physical contact information, which inherently cannot capture non-contact human-object interactions, such as gazing at or pointing toward an object. Second, the reconstruction process is primarily driven by local geometric proximity, neglecting the human and object appearances that provide global context crucial for understanding holistic interactions. To address these issues, we introduce TeHOR, a framework built upon two core designs. First, beyond contact information, our framework leverages text descriptions of human-object interactions to enforce semantic alignment between the 3D reconstruction and its textual cues, enabling reasoning over a wider spectrum of interactions, including non-contact cases. Second, we incorporate appearance cues of the 3D human and object into the alignment process to capture holistic contextual information, thereby ensuring visually plausible reconstructions. As a result, our framework produces accurate and semantically coherent reconstructions, achieving state-of-the-art performance.","authors":["Hyeongjin Nam","Daniel Sungho Jung","Kyoung Mu Lee"],"pdf_url":"","comment":"Published at CVPR 2026, 20 pages including the supplementary material"},{"id":"http://arxiv.org/abs/2507.23465v3","updated":"2026-02-23T10:22:06Z","published":"2025-07-31T11:41:04Z","title":"Role-Aware Language Models for Secure and Contextualized Access Control in Organizations","summary":"As large language models (LLMs) are increasingly deployed in enterprise settings, controlling model behavior based on user roles becomes an essential requirement. Existing safety methods typically assume uniform access and focus on preventing harmful or toxic outputs, without addressing role-specific access constraints. In this work, we investigate whether LLMs can be fine-tuned to generate responses that reflect the access privileges associated with different organizational roles. We explore three modeling strategies: a BERT-based classifier, an LLM-based classifier, and role-conditioned generation. To evaluate these approaches, we construct two complementary datasets. The first is adapted from existing instruction-tuning corpora through clustering and role labeling, while the second is synthetically generated to reflect realistic, role-sensitive enterprise scenarios. We assess model performance across varying organizational structures and analyze robustness to prompt injection, role mismatch, and jailbreak attempts.","authors":["Saeed Almheiri","Yerulan Kongrat","Adrian Santosh","Ruslan Tasmukhanov","Josemaria Loza Vera","Muhammad Dehan Al Kautsar","Fajri Koto"],"pdf_url":"","comment":"AACL 2025 - Main"},{"id":"http://arxiv.org/abs/2602.19674v1","updated":"2026-02-23T10:19:17Z","published":"2026-02-23T10:19:17Z","title":"Continuous Telemonitoring of Heart Failure using Personalised Speech Dynamics","summary":"Remote monitoring of heart failure (HF) via speech signals provides a non-invasive and cost-effective solution for long-term patient management. However, substantial inter-individual heterogeneity in vocal characteristics often limits the accuracy of traditional cross-sectional classification models. To address this, we propose a Longitudinal Intra-Patient Tracking (LIPT) scheme designed to capture the trajectory of relative symptomatic changes within individuals. Central to this framework is a Personalised Sequential Encoder (PSE), which transforms longitudinal speech recordings into context-aware latent representations. By incorporating historical data at each timestamp, the PSE facilitates a holistic assessment of the clinical trajectory rather than modelling discrete visits independently. Experimental results from a cohort of 225 patients demonstrate that the LIPT paradigm significantly outperforms the classic cross-sectional approaches, achieving a recognition accuracy of 99.7% for clinical status transitions. The model's high sensitivity was further corroborated by additional follow-up data, confirming its efficacy in predicting HF deterioration and its potential to secure patient safety in remote, home-based settings. Furthermore, this work addresses the gap in existing literature by providing a comprehensive analysis of different speech task designs and acoustic features. Taken together, the superior performance of the LIPT framework and PSE architecture validates their readiness for integration into long-term telemonitoring systems, offering a scalable solution for remote heart failure management.","authors":["Yue Pan","Xingyao Wang","Hanyue Zhang","Liwei Liu","Changxin Li","Gang Yang","Rong Sheng","Yili Xia","Ming Chu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19672v1","updated":"2026-02-23T10:17:25Z","published":"2026-02-23T10:17:25Z","title":"SkillOrchestra: Learning to Route Agents via Skill Transfer","summary":"Compound AI systems promise capabilities beyond those of individual models, yet their success depends critically on effective orchestration. Existing routing approaches face two limitations: (1) input-level routers make coarse query-level decisions that ignore evolving task requirements; (2) RL-trained orchestrators are expensive to adapt and often suffer from routing collapse, repeatedly invoking one strong but costly option in multi-turn scenarios. We introduce SkillOrchestra, a framework for skill-aware orchestration. Instead of directly learning a routing policy end-to-end, SkillOrchestra learns fine-grained skills from execution experience and models agent-specific competence and cost under those skills. At deployment, the orchestrator infers the skill demands of the current interaction and selects agents that best satisfy them under an explicit performance-cost trade-off. Extensive experiments across ten benchmarks demonstrate that SkillOrchestra outperforms SoTA RL-based orchestrators by up to 22.5% with 700x and 300x learning cost reduction compared to Router-R1 and ToolOrchestra, respectively. These results show that explicit skill modeling enables scalable, interpretable, and sample-efficient orchestration, offering a principled alternative to data-intensive RL-based approaches. The code is available at: https://github.com/jiayuww/SkillOrchestra.","authors":["Jiayu Wang","Yifei Ming","Zixuan Ke","Shafiq Joty","Aws Albarghouthi","Frederic Sala"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.07755v3","updated":"2026-02-23T10:14:07Z","published":"2025-05-12T17:02:02Z","title":"Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems","summary":"Edge computing has emerged as a pivotal technology, offering significant advantages such as low latency, enhanced data security, and reduced reliance on centralized cloud infrastructure. These benefits are crucial for applications requiring real-time data processing or strict security measures. Despite these advantages, edge devices operating within edge clusters are often underutilized. This inefficiency is mainly due to the absence of a holistic performance profiling mechanism which can help dynamically adjust the desired system configuration for a given workload. Since edge computing environments involve a complex interplay between CPU frequency, power consumption, and application performance, a deeper understanding of these correlations is essential. By uncovering these relationships, it becomes possible to make informed decisions that enhance both computational efficiency and energy savings. To address this gap, this paper evaluates the power consumption and performance characteristics of a single processing node within an edge cluster using a synthetic microbenchmark by varying the workload size and CPU frequency. The results show how an optimal measure can lead to optimized usage of edge resources, given both performance and power consumption.","authors":["Tomasz Szydlo","Viacheslav Horbanov","Devki Nandan Jha","Shashikant Ilager","Aleksander Slominski","Rajiv Ranjan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.08549v3","updated":"2026-02-23T10:11:13Z","published":"2026-01-13T13:36:38Z","title":"Contrastive and Multi-Task Learning on Noisy Brain Signals with Nonlinear Dynamical Signatures","summary":"We introduce a two-stage multitask learning framework for analyzing Electroencephalography (EEG) signals that integrates denoising, dynamical modeling, and representation learning. In the first stage, a denoising autoencoder is trained to suppress artifacts and stabilize temporal dynamics, providing robust signal representations. In the second stage, a multitask architecture processes these denoised signals to achieve three objectives: motor imagery classification, chaotic versus non-chaotic regime discrimination using Lyapunov exponent-based labels, and self-supervised contrastive representation learning with NT-Xent loss. A convolutional backbone combined with a Transformer encoder captures spatial-temporal structure, while the dynamical task encourages sensitivity to nonlinear brain dynamics. This staged design mitigates interference between reconstruction and discriminative goals, improves stability across datasets, and supports reproducible training by clearly separating noise reduction from higher-level feature learning. Empirical studies show that our framework not only enhances robustness and generalization but also surpasses strong baselines and recent state-of-the-art methods in EEG decoding, highlighting the effectiveness of combining denoising, dynamical features, and self-supervised learning.","authors":["Sucheta Ghosh","Felix Dietrich","Zahra Monfared"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22387v2","updated":"2026-02-23T10:05:41Z","published":"2025-09-26T14:15:44Z","title":"SpinGPT: A Large-Language-Model Approach to Playing Poker Correctly","summary":"The Counterfactual Regret Minimization (CFR) algorithm and its variants have enabled the development of pokerbots capable of beating the best human players in heads-up (1v1) cash games and competing with them in six-player formats. However, CFR's computational complexity rises exponentially with the number of players. Furthermore, in games with three or more players, following Nash equilibrium no longer guarantees a non-losing outcome. These limitations, along with others, significantly restrict the applicability of CFR to the most popular formats: tournaments. Motivated by the recent success of Large Language Models (LLM) in chess and Diplomacy, we present SpinGPT, the first LLM tailored to Spin & Go, a popular three-player online poker format. SpinGPT is trained in two stages: (1) Supervised Fine-Tuning on 320k high-stakes expert decisions; (2) Reinforcement Learning on 270k solver-generated hands. Our results show that SpinGPT matches the solver's actions in 78% of decisions (tolerant accuracy). With a simple deep-stack heuristic, it achieves 13.4 +/- 12.9 BB/100 versus Slumbot in heads-up over 30,000 hands (95% CI). These results suggest that LLMs could be a new way to deal with multi-player imperfect-information games like poker.","authors":["Narada Maugin","Tristan Cazenave"],"pdf_url":"","comment":"Accepted at Advances in Computer Games (ACG) 2025, LNCS (Springer)"},{"id":"http://arxiv.org/abs/2510.03734v2","updated":"2026-02-23T10:04:26Z","published":"2025-10-04T08:38:03Z","title":"Cost Efficient Fairness Audit Under Partial Feedback","summary":"We study the problem of auditing the fairness of a given classifier under partial feedback, where true labels are available only for positively classified individuals, (e.g., loan repayment outcomes are observed only for approved applicants). We introduce a novel cost model for acquiring additional labeled data, designed to more accurately reflect real-world costs such as credit assessment, loan processing, and potential defaults. Our goal is to find optimal fairness audit algorithms that are more cost-effective than random exploration and natural baselines.\n  In our work, we consider two audit settings: a black-box model with no assumptions on the data distribution, and a mixture model, where features and true labels follow a mixture of exponential family distributions. In the black-box setting, we propose a near-optimal auditing algorithm under mild assumptions and show that a natural baseline can be strictly suboptimal. In the mixture model setting, we design a novel algorithm that achieves significantly lower audit cost than the black-box case. Our approach leverages prior work on learning from truncated samples and maximum-a-posteriori oracles, and extends known results on spherical Gaussian mixtures to handle exponential family mixtures, which may be of independent interest. Moreover, our algorithms apply to popular fairness metrics including demographic parity, equal opportunity, and equalized odds. Empirically, we demonstrate strong performance of our algorithms on real-world fair classification datasets like Adult Income and Law School, consistently outperforming natural baselines by around 50% in terms of audit cost.","authors":["Nirjhar Das","Mohit Sharma","Praharsh Nanavati","Kirankumar Shiragur","Amit Deshpande"],"pdf_url":"","comment":"Accepted at NeurIPS 2025 RegML Workshop; Reliable ML Workshop"},{"id":"http://arxiv.org/abs/2602.19655v1","updated":"2026-02-23T09:59:03Z","published":"2026-02-23T09:59:03Z","title":"Representation Stability in a Minimal Continual Learning Agent","summary":"Continual learning systems are increasingly deployed in environments where retraining or reset is infeasible, yet many approaches emphasize task performance rather than the evolution of internal representations over time. In this work, we study a minimal continual learning agent designed to isolate representational dynamics from architectural complexity and optimization objectives. The agent maintains a persistent state vector across executions and incrementally updates it as new textual data is introduced. We quantify representational change using cosine similarity between successive normalized state vectors and define a stability metric over time intervals. Longitudinal experiments across eight executions reveal a transition from an initial plastic regime to a stable representational regime under consistent input. A deliberately introduced semantic perturbation produces a bounded decrease in similarity, followed by recovery and restabilization under subsequent coherent input. These results demonstrate that meaningful stability plasticity tradeoffs can emerge in a minimal, stateful learning system without explicit regularization, replay, or architectural complexity. The work establishes a transparent empirical baseline for studying representational accumulation and adaptation in continual learning systems.","authors":["Vishnu Subramanian"],"pdf_url":"","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2602.19654v1","updated":"2026-02-23T09:56:22Z","published":"2026-02-23T09:56:22Z","title":"NEXUS : A compact neural architecture for high-resolution spatiotemporal air quality forecasting in Delhi Nationa Capital Region","summary":"Urban air pollution in megacities poses critical public health challenges, particularly in Delhi National Capital Region (NCR) where severe degradation affects millions. We present NEXUS (Neural Extraction and Unified Spatiotemporal) architecture for forecasting carbon monoxide, nitrogen oxide, and sulfur dioxide. Working with four years (2018--2021) of atmospheric data across sixteen spatial grids, NEXUS achieves R$^2$ exceeding 0.94 for CO, 0.91 for NO, and 0.95 for SO$_2$ using merely 18,748 parameters -- substantially fewer than SCINet (35,552), Autoformer (68,704), and FEDformer (298,080). The architecture integrates patch embedding, low-rank projections, and adaptive fusion mechanisms to decode complex atmospheric chemistry patterns. Our investigation uncovers distinct diurnal rhythms and pronounced seasonal variations, with winter months experiencing severe pollution episodes driven by temperature inversions and agricultural biomass burning. Analysis identifies critical meteorological thresholds, quantifies wind field impacts on pollutant dispersion, and maps spatial heterogeneity across the region. Extensive ablation experiments demonstrate each architectural component's role. NEXUS delivers superior predictive performance with remarkable computational efficiency, enabling real-time deployment for air quality monitoring systems.","authors":["Rampunit Kumar","Aditya Maheshwari"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2602.19651v1","updated":"2026-02-23T09:53:23Z","published":"2026-02-23T09:53:23Z","title":"Denoising Particle Filters: Learning State Estimation with Single-Step Objectives","summary":"Learning-based methods commonly treat state estimation in robotics as a sequence modeling problem. While this paradigm can be effective at maximizing end-to-end performance, models are often difficult to interpret and expensive to train, since training requires unrolling sequences of predictions in time. As an alternative to end-to-end trained state estimation, we propose a novel particle filtering algorithm in which models are trained from individual state transitions, fully exploiting the Markov property in robotic systems. In this framework, measurement models are learned implicitly by minimizing a denoising score matching objective. At inference, the learned denoiser is used alongside a (learned) dynamics model to approximately solve the Bayesian filtering equation at each time step, effectively guiding predicted states toward the data manifold informed by measurements. We evaluate the proposed method on challenging robotic state estimation tasks in simulation, demonstrating competitive performance compared to tuned end-to-end trained baselines. Importantly, our method offers the desirable composability of classical filtering algorithms, allowing prior information and external sensor models to be incorporated without retraining.","authors":["Lennart Röstel","Berthold Bäuml"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.05695v2","updated":"2026-02-23T09:49:19Z","published":"2026-02-05T14:21:00Z","title":"SweetSpot: An Analytical Model for Predicting Energy Efficiency of LLM Inference","summary":"Large Language Models (LLMs) inference is central to modern AI applications, dominating worldwide datacenter workloads, making it critical to predict its energy footprint. Existing approaches estimate energy consumption as a simple linear function of input and output sequence. However, by analyzing the autoregressive structure of Transformers, which implies a fundamentally non-linear relationship between input and output sequence lengths and energy consumption, we demonstrate the existence of a generation energy minima. Peak efficiency occurs with short-to-moderate inputs and medium-length outputs, while efficiency drops sharply for long inputs or very short outputs. Consequently, we propose SweetSpot, an analytical model derived from the computational and memory-access complexity of the Transformer architecture, which accurately characterizes the efficiency curve as a function of input and output lengths. To assess accuracy, we measure energy consumption using TensorRT-LLM on NVIDIA H100 GPUs across a diverse set of LLMs ranging from 1B to 9B parameters, including OPT, LLaMA, Gemma, Falcon, Qwen2, and Granite. We test input and output lengths from 64 to 4096 tokens and achieve a mean MAPE of 1.79%. Our results show that aligning sequence lengths with these efficiency \"sweet spots\" reduce energy usage, up to 33.41x, enabling informed truncation, summarization, and adaptive generation strategies in production systems.","authors":["Hiari Pizzini Cavagna","Andrea Proia","Giacomo Madella","Giovanni B. Esposito","Francesco Antici","Daniele Cesarini","Zeynep Kiziltan","Andrea Bartolini"],"pdf_url":"","comment":"To appear at ICPE 2026 (International Conference on Performance Engineering)"},{"id":"http://arxiv.org/abs/2508.05612v5","updated":"2026-02-23T09:33:32Z","published":"2025-08-07T17:53:47Z","title":"Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle","summary":"Reinforcement learning (RL) has emerged as an effective post-training paradigm for enhancing the reasoning capabilities of multimodal large language model (MLLM). However, current RL pipelines often suffer from training inefficiencies caused by two underexplored issues: Advantage Collapsing, where most advantages in a batch concentrate near zero, and Rollout Silencing, where the proportion of rollouts contributing non-zero gradients diminishes over time. These issues lead to suboptimal gradient updates and hinder long-term learning efficiency. To address these issues, we propose Shuffle-R1, a simple yet principled framework that improves RL fine-tuning efficiency by dynamically restructuring trajectory sampling and batch composition. It introduces (1) Pairwise Trajectory Sampling, which selects high-contrast trajectories with large advantages to improve gradient signal quality, and (2) Advantage-based Trajectory Shuffle, which increases exposure of valuable rollouts through informed batch reshuffling. Experiments across multiple reasoning benchmarks show that our framework consistently outperforms strong RL baselines with minimal overhead. These results highlight the importance of data-centric adaptations for more efficient RL training in MLLM.","authors":["Linghao Zhu","Yiran Guan","Dingkang Liang","Jianzhong Ju","Zhenbo Luo","Bin Qin","Jian Luan","Yuliang Liu","Xiang Bai"],"pdf_url":"","comment":"This paper has been accepted by ICLR 2026 Project page at: https://xenozlh.github.io/Shuffle-R1/"},{"id":"http://arxiv.org/abs/2602.19634v1","updated":"2026-02-23T09:22:21Z","published":"2026-02-23T09:22:21Z","title":"Compositional Planning with Jumpy World Models","summary":"The ability to plan with temporal abstractions is central to intelligent decision-making. Rather than reasoning over primitive actions, we study agents that compose pre-trained policies as temporally extended actions, enabling solutions to complex tasks that no constituent alone can solve. Such compositional planning remains elusive as compounding errors in long-horizon predictions make it challenging to estimate the visitation distribution induced by sequencing policies. Motivated by the geometric policy composition framework introduced in arXiv:2206.08736, we address these challenges by learning predictive models of multi-step dynamics -- so-called jumpy world models -- that capture state occupancies induced by pre-trained policies across multiple timescales in an off-policy manner. Building on Temporal Difference Flows (arXiv:2503.09817), we enhance these models with a novel consistency objective that aligns predictions across timescales, improving long-horizon predictive accuracy. We further demonstrate how to combine these generative predictions to estimate the value of executing arbitrary sequences of policies over varying timescales. Empirically, we find that compositional planning with jumpy world models significantly improves zero-shot performance across a wide range of base policies on challenging manipulation and navigation tasks, yielding, on average, a 200% relative improvement over planning with primitive actions on long-horizon tasks.","authors":["Jesse Farebrother","Matteo Pirotta","Andrea Tirinzoni","Marc G. Bellemare","Alessandro Lazaric","Ahmed Touati"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19633v1","updated":"2026-02-23T09:19:56Z","published":"2026-02-23T09:19:56Z","title":"TAPE: Tool-Guided Adaptive Planning and Constrained Execution in Language Model Agents","summary":"Language Model (LM) agents have demonstrated remarkable capabilities in solving tasks that require multiple interactions with the environment. However, they remain vulnerable in environments where a single error often leads to irrecoverable failure, particularly under strict feasibility constraints. We systematically analyze existing agent frameworks, identifying imperfect planning and stochastic execution as the primary causes. To address these challenges, we propose Tool-guided Adaptive Planning with constrained Execution (TAPE). TAPE enhances planning capability by aggregating multiple plans into a graph and employing an external solver to identify a feasible path. During execution, TAPE employs constrained decoding to reduce sampling noise, while adaptively re-planning whenever environmental feedback deviates from the intended state. Experiments across Sokoban, ALFWorld, MuSiQue, and GSM8K-Hard demonstrate that TAPE consistently outperforms existing frameworks, with particularly large gains on hard settings, improving success rates by 21.0 percentage points on hard settings on average, and by 20.0 percentage points for weaker base models on average. Code and data available at here.","authors":["Jongwon Jeong","Jungtaek Kim","Kangwook Lee"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2602.19631v1","updated":"2026-02-23T09:18:27Z","published":"2026-02-23T09:18:27Z","title":"Localized Concept Erasure in Text-to-Image Diffusion Models via High-Level Representation Misdirection","summary":"Recent advances in text-to-image (T2I) diffusion models have seen rapid and widespread adoption. However, their powerful generative capabilities raise concerns about potential misuse for synthesizing harmful, private, or copyrighted content. To mitigate such risks, concept erasure techniques have emerged as a promising solution. Prior works have primarily focused on fine-tuning the denoising component (e.g., the U-Net backbone). However, recent causal tracing studies suggest that visual attribute information is localized in the early self-attention layers of the text encoder, indicating a potential alternative for concept erasing. Building on this insight, we conduct preliminary experiments and find that directly fine-tuning early layers can suppress target concepts but often degrades the generation quality of non-target concepts. To overcome this limitation, we propose High-Level Representation Misdirection (HiRM), which misdirects high-level semantic representations of target concepts in the text encoder toward designated vectors such as random directions or semantically defined directions (e.g., supercategories), while updating only early layers that contain causal states of visual attributes. Our decoupling strategy enables precise concept removal with minimal impact on unrelated concepts, as demonstrated by strong results on UnlearnCanvas and NSFW benchmarks across diverse targets (e.g., objects, styles, nudity). HiRM also preserves generative utility at low training cost, transfers to state-of-the-art architectures such as Flux without additional training, and shows synergistic effects with denoiser-based concept erasing methods.","authors":["Uichan Lee","Jeonghyeon Kim","Sangheum Hwang"],"pdf_url":"","comment":"Accepted at ICLR 2026. The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2602.19629v1","updated":"2026-02-23T09:17:12Z","published":"2026-02-23T09:17:12Z","title":"Cooperation After the Algorithm: Designing Human-AI Coexistence Beyond the Illusion of Collaboration","summary":"Generative artificial intelligence systems increasingly participate in research, law, education, media, and governance. Their fluent and adaptive outputs create an experience of collaboration. However, these systems do not bear responsibility, incur liability, or share stakes in downstream consequences. This structural asymmetry has already produced sanctions, professional errors, and governance failures in high-stakes contexts We argue that stable human-AI coexistence is an institutional achievement that depends on governance infrastructure capable of distributing residual risk. Drawing on institutional analysis and evolutionary cooperation theory, we introduce a formal inequality that specifies when reliance on AI yields positive expected cooperative value. The model makes explicit how governance conditions, system policy, and accountability regimes jointly determine whether cooperation is rational or structurally defective. From this formalization we derive a cooperation ecology framework with six design principles: reciprocity contracts, visible trust infrastructure, conditional cooperation modes, defection-mitigation mechanisms, narrative literacy against authority theatre, and an Earth-first sustainability constraint. We operationalize the framework through three policy artefacts: a Human-AI Cooperation Charter, a Defection Risk Register, and a Cooperation Readiness Audit. Together, these elements shift the unit of analysis from the user-AI dyad to the institutional environment that shapes incentives, signals, accountability, and repair. The paper provides a theoretical foundation and practical toolkit for designing human-AI systems that can sustain accountable, trustworthy cooperation over time.","authors":["Tatia Codreanu"],"pdf_url":"","comment":"11 pages, 2 tables"},{"id":"http://arxiv.org/abs/2602.19623v1","updated":"2026-02-23T09:12:13Z","published":"2026-02-23T09:12:13Z","title":"PedaCo-Gen: Scaffolding Pedagogical Agency in Human-AI Collaborative Video Authoring","summary":"While advancements in Text-to-Video (T2V) generative AI offer a promising path toward democratizing content creation, current models are often optimized for visual fidelity rather than instructional efficacy. This study introduces PedaCo-Gen, a pedagogically-informed human-AI collaborative video generating system for authoring instructional videos based on Mayer's Cognitive Theory of Multimedia Learning (CTML). Moving away from traditional \"one-shot\" generation, PedaCo-Gen introduces an Intermediate Representation (IR) phase, enabling educators to interactively review and refine video blueprints-comprising scripts and visual descriptions-with an AI reviewer. Our study with 23 education experts demonstrates that PedaCo-Gen significantly enhances video quality across various topics and CTML principles compared to baselines. Participants perceived the AI-driven guidance not merely as a set of instructions but as a metacognitive scaffold that augmented their instructional design expertise, reporting high production efficiency (M=4.26) and guide validity (M=4.04). These findings highlight the importance of reclaiming pedagogical agency through principled co-creation, providing a foundation for future AI authoring tools that harmonize generative power with human professional expertise.","authors":["Injun Baek","Yearim Kim","Nojun Kwak"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19622v1","updated":"2026-02-23T09:10:39Z","published":"2026-02-23T09:10:39Z","title":"VecFormer: Towards Efficient and Generalizable Graph Transformer with Graph Token Attention","summary":"Graph Transformer has demonstrated impressive capabilities in the field of graph representation learning. However, existing approaches face two critical challenges: (1) most models suffer from exponentially increasing computational complexity, making it difficult to scale to large graphs; (2) attention mechanisms based on node-level operations limit the flexibility of the model and result in poor generalization performance in out-of-distribution (OOD) scenarios. To address these issues, we propose \\textbf{VecFormer} (the \\textbf{Vec}tor Quantized Graph Trans\\textbf{former}), an efficient and highly generalizable model for node classification, particularly under OOD settings. VecFormer adopts a two-stage training paradigm. In the first stage, two codebooks are used to reconstruct the node features and the graph structure, aiming to learn the rich semantic \\texttt{Graph Codes}. In the second stage, attention mechanisms are performed at the \\texttt{Graph Token} level based on the transformed cross codebook, reducing computational complexity while enhancing the model's generalization capability. Extensive experiments on datasets of various sizes demonstrate that VecFormer outperforms the existing Graph Transformer in both performance and speed.","authors":["Jingbo Zhou","Jun Xia","Siyuan Li","Yunfan Liu","Wenjun Wang","Yufei Huang","Changxi Chi","Mutian Hong","Zhuoli Ouyang","Shu Wang","Zhongqi Wang","Xingyu Wu","Chang Yu","Stan Z. Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19620v1","updated":"2026-02-23T09:07:16Z","published":"2026-02-23T09:07:16Z","title":"Rules or Weights? Comparing User Understanding of Explainable AI Techniques with the Cognitive XAI-Adaptive Model","summary":"Rules and Weights are popular XAI techniques for explaining AI decisions. Yet, it remains unclear how to choose between them, lacking a cognitive framework to compare their interpretability. In an elicitation user study on forward and counterfactual decision tasks, we identified 7 reasoning strategies of interpreting three XAI Schemas - weights, rules, and their hybrid. To analyze their capabilities, we propose CoXAM, a Cognitive XAI-Adaptive Model with shared memory representation to encode instance attributes, linear weights, and decision rules. CoXAM employs computational rationality to choose among reasoning processes based on the trade-off in utility and reasoning time, separately for forward or counterfactual decision tasks. In a validation study, CoXAM demonstrated a stronger alignment with human decision-making compared to baseline machine learning proxy models. The model successfully replicated and explained several key empirical findings, including that counterfactual tasks are inherently harder than forward tasks, decision tree rules are harder to recall and apply than linear weights, and the helpfulness of XAI depends on the application data context, alongside identifying which underlying reasoning strategies were most effective. With CoXAM, we contribute a cognitive basis to accelerate debugging and benchmarking disparate XAI techniques.","authors":["Louth Bin Rawshan","Zhuoyu Wang","Brian Y Lim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.12691v2","updated":"2026-02-23T08:56:56Z","published":"2026-02-13T07:46:37Z","title":"ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training","summary":"We study how to improve large foundation vision-language-action (VLA) systems through online reinforcement learning (RL) in real-world settings. Central to this process is the value function, which provides learning signals to guide VLA learning from experience. In practice, the value function is estimated from trajectory fragments collected from different data sources, including historical policies and intermittent human interventions. Estimating the value function of current behavior quality from the mixture data is inherently an off-policy evaluation problem. However, prior work often adopts conservative on-policy estimation for stability, which avoids direct evaluation of the current high-capacity policy and limits learning effectiveness. In this paper, we propose ALOE, an action-level off-policy evaluation framework for VLA post-training. ALOE applies chunking-based temporal-difference bootstrapping to evaluate individual action sequences instead of predicting final task outcomes. This design improves effective credit assignment to critical action chunks under sparse rewards and supports stable policy improvement. We evaluate our method on three real-world manipulation tasks, including smartphone packing as a high-precision task, laundry folding as a long-horizon deformable-object task, and bimanual pick-and-place involving multi-object perception. Across all tasks, ALOE improves learning efficiency without compromising execution speed, showing that off-policy RL can be reintroduced in a reliable manner for real-world VLA post-training. Videos and additional materials are available at our project website.","authors":["Rushuai Yang","Hecheng Wang","Chiming Liu","Xiaohan Yan","Yunlong Wang","Xuan Du","Shuoyu Yue","Yongcheng Liu","Chuheng Zhang","Lizhe Qi","Yi Chen","Wei Shan","Maoqing Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.08604v4","updated":"2026-02-23T08:51:45Z","published":"2025-06-10T09:13:37Z","title":"Physics vs Distributions: Pareto Optimal Flow Matching with Physics Constraints","summary":"Physics-constrained generative modeling aims to produce high-dimensional samples that are both physically consistent and distributionally accurate, a task that remains challenging due to often conflicting optimization objectives. Recent advances in flow matching and diffusion models have enabled efficient generative modeling, but integrating physical constraints often degrades generative fidelity or requires costly inference-time corrections. Our work is the first to recognize the trade-off between distributional and physical accuracy. Based on the insight of inherently conflicting objectives, we introduce Physics-Based Flow Matching (PBFM) a method that enforces physical constraints at training time using conflict-free gradient updates and unrolling to mitigate Jensen's gap. Our approach avoids manual loss balancing and enables simultaneous optimization of generative and physical objectives. As a consequence, physics constraints do not impede inference performance. We benchmark our method across three representative PDE benchmarks. PBFM achieves a Pareto-optimal trade-off, competitive inference speed, and generalizes to a wide range of physics-constrained generative tasks, providing a practical tool for scientific machine learning. Code and datasets available at https://github.com/tum-pbs/PBFM.","authors":["Giacomo Baldan","Qiang Liu","Alberto Guardone","Nils Thuerey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17439v2","updated":"2026-02-23T08:51:09Z","published":"2025-11-21T17:36:12Z","title":"InTAct: Interval-based Task Activation Consolidation for Continual Learning","summary":"Continual learning is a fundamental challenge in artificial intelligence that requires networks to acquire new knowledge while preserving previously learned representations. Despite the success of various approaches, most existing paradigms do not provide rigorous mathematical guarantees against catastrophic forgetting. Current methods that offer such guarantees primarily focus on analyzing the parameter space using \\textit{interval arithmetic (IA)}, as seen in frameworks such as InterContiNet. However, restricting high-dimensional weight updates can be computationally expensive. In this work, we propose InTAct (Interval-based Task Activation Consolidation), a method that mitigates catastrophic forgetting by enforcing functional invariance at the neuron level. We identify specific activation intervals where previous tasks reside and constrain updates within these regions while allowing for flexible adaptation elsewhere. By ensuring that predictions remain stable within these nested activation intervals, we provide a tractable mathematical guarantee of functional invariance. We emphasize that regulating the activation space is significantly more efficient than parameter-based constraints, because the dimensionality of internal signals is much lower than that of the vast space of model weights. While our approach is architecture-agnostic and applicable to various continual learning settings, its integration with prompt-based methods enables it to achieve state-of-the-art performance on challenging benchmarks.","authors":["Patryk Krukowski","Jan Miksa","Piotr Helm","Jacek Tabor","Paweł Wawrzyński","Przemysław Spurek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19608v1","updated":"2026-02-23T08:50:07Z","published":"2026-02-23T08:50:07Z","title":"Satellite-Based Detection of Looted Archaeological Sites Using Machine Learning","summary":"Looting at archaeological sites poses a severe risk to cultural heritage, yet monitoring thousands of remote locations remains operationally difficult. We present a scalable and satellite-based pipeline to detect looted archaeological sites, using PlanetScope monthly mosaics (4.7m/pixel) and a curated dataset of 1,943 archaeological sites in Afghanistan (898 looted, 1,045 preserved) with multi-year imagery (2016--2023) and site-footprint masks. We compare (i) end-to-end CNN classifiers trained on raw RGB patches and (ii) traditional machine learning (ML) trained on handcrafted spectral/texture features and embeddings from recent remote-sensing foundation models. Results indicate that ImageNet-pretrained CNNs combined with spatial masking reach an F1 score of 0.926, clearly surpassing the strongest traditional ML setup, which attains an F1 score of 0.710 using SatCLIP-V+RF+Mean, i.e., location and vision embeddings fed into a Random Forest with mean-based temporal aggregation. Ablation studies demonstrate that ImageNet pretraining (even in the presence of domain shift) and spatial masking enhance performance. In contrast, geospatial foundation model embeddings perform competitively with handcrafted features, suggesting that looting signatures are extremely localized. The repository is available at https://github.com/microsoft/looted_site_detection.","authors":["Girmaw Abebe Tadesse","Titien Bartette","Andrew Hassanali","Allen Kim","Jonathan Chemla","Andrew Zolli","Yves Ubelmann","Caleb Robinson","Inbal Becker-Reshef","Juan Lavista Ferres"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.13033v2","updated":"2026-02-23T08:47:46Z","published":"2026-02-13T15:39:31Z","title":"Buy versus Build an LLM: A Decision Framework for Governments","summary":"Large Language Models (LLMs) represent a new frontier of digital infrastructure that can support a wide range of public-sector applications, from general purpose citizen services to specialized and sensitive state functions. When expanding AI access, governments face a set of strategic choices over whether to buy existing services, build domestic capabilities, or adopt hybrid approaches across different domains and use cases. These are critical decisions especially when leading model providers are often foreign corporations, and LLM outputs are increasingly treated as trusted inputs to public decision-making and public discourse. In practice, these decisions are not intended to mandate a single approach across all domains; instead, national AI strategies are typically pluralistic, with sovereign, commercial and open-source models coexisting to serve different purposes. Governments may rely on commercial models for non-sensitive or commodity tasks, while pursuing greater control for critical, high-risk or strategically important applications.\n  This paper provides a strategic framework for making this decision by evaluating these options across dimensions including sovereignty, safety, cost, resource capability, cultural fit, and sustainability. Importantly, \"building\" does not imply that governments must act alone: domestic capabilities may be developed through public research institutions, universities, state-owned enterprises, joint ventures, or broader national ecosystems. By detailing the technical requirements and practical challenges of each pathway, this work aims to serve as a reference for policy-makers to determine whether a buy or build approach best aligns with their specific national needs and societal goals.","authors":["Jiahao Lu","Ziwei Xu","William Tjhi","Junnan Li","Antoine Bosselut","Pang Wei Koh","Mohan Kankanhalli"],"pdf_url":"","comment":"The short version of this document is published as an ACM TechBrief at https://dl.acm.org/doi/epdf/10.1145/3797946, and this document is published as an ACM Technology Policy Council white paper at https://www.acm.org/binaries/content/assets/public-policy/buildvsbuyai.pdf"},{"id":"http://arxiv.org/abs/2602.19605v1","updated":"2026-02-23T08:47:19Z","published":"2026-02-23T08:47:19Z","title":"CLCR: Cross-Level Semantic Collaborative Representation for Multimodal Learning","summary":"Multimodal learning aims to capture both shared and private information from multiple modalities. However, existing methods that project all modalities into a single latent space for fusion often overlook the asynchronous, multi-level semantic structure of multimodal data. This oversight induces semantic misalignment and error propagation, thereby degrading representation quality. To address this issue, we propose Cross-Level Co-Representation (CLCR), which explicitly organizes each modality's features into a three-level semantic hierarchy and specifies level-wise constraints for cross-modal interactions. First, a semantic hierarchy encoder aligns shallow, mid, and deep features across modalities, establishing a common basis for interaction. And then, at each level, an Intra-Level Co-Exchange Domain (IntraCED) factorizes features into shared and private subspaces and restricts cross-modal attention to the shared subspace via a learnable token budget. This design ensures that only shared semantics are exchanged and prevents leakage from private channels. To integrate information across levels, the Inter-Level Co-Aggregation Domain (InterCAD) synchronizes semantic scales using learned anchors, selectively fuses the shared representations, and gates private cues to form a compact task representation. We further introduce regularization terms to enforce separation of shared and private features and to minimize cross-level interference. Experiments on six benchmarks spanning emotion recognition, event localization, sentiment analysis, and action recognition show that CLCR achieves strong performance and generalizes well across tasks.","authors":["Chunlei Meng","Guanhong Huang","Rong Fu","Runmin Jian","Zhongxue Gan","Chun Ouyang"],"pdf_url":"","comment":"This study has been Accepted by CVPR 2026"},{"id":"http://arxiv.org/abs/2511.16175v2","updated":"2026-02-23T08:44:17Z","published":"2025-11-20T09:30:23Z","title":"Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight","summary":"Recent advances in Vision-Language-Action (VLA) models demonstrate that visual signals can effectively complement sparse action supervisions. However, letting VLA directly predict high-dimensional visual states can distribute model capacity and incur prohibitive training cost, while compressing visual states into more compact supervisory signals inevitably incurs information bottlenecks. Moreover, existing methods often suffer from poor comprehension and reasoning capabilities due to the neglect of language supervision. This paper introduces Mantis, a novel framework featuring a Disentangled Visual Foresight (DVF) to tackle these issues. Specifically, Mantis decouples visual foresight prediction from the backbone with the combination of meta queries and a diffusion Transformer (DiT) head. With the current visual state provided to the DiT via a residual connection, a simple next-state prediction objective enables the meta queries to automatically capture the latent actions that delineate the visual trajectory, and hence boost the learning of explicit actions. The disentanglement reduces the burden of the VLA backbone, enabling it to maintain comprehension and reasoning capabilities through language supervision. Empirically, pretrained on human manipulation videos, robot demonstrations, and image-text pairs, Mantis achieves a 96.7% success rate on LIBERO benchmark after fine-tuning, surpassing powerful baselines while exhibiting high convergence speed. Real-world evaluations show that Mantis outperforms $π_{0.5}$, a leading open-source VLA model, particularly in instruction-following capability, generalization to unseen instructions, and reasoning ability. Code and weights are released to support the open-source community.","authors":["Yi Yang","Xueqi Li","Yiyang Chen","Jin Song","Yihan Wang","Zipeng Xiao","Jiadi Su","You Qiaoben","Pengfei Liu","Zhijie Deng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14697v2","updated":"2026-02-23T08:43:06Z","published":"2026-02-16T12:34:27Z","title":"Unifying Evolutionary Prompt Search and Reinforcement Learning for LLM Self-Improvement","summary":"Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this work, we propose Evolutionary System Prompt Learning (E-SPL), a method for jointly improving model contexts and model weights. In each RL iteration, E-SPL samples trajectories under multiple system prompts in parallel. It applies RL updates to LLM weights conditioned on system prompts, and evolutionary updates to system prompts via mutation and crossover, two genetic operators based on LLM self-reflection. Each system prompt is assigned a TrueSkill rating for evolutionary selection, updated from relative performance within each RL iteration. E-SPL encourages a natural division between declarative knowledge encoded in prompts and procedural knowledge encoded in weights, resulting in improved performance across reasoning and agentic tasks. For instance, in an easy-to-hard (AIME $\\rightarrow$ BeyondAIME) generalization setting, E-SPL improves RL success rate from 38.8% $\\rightarrow$ 45.1% while also outperforming reflective prompt evolution (40.0%). Overall, our results demonstrate that RL and evolutionary prompt search are deeply synergistic, and unifying the two yields consistent gains in sample efficiency and generalization. Code: https://github.com/LunjunZhang/E-SPL","authors":["Lunjun Zhang","Ryan Chen","Bradly C. Stadie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.01650v2","updated":"2026-02-23T08:37:18Z","published":"2025-10-02T04:10:17Z","title":"The Unseen Frontier: Pushing the Limits of LLM Sparsity with Surrogate-Free ADMM","summary":"Neural network pruning is a promising technique to mitigate the excessive computational and memory requirements of large language models (LLMs). Despite its promise, however, progress in this area has diminished, as conventional methods are seemingly unable to surpass moderate sparsity levels (50-60%) without severely degrading model accuracy. This work breaks through the current impasse, presenting a principled and effective method called $\\texttt{Elsa}$, which achieves extreme sparsity levels of up to 90% while retaining high model fidelity. This is done by identifying several limitations in current practice, all of which can be traced back to their reliance on a surrogate objective formulation. $\\texttt{Elsa}$ tackles this issue directly and effectively via standard and well-established constrained optimization techniques based on ADMM. Our extensive experiments across a wide range of models and scales show that $\\texttt{Elsa}$ achieves substantial improvements over existing methods; e.g., it achieves 7.8$\\times$ less perplexity than the best existing method on LLaMA-2-7B at 90% sparsity. Moreover, we show that $\\texttt{Elsa}$ remains stable even at extreme sparsity (e.g., 95\\%), yielding up to $\\times$3.98 inference speedup and $\\times$7.80 memory compression over its dense counterpart. We also present $\\texttt{Elsa}_{-L}$, a quantized variant that scales to extremely large models (27B), and establish its theoretical convergence guarantees.These results highlight meaningful progress in advancing the frontier of LLM sparsity, while promising that significant opportunities for further advancement may remain in directions that have so far attracted limited exploration.","authors":["Kwanhee Lee","Hyeondo Jang","Dongyeop Lee","Dan Alistarh","Namhoon Lee"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.19591v1","updated":"2026-02-23T08:35:55Z","published":"2026-02-23T08:35:55Z","title":"Detecting High-Potential SMEs with Heterogeneous Graph Neural Networks","summary":"Small and Medium Enterprises (SMEs) constitute 99.9% of U.S. businesses and generate 44% of economic activity, yet systematically identifying high-potential SMEs remains an open challenge. We introduce SME-HGT, a Heterogeneous Graph Transformer framework that predicts which SBIR Phase I awardees will advance to Phase II funding using exclusively public data. We construct a heterogeneous graph with 32,268 company nodes, 124 research topic nodes, and 13 government agency nodes connected by approximately 99,000 edges across three semantic relation types. SME-HGT achieves an AUPRC of 0.621 0.003 on a temporally-split test set, outperforming an MLP baseline (0.590 0.002) and R-GCN (0.608 0.013) across five random seeds. At a screening depth of 100 companies, SME-HGT attains 89.6% precision with a 2.14 lift over random selection. Our temporal evaluation protocol prevents information leakage, and our reliance on public data ensures reproducibility. These results demonstrate that relational structure among firms, research topics, and funding agencies provides meaningful signal for SME potential assessment, with implications for policymakers and early-stage investors.","authors":["Yijiashun Qi","Hanzhe Guo","Yijiazhen Qi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19585v1","updated":"2026-02-23T08:19:54Z","published":"2026-02-23T08:19:54Z","title":"Tri-Subspaces Disentanglement for Multimodal Sentiment Analysis","summary":"Multimodal Sentiment Analysis (MSA) integrates language, visual, and acoustic modalities to infer human sentiment. Most existing methods either focus on globally shared representations or modality-specific features, while overlooking signals that are shared only by certain modality pairs. This limits the expressiveness and discriminative power of multimodal representations. To address this limitation, we propose a Tri-Subspace Disentanglement (TSD) framework that explicitly factorizes features into three complementary subspaces: a common subspace capturing global consistency, submodally-shared subspaces modeling pairwise cross-modal synergies, and private subspaces preserving modality-specific cues. To keep these subspaces pure and independent, we introduce a decoupling supervisor together with structured regularization losses. We further design a Subspace-Aware Cross-Attention (SACA) fusion module that adaptively models and integrates information from the three subspaces to obtain richer and more robust representations. Experiments on CMU-MOSI and CMU-MOSEI demonstrate that TSD achieves state-of-the-art performance across all key metrics, reaching 0.691 MAE on CMU-MOSI and 54.9% ACC-7 on CMU-MOSEI, and also transfers well to multimodal intent recognition tasks. Ablation studies confirm that tri-subspace disentanglement and SACA jointly enhance the modeling of multi-granular cross-modal sentiment cues.","authors":["Chunlei Meng","Jiabin Luo","Zhenglin Yan","Zhenyu Yu","Rong Fu","Zhongxue Gan","Chun Ouyang"],"pdf_url":"","comment":"This study has been Accepted by CVPR 2026"},{"id":"http://arxiv.org/abs/2602.19584v1","updated":"2026-02-23T08:12:49Z","published":"2026-02-23T08:12:49Z","title":"Interpolation-Driven Machine Learning Approaches for Plume Shine Dose Estimation: A Comparison of XGBoost, Random Forest, and TabNet","summary":"Despite the success of machine learning (ML) in surrogate modeling, its use in radiation dose assessment is limited by safety-critical constraints, scarce training-ready data, and challenges in selecting suitable architectures for physics-dominated systems. Within this context, rapid and accurate plume shine dose estimation serves as a practical test case, as it is critical for nuclear facility safety assessment and radiological emergency response, while conventional photon-transport-based calculations remain computationally expensive. In this work, an interpolation-assisted ML framework was developed using discrete dose datasets generated with the pyDOSEIA suite for 17 gamma-emitting radionuclides across varying downwind distances, release heights, and atmospheric stability categories. The datasets were augmented using shape-preserving interpolation to construct dense, high-resolution training data. Two tree-based ML models (Random Forest and XGBoost) and one deep learning (DL) model (TabNet) were evaluated to examine predictive performance and sensitivity to dataset resolution. All models showed higher prediction accuracy with the interpolated high-resolution dataset than with the discrete data; however, XGBoost consistently achieved the highest accuracy. Interpretability analysis using permutation importance (tree-based models) and attention-based feature attribution (TabNet) revealed that performance differences stem from how the models utilize input features. Tree-based models focus mainly on dominant geometry-dispersion features (release height, stability category, and downwind distance), treating radionuclide identity as a secondary input, whereas TabNet distributes attention more broadly across multiple variables. For practical deployment, a web-based GUI was developed for interactive scenario evaluation and transparent comparison with photon-transport reference calculations.","authors":["Biswajit Sadhu","Kalpak Gupte","Trijit Sadhu","S. Anand"],"pdf_url":"","comment":"28 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2204.07520v4","updated":"2026-02-23T08:03:56Z","published":"2022-04-15T15:47:05Z","title":"Resource-Aware Distributed Submodular Maximization: A Paradigm for Multi-Robot Decision-Making","summary":"Multi-robot decision-making is the process where multiple robots coordinate actions. In this paper, we aim for efficient and effective multi-robot decision-making despite the robots' limited on-board resources and the often resource-demanding complexity of their tasks. We introduce the first algorithm enabling the robots to choose with which few other robots to coordinate and provably balance the trade-off of centralized vs. decentralized coordination. Particularly, centralization favors globally near-optimal decision-making but at the cost of increased on-board resource requirements; whereas, decentralization favors minimal resource requirements but at a global suboptimality cost. All robots can thus afford our algorithm, irrespective of their resources. We are motivated by the future of autonomy that involves multiple robots coordinating actions to complete resource-demanding tasks, such as target tracking, area coverage, and monitoring. To provide closed-form guarantees, we focus on maximization problems involving monotone and 2nd-order submodular functions. To capture the cost of decentralization, we introduce the notion of Centralization Of Information among non-Neighbors (COIN). We validate our algorithm in simulated scenarios of image covering.","authors":["Zirui Xu","Vasileios Tzoumas"],"pdf_url":"","comment":"Updated presentation. Accepted to the 2022 IEEE Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2506.05850v3","updated":"2026-02-23T08:02:48Z","published":"2025-06-06T08:08:48Z","title":"Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models","summary":"Reinforcement learning with verifiable reward (RLVR) has been instrumental in eliciting strong reasoning capabilities from large language models (LLMs) via long chains of thought (CoT). During RLVR training, we formalize and systemically study an empirical phenomenon whereby a multilingual model's CoT reverts to its dominant pre-training language (e.g., English) even when prompted in another language, which we term Cross-lingual Collapse. Because the long-CoT regime magnifies exposure to linguistic priors, the underlying trade-off between maximizing reasoning depth and preserving target-language fidelity has remained under-characterized. To examine this trade-off, we train LLMs with Group-Relative Policy Optimization (GRPO) on translated versions of math datasets widely used to elicit long-CoT reasoning. Throughout training, we track both task accuracy and the language consistency of reasoning chains. Our experiments yield three findings: (i) under RLVR, CoT in LLMs systematically drifts toward the pre-training dominant language as reasoning performance rises; (ii) English-centric priors, long-CoT GRPO optimization, task difficulty, and high-entropy decoding jointly amplify this drift, and the pattern persists beyond mathematics; and (iii) interventions that favor target-language traces--via a language-consistency reward, decoding-time controls, or more balanced backbones--mitigate collapse but reveal a persistent performance-fidelity trade-off.","authors":["Cheonbok Park","Jeonghoon Kim","Joosung Lee","Sanghwan Bae","Jaegul Choo","Kang Min Yoo"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2504.05806v2","updated":"2026-02-23T07:58:40Z","published":"2025-04-08T08:38:37Z","title":"Meta-Continual Learning of Neural Fields","summary":"Neural Fields (NF) have gained prominence as a versatile framework for complex data representation. This work unveils a new problem setting termed \\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel strategy that employs a modular architecture combined with optimization-based meta-learning. Focused on overcoming the limitations of existing methods for continual learning of neural fields, such as catastrophic forgetting and slow convergence, our strategy achieves high-quality reconstruction with significantly improved learning speed. We further introduce Fisher Information Maximization loss for neural radiance fields (FIM-NeRF), which maximizes information gains at the sample level to enhance learning generalization, with proved convergence guarantee and generalization bound. We perform extensive evaluations across image, audio, video reconstruction, and view synthesis tasks on six diverse datasets, demonstrating our method's superiority in reconstruction quality and speed over existing MCL and CL-NF approaches. Notably, our approach attains rapid adaptation of neural fields for city-scale NeRF rendering with reduced parameter requirement. Code is available at https://github.com/seungyoon-woo/mcl-nf.","authors":["Seungyoon Woo","Junhyeog Yun","Gunhee Kim"],"pdf_url":"","comment":"Accepted at ICLR 2025"},{"id":"http://arxiv.org/abs/2602.19574v1","updated":"2026-02-23T07:44:14Z","published":"2026-02-23T07:44:14Z","title":"CTC-TTS: LLM-based dual-streaming text-to-speech with CTC alignment","summary":"Large-language-model (LLM)-based text-to-speech (TTS) systems can generate natural speech, but most are not designed for low-latency dual-streaming synthesis. High-quality dual-streaming TTS depends on accurate text--speech alignment and well-designed training sequences that balance synthesis quality and latency. Prior work often relies on GMM-HMM based forced-alignment toolkits (e.g., MFA), which are pipeline-heavy and less flexible than neural aligners; fixed-ratio interleaving of text and speech tokens struggles to capture text--speech alignment regularities. We propose CTC-TTS, which replaces MFA with a CTC based aligner and introduces a bi-word based interleaving strategy. Two variants are designed: CTC-TTS-L (token concatenation along the sequence length) for higher quality and CTC-TTS-F (embedding stacking along the feature dimension) for lower latency. Experiments show that CTC-TTS outperforms fixed-ratio interleaving and MFA-based baselines on streaming synthesis and zero-shot tasks. Speech samples are available at https://ctctts.github.io/.","authors":["Hanwen Liu","Saierdaer Yusuyin","Hao Huang","Zhijian Ou"],"pdf_url":"","comment":"Submitted to INTERSPEECH 2026"},{"id":"http://arxiv.org/abs/2602.19569v1","updated":"2026-02-23T07:36:36Z","published":"2026-02-23T07:36:36Z","title":"Temporal-Aware Heterogeneous Graph Reasoning with Multi-View Fusion for Temporal Question Answering","summary":"Question Answering over Temporal Knowledge Graphs (TKGQA) has attracted growing interest for handling time-sensitive queries. However, existing methods still struggle with: 1) weak incorporation of temporal constraints in question representation, causing biased reasoning; 2) limited ability to perform explicit multi-hop reasoning; and 3) suboptimal fusion of language and graph representations. We propose a novel framework with temporal-aware question encoding, multi-hop graph reasoning, and multi-view heterogeneous information fusion. Specifically, our approach introduces: 1) a constraint-aware question representation that combines semantic cues from language models with temporal entity dynamics; 2) a temporal-aware graph neural network for explicit multi-hop reasoning via time-aware message passing; and 3) a multi-view attention mechanism for more effective fusion of question context and temporal graph knowledge. Experiments on multiple TKGQA benchmarks demonstrate consistent improvements over multiple baselines.","authors":["Wuzhenghong Wen","Bowen Zhou","Jinwen Huang","Xianjie Wu","Yuwei Sun","Su Pan","Liang Li","Jianting Liu"],"pdf_url":"","comment":"6pages"},{"id":"http://arxiv.org/abs/2602.19565v1","updated":"2026-02-23T07:30:47Z","published":"2026-02-23T07:30:47Z","title":"DICArt: Advancing Category-level Articulated Object Pose Estimation in Discrete State-Spaces","summary":"Articulated object pose estimation is a core task in embodied AI. Existing methods typically regress poses in a continuous space, but often struggle with 1) navigating a large, complex search space and 2) failing to incorporate intrinsic kinematic constraints. In this work, we introduce DICArt (DIsCrete Diffusion for Articulation Pose Estimation), a novel framework that formulates pose estimation as a conditional discrete diffusion process. Instead of operating in a continuous domain, DICArt progressively denoises a noisy pose representation through a learned reverse diffusion procedure to recover the GT pose. To improve modeling fidelity, we propose a flexible flow decider that dynamically determines whether each token should be denoised or reset, effectively balancing the real and noise distributions during diffusion. Additionally, we incorporate a hierarchical kinematic coupling strategy, estimating the pose of each rigid part hierarchically to respect the object's kinematic structure. We validate DICArt on both synthetic and real-world datasets. Experimental results demonstrate its superior performance and robustness. By integrating discrete generative modeling with structural priors, DICArt offers a new paradigm for reliable category-level 6D pose estimation in complex environments.","authors":["Li Zhang","Mingyu Mei","Ailing Wang","Xianhui Meng","Yan Zhong","Xinyuan Song","Liu Liu","Rujing Wang","Zaixing He","Cewu Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.03098v2","updated":"2026-02-23T07:25:58Z","published":"2026-02-03T04:43:13Z","title":"TextME: Bridging Unseen Modalities Through Text Descriptions","summary":"Expanding multimodal representations to novel modalities is constrained by reliance on large-scale paired datasets (e.g., text-image, text-audio, text-3D, text-molecule), which are costly and often infeasible in domains requiring expert annotation such as medical imaging and molecular analysis. We introduce TextME, the first text-only modality expansion framework, to the best of our knowledge, projecting diverse modalities into LLM embedding space as a unified anchor. Our approach exploits the geometric structure of pretrained contrastive encoders to enable zero-shot cross-modal transfer using only text descriptions, without paired supervision. We empirically validate that such consistent modality gaps exist across image, video, audio, 3D, X-ray, and molecular domains, demonstrating that text-only training can preserve substantial performance of pretrained encoders. We further show that our framework enables emergent cross-modal retrieval between modality pairs not explicitly aligned during training (e.g., audio-to-image, 3D-to-image). These results establish text-only training as a practical alternative to paired supervision for modality expansion.","authors":["Soyeon Hong","Jinchan Kim","Jaegook You","Seungtaek Choi","Suha Kwak","Hyunsouk Cho"],"pdf_url":"","comment":"Code available at https://github.com/SoyeonHH/TextME"},{"id":"http://arxiv.org/abs/2602.19562v1","updated":"2026-02-23T07:20:11Z","published":"2026-02-23T07:20:11Z","title":"A Multimodal Framework for Aligning Human Linguistic Descriptions with Visual Perceptual Data","summary":"Establishing stable mappings between natural language expressions and visual percepts is a foundational problem for both cognitive science and artificial intelligence. Humans routinely ground linguistic reference in noisy, ambiguous perceptual contexts, yet the mechanisms supporting such cross-modal alignment remain poorly understood. In this work, we introduce a computational framework designed to model core aspects of human referential interpretation by integrating linguistic utterances with perceptual representations derived from large-scale, crowd-sourced imagery. The system approximates human perceptual categorization by combining scale-invariant feature transform (SIFT) alignment with the Universal Quality Index (UQI) to quantify similarity in a cognitively plausible feature space, while a set of linguistic preprocessing and query-transformation operations captures pragmatic variability in referring expressions. We evaluate the model on the Stanford Repeated Reference Game corpus (15,000 utterances paired with tangram stimuli), a paradigm explicitly developed to probe human-level perceptual ambiguity and coordination. Our framework achieves robust referential grounding. It requires 65\\% fewer utterances than human interlocutors to reach stable mappings and can correctly identify target objects from single referring expressions 41.66\\% of the time (versus 20\\% for humans).These results suggest that relatively simple perceptual-linguistic alignment mechanisms can yield human-competitive behavior on a classic cognitive benchmark, and offers insights into models of grounded communication, perceptual inference, and cross-modal concept formation. Code is available at https://anonymous.4open.science/r/metasequoia-9D13/README.md .","authors":["Joseph Bingham"],"pdf_url":"","comment":"19 Pages, 6 figures, preprint"},{"id":"http://arxiv.org/abs/2510.22512v2","updated":"2026-02-23T07:03:22Z","published":"2025-10-26T03:32:31Z","title":"Transitive RL: Value Learning via Divide and Conquer","summary":"In this work, we present Transitive Reinforcement Learning (TRL), a new value learning algorithm based on a divide-and-conquer paradigm. TRL is designed for offline goal-conditioned reinforcement learning (GCRL) problems, where the aim is to find a policy that can reach any state from any other state in the smallest number of steps. TRL converts a triangle inequality structure present in GCRL into a practical divide-and-conquer value update rule. This has several advantages compared to alternative value learning paradigms. Compared to temporal difference (TD) methods, TRL suffers less from bias accumulation, as in principle it only requires $O(\\log T)$ recursions (as opposed to $O(T)$ in TD learning) to handle a length-$T$ trajectory. Unlike Monte Carlo methods, TRL suffers less from high variance as it performs dynamic programming. Experimentally, we show that TRL achieves the best performance in highly challenging, long-horizon benchmark tasks compared to previous offline GCRL algorithms.","authors":["Seohong Park","Aditya Oberai","Pranav Atreya","Sergey Levine"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.19555v1","updated":"2026-02-23T06:57:57Z","published":"2026-02-23T06:57:57Z","title":"Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains","summary":"Agentic systems built on large language models (LLMs) extend beyond text generation to autonomously retrieve information and invoke tools. This runtime execution model shifts the attack surface from build-time artifacts to inference-time dependencies, exposing agents to manipulation through untrusted data and probabilistic capability resolution. While prior work has focused on model-level vulnerabilities, security risks emerging from cyclic and interdependent runtime behavior remain fragmented. We systematize these risks within a unified runtime framework, categorizing threats into data supply chain attacks (transient context injection and persistent memory poisoning) and tool supply chain attacks (discovery, implementation, and invocation). We further identify the Viral Agent Loop, in which agents act as vectors for self-propagating generative worms without exploiting code-level flaws. Finally, we advocate a Zero-Trust Runtime Architecture that treats context as untrusted control flow and constrains tool execution through cryptographic provenance rather than semantic inference.","authors":["Xiaochong Jiang","Shiqi Yang","Wenting Yang","Yichen Liu","Cheng Ji"],"pdf_url":"","comment":"9 Pages, 3 figures"},{"id":"http://arxiv.org/abs/2510.10987v3","updated":"2026-02-23T06:55:02Z","published":"2025-10-13T03:53:40Z","title":"DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation","summary":"The promise of LLM watermarking rests on a core assumption that a specific watermark proves authorship by a specific model. We demonstrate that this assumption is dangerously flawed. We introduce the threat of watermark spoofing, a sophisticated attack that allows a malicious model to generate text containing the authentic-looking watermark of a trusted, victim model. This enables the seamless misattribution of harmful content, such as disinformation, to reputable sources. The key to our attack is repurposing watermark radioactivity, the unintended inheritance of data patterns during fine-tuning, from a discoverable trait into an attack vector. By distilling knowledge from a watermarked teacher model, our framework allows an attacker to steal and replicate the watermarking signal of the victim model. This work reveals a critical security gap in text authorship verification and calls for a paradigm shift towards technologies capable of distinguishing authentic watermarks from expertly imitated ones. Our code is available at https://github.com/hsannn/ditto.git.","authors":["Hyeseon An","Shinwoo Park","Suyeon Woo","Yo-Sub Han"],"pdf_url":"","comment":"Accepted to EACL 2026 (Oral)"},{"id":"http://arxiv.org/abs/2211.12817v3","updated":"2026-02-23T06:38:15Z","published":"2022-11-23T10:02:05Z","title":"Learning to See the Elephant in the Room: Self-Supervised Context Reasoning in Humans and AI","summary":"Humans rarely perceive objects in isolation but interpret scenes through relationships among co-occurring elements. How such contextual knowledge is acquired without explicit supervision remains unclear. Here we combine human psychophysics experiments with computational modelling to study the emergence of contextual reasoning. Participants were exposed to novel objects embedded in naturalistic scenes that followed predefined contextual rules capturing global context, local context and crowding. After viewing short training videos, participants completed a \"lift-the-flap\" task in which a hidden object had to be inferred from the surrounding context under variations in size, resolution and spatial arrangement. Humans rapidly learned these contextual associations without labels or feedback and generalised robustly across contextual changes. We then introduce SeCo (Self-supervised learning for Context Reasoning), a biologically inspired model that learns contextual relationships from complex scenes. SeCo encodes targets and context with separate vision encoders and stores latent contextual priors in a learnable external memory module. Given contextual cues, the model retrieves likely object representations to infer hidden targets. SeCo outperforms state-of-the-art self-supervised learning approaches and predicts object placements most consistent with human behaviour, highlighting the central role of contextual associations in scene understanding.","authors":["Xiao Liu","Soumick Sarker","Ankur Sikarwar","Bryan Atista Kiely","Gabriel Kreiman","Zenglin Shi","Mengmi Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16179v4","updated":"2026-02-23T06:33:42Z","published":"2026-02-18T04:35:46Z","title":"EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments","summary":"We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce CoreCraft, the first environment in EnterpriseBench, Surge AI's suite of agentic RL environments. CoreCraft is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM 4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37% to 36.76% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5% on BFCL Parallel, +7.4% on Tau2-Bench Retail, and +6.8% on Tool Decathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.","authors":["Sushant Mehta","Logan Ritchie","Suhaas Garre","Ian Niebres","Nick Heiner","Edwin Chen"],"pdf_url":"","comment":null}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2602.20082v1","updated":"2026-02-23T17:48:24Z","published":"2026-02-23T17:48:24Z","title":"Machine-Generated, Machine-Checked Proofs for a Verified Compiler (Experience Report)","summary":"We report on using an agentic coding assistant (Claude Code, powered by Claude Opus 4.6) to mechanize a substantial Rocq correctness proof from scratch, with human guidance but without human proof writing. The proof establishes semantic preservation for the administrative normal form (ANF) transformation in the CertiCoq verified compiler for Rocq. The closely related continuation-passing style (CPS) transformation in CertiCoq was previously proved correct by human experts over several months. We use this proof as a template and instruct the LLM to adapt the proof technique to the ANF setting, which differs in important technical ways. The resulting ANF proof comprises approximately 7,800 lines of Rocq (larger than the 5,300-line CPS proof) and was developed in approximately 96 hours. We describe the proof technique and report on the experience of developing it with an LLM, discussing both the strengths and limitations of the approach and its implications for verified compiler construction.","authors":["Zoe Paraskevopoulou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20064v1","updated":"2026-02-23T17:22:35Z","published":"2026-02-23T17:22:35Z","title":"The LLMbda Calculus: AI Agents, Conversations, and Information Flow","summary":"A conversation with a large language model (LLM) is a sequence of prompts and responses, with each response generated from the preceding conversation. AI agents build such conversations automatically: given an initial human prompt, a planner loop interleaves LLM calls with tool invocations and code execution. This tight coupling creates a new and poorly understood attack surface. A malicious prompt injected into a conversation can compromise later reasoning, trigger dangerous tool calls, or distort final outputs. Despite the centrality of such systems, we currently lack a principled semantic foundation for reasoning about their behaviour and safety. We address this gap by introducing an untyped call-by-value lambda calculus enriched with dynamic information-flow control and a small number of primitives for constructing prompt-response conversations. Our language includes a primitive that invokes an LLM: it serializes a value, sends it to the model as a prompt, and parses the response as a new term. This calculus faithfully represents planner loops and their vulnerabilities, including the mechanisms by which prompt injection alters subsequent computation. The semantics explicitly captures conversations, and so supports reasoning about defenses such as quarantined sub-conversations, isolation of generated code, and information-flow restrictions on what may influence an LLM call. A termination-insensitive noninterference theorem establishes integrity and confidentiality guarantees, demonstrating that a formal calculus can provide rigorous foundations for safe agentic programming.","authors":["Zac Garby","Andrew D. Gordon","David Sands"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19973v1","updated":"2026-02-23T15:37:18Z","published":"2026-02-23T15:37:18Z","title":"Misquoted No More: Securely Extracting F* Programs with IO","summary":"Shallow embeddings that use monads to represent effects are popular in proof-oriented languages because they are convenient for formal verification. Once shallowly embedded programs are verified, they are often extracted to mainstream languages like OCaml or C and linked into larger codebases. The extraction process is not fully verified because it often involves quotation -- turning the shallowly embedded program into a deeply embedded one -- and verifying quotation remains a major open challenge. Instead, some prior work obtains formal correctness guarantees using translation validation to certify individual extraction results. We build on this idea, but limit the use of translation validation to a first extraction step that we call relational quotation and that uses a metaprogram to construct a typing derivation for the given shallowly embedded program. This metaprogram is simple, since the typing derivation follows the structure of the original program. Once we validate, syntactically, that the typing derivation is valid for the original program, we pass it to a verified syntax-generation function that produces code guaranteed to be semantically related to the original program.\n  We apply this general idea to build SEIO*, a framework for extracting shallowly embedded F* programs with IO to a deeply embedded lambda-calculus while providing formal secure compilation guarantees. Using two cross-language logical relations, we devise a machine-checked proof in F* that SEIO* guarantees Robust Relational Hyperproperty Preservation (RrHP), a very strong secure compilation criterion that implies full abstraction as well as preservation of trace properties and hyperproperties against arbitrary adversarial contexts. This goes beyond the state of the art in verified and certifying extraction, which so far has focused on correctness rather than security.","authors":["Cezar-Constantin Andrici","Abigail Pribisova","Danel Ahman","Catalin Hritcu","Exequiel Rivas","Théo Winterhalter"],"pdf_url":"","comment":"Submitted to ICFP'26"},{"id":"http://arxiv.org/abs/2602.19951v1","updated":"2026-02-23T15:19:41Z","published":"2026-02-23T15:19:41Z","title":"Taming Scope Extrusion in Gradual Imperative Metaprogramming","summary":"Metaprogramming enables the generation of performant code, while gradual typing facilitates the smooth migration from untyped scripts to robust statically typed programs. However, combining these features with imperative state - specifically mutable references - reintroduces the classic peril of scope extrusion, where code fragments containing free variables escape their defining lexical context. While static type systems utilizing environment classifiers have successfully tamed this interaction, enforcing these invariants in a gradual language remains an open challenge.\n  This paper presents $λ^{α,\\star}_{\\text{Ref}}$, the first gradual metaprogramming language that supports mutable references while guaranteeing scope safety. To put $λ^{α,\\star}_{\\text{Ref}}$ on a firm foundation, we also develop its statically typed sister language, $λ^α_{\\text{Ref}}$, that introduces unrestricted subtyping for environment classifiers. Our key innovation, however, is the dynamic enforcement of the environment classifier discipline in $λ^{α,\\star}_{\\text{Ref}}$, enabling the language to mediate between statically verified scopes and dynamically verified scopes. The dynamic enforcement is carried out in a novel cast calculus $\\mathrm{CC}^{α,\\star}_{\\text{Ref}}$ that uses an extension of Henglein's Coercion Calculus to handle code types, classifier polymorphism, and subtype constraints. We prove that $λ^{α,\\star}_{\\text{Ref}}$ satisfies type safety and scope safety. Finally, we provide a space-efficient implementation strategy for the dynamic scope checks, ensuring that the runtime overhead remains practical.","authors":["Tianyu Chen","Darshal Shetty","Jeremy G. Siek","Chao-Hong Chen","Weixi Ma","Arnaud Venet","Rocky Liu"],"pdf_url":"","comment":"34 pages, 19 figures"},{"id":"http://arxiv.org/abs/2601.13040v2","updated":"2026-02-23T14:16:39Z","published":"2026-01-19T13:22:13Z","title":"CPU-less parallel execution of lambda calculus in digital logic","summary":"While transistor density is still increasing, clock speeds are not, motivating the search for new parallel architectures. One approach is to completely abandon the concept of CPU -- and thus serial imperative programming -- and instead to specify and execute tasks in parallel, compiling from programming languages to data flow digital logic. It is well-known that pure functional languages are inherently parallel, due to the Church-Rosser theorem, and CPU-based parallel compilers exist for many functional languages. However, these still rely on conventional CPUs and their von Neumann bottlenecks. An alternative is to compile functional languages directly into digital logic to maximize available parallelism. It is difficult to work with complete modern functional languages due to their many features, so we demonstrate a proof-of-concept system using lambda calculus as the source language and compiling to digital logic. We show how functional hardware can be tailored to a simplistic functional language, forming the ground for a new model of CPU-less functional computation. At the algorithmic level, we use a tree-based representation, with data localized within nodes and communicated data passed between them. This is implemented by physical digital logic blocks corresponding to nodes, and buses enabling message passing. Node types and behaviors correspond to lambda grammar forms, and beta-reductions are performed in parallel allowing branches independent from one another to perform transformations simultaneously. As evidence for this approach, we present an implementation, along with simulation results, showcasing successful execution of lambda expressions. This suggests that the approach could be scaled to larger functional languages. Successful execution of a test suite of lambda expressions suggests that the approach could be scaled to larger functional languages.","authors":["Harry Fitchett","Charles Fox"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19868v1","updated":"2026-02-23T14:12:17Z","published":"2026-02-23T14:12:17Z","title":"Combining Small-Step and Big-Step Semantics to Verify Loop Optimizations","summary":"Verified compilers aim to guarantee that compilation preserves the observable behavior of source programs. While small-step semantics are widely used in such compilers, they are not always the most convenient framework for structural transformations such as loop optimizations. This paper proposes an approach that leverages both small-step and big-step semantics: small-step semantics are used for local transformations, while big-step semantics are employed for structural transformations. An abstract behavioral semantics is introduced as a common interface between the two styles. Coinductive big-step semantics is extended to correctly handle divergence with both finite and infinite traces, bringing it on par with the expressiveness of small-step semantics. This enables the insertion of big-step transformations into the middle of an existing small-step pipeline, thereby fully preserving all top-level semantic preservation theorems. This approach is practically demonstrated in CompCert by implementing and verifying a few new loop optimizations in big-step Cminor, including loop unswitching and, notably, full loop unrolling.","authors":["David Knothe","Oliver Bringmann"],"pdf_url":"","comment":"18 pages, 6 figures. Submitted to ITP 2026"},{"id":"http://arxiv.org/abs/2602.19762v1","updated":"2026-02-23T12:12:39Z","published":"2026-02-23T12:12:39Z","title":"Hexagon-MLIR: An AI Compilation Stack For Qualcomm's Neural Processing Units (NPUs)","summary":"In this paper, we present Hexagon-MLIR,an open-source compilation stack that targets Qualcomm Hexagon Neural Processing Unit (NPU) and provides unified support for lowering Triton kernels and PyTorch models . Built using the MLIR framework, our compiler applies a structured sequence of passes to exploit NPU architectural features to accelerate AI workloads. It enables faster deployment of new Triton kernels (hand-written or subgraphs from PyTorch 2.0), for our target by providing automated compilation from kernel to binary. By ingesting Triton kernels, we generate mega-kernels that maximize data locality in the NPU's Tightly Coupled Memory (TCM), reducing the bandwidth bottlenecks inherent in library-based approaches. This initiative complements our commercial toolchains by providing developers with an open-source MLIR-based compilation stack that gives them a path to advance AI compilation capabilities through a more flexible approach. Hexagon-MLIR is a work-in-progress, and we are continuing to add many more optimizations and capabilities in this effort.","authors":["Mohammed Javed Absar","Muthu Baskaran","Abhikrant Sharma","Abhilash Bhandari","Ankit Aggarwal","Arun Rangasamy","Dibyendu Das","Fateme Hosseini","Franck Slama","Iulian Brumar","Jyotsna Verma","Krishnaprasad Bindumadhavan","Mitesh Kothari","Mohit Gupta","Ravishankar Kolachana","Richard Lethin","Samarth Narang","Sanjay Motilal Ladwa","Shalini Jain","Snigdha Suresh Dalvi","Tasmia Rahman","Venkat Rasagna Reddy Komatireddy","Vivek Vasudevbhai Pandya","Xiyue Shi","Zachary Zipper"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.20356v3","updated":"2026-02-23T11:45:07Z","published":"2025-06-25T12:11:47Z","title":"Deadlock-free Context-free Session Types","summary":"We tackle the problem of statically ensuring that message-passing programs never run into deadlocks. We focus on concurrent functional programs governed by context-free session types, which can express rich tree-like structures not expressible in standard session types. We propose a new type system based on context-free session types: it enforces both protocol conformance and deadlock freedom, also for programs implementing cyclic communication topologies with recursion and polymorphism. We show how the priority-based approach to deadlock freedom can be extended to this expressive setting. We prove that well-typed concurrent programs respect their protocols and never deadlock.","authors":["Andreia Mordido","Jorge A. Pérez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19686v1","updated":"2026-02-23T10:31:22Z","published":"2026-02-23T10:31:22Z","title":"A Flow Extension to Coroutine Types for Deadlock Detection in Go","summary":"Coroutines, as an abstract programming construct, are a generalization of functions that can suspend execution part- way for later resumption. Coroutine Types are behavioral types to model interactions of coroutines with a single receiving operation followed by a single yielding operation. Coroutine Types have been applied to model-driven engineering, smart contracts, and test case generation. We contribute a Flow extension to Coroutine Types, so that coroutines with more than one receiving and yielding operation can be modeled. We accordingly revise the reduction rules of Coroutine Types. To show the usefulness of the Flow extension, we contribute a type system that maps expressions of the Go programming language to Coroutine Types. If the reduction result is 0, the two channel operations are paired properly and the program has no deadlocks. We choose Go because it is a popular programming language for distributed systems, but a frequent kind of bugs in Go is deadlocks due to the wrong use of concurrency features. We concentrate on the most commonly used semantics in Go: unbuffered channels with the keywords go and defer. Our Flow extension and the type system recognize 17 patterns of channels and goroutine interactions, including mismatched receivers and senders, nested goroutines, etc. We also integrate the Z3 SMT solver to take account of conditional execution and type inheritance. Other static or dynamic deadlock detectors crashed or gave wrong predictions in some patterns. Therefore, our type-based deadlock analyzer not only fills the gap in the landscape of value-based detection, but also complements existing detectors.","authors":["Qiqi Jason Gu","Lixue Liu","Wei Ke"],"pdf_url":"","comment":"Accepted in ICSESS 2025, Macao"},{"id":"http://arxiv.org/abs/2505.24183v5","updated":"2026-02-23T09:24:51Z","published":"2025-05-30T03:51:06Z","title":"QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation","summary":"Large language models (LLMs) trained via reinforcement learning with verifiable reward (RLVR) have achieved breakthroughs on tasks with explicit, automatable verification, such as software programming and mathematical problems. Extending RLVR to electronic design automation (EDA), especially automatically generating hardware description languages (HDLs) like Verilog from natural-language (NL) specifications, however, poses three key challenges: the lack of automated and accurate verification environments, the scarcity of high-quality NL-code pairs, and the prohibitive computation cost of RLVR. To this end, we introduce CodeV-R1, an RLVR framework for training Verilog generation LLMs. First, we develop a rule-based testbench generator that performs robust equivalence checking against golden references. Second, we propose a round-trip data synthesis method that pairs open-source Verilog snippets with LLM-generated NL descriptions, verifies code-NL-code consistency via the generated testbench, and filters out inequivalent examples to yield a high-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training pipeline: distillation for the cold start of reasoning abilities, followed by adaptive DAPO, our novel RLVR algorithm that can reduce training cost by adaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves 68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively, surpassing prior state-of-the-art by 12~20%, while even exceeding the performance of 671B DeepSeek-R1 on RTLLM. We have released our model, training code, and dataset to facilitate research in EDA and LLM communities.","authors":["Yaoyu Zhu","Di Huang","Hanqi Lyu","Xiaoyun Zhang","Chongxiao Li","Wenxuan Shi","Yutong Wu","Jianan Mu","Jinghua Wang","Yang Zhao","Pengwei Jin","Shuyao Cheng","Shengwen Liang","Xishan Zhang","Rui Zhang","Zidong Du","Qi Guo","Xing Hu","Yunji Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16291v2","updated":"2026-02-23T09:04:26Z","published":"2026-02-18T09:17:20Z","title":"A Calculus of Overlays","summary":"Just as the $λ$-calculus uses three primitives (abstraction,\n  application, variable) as the foundation of functional programming,\n  overlay-calculus uses three primitives (record, definition, inheritance)\n  as the foundation of declarative programming.\n  It trivially embeds the $λ$-calculus, although the entire\n  semantics rests solely on naive set theory;\n  as a consequence, all constructs including inheritance are\n  inherently commutative, idempotent, and associative; the\n  linearization problem of multiple inheritance\n  does not arise.\n  This induces a fully abstract semantics of the lazy\n  $λ$-calculus with respect to Böhm tree\n  equivalence~\\cite{barendregt1984lambda}.\n  Overlay-calculus is distilled from the Overlay language, a\n  practical implementation in which we observed further emergent\n  phenomena: the Expression Problem dissolves, programs are\n  function color blind~\\cite{nystrom2015color}, ordinary arithmetic\n  yields the relational semantics of logic programming,\n  and self-reference resolves to multiple targets,\n  making overlay-calculus strictly more expressive than the\n  $λ$-calculus in Felleisen's\n  sense~\\cite{felleisen1991expressive}.\n  These properties suggest applications to configuration languages,\n  dependency injection, object-oriented programming, composable\n  effect systems, modular software architectures,\n  file-system-as-compiler, general-purpose programming,\n  and no-code development.","authors":["Bo Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.05616v5","updated":"2026-02-23T00:13:41Z","published":"2025-01-09T23:35:26Z","title":"Validating Quantum State Preparation Programs (Extended Version)","summary":"One of the key steps in quantum algorithms is to prepare an initial quantum superposition state with different kinds of features. These so-called state preparation algorithms are essential to the behavior of quantum algorithms, and complicated state preparation algorithms are difficult to develop correctly and effectively. This paper presents Pqasm: a high-assurance framework implemented with the Coq proof assistant, allowing us to certify our Pqasm tool to correctly reflect quantum program behaviors. The key in the framework is to reduce the program correctness assurance of a program containing a quantum superposition state to the program correctness assurance for the program state without superposition. The reduction allows the development of an effective testing framework for testing quantum state preparation algorithm implementations on a classical computer - considered to be a hard problem with no clear solution until this point. We utilize the QuickChick property-based testing framework to test state preparation programs. We evaluated the effectiveness of our approach over 5 case studies implemented using Pqasm; such cases are not even simulatable in the current quantum simulators.","authors":["Liyi Li","Anshu Sharma","Zoukarneini Difaizi Tagba","Sean Frett","Alex Potanin"],"pdf_url":"","comment":"Version 5"},{"id":"http://arxiv.org/abs/2602.21257v1","updated":"2026-02-23T17:03:31Z","published":"2026-02-23T17:03:31Z","title":"Structured Prompt Language: Declarative Context Management for LLMs","summary":"We present SPL (Structured Prompt Language), a declarative SQL-inspired language that treats large language models as generative knowledge bases and their context windows as constrained resources. SPL provides explicit WITH BUDGET/LIMIT token management, an automatic query optimizer, EXPLAIN transparency analogous to SQL's EXPLAIN ANALYZE, and native integration of retrieval-augmented generation (RAG) and persistent memory in a single declarative framework. SPL-flow extends SPL into resilient agentic pipelines with a three-tier provider fallback strategy (Ollama -> OpenRouter -> self-healing retry) fully transparent to the .spl script. Five extensions demonstrate the paradigm's breadth: (1) Text2SPL (multilingual NL->SPL translation); (2) Mixture-of-Models (MoM) routing that dispatches each PROMPT to a domain-specialist model at runtime; (3) Logical Chunking, an intelligent strategy for documents exceeding a single context window--expressed naturally through SPL's existing CTE syntax with no new constructs, decomposing a large query into a Map-Reduce pipeline that reduces attention cost from O(N^2) to O(N^2/k) and runs identically on cloud (parallel) or local hardware (sequential); (4) SPL-flow, a declarative agentic orchestration layer with resilient three-tier provider fallback; and (5) BENCHMARK for parallel multi-model comparison with automatic winner persistence. We provide a formal EBNF grammar, two pip-installable Python packages (spl-llm, spl-flow), and comparison against Prompty, DSPy, and LMQL. SPL reduces prompt boilerplate by 65% on average, surfaces a 68x cost spread across model tiers as a pre-execution signal, and runs the identical .spl script at $0.002 on OpenRouter or at zero marginal cost on a local Ollama instance--without modification.","authors":["Wen G. Gong"],"pdf_url":"","comment":"44 pages, 6 figures, 14 tables, 15 code-listings"}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.20048v1","updated":"2026-02-23T16:58:37Z","published":"2026-02-23T16:58:37Z","title":"CodeCompass: Navigating the Navigation Paradox in Agentic Code Intelligence","summary":"Modern code intelligence agents operate in contexts exceeding 1 million tokens--far beyond the scale where humans manually locate relevant files. Yet agents consistently fail to discover architecturally critical files when solving real-world coding tasks. We identify the Navigation Paradox: agents perform poorly not due to context limits, but because navigation and retrieval are fundamentally distinct problems. Through 258 automated trials across 30 benchmark tasks on a production FastAPI repository, we demonstrate that graph-based structural navigation via CodeCompass--a Model Context Protocol server exposing dependency graphs--achieves 99.4% task completion on hidden-dependency tasks, a 23.2 percentage-point improvement over vanilla agents (76.2%) and 21.2 points over BM25 retrieval (78.2%).However, we uncover a critical adoption gap: 58% of trials with graph access made zero tool calls, and agents required explicit prompt engineering to adopt the tool consistently. Our findings reveal that the bottleneck is not tool availability but behavioral alignment--agents must be explicitly guided to leverage structural context over lexical heuristics. We contribute: (1) a task taxonomy distinguishing semantic-search, structural, and hidden-dependency scenarios; (2) empirical evidence that graph navigation outperforms retrieval when dependencies lack lexical overlap; and (3) open-source infrastructure for reproducible evaluation of navigation tools.","authors":["Tarakanath Paipuru"],"pdf_url":"","comment":"23 pages, 7 figures. Research study with 258 trials on SWE-bench-lite tasks. Code and data: https://github.com/tpaip607/research-codecompass"},{"id":"http://arxiv.org/abs/2505.20004v4","updated":"2026-02-23T15:36:27Z","published":"2025-05-26T13:55:33Z","title":"Requirements Coverage-Guided Minimization for Natural Language Test Cases","summary":"As software systems evolve, test suites tend to grow in size and often contain redundant test cases. Such redundancy increases testing effort, time, and cost. Test suite minimization (TSM) aims to eliminate such redundancy while preserving key properties such as requirement coverage and fault detection capability. In this paper, we propose RTM (Requirement coverage-guided Test suite Minimization), a novel TSM approach designed for requirement-based testing (validation), which can effectively reduce test suite redundancy while ensuring full requirement coverage and a high fault detection rate (FDR) under a fixed minimization budget. Based on common practice in critical systems where functional safety is important, we assume test cases are specified in natural language and traced to requirements before being implemented. RTM preprocesses test cases using three different preprocessing methods, and then converts them into vector representations using seven text embedding techniques. Similarity values between vectors are computed utilizing three distance functions. A Genetic Algorithm, whose population is initialized by coverage-preserving initialization strategies, is then employed to identify an optimized subset containing diverse test cases matching the set budget.\n  We evaluate RTM on an industrial automotive system dataset comprising $736$ system test cases and $54$ requirements. Experimental results show that RTM consistently outperforms baseline techniques in terms of FDR across different minimization budgets while maintaining full requirement coverage. Furthermore, we investigate the impact of test suite redundancy levels on the effectiveness of TSM, providing new insights into optimizing requirement-based test suites under practical constraints.","authors":["Rongqi Pan","Feifei Niu","Lionel C. Briand","Hanyang Hu"],"pdf_url":"","comment":"Accepted at ACM Transactions on Software Engineering and Methodology (TOSEM)"},{"id":"http://arxiv.org/abs/2602.19844v1","updated":"2026-02-23T13:48:36Z","published":"2026-02-23T13:48:36Z","title":"LLM-enabled Applications Require System-Level Threat Monitoring","summary":"LLM-enabled applications are rapidly reshaping the software ecosystem by using large language models as core reasoning components for complex task execution. This paradigm shift, however, introduces fundamentally new reliability challenges and significantly expands the security attack surface, due to the non-deterministic, learning-driven, and difficult-to-verify nature of LLM behavior. In light of these emerging and unavoidable safety challenges, we argue that such risks should be treated as expected operational conditions rather than exceptional events, necessitating a dedicated incident-response perspective. Consequently, the primary barrier to trustworthy deployment is not further improving model capability but establishing system-level threat monitoring mechanisms that can detect and contextualize security-relevant anomalies after deployment -- an aspect largely underexplored beyond testing or guardrail-based defenses. Accordingly, this position paper advocates systematic and comprehensive monitoring of security threats in LLM-enabled applications as a prerequisite for reliable operation and a foundation for dedicated incident-response frameworks.","authors":["Yedi Zhang","Haoyu Wang","Xianglin Yang","Jin Song Dong","Jun Sun"],"pdf_url":"","comment":"26 pages"},{"id":"http://arxiv.org/abs/2602.19843v1","updated":"2026-02-23T13:47:43Z","published":"2026-02-23T13:47:43Z","title":"MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems","summary":"As LLM-based Multi-Agent Systems (MAS) are increasingly deployed for complex tasks, ensuring their reliability has become a pressing challenge. Since MAS coordinate through unstructured natural language rather than rigid protocols, they are prone to semantic failures (e.g., hallucinations, misinterpreted instructions, and reasoning drift) that propagate silently without raising runtime exceptions. Prevailing evaluation approaches, which measure only end-to-end task success, offer limited insight into how these failures arise or how effectively agents recover from them. To bridge this gap, we propose MAS-FIRE, a systematic framework for fault injection and reliability evaluation of MAS. We define a taxonomy of 15 fault types covering intra-agent cognitive errors and inter-agent coordination failures, and inject them via three non-invasive mechanisms: prompt modification, response rewriting, and message routing manipulation. Applying MAS-FIRE to three representative MAS architectures, we uncover a rich set of fault-tolerant behaviors that we organize into four tiers: mechanism, rule, prompt, and reasoning. This tiered view enables fine-grained diagnosis of where and why systems succeed or fail. Our findings reveal that stronger foundation models do not uniformly improve robustness. We further show that architectural topology plays an equally decisive role, with iterative, closed-loop designs neutralizing over 40% of faults that cause catastrophic collapse in linear workflows. MAS-FIRE provides the process-level observability and actionable guidance needed to systematically improve multi-agent systems.","authors":["Jin Jia","Zhiling Deng","Zhuangbin Chen","Yingqi Wang","Zibin Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02780v3","updated":"2026-02-23T13:17:25Z","published":"2025-11-04T18:03:12Z","title":"PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts","summary":"Smart contracts operate in a highly adversarial environment, where vulnerabilities can lead to substantial financial losses. Thus, smart contracts are subject to security audits. In auditing, proof-of-concept (PoC) exploits play a critical role by demonstrating to the stakeholders that the reported vulnerabilities are genuine, reproducible, and actionable. However, manually creating PoCs is time-consuming, error-prone, and often constrained by tight audit schedules. We introduce PoCo, an agentic framework that automatically generates executable PoC exploits from natural-language vulnerability descriptions written by auditors. PoCo autonomously generates PoC exploits in an agentic manner by interacting with a set of codeexecution tools in a Reason-Act-Observe loop. It produces fully executable exploits compatible with the Foundry testing framework, ready for integration into audit reports and other security tools. We evaluate PoCo on a dataset of 23 real-world vulnerability reports. PoCo consistently outperforms the Zero-shot and Workflow baselines, generating well-formed and logically correct PoCs. Our results demonstrate that agentic frameworks can significantly reduce the effort required for high-quality PoCs in smart contract audits. Our contribution provides actionable knowledge for the smart contract security community.","authors":["Vivi Andersson","Sofia Bobadilla","Harald Hobbelhagen","Martin Monperrus"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2602.19718v1","updated":"2026-02-23T11:11:56Z","published":"2026-02-23T11:11:56Z","title":"Carbon-Aware Governance Gates: An Architecture for Sustainable GenAI Development","summary":"The rapid adoption of Generative AI (GenAI) in the software development life cycle (SDLC) increases computational demand, which can raise the carbon footprint of development activities. At the same time, organizations are increasingly embedding governance mechanisms into GenAI-assisted development to support trust, transparency, and accountability. However, these governance mechanisms introduce additional computational workloads, including repeated inference, regeneration cycles, and expanded validation pipelines, increasing energy use and the carbon footprint of GenAI-assisted development. This paper proposes Carbon-Aware Governance Gates (CAGG), an architectural extension that embeds carbon budgets, energy provenance, and sustainability-aware validation orchestration into human-AI governance layers. CAGG comprises three components: (i) an Energy and Carbon Provenance Ledger, (ii) a Carbon Budget Manager, and (iii) a Green Validation Orchestrator, operationalized through governance policies and reusable design patterns.","authors":["Mateen A. Abbasi","Tommi J. Mikkonen","Petri J. Ihantola","Muhammad Waseem","Pekka Abrahamsson","Niko K. Mäkitalo"],"pdf_url":"","comment":"5 pages, 1 figure. Preprint version under review"},{"id":"http://arxiv.org/abs/2602.19714v1","updated":"2026-02-23T11:05:56Z","published":"2026-02-23T11:05:56Z","title":"Git Takes Two: Split-View Awareness for Collaborative Learning of Distributed Workflows in Git","summary":"Git is widely used for collaborative software development, but it can be challenging for newcomers. While most learning tools focus on individual workflows, Git is inherently collaborative. We present GitAcademy, a browser-based learning platform that embeds a full Git environment with a split-view collaborative mode: learners work on their own local repositories connected to a shared remote repository, while simultaneously seeing their partner's actions mirrored in real time. This design is not intended for everyday software development, but rather as a training simulator to build awareness of distributed states, coordination, and collaborative troubleshooting. In a within-subjects study with 13 pairs of learners, we found that the split-view interface enhanced social presence, supported peer teaching, and was consistently preferred over a single-view baseline, even though performance gains were mixed. We further discuss how split-view awareness can serve as a training-only scaffold for collaborative learning of Git and other distributed technical systems.","authors":["Joel Bucher","Lahari Goswami","Sverrir Thorgeirsson","April Yi Wang"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2602.19628v1","updated":"2026-02-23T09:16:42Z","published":"2026-02-23T09:16:42Z","title":"Towards Understanding Views on Combining Videos and Gamification in Software Engineering Training","summary":"Watching training videos passively leads to superficial learning. Adding gamification can increase engagement. We study how software engineering students and industry practitioners view gamifying video-based training. We conducted a survey with students and professionals. Students and professionals share similar perceptions toward video-based training in general and support combining gamification and video-based training. Our findings can inform the design of gamified training solutions for software engineers.","authors":["Pasan Peiris","Matthias Galster","Antonija Mitrovic","Sanna Malinen","Raul Vincent Lumapas","Jay Holland"],"pdf_url":"","comment":"2 pages, ICSE-Companion '26"},{"id":"http://arxiv.org/abs/2602.16291v2","updated":"2026-02-23T09:04:26Z","published":"2026-02-18T09:17:20Z","title":"A Calculus of Overlays","summary":"Just as the $λ$-calculus uses three primitives (abstraction,\n  application, variable) as the foundation of functional programming,\n  overlay-calculus uses three primitives (record, definition, inheritance)\n  as the foundation of declarative programming.\n  It trivially embeds the $λ$-calculus, although the entire\n  semantics rests solely on naive set theory;\n  as a consequence, all constructs including inheritance are\n  inherently commutative, idempotent, and associative; the\n  linearization problem of multiple inheritance\n  does not arise.\n  This induces a fully abstract semantics of the lazy\n  $λ$-calculus with respect to Böhm tree\n  equivalence~\\cite{barendregt1984lambda}.\n  Overlay-calculus is distilled from the Overlay language, a\n  practical implementation in which we observed further emergent\n  phenomena: the Expression Problem dissolves, programs are\n  function color blind~\\cite{nystrom2015color}, ordinary arithmetic\n  yields the relational semantics of logic programming,\n  and self-reference resolves to multiple targets,\n  making overlay-calculus strictly more expressive than the\n  $λ$-calculus in Felleisen's\n  sense~\\cite{felleisen1991expressive}.\n  These properties suggest applications to configuration languages,\n  dependency injection, object-oriented programming, composable\n  effect systems, modular software architectures,\n  file-system-as-compiler, general-purpose programming,\n  and no-code development.","authors":["Bo Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19614v1","updated":"2026-02-23T09:02:38Z","published":"2026-02-23T09:02:38Z","title":"Workflow-Level Design Principles for Trustworthy GenAI in Automotive System Engineering","summary":"The adoption of large language models in safety-critical system engineering is constrained by trustworthiness, traceability, and alignment with established verification practices. We propose workflow-level design principles for trustworthy GenAI integration and demonstrate them in an end-to-end automotive pipeline, from requirement delta identification to SysML v2 architecture update and re-testing. First, we show that monolithic (\"big-bang\") prompting misses critical changes in large specifications, while section-wise decomposition with diversity sampling and lightweight NLP sanity checks improves completeness and correctness. Then, we propagate requirement deltas into SysML v2 models and validate updates via compilation and static analysis. Additionally, we ensure traceable regression testing by generating test cases through explicit mappings from specification variables to architectural ports and states, providing practical safeguards for GenAI used in safety-critical automotive engineering.","authors":["Chih-Hong Cheng","Brian Hsuan-Cheng Liao","Adam Molin","Hasan Esen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19490v1","updated":"2026-02-23T04:20:19Z","published":"2026-02-23T04:20:19Z","title":"FuzzySQL: Uncovering Hidden Vulnerabilities in DBMS Special Features with LLM-Driven Fuzzing","summary":"Traditional database fuzzing techniques primarily focus on syntactic correctness and general SQL structures, leaving critical yet obscure DBMS features, such as system-level modes (e.g., GTID), programmatic constructs (e.g., PROCEDURE), advanced process commands (e.g., KILL), largely underexplored. Although rarely triggered by typical inputs, these features can lead to severe crashes or security issues when executed under edge-case conditions. In this paper, we present FuzzySQL, a novel LLM-powered adaptive fuzzing framework designed to uncover subtle vulnerabilities in DBMS special features. FuzzySQL combines grammar-guided SQL generation with logic-shifting progressive mutation, a novel technique that explores alternative control paths by negating conditions and restructuring execution logic, synthesizing structurally and semantically diverse test cases. To further ensure deeper execution coverage of the back end, FuzzySQL employs a hybrid error repair pipeline that unifies rule-based patching with LLM-driven semantic repair, enabling automatic correction of syntactic and context-sensitive failures. We evaluate FuzzySQL across multiple DBMSs, including MySQL, MariaDB, SQLite, PostgreSQL and Clickhouse, uncovering 37 vulnerabilities, 7 of which are tied to under-tested DBMS special features. As of this writing, 29 cases have been confirmed with 9 assigned CVE identifiers, 14 already fixed by vendors, and additional vulnerabilities scheduled to be patched in upcoming releases. Our results highlight the limitations of conventional fuzzers in semantic feature coverage and demonstrate the potential of LLM-based fuzzing to discover deeply hidden bugs in complex database systems.","authors":["Yongxin Chen","Zhiyuan Jiang","Chao Zhang","Haoran Xu","Shenglin Xu","Jianping Tang","Zheming Li","Peidai Xie","Yongjun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19446v1","updated":"2026-02-23T02:31:15Z","published":"2026-02-23T02:31:15Z","title":"\"Write in English, Nobody Understands Your Language Here\": A Study of Non-English Trends in Open-Source Repositories","summary":"The open-source software (OSS) community has historically been dominated by English as the primary language for code, documentation, and developer interactions. However, with growing global participation and better support for non-Latin scripts through standards like Unicode, OSS is gradually becoming more multilingual. This study investigates the extent to which OSS is becoming more multilingual, analyzing 9.14 billion GitHub issues, pull requests, and discussions, and 62,500 repositories across five programming languages and 30 natural languages, covering the period from 2015 to 2025. We examine six research questions to track changes in language use across communication, code, and documentation. We find that multilingual participation has steadily increased, especially in Korean, Chinese, and Russian. This growth appears not only in issues and discussions but also in code comments, string literals, and documentation files. While this shift reflects greater inclusivity and language diversity in OSS, it also creates language tension. The ability to express oneself in a native language can clash with shared norms around English use, especially in collaborative settings. Non-English or multilingual projects tend to receive less visibility and participation, suggesting that language remains both a resource and a barrier, shaping who gets heard, who contributes, and how open collaboration unfolds.","authors":["Masudul Hasan Masud Bhuiyan","Manish Kumar Bala Kumar","Cristian-Alexandru Staicu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19441v1","updated":"2026-02-23T02:20:56Z","published":"2026-02-23T02:20:56Z","title":"When AI Teammates Meet Code Review: Collaboration Signals Shaping the Integration of Agent-Authored Pull Requests","summary":"Autonomous coding agents increasingly contribute to software development by submitting pull requests on GitHub; yet, little is known about how these contributions integrate into human-driven review workflows. We present a large empirical study of agent-authored pull requests using the public AIDev dataset, examining integration outcomes, resolution speed, and review-time collaboration signals. Using logistic regression with repository-clustered standard errors, we find that reviewer engagement has the strongest correlation with successful integration, whereas larger change sizes and coordination-disrupting actions, such as force pushes, are associated with a lower likelihood of merging. In contrast, iteration intensity alone provides limited explanatory power once collaboration signals are considered. A qualitative analysis further shows that successful integration occurs when agents engage in actionable review loops that converge toward reviewer expectations. Overall, our results highlight that the effective integration of agent-authored pull requests depends not only on code quality but also on alignment with established review and coordination practices.","authors":["Costain Nachuma","Minhaz Zibran"],"pdf_url":"","comment":"5 pages, 2 figures, 1 table. Accepted at the 23rd International Conference on Mining Software Repositories (MSR 2026), Rio de Janeiro, Brazil"},{"id":"http://arxiv.org/abs/2602.19407v1","updated":"2026-02-23T00:54:59Z","published":"2026-02-23T00:54:59Z","title":"Multi-CoLoR: Context-Aware Localization and Reasoning across Multi-Language Codebases","summary":"Large language models demonstrate strong capabilities in code generation but struggle to navigate complex, multi-language repositories to locate relevant code. Effective code localization requires understanding both organizational context (e.g., historical issue-fix patterns) and structural relationships within heterogeneous codebases. Existing methods either (i) focus narrowly on single-language benchmarks, (ii) retrieve code across languages via shallow textual similarity, or (iii) assume no prior context. We present Multi-CoLoR, a framework for Context-aware Localization and Reasoning across Multi-Language codebases, which integrates organizational knowledge retrieval with graph-based reasoning to traverse complex software ecosystems. Multi-CoLoR operates in two stages: (i) a similar issue context (SIC) module retrieves semantically and organizationally related historical issues to prune the search space, and (ii) a code graph traversal agent (an extended version of LocAgent, a state-of-the-art localization framework) performs structural reasoning within C++ and QML codebases. Evaluations on a real-world enterprise dataset show that incorporating SIC reduces the search space and improves localization accuracy, and graph-based reasoning generalizes effectively beyond Python-only repositories. Combined, Multi-CoLoR improves Acc@5 over both lexical and graph-based baselines while reducing tool calls on an AMD codebase.","authors":["Indira Vats","Sanjukta De","Subhayan Roy","Saurabh Bodhe","Lejin Varghese","Max Kiehn","Yonas Bedasso","Marsha Chechik"],"pdf_url":"","comment":"This paper has been accepted for publication at the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026)"},{"id":"http://arxiv.org/abs/2602.20334v1","updated":"2026-02-23T20:31:07Z","published":"2026-02-23T20:31:07Z","title":"UAMTERS: Uncertainty-Aware Mutation Analysis for DL-enabled Robotic Software","summary":"Self-adaptive robots adjust their behaviors in response to unpredictable environmental changes. These robots often incorporate deep learning (DL) components into their software to support functionality such as perception, decision-making, and control, enhancing autonomy and self-adaptability. However, the inherent uncertainty of DL-enabled software makes it challenging to ensure its dependability in dynamic environments. Consequently, test generation techniques have been developed to test robot software, and classical mutation analysis injects faults into the software to assess the test suite's effectiveness in detecting the resulting failures. However, there is a lack of mutation analysis techniques to assess the effectiveness under the uncertainty inherent to DL-enabled software. To this end, we propose UAMTERS, an uncertainty-aware mutation analysis framework that introduces uncertainty-aware mutation operators to explicitly inject stochastic uncertainty into DL-enabled robotic software, simulating uncertainty in its behavior. We further propose mutation score metrics to quantify a test suite's ability to detect failures under varying levels of uncertainty. We evaluate UAMTERS across three robotic case studies, demonstrating that UAMTERS more effectively distinguishes test suite quality and captures uncertainty-induced failures in DL-enabled software.","authors":["Chengjie Lu","Jiahui Wu","Shaukat Ali","Malaika Din Hashmi","Sebastian Mathias Thomle Mason","Francois Picard","Mikkel Labori Olsen","Thomas Peyrucain"],"pdf_url":"","comment":"23 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2512.08910v3","updated":"2026-02-23T20:04:19Z","published":"2025-12-09T18:47:00Z","title":"Exploring the Garden of Forking Paths in Empirical Software Engineering Research: A Multiverse Analysis","summary":"In empirical software engineering (SE) research, researchers have considerable freedom to decide how to process data, what operationalizations to use, and which statistical model to fit. Gelman and Loken refer to this freedom as leading to a \"garden of forking paths\". Although this freedom is often seen as an advantage, it also poses a threat to robustness and replicability: variations in analytical decisions, even when justifiable, can lead to divergent conclusions.\n  To better understand this risk, we conducted a so-called multiverse analysis on a published empirical SE paper. The paper we picked is a Mining Software Repositories study, as MSR studies commonly use non-trivial statistical models to analyze post-hoc, observational data. In the study, we identified nine pivotal analytical decisions-each with at least one equally defensible alternative and systematically reran all the 3,072 resulting analysis pipelines on the original dataset. Interestingly, only 6 of these universes (<0.2%) reproduced the published results; the overwhelming majority produced qualitatively different, and sometimes even opposite, findings.\n  This case study of a data analytical method commonly applied to empirical software engineering data reveals how methodological choices can exert a more profound influence on outcomes than is often acknowledged. We therefore advocate that SE researchers complement standard reporting with robustness checks across plausible analysis variants or, at least, explicitly justify each analytical decision. We propose a structured classification model to help classify and improve justification for methodological choices. Secondly, we show how the multiverse analysis is a practical tool in the methodological arsenal of SE researchers, one that can help produce more reliable, reproducible science.","authors":["Nathan Cassee","Robert Feldt"],"pdf_url":"","comment":"Just Accepted at TOSEM"},{"id":"http://arxiv.org/abs/2510.08810v3","updated":"2026-02-23T19:48:02Z","published":"2025-10-09T20:54:26Z","title":"MigrateLib: a tool for end-to-end Python library migration","summary":"Library migration is the process of replacing a library with a similar one in a software project. Manual library migration is time consuming and error prone, as it requires developers to understand the Application Programming Interfaces (API) of both libraries, map equivalent APIs, and perform the necessary code transformations. Due to the difficulty of the library migration process, most of the existing automated techniques and tooling stop at the API mapping stage or support a limited set of libraries and code transformations. In this paper, we develop an end-to-end solution that can automatically migrate code between any arbitrary pair of Python libraries that provide similar functionality. Due to the promising capabilities of Large Language Models (LLMs) in code generation and transformation, we use LLMs as the primary engine for migration. Before building the tool, we first study the capabilities of LLMs for library migration on a benchmark of 321 real-world library migrations. We find that LLMs can effectively perform library migration, but some post-processing steps can further improve the performance. Based on this, we develop MigrateLib, a command line application that combines the power of LLMs, static analysis, and dynamic analysis to provide accurate library migration. We evaluate MigrateLib on 717 real-world Python applications that are not from our benchmark. We find that MigrateLib can migrate 32% of the migrations with complete correctness. Of the remaining migrations, only 14% of the migration-related changes are left for developers to fix for more than half of the projects.","authors":["Mohayeminul Islam","Ajay Kumar Jha","May Mahmoud","Sarah Nadi"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2504.13272"},{"id":"http://arxiv.org/abs/2602.20292v1","updated":"2026-02-23T19:16:30Z","published":"2026-02-23T19:16:30Z","title":"Quantifying the Expectation-Realisation Gap for Agentic AI Systems","summary":"Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across software engineering, clinical documentation, and clinical decision support to quantify this expectation-realisation gap. In software development, experienced developers expected a 24% speedup from AI tools but were slowed by 19% -- a 43 percentage-point calibration error. In clinical documentation, vendor claims of multi-minute time savings contrast with measured reductions of less than one minute per note, and one widely deployed tool showed no statistically significant effect. In clinical decision support, externally validated performance falls substantially below developer-reported metrics. These shortfalls are driven by workflow integration friction, verification burden, measurement construct mismatches, and systematic heterogeneity in treatment effects. The evidence motivates structured planning frameworks that require explicit, quantified benefit expectations with human oversight costs factored in.","authors":["Sebastian Lobentanzer"],"pdf_url":"","comment":"9 pages, no figures"},{"id":"http://arxiv.org/abs/2602.20284v1","updated":"2026-02-23T19:13:22Z","published":"2026-02-23T19:13:22Z","title":"PhantomRun: Auto Repair of Compilation Errors in Embedded Open Source Software","summary":"Continuous Integration (CI) pipelines for embedded software sometimes fail during compilation, consuming significant developer time for debugging. We study four major open-source embedded system projects, spanning over 4000 build failures from the project's CI runs. We find that hardware dependencies account for the majority of compilation failures, followed by syntax errors and build-script issues. Most repairs need relatively small changes, making automated repair potentially suitable as long as the diverse setups and lack of test data can be handled.\n  In this paper, we present PhantomRun, an automated framework that leverages large language models (LLMs) to generate and validate fixes for CI compilation failures. The framework addresses the challenge of diverse build infrastructures and tool chains across embedded system projects by providing an adaptation layer for GitHub Actions and GitLab CI and four different build systems. PhantomRun utilizes build logs, source code, historical fixes, and compiler error messages to synthesize fixes using LLMs. Our evaluations show that PhantomRun successfully repairs up to 45% of CI compilation failures across the targeted projects, demonstrating the viability of LLM-based repairs for embedded-system CI pipelines.","authors":["Han Fu","Andreas Ermedahl","Sigrid Eldh","Kristian Wiklund","Philipp Haller","Cyrille Artho"],"pdf_url":"","comment":"13 pages, 5 figures, Mining Software Repositories 2026 (MSR 2026) , Rio de Janeiro, Brazil, 13-14 April 2026"},{"id":"http://arxiv.org/abs/2602.20213v1","updated":"2026-02-23T05:59:30Z","published":"2026-02-23T05:59:30Z","title":"CodeHacker: Automated Test Case Generation for Detecting Vulnerabilities in Competitive Programming Solutions","summary":"The evaluation of Large Language Models (LLMs) for code generation relies heavily on the quality and robustness of test cases. However, existing benchmarks often lack coverage for subtle corner cases, allowing incorrect solutions to pass. To bridge this gap, we propose CodeHacker, an automated agent framework dedicated to generating targeted adversarial test cases that expose latent vulnerabilities in program submissions. Mimicking the hack mechanism in competitive programming, CodeHacker employs a multi-strategy approach, including stress testing, anti-hash attacks, and logic-specific targeting to break specific code submissions. To ensure the validity and reliability of these attacks, we introduce a Calibration Phase, where the agent iteratively refines its own Validator and Checker via self-generated adversarial probes before evaluating contestant code.Experiments demonstrate that CodeHacker significantly improves the True Negative Rate (TNR) of existing datasets, effectively filtering out incorrect solutions that were previously accepted. Furthermore, generated adversarial cases prove to be superior training data, boosting the performance of RL-trained models on benchmarks like LiveCodeBench.","authors":["Jingwei Shi","Xinxiang Yin","Jing Huang","Jinman Zhao","Shengyu Tao"],"pdf_url":"","comment":null}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2602.20156v1","updated":"2026-02-23T18:59:27Z","published":"2026-02-23T18:59:27Z","title":"Skill-Inject: Measuring Agent Vulnerability to Skill File Attacks","summary":"LLM agents are evolving rapidly, powered by code execution, tools, and the recently introduced agent skills feature. Skills allow users to extend LLM applications with specialized third-party code, knowledge, and instructions. Although this can extend agent capabilities to new domains, it creates an increasingly complex agent supply chain, offering new surfaces for prompt injection attacks. We identify skill-based prompt injection as a significant threat and introduce SkillInject, a benchmark evaluating the susceptibility of widely-used LLM agents to injections through skill files. SkillInject contains 202 injection-task pairs with attacks ranging from obviously malicious injections to subtle, context-dependent attacks hidden in otherwise legitimate instructions. We evaluate frontier LLMs on SkillInject, measuring both security in terms of harmful instruction avoidance and utility in terms of legitimate instruction compliance. Our results show that today's agents are highly vulnerable with up to 80% attack success rate with frontier models, often executing extremely harmful instructions including data exfiltration, destructive action, and ransomware-like behavior. They furthermore suggest that this problem will not be solved through model scaling or simple input filtering, but that robust agent security will require context-aware authorization frameworks. Our benchmark is available at https://www.skill-inject.com/.","authors":["David Schmotz","Luca Beurer-Kellner","Sahar Abdelnabi","Maksym Andriushchenko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.02943v2","updated":"2026-02-23T18:35:44Z","published":"2025-08-04T22:53:36Z","title":"Reliable Non-Leveled Homomorphic Encryption for Web Services","summary":"With the ubiquitous deployment of web services, ensuring data confidentiality has become a challenging imperative. Fully Homomorphic Encryption (FHE) presents a powerful solution for processing encrypted data; however, its widespread adoption is severely constrained by two fundamental bottlenecks: substantial computational overhead and the absence of a built-in automatic error correction mechanism. These limitations render the deployment of FHE in real-world, complex network environments impractical.\n  To address this dual challenge, this work puts forward a new FHE framework that enhances computational efficiency and integrates an automatic error correction capability through new encoding techniques and an algebraic reliability layer. Our system was validated across several web workloads, including encrypted inference on MNIST and CIFAR-10, federated aggregation with non-IID data, and streaming analytics on household power consumption data. Experimental results demonstrate significant performance improvements, particularly with large polynomial modulus degrees such as $N=8192$, while maintaining task accuracy within $0.5\\%$ of the plaintext baseline. Furthermore, our error correction mechanism reduces the service failure rate to below $0.5\\%$ even under harsh, bursty network fault conditions.","authors":["Baigang Chen","Dongfang Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.08227v2","updated":"2026-02-23T18:12:36Z","published":"2025-04-11T03:20:24Z","title":"DaemonSec: Examining the Role of Machine Learning for Daemon Security in Linux Environments","summary":"DaemonSec is an early-stage startup exploring machine learning (ML)-based security for Linux daemons, a critical yet often overlooked attack surface. While daemon security remains underexplored, conventional defenses struggle against adaptive threats and zero-day exploits. To assess the perspectives of IT professionals on ML-driven daemon protection, a systematic interview study based on semi-structured interviews was conducted with 22 professionals from industry and academia. The study evaluates adoption, feasibility, and trust in ML-based security solutions. While participants recognized the potential of ML for real-time anomaly detection, findings reveal skepticism toward full automation, limited security awareness among non-security roles, and concerns about patching delays creating attack windows. This paper presents the methods, key findings, and implications for advancing ML-driven daemon security in industry.","authors":["Sheikh Muhammad Farjad"],"pdf_url":"","comment":"Preprint for industry track"},{"id":"http://arxiv.org/abs/2507.23641v2","updated":"2026-02-23T17:34:49Z","published":"2025-07-31T15:18:52Z","title":"Polynomial Lattices for the BIKE Cryptosystem","summary":"In this paper we introduce a rank $2$ lattice over a polynomial ring arising from the public key of the BIKE cryptosystem. The secret key is a sparse vector in this lattice. We study properties of this lattice and generalize the recovery of weak keys from \"Weak keys for the quasi-cyclic MDPC public key encryption scheme\". In particular, we show that they implicitly solved a shortest vector problem in the lattice we constructed. Rather than finding only a shortest vector, we obtain a reduced basis of the lattice which makes it possible to check for more weak keys.","authors":["Michael Schaller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20064v1","updated":"2026-02-23T17:22:35Z","published":"2026-02-23T17:22:35Z","title":"The LLMbda Calculus: AI Agents, Conversations, and Information Flow","summary":"A conversation with a large language model (LLM) is a sequence of prompts and responses, with each response generated from the preceding conversation. AI agents build such conversations automatically: given an initial human prompt, a planner loop interleaves LLM calls with tool invocations and code execution. This tight coupling creates a new and poorly understood attack surface. A malicious prompt injected into a conversation can compromise later reasoning, trigger dangerous tool calls, or distort final outputs. Despite the centrality of such systems, we currently lack a principled semantic foundation for reasoning about their behaviour and safety. We address this gap by introducing an untyped call-by-value lambda calculus enriched with dynamic information-flow control and a small number of primitives for constructing prompt-response conversations. Our language includes a primitive that invokes an LLM: it serializes a value, sends it to the model as a prompt, and parses the response as a new term. This calculus faithfully represents planner loops and their vulnerabilities, including the mechanisms by which prompt injection alters subsequent computation. The semantics explicitly captures conversations, and so supports reasoning about defenses such as quarantined sub-conversations, isolation of generated code, and information-flow restrictions on what may influence an LLM call. A termination-insensitive noninterference theorem establishes integrity and confidentiality guarantees, demonstrating that a formal calculus can provide rigorous foundations for safe agentic programming.","authors":["Zac Garby","Andrew D. Gordon","David Sands"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20061v1","updated":"2026-02-23T17:17:53Z","published":"2026-02-23T17:17:53Z","title":"Can You Tell It's AI? Human Perception of Synthetic Voices in Vishing Scenarios","summary":"Large Language Models and commercial speech synthesis systems now enable highly realistic AI-generated voice scams (vishing), raising urgent concerns about deception at scale. Yet it remains unclear whether individuals can reliably distinguish AI-generated speech from human-recorded voices in realistic scam contexts and what perceptual strategies underlie their judgments. We conducted a controlled online study in which 22 participants evaluated 16 vishing-style audio clips (8 AI-generated, 8 human-recorded) and classified each as human or AI while reporting confidence. Participants performed poorly: mean accuracy was 37.5%, below chance in a binary classification task. At the stimulus level, misclassification was bidirectional: 75% of AI-generated clips were majority-labeled as human, while 62.5% of human-recorded clips were majority-labeled as AI. Signal Detection Theory analysis revealed near-zero discriminability (d' approx 0), indicating inability to reliably distinguish synthetic from human voices rather than simple response bias. Qualitative analysis of 315 coded excerpts revealed reliance on paralinguistic and emotional heuristics, including pauses, filler words, vocal variability, cadence, and emotional expressiveness. However, these surface-level cues traditionally associated with human authenticity were frequently replicated by AI-generated samples. Misclassifications were often accompanied by moderate to high confidence, suggesting perceptual miscalibration rather than uncertainty. Together, our findings demonstrate that authenticity judgments based on vocal heuristics are unreliable in contemporary vishing scenarios. We discuss implications for security interventions, user education, and AI-mediated deception mitigation.","authors":["Zoha Hayat Bhatti","Bakhtawar Ahtisham","Seemal Tausif","Niklas George","Nida ul Habib Bajwa","Mobin Javed"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06326v2","updated":"2026-02-23T16:56:50Z","published":"2025-09-08T04:17:02Z","title":"AttestLLM: Efficient Attestation Framework for Billion-scale On-device LLMs","summary":"As on-device LLMs(e.g., Apple on-device Intelligence) are widely adopted to reduce network dependency, improve privacy, and enhance responsiveness, verifying the legitimacy of models running on local devices becomes critical. Existing attestation techniques are not suitable for billion-parameter Large Language Models (LLMs), struggling to remain both time- and memory-efficient while addressing emerging threats in the LLM era. In this paper, we present AttestLLM, the first-of-its-kind attestation framework to protect the hardware-level intellectual property (IP) of device vendors by ensuring that only authorized LLMs can execute on target platforms. AttestLLM leverages an algorithm/software/hardware co-design approach to embed robust watermarking signatures onto the activation distributions of LLM building blocks. It also optimizes the attestation protocol within the Trusted Execution Environment (TEE), providing efficient verification without compromising inference throughput. Extensive proof-of-concept evaluations on LLMs from Llama, Qwen, and Phi families for on-device use cases demonstrate AttestLLM's attestation reliability, fidelity, and efficiency. Furthermore, AttestLLM enforces model legitimacy and exhibits resilience against model replacement and forgery attacks.","authors":["Ruisi Zhang","Yifei Zhao","Neusha Javidnia","Mengxin Zheng","Farinaz Koushanfar"],"pdf_url":"","comment":"accept to DAC 2026"},{"id":"http://arxiv.org/abs/2503.16783v3","updated":"2026-02-23T16:38:17Z","published":"2025-03-21T01:39:29Z","title":"CoBRA: A Universal Strategyproof Confirmation Protocol for Quorum-based Proof-of-Stake Blockchains","summary":"The security of many Proof-of-Stake (PoS) payment systems relies on quorum-based State Machine Replication (SMR) protocols. While classical analyses assume purely Byzantine faults, real-world systems must tolerate both arbitrary failures and strategic, profit-driven validators. We therefore study quorum-based SMR under a hybrid model with honest, Byzantine, and rational participants.\n  We first establish the fundamental limitations of traditional consensus mechanisms, proving two impossibility results: (1) in partially synchronous networks, no quorum-based protocol can achieve SMR when rational and Byzantine validators collectively exceed $1/3$ of the participants; and (2) even under synchronous network assumptions, SMR remains unattainable if this coalition comprises more than $2/3$ of the validator set.\n  Assuming a synchrony bound $Δ$, we show how to extend any quorum-based SMR protocol to tolerate up to $1/3$ Byzantine and $1/3$ rational validators by modifying only its finalization rule. Our approach enforces a necessary bound on the total transaction volume finalized within any time window $Δ$ and introduces the \\emph{strongest chain rule}, which enables efficient finalization of transactions when a supermajority of honest participants provably supports execution. Empirical analysis of Ethereum and Cosmos demonstrates validator participation exceeding the required $5/6$ threshold in over $99%$ of blocks, supporting the practicality of our design.\n  Finally, we present a recovery mechanism that restores safety and liveness after consistency violations, even with up to $5/9$ Byzantine stake and $1/9$ rational stake, guaranteeing full reimbursement of provable client losses.","authors":["Zeta Avarikioti","Eleftherios Kokoris Kogias","Ray Neiheiser","Christos Stefo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.01428v2","updated":"2026-02-23T15:55:07Z","published":"2026-02-01T20:30:59Z","title":"Improving the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models","summary":"Watermarking is a principled approach for tracing the provenance of large language model (LLM) outputs, but its deployment in practice is hindered by inference inefficiency. Speculative sampling accelerates inference, with efficiency improving as the acceptance rate between draft and target models increases. Yet recent work reveals a fundamental trade-off: higher watermark strength reduces acceptance, preventing their simultaneous achievement. We revisit this trade-off and show it is not absolute. We introduce a quantitative measure of watermark strength that governs statistical detectability and is maximized when tokens are deterministic functions of pseudorandom numbers. Using this measure, we fully characterize the trade-off as a constrained optimization problem and derive explicit Pareto curves for two existing watermarking schemes. Finally, we introduce a principled mechanism that injects pseudorandomness into draft-token acceptance, ensuring maximal watermark strength while maintaining speculative sampling efficiency. Experiments further show that this approach improves detectability without sacrificing efficiency. Our findings uncover a principle that unites speculative sampling and watermarking, paving the way for their efficient and practical deployment.","authors":["Weiqing He","Xiang Li","Li Shen","Weijie Su","Qi Long"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.19973v1","updated":"2026-02-23T15:37:18Z","published":"2026-02-23T15:37:18Z","title":"Misquoted No More: Securely Extracting F* Programs with IO","summary":"Shallow embeddings that use monads to represent effects are popular in proof-oriented languages because they are convenient for formal verification. Once shallowly embedded programs are verified, they are often extracted to mainstream languages like OCaml or C and linked into larger codebases. The extraction process is not fully verified because it often involves quotation -- turning the shallowly embedded program into a deeply embedded one -- and verifying quotation remains a major open challenge. Instead, some prior work obtains formal correctness guarantees using translation validation to certify individual extraction results. We build on this idea, but limit the use of translation validation to a first extraction step that we call relational quotation and that uses a metaprogram to construct a typing derivation for the given shallowly embedded program. This metaprogram is simple, since the typing derivation follows the structure of the original program. Once we validate, syntactically, that the typing derivation is valid for the original program, we pass it to a verified syntax-generation function that produces code guaranteed to be semantically related to the original program.\n  We apply this general idea to build SEIO*, a framework for extracting shallowly embedded F* programs with IO to a deeply embedded lambda-calculus while providing formal secure compilation guarantees. Using two cross-language logical relations, we devise a machine-checked proof in F* that SEIO* guarantees Robust Relational Hyperproperty Preservation (RrHP), a very strong secure compilation criterion that implies full abstraction as well as preservation of trace properties and hyperproperties against arbitrary adversarial contexts. This goes beyond the state of the art in verified and certifying extraction, which so far has focused on correctness rather than security.","authors":["Cezar-Constantin Andrici","Abigail Pribisova","Danel Ahman","Catalin Hritcu","Exequiel Rivas","Théo Winterhalter"],"pdf_url":"","comment":"Submitted to ICFP'26"},{"id":"http://arxiv.org/abs/2511.22416v2","updated":"2026-02-23T15:04:43Z","published":"2025-11-27T12:51:10Z","title":"QuLore: An Adaptive Security Framework to Extend Quantum-Safe Communications to Real-World Networks","summary":"The advent of quantum computing threatens classical cryptographic mechanisms, demanding new strategies for securing communication networks. Since real-world networks cannot be fully Quantum Key Distribution (QKD)-enabled due to infrastructure constraints, practical security solutions must support hybrid operation. This paper presents an adaptive security framework that enables quantum-safe communications across real-world heterogeneous networks by combining QKD and Post-Quantum Cryptography (PQC). Building upon a hierarchical key management architecture with Virtual Key Management Systems (vKMS) and a centralized Quantum Security Controller (QuSeC), the framework dynamically assigns security levels based on node capabilities. By transitioning between pure QKD, hybrid, and PQC modes, it ensures end-to-end quantum-safe protection regardless of the underlying node capabilities. The framework has been implemented and validated on a Kubernetes-based containerized testbed, demonstrating robust operation and performance across all scenarios. Results highlight its potential to support the gradual integration of quantum-safe technologies into existing infrastructures, paving the way toward fully quantum-safe communication networks.","authors":["Ane Sanz","Eire Salegi","Asier Atutxa","David Franco","Jasone Astorga","Eduardo Jacob"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19918v1","updated":"2026-02-23T14:58:08Z","published":"2026-02-23T14:58:08Z","title":"RobPI: Robust Private Inference against Malicious Client","summary":"The increased deployment of machine learning inference in various applications has sparked privacy concerns. In response, private inference (PI) protocols have been created to allow parties to perform inference without revealing their sensitive data. Despite recent advances in the efficiency of PI, most current methods assume a semi-honest threat model where the data owner is honest and adheres to the protocol. However, in reality, data owners can have different motivations and act in unpredictable ways, making this assumption unrealistic. To demonstrate how a malicious client can compromise the semi-honest model, we first designed an inference manipulation attack against a range of state-of-the-art private inference protocols. This attack allows a malicious client to modify the model output with 3x to 8x fewer queries than current black-box attacks. Motivated by the attacks, we proposed and implemented RobPI, a robust and resilient private inference protocol that withstands malicious clients. RobPI integrates a distinctive cryptographic protocol that bolsters security by weaving encryption-compatible noise into the logits and features of private inference, thereby efficiently warding off malicious-client attacks. Our extensive experiments on various neural networks and datasets show that RobPI achieves ~91.9% attack success rate reduction and increases more than 10x the number of queries required by malicious-client attacks.","authors":["Jiaqi Xue","Mengxin Zheng","Qian Lou"],"pdf_url":"","comment":"Accepted by SaTML 2026"},{"id":"http://arxiv.org/abs/2602.19844v1","updated":"2026-02-23T13:48:36Z","published":"2026-02-23T13:48:36Z","title":"LLM-enabled Applications Require System-Level Threat Monitoring","summary":"LLM-enabled applications are rapidly reshaping the software ecosystem by using large language models as core reasoning components for complex task execution. This paradigm shift, however, introduces fundamentally new reliability challenges and significantly expands the security attack surface, due to the non-deterministic, learning-driven, and difficult-to-verify nature of LLM behavior. In light of these emerging and unavoidable safety challenges, we argue that such risks should be treated as expected operational conditions rather than exceptional events, necessitating a dedicated incident-response perspective. Consequently, the primary barrier to trustworthy deployment is not further improving model capability but establishing system-level threat monitoring mechanisms that can detect and contextualize security-relevant anomalies after deployment -- an aspect largely underexplored beyond testing or guardrail-based defenses. Accordingly, this position paper advocates systematic and comprehensive monitoring of security threats in LLM-enabled applications as a prerequisite for reliable operation and a foundation for dedicated incident-response frameworks.","authors":["Yedi Zhang","Haoyu Wang","Xianglin Yang","Jin Song Dong","Jun Sun"],"pdf_url":"","comment":"26 pages"},{"id":"http://arxiv.org/abs/2602.19831v1","updated":"2026-02-23T13:30:04Z","published":"2026-02-23T13:30:04Z","title":"An Explainable Memory Forensics Approach for Malware Analysis","summary":"Memory forensics is an effective methodology for analyzing living-off-the-land malware, including threats that employ evasion, obfuscation, anti-analysis, and steganographic techniques. By capturing volatile system state, memory analysis enables the recovery of transient artifacts such as decrypted payloads, executed commands, credentials, and cryptographic keys that are often inaccessible through static or traditional dynamic analysis. While several automated models have been proposed for malware detection from memory, their outputs typically lack interpretability, and memory analysis still relies heavily on expert-driven inspection of complex tool outputs, such as those produced by Volatility. In this paper, we propose an explainable, AI-assisted memory forensics approach that leverages general-purpose large language models (LLMs) to interpret memory analysis outputs in a human-readable form and to automatically extract meaningful Indicators of Compromise (IoCs), in some circumstances detecting more IoCs than current state-of-the-art tools. We apply the proposed methodology to both Windows and Android malware, comparing full RAM acquisition with target-process memory dumping and highlighting their complementary forensic value. Furthermore, we demonstrate how LLMs can support both expert and non-expert analysts by explaining analysis results, correlating artifacts, and justifying malware classifications. Finally, we show that a human-in-the-loop workflow, assisted by LLMs during kernel-assisted setup and analysis, improves reproducibility and reduces operational complexity, thereby reinforcing the practical applicability of AI-driven memory forensics for modern malware investigations.","authors":["Silvia Lucia Sanna","Davide Maiorca","Giorgio Giacinto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19819v1","updated":"2026-02-23T13:20:24Z","published":"2026-02-23T13:20:24Z","title":"Quantum approaches to learning parity with noise","summary":"The learning parity with noise (LPN) problem is a well-established computational challenge whose difficulty is critical to the security of several post-quantum cryptographic primitives such as HQC and Classic McEliece. Classically, the best-known attacks involve information set decoding methods which are exponential in complexity for parameterisations of interest. In this paper we investigate whether quantum methods might offer alternative approaches. The line of inquiry is inspired by Regev's relating of certain lattice problems to the hidden dihedral subgroup problem. We use neighbourhoods of binary fields to produce a function close to fulfilling Simon's promise with difference equal to the secret parity vector. Although unlikely to recover the secret parity vector directly, running Simon's algorithm essentially produces new LPN samples. This gives the hope that we might be able to produce enough new samples to ignore one or more variables and iteratively reduce the problem.\n  We make no claim that these methods will necessarily be competitive with existing approaches, merely that they warrant deeper investigation.","authors":["Daniel Shiu"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2602.19818v1","updated":"2026-02-23T13:19:43Z","published":"2026-02-23T13:19:43Z","title":"SafePickle: Robust and Generic ML Detection of Malicious Pickle-based ML Models","summary":"Model repositories such as Hugging Face increasingly distribute machine learning artifacts serialized with Python's pickle format, exposing users to remote code execution (RCE) risks during model loading. Recent defenses, such as PickleBall, rely on per-library policy synthesis that requires complex system setups and verified benign models, which limits scalability and generalization. In this work, we propose a lightweight, machine-learning-based scanner that detects malicious Pickle-based files without policy generation or code instrumentation. Our approach statically extracts structural and semantic features from Pickle bytecode and applies supervised and unsupervised models to classify files as benign or malicious. We construct and release a labeled dataset of 727 Pickle-based files from Hugging Face and evaluate our models on four datasets: our own, PickleBall (out-of-distribution), Hide-and-Seek (9 advanced evasive malicious models), and synthetic joblib files. Our method achieves 90.01% F1-score compared with 7.23%-62.75% achieved by the SOTA scanners (Modelscan, Fickling, ClamAV, VirusTotal) on our dataset. Furthermore, on the PickleBall data (OOD), it achieves 81.22% F1-score compared with 76.09% achieved by the PickleBall method, while remaining fully library-agnostic. Finally, we show that our method is the only one to correctly parse and classify 9/9 evasive Hide-and-Seek malicious models specially crafted to evade scanners. This demonstrates that data-driven detection can effectively and generically mitigate Pickle-based model file attacks.","authors":["Hillel Ohayon","Daniel Gilkarov","Ran Dubin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.02780v3","updated":"2026-02-23T13:17:25Z","published":"2025-11-04T18:03:12Z","title":"PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts","summary":"Smart contracts operate in a highly adversarial environment, where vulnerabilities can lead to substantial financial losses. Thus, smart contracts are subject to security audits. In auditing, proof-of-concept (PoC) exploits play a critical role by demonstrating to the stakeholders that the reported vulnerabilities are genuine, reproducible, and actionable. However, manually creating PoCs is time-consuming, error-prone, and often constrained by tight audit schedules. We introduce PoCo, an agentic framework that automatically generates executable PoC exploits from natural-language vulnerability descriptions written by auditors. PoCo autonomously generates PoC exploits in an agentic manner by interacting with a set of codeexecution tools in a Reason-Act-Observe loop. It produces fully executable exploits compatible with the Foundry testing framework, ready for integration into audit reports and other security tools. We evaluate PoCo on a dataset of 23 real-world vulnerability reports. PoCo consistently outperforms the Zero-shot and Workflow baselines, generating well-formed and logically correct PoCs. Our results demonstrate that agentic frameworks can significantly reduce the effort required for high-quality PoCs in smart contract audits. Our contribution provides actionable knowledge for the smart contract security community.","authors":["Vivi Andersson","Sofia Bobadilla","Harald Hobbelhagen","Martin Monperrus"],"pdf_url":"","comment":"Under review"},{"id":"http://arxiv.org/abs/2602.19777v1","updated":"2026-02-23T12:32:05Z","published":"2026-02-23T12:32:05Z","title":"AegisSat: Securing AI-Enabled SoC FPGA Satellite Platforms","summary":"The increasing adoption of System-on-Chip Field-Programmable Gate Arrays (SoC FPGAs) in AI-enabled satellite systems, valued for their reconfigurability and in-orbit update capabilities, introduces significant security challenges. Compromised updates can lead to performance degradation, service disruptions, or adversarial manipulation of mission outcomes. To address these risks, this paper proposes a comprehensive security framework, AegisSat. It ensures the integrity and resilience of satellite platforms by (i) integrating cryptographically-based secure boot mechanisms to establish a trusted computing base; (ii) enforcing strict runtime resource isolation; (iii) employing authenticated procedures for in-orbit reconfiguration and AI model updates to prevent unauthorized modifications; and (iv) providing robust rollback capabilities to recover from boot and update failures and maintain system stability. To further support our claims, we conducted experiments demonstrating the integration of these mechanisms on contemporary SoC FPGA devices. This defense-in-depth framework is crucial for space applications, where physical access is impossible and systems must operate reliably over extended periods, thereby enhancing the trustworthiness of SoC FPGA-based satellite systems and enabling secure and resilient AI operations in orbit.","authors":["Huimin Li","Vusal Novruzov","Nikhilesh Singh","Lichao Wu","Mohamadreza Rostami","Ahmad-Reza Sadeghi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19606v1","updated":"2026-02-23T08:47:48Z","published":"2026-02-23T08:47:48Z","title":"Predicting known Vulnerabilities from Attack News: A Transformer-Based Approach","summary":"Identifying the vulnerabilities exploited during cyberattacks is essential for enabling timely responses and effective mitigation in software security. This paper directly examines the process of predicting software vulnerabilities, specifically Common Vulnerabilities and Exposures (CVEs), from unstructured descriptions of attacks reported in cybersecurity news articles. We propose a semantic similarity-based approach utilizing the multi-qa-mpnet-base-dot-v1 (MPNet) sentence transformer model to generate a ranked list of the most likely CVEs corresponding to each news report. To assess the accuracy of the predicted vulnerabilities, we implement four complementary validation methods: filtering predictions based on similarity thresholds, conducting manual validation, performing semantic comparisons with the first vulnerability explicitly mentioned in each report, and comparing against all CVEs referenced within the report. Experimental results, drawn from a dataset of 100 SecurityWeek news articles, demonstrate that the model attains a precision of 81 percent when employing threshold-based filtering. Manual evaluations report that 70 percent of the predictions are relevant, while comparisons with the initially mentioned CVEs reveal agreement rates of 80 percent with the first listed vulnerability and 78 percent across all referenced CVEs. In 57 percent of the news reports analyzed, at least one predicted vulnerability precisely matched a CVE-ID mentioned in the article. These findings underscore the model's potential to facilitate automated vulnerability identification from real-world cyberattack news reports.","authors":["Refat Othman","Diaeddin Rimawi","Bruno Rossi","Barbara Russo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.09548v2","updated":"2026-02-23T08:46:46Z","published":"2026-02-10T08:57:49Z","title":"ReSIM: Re-ranking Binary Similarity Embeddings to Improve Function Search Performance","summary":"Binary Function Similarity (BFS), the problem of determining whether two binary functions originate from the same source code, has been extensively studied in recent research across security, software engineering, and machine learning communities. This interest arises from its central role in developing vulnerability detection systems, copyright infringement analysis, and malware phylogeny tools. Nearly all binary function similarity systems embed assembly functions into real-valued vectors, where similar functions map to points that lie close to each other in the metric space. These embeddings enable function search: a query function is embedded and compared against a database of candidate embeddings to retrieve the most similar matches.\n  Despite their effectiveness, such systems rely on bi-encoder architectures that embed functions independently, limiting their ability to capture cross-function relationships and similarities. To address this limitation, we introduce ReSIM, a novel and enhanced function search system that complements embedding-based search with a neural re-ranker. Unlike traditional embedding models, our reranking module jointly processes query-candidate pairs to compute ranking scores based on their mutual representation, allowing for more accurate similarity assessment. By re-ranking the top results from embedding-based retrieval, ReSIM leverages fine-grained relation information that bi-encoders cannot capture.\n  We evaluate ReSIM across seven embedding models on two benchmark datasets, demonstrating consistent improvements in search effectiveness, with average gains of 21.7% in terms of nDCG and 27.8% in terms of Recall.","authors":["Gianluca Capozzi","Anna Paola Giancaspro","Fabio Petroni","Leonardo Querzoni","Giuseppe Antonio Di Luna"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19604v1","updated":"2026-02-23T08:45:47Z","published":"2026-02-23T08:45:47Z","title":"Efficient Multi-Party Secure Comparison over Different Domains with Preprocessing Assistance","summary":"Secure comparison is a fundamental primitive in multi-party computation, supporting privacy-preserving applications such as machine learning and data analytics. A critical performance bottleneck in comparison protocols is their preprocessing phase, primarily due to the high cost of generating the necessary correlated randomness. Recent frameworks introduce a passive, non-colluding dealer to accelerate preprocessing. However, two key issues still remain. First, existing dealer-assisted approaches treat the dealer as a drop-in replacement for conventional preprocessing without redesigning the comparison protocol to optimize the online phase. Second, most protocols are specialized for particular algebraic domains, adversary models, or party configurations, lacking broad generality. In this work, we present the first dealer-assisted $n$-party LTBits (Less-Than-Bits) and MSB (Most Significant Bit) extraction protocols over both $\\mathbb{F}_p$ and $\\mathbb{Z}_{2^k}$, achieving perfect security at the protocol level. By fully exploiting the dealer's capability to generate rich correlated randomness, our $\\mathbb{F}_p$ construction achieves constant-round online complexity and our $\\mathbb{Z}_{2^k}$ construction achieves $O(\\log_n k)$ rounds with tunable branching factor. All protocols are formulated as black-box constructions via an extended ABB model, ensuring portability across MPC backends and adversary models. Experimental results demonstrate $1.79\\times$ to $19.4\\times$ speedups over state-of-the-art MPC frameworks, highlighting the practicality of our protocols for comparison-intensive MPC applications.","authors":["Kaiwen Wang","Xiaolin Chang","Yuehan Dong","Ruichen Zhang"],"pdf_url":"","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.02099v3","updated":"2026-02-23T07:20:10Z","published":"2024-10-02T23:39:19Z","title":"A Watermark for Black-Box Language Models","summary":"Watermarking has recently emerged as an effective strategy for detecting the outputs of large language models (LLMs). Most existing schemes require white-box access to the model's next-token probability distribution, which is typically not accessible to downstream users of an LLM API. In this work, we propose a principled watermarking scheme that requires only the ability to sample sequences from the LLM (i.e. black-box access), boasts a distortion-free property, and can be chained or nested using multiple secret keys. We provide performance guarantees, demonstrate how it can be leveraged when white-box access is available, and show when it can outperform existing white-box schemes via comprehensive experiments.","authors":["Dara Bahri","John Wieting"],"pdf_url":"","comment":"Published at TMLR 2026"},{"id":"http://arxiv.org/abs/2602.19555v1","updated":"2026-02-23T06:57:57Z","published":"2026-02-23T06:57:57Z","title":"Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains","summary":"Agentic systems built on large language models (LLMs) extend beyond text generation to autonomously retrieve information and invoke tools. This runtime execution model shifts the attack surface from build-time artifacts to inference-time dependencies, exposing agents to manipulation through untrusted data and probabilistic capability resolution. While prior work has focused on model-level vulnerabilities, security risks emerging from cyclic and interdependent runtime behavior remain fragmented. We systematize these risks within a unified runtime framework, categorizing threats into data supply chain attacks (transient context injection and persistent memory poisoning) and tool supply chain attacks (discovery, implementation, and invocation). We further identify the Viral Agent Loop, in which agents act as vectors for self-propagating generative worms without exploiting code-level flaws. Finally, we advocate a Zero-Trust Runtime Architecture that treats context as untrusted control flow and constrains tool execution through cryptographic provenance rather than semantic inference.","authors":["Xiaochong Jiang","Shiqi Yang","Wenting Yang","Yichen Liu","Cheng Ji"],"pdf_url":"","comment":"9 Pages, 3 figures"},{"id":"http://arxiv.org/abs/2510.10987v3","updated":"2026-02-23T06:55:02Z","published":"2025-10-13T03:53:40Z","title":"DITTO: A Spoofing Attack Framework on Watermarked LLMs via Knowledge Distillation","summary":"The promise of LLM watermarking rests on a core assumption that a specific watermark proves authorship by a specific model. We demonstrate that this assumption is dangerously flawed. We introduce the threat of watermark spoofing, a sophisticated attack that allows a malicious model to generate text containing the authentic-looking watermark of a trusted, victim model. This enables the seamless misattribution of harmful content, such as disinformation, to reputable sources. The key to our attack is repurposing watermark radioactivity, the unintended inheritance of data patterns during fine-tuning, from a discoverable trait into an attack vector. By distilling knowledge from a watermarked teacher model, our framework allows an attacker to steal and replicate the watermarking signal of the victim model. This work reveals a critical security gap in text authorship verification and calls for a paradigm shift towards technologies capable of distinguishing authentic watermarks from expertly imitated ones. Our code is available at https://github.com/hsannn/ditto.git.","authors":["Hyeseon An","Shinwoo Park","Suyeon Woo","Yo-Sub Han"],"pdf_url":"","comment":"Accepted to EACL 2026 (Oral)"},{"id":"http://arxiv.org/abs/2602.19550v1","updated":"2026-02-23T06:49:32Z","published":"2026-02-23T06:49:32Z","title":"Hardware-Friendly Randomization: Enabling Random-Access and Minimal Wiring in FHE Accelerators with Low Total Cost","summary":"The Ring-Learning With Errors (RLWE) problem forms the backbone of highly efficient Fully Homomorphic Encryption (FHE) schemes. A significant component of the RLWE public key and ciphertext of the form $(b,a)$ is the uniformly random polynomial $a \\in R_q$ . While essential for security, the communication overhead of transmitting $a$ from client to server, and inputting it into a hardware accelerator, can be substantial, especially for FHE accelerators aiming at high acceleration factors. A known technique in reducing this overhead generates $a$ from a small seed on the client side via a deterministic process, transmits only the seed, and generates $a$ on-the-fly within the accelerator. Challenges in the hardware implementation of an accelerator include wiring (density and power), compute area, compute power as well as flexibility in scheduling of on-the-fly generation instructions. This extended abstract proposes a concrete scheme and parameters wherein these practical challenges are addressed. We detail the benefits of our approach, which maintains the reduction in communication latency and memory footprint, while allowing parallel generation of uniformly distributed samples, relaxed wiring requirements, unrestricted randomaccess to RNS limbs, and results in an extremely low overhead on the client side (i.e. less than 3%) during the key generation process. The proposed scheme eliminates the need for thick metal layers for randomness distribution and prevents the power consumption of the PRNG subsystem from scaling prohibitively with the acceleration factor, potentially saving tens of Watts per accelerator chip in high-throughput configurations.","authors":["Ilan Rosenfeld","Noam Kleinburd","Hillel Chapman","Dror Reuven"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19547v1","updated":"2026-02-23T06:41:41Z","published":"2026-02-23T06:41:41Z","title":"CIBER: A Comprehensive Benchmark for Security Evaluation of Code Interpreter Agents","summary":"LLM-based code interpreter agents are increasingly deployed in critical workflows, yet their robustness against risks introduced by their code execution capabilities remains underexplored. Existing benchmarks are limited to static datasets or simulated environments, failing to capture the security risks arising from dynamic code execution, tool interactions, and multi-turn context. To bridge this gap, we introduce CIBER, an automated benchmark that combines dynamic attack generation, isolated secure sandboxing, and state-aware evaluation to systematically assess the vulnerability of code interpreter agents against four major types of adversarial attacks: Direct/Indirect Prompt Injection, Memory Poisoning, and Prompt-based Backdoor.\n  We evaluate six foundation models across two representative code interpreter agents (OpenInterpreter and OpenCodeInterpreter), incorporating a controlled study of identical models. Our results reveal that Interpreter Architecture and Model Alignment Set the Security Baseline. Structural integration enables aligned specialized models to outperform generic SOTA models. Conversely, high intelligence paradoxically increases susceptibility to complex adversarial prompts due to stronger instruction adherence. Furthermore, we identify a \"Natural Language Disguise\" Phenomenon, where natural language functions as a significantly more effective input modality than explicit code snippets (+14.1% ASR), thereby bypassing syntax-based defenses. Finally, we expose an alarming Security Polarization, where agents exhibit robust defenses against explicit threats yet fail catastrophically against implicit semantic hazards, highlighting a fundamental blind spot in current pattern-matching protection approaches.","authors":["Lei Ba","Qinbin Li","Songze Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19539v1","updated":"2026-02-23T06:13:52Z","published":"2026-02-23T06:13:52Z","title":"Can a Teenager Fool an AI? Evaluating Low-Cost Cosmetic Attacks on Age Estimation Systems","summary":"Age estimation systems are increasingly deployed as gatekeepers for age-restricted online content, yet their robustness to cosmetic modifications has not been systematically evaluated. We investigate whether simple, household-accessible cosmetic changes, including beards, grey hair, makeup, and simulated wrinkles, can cause AI age estimators to classify minors as adults. To study this threat at scale without ethical concerns, we simulate these physical attacks on 329 facial images of individuals aged 10 to 21 using a VLM image editor (Gemini 2.5 Flash Image). We then evaluate eight models from our prior benchmark: five specialized architectures (MiVOLO, Custom-Best, Herosan, MiViaLab, DEX) and three vision-language models (Gemini 3 Flash, Gemini 2.5 Flash, GPT-5-Nano). We introduce the Attack Conversion Rate (ACR), defined as the fraction of images predicted as minor at baseline that flip to adult after attack, a population-agnostic metric that does not depend on the ratio of minors to adults in the test set. Our results reveal that a synthetic beard alone achieves 28 to 69 percent ACR across all eight models; combining all four attacks shifts predicted age by +7.7 years on average across all 329 subjects and reaches up to 83 percent ACR; and vision-language models exhibit lower ACR (59 to 71 percent) than specialized models (63 to 83 percent) under the full attack, although the ACR ranges overlap and the difference is not statistically tested. These findings highlight a critical vulnerability in deployed age-verification pipelines and call for adversarial robustness evaluation as a mandatory criterion for model selection.","authors":["Xingyu Shen","Tommy Duong","Xiaodong An","Zengqi Zhao","Zebang Hu","Haoyu Hu","Ziyou Wang","Finn Guo","Simiao Ren"],"pdf_url":"","comment":"13 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.19514v1","updated":"2026-02-23T05:08:27Z","published":"2026-02-23T05:08:27Z","title":"Security Risks of AI Agents Hiring Humans: An Empirical Marketplace Study","summary":"Autonomous AI agents can now programmatically hire human workers through marketplaces using REST APIs and Model Context Protocol (MCP) integrations. This creates an attack surface analogous to CAPTCHA-solving services but with physical-world reach. We present an empirical measurement study of this threat, analyzing 303 bounties from RENTAHUMAN.AI, a marketplace where agents post tasks and manage escrow payments. We find that 99 bounties (32.7%), originate from programmatic channels (API keys or MCP). Using a dual-coder methodology (\\k{appa} = 0.86 ), we identify six active abuse classes: credential fraud, identity impersonation, automated reconnaissance, social media manipulation, authentication circumvention, and referral fraud, all purchasable for a median of $25 per worker. A retrospective evaluation of seven content-screening rules flags 52 bounties (17.2%) with a single false positive, demonstrating that while basic defenses are feasible, they are currently absent.","authors":["Pulak Mehta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19490v1","updated":"2026-02-23T04:20:19Z","published":"2026-02-23T04:20:19Z","title":"FuzzySQL: Uncovering Hidden Vulnerabilities in DBMS Special Features with LLM-Driven Fuzzing","summary":"Traditional database fuzzing techniques primarily focus on syntactic correctness and general SQL structures, leaving critical yet obscure DBMS features, such as system-level modes (e.g., GTID), programmatic constructs (e.g., PROCEDURE), advanced process commands (e.g., KILL), largely underexplored. Although rarely triggered by typical inputs, these features can lead to severe crashes or security issues when executed under edge-case conditions. In this paper, we present FuzzySQL, a novel LLM-powered adaptive fuzzing framework designed to uncover subtle vulnerabilities in DBMS special features. FuzzySQL combines grammar-guided SQL generation with logic-shifting progressive mutation, a novel technique that explores alternative control paths by negating conditions and restructuring execution logic, synthesizing structurally and semantically diverse test cases. To further ensure deeper execution coverage of the back end, FuzzySQL employs a hybrid error repair pipeline that unifies rule-based patching with LLM-driven semantic repair, enabling automatic correction of syntactic and context-sensitive failures. We evaluate FuzzySQL across multiple DBMSs, including MySQL, MariaDB, SQLite, PostgreSQL and Clickhouse, uncovering 37 vulnerabilities, 7 of which are tied to under-tested DBMS special features. As of this writing, 29 cases have been confirmed with 9 assigned CVE identifiers, 14 already fixed by vendors, and additional vulnerabilities scheduled to be patched in upcoming releases. Our results highlight the limitations of conventional fuzzers in semantic feature coverage and demonstrate the potential of LLM-based fuzzing to discover deeply hidden bugs in complex database systems.","authors":["Yongxin Chen","Zhiyuan Jiang","Chao Zhang","Haoran Xu","Shenglin Xu","Jianping Tang","Zheming Li","Peidai Xie","Yongjun Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.01317v5","updated":"2026-02-23T03:35:50Z","published":"2026-02-01T16:17:33Z","title":"TxRay: Agentic Postmortem of Live Blockchain Attacks","summary":"Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to reported exploits. Many exploits arise from permissionless opportunities that any participant can trigger using only public state and standard interfaces, which we call Anyone-Can-Take (ACT) opportunities. Despite on-chain transparency, postmortem analysis remains slow and manual: investigations start from limited evidence, sometimes only a single transaction hash, and must reconstruct the exploit lifecycle by recovering related transactions, contract code, and state dependencies.\n  We present TxRay, a Large Language Model (LLM) agentic postmortem system that uses tool calls to reconstruct live ACT attacks from limited evidence. Starting from one or more seed transactions, TxRay recovers the exploit lifecycle, derives an evidence-backed root cause, and generates a runnable, self-contained Proof of Concept (PoC) that deterministically reproduces the incident. TxRay self-checks postmortems by encoding incident-specific semantic oracles as executable assertions.\n  To evaluate PoC correctness and quality, we develop PoCEvaluator, an independent agentic execution-and-review evaluator. On 114 incidents from DeFiHackLabs, TxRay produces an expert-aligned root cause and an executable PoC for 105 incidents, achieving 92.11% end-to-end reproduction. Under PoCEvaluator, 98.1% of TxRay PoCs avoid hard-coding attacker addresses, a +22.9pp lift over DeFiHackLabs. In a live deployment, TxRay delivers validated root causes in 40 minutes and PoCs in 59 minutes at median latency. TxRay's oracle-validated PoCs enable attack imitation, improving coverage by 15.6% and 65.5% over STING and APE.","authors":["Ziyue Wang","Jiangshan Yu","Kaihua Qin","Dawn Song","Arthur Gervais","Liyi Zhou"],"pdf_url":"","comment":"24 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.19450v1","updated":"2026-02-23T02:47:05Z","published":"2026-02-23T02:47:05Z","title":"Red-Teaming Claude Opus and ChatGPT-based Security Advisors for Trusted Execution Environments","summary":"Trusted Execution Environments (TEEs) (e.g., Intel SGX and ArmTrustZone) aim to protect sensitive computation from a compromised operating system, yet real deployments remain vulnerable to microarchitectural leakage, side-channel attacks, and fault injection. In parallel, security teams increasingly rely on Large Language Model (LLM) assistants as security advisors for TEE architecture review, mitigation planning, and vulnerability triage. This creates a socio-technical risk surface: assistants may hallucinate TEE mechanisms, overclaim guarantees (e.g., what attestation does and does not establish), or behave unsafely under adversarial prompting.\n  We present a red-teaming study of two prevalently deployed LLM assistants in the role of TEE security advisors: ChatGPT-5.2 and Claude Opus-4.6, focusing on the inherent limitations and transferability of prompt-induced failures across LLMs. We introduce TEE-RedBench, a TEE-grounded evaluation methodology comprising (i) a TEE-specific threat model for LLM-mediated security work, (ii) a structured prompt suite spanning SGX and TrustZone architecture, attestation and key management, threat modeling, and non-operational mitigation guidance, along with policy-bound misuse probes, and (iii) an annotation rubric that jointly measures technical correctness, groundedness, uncertainty calibration, refusal quality, and safe helpfulness. We find that some failures are not purely idiosyncratic, transferring up to 12.02% across LLM assistants, and we connect these outcomes to secure architecture by outlining an \"LLM-in-the-loop\" evaluation pipeline: policy gating, retrieval grounding, structured templates, and lightweight verification checks that, when combined, reduce failures by 80.62%.","authors":["Kunal Mukherjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19410v1","updated":"2026-02-23T01:06:16Z","published":"2026-02-23T01:06:16Z","title":"BioEnvSense: A Human-Centred Security Framework for Preventing Behaviour-Driven Cyber Incidents","summary":"Modern organizations increasingly face cybersecurity incidents driven by human behaviour rather than technical failures. To address this, we propose a conceptual security framework that integrates a hybrid Convolutional Neural Network-Long Short-Term Memory (CNN-LSTM) model to analyze biometric and environmental data for context-aware security decisions. The CNN extracts spatial patterns from sensor data, while the LSTM captures temporal dynamics associated with human error susceptibility. The model achieves 84% accuracy, demonstrating its ability to reliably detect conditions that lead to elevated human-centred cyber risk. By enabling continuous monitoring and adaptive safeguards, the framework supports proactive interventions that reduce the likelihood of human-driven cyber incidents","authors":["Duy Anh Ta","Farnaz Farid","Farhad Ahamed","Ala Al-Areqi","Robert Beutel","Tamara Watson","Alana Maurushat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.11963v3","updated":"2026-02-23T21:56:58Z","published":"2025-05-17T11:31:24Z","title":"MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models","summary":"Hardware security verification is a challenging and time-consuming task. Design engineers may use formal verification, linting, and functional simulation tests, coupled with analysis and a deep understanding of the hardware design being inspected. Large Language Models (LLMs) have been used to assist during this task, either directly or in conjunction with existing tools. We improve the state of the art by proposing MARVEL, a multi-agent LLM framework for a unified approach to decision-making, tool use, and reasoning. MARVEL mimics the cognitive process of a designer looking for security vulnerabilities in RTL code. It consists of a supervisor agent that devises the security policy of the system-on-chips (SoCs) using its security documentation. It delegates tasks to validate the security policy to individual executor agents. Each executor agent carries out its assigned task using a particular strategy. Each executor agent may use one or more tools to identify potential security bugs in the design and send the results back to the supervisor agent for further analysis and confirmation. MARVEL includes executor agents that leverage formal tools, linters, simulation tests, LLM-based detection schemes, and static analysis-based checks. We test our approach on a known buggy SoC based on OpenTitan from the Hack@DATE competition. We find that of the 51 issues reported by MARVEL, 19 are valid security vulnerabilities, 14 are concrete warnings, and 18 are hallucinated reports.","authors":["Luca Collini","Baleegh Ahmad","Joey Ah-kiow","Ramesh Karri"],"pdf_url":"","comment":"Submitted for Peer Review"},{"id":"http://arxiv.org/abs/2602.16729v2","updated":"2026-02-23T21:46:20Z","published":"2026-02-17T18:29:22Z","title":"Intent Laundering: AI Safety Datasets Are Not What They Seem","summary":"We systematically evaluate the quality of widely used AI safety datasets from two perspectives: in isolation and in practice. In isolation, we examine how well these datasets reflect real-world adversarial attacks based on three key properties: being driven by ulterior intent, well-crafted, and out-of-distribution. We find that these datasets overrely on \"triggering cues\": words or phrases with overt negative/sensitive connotations that are intended to trigger safety mechanisms explicitly, which is unrealistic compared to real-world attacks. In practice, we evaluate whether these datasets genuinely measure safety risks or merely provoke refusals through triggering cues. To explore this, we introduce \"intent laundering\": a procedure that abstracts away triggering cues from adversarial attacks (data points) while strictly preserving their malicious intent and all relevant details. Our results indicate that current AI safety datasets fail to faithfully represent real-world adversarial behavior due to their overreliance on triggering cues. Once these cues are removed, all previously evaluated \"reasonably safe\" models become unsafe, including Gemini 3 Pro and Claude Sonnet 3.7. Moreover, when intent laundering is adapted as a jailbreaking technique, it consistently achieves high attack success rates, ranging from 90% to over 98%, under fully black-box access. Overall, our findings expose a significant disconnect between how model safety is evaluated by existing datasets and how real-world adversaries behave.","authors":["Shahriar Golchin","Marc Wetter"],"pdf_url":"","comment":"v1.1 preprint"},{"id":"http://arxiv.org/abs/2602.12194v2","updated":"2026-02-23T19:50:22Z","published":"2026-02-12T17:27:43Z","title":"MalTool: Malicious Tool Attacks on LLM Agents","summary":"In a malicious tool attack, an attacker uploads a malicious tool to a distribution platform; once a user installs the tool and the LLM agent selects it during task execution, the tool can compromise the user's security and privacy. Prior work primarily focuses on manipulating tool names and descriptions to increase the likelihood of installation by users and selection by LLM agents. However, a successful attack also requires embedding malicious behaviors in the tool's code implementation, which remains largely unexplored.\n  In this work, we bridge this gap by presenting the first systematic study of malicious tool code implementations. We first propose a taxonomy of malicious tool behaviors based on the confidentiality-integrity-availability triad, tailored to LLM-agent settings. To investigate the severity of the risks posed by attackers exploiting coding LLMs to automatically generate malicious tools, we develop MalTool, a coding-LLM-based framework that synthesizes tools exhibiting specified malicious behaviors, either as standalone tools or embedded within otherwise benign implementations. To ensure functional correctness and structural diversity, MalTool leverages an automated verifier that validates whether generated tools exhibit the intended malicious behaviors and differ sufficiently from prior instances, iteratively refining generations until success. Our evaluation demonstrates that MalTool is highly effective even when coding LLMs are safety-aligned. Using MalTool, we construct two datasets of malicious tools: 1,200 standalone malicious tools and 5,287 real-world tools with embedded malicious behaviors. We further show that existing detection methods, including commercial malware detection approaches such as VirusTotal and methods tailored to the LLM-agent setting, exhibit limited effectiveness at detecting the malicious tools, highlighting an urgent need for new defenses.","authors":["Yuepeng Hu","Yuqi Jia","Mengyuan Li","Dawn Song","Neil Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.10281v5","updated":"2026-02-23T19:16:04Z","published":"2024-06-12T05:13:09Z","title":"Watermarking Language Models with Error Correcting Codes","summary":"Recent progress in large language models enables the creation of realistic machine-generated content. Watermarking is a promising approach to distinguish machine-generated text from human text, embedding statistical signals in the output that are ideally undetectable to humans. We propose a watermarking framework that encodes such signals through an error correcting code. Our method, termed robust binary code (RBC) watermark, introduces no noticeable degradation in quality. We evaluate our watermark on base and instruction fine-tuned models and find that our watermark is robust to edits, deletions, and translations. We provide an information-theoretic perspective on watermarking, a powerful statistical test for detection and for generating $p$-values, and theoretical guarantees. Our empirical findings suggest our watermark is fast, powerful, and robust, comparing favorably to the state-of-the-art.","authors":["Patrick Chao","Yan Sun","Edgar Dobriban","Hamed Hassani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20285v1","updated":"2026-02-23T19:13:35Z","published":"2026-02-23T19:13:35Z","title":"CryptRISC: A Secure RISC-V Processor for High-Performance Cryptography with Power Side-Channel Protection","summary":"Cryptographic computations are fundamental to modern computing, ensuring data confidentiality and integrity. However, these operations are highly vulnerable to power side-channel attacks that exploit variations in power consumption to leak sensitive information. Masking is a widely used countermeasure, yet software-based techniques often introduce significant performance overhead and implementation complexity, while fixed-function hardware masking lacks flexibility across diverse cryptographic algorithms. In this paper, we present CryptRISC, the first RISC-V-based processor that combines cryptographic acceleration with hardware-level power side-channel resistance through an ISA-driven operand masking framework. Our design extends the CVA6 core with 64-bit RISC-V Scalar Cryptography Extensions and introduces two microarchitectural components: a Field Detection Layer, which identifies the dominant algebraic field of each cryptographic instruction, and a Masking Control Unit, which applies field-aware operand randomization at runtime. This enables dynamic selection of Boolean, affine, or arithmetic masking schemes based on instruction semantics, providing optimized protection across algorithms including AES, SHA-256, SHA-512, SM3, and SM4. Unlike prior approaches relying on static masking logic or software instrumentation, our method performs operand masking transparently within the execution pipeline without modifying instruction encoding. Experimental results show speedups up to 6.80$\\times$ over baseline software implementations, with only a 1.86% hardware overhead relative to the baseline CVA6 core, confirming the efficiency and practicality of CryptRISC.","authors":["Amisha Srivastava","Muskan Porwal","Kanad Basu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04462v4","updated":"2026-02-23T19:05:29Z","published":"2025-06-04T21:29:07Z","title":"Watermarking Degrades Alignment in Language Models: Analysis and Mitigation","summary":"Watermarking has become a practical tool for tracing language model outputs, but it modifies token probabilities at inference time, which were carefully tuned by alignment training. This creates a tension: how do watermark-induced shifts interact with the procedures intended to make models safe and useful? Experiments on several contemporary models and two representative watermarking schemes reveal that watermarking induces a nontrivial, patterned yet model-specific shift in alignment. We see two failure modes: guard attenuation, where models become more helpful but less safe, and guard amplification, where refusals become overly conservative. These effects persist even after controlling for perplexity degradation, pointing to alignment-specific distortions, not just quality loss. We address this with Alignment Resampling (AR), a procedure that samples multiple watermarked outputs and selects the most aligned response according to an external reward model. Using standard results on the expected maximum of Gaussian random variables, we derive a theoretical lower bound showing that alignment gains grow sublogarithmically with sample size. In practice, sampling as few as two to four candidates largely restores unwatermarked alignment performance in truthfulness, safety, and helpfulness, without hurting watermark detection. This is the first empirical study of watermarking-alignment interactions; it shows that a simple inference-time fix can recover alignment.","authors":["Apurv Verma","NhatHai Phan","Shubhendu Trivedi"],"pdf_url":"","comment":"Published in Transactions of Machine Learning Research 02/2026. Extended version of the earlier paper published at the 1st Workshop on GenAI Watermarking (ICLR 2025)"},{"id":"http://arxiv.org/abs/2602.20222v1","updated":"2026-02-23T13:24:59Z","published":"2026-02-23T13:24:59Z","title":"The TCF doesn't really A(A)ID -- Automatic Privacy Analysis and Legal Compliance of TCF-based Android Applications","summary":"The Transparency and Consent Framework (TCF), developed by the Interactive Advertising Bureau (IAB) Europe, provides a de facto standard for requesting, recording, and managing user consent from European end-users. This framework has previously been found to infringe European data protection law and has subsequently been regularly updated. Previous research on the TCF focused exclusively on web contexts, with no attention given to its implementation in mobile applications. No work has systematically studied the privacy implications of the TCF on Android apps. To address this gap, we investigate the prevalence of the TCF in popular Android apps from the Google Play Store, and assess whether these apps respect users' consent banner choices. By scraping and downloading 4482 of the most popular Google Play Store apps on an emulated Android device, we automatically determine which apps use the TCF, automatically interact with consent banners, and analyze the apps' traffic in two different stages, passive (post choices) and active (during banner interaction and post choices).\n  We found that 576 (12.85%) of the 4482 downloadable apps in our dataset implemented the TCF, and we identified potential privacy violations within this subset. In 15 (2.6%) of these apps, users' choices are stored only when consent is granted. Users who refuse consent are shown the consent banner again each time they launch the app. Network traffic analysis conducted during the passive stage reveals that 66.2% of the analyzed TCF-based apps share personal data, through the Android Advertising ID (AAID), in the absence of a lawful basis for processing. 55.3% of apps analyzed during the active stage share AAID before users interact with the apps' consent banners, violating the prior consent requirement.","authors":["Victor Morel","Cristiana Santos","Pontus Carlsson","Joel Ahlinder","Romaric Duvignau"],"pdf_url":"","comment":"Accepted for publication at PETS'26"},{"id":"http://arxiv.org/abs/2602.20214v1","updated":"2026-02-23T07:09:36Z","published":"2026-02-23T07:09:36Z","title":"Right to History: A Sovereignty Kernel for Verifiable AI Agent Execution","summary":"AI agents increasingly act on behalf of humans, yet no existing system provides a tamper-evident, independently verifiable record of what they did. As regulations such as the EU AI Act begin mandating automatic logging for high-risk AI systems, this gap carries concrete consequences -- especially for agents running on personal hardware, where no centralized provider controls the log. Extending Floridi's informational rights framework from data about individuals to actions performed on their behalf, this paper proposes the Right to History: the principle that individuals are entitled to a complete, verifiable record of every AI agent action on their own hardware. The paper formalizes this principle through five system invariants with structured proof sketches, and implements it in PunkGo, a Rust sovereignty kernel that unifies RFC 6962 Merkle tree audit logs, capability-based isolation, energy-budget governance, and a human-approval mechanism. Adversarial testing confirms all five invariants hold. Performance evaluation shows sub-1.3 ms median action latency, ~400 actions/sec throughput, and 448-byte Merkle inclusion proofs at 10,000 log entries.","authors":["Jing Zhang"],"pdf_url":"","comment":"22 pages, 3 figures, 7 tables. Open-source: https://github.com/PunkGo/punkgo-kernel"},{"id":"http://arxiv.org/abs/2602.20213v1","updated":"2026-02-23T05:59:30Z","published":"2026-02-23T05:59:30Z","title":"CodeHacker: Automated Test Case Generation for Detecting Vulnerabilities in Competitive Programming Solutions","summary":"The evaluation of Large Language Models (LLMs) for code generation relies heavily on the quality and robustness of test cases. However, existing benchmarks often lack coverage for subtle corner cases, allowing incorrect solutions to pass. To bridge this gap, we propose CodeHacker, an automated agent framework dedicated to generating targeted adversarial test cases that expose latent vulnerabilities in program submissions. Mimicking the hack mechanism in competitive programming, CodeHacker employs a multi-strategy approach, including stress testing, anti-hash attacks, and logic-specific targeting to break specific code submissions. To ensure the validity and reliability of these attacks, we introduce a Calibration Phase, where the agent iteratively refines its own Validator and Checker via self-generated adversarial probes before evaluating contestant code.Experiments demonstrate that CodeHacker significantly improves the True Negative Rate (TNR) of existing datasets, effectively filtering out incorrect solutions that were previously accepted. Furthermore, generated adversarial cases prove to be superior training data, boosting the performance of RL-trained models on benchmarks like LiveCodeBench.","authors":["Jingwei Shi","Xinxiang Yin","Jing Huang","Jinman Zhao","Shengyu Tao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22237v1","updated":"2026-02-23T21:34:25Z","published":"2026-02-23T21:34:25Z","title":"Optimized Disaster Recovery for Distributed Storage Systems: Lightweight Metadata Architectures to Overcome Cryptographic Hashing Bottleneck","summary":"Distributed storage architectures are foundational to modern cloud-native infrastructure, yet a critical operational bottleneck persists within disaster recovery (DR) workflows: the dependence on content-based cryptographic hashing for data identification and synchronization. While hash-based deduplication is effective for storage efficiency in steady-state operation, it becomes a systemic liability during failover and failback events when hash indexes are stale, incomplete, or must be rebuilt following a crash. This paper precisely characterizes the operational conditions under which full or partial re-hashing becomes unavoidable. The paper also analyzes the downstream impact of cryptographic re-hashing on Recovery Time Objective (RTO) compliance, and proposes a generalized architectural shift toward deterministic, metadata-driven identification. The proposed framework assigns globally unique composite identifiers to data blocks at ingestion time-independent of content analysis enabling instantaneous delta computation during DR without any cryptographic overhead.","authors":["Prasanna Kumar","Nishank Soni","Gaurang Munje"],"pdf_url":"","comment":"8 pages, 7 Tables"}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2602.20159v1","updated":"2026-02-23T18:59:41Z","published":"2026-02-23T18:59:41Z","title":"A Very Big Video Reasoning Suite","summary":"Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .","authors":["Maijunxian Wang","Ruisi Wang","Juyi Lin","Ran Ji","Thaddäus Wiedemer","Qingying Gao","Dezhi Luo","Yaoyao Qian","Lianyu Huang","Zelong Hong","Jiahui Ge","Qianli Ma","Hang He","Yifan Zhou","Lingzi Guo","Lantao Mei","Jiachen Li","Hanwen Xing","Tianqi Zhao","Fengyuan Yu","Weihang Xiao","Yizheng Jiao","Jianheng Hou","Danyang Zhang","Pengcheng Xu","Boyang Zhong","Zehong Zhao","Gaoyun Fang","John Kitaoka","Yile Xu","Hua Xu","Kenton Blacutt","Tin Nguyen","Siyuan Song","Haoran Sun","Shaoyue Wen","Linyang He","Runming Wang","Yanzhi Wang","Mengyue Yang","Ziqiao Ma","Raphaël Millière","Freda Shi","Nuno Vasconcelos","Daniel Khashabi","Alan Yuille","Yilun Du","Ziming Liu","Bo Li","Dahua Lin","Ziwei Liu","Vikash Kumar","Yijiang Li","Lei Yang","Zhongang Cai","Hokin Deng"],"pdf_url":"","comment":"Homepage: https://video-reason.com/"},{"id":"http://arxiv.org/abs/2602.20150v1","updated":"2026-02-23T18:58:24Z","published":"2026-02-23T18:58:24Z","title":"Simulation-Ready Cluttered Scene Estimation via Physics-aware Joint Shape and Pose Optimization","summary":"Estimating simulation-ready scenes from real-world observations is crucial for downstream planning and policy learning tasks. Regretfully, existing methods struggle in cluttered environments, often exhibiting prohibitive computational cost, poor robustness, and restricted generality when scaling to multiple interacting objects. We propose a unified optimization-based formulation for real-to-sim scene estimation that jointly recovers the shapes and poses of multiple rigid objects under physical constraints. Our method is built on two key technical innovations. First, we leverage the recently introduced shape-differentiable contact model, whose global differentiability permits joint optimization over object geometry and pose while modeling inter-object contacts. Second, we exploit the structured sparsity of the augmented Lagrangian Hessian to derive an efficient linear system solver whose computational cost scales favorably with scene complexity. Building on this formulation, we develop an end-to-end real-to-sim scene estimation pipeline that integrates learning-based object initialization, physics-constrained joint shape-pose optimization, and differentiable texture refinement. Experiments on cluttered scenes with up to 5 objects and 22 convex hulls demonstrate that our approach robustly reconstructs physically valid, simulation-ready object shapes and poses.","authors":["Wei-Cheng Huang","Jiaheng Han","Xiaohan Ye","Zherong Pan","Kris Hauser"],"pdf_url":"","comment":"15 pages, 13 figures, in submission"},{"id":"http://arxiv.org/abs/2601.04493v2","updated":"2026-02-23T18:57:12Z","published":"2026-01-08T01:53:42Z","title":"Continuum Robot State Estimation with Actuation Uncertainty","summary":"Continuum robots are flexible, thin manipulators capable of navigating confined or delicate environments making them well suited for surgical applications. Previous approaches to continuum robot state estimation typically rely on simplified, deterministic actuation models. In contrast, our method jointly estimates robot shape, external loads, internal stresses, and actuation inputs. We adopt a discrete Cosserat rod formulation and show that, when paired with a midpoint integration rule, it achieves high numerical accuracy with relatively few state nodes. This discretization naturally induces a factor-graph structure for sparse nonlinear optimization on SE(3). We extend the formulation with actuation factors for tendon-driven robots and combine multiple rod graphs for parallel continuum robots with closed-loop topologies. By explicitly including actuation variables in the state, the linearized system can be reused to extract manipulator Jacobians, which we leverage in performing trajectory tracking. Finally, we validate the approach experimentally on a surgical concentric tube robot. Overall, our approach enables principled, real-time estimation across multiple continuum robot architectures, accounting for actuation uncertainty and providing direct access to manipulator Jacobians.","authors":["James M. Ferguson","Alan Kuntz","Tucker Hermans"],"pdf_url":"","comment":"Public preprint for IEEE RAL"},{"id":"http://arxiv.org/abs/2505.16547v3","updated":"2026-02-23T18:46:55Z","published":"2025-05-22T11:37:39Z","title":"Find the Fruit: Zero-Shot Sim2Real RL for Occlusion-Aware Plant Manipulation","summary":"Autonomous harvesting in the open presents a complex manipulation problem. In most scenarios, an autonomous system has to deal with significant occlusion and require interaction in the presence of large structural uncertainties (every plant is different). Perceptual and modeling uncertainty make design of reliable manipulation controllers for harvesting challenging, resulting in poor performance during deployment. We present a sim2real reinforcement learning (RL) framework for occlusion-aware plant manipulation, where a policy is learned entirely in simulation to reposition stems and leaves to reveal target fruit(s). In our proposed approach, we decouple high-level kinematic planning from low-level compliant control which simplifies the sim2real transfer. This decomposition allows the learned policy to generalize across multiple plants with different stiffness and morphology. In experiments with multiple real-world plant setups, our system achieves up to 86.7% success in exposing target fruits, demonstrating robustness to occlusion variation and structural uncertainty.","authors":["Nitesh Subedi","Hsin-Jung Yang","Devesh K. Jha","Soumik Sarkar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20119v1","updated":"2026-02-23T18:35:18Z","published":"2026-02-23T18:35:18Z","title":"NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning","summary":"Solving long-horizon tasks requires robots to integrate high-level semantic reasoning with low-level physical interaction. While vision-language models (VLMs) and video generation models can decompose tasks and imagine outcomes, they often lack the physical grounding necessary for real-world execution. We introduce NovaPlan, a hierarchical framework that unifies closed-loop VLM and video planning with geometrically grounded robot execution for zero-shot long-horizon manipulation. At the high level, a VLM planner decomposes tasks into sub-goals and monitors robot execution in a closed loop, enabling the system to recover from single-step failures through autonomous re-planning. To compute low-level robot actions, we extract and utilize both task-relevant object keypoints and human hand poses as kinematic priors from the generated videos, and employ a switching mechanism to choose the better one as a reference for robot actions, maintaining stable execution even under heavy occlusion or depth inaccuracy. We demonstrate the effectiveness of NovaPlan on three long-horizon tasks and the Functional Manipulation Benchmark (FMB). Our results show that NovaPlan can perform complex assembly tasks and exhibit dexterous error recovery behaviors without any prior demonstrations or training. Project page: https://nova-plan.github.io/","authors":["Jiahui Fu","Junyu Nan","Lingfeng Sun","Hongyu Li","Jianing Qian","Jennifer L. Barry","Kris Kitani","George Konidaris"],"pdf_url":"","comment":"25 pages, 15 figures. Project webpage: https://nova-plan.github.io/"},{"id":"http://arxiv.org/abs/2602.20076v1","updated":"2026-02-23T17:40:05Z","published":"2026-02-23T17:40:05Z","title":"Robust Taylor-Lagrange Control for Safety-Critical Systems","summary":"Solving safety-critical control problem has widely adopted the Control Barrier Function (CBF) method. However, the existence of a CBF is only a sufficient condition for system safety. The recently proposed Taylor-Lagrange Control (TLC) method addresses this limitation, but is vulnerable to the feasibility preservation problem (e.g., inter-sampling effect). In this paper, we propose a robust TLC (rTLC) method to address the feasibility preservation problem. Specifically, the rTLC method expands the safety function at an order higher than the relative degree of the function using Taylor's expansion with Lagrange remainder, which allows the control to explicitly show up at the current time instead of the future time in the TLC method. The rTLC method naturally addresses the feasibility preservation problem with only one hyper-parameter (the discretization time interval size during implementation), which is much less than its counterparts. Finally, we illustrate the effectiveness of the proposed rTLC method through an adaptive cruise control problem, and compare it with existing safety-critical control methods.","authors":["Wei Xiao","Christos Cassandras","Anni Li"],"pdf_url":"","comment":"7 pages"},{"id":"http://arxiv.org/abs/2503.14637v2","updated":"2026-02-23T17:30:07Z","published":"2025-03-18T18:37:49Z","title":"KINESIS: Motion Imitation for Human Musculoskeletal Locomotion","summary":"How do humans move? Advances in reinforcement learning (RL) have produced impressive results in capturing human motion using physics-based humanoid control. However, torque-controlled humanoids fail to model key aspects of human motor control such as biomechanical joint constraints \\& non-linear and overactuated musculotendon control. We present KINESIS, a model-free motion imitation framework that tackles these challenges. KINESIS is trained on 1.8 hours of locomotion data and achieves strong motion imitation performance on unseen trajectories. Through a negative mining approach, KINESIS learns robust locomotion priors that we leverage to deploy the policy on several downstream tasks such as text-to-control, target point reaching, and football penalty kicks. Importantly, KINESIS learns to generate muscle activity patterns that correlate well with human EMG activity. We show that these results scale seamlessly across biomechanical model complexity, demonstrating control of up to 290 muscles. Overall, the physiological plausibility makes KINESIS a promising model for tackling challenging problems in human motor control. Code, videos and benchmarks are available at https://github.com/amathislab/Kinesis.","authors":["Merkourios Simos","Alberto Silvio Chiappa","Alexander Mathis"],"pdf_url":"","comment":"Accepted to ICRA. Here we include an appendix"},{"id":"http://arxiv.org/abs/2602.20060v1","updated":"2026-02-23T17:17:26Z","published":"2026-02-23T17:17:26Z","title":"MeanFuser: Fast One-Step Multi-Modal Trajectory Generation and Adaptive Reconstruction via MeanFlow for End-to-End Autonomous Driving","summary":"Generative models have shown great potential in trajectory planning. Recent studies demonstrate that anchor-guided generative models are effective in modeling the uncertainty of driving behaviors and improving overall performance. However, these methods rely on discrete anchor vocabularies that must sufficiently cover the trajectory distribution during testing to ensure robustness, inducing an inherent trade-off between vocabulary size and model performance. To overcome this limitation, we propose MeanFuser, an end-to-end autonomous driving method that enhances both efficiency and robustness through three key designs. (1) We introduce Gaussian Mixture Noise (GMN) to guide generative sampling, enabling a continuous representation of the trajectory space and eliminating the dependency on discrete anchor vocabularies. (2) We adapt ``MeanFlow Identity\" to end-to-end planning, which models the mean velocity field between GMN and trajectory distribution instead of the instantaneous velocity field used in vanilla flow matching methods, effectively eliminating numerical errors from ODE solvers and significantly accelerating inference. (3) We design a lightweight Adaptive Reconstruction Module (ARM) that enables the model to implicitly select from all sampled proposals or reconstruct a new trajectory when none is satisfactory via attention weights. Experiments on the NAVSIM closed-loop benchmark demonstrate that MeanFuser achieves outstanding performance without the supervision of the PDM Score. and exceptional inference efficiency, offering a robust and efficient solution for end-to-end autonomous driving. Our code and model are available at https://github.com/wjl2244/MeanFuser.","authors":["Junli Wang","Xueyi Liu","Yinan Zheng","Zebing Xing","Pengfei Li","Guang Li","Kun Ma","Guang Chen","Hangjun Ye","Zhongpu Xia","Long Chen","Qichao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20057v1","updated":"2026-02-23T17:12:25Z","published":"2026-02-23T17:12:25Z","title":"AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation","summary":"Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. In this work, we introduce a unified framework, World-Model-Driven Diffusion Policy with Online Adaptive Learning (AdaWorldPolicy) to enhance robotic manipulation under dynamic conditions with minimal human involvement. Our core insight is that world models provide strong supervision signals, enabling online adaptive learning in dynamic environments, which can be complemented by force-torque feedback to mitigate dynamic force shifts. Our AdaWorldPolicy integrates a world model, an action expert, and a force predictor-all implemented as interconnected Flow Matching Diffusion Transformers (DiT). They are interconnected via the multi-modal self-attention layers, enabling deep feature exchange for joint learning while preserving their distinct modularity characteristics. We further propose a novel Online Adaptive Learning (AdaOL) strategy that dynamically switches between an Action Generation mode and a Future Imagination mode to drive reactive updates across all three modules. This creates a powerful closed-loop mechanism that adapts to both visual and physical domain shifts with minimal overhead. Across a suite of simulated and real-robot benchmarks, our AdaWorldPolicy achieves state-of-the-art performance, with dynamical adaptive capacity to out-of-distribution scenarios.","authors":["Ge Yuan","Qiyuan Qiao","Jing Zhang","Dong Xu"],"pdf_url":"","comment":"Homepage: https://AdaWorldPolicy.github.io"},{"id":"http://arxiv.org/abs/2602.20055v1","updated":"2026-02-23T17:10:00Z","published":"2026-02-23T17:10:00Z","title":"To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation","summary":"Visual navigation typically assumes the existence of at least one obstacle-free path between start and goal, which must be discovered/planned by the robot. However, in real-world scenarios, such as home environments and warehouses, clutter can block all routes. Targeted at such cases, we introduce the Lifelong Interactive Navigation problem, where a mobile robot with manipulation abilities can move clutter to forge its own path to complete sequential object- placement tasks - each involving placing an given object (eg. Alarm clock, Pillow) onto a target object (eg. Dining table, Desk, Bed). To address this lifelong setting - where effects of environment changes accumulate and have long-term effects - we propose an LLM-driven, constraint-based planning framework with active perception. Our framework allows the LLM to reason over a structured scene graph of discovered objects and obstacles, deciding which object to move, where to place it, and where to look next to discover task-relevant information. This coupling of reasoning and active perception allows the agent to explore the regions expected to contribute to task completion rather than exhaustively mapping the environment. A standard motion planner then executes the corresponding navigate-pick-place, or detour sequence, ensuring reliable low-level control. Evaluated in physics-enabled ProcTHOR-10k simulator, our approach outperforms non-learning and learning-based baselines. We further demonstrate our approach qualitatively on real-world hardware.","authors":["Apoorva Vashisth","Manav Kulshrestha","Pranav Bakshi","Damon Conover","Guillaume Sartoretti","Aniket Bera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20054v1","updated":"2026-02-23T17:04:21Z","published":"2026-02-23T17:04:21Z","title":"Hydrodynamic Performance Enhancement of Unmanned Underwater Gliders with Soft Robotic Morphing Wings for Agility Improvement","summary":"This work assesses the hydrodynamic efficiency of Underwater Unmanned Vehicles (UUVs) equipped with soft morphing wings compared to conventional rigid wings. Unlike rigid wings, deformable counterparts can alter their aerodynamic properties on demand. Improvements in hydrodynamic efficiency extend a UUV's operational range and may determine mission feasibility. Structural and Computational Fluid Dynamics (CFD) simulations were conducted for both a soft morphing wing and a UUV incorporating it. The results show that a UUV employing soft wings achieves 9.75 percent higher overall efficiency than an equivalent vehicle with traditional rigid wings. These findings confirm the potential of soft robotics to enhance underwater vehicle performance, particularly in applications requiring pressure-agnostic operation.","authors":["A. Giordano","G. De Meurichy","V. Telazzi","C. Mucignat","I. Lunati","D. A. L. M. Louchard","M. Iovieno","S. F. Armanini","M. Kovac"],"pdf_url":"","comment":"Conference paper accepted at 9th IEEE-RAS International Conference on Soft Robotics (RoboSoft 2026)"},{"id":"http://arxiv.org/abs/2509.26518v2","updated":"2026-02-23T17:03:31Z","published":"2025-09-30T16:54:59Z","title":"Memory-Efficient 2D/3D Shape Assembly of Robot Swarms","summary":"Mean-shift-based approaches have recently emerged as a representative class of methods for robot swarm shape assembly. They rely on image-based target-shape representations to compute local density gradients and perform mean-shift exploration, which constitute their core mechanism. However, such representations incur substantial memory overhead, especially for high-resolution or 3D shapes. To address this limitation, we propose a memory-efficient tree representation that hierarchically encodes user-specified shapes in both 2D and 3D. Based on this representation, we design a behavior-based distributed controller for assignment-free shape assembly. Comparative 2D and 3D simulations against a state-of-the-art mean-shift algorithm show one to two orders of magnitude lower memory usage and two to four times faster shape entry. Physical experiments with 6 to 7 UAVs further validate real-world practicality.","authors":["Shuoyu Yue","Pengpeng Li","Yang Xu","Kunrui Ze","Xingjian Long","Huazi Cao","Guibin Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20041v1","updated":"2026-02-23T16:50:21Z","published":"2026-02-23T16:50:21Z","title":"EEG-Driven Intention Decoding: Offline Deep Learning Benchmarking on a Robotic Rover","summary":"Brain-computer interfaces (BCIs) provide a hands-free control modality for mobile robotics, yet decoding user intent during real-world navigation remains challenging. This work presents a brain-robot control framework for offline decoding of driving commands during robotic rover operation. A 4WD Rover Pro platform was remotely operated by 12 participants who navigated a predefined route using a joystick, executing the commands forward, reverse, left, right, and stop. Electroencephalogram (EEG) signals were recorded with a 16-channel OpenBCI cap and aligned with motor actions at Delta = 0 ms and future prediction horizons (Delta > 0 ms). After preprocessing, several deep learning models were benchmarked, including convolutional neural networks, recurrent neural networks, and Transformer architectures. ShallowConvNet achieved the highest performance for both action prediction and intent prediction. By combining real-world robotic control with multi-horizon EEG intention decoding, this study introduces a reproducible benchmark and reveals key design insights for predictive deep learning-based BCI systems.","authors":["Ghadah Alosaimi","Maha Alsayyari","Yixin Sun","Stamos Katsigiannis","Amir Atapour-Abarghouei","Toby P. Breckon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.12846v2","updated":"2026-02-23T16:34:59Z","published":"2025-09-16T09:05:46Z","title":"Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration","summary":"Visual-inertial fusion is crucial for a large amount of intelligent and autonomous applications, such as robot navigation and augmented reality. To bootstrap and achieve optimal state estimation, the spatial-temporal displacements between IMU and cameras must be calibrated in advance. Most existing calibration methods adopt continuous-time state representation, more specifically the B-spline. Despite these methods achieve precise spatial-temporal calibration, they suffer from high computational cost caused by continuous-time state representation. To this end, we propose a novel and extremely efficient calibration method that unleashes the power of discrete-time state representation. Moreover, the weakness of discrete-time state representation in temporal calibration is tackled in this paper. With the increasing production of drones, cellphones and other visual-inertial platforms, if one million devices need calibration around the world, saving one minute for the calibration of each device means saving 2083 work days in total. To benefit both the research and industry communities, the open-source implementation is released at https://github.com/JunlinSong/DT-VI-Calib.","authors":["Junlin Song","Antoine Richard","Miguel Olivares-Mendez"],"pdf_url":"","comment":"Accepted by ICRA 2026"},{"id":"http://arxiv.org/abs/2602.19983v1","updated":"2026-02-23T15:51:23Z","published":"2026-02-23T15:51:23Z","title":"Contextual Safety Reasoning and Grounding for Open-World Robots","summary":"Robots are increasingly operating in open-world environments where safe behavior depends on context: the same hallway may require different navigation strategies when crowded versus empty, or during an emergency versus normal operations. Traditional safety approaches enforce fixed constraints in user-specified contexts, limiting their ability to handle the open-ended contextual variability of real-world deployment. We address this gap via CORE, a safety framework that enables online contextual reasoning, grounding, and enforcement without prior knowledge of the environment (e.g., maps or safety specifications). CORE uses a vision-language model (VLM) to continuously reason about context-dependent safety rules directly from visual observations, grounds these rules in the physical environment, and enforces the resulting spatially-defined safe sets via control barrier functions. We provide probabilistic safety guarantees for CORE that account for perceptual uncertainty, and we demonstrate through simulation and real-world experiments that CORE enforces contextually appropriate behavior in unseen environments, significantly outperforming prior semantic safety methods that lack online contextual reasoning. Ablation studies validate our theoretical guarantees and underscore the importance of both VLM-based reasoning and spatial grounding for enforcing contextual safety in novel settings. We provide additional resources at https://zacravichandran.github.io/CORE.","authors":["Zachary Ravichadran","David Snyder","Alexander Robey","Hamed Hassani","Vijay Kumar","George J. Pappas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19943v1","updated":"2026-02-23T15:13:43Z","published":"2026-02-23T15:13:43Z","title":"Scaling Law of Neural Koopman Operators","summary":"Data-driven neural Koopman operator theory has emerged as a powerful tool for linearizing and controlling nonlinear robotic systems. However, the performance of these data-driven models fundamentally depends on the trade-off between sample size and model dimensions, a relationship for which the scaling laws have remained unclear. This paper establishes a rigorous framework to address this challenge by deriving and empirically validating scaling laws that connect sample size, latent space dimension, and downstream control quality. We derive a theoretical upper bound on the Koopman approximation error, explicitly decomposing it into sampling error and projection error. We show that these terms decay at specific rates relative to dataset size and latent dimension, providing a rigorous basis for the scaling law. Based on the theoretical results, we introduce two lightweight regularizers for the neural Koopman operator: a covariance loss to help stabilize the learned latent features and an inverse control loss to ensure the model aligns with physical actuation. The results from systematic experiments across six robotic environments confirm that model fitting error follows the derived scaling laws, and the regularizers improve dynamic model fitting fidelity, with enhanced closed-loop control performance. Together, our results provide a simple recipe for allocating effort between data collection and model capacity when learning Koopman dynamics for control.","authors":["Abulikemu Abuduweili","Yuyang Pang","Feihan Li","Changliu Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01809v3","updated":"2026-02-23T15:07:01Z","published":"2025-12-01T15:44:53Z","title":"Much Ado About Noising: Dispelling the Myths of Generative Robotic Control","summary":"Generative models, like flows and diffusions, have recently emerged as popular and efficacious policy parameterizations in robotics. There has been much speculation as to the factors underlying their successes, ranging from capturing multi-modal action distribution to expressing more complex behaviors. In this work, we perform a comprehensive evaluation of popular generative control policies (GCPs) on common behavior cloning (BC) benchmarks. We find that GCPs do not owe their success to their ability to capture multi-modality or to express more complex observation-to-action mappings. Instead, we find that their advantage stems from iterative computation, as long as intermediate steps are supervised during training and this supervision is paired with a suitable level of stochasticity. As a validation of our findings, we show that a minimum iterative policy (MIP), a lightweight two-step regression-based policy, essentially matches the performance of flow GCPs, and often outperforms distilled shortcut models. Our results suggest that the distribution-fitting component of GCPs is less salient than commonly believed, and point toward new design spaces focusing solely on control performance. Project page: https://simchowitzlabpublic.github.io/much-ado-about-noising-project/","authors":["Chaoyi Pan","Giri Anantharaman","Nai-Chieh Huang","Claire Jin","Daniel Pfrommer","Chenyang Yuan","Frank Permenter","Guannan Qu","Nicholas Boffi","Guanya Shi","Max Simchowitz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19917v1","updated":"2026-02-23T14:57:52Z","published":"2026-02-23T14:57:52Z","title":"Uncertainty-Aware Rank-One MIMO Q Network Framework for Accelerated Offline Reinforcement Learning","summary":"Offline reinforcement learning (RL) has garnered significant interest due to its safe and easily scalable paradigm. However, training under this paradigm presents its own challenge: the extrapolation error stemming from out-of-distribution (OOD) data. Existing methodologies have endeavored to address this issue through means like penalizing OOD Q-values or imposing similarity constraints on the learned policy and the behavior policy. Nonetheless, these approaches are often beset by limitations such as being overly conservative in utilizing OOD data, imprecise OOD data characterization, and significant computational overhead. To address these challenges, this paper introduces an Uncertainty-Aware Rank-One Multi-Input Multi-Output (MIMO) Q Network framework. The framework aims to enhance Offline Reinforcement Learning by fully leveraging the potential of OOD data while still ensuring efficiency in the learning process. Specifically, the framework quantifies data uncertainty and harnesses it in the training losses, aiming to train a policy that maximizes the lower confidence bound of the corresponding Q-function. Furthermore, a Rank-One MIMO architecture is introduced to model the uncertainty-aware Q-function, \\TP{offering the same ability for uncertainty quantification as an ensemble of networks but with a cost nearly equivalent to that of a single network}. Consequently, this framework strikes a harmonious balance between precision, speed, and memory efficiency, culminating in improved overall performance. Extensive experimentation on the D4RL benchmark demonstrates that the framework attains state-of-the-art performance while remaining computationally efficient. By incorporating the concept of uncertainty quantification, our framework offers a promising avenue to alleviate extrapolation errors and enhance the efficiency of offline RL.","authors":["Thanh Nguyen","Tung Luu","Tri Ton","Sungwoong Kim","Chang D. Yoo"],"pdf_url":"","comment":"10 pages, 4 Figures, IEEE Access"},{"id":"http://arxiv.org/abs/2509.26308v3","updated":"2026-02-23T14:52:42Z","published":"2025-09-30T14:22:45Z","title":"Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation","summary":"Out-of-distribution states in robot manipulation often lead to unpredictable robot behavior or task failure, limiting success rates and increasing risk of damage. Anomaly detection (AD) can identify deviations from expected patterns in data, which can be used to trigger failsafe behaviors and recovery strategies. Prior work has applied data-driven AD on time series data for specific robotic tasks, however the transferability of an AD approach between different robot control strategies and task types has not been shown. Leveraging time series data, such as force/torque signals, allows to directly capture robot-environment interactions, crucial for manipulation and online failure detection. As robotic tasks can have widely signal characteristics and requirements, AD methods which can be applied in the same way to a wide range of tasks is needed, ideally with good data efficiency. We examine three industrial robotic tasks, robotic cabling, screwing, and sanding, each with multi-modal time series data and several anomalies. Several autoencoderbased methods are compared, and we evaluate the generalization across different robotic tasks and control methods (diffusion policy-, position-, and impedance-controlled). This allows us to validate the integration of AD in complex tasks involving tighter tolerances and variation from both the robot and its environment. Additionally, we evaluate data efficiency, detection latency, and task characteristics which support robust detection. The results indicate reliable detection with AUROC exceeding 0.96 in failures in the cabling and screwing task, such as incorrect or misaligned parts and obstructed targets. In the polishing task, only severe failures were reliably detected, while more subtle failure types remained undetected.","authors":["Niklas Grambow","Lisa-Marie Fenner","Felipe Kempkes","Philip Hotz","Dingyuan Wan","Jörg Krüger","Kevin Haninger"],"pdf_url":"","comment":"8 pages, 5 figures, 4 tables, the paper has been accepted for publication in the IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2602.19898v1","updated":"2026-02-23T14:38:23Z","published":"2026-02-23T14:38:23Z","title":"Athena: An Autonomous Open-Hardware Tracked Rescue Robot Platform","summary":"In disaster response and situation assessment, robots have great potential in reducing the risks to the safety and health of first responders. As the situations encountered and the required capabilities of the robots deployed in such missions differ wildly and are often not known in advance, heterogeneous fleets of robots are needed to cover a wide range of mission requirements. While UAVs can quickly survey the mission environment, their ability to carry heavy payloads such as sensors and manipulators is limited. UGVs can carry required payloads to assess and manipulate the mission environment, but need to be able to deal with difficult and unstructured terrain such as rubble and stairs. The ability of tracked platforms with articulated arms (flippers) to reconfigure their geometry makes them particularly effective for navigating challenging terrain. In this paper, we present Athena, an open-hardware rescue ground robot research platform with four individually reconfigurable flippers and a reliable low-cost remote emergency stop (E-Stop) solution. A novel mounting solution using an industrial PU belt and tooth inserts allows the replacement and testing of different track profiles. The manipulator with a maximum reach of 1.54m can be used to operate doors, valves, and other objects of interest. Full CAD & PCB files, as well as all low-level software, are released as open-source contributions.","authors":["Stefan Fabian","Aljoscha Schmidt","Jonas Süß"," Dishant","Aum Oza","Oskar von Stryk"],"pdf_url":"","comment":"https://github.com/tu-darmstadt-ros-pkg/athena"},{"id":"http://arxiv.org/abs/2602.19862v1","updated":"2026-02-23T14:01:37Z","published":"2026-02-23T14:01:37Z","title":"Rendezvous and Docking of Mobile Ground Robots for Efficient Transportation Systems","summary":"In-Motion physical coupling of multiple mobile ground robots has the potential to enable new applications like in-motion transfer that improves efficiency in handling and transferring goods, which tackles current challenges in logistics. A key challenge lies in achieving reliable autonomous in-motion physical coupling of two mobile ground robots starting at any initial position. Existing approaches neglect the modeling of the docking interface and the strategy for approaching it, resulting in uncontrolled collisions that make in-motion physical coupling either impossible or inefficient. To address this challenge, we propose a central mpc approach that explicitly models the dynamics and states of two omnidirectional wheeled robots, incorporates constraints related to their docking interface, and implements an approaching strategy for rendezvous and docking. This novel approach enables omnidirectional wheeled robots with a docking interface to physically couple in motion regardless of their initial position. In addition, it makes in-motion transfer possible, which is 19.75% more time- and 21.04% energy-efficient compared to a non-coupling approach in a logistic scenario.","authors":["Lars Fischer","Daniel Flögel","Sören Hohmann"],"pdf_url":"","comment":"8 pages, conference paper"},{"id":"http://arxiv.org/abs/2507.16874v2","updated":"2026-02-23T13:53:21Z","published":"2025-07-22T08:32:55Z","title":"Budget Allocation Policies for Real-Time Multi-Agent Path Finding","summary":"Multi-Agent Path finding (MAPF) is the problem of finding paths for a set of agents such that each agent reaches its desired destination while avoiding collisions with the other agents. This problem arises in many robotics applications, such as automated warehouses and swarms of drones. Many MAPF solvers are designed to run offline, that is, first generate paths for all agents and then execute them. In real-world scenarios, waiting for a complete solution before allowing any robot to move is often impractical. Real-time MAPF (RT-MAPF) captures this setting by assuming that agents must begin execution after a fixed planning period, referred to as the planning budget, and execute a fixed number of actions, referred to as the execution window. This results in an iterative process in which a short plan is executed, while the next execution window is planned concurrently. Existing solutions to RT-MAPF iteratively call windowed versions of MAPF algorithms in every planning period, without explicitly considering the size of the planning budget. We address this gap and explore different policies for allocating the planning budget in windowed versions of MAPF-LNS2, a state-of-the-art MAPF algorithm. Our exploration shows that the baseline approach in which all agents draw from a shared planning budget pool is ineffective in challenging scenarios. Instead, policies that intelligently distribute the planning budget among agents are able to solve more problem instances in less time.","authors":["Raz Beck","Roni Stern"],"pdf_url":"","comment":"11 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2602.19850v1","updated":"2026-02-23T13:53:14Z","published":"2026-02-23T13:53:14Z","title":"TactiVerse: Generalizing Multi-Point Tactile Sensing in Soft Robotics Using Single-Point Data","summary":"Real-time prediction of deformation in highly compliant soft materials remains a significant challenge in soft robotics. While vision-based soft tactile sensors can track internal marker displacements, learning-based models for 3D contact estimation heavily depend on their training datasets, inherently limiting their ability to generalize to complex scenarios such as multi-point sensing. To address this limitation, we introduce TactiVerse, a U-Net-based framework that formulates contact geometry estimation as a spatial heatmap prediction task. Even when trained exclusively on a limited dataset of single-point indentations, our architecture achieves highly accurate single-point sensing, yielding a superior mean absolute error of 0.0589 mm compared to the 0.0612 mm of a conventional regression-based CNN baseline. Furthermore, we demonstrate that augmenting the training dataset with multi-point contact data substantially enhances the sensor's multi-point sensing capabilities, significantly improving the overall mean MAE for two-point discrimination from 1.214 mm to 0.383 mm. By successfully extrapolating complex contact geometries from fundamental interactions, this methodology unlocks advanced multi-point and large-area shape sensing. Ultimately, it significantly streamlines the development of marker-based soft sensors, offering a highly scalable solution for real-world tactile perception.","authors":["Junhui Lee","Hyosung Kim","Saekwang Nam"],"pdf_url":"","comment":"6 pages, 7 figures, accepted at 9th IEEE-RAS International Conference on Soft Robotics (RoboSoft)"},{"id":"http://arxiv.org/abs/2602.19764v1","updated":"2026-02-23T12:12:51Z","published":"2026-02-23T12:12:51Z","title":"Towards Dexterous Embodied Manipulation via Deep Multi-Sensory Fusion and Sparse Expert Scaling","summary":"Realizing dexterous embodied manipulation necessitates the deep integration of heterogeneous multimodal sensory inputs. However, current vision-centric paradigms often overlook the critical force and geometric feedback essential for complex tasks. This paper presents DeMUSE, a Deep Multimodal Unified Sparse Experts framework leveraging a Diffusion Transformer to integrate RGB, depth, and 6-axis force into a unified serialized stream. Adaptive Modality-specific Normalization (AdaMN) is employed to recalibrate modality-aware features, mitigating representation imbalance and harmonizing the heterogeneous distributions of multi-sensory signals. To facilitate efficient scaling, the architecture utilizes a Sparse Mixture-of-Experts (MoE) with shared experts, increasing model capacity for physical priors while maintaining the low inference latency required for real-time control. A Joint denoising objective synchronously synthesizes environmental evolution and action sequences to ensure physical consistency. Achieving success rates of 83.2% and 72.5% in simulation and real-world trials, DeMUSE demonstrates state-of-the-art performance, validating the necessity of deep multi-sensory integration for complex physical interactions.","authors":["Yirui Sun","Guangyu Zhuge","Keliang Liu","Jie Gu","Zhihao xia","Qionglin Ren","Chunxu tian","Zhongxue Ga"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.12924v2","updated":"2026-02-23T12:06:20Z","published":"2025-10-14T18:56:25Z","title":"Geometric Model Predictive Path Integral for Agile UAV Control with Online Collision Avoidance","summary":"In this letter, we introduce Geometric Model Predictive Path Integral (GMPPI), a sampling-based controller capable of tracking agile trajectories while avoiding obstacles. In each iteration, GMPPI generates a large number of candidate rollout trajectories and then averages them to create a nominal control to be followed by the controlled Unmanned Aerial Vehicle (UAV). Classical Model Predictive Path Integral (MPPI) faces a trade-off between tracking precision and obstacle avoidance; high-noise random rollouts are inefficient for tracking but necessary for collision avoidance. To this end, we propose leveraging geometric SE(3) control to generate a portion of GMPPI rollouts. To maximize their benefit, we introduce a UAV-tailored cost function balancing tracking performance with obstacle avoidance. All generated rollouts are projected onto depth images for collision avoidance, representing, to our knowledge, the first method utilizing depth data directly in a UAV MPPI loop. Simulations show GMPPI matches the tracking error of an obstacle-blind geometric controller while exceeding the avoidance capabilities of state-of-the-art planners and learning-based controllers. Real-world experiments demonstrate flight at speeds up to 17 m/s and obstacle avoidance up to 10 m/s.","authors":["Pavel Pochobradský","Ondřej Procházka","Robert Pěnička","Vojtěch Vonásek","Martin Saska"],"pdf_url":"","comment":"This work has been accepted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2602.19710v1","updated":"2026-02-23T11:00:08Z","published":"2026-02-23T11:00:08Z","title":"Universal Pose Pretraining for Generalizable Vision-Language-Action Policies","summary":"Existing Vision-Language-Action (VLA) models often suffer from feature collapse and low training efficiency because they entangle high-level perception with sparse, embodiment-specific action supervision. Since these models typically rely on VLM backbones optimized for Visual Question Answering (VQA), they excel at semantic identification but often overlook subtle 3D state variations that dictate distinct action patterns.\n  To resolve these misalignments, we propose Pose-VLA, a decoupled paradigm that separates VLA training into a pre-training phase for extracting universal 3D spatial priors in a unified camera-centric space, and a post-training phase for efficient embodiment alignment within robot-specific action space. By introducing discrete pose tokens as a universal representation, Pose-VLA seamlessly integrates spatial grounding from diverse 3D datasets with geometry-level trajectories from robotic demonstrations. Our framework follows a two-stage pre-training pipeline, establishing fundamental spatial grounding via poses followed by motion alignment through trajectory supervision.\n  Extensive evaluations demonstrate that Pose-VLA achieves state-of-the-art results on RoboTwin 2.0 with a 79.5% average success rate and competitive performance on LIBERO at 96.0%. Real-world experiments further showcase robust generalization across diverse objects using only 100 demonstrations per task, validating the efficiency of our pre-training paradigm.","authors":["Haitao Lin","Hanyang Yu","Jingshun Huang","He Zhang","Yonggen Ling","Ping Tan","Xiangyang Xue","Yanwei Fu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19699v1","updated":"2026-02-23T10:45:36Z","published":"2026-02-23T10:45:36Z","title":"CACTO-BIC: Scalable Actor-Critic Learning via Biased Sampling and GPU-Accelerated Trajectory Optimization","summary":"Trajectory Optimization (TO) and Reinforcement Learning (RL) offer complementary strengths for solving optimal control problems. TO efficiently computes locally optimal solutions but can struggle with non-convexity, while RL is more robust to non-convexity at the cost of significantly higher computational demands. CACTO (Continuous Actor-Critic with Trajectory Optimization) was introduced to combine these advantages by learning a warm-start policy that guides the TO solver towards low-cost trajectories. However, scalability remains a key limitation, as increasing system complexity significantly raises the computational cost of TO. This work introduces CACTO-BIC to address these challenges. CACTO-BIC improves data efficiency by biasing initial-state sampling leveraging a property of the value function associated with locally optimal policies; moreover, it reduces computation time by exploiting GPU acceleration. Empirical evaluations show improved sample efficiency and faster computation compared to CACTO. Comparisons with PPO demonstrate that our approach can achieve similar solutions in less time. Finally, experiments on the AlienGO quadruped robot demonstrate that CACTO-BIC can scale to high-dimensional systems and is suitable for real-time applications.","authors":["Elisa Alboni","Pietro Noah Crestaz","Elias Fontanari","Andrea Del Prete"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19697v1","updated":"2026-02-23T10:44:15Z","published":"2026-02-23T10:44:15Z","title":"BayesFusion-SDF: Probabilistic Signed Distance Fusion with View Planning on CPU","summary":"Key part of robotics, augmented reality, and digital inspection is dense 3D reconstruction from depth observations. Traditional volumetric fusion techniques, including truncated signed distance functions (TSDF), enable efficient and deterministic geometry reconstruction; however, they depend on heuristic weighting and fail to transparently convey uncertainty in a systematic way. Recent neural implicit methods, on the other hand, get very high fidelity but usually need a lot of GPU power for optimization and aren't very easy to understand for making decisions later on. This work presents BayesFusion-SDF, a CPU-centric probabilistic signed distance fusion framework that conceptualizes geometry as a sparse Gaussian random field with a defined posterior distribution over voxel distances. First, a rough TSDF reconstruction is used to create an adaptive narrow-band domain. Then, depth observations are combined using a heteroscedastic Bayesian formulation that is solved using sparse linear algebra and preconditioned conjugate gradients. Randomized diagonal estimators are a quick way to get an idea of posterior uncertainty. This makes it possible to extract surfaces and plan the next best view while taking into account uncertainty. Tests on a controlled ablation scene and a CO3D object sequence show that the new method is more accurate geometrically than TSDF baselines and gives useful estimates of uncertainty for active sensing. The proposed formulation provides a clear and easy-to-use alternative to GPU-heavy neural reconstruction methods while still being able to be understood in a probabilistic way and acting in a predictable way. GitHub: https://mazumdarsoumya.github.io/BayesFusionSDF","authors":["Soumya Mazumdar","Vineet Kumar Rakesh","Tapas Samanta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19653v1","updated":"2026-02-23T09:54:32Z","published":"2026-02-23T09:54:32Z","title":"Scalable Low-Density Distributed Manipulation Using an Interconnected Actuator Array","summary":"Distributed Manipulator Systems, composed of arrays of robotic actuators necessitate dense actuator arrays to effectively manipulate small objects. This paper presents a system composed of modular 3-DoF robotic tiles interconnected by a compliant surface layer, forming a continuous, controllable manipulation surface. The compliant layer permits increased actuator spacing without compromising object manipulation capabilities, significantly reducing actuator density while maintaining robust control, even for smaller objects. We characterize the coupled workspace of the array and develop a manipulation strategy capable of translating objects to arbitrary positions within an N X N array. The approach is validated experimentally using a minimal 2 X 2 prototype, demonstrating the successful manipulation of objects with varied shapes and sizes.","authors":["Bailey Dacre","Rodrigo Moreno","Jørn Lambertsen","Kasper Stoy","Andrés Faíña"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19651v1","updated":"2026-02-23T09:53:23Z","published":"2026-02-23T09:53:23Z","title":"Denoising Particle Filters: Learning State Estimation with Single-Step Objectives","summary":"Learning-based methods commonly treat state estimation in robotics as a sequence modeling problem. While this paradigm can be effective at maximizing end-to-end performance, models are often difficult to interpret and expensive to train, since training requires unrolling sequences of predictions in time. As an alternative to end-to-end trained state estimation, we propose a novel particle filtering algorithm in which models are trained from individual state transitions, fully exploiting the Markov property in robotic systems. In this framework, measurement models are learned implicitly by minimizing a denoising score matching objective. At inference, the learned denoiser is used alongside a (learned) dynamics model to approximately solve the Bayesian filtering equation at each time step, effectively guiding predicted states toward the data manifold informed by measurements. We evaluate the proposed method on challenging robotic state estimation tasks in simulation, demonstrating competitive performance compared to tuned end-to-end trained baselines. Importantly, our method offers the desirable composability of classical filtering algorithms, allowing prior information and external sensor models to be incorporated without retraining.","authors":["Lennart Röstel","Berthold Bäuml"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.12691v2","updated":"2026-02-23T08:56:56Z","published":"2026-02-13T07:46:37Z","title":"ALOE: Action-Level Off-Policy Evaluation for Vision-Language-Action Model Post-Training","summary":"We study how to improve large foundation vision-language-action (VLA) systems through online reinforcement learning (RL) in real-world settings. Central to this process is the value function, which provides learning signals to guide VLA learning from experience. In practice, the value function is estimated from trajectory fragments collected from different data sources, including historical policies and intermittent human interventions. Estimating the value function of current behavior quality from the mixture data is inherently an off-policy evaluation problem. However, prior work often adopts conservative on-policy estimation for stability, which avoids direct evaluation of the current high-capacity policy and limits learning effectiveness. In this paper, we propose ALOE, an action-level off-policy evaluation framework for VLA post-training. ALOE applies chunking-based temporal-difference bootstrapping to evaluate individual action sequences instead of predicting final task outcomes. This design improves effective credit assignment to critical action chunks under sparse rewards and supports stable policy improvement. We evaluate our method on three real-world manipulation tasks, including smartphone packing as a high-precision task, laundry folding as a long-horizon deformable-object task, and bimanual pick-and-place involving multi-object perception. Across all tasks, ALOE improves learning efficiency without compromising execution speed, showing that off-policy RL can be reintroduced in a reliable manner for real-world VLA post-training. Videos and additional materials are available at our project website.","authors":["Rushuai Yang","Hecheng Wang","Chiming Liu","Xiaohan Yan","Yunlong Wang","Xuan Du","Shuoyu Yue","Yongcheng Liu","Chuheng Zhang","Lizhe Qi","Yi Chen","Wei Shan","Maoqing Yao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.17448v2","updated":"2026-02-23T08:30:19Z","published":"2025-10-20T11:35:01Z","title":"Switching Among Feedback-Linearizing Output Sets (Melds): Dwell-Time and Compatibility Guarantees","summary":"We study switching among multiple square selections of output functions (melds) drawn from a deck of candidate outputs for nonlinear systems that are static feedback linearizable via outputs. Fixing an operating point, each meld induces a distinct feedback-linearizing coordinate chart defined on a common neighborhood. Switching between melds therefore produces state-dependent coordinate mismatches that are not captured by classical switched-system analyses. We quantify this effect through Lipschitz bounds on the cross-chart maps over a compact safe set and introduce a reference-compatibility constant that measures mismatch among reference families across melds. We derive an explicit dwell-time condition depending on controller decay rates and the compatibility constant, that guarantees exponential decay of the active-output tracking errors between switches, seamless tracking of outputs shared by consecutive melds, and uniform boundedness of the state error within the safe set. A planar 3R manipulator illustrates the results.","authors":["Mirko Mizzoni","Pieter van Goor","Barbara Bazzana","Antonio Franchi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2204.07520v4","updated":"2026-02-23T08:03:56Z","published":"2022-04-15T15:47:05Z","title":"Resource-Aware Distributed Submodular Maximization: A Paradigm for Multi-Robot Decision-Making","summary":"Multi-robot decision-making is the process where multiple robots coordinate actions. In this paper, we aim for efficient and effective multi-robot decision-making despite the robots' limited on-board resources and the often resource-demanding complexity of their tasks. We introduce the first algorithm enabling the robots to choose with which few other robots to coordinate and provably balance the trade-off of centralized vs. decentralized coordination. Particularly, centralization favors globally near-optimal decision-making but at the cost of increased on-board resource requirements; whereas, decentralization favors minimal resource requirements but at a global suboptimality cost. All robots can thus afford our algorithm, irrespective of their resources. We are motivated by the future of autonomy that involves multiple robots coordinating actions to complete resource-demanding tasks, such as target tracking, area coverage, and monitoring. To provide closed-form guarantees, we focus on maximization problems involving monotone and 2nd-order submodular functions. To capture the cost of decentralization, we introduce the notion of Centralization Of Information among non-Neighbors (COIN). We validate our algorithm in simulated scenarios of image covering.","authors":["Zirui Xu","Vasileios Tzoumas"],"pdf_url":"","comment":"Updated presentation. Accepted to the 2022 IEEE Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2602.19577v1","updated":"2026-02-23T07:51:27Z","published":"2026-02-23T07:51:27Z","title":"Chasing Ghosts: A Simulation-to-Real Olfactory Navigation Stack with Optional Vision Augmentation","summary":"Autonomous odor source localization remains a challenging problem for aerial robots due to turbulent airflow, sparse and delayed sensory signals, and strict payload and compute constraints. While prior unmanned aerial vehicle (UAV)-based olfaction systems have demonstrated gas distribution mapping or reactive plume tracing, they rely on predefined coverage patterns, external infrastructure, or extensive sensing and coordination. In this work, we present a complete, open-source UAV system for online odor source localization using a minimal sensor suite. The system integrates custom olfaction hardware, onboard sensing, and a learning-based navigation policy trained in simulation and deployed on a real quadrotor. Through our minimal framework, the UAV is able to navigate directly toward an odor source without constructing an explicit gas distribution map or relying on external positioning systems. Vision is incorporated as an optional complementary modality to accelerate navigation under certain conditions. We validate the proposed system through real-world flight experiments in a large indoor environment using an ethanol source, demonstrating consistent source-finding behavior under realistic airflow conditions. The primary contribution of this work is a reproducible system and methodological framework for UAV-based olfactory navigation and source finding under minimal sensing assumptions. We elaborate on our hardware design and open source our UAV firmware, simulation code, olfaction-vision dataset, and circuit board to the community. Code, data, and designs will be made available at https://github.com/KordelFranceTech/ChasingGhosts.","authors":["Kordel K. France","Ovidiu Daescu","Latifur Khan","Rohith Peddi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.13850v3","updated":"2026-02-23T07:14:01Z","published":"2026-02-14T19:11:02Z","title":"Humanoid Hanoi: Investigating Shared Whole-Body Control for Skill-Based Box Rearrangement","summary":"We investigate a skill-based framework for humanoid box rearrangement that enables long-horizon execution by sequencing reusable skills at the task level. In our architecture, all skills execute through a shared, task-agnostic whole-body controller (WBC), providing a consistent closed-loop interface for skill composition, in contrast to non-shared designs that use separate low-level controllers per skill. We find that naively reusing the same pretrained WBC can reduce robustness over long horizons, as new skills and their compositions induce shifted state and command distributions. We address this with a simple data aggregation procedure that augments shared-WBC training with rollouts from closed-loop skill execution under domain randomization. To evaluate the approach, we introduce Humanoid Hanoi, a long-horizon Tower-of-Hanoi box rearrangement benchmark, and report results in simulation and on the Digit V3 humanoid robot, demonstrating fully autonomous rearrangement over extended horizons and quantifying the benefits of the shared-WBC approach over non-shared baselines. Project page: https://osudrl.github.io/Humanoid_Hanoi/","authors":["Minku Kim","Kuan-Chia Chen","Aayam Shrestha","Li Fuxin","Stefan Lee","Alan Fern"],"pdf_url":"","comment":"10 pages, 6 figures, Project page: https://osudrl.github.io/Humanoid_Hanoi/"},{"id":"http://arxiv.org/abs/2403.10996v8","updated":"2026-02-23T06:49:35Z","published":"2024-03-16T18:47:04Z","title":"Mixed-Reality Digital Twins: Leveraging the Physical and Virtual Worlds for Hybrid Sim2Real Transition of Multi-Agent Reinforcement Learning Policies","summary":"Multi-agent reinforcement learning (MARL) for cyber-physical vehicle systems usually requires a significantly long training time due to their inherent complexity. Furthermore, deploying the trained policies in the real world demands a feature-rich environment along with multiple physical embodied agents, which may not be feasible due to monetary, physical, energy, or safety constraints. This work seeks to address these pain points by presenting a mixed-reality (MR) digital twin (DT) framework capable of: (i) boosting training speeds by selectively scaling parallelized simulation workloads on-demand, and (ii) immersing the MARL policies across hybrid simulation-to-reality (sim2real) experiments. The viability and performance of the proposed framework are highlighted through two representative use cases, which cover cooperative as well as competitive classes of MARL problems. We study the effect of: (i) agent and environment parallelization on training time, and (ii) systematic domain randomization on zero-shot sim2real transfer, across both case studies. Results indicate up to 76.3% reduction in training time with the proposed parallelization scheme and sim2real gap as low as 2.9% using the proposed deployment method.","authors":["Chinmay Vilas Samak","Tanmay Vilas Samak","Venkat Narayan Krovi"],"pdf_url":"","comment":"Accepted in IEEE Robotics and Automation Letters (RA-L) and additionally accepted to be presented at IEEE International Conference on Robotics and Automation (ICRA) 2026"},{"id":"http://arxiv.org/abs/2602.19538v1","updated":"2026-02-23T06:11:51Z","published":"2026-02-23T06:11:51Z","title":"Cost-Aware Diffusion Active Search","summary":"Active search for recovering objects of interest through online, adaptive decision making with autonomous agents requires trading off exploration of unknown environments with exploitation of prior observations in the search space. Prior work has proposed information gain and Thompson sampling based myopic, greedy approaches for agents to actively decide query or search locations when the number of targets is unknown. Decision making algorithms in such partially observable environments have also shown that agents capable of lookahead over a finite horizon outperform myopic policies for active search. Unfortunately, lookahead algorithms typically rely on building a computationally expensive search tree that is simulated and updated based on the agent's observations and a model of the environment dynamics. Instead, in this work, we leverage the sequence modeling abilities of diffusion models to sample lookahead action sequences that balance the exploration-exploitation trade-off for active search without building an exhaustive search tree. We identify the optimism bias in prior diffusion based reinforcement learning approaches when applied to the active search setting and propose mitigating solutions for efficient cost-aware decision making with both single and multi-agent teams. Our proposed algorithm outperforms standard baselines in offline reinforcement learning in terms of full recovery rate and is computationally more efficient than tree search in cost-aware active decision making.","authors":["Arundhati Banerjee","Jeff Schneider"],"pdf_url":"","comment":"In submission"},{"id":"http://arxiv.org/abs/2602.19534v1","updated":"2026-02-23T05:56:43Z","published":"2026-02-23T05:56:43Z","title":"Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial","summary":"Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and context-aware aerial operations. This survey systematically explores the intersection of LLMs and UAV technologies and proposes a unified framework that consolidates existing architectures, methodologies, and applications for UAVs. We first present a structured taxonomy of LLM adaptation techniques for UAVs, including pretraining, fine-tuning, Retrieval-Augmented Generation (RAG), and prompt engineering, along with key reasoning capabilities such as Chain-of-Thought (CoT) and In-Context Learning (ICL). We then examine LLM-assisted UAV communications and operations, covering navigation, mission planning, swarm control, safety, autonomy, and network management. After that, the survey further discusses Multimodal LLMs (MLLMs) for human-swarm interaction, perception-driven navigation, and collaborative control. Finally, we address ethical considerations, including bias, transparency, accountability, and Human-in-the-Loop (HITL) strategies, and outline future research directions. Overall, this work positions LLM-assisted UAVs as a foundation for intelligent and adaptive aerial systems.","authors":["Yousef Emami","Hao Zhou","Radha Reddy","Atefeh Hajijamali Arani","Biliang Wang","Kai Li","Luis Almeida","Zhu Han"],"pdf_url":"","comment":"40 pages, 10 figures, 13 tables"},{"id":"http://arxiv.org/abs/2602.19532v1","updated":"2026-02-23T05:48:58Z","published":"2026-02-23T05:48:58Z","title":"Bellman Value Decomposition for Task Logic in Safe Optimal Control","summary":"Real-world tasks involve nuanced combinations of goal and safety specifications. In high dimensions, the challenge is exacerbated: formal automata become cumbersome, and the combination of sparse rewards tends to require laborious tuning. In this work, we consider the innate structure of the Bellman Value as a means to naturally organize the problem for improved automatic performance. Namely, we prove the Bellman Value for a complex task defined in temporal logic can be decomposed into a graph of Bellman Values, connected by a set of well-known Bellman equations (BEs): the Reach-Avoid BE, the Avoid BE, and a novel type, the Reach-Avoid-Loop BE. To solve the Value and optimal policy, we propose VDPPO, which embeds the decomposed Value graph into a two-layer neural net, bootstrapping the implicit dependencies. We conduct a variety of simulated and hardware experiments to test our method on complex, high-dimensional tasks involving heterogeneous teams and nonlinear dynamics. Ultimately, we find this approach greatly improves performance over existing baselines, balancing safety and liveness automatically.","authors":["William Sharpless","Oswin So","Dylan Hirsch","Sylvia Herbert","Chuchu Fan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19518v1","updated":"2026-02-23T05:18:11Z","published":"2026-02-23T05:18:11Z","title":"Anticipate, Adapt, Act: A Hybrid Framework for Task Planning","summary":"Anticipating and adapting to failures is a key capability robots need to collaborate effectively with humans in complex domains. This continues to be a challenge despite the impressive performance of state of the art AI planning systems and Large Language Models (LLMs) because of the uncertainty associated with the tasks and their outcomes. Toward addressing this challenge, we present a hybrid framework that integrates the generic prediction capabilities of an LLM with the probabilistic sequential decision-making capability of Relational Dynamic Influence Diagram Language. For any given task, the robot reasons about the task and the capabilities of the human attempting to complete it; predicts potential failures due to lack of ability (in the human) or lack of relevant domain objects; and executes actions to prevent such failures or recover from them. Experimental evaluation in the VirtualHome 3D simulation environment demonstrates substantial improvement in performance compared with state of the art baselines.","authors":["Nabanita Dash","Ayush Kaura","Shivam Singh","Ramandeep Singh","Snehasis Banerjee","Mohan Sridharan","K. Madhava Krishna"],"pdf_url":"","comment":"Accepted at IEEE European Conference on Mobile Robots (ECMR)"},{"id":"http://arxiv.org/abs/2511.05275v2","updated":"2026-02-23T04:57:06Z","published":"2025-11-07T14:37:07Z","title":"TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models","summary":"Vision-language-action models (VLAs) trained on large-scale robotic datasets have demonstrated strong performance on manipulation tasks, including bimanual tasks. However, because most public datasets focus on single-arm demonstrations, adapting VLAs for bimanual tasks typically requires substantial additional bimanual data and fine-tuning. To address this challenge, we introduce TwinVLA, a modular framework that composes two copies of a pretrained single-arm VLA into a coordinated bimanual VLA. Unlike monolithic cross-embodiment models trained on mixtures of single-arm and bimanual data, TwinVLA improves both data efficiency and performance by composing pretrained single-arm policies. Across diverse bimanual tasks in real-world and simulation settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model without requiring any bimanual pretraining. Furthermore, it narrows the gap to state-of-the-art model $π_0$, which relies on extensive proprietary bimanual data and compute cost. These results establish our modular composition approach as a data-efficient and scalable path toward high-performance bimanual manipulation, leveraging public single-arm data.","authors":["Hokyun Im","Euijin Jeong","Andrey Kolobov","Jianlong Fu","Youngwoon Lee"],"pdf_url":"","comment":"Accepted to ICLR 2026 (Poster). Project webpage : https://jellyho.github.io/TwinVLA/"},{"id":"http://arxiv.org/abs/2602.19491v1","updated":"2026-02-23T04:21:05Z","published":"2026-02-23T04:21:05Z","title":"Botson: An Accessible and Low-Cost Platform for Social Robotics Research","summary":"Trust remains a critical barrier to the effective integration of Artificial Intelligence (AI) into human-centric domains. Disembodied agents, such as voice assistants, often fail to establish trust due to their inability to convey non-verbal social cues. This paper introduces the architecture of Botson: an anthropomorphic social robot powered by a large language model (LLM). Botson was created as a low-cost and accessible platform for social robotics research.","authors":["Samuel Bellaire","Abdalmalek Abu-raddaha","Natalie Kim","Nathan Morhan","William Elliott","Samir Rawashdeh"],"pdf_url":"","comment":"5 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.19422v1","updated":"2026-02-23T01:29:39Z","published":"2026-02-23T01:29:39Z","title":"Positioning Modular Co-Design in Future HRI Design Research","summary":"Design-oriented HRI is increasingly interested in robots as long-term companions, yet many designs still assume a fixed form and a stable set of functions. We present an ongoing design research program that treats modularity as a designerly medium - a way to make long-term human-robot relationships discussable and material through co-design. Across a series of lifespan-oriented co-design activities, participants repeatedly reconfigured the same robot for different life stages, using modular parts to express changing needs, values, and roles. From these outcomes, we articulate PAS (Personalization-Adaptability-Sustainability) as a human-centered lens on how people enact modularity in practice: configuring for self-expression, adapting across transitions, and sustaining robots through repair, reuse, and continuity. We then sketch next steps toward a fabrication-aware, community-extensible modular platform and propose evaluation criteria for designerly HRI work that prioritize expressive adequacy, lifespan plausibility, repairability-in-use, and responsible stewardship - not only usability or performance.","authors":["Lingyun Chen","Qing Xiao","Zitao Zhang","Eli Blevis","Selma Šabanović"],"pdf_url":"","comment":"4 pages, 1 figure, accepted by 3rd Workshop on Designerly HRI at HRI'26"},{"id":"http://arxiv.org/abs/2602.19400v1","updated":"2026-02-23T00:19:19Z","published":"2026-02-23T00:19:19Z","title":"Hilbert-Augmented Reinforcement Learning for Scalable Multi-Robot Coverage and Exploration","summary":"We present a coverage framework that integrates Hilbert space-filling priors into decentralized multi-robot learning and execution. We augment DQN and PPO with Hilbert-based spatial indices to structure exploration and reduce redundancy in sparse-reward environments, and we evaluate scalability in multi-robot grid coverage. We further describe a waypoint interface that converts Hilbert orderings into curvature-bounded, time-parameterized SE(2) trajectories (planar (x, y, θ)), enabling onboard feasibility on resource-constrained robots. Experiments show improvements in coverage efficiency, redundancy, and convergence speed over DQN/PPO baselines. In addition, we validate the approach on a Boston Dynamics Spot legged robot, executing the generated trajectories in indoor environments and observing reliable coverage with low redundancy. These results indicate that geometric priors improve autonomy and scalability for swarm and legged robotics.","authors":["Tamil Selvan Gurunathan","Aryya Gangopadhyay"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.02002v3","updated":"2026-02-23T22:31:52Z","published":"2025-12-01T18:57:10Z","title":"LLM-Driven Corrective Robot Operation Code Generation with Static Text-Based Simulation","summary":"Recent advances in Large language models (LLMs) have demonstrated their promising capabilities of generating robot operation code to enable LLM-driven robots. To enhance the reliability of operation code generated by LLMs, corrective designs with feedback from the observation of executing code have been increasingly adopted in existing research. However, the code execution in these designs relies on either a physical experiment or a customized simulation environment, which limits their deployment due to the high configuration effort of the environment and the potential long execution time. In this paper, we explore the possibility of directly leveraging LLM to enable static simulation of robot operation code, and then leverage it to design a new reliable LLM-driven corrective robot operation code generation framework. Our framework configures the LLM as a static simulator with enhanced capabilities that reliably simulate robot code execution by interpreting actions, reasoning over state transitions, analyzing execution outcomes, and generating semantic observations that accurately capture trajectory dynamics. To validate the performance of our framework, we performed experiments on various operation tasks for different robots, including UAVs and small ground vehicles. The experiment results not only demonstrated the high accuracy of our static text-based simulation but also the reliable code generation of our LLM-driven corrective framework, which achieves a comparable performance with state-of-the-art research while does not rely on dynamic code execution using physical experiments or simulators.","authors":["Wenhao Wang","Yi Rong","Yanyan Li","Long Jiao","Jiawei Yuan"],"pdf_url":"","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2601.00548v2","updated":"2026-02-23T22:01:26Z","published":"2026-01-02T03:35:25Z","title":"Optimal Transport-Based Decentralized Multi-Agent Distribution Matching","summary":"This paper presents a decentralized control framework for distribution matching in multi-agent systems (MAS), where agents collectively achieve a prescribed terminal spatial distribution. The problem is formulated using optimal transport (Wasserstein distance), which provides a principled measure of distributional discrepancy and serves as the basis for the control design. To avoid solving the global optimal transport problem directly, the distribution-matching objective is reformulated into a tractable per-agent decision process, enabling each agent to identify its desired terminal locations using only locally available information. A sequential weight-update rule is introduced to construct feasible local transport plans, and a memory-based correction mechanism is incorporated to maintain reliable operation under intermittent and range-limited communication. Convergence guarantees are established, showing cycle-wise improvement of a surrogate transport cost under both linear and nonlinear agent dynamics. Simulation results demonstrate that the proposed framework achieves effective and scalable distribution matching while operating fully in a decentralized manner.","authors":["Kooktae Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20375v1","updated":"2026-02-23T21:25:06Z","published":"2026-02-23T21:25:06Z","title":"Generalizing from References using a Multi-Task Reference and Goal-Driven RL Framework","summary":"Learning agile humanoid behaviors from human motion offers a powerful route to natural, coordinated control, but existing approaches face a persistent trade-off: reference-tracking policies are often brittle outside the demonstration dataset, while purely task-driven Reinforcement Learning (RL) can achieve adaptability at the cost of motion quality. We introduce a unified multi-task RL framework that bridges this gap by treating reference motion as a prior for behavioral shaping rather than a deployment-time constraint. A single goal-conditioned policy is trained jointly on two tasks that share the same observation and action spaces, but differ in their initialization schemes, command spaces, and reward structures: (i) a reference-guided imitation task in which reference trajectories define dense imitation rewards but are not provided as policy inputs, and (ii) a goal-conditioned generalization task in which goals are sampled independently of any reference and where rewards reflect only task success. By co-optimizing these objectives within a shared formulation, the policy acquires structured, human-like motor skills from dense reference supervision while learning to adapt these skills to novel goals and initial conditions. This is achieved without adversarial objectives, explicit trajectory tracking, phase variables, or reference-dependent inference. We evaluate the method on a challenging box-based parkour playground that demands diverse athletic behaviors (e.g., jumping and climbing), and show that the learned controller transfers beyond the reference distribution while preserving motion naturalness. Finally, we demonstrate long-horizon behavior generation by composing multiple learned skills, illustrating the flexibility of the learned polices in complex scenarios.","authors":["Jiashun Wang","M. Eva Mungai","He Li","Jean Pierre Sleiman","Jessica Hodgins","Farbod Farshidian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20362v1","updated":"2026-02-23T21:07:48Z","published":"2026-02-23T21:07:48Z","title":"Energy-Based Injury Protection Database: Including Shearing Contact Thresholds for Hand and Finger Using Porcine Surrogates","summary":"While robotics research continues to propose strategies for collision avoidance in human-robot interaction, the reality of constrained environments and future humanoid systems makes contact inevitable. To mitigate injury risks, energy-constraining control approaches are commonly used, often relying on safety thresholds derived from blunt impact data in EN ISO 10218-2:2025. However, this dataset does not extend to edged or pointed collisions. Without scalable, clinically grounded datasets covering diverse contact scenarios, safety validation remains limited. Previous studies have laid the groundwork by assessing surrogate-based velocity and mass limits across various geometries, focusing on perpendicular impacts. This study expands those datasets by including shearing contact scenarios in unconstrained collisions, revealing that collision angle significantly affects injury outcomes. Notably, unconstrained shearing contacts result in fewer injuries than perpendicular ones. By reevaluating all prior porcine surrogate data, we establish energy thresholds across geometries and contact types, forming the first energy-based Injury Protection Database. This enables the development of meaningful energy-limiting controllers that ensure safety across a wide range of realistic collision events.","authors":["Robin Jeanne Kirschner","Anna Huber","Carina M. Micheler","Dirk Müller","Nader Rajaei","Rainer Burgkart","Sami Haddadin"],"pdf_url":"","comment":"9 pages, 11 figures"},{"id":"http://arxiv.org/abs/2507.23592v3","updated":"2026-02-23T21:05:46Z","published":"2025-07-31T14:29:38Z","title":"Human-Exoskeleton Kinematic Calibration to Improve Hand Tracking for Dexterous Teleoperation","summary":"Hand exoskeletons are critical tools for dexterous teleoperation and immersive manipulation interfaces, but achieving accurate hand tracking remains a challenge due to user-specific anatomical variability and donning inconsistencies. These issues lead to kinematic misalignments that degrade tracking performance and limit applicability in precision tasks. We propose a subject-specific calibration framework for exoskeleton-based hand tracking that estimates virtual link parameters through residual-weighted optimization. A data-driven approach is introduced to empirically tune cost function weights using motion capture ground truth, enabling accurate and consistent calibration across users. Implemented on the Maestro hand exoskeleton with seven healthy participants, the method achieved substantial reductions in joint and fingertip tracking errors across diverse hand geometries. Qualitative visualizations using a Unity-based virtual hand further demonstrate improved motion fidelity. The proposed framework generalizes to exoskeletons with closed-loop kinematics and minimal sensing, laying the foundation for high-fidelity teleoperation and robot learning applications.","authors":["Haiyun Zhang","Stefano Dalla Gasperina","Saad N. Yousaf","Toshimitsu Tsuboi","Tetsuya Narita","Ashish D. Deshpande"],"pdf_url":"","comment":"8 pages, 10 figures, 1 supplementary video, submitted to RA-L"},{"id":"http://arxiv.org/abs/2602.20342v1","updated":"2026-02-23T20:40:26Z","published":"2026-02-23T20:40:26Z","title":"Large-scale Photorealistic Outdoor 3D Scene Reconstruction from UAV Imagery Using Gaussian Splatting Techniques","summary":"In this study, we present an end-to-end pipeline capable of converting drone-captured video streams into high-fidelity 3D reconstructions with minimal latency. Unmanned aerial vehicles (UAVs) are extensively used in aerial real-time perception applications. Moreover, recent advances in 3D Gaussian Splatting (3DGS) have demonstrated significant potential for real-time neural rendering. However, their integration into end-to-end UAV-based reconstruction and visualization systems remains underexplored. Our goal is to propose an efficient architecture that combines live video acquisition via RTMP streaming, synchronized sensor fusion, camera pose estimation, and 3DGS optimization, achieving continuous model updates and low-latency deployment within interactive visualization environments that supports immersive augmented and virtual reality (AR/VR) applications. Experimental results demonstrate that the proposed method achieves competitive visual fidelity, while delivering significantly higher rendering performance and substantially reduced end-to-end latency, compared to NeRF-based approaches. Reconstruction quality remains within 4-7\\% of high-fidelity offline references, confirming the suitability of the proposed system for real-time, scalable augmented perception from aerial platforms.","authors":["Christos Maikos","Georgios Angelidis","Georgios Th. Papadopoulos"],"pdf_url":"","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.20334v1","updated":"2026-02-23T20:31:07Z","published":"2026-02-23T20:31:07Z","title":"UAMTERS: Uncertainty-Aware Mutation Analysis for DL-enabled Robotic Software","summary":"Self-adaptive robots adjust their behaviors in response to unpredictable environmental changes. These robots often incorporate deep learning (DL) components into their software to support functionality such as perception, decision-making, and control, enhancing autonomy and self-adaptability. However, the inherent uncertainty of DL-enabled software makes it challenging to ensure its dependability in dynamic environments. Consequently, test generation techniques have been developed to test robot software, and classical mutation analysis injects faults into the software to assess the test suite's effectiveness in detecting the resulting failures. However, there is a lack of mutation analysis techniques to assess the effectiveness under the uncertainty inherent to DL-enabled software. To this end, we propose UAMTERS, an uncertainty-aware mutation analysis framework that introduces uncertainty-aware mutation operators to explicitly inject stochastic uncertainty into DL-enabled robotic software, simulating uncertainty in its behavior. We further propose mutation score metrics to quantify a test suite's ability to detect failures under varying levels of uncertainty. We evaluate UAMTERS across three robotic case studies, demonstrating that UAMTERS more effectively distinguishes test suite quality and captures uncertainty-induced failures in DL-enabled software.","authors":["Chengjie Lu","Jiahui Wu","Shaukat Ali","Malaika Din Hashmi","Sebastian Mathias Thomle Mason","Francois Picard","Mikkel Labori Olsen","Thomas Peyrucain"],"pdf_url":"","comment":"23 pages, 6 figures, 7 tables"},{"id":"http://arxiv.org/abs/2602.20323v1","updated":"2026-02-23T20:18:35Z","published":"2026-02-23T20:18:35Z","title":"Learning Physical Principles from Interaction: Self-Evolving Planning via Test-Time Memory","summary":"Reliable object manipulation requires understanding physical properties that vary across objects and environments. Vision-language model (VLM) planners can reason about friction and stability in general terms; however, they often cannot predict how a specific ball will roll on a particular surface or which stone will provide a stable foundation without direct experience. We present PhysMem, a memory framework that enables VLM robot planners to learn physical principles from interaction at test time, without updating model parameters. The system records experiences, generates candidate hypotheses, and verifies them through targeted interaction before promoting validated knowledge to guide future decisions. A central design choice is verification before application: the system tests hypotheses against new observations rather than applying retrieved experience directly, reducing rigid reliance on prior experience when physical conditions change. We evaluate PhysMem on three real-world manipulation tasks and simulation benchmarks across four VLM backbones. On a controlled brick insertion task, principled abstraction achieves 76% success compared to 23% for direct experience retrieval, and real-world experiments show consistent improvement over 30-minute deployment sessions.","authors":["Haoyang Li","Yang You","Hao Su","Leonidas Guibas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20304v1","updated":"2026-02-23T19:34:47Z","published":"2026-02-23T19:34:47Z","title":"Smoothly Differentiable and Efficiently Vectorizable Contact Manifold Generation","summary":"Simulating rigid-body dynamics with contact in a fast, massively vectorizable, and smoothly differentiable manner is highly desirable in robotics. An important bottleneck faced by existing differentiable simulation frameworks is contact manifold generation: representing the volume of intersection between two colliding geometries via a discrete set of properly distributed contact points. A major factor contributing to this bottleneck is that the related routines of commonly used robotics simulators were not designed with vectorization and differentiability as a primary concern, and thus rely on logic and control flow that hinder these goals. We instead propose a framework designed from the ground up with these goals in mind, by trying to strike a middle ground between: i) convex primitive based approaches used by common robotics simulators (efficient but not differentiable), and ii) mollified vertex-face and edge-edge unsigned distance-based approaches used by barrier methods (differentiable but inefficient). Concretely, we propose: i) a representative set of smooth analytical signed distance primitives to implement vertex-face collisions, and ii) a novel differentiable edge-edge collision routine that can provide signed distances and signed contact normals. The proposed framework is evaluated via a set of didactic experiments and benchmarked against the collision detection routine of the well-established Mujoco XLA framework, where we observe a significant speedup. Supplementary videos can be found at https://github.com/bekeronur/contax, where a reference implementation in JAX will also be made available at the conclusion of the review process.","authors":["Onur Beker","Andreas René Geist","Anselm Paulus","Nico Gürtler","Ji Shi","Sylvain Calinon","Georg Martius"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20231v1","updated":"2026-02-23T18:41:41Z","published":"2026-02-23T18:41:41Z","title":"UniLACT: Depth-Aware RGB Latent Action Learning for Vision-Language-Action Models","summary":"Latent action representations learned from unlabeled videos have recently emerged as a promising paradigm for pretraining vision-language-action (VLA) models without explicit robot action supervision. However, latent actions derived solely from RGB observations primarily encode appearance-driven dynamics and lack explicit 3D geometric structure, which is essential for precise and contact-rich manipulation. To address this limitation, we introduce UniLACT, a transformer-based VLA model that incorporates geometric structure through depth-aware latent pretraining, enabling downstream policies to inherit stronger spatial priors. To facilitate this process, we propose UniLARN, a unified latent action learning framework based on inverse and forward dynamics objectives that learns a shared embedding space for RGB and depth while explicitly modeling their cross-modal interactions. This formulation produces modality-specific and unified latent action representations that serve as pseudo-labels for the depth-aware pretraining of UniLACT. Extensive experiments in both simulation and real-world settings demonstrate the effectiveness of depth-aware unified latent action representations. UniLACT consistently outperforms RGB-based latent action baselines under in-domain and out-of-domain pretraining regimes, as well as on both seen and unseen manipulation tasks.","authors":["Manish Kumar Govind","Dominick Reilly","Pu Wang","Srijan Das"],"pdf_url":"","comment":"https://manishgovind.github.io/unilact-vla/"},{"id":"http://arxiv.org/abs/2602.20225v1","updated":"2026-02-23T16:38:13Z","published":"2026-02-23T16:38:13Z","title":"FACTO: Function-space Adaptive Constrained Trajectory Optimization for Robotic Manipulators","summary":"This paper introduces Function-space Adaptive Constrained Trajectory Optimization (FACTO), a new trajectory optimization algorithm for both single- and multi-arm manipulators. Trajectory representations are parameterized as linear combinations of orthogonal basis functions, and optimization is performed directly in the coefficient space. The constrained problem formulation consists of both an objective functional and a finite-dimensional objective defined over truncated coefficients. To address nonlinearity, FACTO uses a Gauss-Newton approximation with exponential moving averaging, yielding a smoothed quadratic subproblem. Trajectory-wide constraints are addressed using coefficient-space mappings, and an adaptive constrained update using the Levenberg-Marquardt algorithm is performed in the null space of active constraints. Comparisons with optimization-based planners (CHOMP, TrajOpt, GPMP2) and sampling-based planners (RRT-Connect, RRT*, PRM) show the improved solution quality and feasibility, especially in constrained single- and multi-arm scenarios. The experimental evaluation of FACTO on Franka robots verifies the feasibility of deployment.","authors":["Yichang Feng","Xiao Liang","Minghui Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20220v1","updated":"2026-02-23T10:34:15Z","published":"2026-02-23T10:34:15Z","title":"What Matters for Simulation to Online Reinforcement Learning on Real Robots","summary":"We investigate what specific design choices enable successful online reinforcement learning (RL) on physical robots. Across 100 real-world training runs on three distinct robotic platforms, we systematically ablate algorithmic, systems, and experimental decisions that are typically left implicit in prior work. We find that some widely used defaults can be harmful, while a set of robust, readily adopted design choices within standard RL practice yield stable learning across tasks and hardware. These results provide the first large-sample empirical study of such design choices, enabling practitioners to deploy online RL with lower engineering effort.","authors":["Yarden As","Dhruva Tirumala","René Zurbrügg","Chenhao Li","Stelian Coros","Andreas Krause","Markus Wulfmeier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20219v1","updated":"2026-02-23T09:05:15Z","published":"2026-02-23T09:05:15Z","title":"An Approach to Combining Video and Speech with Large Language Models in Human-Robot Interaction","summary":"Interpreting human intent accurately is a central challenge in human-robot interaction (HRI) and a key requirement for achieving more natural and intuitive collaboration between humans and machines. This work presents a novel multimodal HRI framework that combines advanced vision-language models, speech processing, and fuzzy logic to enable precise and adaptive control of a Dobot Magician robotic arm. The proposed system integrates Florence-2 for object detection, Llama 3.1 for natural language understanding, and Whisper for speech recognition, providing users with a seamless and intuitive interface for object manipulation through spoken commands. By jointly addressing scene perception and action planning, the approach enhances the reliability of command interpretation and execution. Experimental evaluations conducted on consumer-grade hardware demonstrate a command execution accuracy of 75\\%, highlighting both the robustness and adaptability of the system. Beyond its current performance, the proposed architecture serves as a flexible and extensible foundation for future HRI research, offering a practical pathway toward more sophisticated and natural human-robot collaboration through tightly coupled speech and vision-language processing.","authors":["Guanting Shen","Zi Tian"],"pdf_url":"","comment":"Preprint currently under revision"},{"id":"http://arxiv.org/abs/2602.20216v1","updated":"2026-02-23T07:58:08Z","published":"2026-02-23T07:58:08Z","title":"Sample-Efficient Learning with Online Expert Correction for Autonomous Catheter Steering in Endovascular Bifurcation Navigation","summary":"Robot-assisted endovascular intervention offers a safe and effective solution for remote catheter manipulation, reducing radiation exposure while enabling precise navigation. Reinforcement learning (RL) has recently emerged as a promising approach for autonomous catheter steering; however, conventional methods suffer from sparse reward design and reliance on static vascular models, limiting their sample efficiency and generalization to intraoperative variations. To overcome these challenges, this paper introduces a sample-efficient RL framework with online expert correction for autonomous catheter steering in endovascular bifurcation navigation. The proposed framework integrates three key components: (1) A segmentation-based pose estimation module for accurate real-time state feedback, (2) A fuzzy controller for bifurcation-aware orientation adjustment, and (3) A structured reward generator incorporating expert priors to guide policy learning. By leveraging online expert correction, the framework reduces exploration inefficiency and enhances policy robustness in complex vascular structures. Experimental validation on a robotic platform using a transparent vascular phantom demonstrates that the proposed approach achieves convergence in 123 training episodes -- a 25.9% reduction compared to the baseline Soft Actor-Critic (SAC) algorithm -- while reducing average positional error to 83.8% of the baseline. These results indicate that combining sample-efficient RL with online expert correction enables reliable and accurate catheter steering, particularly in anatomically challenging bifurcation scenarios critical for endovascular navigation.","authors":["Hao Wang","Tianliang Yao","Bo Lu","Zhiqiang Pei","Liu Dong","Lei Ma","Peng Qi"],"pdf_url":"","comment":"This paper has been accepted by IEEE ICRA 2026. 8 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2602.20215v1","updated":"2026-02-23T07:39:55Z","published":"2026-02-23T07:39:55Z","title":"Vision-Based Reasoning with Topology-Encoded Graphs for Anatomical Path Disambiguation in Robot-Assisted Endovascular Navigation","summary":"Robotic-assisted percutaneous coronary intervention (PCI) is constrained by the inherent limitations of 2D Digital Subtraction Angiography (DSA). Unlike physicians, who can directly manipulate guidewires and integrate tactile feedback with their prior anatomical knowledge, teleoperated robotic systems must rely solely on 2D projections. This mode of operation, simultaneously lacking spatial context and tactile sensation, may give rise to projection-induced ambiguities at vascular bifurcations. To address this challenge, we propose a two-stage framework (SCAR-UNet-GAT) for real-time robotic path planning. In the first stage, SCAR-UNet, a spatial-coordinate-attention-regularized U-Net, is employed for accurate coronary vessel segmentation. The integration of multi-level attention mechanisms enhances the delineation of thin, tortuous vessels and improves robustness against imaging noise. From the resulting binary masks, vessel centerlines and bifurcation points are extracted, and geometric descriptors (e.g., branch diameter, intersection angles) are fused with local DSA patches to construct node features. In the second stage, a Graph Attention Network (GAT) reasons over the vessel graph to identify anatomically consistent and clinically feasible trajectories, effectively distinguishing true bifurcations from projection-induced false crossings. On a clinical DSA dataset, SCAR-UNet achieved a Dice coefficient of 93.1%. For path disambiguation, the proposed GAT-based method attained a success rate of 95.0% and a target-arrival success rate of 90.0%, substantially outperforming conventional shortest-path planning (60.0% and 55.0%) and heuristic-based planning (75.0% and 70.0%). Validation on a robotic platform further confirmed the practical feasibility and robustness of the proposed framework.","authors":["Jiyuan Zhao","Zhengyu Shi","Wentong Tian","Tianliang Yao","Dong Liu","Tao Liu","Yizhe Wu","Peng Qi"],"pdf_url":"","comment":"This paper has been accepted by IEEE ICRA 2026. 8 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2602.21259v1","updated":"2026-02-23T20:56:21Z","published":"2026-02-23T20:56:21Z","title":"Cross domain Persistent Monitoring for Hybrid Aerial Underwater Vehicles","summary":"Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) have emerged as platforms capable of operating in both aerial and underwater environments, enabling applications such as inspection, mapping, search, and rescue in challenging scenarios. However, the development of novel methodologies poses significant challenges due to the distinct dynamics and constraints of the air and water domains. In this work, we present persistent monitoring tasks for HUAUVs by combining Deep Reinforcement Learning (DRL) and Transfer Learning to enable cross-domain adaptability. Our approach employs a shared DRL architecture trained on Lidar sensor data (on air) and Sonar data (underwater), demonstrating the feasibility of a unified policy for both environments. We further show that the methodology presents promising results, taking into account the uncertainty of the environment and the dynamics of multiple mobile targets. The proposed framework lays the groundwork for scalable autonomous persistent monitoring solutions based on DRL for hybrid aerial-underwater vehicles.","authors":["Ricardo B. Grando","Victor A. Kich","Alisson H. Kolling","Junior C. D. Jesus","Rodrigo S. Guerra","Paulo L. J. Drews-Jr"],"pdf_url":"","comment":"Accepted to the Brazilian Conference on Robotics 2026"}]},"2026-02-22T00:00:00Z":{"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2512.09412v2","updated":"2026-02-22T18:32:32Z","published":"2025-12-10T08:14:19Z","title":"Simple Modal Types for Functional Reactive Programming","summary":"Functional reactive programming (FRP) is a declarative programming paradigm for implementing reactive programs at a high level of abstraction. It applies functional programming principles to construct and manipulate time-varying values, also known as signals. However, for this programming paradigm to work in practice, an FRP language must ensure that programs are causal, productive, and free of space leaks. Over the past fifteen years, several modal type systems to enforce these operational properties have been developed.\n  We present a new FRP language with a significantly simplified modal type system that imposes fewer restrictions than previous modal FRP languages while still guaranteeing the central operational properties of causality, productivity, and absence of space leaks. The key enabling idea is to alter the semantics of signals so that the type system can safely allow more programs to type-check, thereby making the language more expressive, too. With this new semantics, signals are modelled as mutable references whose mutability is tightly controlled by the 'later' type modality. This disciplined form of mutability also enables more efficient in-place updates of signals, all while preserving a functional programming style.","authors":["Patrick Bahr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20204v1","updated":"2026-02-22T19:14:23Z","published":"2026-02-22T19:14:23Z","title":"Analyzing Latency Hiding and Parallelism in an MLIR-based AI Kernel Compiler","summary":"AI kernel compilation for edge devices depends on the compiler's ability to exploit parallelism and hide memory latency in the presence of hierarchical memory and explicit data movement. This paper reports a benchmark methodology and corresponding results for three compiler-controlled mechanisms in an MLIR-based compilation pipeline: vectorization (Vec), multi-threading (MT) across hardware contexts, and double buffering (DB) using ping--pong scratchpad buffers to overlap DMA transfers with compute. Using Triton/Inductor-generated kernels, we present an ablation ladder that separates the contribution of Vec, MT, and DB, and we quantify how MT speedup scales with problem size using GELU as a representative activation kernel. The results show that vectorization provides the primary gain for bandwidth-sensitive kernels, MT delivers substantial improvements once scheduling overhead is amortized, and DB provides additional benefit when transfers and compute can be overlapped (i.e., outside the extremes of purely memory-bound or purely compute-bound behavior).","authors":["Javed Absar","Samarth Narang","Muthu Baskaran"],"pdf_url":"","comment":"Accepted at MLBench workshop as part of ASPLOS'26"}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.19383v1","updated":"2026-02-22T23:31:42Z","published":"2026-02-22T23:31:42Z","title":"On the Variability of Source Code in Maven Package Rebuilds","summary":"Rebuilding packages from open source is a common practice to improve the security of software supply chains, and is now done at an industrial scale. The basic principle is to acquire the source code used to build a package published in a repository such as Maven Central (for Java), rebuild the package independently with hardened security, and publish it in some alternative repository. In this paper we test the assumption that the same source code is being used by those alternative builds. To study this, we compare the sources released with packages on Maven Central, with the sources associated with independently built packages from Google's Assured Open Source and Oracle's Build-from-Source projects. We study non-equivalent sources for alternative builds of 28 popular packages with 85 releases. We investigate the causes of non-equivalence, and find that the main cause is build extensions that generate code at build time, which are difficult to reproduce. We suggest strategies to address this issue.","authors":["Jens Dietrich","Behnaz Hassanshahi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19360v1","updated":"2026-02-22T22:10:25Z","published":"2026-02-22T22:10:25Z","title":"Compliance Management for Federated Data Processing","summary":"Federated data processing (FDP) offers a promising approach for enabling collaborative analysis of sensitive data without centralizing raw datasets. However, real-world adoption remains limited due to the complexity of managing heterogeneous access policies, regulatory requirements, and long-running workflows across organizational boundaries. In this paper, we present a framework for compliance-aware FDP that integrates policy-as-code, workflow orchestration, and large language model (LLM)-assisted compliance management. Through the implemented prototype, we show how legal and organizational requirements can be collected and translated into machine-actionable policies in FDP networks.","authors":["Natallia Kokash","Adam Belloum","Paola Grosso"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19353v1","updated":"2026-02-22T22:02:53Z","published":"2026-02-22T22:02:53Z","title":"Designing and Implementing a Comprehensive Research Software Engineer Career Ladder: A Case Study from Princeton University","summary":"Research Software Engineers (RSEs) have become indispensable to computational research and scholarship. The fast rise of RSEs in higher education and the trend of universities to be slow creating or adopting models for new technology roles means a lack of structured career pathways that recognize technical mastery, scholarly impact, and leadership growth. In response to an immense demand for RSEs at Princeton University, and dedicated funding to grow the RSE group at least two-fold, Princeton was forced to strategize how to cohesively define job descriptions to match the rapid hiring of RSE positions but with enough flexibility to recognize the unique nature of each individual position. This case study describes our design and implementation of a comprehensive RSE career ladder spanning Associate through Principal levels, with parallel team-lead and managerial tracks. We outline the guiding principles, competency framework, Human Resources (HR) alignment, and implementation process, including engagement with external consultants and mapping to a standard job leveling framework utilizing market benchmarks. We share early lessons learned and outcomes including improved hiring efficiency, clearer promotion pathways, and positive reception among staff.","authors":["Ian A. Cosden","Elizabeth Holtz","Joel U. Bretheim"],"pdf_url":"","comment":"Submitted to Future Generation Computer Systems: Special Issue on Research Software Engineering - Software-Enabled Discovery and Beyond"},{"id":"http://arxiv.org/abs/2602.19338v1","updated":"2026-02-22T21:01:58Z","published":"2026-02-22T21:01:58Z","title":"Complex Event Processing in the Edge: A Combined Optimization Approach for Data and Code Placement","summary":"The increasing variety of input data and complexity of tasks that are handled by the devices of internet of things (IoT) environments require solutions that consider the limited hardware and computation power of the edge devices. Complex event processing (CEP), can be given as an example, which involves reading and aggregating data from multiple sources to infer triggering of important events. In this study, we balance the execution costs between different paths of the CEP task graph with a constrained programming optimization approach and improve critical path performance. The proposed approach is implemented as a Python library, allowing small-scale IoT devices to adaptively optimize code and I/O assignments and improve overall latency and throughput. The implemented library abstracts away the communication details and allows virtualization of a shared memory between IoT devices. The results show that optimizing critical path performance increases throughput and reduces delay across multiple devices during CEP operations.","authors":["Halit Uyanık","Tolga Ovatman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2306.07400v2","updated":"2026-02-22T20:29:49Z","published":"2023-06-12T19:59:36Z","title":"Neural Embeddings for Web Testing","summary":"Web test automation techniques often rely on crawlers to infer models of web applications for automated test generation. However, current crawlers rely on state equivalence algorithms that struggle to distinguish near-duplicate pages, often leading to redundant test cases and incomplete coverage of application functionality. In this paper, we present a model-based test generation approach that employs transformer-based Siamese neural networks (SNNs) to infer web application models more accurately. By learning similarity-based representations, SNNs capture structural and textual relationships among web pages, improving near-duplicate detection during crawling and enhancing the quality of inferred models, and thus, the effectiveness of generated test suites. Our evaluation across nine web apps shows that SNNs outperform state-of-the-art techniques in near-duplicate detection, resulting in superior web app models with an average F-1 score improvement of 56%. These enhanced models enable the generation of more effective test suites that achieve higher code coverage, with improvements ranging from 6% to 21% and averaging at 12%.","authors":["Kasun Kanaththage","Luigi Libero Lucio Starace","Matteo Biagiola","Paolo Tonella","Andrea Stocco"],"pdf_url":"","comment":"In proceedings of the 19th IEEE International Conference on Software Testing, Verification and Validation 2026 (ICST '26)"},{"id":"http://arxiv.org/abs/2510.07070v2","updated":"2026-02-22T19:46:23Z","published":"2025-10-08T14:32:31Z","title":"Building an Open AIBOM Standard in the Wild","summary":"Modern software engineering increasingly relies on open, community-driven standards, yet how such standards are created in fast-evolving domains like AI-powered systems remains underexplored. This paper presents a detailed experience report on the development of the AI Bill of Materials AIBOM specification, an extension of the ISO/IEC 5962:2021 Software Package Data Exchange (SPDX) software bill of materials (SBOM) standard, which captures AI components such as datasets and iterative training artifacts. Framed through the lens of Action Research (AR), we document a global, multi-stakeholder effort involving over 90 contributors and structured AR cycles. The resulting specification was validated through four complementary approaches: alignment with major regulations and ethical standards (e.g., EU AI Act and IEEE 7000 standards), systematic mapping to six industry use cases, semi-structured practitioner interviews, and an industrial case study. Beyond delivering a validated artefact, our paper documents the process of building the AIBOM specification in the wild, and reflects on how it aligns with the AR cycle, and distills lessons that can inform future standardization efforts in the software engineering community.","authors":["Gopi Krishnan Rajbahadur","Keheliya Gallaba","Elyas Rashno","Arthit Suriyawongkul","Karen Bennet","Kate Stewart","Ahmed E. Hassan"],"pdf_url":"","comment":"Accepted to be published at the IEEE/ACM 48th International Conference on Software Engineering (ICSE) - Software Engineering in Practice (SEIP) track. April 12 - 18, 2026. Rio de Janeiro, Brazil"},{"id":"http://arxiv.org/abs/2602.19294v1","updated":"2026-02-22T18:06:57Z","published":"2026-02-22T18:06:57Z","title":"Towards Automated Page Object Generation for Web Testing using Large Language Models","summary":"Page Objects (POs) are a widely adopted design pattern for improving the maintainability and scalability of automated end-to-end web tests. However, creating and maintaining POs is still largely a manual, labor-intensive activity, while automated solutions have seen limited practical adoption. In this context, the potential of Large Language Models (LLMs) for these tasks has remained largely unexplored. This paper presents an empirical study on the feasibility of using LLMs, specifically GPT-4o and DeepSeek Coder, to automatically generate POs for web testing. We evaluate the generated artifacts on an existing benchmark of five web applications for which manually written POs are available (the ground truth), focusing on accuracy (i.e., the proportion of ground truth elements correctly identified) and element recognition rate (i.e., the proportion of ground truth elements correctly identified or marked for modification). Our results show that LLMs can generate syntactically correct and functionally useful POs with accuracy values ranging from 32.6% to 54.0% and element recognition rate exceeding 70% in most cases. Our study contributes the first systematic evaluation of LLMs strengths and open challenges for automated PO generation, and provides directions for further research on integrating LLMs into practical testing workflows.","authors":["Betül Karagöz","Filippo Ricca","Matteo Biagiola","Andrea Stocco"],"pdf_url":"","comment":"In proceedings of the 19th IEEE International Conference on Software Testing, Verification and Validation 2026 (ICST '26)"},{"id":"http://arxiv.org/abs/2602.19276v1","updated":"2026-02-22T17:17:16Z","published":"2026-02-22T17:17:16Z","title":"ComUICoder: Component-based Reusable UI Code Generation for Complex Websites via Semantic Segmentation and Element-wise Feedback","summary":"Multimodal Large Language Models (MLLMs) have demonstrated strong performance on the UI-to-code task, which aims to generate UI code from design mock-ups. However, when applied to long and complex websites, they often struggle with fragmented segmentation, redundant code generation for repetitive components, and frequent UI inconsistencies. To systematically investigate and address these challenges, we introduce ComUIBench, a new multi-page complex webpage benchmark with component annotations, designed to evaluate MLLMs' ability to generate reusable UI code in realistic website scenarios. Building upon this benchmark, we propose ComUICoder, a component-based UI code generation framework that emphasizes semantic-aware segmentation, code reuse, and fine-grained refinement. Specifically, ComUICoder incorporates (1) Hybrid Semantic-aware Block Segmentation for accurate UI semantic coherent block detection, (2) Visual-aware Graph-based Block Merge to consolidate structurally similar components within and across webpages for reusable implementation, and (3) Priority-based Element-wise Feedback to refine generated code and reduce element-level inconsistencies. Extensive experiments demonstrate that ComUICoder significantly improves overall generation quality and code reusability on complex multipage websites. Our datasets and code are publicly available at https://github.com/WebPAI/ComUICoder.","authors":["Jingyu Xiao","Jiantong Qin","Shuoqi Li","Man Ho Lam","Yuxuan Wan","Jen-tse Huang","Yintong Huo","Michael R. Lyu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19274v1","updated":"2026-02-22T17:12:31Z","published":"2026-02-22T17:12:31Z","title":"DD-CAM: Minimal Sufficient Explanations for Vision Models Using Delta Debugging","summary":"We introduce a gradient-free framework for identifying minimal, sufficient, and decision-preserving explanations in vision models by isolating the smallest subset of representational units whose joint activation preserves predictions. Unlike existing approaches that aggregate all units, often leading to cluttered saliency maps, our approach, DD-CAM, identifies a 1-minimal subset whose joint activation suffices to preserve the prediction (i.e., removing any unit from the subset alters the prediction). To efficiently isolate minimal sufficient subsets, we adapt delta debugging, a systematic reduction strategy from software debugging, and configure its search strategy based on unit interactions in the classifier head: testing individual units for models with non-interacting units and testing unit combinations for models in which unit interactions exist. We then generate minimal, prediction-preserving saliency maps that highlight only the most essential features. Our experimental evaluation demonstrates that our approach can produce more faithful explanations and achieve higher localization accuracy than the state-of-the-art CAM-based approaches.","authors":["Krishna Khadka","Yu Lei","Raghu N. Kacker","D. Richard Kuhn"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19218v1","updated":"2026-02-22T15:02:00Z","published":"2026-02-22T15:02:00Z","title":"Gecko: A Simulation Environment with Stateful Feedback for Refining Agent Tool Calls","summary":"The ability to use tools is fundamental for large language model (LLM) agents. Given a task, existing systems use LLMs to plan and generate tool calls, which are executed by real-world tools to complete the task. However, tool calls are prone to errors because they are derived merely from LLM intrinsic capabilities. What is more, while it is useful to let LLMs iteratively refine the tool-call sequence using execution results from real tools, this process can be expensive and lead to unsafe results. To improve LLM tool calls and address issues caused by using real tools for refinement, we introduce Gecko, a comprehensive environment that simulates tool responses using a combination of rules and LLMs. Specifically, Gecko checks the validity of tool calls including input arguments and tool names, synthesizes reasonable responses that adhere to the output schema, and assesses whether all task objectives have been achieved. These three types of feedback provided by Gecko allow LLMs to refine their tool calls, forming a simple yet effective test-time scaling method named GATS. On BFCLv3 and $τ^2$-bench, GATS consistently improves the tool calling performance of various LLMs including GPT-4o, GPT-5, and Gemini-3.0-pro. We further discuss working mechanisms of our method and share future possibilities.","authors":["Zeyu Zhang","Guohao Li","Zhenchang Xing","Alexandros Apostolopoulos","Yu Lin Lee","Liang Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.09467v3","updated":"2026-02-22T14:11:21Z","published":"2026-02-10T07:01:13Z","title":"Toward Linking Declined Proposals and Source Code: An Exploratory Study on the Go Repository","summary":"Traceability links are key information sources for software developers, connecting software artifacts. Such links play an important role, particularly between contribution artifacts and their corresponding source code. Through these links, developers can trace the discussions in contributions and uncover design rationales, constraints, and security concerns. Previous studies have mainly examined accepted contributions, while those declined after discussion have been overlooked. Declined-contribution discussions capture valuable design rationale and implicit decision criteria, revealing why features are accepted or rejected. Our prior work also shows developers often revisit and resubmit declined contributions, making traceability to them useful. In this study, we present the first attempt to establish traceability links between declined contributions and related source code. We propose a linking approach and conduct an empirical analysis of the generated links to discuss the factors that affect link generation. As our dataset, we use proposals from the official Go repository, which are GitHub issues used to propose new features or language changes. To link declined proposals to source code, we design an LLM-driven pipeline. Our results show that the pipeline selected the correct granularity for each declined proposal with an accuracy of 0.836, and generated correct links at that granularity with a mean precision of 0.643. To clarify the challenges of linking declined proposals, we conduct a failure analysis of instances where the pipeline failed to generate links. In these cases, discussions were often redundant and lacked concrete information (e.g., details on how the feature should be implemented).","authors":["Sota Nakashima","Masanari Kondo","Mahmoud Alfadel","Aly Ahmad","Toshihiro Nakae","Hidenori Matsuzaki","Yasutaka Kamei"],"pdf_url":"","comment":"11 pages, MSR2026 Technical Track"},{"id":"http://arxiv.org/abs/2512.01356v2","updated":"2026-02-22T13:09:58Z","published":"2025-12-01T07:10:23Z","title":"LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM","summary":"Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.","authors":["Yuxin Zhang","Yuxia Zhang","Zeyu Sun","Yanjie Jiang","Hui Liu"],"pdf_url":"","comment":"This arXiv submission is the author's accepted manuscript"},{"id":"http://arxiv.org/abs/2602.19098v1","updated":"2026-02-22T08:59:27Z","published":"2026-02-22T08:59:27Z","title":"A Systematic Evaluation of Environmental Flakiness in JavaScript Tests","summary":"Test flakiness is a significant issue in industry, affecting test efficiency and product quality. While extensive research has examined the impact of flaky tests, many root causes remain unexplored, particularly in the context of dynamic languages such as JavaScript. In this paper, we conduct a systematic evaluation of the impact of environmental factors on test flakiness in JavaScript. We first executed test suites across multiple environmental configurations to determine whether changes in the environment could lead to flaky behavior. We selected three environmental factors to manipulate: the operating system, the Node.js version, and the browser. We identified a total of 65 environmental flaky projects, with 28 related to operating system issues, five to Node.js version compatibility, 16 to a combination of operating system and Node.js issues, and 17 related to browser compatibility. To address environmental flakiness, we developed a lightweight mitigation approach, js-env-sanitizer, that can sanitize environmental-related flaky tests by skipping and reporting them (rather than failing), allowing CI builds to continue/succeed without rerunning entire test suites. The tool achieves high accuracy with minimal performance or configuration overhead, and currently supports three popular JavaScript testing frameworks (Jest, Mocha, and Vitest)","authors":["Negar Hashemi","Amjed Tahir","August Shi","Shawn Rasheed","Rachel Blagojevic"],"pdf_url":"","comment":"Accepted at ICST 2026"},{"id":"http://arxiv.org/abs/2602.10471v2","updated":"2026-02-22T05:13:04Z","published":"2026-02-11T03:22:51Z","title":"TestExplora: Benchmarking LLMs for Proactive Bug Discovery via Repository-Level Test Generation","summary":"Given that Large Language Models (LLMs) are increasingly applied to automate software development, comprehensive software assurance spans three distinct goals: regression prevention, reactive reproduction, and proactive discovery. Current evaluations systematically overlook the third goal. Specifically, they either treat existing code as ground truth (a compliance trap) for regression prevention, or depend on post-failure artifacts (e.g., issue reports) for bug reproduction-so they rarely surface defects before failures. To bridge this gap, we present TestExplora, a benchmark designed to evaluate LLMs as proactive testers within full-scale, realistic repository environments. TestExplora contains 2,389 tasks from 482 repositories and hides all defect-related signals. Models must proactively find bugs by comparing implementations against documentation-derived intent, using documentation as the oracle. Furthermore, to keep evaluation sustainable and reduce leakage, we propose continuous, time-aware data collection. Our evaluation reveals a significant capability gap: state-of-the-art models achieve a maximum Fail-to-Pass (F2P) rate of only 16.06%. Further analysis indicates that navigating complex cross-module interactions and leveraging agentic exploration are critical to advancing LLMs toward autonomous software quality assurance. Consistent with this, SWEAgent instantiated with GPT-5-mini achieves an F2P of 17.27% and an F2P@5 of 29.7%, highlighting the effectiveness and promise of agentic exploration in proactive bug discovery tasks.","authors":["Steven Liu","Jane Luo","Xin Zhang","Aofan Liu","Hao Liu","Jie Wu","Ziyang Huang","Yangyu Huang","Yu Kang","Scarlett Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.00920v3","updated":"2026-02-22T02:45:05Z","published":"2025-10-01T13:58:19Z","title":"Can Emulating Semantic Translation Help LLMs with Code Translation? A Study Based on Pseudocode","summary":"Although large language models (LLMs) show promising potential in code translation, they still struggle to generate accurate translations using the commonly adopted direct code-to-code translation approach, which converts an original program into the target programming language (PL) in a single step. Inspired by the success of incorporating intermediate steps to guide LLMs in resolving challenging tasks, in this study, we explore pseudocode-based code translation. This approach emulates human semantic translation by first interpreting the original program's intent and logic into pseudocode and then implementing it in the target PL. To understand the effectiveness of this underexplored approach, we present a systematic empirical study on pseudocode-based code translation, aiming to investigate its helpfulness in enhancing the direct translation approach, illuminate its effective usage, and identify its limitations. By comparing direct and pseudocode-based translation on 9,690 translation tasks across six PLs with five popular LLMs, we found that pseudocode-based translation can effectively complement direct translation, particularly when translating from flexible to rigid PLs and handling a low-training-resource PL. Based on the findings, we suggest combining the translation results of both approaches for test-based selection to leverage their complementary strengths. We also reveal the advantages of pseudocode-based translation in decoupling the code understanding and generation burden on complicated programs and mitigating distractions from PL-specific implementations in original programs, as well as its limitations due to incorrect, incomplete, or ambiguous pseudocode. Our study sheds light on the effective use of pseudocode-based translation and provides evidence to help enhance LLMs in code translation.","authors":["Songqiang Chen","Congying Xu","Jingyi Chen","Jialun Cao","Jiarong Wu","Shing-Chi Cheung"],"pdf_url":"","comment":"Accepted by ACM Transactions on Software Engineering and Methodology (TOSEM)"},{"id":"http://arxiv.org/abs/2602.20206v1","updated":"2026-02-22T21:25:04Z","published":"2026-02-22T21:25:04Z","title":"Mitigating \"Epistemic Debt\" in Generative AI-Scaffolded Novice Programming using Metacognitive Scripts","summary":"The democratization of Large Language Models (LLMs) has given rise to ``Vibe Coding,\" a workflow where novice programmers prioritize semantic intent over syntactic implementation. While this lowers barriers to entry, we hypothesize that without pedagogical guardrails, it is fundamentally misaligned with cognitive skill acquisition. Drawing on the distinction between Cognitive Offloading and Cognitive Outsourcing, we argue that unrestricted AI encourages novices to outsource the Intrinsic Cognitive Load required for schema formation, rather than merely offloading Extraneous Load. This accumulation of ``Epistemic Debt\" creates ``Fragile Experts\" whose high functional utility masks critically low corrective competence.\n  To quantify and mitigate this debt, we conducted a between-subjects experiment (N=78) using a custom Cursor IDE plugin backed by Claude 3.5 Sonnet. Participants represented \"AI-Native\" learners across three conditions: Manual (Control), Unrestricted AI (Outsourcing), and Scaffolded AI (Offloading). The Scaffolded condition utilized a novel ``Explanation Gate,\" leveraging a real-time LLM-as-a-Judge framework to enforce a ``Teach-Back\" protocol before generated code could be integrated.\n  Results reveal a ``Collapse of Competence\": while Unrestricted AI users matched the productivity of the Scaffolded group (p < .001 vs. Manual), they suffered a 77% failure rate in a subsequent AI-Blackout maintenance task, compared to only 39% in the Scaffolded group. Qualitative analysis suggests that successful vibe coders naturally engage in self-scaffolding, treating the AI as a consultant rather than a contractor. We discuss the implications for the maintainability of AI-generated software and propose that future learning systems must enforce Metacognitive Friction to prevent the mass production of unmaintainable code.","authors":["Sreecharan Sankaranarayanan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21253v1","updated":"2026-02-22T16:19:51Z","published":"2026-02-22T16:19:51Z","title":"A Physics-Informed Neuro-Fuzzy Framework for Quantum Error Attribution","summary":"As quantum processors scale beyond 100 qubits, distinguishing software bugs from stochastic hardware noise becomes a critical diagnostic challenge. We present a neuro-fuzzy framework that addresses this attribution problem by combining Adaptive Neuro-Fuzzy Inference Systems (ANFIS) with physics-grounded feature engineering. We introduce the Bhattacharyya Veto, a hard physical constraint grounded in the Data Processing Inequality that prevents the classifier from attributing topologically impossible output distributions to noise. Validated on IBM's 156-qubit Heron r2 processor (ibm_fez) across 105 circuits spanning 17 algorithm families, the framework achieves 89.5% effective accuracy (+/- 5.9% CI). The system implements a safe failure mode, flagging 14.3% of ambiguous cases for manual review rather than forcing low-confidence predictions. We resolve key ambiguities -- such as distinguishing correct Grover amplification from bug-induced collapse -- and identify fundamental limits of single-basis diagnostics, including a Z-basis blind spot where phase-flip errors remain statistically invisible. This work establishes a robust, interpretable diagnostic layer that prevents error mitigation techniques from being applied to logically flawed circuits.","authors":["Marwa R. Hassan","Naima Kaabouch"],"pdf_url":"","comment":null}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2404.07831v4","updated":"2026-02-22T20:05:54Z","published":"2024-04-11T15:16:26Z","title":"Protected QR Code-based Anti-counterfeit System for Pharmaceutical Manufacturing","summary":"The pharmaceutical manufacturing faces critical challenges due to the global threat of counterfeit drugs. This paper proposes a new approach of protected QR codes to secure unique product information for safeguarding the pharmaceutical supply chain. The proposed solution integrates secure QR code generation and encrypted data transmission to establish a comprehensive anti-counterfeit ecosystem. The protected QR codes encapsulate product information that cannot be identified using traditional QR code scanners which protect the information against replication and tampering. The system is developed with scalability in mind, which can be easily implemented without introducing any additional modification in the traditional supply chain.","authors":["Md Masruk Aulia","Nitol Saha","Md. Mostafizur Rahman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19319v1","updated":"2026-02-22T19:48:57Z","published":"2026-02-22T19:48:57Z","title":"Health+: Empowering Individuals via Unifying Health Data","summary":"Managing personal health data is a challenge in today's fragmented and institution-centric healthcare ecosystem. Individuals often lack meaningful control over their medical records, which are scattered across incompatible systems and formats. This vision paper presents Health+, a user-centric, multimodal health data management system that empowers individuals (including those with limited technical expertise) to upload, query, and share their data across modalities (e.g., text, images, reports). Rather than aiming for institutional overhaul, Health+ emphasizes individual agency by providing intuitive interfaces and intelligent recommendations for data access and sharing. At the system level, it tackles the complexity of storing, integrating, and securing heterogeneous health records, ensuring both efficiency and privacy. By unifying multimodal data and prioritizing patients, Health+ lays the foundation for a more connected, interpretable, and user-controlled health information ecosystem.","authors":["Sujaya Maiyya","Shantanu Sharma","Avinash Kumar"],"pdf_url":"","comment":"This paper has been accepted in ACM Multimedia 2025"},{"id":"http://arxiv.org/abs/2602.14281v2","updated":"2026-02-22T18:19:38Z","published":"2026-02-15T19:10:00Z","title":"MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents","summary":"The Model Context Protocol (MCP) standardizes tool use for LLM-based agents and enable third-party servers. This openness introduces a security misalignment: agents implicitly trust tools exposed by potentially untrusted MCP servers. However, despite its excellent utility, existing agents typically offer limited validation for third-party MCP servers. As a result, agents remain vulnerable to MCP-based attacks that exploit the misalignment between agents and servers throughout the tool invocation lifecycle. In this paper, we propose MCPShield as a plug-in security cognition layer that mitigates this misalignment and ensures agent security when invoking MCP-based tools. Drawing inspiration from human experience-driven tool validation, MCPShield assists agent forms security cognition with metadata-guided probing before invocation. Our method constrains execution within controlled boundaries while cognizing runtime events, and subsequently updates security cognition by reasoning over historical traces after invocation, building on human post-use reflection on tool behavior. Experiments demonstrate that MCPShield exhibits strong generalization in defending against six novel MCP-based attack scenarios across six widely used agentic LLMs, while avoiding false positives on benign servers and incurring low deployment overhead. Overall, our work provides a practical and robust security safeguard for MCP-based tool invocation in open agent ecosystems.","authors":["Zhenhong Zhou","Yuanhe Zhang","Hongwei Cai","Moayad Aloqaily","Ouns Bouachir","Linsey Pang","Prakhar Mehrotra","Kun Wang","Qingsong Wen"],"pdf_url":"","comment":"21 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2602.19275v1","updated":"2026-02-22T17:16:49Z","published":"2026-02-22T17:16:49Z","title":"KUDA: Knowledge Unlearning by Deviating Representation for Large Language Models","summary":"Large language models (LLMs) acquire a large amount of knowledge through pre-training on vast and diverse corpora. While this endows LLMs with strong capabilities in generation and reasoning, it amplifies risks associated with sensitive, copyrighted, or harmful content in training data.LLM unlearning, which aims to remove specific knowledge encoded within models, is a promising technique to reduce these risks. However, existing LLM unlearning methods often force LLMs to generate random or incoherent answers due to their inability to alter the encoded knowledge precisely. To achieve effective unlearning at the knowledge level of LLMs, we propose Knowledge Unlearning by Deviating representAtion (KUDA). We first utilize causal tracing to locate specific layers for target knowledge storage. We then design a new unlearning objective that induces the model's representations to deviate from its original position in the phase of knowledge removal, thus disrupting the ability to associate with the target knowledge. To resolve the optimization conflicts between forgetting and retention, we employ a relaxation null-space projection mechanism to mitigate the disruption to the representation space of retaining knowledge. Extensive experiments on representative benchmarks, WMDP and MUSE, demonstrate that KUDA outperforms most existing baselines by effectively balancing knowledge removal and model utility retention.","authors":["Ce Fang","Zhikun Zhang","Min Chen","Qing Liu","Lu Zhou","Zhe Liu","Yunjun Gao"],"pdf_url":"","comment":"24 pages, 15 figures"},{"id":"http://arxiv.org/abs/2602.19270v1","updated":"2026-02-22T16:53:14Z","published":"2026-02-22T16:53:14Z","title":"Hagenberg Risk Management Process (Part 2): From Context-Sensitive Triage to Case Analysis With Bowtie and Bayesian Networks","summary":"Risk matrices (heatmaps) are widely used for information and cyber risk management and decision-making, yet they are often too coarse for today's resilience-driven organizational and system landscapes. Likelihood and impact (the two dimensions represented in a heatmap) can vary with operational conditions, third-party dependencies, and the effectiveness of technical and organizational controls. At the same time, organizations cannot afford to analyze and operationalize every identified risk with equal depth using more sophisticated methods, telemetry, and real-time decision logic. We therefore propose a traceable triage pipeline that connects broad, context-sensitive screening with selective deep-dive analysis of material risks.\n  The Hagenberg Risk Management Process presented in this paper integrates three steps: (i) context-aware prioritization using multidimensional polar heatmaps to compare risks across multiple operational states, (ii) Bowtie analysis for triaged risks to structure causes, consequences, and barriers, and (iii) an automated transformation of Bowties into directed acyclic graphs as the structural basis for Bayesian networks. A distinctive feature is the explicit representation of barriers as activation nodes in the resulting graph, making control points visible and preparing for later intervention and what-if analyses. The approach is demonstrated on an instant-payments gateway scenario in which a faulty production change under peak load leads to cascading degradation and transaction loss; DORA serves as the reference framework for resilience requirements. The result is an end-to-end, tool-supported workflow that improves transparency, auditability, and operational readiness from prioritization to monitoring-oriented models.","authors":["Eckehard Hermann","Harald Lampesberger"],"pdf_url":"","comment":"12 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2505.13362v2","updated":"2026-02-22T15:05:53Z","published":"2025-05-19T17:07:00Z","title":"Dynamic Probabilistic Noise Injection for Membership Inference Defense","summary":"Membership Inference Attacks (MIAs) expose privacy risks by determining whether a specific sample was part of a model's training set. These threats are especially serious in sensitive domains such as healthcare and finance. Traditional mitigation techniques, such as static differential privacy, rely on injecting a fixed amount of noise during training or inference. However, this often leads to a detrimental trade-off: the noise may be insufficient to counter sophisticated attacks or, when increased, can substantially degrade model accuracy. To address this limitation, we propose DynaNoise, an adaptive inference-time defense that modulates injected noise based on per-query sensitivity. DynaNoise estimates risk using measures such as Shannon entropy and scales the noise variance accordingly, followed by a smoothing step that re-normalizes the perturbed outputs to preserve predictive utility. We further introduce MIDPUT (Membership Inference Defense Privacy-Utility Trade-off), a scalar metric that captures both privacy gains and accuracy retention. Our evaluation on several benchmark datasets demonstrates that DynaNoise substantially lowers attack success rates while maintaining competitive accuracy, achieving strong overall MIDPUT scores compared to state-of-the-art defenses.","authors":["Javad Forough","Hamed Haddadi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19199v1","updated":"2026-02-22T14:00:54Z","published":"2026-02-22T14:00:54Z","title":"Counted NFT Transfers","summary":"Non-fungible tokens (NFTs) on Ethereum currently follow a binary mobility paradigm: ERC-721 enables unrestricted transfers, whereas SBTs (ERC-5192) prohibit transfers entirely. We identify a design gap in which no standard mechanism supports bounded transferability, where ownership mobility is allowed but limited to a finite number of programmable transfers. We study counted NFT transfers and introduce ERC-7634 as a minimal realization compatible with ERC-721. The design augments each token with a transfer counter and configurable cap L, allowing ownership to evolve under a finite transfer budget. ERC-7634 defines a minimal extension interface with three lightweight functions (transferCountOf, setTransferLimit, and transferLimitOf), two events, and native-transfer hooks, requiring fewer than 60 additional lines of Solidity while preserving full backward compatibility with existing NFT infrastructure.\n  We analyze behavioral and economic consequences of counted transfers. Our results reveal (i) a mobility premium induced by remaining transfer capacity, (ii) a protocol-level costing signal that can deter wash trading in cap-aware markets through irreversible budget consumption, (iii) bounded recursive collateralization enabled by limited ownership turnover, and (iv) associated security and gas-cost implications, including wrapper-bypass trade-offs.\n  Evaluation on calibrated simulations shows that moderate limits (e.g., L = 10) affect fewer than 15% of tokens under representative transfer distributions, while repeated manipulation becomes unprofitable after a few cycles in a cap-aware pricing model; the additional gas overhead remains below 11% per transfer. We further position ERC-7634 within the NFT mobility design space, derive practical cap-selection guidelines, and discuss post-cap ownership outcomes including soulbound conversion, auto-burn, and provenance freeze.","authors":["Qin Wang","Minfeng Qi","Guangsheng Yu","Shiping Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.16224v3","updated":"2026-02-22T13:51:02Z","published":"2025-06-19T11:32:53Z","title":"Malware Classification Leveraging NLP & Machine Learning for Enhanced Accuracy","summary":"This paper investigates the application of natural language processing (NLP)-based n-gram analysis and machine learning techniques to enhance malware classification. We explore how NLP can be used to extract and analyze textual features from malware samples through n-grams, contiguous string or API call sequences. This approach effectively captures distinctive linguistic patterns among malware and benign families, enabling finer-grained classification. We delve into n-gram size selection, feature representation, and classification algorithms. While evaluating our proposed method on real-world malware samples, we observe significantly improved accuracy compared to the traditional methods. By implementing our n-gram approach, we achieved an accuracy of 99.02% across various machine learning algorithms by using hybrid feature selection technique to address high dimensionality. Hybrid feature selection technique reduces the feature set to only 1.6% of the original features.","authors":["Bishwajit Prasad Gond"," Rajneekant","Pushkar Kishore","Durga Prasad Mohapatra"],"pdf_url":"","comment":"After review, I found errors in methodology and results that invalidate the conclusions. Discovered via peer feedback and self-verification, these issues necessitate withdrawal to maintain scientific integrity"},{"id":"http://arxiv.org/abs/2602.19149v1","updated":"2026-02-22T12:30:01Z","published":"2026-02-22T12:30:01Z","title":"ReVision : A Post-Hoc, Vision-Based Technique for Replacing Unacceptable Concepts in Image Generation Pipeline","summary":"Image-generative models are widely deployed across industries. Recent studies show that they can be exploited to produce policy-violating content. Existing mitigation strategies primarily operate at the pre- or mid-generation stages through techniques such as prompt filtering and safety-aware training/fine-tuning. Prior work shows that these approaches can be bypassed and often degrade generative quality. In this work, we propose ReVision, a training-free, prompt-based, post-hoc safety framework for image-generation pipeline. ReVision acts as a last-line defense by analyzing generated images and selectively editing unsafe concepts without altering the underlying generator. It uses the Gemini-2.5-Flash model as a generic policy-violating concept detector, avoiding reliance on multiple category-specific detectors, and performs localized semantic editing to replace unsafe content. Prior post-hoc editing methods often rely on imprecise spatial localization, that undermines usability and limits deployability, particularly in multi-concept scenes. To address this limitation, ReVision introduces a VLM-assisted spatial gating mechanism that enforces instance-consistent localization, enabling precise edits while preserving scene integrity. We evaluate ReVision on a 245-image benchmark covering both single- and multi-concept scenarios. Results show that ReVision (i) improves CLIP-based alignment toward safe prompts by +$0.121$ on average; (ii) significantly improves multi-concept background fidelity (LPIPS $0.166 \\rightarrow 0.058$); (iii) achieves near-complete suppression on category-specific detectors (e.g., NudeNet $70.51 \\rightarrow 0$); and (iv) reduces policy-violating content recognizability in a human moderation study from $95.99\\%$ to $10.16\\%$.","authors":["Gurjot Singh","Prabhjot Singh","Aashima Sharma","Maninder Singh","Ryan Ko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19097v1","updated":"2026-02-22T08:48:49Z","published":"2026-02-22T08:48:49Z","title":"SiGRRW: A Single-Watermark Robust Reversible Watermarking Framework with Guiding Strategy","summary":"Robust reversible watermarking (RRW) enables copyright protection for images while overcoming the limitation of distortion introduced by watermark itself. Current RRW schemes typically employ a two-stage framework, which fails to achieve simultaneous robustness and reversibility within a single watermarking, and functional interference between the two watermarks results in performance degradation in multiple terms such as capacity and imperceptibility. We propose SiGRRW, a single-watermark RRW framework, which is applicable to both generative models and natural images. We introduce a novel guiding strategy to generate guiding images, serving as the guidance for embedding and recovery. The watermark is reversibly embedded with the guiding residual, which can be calculated from both cover images and watermark images. The proposed framework can be deployed either as a plug-and-play watermarking layer at the output stage of generative models, or directly applied to natural images. Extensive experiments demonstrate that SiGRRW effectively enhances imperceptibility and robustness compared to existing RRW schemes while maintaining lossless recovery of cover images, with significantly higher capacity than conventional schemes.","authors":["Zikai Xu","Bin Liu","Weihai Li","Lijunxian Zhang","Nenghai Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19087v1","updated":"2026-02-22T08:01:14Z","published":"2026-02-22T08:01:14Z","title":"Detecting Cybersecurity Threats by Integrating Explainable AI with SHAP Interpretability and Strategic Data Sampling","summary":"The critical need for transparent and trustworthy machine learning in cybersecurity operations drives the development of this integrated Explainable AI (XAI) framework. Our methodology addresses three fundamental challenges in deploying AI for threat detection: handling massive datasets through Strategic Sampling Methodology that preserves class distributions while enabling efficient model development; ensuring experimental rigor via Automated Data Leakage Prevention that systematically identifies and removes contaminated features; and providing operational transparency through Integrated XAI Implementation using SHAP analysis for model-agnostic interpretability across algorithms. Applied to the CIC-IDS2017 dataset, our approach maintains detection efficacy while reducing computational overhead and delivering actionable explanations for security analysts. The framework demonstrates that explainability, computational efficiency, and experimental integrity can be simultaneously achieved, providing a robust foundation for deploying trustworthy AI systems in security operations centers where decision transparency is paramount.","authors":["Norrakith Srisumrith","Sunantha Sodsee"],"pdf_url":"","comment":"10 pages, 6 figures, accepted for publication in ICTIS 2026"},{"id":"http://arxiv.org/abs/2602.19025v1","updated":"2026-02-22T03:27:17Z","published":"2026-02-22T03:27:17Z","title":"Routing-Aware Explanations for Mixture of Experts Graph Models in Malware Detection","summary":"Mixture-of-Experts (MoE) offers flexible graph reasoning by combining multiple views of a graph through a learned router. We investigate routing-aware explanations for MoE graph models in malware detection using control flow graphs (CFGs). Our architecture builds diversity at two levels. At the node level, each layer computes multiple neighborhood statistics and fuses them with an MLP, guided by a degree reweighting factor rho and a pooling choice lambda in {mean, std, max}, producing distinct node representations that capture complementary structural cues in CFGs. At the readout level, six experts, each tied to a specific (rho, lambda) view, output graph-level logits that the router weights into a final prediction. Post-hoc explanations are generated with edge-level attributions per expert and aggregated using the router gates so the rationale reflects both what each expert highlights and how strongly it is selected. Evaluated against single-expert GNN baselines such as GCN, GIN, and GAT on the same CFG dataset, the proposed MoE achieves strong detection accuracy while yielding stable, faithful attributions under sparsity-based perturbations. The results indicate that making the router explicit and combining multi-statistic node encoding with expert-level diversity can improve the transparency of MoE decisions for malware analysis.","authors":["Hossein Shokouhinejad","Roozbeh Razavi-Far","Griffin Higgins","Ali. A Ghorbani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19021v1","updated":"2026-02-22T03:20:49Z","published":"2026-02-22T03:20:49Z","title":"LLM Scalability Risk for Agentic-AI and Model Supply Chain Security","summary":"Large Language Models (LLMs) & Generative AI are transforming cybersecurity, enabling both advanced defenses and new attacks. Organizations now use LLMs for threat detection, code review, and DevSecOps automation, while adversaries leverage them to produce malwares and run targeted social-engineering campaigns. This paper presents a unified analysis integrating offensive and defensive perspectives on GenAI-driven cybersecurity. Drawing on 70 academic, industry, and policy sources, it analyzes the rise of AI-facilitated threats and its implications for global security to ground necessity for scalable defensive mechanisms. We introduce two primary contributions: the LLM Scalability Risk Index (LSRI), a parametric framework to stress-test operational risks when deploying LLMs in security-critical environments & a model-supply-chain framework establishing a verifiable root of trust throughout model lifecycle. We also synthesize defense strategies from platforms like Google Play Protect, Microsoft Security Copilot and outline a governance roadmap for secure, large-scale LLM deployment.","authors":["Kiarash Ahi","Vaibhav Agrawal","Saeed Valizadeh"],"pdf_url":"","comment":"Accepted for publication in Journal of Computer Information Systems (2026). DOI: 10.1080/08874417.2026.2624670"},{"id":"http://arxiv.org/abs/2602.20202v1","updated":"2026-02-22T18:20:49Z","published":"2026-02-22T18:20:49Z","title":"Evaluating the Reliability of Digital Forensic Evidence Discovered by Large Language Model: A Case Study","summary":"The growing reliance on AI-identified digital evidence raises significant concerns about its reliability, particularly as large language models (LLMs) are increasingly integrated into forensic investigations. This paper proposes a structured framework that automates forensic artifact extraction, refines data through LLM-driven analysis, and validates results using a Digital Forensic Knowledge Graph (DFKG). Evaluated on a 13 GB forensic image dataset containing 61 applications, 2,864 databases, and 5,870 tables, the framework ensures artifact traceability and evidentiary consistency through deterministic Unique Identifiers (UIDs) and forensic cross-referencing. We propose this methodology to address challenges in ensuring the credibility and forensic integrity of AI-identified evidence, reducing classification errors, and advancing scalable, auditable methodologies. A comprehensive case study on this dataset demonstrates the framework's effectiveness, achieving over 95 percent accuracy in artifact extraction, strong support of chain-of-custody adherence, and robust contextual consistency in forensic relationships. Key results validate the framework's ability to enhance reliability, reduce errors, and establish a legally sound paradigm for AI-assisted digital forensics.","authors":["Jeel Piyushkumar Khatiwala","Daniel Kwaku Ntiamoah Addai","Weifeng Xu"],"pdf_url":"","comment":"10 pages, 5 figures. Published in the Proceedings of the 2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC), Toronto, ON, Canada, 8-11 July 2025"},{"id":"http://arxiv.org/abs/2602.20196v1","updated":"2026-02-22T05:16:40Z","published":"2026-02-22T05:16:40Z","title":"OpenPort Protocol: A Security Governance Specification for AI Agent Tool Access","summary":"AI agents increasingly require direct, structured access to application data and actions, but production deployments still struggle to express and verify the governance properties that matter in practice: least-privilege authorization, controlled write execution, predictable failure handling, abuse resistance, and auditability. This paper introduces OpenPort Protocol (OPP), a governance-first specification for exposing application tools through a secure server-side gateway that is model- and runtime-neutral and can bind to existing tool ecosystems. OpenPort defines authorization-dependent discovery, stable response envelopes with machine-actionable \\texttt{agent.*} reason codes, and an authorization model combining integration credentials, scoped permissions, and ABAC-style policy constraints. For write operations, OpenPort specifies a risk-gated lifecycle that defaults to draft creation and human review, supports time-bounded auto-execution under explicit policy, and enforces high-risk safeguards including preflight impact binding and idempotency. To address time-of-check/time-of-use drift in delayed approval flows, OpenPort also specifies an optional State Witness profile that revalidates execution-time preconditions and fails closed on state mismatch. Operationally, the protocol requires admission control (rate limits/quotas) with stable 429 semantics and structured audit events across allow/deny/fail paths so that client recovery and incident analysis are deterministic. We present a reference runtime and an executable governance toolchain (layered conformance profiles, negative security tests, fuzz/abuse regression, and release-gate scans) and evaluate the core profile at a pinned release tag using artifact-based, externally reproducible validation.","authors":["Genliang Zhu","Chu Wang","Ziyuan Wang","Zhida Li","Qiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21252v1","updated":"2026-02-22T07:38:46Z","published":"2026-02-22T07:38:46Z","title":"INTACT: Intent-Aware Representation Learning for Cryptographic Traffic Violation Detection","summary":"Security monitoring systems typically treat anomaly detection as identifying statistical deviations from observed data distributions. In cryptographic traffic analysis, however, violations are defined not by rarity but by explicit policy constraints, including key reuse prohibition, downgrade prevention, and bounded key lifetimes. This fundamental mismatch limits the interpretability and adaptability of conventional anomaly detection methods. We introduce INTACT (INTent-Aware Cryptographic Traffic), a policy-conditioned framework that reformulates violation detection as conditional constraint learning. Instead of learning a static decision boundary over behavioral features, INTACT models the probability of violation conditioned on both observed behavior and declared security intent. The architecture factorizes representation learning into behavioral and intent encoders whose fused embeddings produce a violation score, yielding a policy-parameterized family of decision boundaries. We evaluate the framework on a real-world network flow dataset and a 210,000-trace synthetic multi-intent cryptographic dataset. INTACT matches or exceeds strong unsupervised and supervised baselines, achieving near-perfect discrimination (AUROC up to 1.0000) in the real dataset and consistent superiority in detecting relational and composite violations in the synthetic setting. These results demonstrate that explicit intent conditioning improves discrimination, interpretability, and robustness in cryptographic monitoring.","authors":["Rahul D Ray"],"pdf_url":"","comment":"13 pages, 3 figures"}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2510.09469v2","updated":"2026-02-22T23:52:42Z","published":"2025-10-10T15:25:40Z","title":"Towards Information-Optimized Multi-Agent Path Finding: A Hybrid Framework with Reduced Inter-Agent Information Sharing","summary":"Multi-agent pathfinding (MAPF) remains a critical problem in robotics and autonomous systems, where agents must navigate shared spaces efficiently while avoiding conflicts. Traditional centralized algorithms with global information provide high-quality solutions but scale poorly in large-scale scenarios due to the combinatorial explosion of conflicts. Conversely, distributed approaches that have local information, particularly learning-based methods, offer better scalability by operating with relaxed information availability, yet often at the cost of solution quality. In realistic deployments, information is a constrained resource: broadcasting full agent states and goals can raise privacy concerns, strain limited bandwidth, and require extra sensing and communication hardware, increasing cost and energy use. We focus on the core question of how MAPF can be solved with minimal inter-agent information sharing while preserving solution feasibility. To this end, we present an information-centric formulation of the MAPF problem and introduce a hybrid framework, IO-MAPF, that integrates decentralized path planning with a lightweight centralized coordinator. In this framework, agents use reinforcement learning (RL) to plan independently, while the central coordinator provides minimal, targeted signals, such as static conflict-cell indicators or short conflict trajectories, that are dynamically shared to support efficient conflict resolution. We introduce an Information Units (IU) metric to quantify information use and show that our alert-driven design achieves 2x to 23x reduction in information sharing, compared to the state-of-the-art algorithms, while maintaining high success rates, demonstrating that reliable MAPF is achievable under strongly information-restricted, privacy-preserving conditions. We demonstrate the effectiveness of our algorithm using simulation and hardware experiments.","authors":["Bharath Muppasani","Ritirupa Dey","Biplav Srivastava","Vignesh Narayanan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19372v1","updated":"2026-02-22T22:53:16Z","published":"2026-02-22T22:53:16Z","title":"Seeing Farther and Smarter: Value-Guided Multi-Path Reflection for VLM Policy Optimization","summary":"Solving complex, long-horizon robotic manipulation tasks requires a deep understanding of physical interactions, reasoning about their long-term consequences, and precise high-level planning. Vision-Language Models (VLMs) offer a general perceive-reason-act framework for this goal. However, previous approaches using reflective planning to guide VLMs in correcting actions encounter significant limitations. These methods rely on inefficient and often inaccurate implicit learning of state-values from noisy foresight predictions, evaluate only a single greedy future, and suffer from substantial inference latency. To address these limitations, we propose a novel test-time computation framework that decouples state evaluation from action generation. This provides a more direct and fine-grained supervisory signal for robust decision-making. Our method explicitly models the advantage of an action plan, quantified by its reduction in distance to the goal, and uses a scalable critic to estimate. To address the stochastic nature of single-trajectory evaluation, we employ beam search to explore multiple future paths and aggregate them during decoding to model their expected long-term returns, leading to more robust action generation. Additionally, we introduce a lightweight, confidence-based trigger that allows for early exit when direct predictions are reliable, invoking reflection only when necessary. Extensive experiments on diverse, unseen multi-stage robotic manipulation tasks demonstrate a 24.6% improvement in success rate over state-of-the-art baselines, while significantly reducing inference time by 56.5%.","authors":["Yanting Yang","Shenyuan Gao","Qingwen Bu","Li Chen","Dimitris N. Metaxas"],"pdf_url":"","comment":"ICRA 2026"},{"id":"http://arxiv.org/abs/2602.19366v1","updated":"2026-02-22T22:36:37Z","published":"2026-02-22T22:36:37Z","title":"Self-Configurable Mesh-Networks for Scalable Distributed Submodular Bandit Optimization","summary":"We study how to scale distributed bandit submodular coordination under realistic communication constraints in bandwidth, data rate, and connectivity. We are motivated by multi-agent tasks of active situational awareness in unknown, partially-observable, and resource-limited environments, where the agents must coordinate through agent-to-agent communication. Our approach enables scalability by (i) limiting information relays to only one-hop communication and (ii) keeping inter-agent messages small, having each agent transmit only its own action information. Despite these information-access restrictions, our approach enables near-optimal action coordination by optimizing the agents' communication neighborhoods over time, through distributed online bandit optimization, subject to the agents' bandwidth constraints. Particularly, our approach enjoys an anytime suboptimality bound that is also strictly positive for arbitrary network topologies, even disconnected. To prove the bound, we define the Value of Coordination (VoC), an information-theoretic metric that quantifies for each agent the benefit of information access to its neighbors. We validate in simulations the scalability and near-optimality of our approach: it is observed to converge faster, outperform benchmarks for bandit submodular coordination, and can even outperform benchmarks that are privileged with a priori knowledge of the environment.","authors":["Zirui Xu","Vasileios Tzoumas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.25850v2","updated":"2026-02-22T22:15:58Z","published":"2025-10-29T18:00:16Z","title":"Debate2Create: Robot Co-design via Multi-Agent LLM Debate","summary":"We introduce Debate2Create (D2C), a multi-agent LLM framework that formulates robot co-design as structured, iterative debate grounded in physics-based evaluation. A design agent and control agent engage in a thesis-antithesis-synthesis loop, while pluralistic LLM judges provide multi-objective feedback to steer exploration. Across five MuJoCo locomotion benchmarks, D2C achieves up to $3.2\\times$ the default Ant score and $\\sim9\\times$ on Swimmer, outperforming prior LLM-based methods and black-box optimization. Iterative debate yields 18--35% gains over compute-matched zero-shot generation, and D2C-generated rewards transfer to default morphologies in 4/5 tasks. Our results demonstrate that structured multi-agent debate offers an effective alternative to hand-designed objectives for joint morphology-reward optimization.","authors":["Kevin Qiu","Marek Cygan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19359v1","updated":"2026-02-22T22:08:16Z","published":"2026-02-22T22:08:16Z","title":"Vid2Sid: Videos Can Help Close the Sim2Real Gap","summary":"Calibrating a robot simulator's physics parameters (friction, damping, material stiffness) to match real hardware is often done by hand or with black-box optimizers that reduce error but cannot explain which physical discrepancies drive the error. When sensing is limited to external cameras, the problem is further compounded by perception noise and the absence of direct force or state measurements. We present Vid2Sid, a video-driven system identification pipeline that couples foundation-model perception with a VLM-in-the-loop optimizer that analyzes paired sim-real videos, diagnoses concrete mismatches, and proposes physics parameter updates with natural language rationales. We evaluate our approach on a tendon-actuated finger (rigid-body dynamics in MuJoCo) and a deformable continuum tentacle (soft-body dynamics in PyElastica). On sim2real holdout controls unseen during training, Vid2Sid achieves the best average rank across all settings, matching or exceeding black-box optimizers while uniquely providing interpretable reasoning at each iteration. Sim2sim validation confirms that Vid2Sid recovers ground-truth parameters most accurately (mean relative error under 13\\% vs. 28--98\\%), and ablation analysis reveals three calibration regimes. VLM-guided optimization excels when perception is clean and the simulator is expressive, while model-class limitations bound performance in more challenging settings.","authors":["Kevin Qiu","Yu Zhang","Marek Cygan","Josie Hughes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19346v1","updated":"2026-02-22T21:25:05Z","published":"2026-02-22T21:25:05Z","title":"Design and Control of Modular Magnetic Millirobots for Multimodal Locomotion and Shape Reconfiguration","summary":"Modular small-scale robots offer the potential for on-demand assembly and disassembly, enabling task-specific adaptation in dynamic and constrained environments. However, existing modular magnetic platforms often depend on workspace collisions for reconfiguration, employ bulky three-dimensional electromagnetic systems, and lack robust single-module control, which limits their applicability in biomedical settings. In this work, we present a modular magnetic millirobotic platform comprising three cube-shaped modules with embedded permanent magnets, each designed for a distinct functional role: a free module that supports self-assembly and reconfiguration, a fixed module that enables flip-and-walk locomotion, and a gripper module for cargo manipulation. Locomotion and reconfiguration are actuated by programmable combinations of time-varying two-dimensional uniform and gradient magnetic field inputs. Experiments demonstrate closed-loop navigation using real-time vision feedback and A* path planning, establishing robust single-module control capabilities. Beyond locomotion, the system achieves self-assembly, multimodal transformations, and disassembly at low field strengths. Chain-to-gripper transformations succeeded in 90% of trials, while chain-to-square transformations were less consistent, underscoring the role of module geometry in reconfiguration reliability. These results establish a versatile modular robotic platform capable of multimodal behavior and robust control, suggesting a promising pathway toward scalable and adaptive task execution in confined environments.","authors":["Erik Garcia Oyono","Jialin Lin","Dandan Zhang"],"pdf_url":"","comment":"Accepted by 2026 ICRA"},{"id":"http://arxiv.org/abs/2602.19315v1","updated":"2026-02-22T19:34:10Z","published":"2026-02-22T19:34:10Z","title":"Online Navigation Planning for Long-term Autonomous Operation of Underwater Gliders","summary":"Underwater glider robots have become an indispensable tool for ocean sampling. Although stakeholders are calling for tools to manage increasingly large fleets of gliders, successful autonomous long-term deployments have thus far been scarce, which hints at a lack of suitable methodologies and systems. In this work, we formulate glider navigation planning as a stochastic shortest-path Markov Decision Process and propose a sample-based online planner based on Monte Carlo Tree Search. Samples are generated by a physics-informed simulator that captures uncertain execution of controls and ocean current forecasts while remaining computationally tractable. The simulator parameters are fitted using historical glider data. We integrate these methods into an autonomous command-and-control system for Slocum gliders that enables closed-loop replanning at each surfacing. The resulting system was validated in two field deployments in the North Sea totalling approximately 3 months and 1000 km of autonomous operation. Results demonstrate improved efficiency compared to straight-to-goal navigation and show the practicality of sample-based planning for long-term marine autonomy.","authors":["Victor-Alexandru Darvariu","Charlotte Z. Reed","Jan Stratmann","Bruno Lacerda","Benjamin Allsup","Stephen Woodward","Elizabeth Siddle","Trishna Saeharaseelan","Owain Jones","Dan Jones","Tobias Ferreira","Chloe Baker","Kevin Chaplin","James Kirk","Ashley Morris","Ryan Patmore","Jeff Polton","Charlotte Williams","Alexandra Kokkinaki","Alvaro Lorenzo Lopez","Justin J. H. Buck","Nick Hawes"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19313v1","updated":"2026-02-22T19:25:48Z","published":"2026-02-22T19:25:48Z","title":"TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics","summary":"While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, their advancement in Reinforcement Learning (RL) remains hampered by low sample efficiency and sparse rewards in real-world settings. Developing generalizable process reward models is essential for providing the fine-grained feedback necessary to bridge this gap, yet existing temporal value functions often fail to generalize beyond their training domains. We introduce TOPReward, a novel, probabilistically grounded temporal value function that leverages the latent world knowledge of pretrained video Vision-Language Models (VLMs) to estimate robotic task progress. Unlike prior methods that prompt VLMs to directly output progress values, which are prone to numerical misrepresentation, TOPReward extracts task progress directly from the VLM's internal token logits. In zero-shot evaluations across 130+ distinct real-world tasks and multiple robot platforms (e.g., Franka, YAM, SO-100/101), TOPReward achieves 0.947 mean Value-Order Correlation (VOC) on Qwen3-VL, dramatically outperforming the state-of-the-art GVL baseline which achieves near-zero correlation on the same open-source model. We further demonstrate that TOPReward serves as a versatile tool for downstream applications, including success detection and reward-aligned behavior cloning.","authors":["Shirui Chen","Cole Harrison","Ying-Chun Lee","Angela Jin Yang","Zhongzheng Ren","Lillian J. Ratliff","Jiafei Duan","Dieter Fox","Ranjay Krishna"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19308v1","updated":"2026-02-22T19:14:00Z","published":"2026-02-22T19:14:00Z","title":"WildOS: Open-Vocabulary Object Search in the Wild","summary":"Autonomous navigation in complex, unstructured outdoor environments requires robots to operate over long ranges without prior maps and limited depth sensing. In such settings, relying solely on geometric frontiers for exploration is often insufficient. In such settings, the ability to reason semantically about where to go and what is safe to traverse is crucial for robust, efficient exploration. This work presents WildOS, a unified system for long-range, open-vocabulary object search that combines safe geometric exploration with semantic visual reasoning. WildOS builds a sparse navigation graph to maintain spatial memory, while utilizing a foundation-model-based vision module, ExploRFM, to score frontier nodes of the graph. ExploRFM simultaneously predicts traversability, visual frontiers, and object similarity in image space, enabling real-time, onboard semantic navigation tasks. The resulting vision-scored graph enables the robot to explore semantically meaningful directions while ensuring geometric safety. Furthermore, we introduce a particle-filter-based method for coarse localization of the open-vocabulary target query, that estimates candidate goal positions beyond the robot's immediate depth horizon, enabling effective planning toward distant goals. Extensive closed-loop field experiments across diverse off-road and urban terrains demonstrate that WildOS enables robust navigation, significantly outperforming purely geometric and purely vision-based baselines in both efficiency and autonomy. Our results highlight the potential of vision foundation models to drive open-world robotic behaviors that are both semantically informed and geometrically grounded. Project Page: https://leggedrobotics.github.io/wildos/","authors":["Hardik Shah","Erica Tevere","Deegan Atha","Marcel Kaufmann","Shehryar Khattak","Manthan Patel","Marco Hutter","Jonas Frey","Patrick Spieler"],"pdf_url":"","comment":"28 pages, 16 figures, 2 tables"},{"id":"http://arxiv.org/abs/2602.19304v1","updated":"2026-02-22T18:57:07Z","published":"2026-02-22T18:57:07Z","title":"Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation","summary":"Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In this work, we focus on path-level cooperation in which agents must adapt their paths to one another in order to avoid collisions or perform physical collaboration such as joint carrying. In particular, we propose a safe and interpretable multimodal path planning method, CaPE (Code as Path Editor), which generates and updates path plans for an agent based on the environment and language communication from other agents. CaPE leverages a vision-language model (VLM) to synthesize a path editing program verified by a model-based planner, grounding communication to path plan updates in a safe and interpretable way. We evaluate our approach in diverse simulated and real-world scenarios, including multi-robot and human-robot cooperation in autonomous driving, household, and joint carrying tasks. Experimental results demonstrate that CaPE can be integrated into different robotic systems as a plug-and-play module, greatly enhancing a robot's ability to align its plan to language communication from other robots or humans. We also show that the combination of the VLM-based path editing program synthesis and model-based planning safety enables robots to achieve open-ended cooperation while maintaining safety and interpretability.","authors":["Haojun Shi","Suyu Ye","Katherine M. Guerrerio","Jianzhi Shen","Yifan Yin","Daniel Khashabi","Chien-Ming Huang","Tianmin Shu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19273v1","updated":"2026-02-22T17:06:16Z","published":"2026-02-22T17:06:16Z","title":"3D Shape Control of Extensible Multi-Section Soft Continuum Robots via Visual Servoing","summary":"In this paper, we propose a novel vision-based control algorithm for regulating the whole body shape of extensible multisection soft continuum manipulators. Contrary to existing vision-based control algorithms in the literature that regulate the robot's end effector pose, our proposed control algorithm regulates the robot's whole body configuration, enabling us to leverage its kinematic redundancy. Additionally, our model-based 2.5D shape visual servoing provides globally stable asymptotic convergence in the robot's 3D workspace compared to the closest works in the literature that report local minima. Unlike existing visual servoing algorithms in the literature, our approach does not require information from proprioceptive sensors, making it suitable for continuum manipulators without such capabilities. Instead, robot state is estimated from images acquired by an external camera that observes the robot's whole body shape and is also utilized to close the shape control loop. Traditionally, visual servoing schemes require an image of the robot at its reference pose to generate the reference features. In this work, we utilize an inverse kinematics solver to generate reference features for the desired robot configuration and do not require images of the robot at the reference. Experiments are performed on a multisection continuum manipulator demonstrating the controller's capability to regulate the robot's whole body shape while precisely positioning the robot's end effector. Results validate our controller's ability to regulate the shape of continuum robots while demonstrating a smooth transient response and a steady-state error within 1 mm. Proof-of-concept object manipulation experiments including stacking, pouring, and pulling tasks are performed to demonstrate our controller's applicability.","authors":["Abhinav Gandhi","Shou-Shan Chiang","Cagdas D. Onal","Berk Calli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19260v1","updated":"2026-02-22T16:22:06Z","published":"2026-02-22T16:22:06Z","title":"The Price Is Not Right: Neuro-Symbolic Methods Outperform VLAs on Structured Long-Horizon Manipulation Tasks with Significantly Lower Energy Consumption","summary":"Vision-Language-Action (VLA) models have recently been proposed as a pathway toward generalist robotic policies capable of interpreting natural language and visual inputs to generate manipulation actions. However, their effectiveness and efficiency on structured, long-horizon manipulation tasks remain unclear. In this work, we present a head-to-head empirical comparison between a fine-tuned open-weight VLA model π0 and a neuro-symbolic architecture that combines PDDL-based symbolic planning with learned low-level control. We evaluate both approaches on structured variants of the Towers of Hanoi manipulation task in simulation while measuring both task performance and energy consumption during training and execution. On the 3-block task, the neuro-symbolic model achieves 95% success compared to 34% for the best-performing VLA. The neuro-symbolic model also generalizes to an unseen 4-block variant (78% success), whereas both VLAs fail to complete the task. During training, VLA fine-tuning consumes nearly two orders of magnitude more energy than the neuro-symbolic approach. These results highlight important trade-offs between end-to-end foundation-model approaches and structured reasoning architectures for long-horizon robotic manipulation, emphasizing the role of explicit symbolic structure in improving reliability, data efficiency, and energy efficiency. Code and models are available at https://price-is-not-right.github.io","authors":["Timothy Duggan","Pierrick Lorang","Hong Lu","Matthias Scheutz"],"pdf_url":"","comment":"Accepted at the 2026 IEEE International Conference on Robotics & Automation (ICRA 2026)"},{"id":"http://arxiv.org/abs/2602.19193v1","updated":"2026-02-22T13:48:38Z","published":"2026-02-22T13:48:38Z","title":"Visual Prompt Guided Unified Pushing Policy","summary":"As one of the simplest non-prehensile manipulation skills, pushing has been widely studied as an effective means to rearrange objects. Existing approaches, however, typically rely on multi-step push plans composed of pre-defined pushing primitives with limited application scopes, which restrict their efficiency and versatility across different scenarios. In this work, we propose a unified pushing policy that incorporates a lightweight prompting mechanism into a flow matching policy to guide the generation of reactive, multimodal pushing actions. The visual prompt can be specified by a high-level planner, enabling the reuse of the pushing policy across a wide range of planning problems. Experimental results demonstrate that the proposed unified pushing policy not only outperforms existing baselines but also effectively serves as a low-level primitive within a VLM-guided planning framework to solve table-cleaning tasks efficiently.","authors":["Hieu Bui","Ziyan Gao","Yuya Hosoda","Joo-Ho Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19184v1","updated":"2026-02-22T13:26:27Z","published":"2026-02-22T13:26:27Z","title":"Human-to-Robot Interaction: Learning from Video Demonstration for Robot Imitation","summary":"Learning from Demonstration (LfD) offers a promising paradigm for robot skill acquisition. Recent approaches attempt to extract manipulation commands directly from video demonstrations, yet face two critical challenges: (1) general video captioning models prioritize global scene features over task-relevant objects, producing descriptions unsuitable for precise robotic execution, and (2) end-to-end architectures coupling visual understanding with policy learning require extensive paired datasets and struggle to generalize across objects and scenarios. To address these limitations, we propose a novel ``Human-to-Robot'' imitation learning pipeline that enables robots to acquire manipulation skills directly from unstructured video demonstrations, inspired by the human ability to learn by watching and imitating. Our key innovation is a modular framework that decouples the learning process into two distinct stages: (1) Video Understanding, which combines Temporal Shift Modules (TSM) with Vision-Language Models (VLMs) to extract actions and identify interacted objects, and (2) Robot Imitation, which employs TD3-based deep reinforcement learning to execute the demonstrated manipulations. We validated our approach in PyBullet simulation environments with a UR5e manipulator and in a real-world experiment with a UF850 manipulator across four fundamental actions: reach, pick, move, and put. For video understanding, our method achieves 89.97% action classification accuracy and BLEU-4 scores of 0.351 on standard objects and 0.265 on novel objects, representing improvements of 76.4% and 128.4% over the best baseline, respectively. For robot manipulation, our framework achieves an average success rate of 87.5% across all actions, with 100% success on reaching tasks and up to 90% on complex pick-and-place operations. The project website is available at https://thanhnguyencanh.github.io/LfD4hri.","authors":["Thanh Nguyen Canh","Thanh-Tuan Tran","Haolan Zhang","Ziyan Gao","Nak Young Chong","Xiem HoangVan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19179v1","updated":"2026-02-22T13:18:45Z","published":"2026-02-22T13:18:45Z","title":"Distributional Stability of Tangent-Linearized Gaussian Inference on Smooth Manifolds","summary":"Gaussian inference on smooth manifolds is central to robotics, but exact marginalization and conditioning are generally non-Gaussian and geometry-dependent. We study tangent-linearized Gaussian inference and derive explicit non-asymptotic $W_2$ stability bounds for projection marginalization and surface-measure conditioning. The bounds separate local second-order geometric distortion from nonlocal tail leakage and, for Gaussian inputs, yield closed-form diagnostics from $(μ,Σ)$ and curvature/reach surrogates. Circle and planar-pushing experiments validate the predicted calibration transition near $\\sqrt{\\|Σ\\|_{\\mathrm{op}}}/R\\approx 1/6$ and indicate that normal-direction uncertainty is the dominant failure mode when locality breaks. These diagnostics provide practical triggers for switching from single-chart linearization to multi-chart or sample-based manifold inference.","authors":["Junghoon Seo","Hakjin Lee","Jaehoon Sim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19173v1","updated":"2026-02-22T13:07:50Z","published":"2026-02-22T13:07:50Z","title":"Distributed and Consistent Multi-Robot Visual-Inertial-Ranging Odometry on Lie Groups","summary":"Reliable localization is a fundamental requirement for multi-robot systems operating in GPS-denied environments. Visual-inertial odometry (VIO) provides lightweight and accurate motion estimation but suffers from cumulative drift in the absence of global references. Ultra-wideband (UWB) ranging offers complementary global observations, yet most existing UWB-aided VIO methods are designed for single-robot scenarios and rely on pre-calibrated anchors, which limits their robustness in practice. This paper proposes a distributed collaborative visual-inertial-ranging odometry (DC-VIRO) framework that tightly fuses VIO and UWB measurements across multiple robots. Anchor positions are explicitly included in the system state to address calibration uncertainty, while shared anchor observations are exploited through inter-robot communication to provide additional geometric constraints. By leveraging a right-invariant error formulation on Lie groups, the proposed approach preserves the observability properties of standard VIO, ensuring estimator consistency. Simulation results with multiple robots demonstrate that DC-VIRO significantly improves localization accuracy and robustness, while simultaneously enabling anchor self-calibration in distributed settings.","authors":["Ziwei Kang","Yizhi Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.13762v2","updated":"2026-02-22T10:55:25Z","published":"2026-02-14T13:16:46Z","title":"Impact-Robust Posture Optimization for Aerial Manipulation","summary":"We present a novel method for optimizing the posture of kinematically redundant torque-controlled robots to improve robustness during impacts. A rigid impact model is used as the basis for a configuration-dependent metric that quantifies the variation between pre- and post-impact velocities. By finding configurations (postures) that minimize the aforementioned metric, spikes in the robot's state and input commands can be significantly reduced during impacts, improving safety and robustness. The problem of identifying impact-robust postures is posed as a min-max optimization of the aforementioned metric. To overcome the real-time intractability of the problem, we reformulate it as a gradient-based motion task that iteratively guides the robot towards configurations that minimize the proposed metric. This task is embedded within a task-space inverse dynamics (TSID) whole-body controller, enabling seamless integration with other control objectives. The method is applied to a kinematically redundant aerial manipulator performing repeated point contact tasks. We test our method inside a realistic physics simulator and compare it with the nominal TSID. Our method leads to a reduction (up to 51% w.r.t. standard TSID) of post-impact spikes in the robot's configuration and successfully avoids actuator saturation. Moreover, we demonstrate the importance of kinematic redundancy for impact robustness using additional numerical simulations on a quadruped and a humanoid robot, resulting in up to 45% reduction of post-impact spikes in the robot's state w.r.t. nominal TSID.","authors":["Amr Afifi","Ahmad Gazar","Javier Alonso-Mora","Paolo Robuffo Giordano","Antonio Franchi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.12206v3","updated":"2026-02-22T10:30:53Z","published":"2025-10-14T06:56:33Z","title":"Controllable Collision Scenario Generation via Collision Pattern Prediction","summary":"Evaluating the safety of autonomous vehicles (AVs) requires diverse, safety-critical scenarios, with collisions being especially important yet rare and unsafe to collect in the real world. Therefore, the community has been focusing on generating safety-critical scenarios in simulation. However, controlling attributes such as collision type and time-to-accident (TTA) remains challenging. We introduce a new task called controllable collision scenario generation, where the goal is to produce trajectories that realize a user-specified collision type and TTA, to investigate the feasibility of automatically generating desired collision scenarios. To support this task, we present COLLIDE, a large-scale collision scenario dataset constructed by transforming real-world driving logs into diverse collisions, balanced across five representative collision types and different TTA intervals. We propose a framework that predicts Collision Pattern, a compact and interpretable representation that captures the spatial configuration of the ego and the adversarial vehicles at impact, before rolling out full adversarial trajectories. Experiments show that our approach outperforms strong baselines in both collision rate and controllability. Furthermore, generated scenarios consistently induce higher planner failure rates, revealing limitations of existing planners. We demonstrate that these scenarios fine-tune planners for robustness improvements, contributing to safer AV deployment in different collision scenarios. Additional generated scenarios are available at our project page: https://plchen86157.github.io/conditional_scenario_generation/","authors":["Pin-Lun Chen","Chi-Hsi Kung","Che-Han Chang","Wei-Chen Chiu","Yi-Ting Chen"],"pdf_url":"","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2602.19108v1","updated":"2026-02-22T09:44:12Z","published":"2026-02-22T09:44:12Z","title":"Understanding Fire Through Thermal Radiation Fields for Mobile Robots","summary":"Safely moving through environments affected by fire is a critical capability for autonomous mobile robots deployed in disaster response. In this work, we present a novel approach for mobile robots to understand fire through building real-time thermal radiation fields. We register depth and thermal images to obtain a 3D point cloud annotated with temperature values. From these data, we identify fires and use the Stefan-Boltzmann law to approximate the thermal radiation in empty spaces. This enables the construction of a continuous thermal radiation field over the environment. We show that this representation can be used for robot navigation, where we embed thermal constraints into the cost map to compute collision-free and thermally safe paths. We validate our approach on a Boston Dynamics Spot robot in controlled experimental settings. Our experiments demonstrate the robot's ability to avoid hazardous regions while still reaching navigation goals. Our approach paves the way toward mobile robots that can be autonomously deployed in fire-affected environments, with potential applications in search-and-rescue, firefighting, and hazardous material response.","authors":["Anton R. Wagner","Madhan Balaji Rao","Xuesu Xiao","Sören Pirk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19107v1","updated":"2026-02-22T09:33:18Z","published":"2026-02-22T09:33:18Z","title":"A User-driven Design Framework for Robotaxi","summary":"Robotaxis are emerging as a promising form of urban mobility, yet research has largely emphasized technical driving performance while leaving open how passengers experience and evaluate rides without a human driver. To address the limitations of prior work that often relies on simulated or hypothetical settings, we investigate real-world robotaxi use through 18 semi-structured interviews and autoethnographic ride experiences. We found that users were drawn to robotaxis by low cost, social recommendation, and curiosity. They valued a distinctive set of benefits, such as an increased sense of agency, and consistent driving behavioral consistency and standardized ride experiences. However, they encountered persistent challenges around limited flexibility, insufficient transparency, management difficulty, robustness concerns in edge cases, and emergency handling concerns. Robotaxi experiences were shaped by privacy, safety, ethics, and trust. Users were often privacy-indifferent yet sensitive to opaque access and leakage risks; safety perceptions were polarized; and ethical considerations surfaced round issues such as accountability, feedback responsibility and absence of human-like social norms. Based on these findings, we propose a user-driven design framework spanning the end-to-end journey, such as pre-ride configuration (hailing), context-aware pickup facilitation (pick-up) in-ride explainability (traveling), and accountable post-ride feedback (drop-off) to guide robotaxi interaction and service design.","authors":["Yue Deng","Changyang He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19077v1","updated":"2026-02-22T07:18:02Z","published":"2026-02-22T07:18:02Z","title":"Design, Locomotion, and Control of Amphibious Robots: Recent Advances","summary":"Amphibious robots, operating seamlessly across land and water, are advancing applications in conservation, disaster response, and defense. Their performance depends on locomotion mechanisms, actuation technologies, and sensor-control integration. This review highlights recent progress in these areas, examining movement strategies, material-based actuators, and control systems for autonomy and adaptability. Challenges and opportunities are outlined to guide future research toward more efficient, resilient, and multifunctional amphibious robots.","authors":["Yi Jin","Chang Liu","Roger D. Quinn","Robert J. Wood","C. Chase Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19062v1","updated":"2026-02-22T06:30:34Z","published":"2026-02-22T06:30:34Z","title":"Path planning for unmanned surface vehicle based on predictive artificial potential field. International Journal of Advanced Robotic Systems","summary":"Path planning for high-speed unmanned surface vehicles requires more complex solutions to reduce sailing time and save energy. This article proposes a new predictive artificial potential field that incorporates time information and predictive potential to plan smoother paths. It explores the principles of the artificial potential field, considering vehicle dynamics and local minimum reachability. The study first analyzes the most advanced traditional artificial potential field and its drawbacks in global and local path planning. It then introduces three modifications to the predictive artificial potential field-angle limit, velocity adjustment, and predictive potential to enhance the feasibility and flatness of the generated path. A comparison between the traditional and predictive artificial potential fields demonstrates that the latter successfully restricts the maximum turning angle, shortens sailing time, and intelligently avoids obstacles. Simulation results further verify that the predictive artificial potential field addresses the concave local minimum problem and improves reachability in special scenarios, ultimately generating a more efficient path that reduces sailing time and conserves energy for unmanned surface vehicles.","authors":["Jia Song","Ce Hao","Jiangcheng Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19053v1","updated":"2026-02-22T05:50:16Z","published":"2026-02-22T05:50:16Z","title":"TeFlow: Enabling Multi-frame Supervision for Self-Supervised Feed-forward Scene Flow Estimation","summary":"Self-supervised feed-forward methods for scene flow estimation offer real-time efficiency, but their supervision from two-frame point correspondences is unreliable and often breaks down under occlusions. Multi-frame supervision has the potential to provide more stable guidance by incorporating motion cues from past frames, yet naive extensions of two-frame objectives are ineffective because point correspondences vary abruptly across frames, producing inconsistent signals. In the paper, we present TeFlow, enabling multi-frame supervision for feed-forward models by mining temporally consistent supervision. TeFlow introduces a temporal ensembling strategy that forms reliable supervisory signals by aggregating the most temporally consistent motion cues from a candidate pool built across multiple frames. Extensive evaluations demonstrate that TeFlow establishes a new state-of-the-art for self-supervised feed-forward methods, achieving performance gains of up to 33\\% on the challenging Argoverse 2 and nuScenes datasets. Our method performs on par with leading optimization-based methods, yet speeds up 150 times. The code is open-sourced at https://github.com/KTH-RPL/OpenSceneFlow along with trained model weights.","authors":["Qingwen Zhang","Chenhan Jiang","Xiaomeng Zhu","Yunqi Miao","Yushan Zhang","Olov Andersson","Patric Jensfelt"],"pdf_url":"","comment":"CVPR 2026; 15 pages, 8 figures"},{"id":"http://arxiv.org/abs/2504.20391v3","updated":"2026-02-22T05:37:44Z","published":"2025-04-29T03:25:39Z","title":"The Mean of Multi-Object Trajectories","summary":"This paper introduces the concept of a mean for trajectories and multi-object trajectories (defined as sets or multi-sets of trajectories) along with algorithms for computing them. Specifically, we use the Fréchet mean, and metrics based on the optimal sub-pattern assignment (OSPA) construct, to extend the notion of average from vectors to trajectories and multi-object trajectories. Further, we develop efficient algorithms to compute these means using greedy search and Gibbs sampling. Using distributed multi-object tracking as an application, we demonstrate that the Fréchet mean approach to multi-object trajectory consensus significantly outperforms state-of-the-art distributed multi-object tracking methods.","authors":["Tran Thien Dat Nguyen","Ba Tuong Vo","Ba-Ngu Vo","Hoa Van Nguyen","Changbeom Shim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19038v1","updated":"2026-02-22T04:26:57Z","published":"2026-02-22T04:26:57Z","title":"A Checklist for Deploying Robots in Public: Articulating Tacit Knowledge in the HRI Community","summary":"Many of the challenges encountered in in-the-wild public deployments of robots remain undocumented despite sharing many common pitfalls. This creates a high barrier of entry and results in repetition of avoidable mistakes. To articulate the tacit knowledge in the HRI community, this paper presents a guideline in the form of a checklist to support researchers in preparing for robot deployments in public. Drawing on their own experience with public robot deployments, the research team collected essential topics to consider in public HRI research. These topics are represented as modular flip cards in a hierarchical table, structured into deployment phases and important domains. We interviewed six interdisciplinary researchers with expertise in public HRI and show how including community input refines the checklist. We further show the checklist in action in context of real public studies. Finally, we contribute the checklist as an open-source, customizable community resource that both collects joint expertise for continual evolution and is usable as a list, set of cards, and an interactive web tool.","authors":["Claire Liang","Franziska Babel","Hannah Pelikan","Sydney Thompson","Xiang Zhi Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.20648v3","updated":"2026-02-22T04:10:00Z","published":"2025-09-25T01:07:08Z","title":"Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration","summary":"Autonomous exploration in complex multi-agent reinforcement learning (MARL) with sparse rewards critically depends on providing agents with effective intrinsic motivation. While artificial curiosity offers a powerful self-supervised signal, it often confuses environmental stochasticity with meaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniform novelty bias, treating all unexpected observations equally. However, peer behavior novelty, which encode latent task dynamics, are often overlooked, resulting in suboptimal exploration in decentralized, communication-free MARL settings. To this end, inspired by how human children adaptively calibrate their own exploratory behaviors via observing peers, we propose a novel approach to enhance multi-agent exploration. We introduce CERMIC, a principled framework that empowers agents to robustly filter noisy surprise signals and guide exploration by dynamically calibrating their intrinsic curiosity with inferred multi-agent context. Additionally, CERMIC generates theoretically-grounded intrinsic rewards, encouraging agents to explore state transitions with high information gain. We evaluate CERMIC on benchmark suites including VMAS, Meltingpot, and SMACv2. Empirical results demonstrate that exploration with CERMIC significantly outperforms SoTA algorithms in sparse-reward environments.","authors":["Yiyuan Pan","Zhe Liu","Hesheng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.10824v3","updated":"2026-02-22T03:47:53Z","published":"2024-09-17T01:31:31Z","title":"Evaluating and Improving the Robustness of LiDAR Odometry and Localization Under Real-World Corruptions","summary":"LiDAR odometry and localization are two widely used and fundamental applications in robotic and autonomous driving systems. Although state-of-the-art (SOTA) systems achieve high accuracy on clean point clouds, their robustness to corrupted data remains largely unexplored. We present the first comprehensive benchmark to evaluate the robustness of LiDAR pose-estimation techniques under 18 realistic synthetic corruptions. Our results show that, under these corruptions, odometry position errors escalate from 0.5% to more than 80%, while localization performance stays consistently high. To address this sensitivity, we propose two complementary strategies. First, we design a lightweight detection-and-filter pipeline that classifies the point cloud corruption and applies a corresponding filter (e.g., bilateral filter for noise) to restore the point cloud quality. Our classifier accurately identifies each corruption type, and the filter effectively restores odometry accuracy to near-clean data levels. Second, for learning-based systems, we show that fine-tuning using the corrupted data substantially improves robustness across all tested corruptions and even boosts performance on clean point clouds on one data sequence.","authors":["Bo Yang","Tri Minh Triet Pham","Jinqiu Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.07730v3","updated":"2026-02-22T03:02:55Z","published":"2025-11-11T01:28:10Z","title":"Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning","summary":"Learning how to reach goals in an environment is a longstanding challenge in AI, yet reasoning over long horizons remains a challenge for modern methods. The key question is how to estimate the temporal distance between pairs of observations. While temporal difference methods leverage local updates to provide optimality guarantees, they often perform worse than Monte Carlo methods that perform global updates (e.g., with multi-step returns), which lack such guarantees. We show how these approaches can be integrated into a practical offline GCRL method that fits a quasimetric distance using a multistep Monte-Carlo return. We show our method outperforms existing offline GCRL methods on long-horizon simulated tasks with up to 4000 steps, even with visual observations. We also demonstrate that our method can enable stitching in the real-world robotic manipulation domain (Bridge setup). Our approach is the first end-to-end offline GCRL method that enables multistep stitching in this real-world manipulation domain from an unlabeled offline dataset of visual observations and demonstrate robust horizon generalization.","authors":["Bill Chunyuan Zheng","Vivek Myers","Benjamin Eysenbach","Sergey Levine"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.09217v2","updated":"2026-02-22T02:46:55Z","published":"2025-06-10T20:22:09Z","title":"Perception Characteristics Distance: Measuring Stability and Robustness of Perception System in Dynamic Conditions under a Certain Decision Rule","summary":"The safety of autonomous driving systems (ADS) depends on accurate perception across distance and driving conditions. The outputs of AI perception algorithms are stochastic, which have a major impact on decision making and safety outcomes, including time-to-collision estimation. However, current perception evaluation metrics do not reflect the stochastic nature of perception algorithms. We introduce the Perception Characteristics Distance (PCD), a novel metric incorporating model output uncertainty as represented by the farthest distance at which an object can be reliably detected. To represent a system's overall perception capability in terms of reliable detection distance, we average PCD values across multiple detection quality and probabilistic thresholds to produce the average PCD (aPCD). For empirical validation, we present the SensorRainFall dataset, collected on the Virginia Smart Road using a sensor-equipped vehicle (cameras, radar, and LiDAR) under different weather (clear and rainy) and illumination conditions (daylight, streetlight, and nighttime). The dataset includes ground-truth distances, bounding boxes, and segmentation masks for target objects. Experiments with state-of-the-art models show that aPCD captures meaningful differences across weather, daylight, and illumination conditions, which traditional evaluation metrics fail to reflect. PCD provides an uncertainty-aware measure of perception performance, supporting safer and more robust ADS operation, while the SensorRainFall dataset offers a valuable benchmark for evaluation. The SensorRainFall dataset is publicly available at https://www.kaggle.com/datasets/datadrivenwheels/sensorrainfall, and the evaluation code is available at https://github.com/datadrivenwheels/PCD_Python.","authors":["Boyu Jiang","Liang Shi","Zhengzhi Lin","Lanxin Xiang","Loren Stowe","Feng Guo"],"pdf_url":"","comment":"This paper has been accepted to the CVPR 2026 Main Conference"},{"id":"http://arxiv.org/abs/2510.04666v3","updated":"2026-02-22T01:47:28Z","published":"2025-10-06T10:21:00Z","title":"Learning a Shape-adaptive Assist-as-needed Rehabilitation Policy from Therapist-informed Input","summary":"Therapist-in-the-loop robotic rehabilitation has shown great promise in enhancing rehabilitation outcomes by integrating the strengths of therapists and robotic systems. However, its broader adoption remains limited due to insufficient safe interaction and limited adaptation capability. This article proposes a novel telerobotics-mediated framework that enables therapists to intuitively and safely deliver assist-as-needed~(AAN) therapy based on two primary contributions. First, our framework encodes the therapist-informed corrective force into via-points in a latent space, allowing the therapist to provide only minimal assistance while encouraging patient maintaining own motion preferences. Second, a shape-adaptive ANN rehabilitation policy is learned to partially and progressively deform the reference trajectory for movement therapy based on encoded patient motion preferences and therapist-informed via-points. The effectiveness of the proposed shape-adaptive AAN strategy was validated on a telerobotic rehabilitation system using two representative tasks. The results demonstrate its practicality for remote AAN therapy and its superiority over two state-of-the-art methods in reducing corrective force and improving movement smoothness.","authors":["Zhimin Hou","Jiacheng Hou","Xiao Chen","Hamid Sadeghian","Tianyu Ren","Sami Haddadin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18991v1","updated":"2026-02-22T00:38:33Z","published":"2026-02-22T00:38:33Z","title":"FruitTouch: A Perceptive Gripper for Gentle and Scalable Fruit Harvesting","summary":"The automation of fruit harvesting has gained increasing significance in response to rising labor shortages. A sensorized gripper is a key component of this process, which must be compact enough for confined spaces, able to stably grasp diverse fruits, and provide reliable feedback on fruit conditions for efficient harvesting. To address this need, we propose FruitTouch, a compact gripper that integrates high-resolution, vision-based tactile sensing through an optimized optical design. This configuration accommodates a wide range of fruit sizes while maintaining low cost and mechanical simplicity. Tactile images captured by an embedded camera provide rich information for real-time force estimation, slip detection, and softness prediction. We validate the gripper in real-world fruit harvesting experiments, demonstrating robust grasp stability and effective damage prevention.","authors":["Ruohan Zhang","Mohammad Amin Mirzaee","Wenzhen Yuan"],"pdf_url":"","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2510.18316v2","updated":"2026-02-22T00:31:15Z","published":"2025-10-21T05:56:47Z","title":"MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation","summary":"Imitation learning from large-scale, diverse human demonstrations has been shown to be effective for training robots, but collecting such data is costly and time-consuming. This challenge intensifies for multi-step bimanual mobile manipulation, where humans must teleoperate both the mobile base and two high-DoF arms. Prior X-Gen works have developed automated data generation frameworks for static (bimanual) manipulation tasks, augmenting a few human demos in simulation with novel scene configurations to synthesize large-scale datasets. However, prior works fall short for bimanual mobile manipulation tasks for two major reasons: 1) a mobile base introduces the problem of how to place the robot base to enable downstream manipulation (reachability) and 2) an active camera introduces the problem of how to position the camera to generate data for a visuomotor policy (visibility). To address these challenges, MoMaGen formulates data generation as a constrained optimization problem that satisfies hard constraints (e.g., reachability) while balancing soft constraints (e.g., visibility while navigation). This formulation generalizes across most existing automated data generation approaches and offers a principled foundation for developing future methods. We evaluate on four multi-step bimanual mobile manipulation tasks and find that MoMaGen enables the generation of much more diverse datasets than previous methods. As a result of the dataset diversity, we also show that the data generated by MoMaGen can be used to train successful imitation learning policies using a single source demo. Furthermore, the trained policy can be fine-tuned with a very small amount of real-world data (40 demos) to be succesfully deployed on real robotic hardware. More details are on our project page: momagen.github.io.","authors":["Chengshu Li","Mengdi Xu","Arpit Bahety","Hang Yin","Yunfan Jiang","Huang Huang","Josiah Wong","Sujay Garlanka","Cem Gokmen","Ruohan Zhang","Weiyu Liu","Jiajun Wu","Roberto Martín-Martín","Li Fei-Fei"],"pdf_url":"","comment":"Project website: momagen.github.io. The first four authors contribute equally. Accpeted to International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2602.20200v1","updated":"2026-02-22T15:39:34Z","published":"2026-02-22T15:39:34Z","title":"Global Prior Meets Local Consistency: Dual-Memory Augmented Vision-Language-Action Model for Efficient Robotic Manipulation","summary":"Hierarchical Vision-Language-Action (VLA) models have rapidly become a dominant paradigm for robotic manipulation. It typically comprising a Vision-Language backbone for perception and understanding, together with a generative policy for action generation. However, its performance is increasingly bottlenecked by the action generation proceess. (i) Low inference efficiency. A pronounced distributional gap between isotropic noise priors and target action distributions, which increases denoising steps and the incidence of infeasible samples. (ii) Poor robustness. Existing policies condition solely on the current observation, neglecting the constraint of history sequence and thus lacking awareness of task progress and temporal consistency. To address these issues, we introduce OptimusVLA, a dual-memory VLA framework with Global Prior Memory (GPM) and Local Consistency Memory (LCM). GPM replaces Gaussian noise with task-level priors retrieved from semantically similar trajectories, thereby shortening the generative path and reducing the umber of function evaluations (NFE). LCM dynamically models executed action sequence to infer task progress and injects a learned consistency constraint that enforces temporal coherence and smoothness of trajectory. Across three simulation benchmarks, OptimusVLA consistently outperforms strong baselines: it achieves 98.6% average success rate on LIBERO, improves over pi_0 by 13.5% on CALVIN, and attains 38% average success rate on RoboTwin 2.0 Hard. In Real-World evaluation, OptimusVLA ranks best on Generalization and Long-horizon suites, surpassing pi_0 by 42.9% and 52.4%, respectively, while delivering 2.9x inference speedup.","authors":["Zaijing Li","Bing Hu","Rui Shao","Gongwei Chen","Dongmei Jiang","Pengwei Xie","Jianye Hao","Liqiang Nie"],"pdf_url":"","comment":"17 pages, 8 figures"}]},"2026-02-21T00:00:00Z":{"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.18935v1","updated":"2026-02-21T19:05:03Z","published":"2026-02-21T19:05:03Z","title":"Responsible Intelligence in Practice: A Fairness Audit of Open Large Language Models for Library Reference Services","summary":"As libraries explore large language models (LLMs) as a scalable layer for reference services, a core fairness question follows: can LLM-based services support all patrons fairly, regardless of demographic identity? While LLMs offer great potential for broadening access to information assistance, they may also reproduce societal biases embedded in their training data, potentially undermining libraries' commitments to impartial service. In this chapter, we apply a systematic evaluation approach that combines diagnostic classification to detect systematic differences with linguistic analysis to interpret their sources. Across three widely used open models (Llama-3.1 8B, Gemma-2 9B, and Ministral 8B), we find no compelling evidence of systematic differentiation by race/ethnicity, and only minor evidence of sex-linked differentiation in one model. We discuss implications for responsible AI adoption in libraries and the importance of ongoing monitoring in aligning LLM-based services with core professional values.","authors":["Haining Wang","Jason Clark","Angelica Peña"],"pdf_url":"","comment":"Invited chapter for the edited volume Artificial Intelligence and Social Justice Intersections in Library and Information Studies: Challenges and Opportunities (Emerald Group Publishing, in preparation)"},{"id":"http://arxiv.org/abs/2602.18928v1","updated":"2026-02-21T18:39:06Z","published":"2026-02-21T18:39:06Z","title":"Narrowing the Complexity Gap in the Evaluation of Large Language Models","summary":"Evaluating Large Language Models (LLMs) with respect to real-world code complexity is essential. Otherwise, there is a risk of overestimating LLMs' programming abilities based on simplistic benchmarks, only to be disappointed when using them in real-world settings. Recently, researchers explored the construction of more realistic benchmarks by mining or augmenting open-source repositories. Such solutions are usually task-specific. Data quality control from real-world projects can also be time-consuming and error-prone. More importantly, evaluating LLMs on fixed benchmark problems is subject to data contamination and overfitting. We propose GeneBench, an automated technique to add real-world complexities to any programming benchmark. GeneBench leverages a multi-objective optimization to increase the complexity of programming problems while maintaining the readability of code similar to real-world programs. Transforming four widely-used programming benchmarks using GeneBench and evaluating 13 LLMs (including two reasoning LLMs) on them shows a notable performance drop across all programming tasks (14.9%-60.5%, avg=35.2%), demonstrating LLMs' struggle under real-world complexities. The struggle persists even when LLMs are few-shot prompted or fine-tuned with examples from different versions of GeneBench, demonstrating the challenging nature of the problems. Finally, we show that the performance of the studied LLMs in bug repair is similar under GeneBench and SWE-Bench. This, along with the consistent reproduction of performance drop of all studied LLMs across four tasks under different versions of GeneBench, makes the technique suitable to evaluate LLMs without costly construction of real-world benchmarks.","authors":["Yang Chen","Shuyang Liu","Reyhaneh Jabbarvand"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.14861v2","updated":"2026-02-21T18:08:05Z","published":"2025-12-16T19:23:04Z","title":"Industry Expectations and Skill Demands in Quantum Software Testing","summary":"Quantum software testing introduces new challenges that differ fundamentally from those in classical software engineering. Aims: This study investigates how the quantum software industry defines testing roles and what skills are expected from professionals in these positions. Method: We analyzed 110 job postings from organizations involved in quantum software and hardware development, identifying activities, competencies, and skill requirements related to testing. Results: The findings show that testing in quantum contexts combines traditional software quality assurance with experimental validation, emphasizing calibration, control, and hybrid quantum-classical verification. Employers seek professionals who integrate programming and automation expertise with quantum-specific technical knowledge and interdisciplinary collaboration skills. Conclusions: Quantum software testing remains at an early but rapidly evolving stage that bridges software engineering and experimental physics, highlighting the need for educational and research efforts that align testing practices with industrial realities.","authors":["Ronnie de Souza Santos","Maria Teresa Baldassarre","Cesar França"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18914v1","updated":"2026-02-21T17:45:07Z","published":"2026-02-21T17:45:07Z","title":"From Docs to Descriptions: Smell-Aware Evaluation of MCP Server Descriptions","summary":"The Model Context Protocol (MCP) has rapidly become a de facto standard for connecting LLM-based agents with external tools via reusable MCP servers. In practice, however, server selection and onboarding rely heavily on free-text tool descriptions that are intentionally loosely constrained. Although this flexibility largely ensures the scalability of MCP servers, it also creates a reliability gap that descriptions often misrepresent or omit key semantics, increasing trial-and-error integration, degrading agent behavior, and potentially introducing security risks. To this end, we present the first systematic study of description smells in MCP tool descriptions and their impact on usability. Specifically, we synthesize software/API documentation practices and agentic tool-use requirements into a four-dimensional quality standard: accuracy, functionality, information completeness, and conciseness, covering 18 specific smell categories. Using this standard, we conducted a large-scale empirical study on a well-constructed dataset of 10,831 MCP servers. We find that description smells are pervasive (e.g., 73% repeated tool names, thousands with incorrect parameter semantics or missing return descriptions), reflecting a \"code-first, description-last\" pattern. Through a controlled mutation-based study, we show these smells significantly affect LLM tool selection, with functionality and accuracy having the largest effects (+11.6% and +8.8%, p < 0.001). In competitive settings with functionally equivalent servers, standard-compliant descriptions reach 72% selection probability (260% over a 20% baseline), demonstrating that smell-guided remediation yields substantial practical benefits. We release our labeled dataset and standards to support future work on reliable and secure MCP ecosystems.","authors":["Peiran Wang","Ying Li","Yuqiang Sun","Chengwei Liu","Yang Liu","Yuan Tian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14878v2","updated":"2026-02-21T17:39:49Z","published":"2026-02-16T16:10:11Z","title":"Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions","summary":"The Model Context Protocol (MCP) introduces a standard specification that defines how Foundation Model (FM)-based agents should interact with external systems by invoking tools. However, to understand a tool's purpose and features, FMs rely on natural-language tool descriptions, making these descriptions a critical component in guiding FMs to select the optimal tool for a given (sub)task and to pass the right arguments to the tool. While defects or smells in these descriptions can misguide FM-based agents, their prevalence and consequences in the MCP ecosystem remain unclear.\n  Hence, we examine 856 tools spread across 103 MCP servers empirically, assess their description quality, and their impact on agent performance. We identify six components of tool descriptions from the literature, develop a scoring rubric utilizing these components, and then formalize tool description smells based on this rubric. By operationalizing this rubric through an FM-based scanner, we find that 97.1% of the analyzed tool descriptions contain at least one smell, with 56% failing to state their purpose clearly. While augmenting these descriptions for all components improves task success rates by a median of 5.85 percentage points and improves partial goal completion by 15.12%, it also increases the number of execution steps by 67.46% and regresses performance in 16.67% of cases. These results indicate that achieving performance gains is not straightforward; while execution cost can act as a trade-off, execution context can also impact. Furthermore, component ablations show that compact variants of different component combinations often preserve behavioral reliability while reducing unnecessary token overhead, enabling more efficient use of the FM context window and lower execution costs.","authors":["Mohammed Mehedi Hasan","Hao Li","Gopi Krishnan Rajbahadur","Bram Adams","Ahmed E. Hassan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18800v1","updated":"2026-02-21T11:21:13Z","published":"2026-02-21T11:21:13Z","title":"Operational Robustness of LLMs on Code Generation","summary":"It is now common practice in software development for large language models (LLMs) to be used to generate program code. It is desirable to evaluate the robustness of LLMs for this usage. This paper is concerned in particular with how sensitive LLMs are to variations in descriptions of the coding tasks. However, existing techniques for evaluating this robustness are unsuitable for code generation because the input data space of natural language descriptions is discrete. To address this problem, we propose a robustness evaluation method called scenario domain analysis, which aims to find the expected minimal change in the natural language descriptions of coding tasks that would cause the LLMs to produce incorrect outputs. We have formally proved the theoretical properties of the method and also conducted extensive experiments to evaluate the robustness of four state-of-the-art art LLMs: Gemini-pro, Codex, Llamma2 and Falcon 7B, and have found that we are able to rank these with confidence from best to worst. Moreover, we have also studied how robustness varies in different scenarios, including the variations with the topic of the coding task and with the complexity of its sample solution, and found that robustness is lower for more complex tasks and also lower for more advanced topics, such as multi-threading and data structures.","authors":["Debalina Ghosh Paul","Hong Zhu","Ian Bayley"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18774v1","updated":"2026-02-21T09:51:51Z","published":"2026-02-21T09:51:51Z","title":"Computational Complexity of Edge Coverage Problem for Constrained Control Flow Graphs","summary":"The article studies edge coverage for control flow graphs extended with explicit constraints. Achieving a given level of white-box coverage for a given code is a classic problem in software testing. We focus on designing test sets that achieve edge coverage \\textit{while respecting additional constraints} between vertices. The paper analyzes how such constraints affect both the feasibility and computational complexity of edge coverage.\n  The paper discusses five types of constraints. POSITIVE constraints require at least one test path where a given vertex precedes another. NEGATIVE constraints forbid any such test path. ONCE constraints require exactly one test path with a single occurrence of one vertex before another. MAX ONCE constraints allow such precedence in at most one test path. ALWAYS constraints require every test path containing a given vertex to also contain another vertex later on the same path. Each type models a different test requirement, such as mandatory flows, semantic exclusions, or execution cost limits.\n  We investigate the computational complexity of finding a test set that achieves edge coverage and respects a given set of constraints. For POSITIVE constraints, the existence of an edge covering test set is decidable in polynomial time by extending standard edge coverage constructions with additional paths for each constraint. For NEGATIVE, MAX ONCE, ONCE, and ALWAYS constraints, the decision problem is NP-complete. The proofs rely on polynomial reductions from variants of SAT. The NP-completeness results hold even for restricted graph classes, including acyclic graphs, for all these four constraints.\n  Finally, we study the fixed-parameter tractability of the NEGATIVE constraint. Although the general problem is NP-complete, the paper presents an FPT algorithm with respect to the number of constraints.","authors":["Jakub Ruszil","Artur Polański","Adam Roman","Jakub Zelek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18768v1","updated":"2026-02-21T09:26:23Z","published":"2026-02-21T09:26:23Z","title":"Efficient Dynamic Test Case Generation for Path-Based Coverage Criteria","summary":"We present a novel approach to test-case generation that satisfies four white-box, path-based coverage criteria: Prime Path, Simple Cycle, Simple Path, and Edge-Acyclic Path. Our method builds on a modified version of Johnson algorithm and enables test cases to be generated incrementally and on demand, rather than requiring the entire test suite to be computed upfront. This streaming capability represents a substantial advancement over existing approaches, as it allows testers to begin executing and refining tests immediately, thereby significantly improving the efficiency of test design. Our solution is inherently memory efficient, as it does not store all discovered coverage items; instead, it retains only the minimal set of paths required to generate subsequent coverage items on the fly. As a result, the approach scales to arbitrarily large graphs. In addition, the algorithm gives testers explicit control over the size of the generated test suite by allowing them to restrict the number of cycles permitted in a test path. The approach is grounded in new theoretical insights, most notably a novel characterization of prime paths in terms of the strongly connected components of control-flow graphs. We complement these theoretical contributions with a practical implementation and a comprehensive empirical evaluation. The results demonstrate that our method not only outperforms existing techniques in terms of execution time and memory consumption, but also provides testers with a more flexible and efficient tool for achieving high coverage while substantially reducing test design overhead.","authors":["Jakub Zelek","Jakub Ruszil","Adam Roman","Artur Polański"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18689v1","updated":"2026-02-21T01:48:17Z","published":"2026-02-21T01:48:17Z","title":"Automatic, Expressive, and Scalable Fuzzing with Stitching","summary":"Fuzzing is a powerful technique for finding bugs in software libraries, but scaling it remains difficult. Automated harness generation commits to fixed API sequences at synthesis time, limiting the behaviors each harness can test. Approaches that instead explore new sequences dynamically lack the expressiveness to model real-world usage constraints leading to false positives from straightforward API misuse.\n  We propose stitching, a technique that encodes API usage constraints in pieces that a fuzzer dynamically assembles at runtime. A static type system governs how objects flow between blocks, while a dynamically-checked extrinsic typestate tracks arbitrary metadata across blocks, enabling specifications to express rich semantic constraints such as object state dependencies and cross-function preconditions. This allows a single specification to describe an open-ended space of valid API interactions that the fuzzer explores guided by coverage feedback.\n  We implement stitching in STITCH, using LLMs to automatically configure projects for fuzzing, synthesize a specification, triage crashes, and repair the specification itself. We evaluated STITCH against four state-of-the-art tools on 33 benchmarks, where it achieved the highest code coverage on 21 and found 30 true-positive bugs compared to 10 by all other tools combined, with substantially higher precision (70% vs. 12% for the next-best LLM-based tool). Deployed automatically on 1365 widely used open-source projects, STITCH discovered 131 new bugs across 102 projects, 73 of which have already been patched.","authors":["Harrison Green","Fraser Brown","Claire Le Goues"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21251v1","updated":"2026-02-21T17:53:30Z","published":"2026-02-21T17:53:30Z","title":"AgenticTyper: Automated Typing of Legacy Software Projects Using Agentic AI","summary":"Legacy JavaScript systems lack type safety, making maintenance risky. While TypeScript can help, manually adding types is expensive. Previous automated typing research focuses on type inference but rarely addresses type checking setup, definition generation, bug identification, or behavioral correctness at repository scale. We present AgenticTyper, a Large Language Model (LLM)-based agentic system that addresses these gaps through iterative error correction and behavior preservation via transpilation comparison. Evaluation on two proprietary repositories (81K LOC) shows that AgenticTyper resolves all 633 initial type errors in 20 minutes, reducing manual effort from one working day.","authors":["Clemens Pohle"],"pdf_url":"","comment":"Accepted at ICSE 2026 Student Research Competition (SRC)"}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2602.18934v1","updated":"2026-02-21T18:57:17Z","published":"2026-02-21T18:57:17Z","title":"LoMime: Query-Efficient Membership Inference using Model Extraction in Label-Only Settings","summary":"Membership inference attacks (MIAs) threaten the privacy of machine learning models by revealing whether a specific data point was used during training. Existing MIAs often rely on impractical assumptions such as access to public datasets, shadow models, confidence scores, or training data distribution knowledge and making them vulnerable to defenses like confidence masking and adversarial regularization. Label-only MIAs, even under strict constraints suffer from high query requirements per sample. We propose a cost-effective label-only MIA framework based on transferability and model extraction. By querying the target model M using active sampling, perturbation-based selection, and synthetic data, we extract a functionally similar surrogate S on which membership inference is performed. This shifts query overhead to a one-time extraction phase, eliminating repeated queries to M . Operating under strict black-box constraints, our method matches the performance of state-of-the-art label-only MIAs while significantly reducing query costs. On benchmarks including Purchase, Location, and Texas Hospital, we show that a query budget equivalent to testing $\\approx1\\%$ of training samples suffices to extract S and achieve membership inference accuracy within $\\pm1\\%$ of M . We also evaluate the effectiveness of standard defenses proposed for label-only MIAs against our attack.","authors":["Abdullah Caglar Oksuz","Anisa Halimi","Erman Ayday"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18900v1","updated":"2026-02-21T16:45:56Z","published":"2026-02-21T16:45:56Z","title":"PrivacyBench: Privacy Isn't Free in Hybrid Privacy-Preserving Vision Systems","summary":"Privacy preserving machine learning deployments in sensitive deep learning applications; from medical imaging to autonomous systems; increasingly require combining multiple techniques. Yet, practitioners lack systematic guidance to assess the synergistic and non-additive interactions of these hybrid configurations, relying instead on isolated technique analysis that misses critical system level interactions. We introduce PrivacyBench, a benchmarking framework that reveals striking failures in privacy technique combinations with severe deployment implications. Through systematic evaluation across ResNet18 and ViT models on medical datasets, we uncover that FL + DP combinations exhibit severe convergence failure, with accuracy dropping from 98% to 13% while compute costs and energy consumption substantially increase. In contrast, FL + SMPC maintains near-baseline performance with modest overhead. Our framework provides the first systematic platform for evaluating privacy-utility-cost trade-offs through automated YAML configuration, resource monitoring, and reproducible experimental protocols. PrivacyBench enables practitioners to identify problematic technique interactions before deployment, moving privacy-preserving computer vision from ad-hoc evaluation toward principled systems design. These findings demonstrate that privacy techniques cannot be composed arbitrarily and provide critical guidance for robust deployment in resource-constrained environments.","authors":["Nnaemeka Obiefuna","Samuel Oyeneye","Similoluwa Odunaiya","Iremide Oyelaja","Steven Kolawole"],"pdf_url":"","comment":"20 pages, 2 figures"},{"id":"http://arxiv.org/abs/2510.15133v2","updated":"2026-02-21T15:31:27Z","published":"2025-10-16T20:48:22Z","title":"Intermittent File Encryption in Ransomware: Measurement, Modeling, and Detection","summary":"File encrypting ransomware increasingly employs intermittent encryption techniques, encrypting only parts of files to evade classical detection methods. These strategies, exemplified by ransomware families like BlackCat, complicate file structure based detection techniques due to diverse file formats exhibiting varying traits under partial encryption. This paper provides a systematic empirical characterization of byte level statistics under intermittent encryption across common file types, establishing a comprehensive baseline of how partial encryption impacts data structure. We specialize a classical KL divergence upper bound on a tailored mixture model of intermittent encryption, yielding filetype specific detectability ceilings for histogram-based detectors. Leveraging insights from this analysis, we empirically evaluate convolutional neural network (CNN) based detection methods using realistic intermittent encryption configurations derived from leading ransomware variants. Our findings demonstrate that localized analysis via chunk level CNNs consistently outperforms global analysis methods, highlighting their practical effectiveness and establishing a robust baseline for future detection systems.","authors":["Ynes Ineza","Gerald Jackson","Prince Niyonkuru","Jaden Kevil","Abdul Serwadda"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.16670v4","updated":"2026-02-21T14:17:59Z","published":"2025-05-22T13:36:00Z","title":"BitHydra: Towards Bit-flip Inference Cost Attack against Large Language Models","summary":"Large language models (LLMs) are widely deployed, but their substantial compute demands make them vulnerable to inference cost attacks that aim to deliberately maximize the output length. In this work, we investigate a distinct attack surface: maximizing inference cost by tampering with the model parameters instead of inputs. This approach leverages the established capability of Bit-Flip Attacks (BFAs) to persistently alter model behavior via minute weight perturbations, effectively decoupling the attack from specific input queries. To realize this, we propose BitHydra, a framework that addresses the unique optimization challenge of identifying the exact weight bits that maximize generation cost. We formulate the attack as a constrained Binary Integer Programming (BIP) problem designed to systematically suppress the end-of-sequence (i.e., <eos>) probability. To overcome the intractability of the discrete search space, we relax the problem into a continuous optimization task and solve it via the Alternating Direction Method of Multipliers (ADMM). We evaluate BitHydra across 10 LLMs (1.5B-16B). Our results demonstrate that the proposed optimization method efficiently achieves endless generation with as few as 1-4 bit flips on all testing models, verifying the effectiveness of the ADMM-based formulation against both standard models and potential defenses.","authors":["Xiaobei Yan","Yiming Li","Hao Wang","Han Qiu","Tianwei Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18834v1","updated":"2026-02-21T13:32:14Z","published":"2026-02-21T13:32:14Z","title":"When Friction Helps: Transaction Confirmation Improves Decision Quality in Blockchain Interactions","summary":"In blockchain applications, transaction confirmation is often treated as usability friction to be minimized or removed. However, confirmation also marks the boundary between deliberation and irreversible commitment, suggesting it may play a functional role in human decision-making. To investigate this tension, we conducted an experiment using a blockchain-based Connect Four game with two interaction modes differing only in authorization flow: manual wallet confirmation (Confirmation Mode) versus auto-authorized delegation (Frictionless Mode). Although participants preferred Frictionless Mode and perceived better performance (N=109), objective performance was worse without confirmation in a counterbalanced deployment (Wave 2: win rate -11.8%, p=0.044; move quality -0.051, p=0.022). Analysis of canceled submissions suggests confirmation can enable pre-submission self-correction (N=66, p=0.005). These findings suggest that transaction confirmation can function as a cognitively meaningful checkpoint rather than mere usability friction, highlighting a trade-off between interaction smoothness and decision quality in irreversible blockchain interactions.","authors":["Eason Chen","Xinyi Tang","George Digkas","Dionysios Lougaris","John E. Naulty","Kostas Chalkias"],"pdf_url":"","comment":"5 Pages, paper will appear at CHI 2026 Poster"},{"id":"http://arxiv.org/abs/2602.13597v2","updated":"2026-02-21T10:59:49Z","published":"2026-02-14T04:35:24Z","title":"AlignSentinel: Alignment-Aware Detection of Prompt Injection Attacks","summary":"Prompt injection attacks insert malicious instructions into an LLM's input to steer it toward an attacker-chosen task instead of the intended one. Existing detection defenses typically classify any input with instruction as malicious, leading to misclassification of benign inputs containing instructions that align with the intended task. In this work, we account for the instruction hierarchy and distinguish among three categories: inputs with misaligned instructions, inputs with aligned instructions, and non-instruction inputs. We introduce AlignSentinel, a three-class classifier that leverages features derived from LLM's attention maps to categorize inputs accordingly. To support evaluation, we construct the first systematic benchmark containing inputs from all three categories. Experiments on both our benchmark and existing ones--where inputs with aligned instructions are largely absent--show that AlignSentinel accurately detects inputs with misaligned instructions and substantially outperforms baselines.","authors":["Yuqi Jia","Ruiqi Wang","Xilong Wang","Chong Xiang","Neil Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.11878v2","updated":"2026-02-21T10:21:08Z","published":"2025-12-07T21:27:48Z","title":"A Technical Policy Blueprint for Trustworthy Decentralized AI","summary":"Decentralized AI systems, such as federated learning, can play a critical role in further unlocking AI asset marketplaces (e.g., healthcare data marketplaces) thanks to increased asset privacy protection. Unlocking this big potential necessitates governance mechanisms that are transparent, scalable, and verifiable. However current governance approaches rely on bespoke, infrastructure-specific policies that hinder asset interoperability and trust among systems. We are proposing a Technical Policy Blueprint that encodes governance requirements as policy-as-code objects and separates asset policy verification from asset policy enforcement. In this architecture the Policy Engine verifies evidence (e.g., identities, signatures, payments, trusted-hardware attestations) and issues capability packages. Asset Guardians (e.g. data guardians, model guardians, computation guardians, etc.) enforce access or execution solely based on these capability packages. This core concept of decoupling policy processing from capabilities enables governance to evolve without reconfiguring AI infrastructure, thus creating an approach that is transparent, auditable, and resilient to change.","authors":["Hasan Kassem","Orion Banks","Sergen Cansiz","Brandon Edwards","Patrick Foley","Inken Hagestedt","Taeho Jung","Prakash Moorthy","Michael O'Connor","Marco Lorenzi","Ann K Novakowski","Bruno Rodrigues","Holger Roth","Micah Sheller","Dimitris Stripelis","Marc Vesin","Renato Umeton","Mic Bowman","Alexandros Karargyris"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18782v1","updated":"2026-02-21T10:17:55Z","published":"2026-02-21T10:17:55Z","title":"MANATEE: Inference-Time Lightweight Diffusion Based Safety Defense for LLMs","summary":"Defending LLMs against adversarial jailbreak attacks remains an open challenge. Existing defenses rely on binary classifiers that fail when adversarial input falls outside the learned decision boundary, and repeated fine-tuning is computationally expensive while potentially degrading model capabilities. We propose MANATEE, an inference-time defense that uses density estimation over a benign representation manifold. MANATEE learns the score function of benign hidden states and uses diffusion to project anomalous representations toward safe regions--requiring no harmful training data and no architectural modifications. Experiments across Mistral-7B-Instruct, Llama-3.1-8B-Instruct, and Gemma-2-9B-it demonstrate that MANATEE reduce Attack Success Rate by up to 100\\% on certain datasets, while preserving model utility on benign inputs.","authors":["Chun Yan Ryan Kan","Tommy Tran","Vedant Yadav","Ava Cai","Kevin Zhu","Ruizhe Li","Maheep Chaudhary"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18758v1","updated":"2026-02-21T08:45:05Z","published":"2026-02-21T08:45:05Z","title":"UFO: Unlocking Ultra-Efficient Quantized Private Inference with Protocol and Algorithm Co-Optimization","summary":"Private convolutional neural network (CNN) inference based on secure two-party computation (2PC) suffers from high communication and latency overhead, especially from convolution layers. In this paper, we propose UFO, a quantized 2PC inference framework that jointly optimizes the 2PC protocols and quantization algorithm. UFO features a novel 2PC protocol that systematically combines the efficient Winograd convolution algorithm with quantization to improve inference efficiency. However, we observe that naively combining quantization and Winograd convolution faces the following challenges: 1) From the inference perspective, Winograd transformations introduce extensive additions and require frequent bit width conversions to avoid inference overflow, leading to non-negligible communication overhead; 2) From the training perspective, Winograd transformations introduce weight outliers that make quantization-aware training (QAT) difficult, resulting in inferior model accuracy. To address these challenges, we co-optimize both protocol and algorithm. 1) At the protocol level, we propose a series of graph-level optimizations for 2PC inference to minimize the communication. 2) At the algorithm level, we develop a mixed-precision QAT algorithm based on layer sensitivity to optimize model accuracy given communication constraints. To accommodate the outliers, we further introduce a 2PC-friendly bit re-weighting algorithm to increase the representation range without explicitly increasing bit widths. With extensive experiments, UFO demonstrates 11.7x, 3.6x, and 6.3x communication reduction with 1.29%, 1.16%, and 1.29% higher accuracy compared to state-of-the-art frameworks SiRNN, COINN, and CoPriv, respectively.","authors":["Wenxuan Zeng","Chao Yang","Tianshi Xu","Bo Zhang","Changrui Ren","Jin Dong","Meng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.02181v3","updated":"2026-02-21T07:01:15Z","published":"2025-07-02T22:27:33Z","title":"Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher","summary":"This paper introduces {\\em truncated inner $c$-differential cryptanalysis}, a technique that enables the practical application of $c$-differential uniformity to block ciphers. While Ellingsen et al. (IEEE Trans. Inf. Theory, 2020) established the notion of $c$-differential uniformity by analyzing the equation $F(x\\oplus a) \\oplus cF(x) = b$, a key challenge remained: the outer multiplication by $c$ disrupts the structural properties essential for block cipher analysis, particularly key addition. We address this challenge by developing an \\emph{inner} $c$-differential approach where multiplication by $c$ affects the input: $(F(cx\\oplus a), F(x))$, thereby returning to the original idea of Borisov et al. (FSE, 2002). We prove that the inner $c$-differential uniformity of a function $F$ equals the outer $c$-differential uniformity of $F^{-1}$, establishing a duality between the two notions. This modification preserves cipher structure while enabling practical cryptanalytic applications.\n  We apply our methodology to Kuznyechik (GOST R 34.12-2015) without initial key whitening. For reduced rounds, we construct explicit $c$-differential trails achieving probability $2^{-84.0}$ for two rounds and $2^{-169.7}$ for three rounds, representing improvements of 5.2 and 4.6 bits respectively over the best classical differential trails. For the full 9-round cipher, we develop a statistical truncated $c$-differential distinguisher. Through computational analysis involving millions of differential pairs, we identify configurations with bias ratios reaching $1.7\\times$ and corrected p-values as low as $1.85 \\times 10^{-3}$. The distinguisher requires data complexity $2^{33}$ chosen plaintext pairs, time complexity $2^{34}$, and memory complexity $2^{16}$.","authors":["Pantelimon Stanica","Ranit Dutta","Bimal Mandal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.21051v2","updated":"2026-02-21T04:22:01Z","published":"2025-05-27T11:36:18Z","title":"SHE-LoRA: Selective Homomorphic Encryption for Federated Tuning with Heterogeneous LoRA","summary":"Federated fine-tuning is critical for improving the performance of large language models (LLMs) in handling domain-specific tasks while keeping training data decentralized and private. However, prior work has shown that clients' private data can actually be recovered via gradient inversion attacks. Existing privacy preservation techniques against such attacks typically entail performance degradation and high costs, making them ill-suited for clients with heterogeneous data distributions and device capabilities. In this paper, we propose SHE-LoRA, which integrates selective homomorphic encryption (SHE) and low-rank adaptation (LoRA) to enable efficient and privacy-preserving federated tuning of LLMs in cross-device environments. Based on model parameter sensitivity assessment, heterogeneous clients adaptively negotiate and select a subset of model parameters for homomorphic encryption. To ensure accurate model aggregation, we design a column-aware secure aggregation method and customized reparameterization techniques to align the aggregation results with the heterogeneous device capabilities of clients. Extensive experiments demonstrate that SHE-LoRA maintains performance comparable to non-private baselines, achieves strong resistance to state-of-the-art attacks, and significantly reduces communication overhead by 99.71% and encryption time by 99.87%, compared to HE baselines.","authors":["Jianmin Liu","Li Yan","Borui Li","Lei Yu","Chao Shen"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.18708v1","updated":"2026-02-21T03:56:54Z","published":"2026-02-21T03:56:54Z","title":"On the Energy Cost of Post-Quantum Key Establishment in Wireless Low-Power Personal Area Networks","summary":"Post-Quantum Cryptography (PQC) creates payloads that strain the timing and energy budgets of Personal Area Networks. In post-quantum key exchange (PQKE), this causes severe fragmentation, prolonged radio activity, and high transmission overhead on low-power devices. Prior work optimizes cryptographic computation but largely ignores communication cost. This paper separates computation and communication costs using Bluetooth Low Energy as a representative platform and validates them on real hardware. Results show communication often dominates PQKE energy, exceeding cryptographic cost. Efficient quantum-resilient pairing therefore requires coordinated protocol configuration and lower-layer optimization. This work provides developers a practical way to reason about PQC energy trade-offs and informs the evolution of PAN standards toward quantum-safe operation.","authors":["Tao Liu","Gowri Ramachandra","Raja Jurdak"],"pdf_url":"","comment":"6 pages, 3 figures, Submitted to SenSys'26"},{"id":"http://arxiv.org/abs/2602.18700v1","updated":"2026-02-21T03:12:29Z","published":"2026-02-21T03:12:29Z","title":"Watermarking LLM Agent Trajectories","summary":"LLM agents rely heavily on high-quality trajectory data to guide their problem-solving behaviors, yet producing such data requires substantial task design, high-capacity model generation, and manual filtering. Despite the high cost of creating these datasets, existing literature has overlooked copyright protection for LLM agent trajectories. This gap leaves creators vulnerable to data theft and makes it difficult to trace misuse or enforce ownership rights. This paper introduces ActHook, the first watermarking method tailored for agent trajectory datasets. Inspired by hook mechanisms in software engineering, ActHook embeds hook actions that are activated by a secret input key and do not alter the original task outcome. Like software execution, LLM agents operate sequentially, allowing hook actions to be inserted at decision points without disrupting task flow. When the activation key is present, an LLM agent trained on watermarked trajectories can produce these hook actions at a significantly higher rate, enabling reliable black-box detection. Experiments on mathematical reasoning, web searching, and software engineering agents show that ActHook achieves an average detection AUC of 94.3 on Qwen-2.5-Coder-7B while incurring negligible performance degradation.","authors":["Wenlong Meng","Chen Gong","Terry Yue Zhuo","Fan Zhang","Kecen Li","Zheng Liu","Zhou Yang","Chengkun Wei","Wenzhi Chen"],"pdf_url":"","comment":"20 pages, 9 figures"},{"id":"http://arxiv.org/abs/2602.14135v3","updated":"2026-02-21T02:30:08Z","published":"2026-02-15T13:12:44Z","title":"ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI","summary":"Rapidly evolving AI exhibits increasingly strong autonomy and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical limitations such as restricted risk dimensions and failed frontier risk detection. The lagging safety benchmarks and alignment technologies can hardly address the complex challenges posed by cutting-edge AI models. To bridge this gap, we propose the \"ForesightSafety Bench\" AI Safety Evaluation Framework, beginning with 7 major Fundamental Safety pillars and progressively extends to advanced Embodied AI Safety, AI4Science Safety, Social and Environmental AI risks, Catastrophic and Existential Risks, as well as 8 critical industrial safety domains, forming a total of 94 refined risk dimensions. To date, the benchmark has accumulated tens of thousands of structured risk data points and assessment results, establishing a widely encompassing, hierarchically clear, and dynamically evolving AI safety evaluation framework. Based on this benchmark, we conduct systematic evaluation and in-depth analysis of over twenty mainstream advanced large models, identifying key risk patterns and their capability boundaries. The safety capability evaluation results reveals the widespread safety vulnerabilities of frontier AI across multiple pillars, particularly focusing on Risky Agentic Autonomy, AI4Science Safety, Embodied AI Safety, Social AI Safety and Catastrophic and Existential Risks. Our benchmark is released at https://github.com/Beijing-AISI/ForesightSafety-Bench. The project website is available at https://foresightsafety-bench.beijing-aisi.ac.cn/.","authors":["Haibo Tong","Feifei Zhao","Linghao Feng","Ruoyu Wu","Ruolin Chen","Lu Jia","Zhou Zhao","Jindong Li","Tenglong Li","Erliang Lin","Shuai Yang","Enmeng Lu","Yinqian Sun","Qian Zhang","Zizhe Ruan","Jinyu Fan","Zeyang Yue","Ping Wu","Huangrui Li","Chengyi Sun","Yi Zeng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18689v1","updated":"2026-02-21T01:48:17Z","published":"2026-02-21T01:48:17Z","title":"Automatic, Expressive, and Scalable Fuzzing with Stitching","summary":"Fuzzing is a powerful technique for finding bugs in software libraries, but scaling it remains difficult. Automated harness generation commits to fixed API sequences at synthesis time, limiting the behaviors each harness can test. Approaches that instead explore new sequences dynamically lack the expressiveness to model real-world usage constraints leading to false positives from straightforward API misuse.\n  We propose stitching, a technique that encodes API usage constraints in pieces that a fuzzer dynamically assembles at runtime. A static type system governs how objects flow between blocks, while a dynamically-checked extrinsic typestate tracks arbitrary metadata across blocks, enabling specifications to express rich semantic constraints such as object state dependencies and cross-function preconditions. This allows a single specification to describe an open-ended space of valid API interactions that the fuzzer explores guided by coverage feedback.\n  We implement stitching in STITCH, using LLMs to automatically configure projects for fuzzing, synthesize a specification, triage crashes, and repair the specification itself. We evaluated STITCH against four state-of-the-art tools on 33 benchmarks, where it achieved the highest code coverage on 21 and found 30 true-positive bugs compared to 10 by all other tools combined, with substantially higher precision (70% vs. 12% for the next-best LLM-based tool). Deployed automatically on 1365 widely used open-source projects, STITCH discovered 131 new bugs across 102 projects, 73 of which have already been patched.","authors":["Harrison Green","Fraser Brown","Claire Le Goues"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18681v1","updated":"2026-02-21T01:06:13Z","published":"2026-02-21T01:06:13Z","title":"Media Integrity and Authentication: Status, Directions, and Futures","summary":"We provide background on emerging challenges and future directions with media integrity and authentication methods, focusing on distinguishing AI-generated media from authentic content captured by cameras and microphones. We evaluate several approaches, including provenance, watermarking, and fingerprinting. After defining each method, we analyze three representative technologies: cryptographically secured provenance, imperceptible watermarking, and soft-hash fingerprinting. We analyze how these tools operate across modalities and evaluate relevant threat models, attack categories, and real-world workflows spanning capture, editing, distribution, and verification. We consider sociotechnical reversal attacks that can invert integrity signals, making authentic content appear synthetic and vice versa, highlighting the value of verification systems that are resilient to both technical and psychosocial manipulation. Finally, we outline techniques for delivering high-confidence provenance authentication, including directions for strengthening edge-device security using secure enclaves.","authors":["Jessica Young","Sam Vaughan","Andrew Jenks","Henrique Malvar","Christian Paquin","Paul England","Thomas Roca","Juan LaVista Ferres","Forough Poursabzi","Neil Coles","Ken Archer","Eric Horvitz"],"pdf_url":"","comment":"56 pages"},{"id":"http://arxiv.org/abs/2602.20193v1","updated":"2026-02-21T23:48:04Z","published":"2026-02-21T23:48:04Z","title":"When Backdoors Go Beyond Triggers: Semantic Drift in Diffusion Models Under Encoder Attacks","summary":"Standard evaluations of backdoor attacks on text-to-image (T2I) models primarily measure trigger activation and visual fidelity. We challenge this paradigm, demonstrating that encoder-side poisoning induces persistent, trigger-free semantic corruption that fundamentally reshapes the representation manifold. We trace this vulnerability to a geometric mechanism: a Jacobian-based analysis reveals that backdoors act as low-rank, target-centered deformations that amplify local sensitivity, causing distortion to propagate coherently across semantic neighborhoods. To rigorously quantify this structural degradation, we introduce SEMAD (Semantic Alignment and Drift), a diagnostic framework that measures both internal embedding drift and downstream functional misalignment. Our findings, validated across diffusion and contrastive paradigms, expose the deep structural risks of encoder poisoning and highlight the necessity of geometric audits beyond simple attack success rates.","authors":["Shenyang Chen","Liuwan Zhu"],"pdf_url":"","comment":null}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2507.03831v4","updated":"2026-02-21T22:49:04Z","published":"2025-07-04T22:40:03Z","title":"Query-Based Adaptive Aggregation for Multi-Dataset Joint Training Toward Universal Visual Place Recognition","summary":"Deep learning methods for Visual Place Recognition (VPR) have advanced significantly, largely driven by large-scale datasets. However, most existing approaches are trained on a single dataset, which can introduce dataset-specific inductive biases and limit model generalization. While multi-dataset joint training offers a promising solution for developing universal VPR models, divergences among training datasets can saturate the limited information capacity in feature aggregation layers, leading to suboptimal performance. To address these challenges, we propose Query-based Adaptive Aggregation (QAA), a novel feature aggregation technique that leverages learned queries as reference codebooks to effectively enhance information capacity without significant computational or parameter complexity. We show that computing the Cross-query Similarity (CS) between query-level image features and reference codebooks provides a simple yet effective way to generate robust descriptors. Our results demonstrate that QAA outperforms state-of-the-art models, achieving balanced generalization across diverse datasets while maintaining peak performance comparable to dataset-specific models. Ablation studies further explore QAA's mechanisms and scalability. Visualizations reveal that the learned queries exhibit diverse attention patterns across datasets. Project page: http://xjh19971.github.io/QAA.","authors":["Jiuhong Xiao","Yang Zhou","Giuseppe Loianno"],"pdf_url":"","comment":"8 pages, 4 figures, accepted at ICRA 2026"},{"id":"http://arxiv.org/abs/2602.18976v1","updated":"2026-02-21T22:44:40Z","published":"2026-02-21T22:44:40Z","title":"Bumper Drone: Elastic Morphology Design for Aerial Physical Interaction","summary":"Aerial robots are evolving from avoiding obstacles to exploiting the environmental contact interactions for navigation, exploration and manipulation. A key challenge in such aerial physical interactions lies in handling uncertain contact forces on unknown targets, which typically demand accurate sensing and active control. We present a drone platform with elastic horns that enables touch-and-go manoeuvres - a self-regulated, consecutive bumping motion that allows the drone to maintain proximity to a wall without relying on active obstacle avoidance. It leverages environmental interaction as a form of embodied control, where low-level stabilisation and near-obstacle navigation emerge from the passive dynamic responses of the drone-obstacle system that resembles a mass-spring-damper system. Experiments show that the elastic horn can absorb impact energy while maintaining vehicle stability, reducing pitch oscillations by 38% compared to the rigid horn configuration. The lower horn arrangement was found to reduce pitch oscillations by approximately 54%. In addition to intermittent contact, the platform equipped with elastic horns also demonstrates stable, sustained contact with static objects, relying on a standard attitude PID controller.","authors":["Pongporn Supa","Alex Dunnett","Feng Xiao","Rui Wu","Mirko Kovac","Basaran Bahadir Kocer"],"pdf_url":"","comment":"Accepted to the 9th IEEE-RAS International Conference on Soft Robotics (RoboSoft) 2026"},{"id":"http://arxiv.org/abs/2602.18967v1","updated":"2026-02-21T22:18:17Z","published":"2026-02-21T22:18:17Z","title":"TactEx: An Explainable Multimodal Robotic Interaction Framework for Human-Like Touch and Hardness Estimation","summary":"Accurate perception of object hardness is essential for safe and dexterous contact-rich robotic manipulation. Here, we present TactEx, an explainable multimodal robotic interaction framework that unifies vision, touch, and language for human-like hardness estimation and interactive guidance. We evaluate TactEx on fruit-ripeness assessment, a representative task that requires both tactile sensing and contextual understanding. The system fuses GelSight-Mini tactile streams with RGB observations and language prompts. A ResNet50+LSTM model estimates hardness from sequential tactile data, while a cross-modal alignment module combines visual cues with guidance from a large language model (LLM). This explainable multimodal interface allows users to distinguish ripeness levels with statistically significant class separation (p < 0.01 for all fruit pairs). For touch placement, we compare YOLO with Grounded-SAM (GSAM) and find GSAM to be more robust for fine-grained segmentation and contact-site selection. A lightweight LLM parses user instructions and produces grounded natural-language explanations linked to the tactile outputs. In end-to-end evaluations, TactEx attains 90% task success on simple user queries and generalises to novel tasks without large-scale tuning. These results highlight the promise of combining pretrained visual and tactile models with language grounding to advance explainable, human-like touch perception and decision-making in robotics.","authors":["Felix Verstraete","Lan Wei","Wen Fan","Dandan Zhang"],"pdf_url":"","comment":"Accepted by 2026 ICRA"},{"id":"http://arxiv.org/abs/2602.18951v1","updated":"2026-02-21T20:08:46Z","published":"2026-02-21T20:08:46Z","title":"Temporal-Logic-Aware Frontier-Based Exploration","summary":"This paper addresses the problem of temporal logic motion planning for an autonomous robot operating in an unknown environment. The objective is to enable the robot to satisfy a syntactically co-safe Linear Temporal Logic (scLTL) specification when the exact locations of the desired labels are not known a priori. We introduce a new type of automaton state, referred to as commit states. These states capture intermediate task progress resulting from actions whose consequences are irreversible. In other words, certain future paths to satisfaction become not feasible after taking those actions that lead to the commit states. By leveraging commit states, we propose a sound and complete frontier-based exploration algorithm that strategically guides the robot to make progress toward the task while preserving all possible ways of satisfying it. The efficacy of the proposed method is validated through simulations.","authors":["Azizollah Taheri","Derya Aksaray"],"pdf_url":"","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2511.10376v3","updated":"2026-02-21T18:56:19Z","published":"2025-11-13T14:51:21Z","title":"MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation","summary":"Embodied navigation is a fundamental capability for robotic agents operating. Real-world deployment requires open vocabulary generalization and low training overhead, motivating zero-shot methods rather than task-specific RL training. However, existing zero-shot methods that build explicit 3D scene graphs often compress rich visual observations into text-only relations, leading to high construction cost, irreversible loss of visual evidence, and constrained vocabularies. To address these limitations, we introduce the Multi-modal 3D Scene Graph (M3DSG), which preserves visual cues by replacing textual relation","authors":["Xun Huang","Shijia Zhao","Yunxiang Wang","Xin Lu","Wanfa Zhang","Rongsheng Qu","Weixin Li","Yunhong Wang","Chenglu Wen"],"pdf_url":"","comment":"18 pages, Accepted by CVPR 2026"},{"id":"http://arxiv.org/abs/2509.16650v2","updated":"2026-02-21T18:23:54Z","published":"2025-09-20T11:55:24Z","title":"Safe and Near-Optimal Control with Online Dynamics Learning","summary":"Achieving both optimality and safety under unknown system dynamics is a central challenge in real-world deployment of agents. To address this, we introduce a notion of maximum safe dynamics learning, where sufficient exploration is performed within the space of safe policies. Our method executes $\\textit{pessimistically}$ safe policies while $\\textit{optimistically}$ exploring informative states and, despite not reaching them due to model uncertainty, ensures continuous online learning of dynamics. The framework achieves first-of-its-kind results: learning the dynamics model sufficiently $-$ up to an arbitrary small tolerance (subject to noise) $-$ in a finite time, while ensuring provably safe operation throughout with high probability and without requiring resets. Building on this, we propose an algorithm to maximize rewards while learning the dynamics $\\textit{only to the extent needed}$ to achieve close-to-optimal performance. Unlike typical reinforcement learning (RL) methods, our approach operates online in a non-episodic setting and ensures safety throughout the learning process. We demonstrate the effectiveness of our approach in challenging domains such as autonomous car racing and drone navigation under aerodynamic effects $-$ scenarios where safety is critical and accurate modeling is difficult.","authors":["Manish Prajapat","Johannes Köhler","Melanie N. Zeilinger","Andreas Krause"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11103v2","updated":"2026-02-21T17:10:30Z","published":"2025-10-13T07:49:21Z","title":"A Primer on SO(3) Action Representations in Deep Reinforcement Learning","summary":"Many robotic control tasks require policies to act on orientations, yet the geometry of SO(3) makes this nontrivial. Because SO(3) admits no global, smooth, minimal parameterization, common representations such as Euler angles, quaternions, rotation matrices, and Lie algebra coordinates introduce distinct constraints and failure modes. While these trade-offs are well studied for supervised learning, their implications for actions in reinforcement learning remain unclear. We systematically evaluate SO(3) action representations across three standard continuous control algorithms, PPO, SAC, and TD3, under dense and sparse rewards. We compare how representations shape exploration, interact with entropy regularization, and affect training stability through empirical studies and analyze the implications of different projections for obtaining valid rotations from Euclidean network outputs. Across a suite of robotics benchmarks, we quantify the practical impact of these choices and distill simple, implementation-ready guidelines for selecting and using rotation actions. Our results highlight that representation-induced geometry strongly influences exploration and optimization and show that representing actions as tangent vectors in the local frame yields the most reliable results across algorithms. The project webpage and code are available at amacati.github.io/so3 primer.","authors":["Martin Schuck","Sherif Samy","Angela P. Schoellig"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18872v1","updated":"2026-02-21T15:39:22Z","published":"2026-02-21T15:39:22Z","title":"Equivalence and Divergence of Bayesian Log-Odds and Dempster's Combination Rule for 2D Occupancy Grids","summary":"We introduce a pignistic-transform-based methodology for fair comparison of Bayesian log-odds and Dempster's combination rule in occupancy grid mapping, matching per-observation decision probabilities to isolate the fusion rule from sensor parameterization. Under BetP matching across simulation, two real lidar datasets, and downstream path planning, Bayesian fusion is consistently favored (15/15 directional consistency, p = 3.1e-5) with small absolute differences (0.001-0.022). Under normalized plausibility matching, the direction reverses, confirming the result is matching-criterion-specific. The methodology is reusable for any future Bayesian/belief function comparison.","authors":["Tatiana Berlenko","Kirill Krinkin"],"pdf_url":"","comment":"29 pages, 6 figures, 6 tables. Includes complete proofs, ablation studies, and supplementary statistical analysis"},{"id":"http://arxiv.org/abs/2602.18862v1","updated":"2026-02-21T15:04:37Z","published":"2026-02-21T15:04:37Z","title":"Gait Asymmetry from Unilateral Weakness and Improvement With Ankle Assistance: a Reinforcement Learning based Simulation Study","summary":"Unilateral muscle weakness often leads to asymmetric gait, disrupting interlimb coordination and stance timing. This study presents a reinforcement learning (RL) based musculoskeletal simulation framework to (1) quantify how progressive unilateral muscle weakness affects gait symmetry and (2) evaluate whether ankle exoskeleton assistance can improve gait symmetry under impaired conditions. The overarching goal is to establish a simulation- and learning-based workflow that supports early controller development prior to patient experiments. Asymmetric gait was induced by reducing right-leg muscle strength to 75%, 50%, and 25% of baseline. Gait asymmetry was quantified using toe-off timing, peak contact forces, and joint-level symmetry metrics. Increasing weakness produced progressively larger temporal and kinematic asymmetry, most pronounced at the ankle. Ankle range of motion symmetry degraded from near-symmetric behavior at 100% strength (symmetry index, SI = +6.4%; correlation r=0.974) to severe asymmetry at 25% strength (SI = -47.1%, r=0.889), accompanied by a load shift toward the unimpaired limb. At 50% strength, ankle exoskeleton assistance improved kinematic symmetry relative to the unassisted impaired condition, reducing the magnitude of ankle SI from 25.8% to 18.5% and increasing ankle correlation from r=0.948 to 0.966, although peak loading remained biased toward the unimpaired side. Overall, this framework supports controlled evaluation of impairment severity and assistive strategies, and provides a basis for future validation in human experiments.","authors":["Yifei Yuan","Ghaith Androwis","Xianlian Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.00497v2","updated":"2026-02-21T14:58:13Z","published":"2025-08-30T13:38:42Z","title":"FLUID: A Fine-Grained Lightweight Urban Signalized-Intersection Dataset of Dense Conflict Trajectories","summary":"The trajectory data of traffic participants (TPs) is a fundamental resource for evaluating traffic conditions and optimizing policies, especially at urban intersections. Although data acquisition using drones is efficient, existing datasets still have limitations in scene representativeness, information richness, and data fidelity. This study introduces FLUID, comprising a fine-grained trajectory dataset that captures dense conflicts at typical urban signalized intersections, and a lightweight, full-pipeline framework for drone-based trajectory processing. FLUID covers three distinct intersection types, with approximately 5 hours of recording time and featuring over 20,000 TPs across 8 categories. Notably, the dataset records an average of 2.8 vehicle conflicts per minute across all scenes, with roughly 15% of all recorded motor vehicles directly involved in these conflicts. FLUID provides comprehensive data, including trajectories, traffic signals, maps, and raw videos. Comparison with the DataFromSky platform and ground-truth measurements validates its high spatio-temporal accuracy. Through a detailed classification of motor vehicle conflicts and violations, FLUID reveals a diversity of interactive behaviors, demonstrating its value for human preference mining, traffic behavior modeling, and autonomous driving research.","authors":["Yiyang Chen","Zhigang Wu","Guohong Zheng","Xuesong Wu","Liwen Xu","Haoyuan Tang","Zhaocheng He","Haipeng Zeng"],"pdf_url":"","comment":"30 pages, 16 figures"},{"id":"http://arxiv.org/abs/2602.18850v1","updated":"2026-02-21T14:27:10Z","published":"2026-02-21T14:27:10Z","title":"When the Inference Meets the Explicitness or Why Multimodality Can Make Us Forget About the Perfect Predictor","summary":"Although in the literature it is common to find predictors and inference systems that try to predict human intentions, the uncertainty of these models due to the randomness of human behavior has led some authors to start advocating the use of communication systems that explicitly elicit human intention. In this work, it is analyzed the use of four different communication systems with a human-robot collaborative object transportation task as experimental testbed: two intention predictors (one based on force prediction and another with an enhanced velocity prediction algorithm) and two explicit communication methods (a button interface and a voice-command recognition system). These systems were integrated into IVO, a custom mobile social robot equipped with force sensor to detect the force exchange between both agents and LiDAR to detect the environment. The collaborative task required transporting an object over a 5-7 meter distance with obstacles in the middle, demanding rapid decisions and precise physical coordination. 75 volunteers perform a total of 255 executions divided into three groups, testing inference systems in the first round, communication systems in the second, and the combined strategies in the third. The results show that, 1) once sufficient performance is achieved, the human no longer notices and positively assesses technical improvements; 2) the human prefers systems that are more natural to them even though they have higher failure rates; and 3) the preferred option is the right combination of both systems.","authors":["J. E. Domínguez-Vidal","Alberto Sanfeliu"],"pdf_url":"","comment":"Original version submitted to the International Journal of Social Robotics. Final version available on the SORO website"},{"id":"http://arxiv.org/abs/2602.18835v1","updated":"2026-02-21T13:42:04Z","published":"2026-02-21T13:42:04Z","title":"GRAB: A Systematic Real-World Grasping Benchmark for Robotic Food Waste Sorting","summary":"Food waste management is critical for sustainability, yet inorganic contaminants hinder recycling potential. Robotic automation presents a compelling approach to this challenge by accelerating the sorting process through automated contaminant removal. Still, the diverse and unpredictable nature of contaminants creates major challenges for robotic grasping. Benchmarking frameworks are critical for evaluating challenges from various perspectives. However, existing protocols rely on limited simulation datasets, prioritise simple metrics such as success rate, and overlook key object and environment-related pre-grasp conditions. This paper introduces GRAB, a comprehensive Grasping Real-World Article Benchmarking framework that addresses this gap by integrating diverse deformable objects, advanced grasp-pose-estimation vision, and, importantly, pre-grasp conditions, establishing a set of critical graspability metrics. It systematically compares industrial grasping modalities through an in-depth experimental evaluation involving 1,750 food contaminant grasp attempts across four high-fidelity scenes. This large-scale evaluation provides an extensive assessment of grasp performance for food waste sorting, offering a level of depth that has rarely been explored in previous studies. The results reveal distinct gripper strengths and limitations, with object quality emerging as the dominant performance factor in cluttered environments, while vision quality and clutter levels play moderate roles. These findings highlight essential design considerations and reinforce the necessity of developing multimodal gripper technologies capable of robust cross-category performance for effective robotic food waste sorting.","authors":["Moniesha Thilakarathna","Xing Wang","Min Wang","David Hinwood","Shuangzhe Liu","Damith Herath"],"pdf_url":"","comment":"23 pages, 12 Figures, 3 Tables, submitted to Advanced Intelligent Systems Journal and under review"},{"id":"http://arxiv.org/abs/2602.18814v1","updated":"2026-02-21T12:19:03Z","published":"2026-02-21T12:19:03Z","title":"RotorSuite: A MATLAB/Simulink Toolbox for Tilt Multi-Rotor UAV Modeling","summary":"In recent years, aerial platforms have evolved from passive flying sensors into versatile, contact-aware robotic systems, leading to rapid advances in platform design. Standard coplanar and collinear quadrotors have been complemented by modern tilted and tilting multi-rotor platforms with enhanced maneuverability. To properly analyze, control, and validate the performance of these emerging platforms, an accurate modeling step is required; however, this can be time-consuming, user-dependent and error-prone. To address this issue, we propose a MATLAB/Simulink toolbox for modeling and simulating the dynamics of a broad class of multi-rotor platforms through both an analytical and physics-based approaches. The toolbox, named RotorSuite, is provided with comprehensive documentation and example use cases, representing a valuable tool for didactic, research, and industrial development purposes.","authors":["Nicola Cigarini","Giulia Michieletto","Angelo Cenedese"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18813v1","updated":"2026-02-21T12:15:49Z","published":"2026-02-21T12:15:49Z","title":"Habilis-$β$: A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model","summary":"We introduce Habilis-$β$, a fast-motion and long-lasting on-device vision-language-action (VLA) model designed for real-world deployment. Current VLA evaluation remains largely confined to single-trial success rates under curated resets, which fails to capture the fast-motion and long-lasting capabilities essential for practical operation. To address this, we introduce the Productivity-Reliability Plane (PRP), which evaluates performance through Tasks per Hour (TPH) and Mean Time Between Intervention (MTBI) under a continuous-run protocol that demands both high-speed execution and sustained robustness. Habilis-$β$ achieves high performance by integrating language-free pre-training on large-scale play data for robust interaction priors with post-training on cyclic task demonstrations that capture state drift across consecutive task iterations. The system further employs ESPADA for phase-adaptive motion shaping to accelerate free-space transit, utilizes rectified-flow distillation to enable high-frequency control on edge devices, and incorporates classifier-free guidance (CFG) as a deployment-time knob to dynamically balance instruction adherence and learned interaction priors. In 1-hour continuous-run evaluations, Habilis-$β$ achieves strong performance under the PRP metrics, compared to $π_{0.5}$ in both simulation and real-world environments. In simulation, Habilis-$β$ achieves 572.6 TPH and 39.2 s MTBI (vs. 120.5 TPH and 30.5 s for $π_{0.5}$), while in a real-world humanoid logistics workflow it achieves 124 TPH and 137.4 s MTBI (vs. 19 TPH and 46.1 s for $π_{0.5}$). Finally, Habilis-$β$ achieves the highest reported performance on the standard RoboTwin 2.0 leaderboard across representative tasks, validating its effectiveness in complex manipulation scenarios.","authors":["Tommoro Robotics"," :","Jesoon Kang","Taegeon Park","Jisu An","Soo Min Kimm","Jaejoon Kim","Jinu Pahk","Byungju Kim","Junseok Lee","Namheon Baek","Sungwan Ha","Hojun Baek","Eduardo Ayerve Cruz","Wontae Kim","Junghyeon Choi","Yousuk Lee","Joonmo Han","Sunghyun Cho","Sunghyun Kwon","Soyoung Lee","Jun Ki Lee","Seung-Joon Yi","Byoung-Tak Zhang","Theo Taeyeong Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18803v1","updated":"2026-02-21T11:33:00Z","published":"2026-02-21T11:33:00Z","title":"Learning to Localize Reference Trajectories in Image-Space for Visual Navigation","summary":"We present LoTIS, a model for visual navigation that provides robot-agnostic image-space guidance by localizing a reference RGB trajectory in the robot's current view, without requiring camera calibration, poses, or robot-specific training. Instead of predicting actions tied to specific robots, we predict the image-space coordinates of the reference trajectory as they would appear in the robot's current view. This creates robot-agnostic visual guidance that easily integrates with local planning. Consequently, our model's predictions provide guidance zero-shot across diverse embodiments. By decoupling perception from action and learning to localize trajectory points rather than imitate behavioral priors, we enable a cross-trajectory training strategy for robustness to viewpoint and camera changes. We outperform state-of-the-art methods by 20-50 percentage points in success rate on conventional forward navigation, achieving 94-98% success rate across diverse sim and real environments. Furthermore, we achieve over 5x improvements on challenging tasks where baselines fail, such as backward traversal. The system is straightforward to use: we show how even a video from a phone camera directly enables different robots to navigate to any point on the trajectory. Videos, demo, and code are available at https://finnbusch.com/lotis.","authors":["Finn Lukas Busch","Matti Vahs","Quantao Yang","Jesús Gerardo Ortega Peimbert","Yixi Cai","Jana Tumova","Olov Andersson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.11231v2","updated":"2026-02-21T11:30:37Z","published":"2026-01-16T12:21:27Z","title":"Adaptive Monitoring of Stochastic Fire Front Processes via Information-seeking Predictive Control","summary":"We consider the problem of adaptively monitoring a wildfire front using a mobile agent (e.g., a drone), whose trajectory determines where sensor data is collected and thus influences the accuracy of fire propagation estimation. This is a challenging problem, as the stochastic nature of wildfire evolution requires the seamless integration of sensing, estimation, and control, often treated separately in existing methods. State-of-the-art methods either impose linear-Gaussian assumptions to establish optimality or rely on approximations and heuristics, often without providing explicit performance guarantees. To address these limitations, we formulate the fire front monitoring task as a stochastic optimal control problem that integrates sensing, estimation, and control. We derive an optimal recursive Bayesian estimator for a class of stochastic nonlinear elliptical-growth fire front models. Subsequently, we transform the resulting nonlinear stochastic control problem into a finite-horizon Markov decision process and design an information-seeking predictive control law obtained via a lower confidence bound-based adaptive search algorithm with asymptotic convergence to the optimal policy.","authors":["Savvas Papaioannou","Panayiotis Kolios","Christos G. Panayiotou","Marios M. Polycarpou"],"pdf_url":"","comment":"2025 IEEE 64th Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2512.17321v2","updated":"2026-02-21T08:57:56Z","published":"2025-12-19T08:08:40Z","title":"Neuro-Symbolic Control with Large Language Models for Language-Guided Spatial Tasks","summary":"Although large language models (LLMs) have recently become effective tools for language-conditioned control in embodied systems, instability, slow convergence, and hallucinated actions continue to limit their direct application to continuous control. A modular neuro-symbolic control framework that clearly distinguishes between low-level motion execution and high-level semantic reasoning is proposed in this work. While a lightweight neural delta controller performs bounded, incremental actions in continuous space, a locally deployed LLM interprets symbolic tasks. We assess the suggested method in a planar manipulation setting with spatial relations between objects specified by language. Numerous tasks and local language models, such as Mistral, Phi, and LLaMA-3.2, are used in extensive experiments to compare LLM-only control, neural-only control, and the suggested LLM+DL framework. In comparison to LLM-only baselines, the results show that the neuro-symbolic integration consistently increases both success rate and efficiency, achieving average step reductions exceeding 70% and speedups of up to 8.83x while remaining robust to language model quality. The suggested framework enhances interpretability, stability, and generalization without any need of reinforcement learning or costly rollouts by controlling the LLM to symbolic outputs and allocating uninterpreted execution to a neural controller trained on artificial geometric data. These outputs show empirically that neuro-symbolic decomposition offers a scalable and principled way to integrate language understanding with ongoing control, this approach promotes the creation of dependable and effective language-guided embodied systems.","authors":["Momina Liaqat Ali","Muhammad Abid","Muhammad Saqlain","Jose M. Merigo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.24243v3","updated":"2026-02-21T08:32:36Z","published":"2025-09-29T03:33:33Z","title":"SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control Barrier Functions","summary":"Generative planners based on flow matching (FM) produce high-quality paths in a single or a few ODE steps, but their sampling dynamics offer no formal safety guarantees and can yield incomplete paths near constraints. We present SafeFlowMatcher, a planning framework that couples FM with control barrier functions (CBFs) to achieve both real-time efficiency and certified safety. SafeFlowMatcher uses a two-phase (PC) integrator: (i) a prediction phase integrates the learned FM once (or a few steps) to obtain a candidate path without intervention; (ii) a correction phase refines this path with a vanishing time-scaled vector field and a CBF-based quadratic program that minimally perturbs the vector field. We prove a barrier certificate for the resulting flow system, establishing forward invariance of a robust safe set and finite-time convergence to the safe set. In addition, by enforcing safety only on the executed path, rather than all intermediate latent paths, SafeFlowMatcher avoids distributional drift and mitigates local trap problems. Moreover, SafeFlowMatcher attains faster, smoother, and safer paths than diffusion- and FM-based baselines on maze navigation, locomotion, and robot manipulation tasks. Extensive ablations corroborate the contributions of the PC integrator and the barrier certificate.","authors":["Jeongyong Yang","Seunghwan Jang","SooJean Han"],"pdf_url":"","comment":"ICLR 2026(poster)"},{"id":"http://arxiv.org/abs/2411.17195v2","updated":"2026-02-21T08:08:01Z","published":"2024-11-26T08:09:57Z","title":"Depth-PC: A Visual Servo Framework Integrated with Cross-Modality Fusion for Sim2Real Transfer","summary":"Visual servoing techniques guide robotic motion using visual information to accomplish manipulation tasks, requiring high precision and robustness against noise. Traditional methods often require prior knowledge and are susceptible to external disturbances. Learning-driven alternatives, while promising, frequently struggle with the scarcity of training data and fall short in generalization. To address these challenges, we propose Depth-PC, a novel visual servoing framework that leverages decoupled simulation-based training from real-world inference, achieving zero-shot Sim2Real transfer for servo tasks. To exploit spatial and geometric information of depth and point cloud features, we introduce cross-modal feature fusion, a first in servo tasks, followed by a dedicated Graph Neural Network to establish keypoint correspondences. Through simulation and real-world experiments, our approach demonstrates superior convergence basin and accuracy compared to SOTA methods, fulfilling the requirements for robotic servo tasks while enabling zero-shot Sim2Real transfer. In addition to the enhancements achieved with our proposed framework, we have also demonstrated the effectiveness of cross-modality feature fusion within the realm of servo tasks. Code is available at https://github.com/3nnui/Depth-PC.","authors":["Haoyu Zhang","Yang Liu","Yimu Jiang","Weiyang Lin","Chao Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18742v1","updated":"2026-02-21T07:33:24Z","published":"2026-02-21T07:33:24Z","title":"RoboCurate: Harnessing Diversity with Action-Verified Neural Trajectory for Robot Learning","summary":"Synthetic data generated by video generative models has shown promise for robot learning as a scalable pipeline, but it often suffers from inconsistent action quality due to imperfectly generated videos. Recently, vision-language models (VLMs) have been leveraged to validate video quality, but they have limitations in distinguishing physically accurate videos and, even then, cannot directly evaluate the generated actions themselves. To tackle this issue, we introduce RoboCurate, a novel synthetic robot data generation framework that evaluates and filters the quality of annotated actions by comparing them with simulation replay. Specifically, RoboCurate replays the predicted actions in a simulator and assesses action quality by measuring the consistency of motion between the simulator rollout and the generated video. In addition, we unlock observation diversity beyond the available dataset via image-to-image editing and apply action-preserving video-to-video transfer to further augment appearance. We observe RoboCurate's generated data yield substantial relative improvements in success rates compared to using real data only, achieving +70.1% on GR-1 Tabletop (300 demos), +16.1% on DexMimicGen in the pre-training setup, and +179.9% in the challenging real-world ALLEX humanoid dexterous manipulation setting.","authors":["Seungku Kim","Suhyeok Jang","Byungjun Yoon","Dongyoung Kim","John Won","Jinwoo Shin"],"pdf_url":"","comment":"20 pages; 6 figures; Project page is available at https://seungkukim.github.io/robocurate/"},{"id":"http://arxiv.org/abs/2602.18735v1","updated":"2026-02-21T06:55:28Z","published":"2026-02-21T06:55:28Z","title":"LaS-Comp: Zero-shot 3D Completion with Latent-Spatial Consistency","summary":"This paper introduces LaS-Comp, a zero-shot and category-agnostic approach that leverages the rich geometric priors of 3D foundation models to enable 3D shape completion across diverse types of partial observations. Our contributions are threefold: First, \\ourname{} harnesses these powerful generative priors for completion through a complementary two-stage design: (i) an explicit replacement stage that preserves the partial observation geometry to ensure faithful completion; and (ii) an implicit refinement stage ensures seamless boundaries between the observed and synthesized regions. Second, our framework is training-free and compatible with different 3D foundation models. Third, we introduce Omni-Comp, a comprehensive benchmark combining real-world and synthetic data with diverse and challenging partial patterns, enabling a more thorough and realistic evaluation. Both quantitative and qualitative experiments demonstrate that our approach outperforms previous state-of-the-art approaches. Our code and data will be available at \\href{https://github.com/DavidYan2001/LaS-Comp}{LaS-Comp}. ","authors":["Weilong Yan","Haipeng Li","Hao Xu","Nianjin Ye","Yihao Ai","Shuaicheng Liu","Jingyu Hu"],"pdf_url":"","comment":"Accepted to CVPR2026"},{"id":"http://arxiv.org/abs/2512.19010v2","updated":"2026-02-21T05:56:05Z","published":"2025-12-22T03:53:09Z","title":"PalpAid: Multimodal Pneumatic Tactile Sensor for Tissue Palpation","summary":"The tactile properties of tissue, such as elasticity and stiffness, often play an important role in surgical oncology when identifying tumors and pathological tissue boundaries. Though extremely valuable, robot-assisted surgery comes at the cost of reduced sensory information to the surgeon, with vision being the primary. Sensors proposed to overcome this sensory desert are often bulky, complex, and incompatible with the surgical workflow. We present PalpAid, a multimodal pneumatic tactile sensor to restore touch in robot-assisted surgery. PalpAid is equipped with a microphone and pressure sensor, converting contact force into an internal pressure differential. The pressure sensor acts as an event detector, while the acoustic signature assists in tissue identification. We show the design, fabrication, and assembly of sensory units with characterization tests for robustness to use, repetition cycles, and integration with a robotic system. Finally, we demonstrate the sensor's ability to classify 3D-printed hard objects with varying infills and soft ex vivo tissues. We envision PalpAid to be easily retrofitted with existing surgical/general robotic systems, allowing soft tissue palpation.","authors":["Devi Yuliarti","Ravi Prakash","Hiu Ching Cheung","Amy Strong","Patrick J. Codd","Shan Lin"],"pdf_url":"","comment":"IEEE-RAS RoboSoft 2026"},{"id":"http://arxiv.org/abs/2602.18716v1","updated":"2026-02-21T04:31:55Z","published":"2026-02-21T04:31:55Z","title":"Temporal Action Representation Learning for Tactical Resource Control and Subsequent Maneuver Generation","summary":"Autonomous robotic systems should reason about resource control and its impact on subsequent maneuvers, especially when operating with limited energy budgets or restricted sensing. Learning-based control is effective in handling complex dynamics and represents the problem as a hybrid action space unifying discrete resource usage and continuous maneuvers. However, prior works on hybrid action space have not sufficiently captured the causal dependencies between resource usage and maneuvers. They have also overlooked the multi-modal nature of tactical decisions, both of which are critical in fast-evolving scenarios. In this paper, we propose TART, a Temporal Action Representation learning framework for Tactical resource control and subsequent maneuver generation. TART leverages contrastive learning based on a mutual information objective, designed to capture inherent temporal dependencies in resource-maneuver interactions. These learned representations are quantized into discrete codebook entries that condition the policy, capturing recurring tactical patterns and enabling multi-modal and temporally coherent behaviors. We evaluate TART in two domains where resource deployment is critical: (i) a maze navigation task where a limited budget of discrete actions provides enhanced mobility, and (ii) a high-fidelity air combat simulator in which an F-16 agent operates weapons and defensive systems in coordination with flight maneuvers. Across both domains, TART consistently outperforms hybrid-action baselines, demonstrating its effectiveness in leveraging limited resources and producing context-aware subsequent maneuvers.","authors":["Hoseong Jung","Sungil Son","Daesol Cho","Jonghae Park","Changhyun Choi","H. Jin Kim"],"pdf_url":"","comment":"ICRA 2026, 8 pages"},{"id":"http://arxiv.org/abs/2602.18709v1","updated":"2026-02-21T03:57:01Z","published":"2026-02-21T03:57:01Z","title":"IRIS-SLAM: Unified Geo-Instance Representations for Robust Semantic Localization and Mapping","summary":"Geometry foundation models have significantly advanced dense geometric SLAM, yet existing systems often lack deep semantic understanding and robust loop closure capabilities. Meanwhile, contemporary semantic mapping approaches are frequently hindered by decoupled architectures and fragile data association. We propose IRIS-SLAM, a novel RGB semantic SLAM system that leverages unified geometric-instance representations derived from an instance-extended foundation model. By extending a geometry foundation model to concurrently predict dense geometry and cross-view consistent instance embeddings, we enable a semantic-synergized association mechanism and instance-guided loop closure detection. Our approach effectively utilizes viewpoint-agnostic semantic anchors to bridge the gap between geometric reconstruction and open-vocabulary mapping. Experimental results demonstrate that IRIS-SLAM significantly outperforms state-of-the-art methods, particularly in map consistency and wide-baseline loop closure reliability.","authors":["Tingyang Xiao","Liu Liu","Wei Feng","Zhengyu Zou","Xiaolin Zhou","Wei Sui","Hao Li","Dingwen Zhang","Zhizhong Su"],"pdf_url":"","comment":"15 pages"},{"id":"http://arxiv.org/abs/2602.18707v1","updated":"2026-02-21T03:39:33Z","published":"2026-02-21T03:39:33Z","title":"CLASH: Collision Learning via Augmented Sim-to-real Hybridization to Bridge the Reality Gap","summary":"The sim-to-real gap, particularly in the inaccurate modeling of contact-rich dynamics like collisions, remains a primary obstacle to deploying robot policies trained in simulation. Conventional physics engines often trade accuracy for computational speed, leading to discrepancies that prevent direct policy transfer. To address this, we introduce Collision Learning via Augmented Sim-to-real Hybridization (CLASH), a data-efficient framework that creates a high-fidelity hybrid simulator by learning a surrogate collision model from a minimal set of real-world data. In CLASH, a base model is first distilled from an imperfect simulator (MuJoCo) to capture general physical priors; this model is then fine-tuned with a remarkably small number of real-world interactions (as few as 10 samples) to correct for the simulator's inherent inaccuracies. The resulting hybrid simulator not only achieves higher predictive accuracy but also reduces collision computation time by nearly 50\\%. We demonstrate that policies obtained with our hybrid simulator transfer more robustly to the real world, doubling the success rate in sequential pushing tasks with reinforecement learning and significantly increase the task performance with model-based control.","authors":["Haotian He","Ning Guo","Siqi Shi","Qipeng Liu","Wenzhao Lian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23575v2","updated":"2026-02-21T01:51:02Z","published":"2025-09-28T02:11:47Z","title":"Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints","summary":"Hierarchical coarse-to-fine policy, where a coarse branch predicts a region of interest to guide a fine-grained action predictor, has demonstrated significant potential in robotic 3D manipulation tasks by especially enhancing sample efficiency and enabling more precise manipulation. However, even augmented with pre-trained models, these hierarchical policies still suffer from generalization issues. To enhance generalization to novel instructions and environment variations, we propose Coarse-to-fine Language-Aligned manipulation Policy (CLAP), a framework that integrates three key components: 1) task decomposition, 2) VLM fine-tuning for 3D keypoint prediction, and 3) 3D-aware representation. Through comprehensive experiments in simulation and on a real robot, we demonstrate its superior generalization capability. Specifically, on GemBench, a benchmark designed for evaluating generalization, our approach achieves a 12\\% higher average success rate than the SOTA method while using only 1/5 of the training trajectories. In real-world experiments, our policy, trained on only 10 demonstrations, successfully generalizes to novel instructions and environments.","authors":["Jianshu Hu","Lidi Wang","Shujia Li","Yunpeng Jiang","Xiao Li","Paul Weng","Yutong Ban"],"pdf_url":"","comment":"Published in ICLR 2026"},{"id":"http://arxiv.org/abs/2602.18688v1","updated":"2026-02-21T01:41:40Z","published":"2026-02-21T01:41:40Z","title":"Scout-Rover cooperation: online terrain strength mapping and traversal risk estimation for planetary-analog explorations","summary":"Robot-aided exploration of planetary surfaces is essential for understanding geologic processes, yet many scientifically valuable regions, such as Martian dunes and lunar craters, remain hazardous due to loose, deformable regolith. We present a scout-rover cooperation framework that expands safe access to such terrain using a hybrid team of legged and wheeled robots. In our approach, a high-mobility legged robot serves as a mobile scout, using proprioceptive leg-terrain interactions to estimate regolith strength during locomotion and construct spatially resolved terrain maps. These maps are integrated with rover locomotion models to estimate traversal risk and inform path planning.\n  We validate the framework through analogue missions at the NASA Ames Lunar Simulant Testbed and the White Sands Dune Field. Experiments demonstrate (1) online terrain strength mapping from legged locomotion and (2) rover-specific traversal-risk estimation enabling safe navigation to scientific targets. Results show that scout-generated terrain maps reliably capture spatial variability and predict mobility failure modes, allowing risk-aware path planning that avoids hazardous regions. By combining embodied terrain sensing with heterogeneous rover cooperation, this framework enhances operational robustness and expands the reachable science workspace in deformable planetary environments.","authors":["Shipeng Liu","J. Diego Caporale","Yifeng Zhang","Xingjue Liao","William Hoganson","Wilson Hu","Shivangi Misra","Neha Peddinti","Rachel Holladay","Ethan Fulcher","Akshay Ram Panyam","Andrik Puentes","Jordan M. Bretzfelder","Michael Zanetti","Uland Wong","Daniel E. Koditschek","Mark Yim","Douglas Jerolmack","Cynthia Sung","Feifei Qian"],"pdf_url":"","comment":"8 figures"},{"id":"http://arxiv.org/abs/2602.18684v1","updated":"2026-02-21T01:18:34Z","published":"2026-02-21T01:18:34Z","title":"Systematic Analysis of Coupling Effects on Closed-Loop and Open-Loop Performance in Aerial Continuum Manipulators","summary":"This paper investigates two distinct approaches to the dynamic modeling of aerial continuum manipulators (ACMs): the decoupled and the coupled formulations. Both open-loop and closed-loop behaviors of a representative ACM are analyzed. The primary objective is to determine the conditions under which the decoupled model attains accuracy comparable to the coupled model while offering reduced computational cost under identical numerical conditions. The system dynamics are first derived using the Euler--Lagrange method under the piecewise constant curvature (PCC) assumption, with explicit treatment of the near-zero curvature singularity. A decoupled model is then obtained by neglecting the coupling terms in the ACM dynamics, enabling systematic evaluation of open-loop responses under diverse actuation profiles and external wrenches. To extend the analysis to closed-loop performance, a novel dynamics-based proportional-derivative sliding mode image-based visual servoing (DPD-SM-IBVS) controller is developed for regulating image feature errors in the presence of a moving target. The controller is implemented with both coupled and decoupled models, allowing a direct comparison of their effectiveness. The open-loop simulations reveal pronounced discrepancies between the two modeling approaches, particularly under varying torque inputs and continuum arm parameters. Conversely, the closed-loop experiments demonstrate that the decoupled model achieves tracking accuracy on par with the coupled model (within subpixel error) while incurring lower computational cost.","authors":["Niloufar Amiri","Shayan Sepahvand","Iraj Mantegh","Farrokh Janabi-Sharifi"],"pdf_url":"","comment":"Submitted to the 2026 International Conference on Unmanned Aircraft Systems (ICUAS 2026)"},{"id":"http://arxiv.org/abs/2601.21363v3","updated":"2026-02-21T01:04:58Z","published":"2026-01-29T07:43:24Z","title":"Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control","summary":"Reinforcement learning (RL) is widely used for humanoid control, with on-policy methods such as Proximal Policy Optimization (PPO) enabling robust training via large-scale parallel simulation and, in some cases, zero-shot deployment to real robots. However, the low sample efficiency of on-policy algorithms limits safe adaptation to new environments. Although off-policy RL and model-based RL have shown improved sample efficiency, the gap between large-scale pretraining and efficient finetuning on humanoids still exists. In this paper, we find that off-policy Soft Actor-Critic (SAC), with large-batch update and a high Update-To-Data (UTD) ratio, reliably supports large-scale pretraining of humanoid locomotion policies, achieving zero-shot deployment on real robots. For adaptation, we demonstrate that these SAC-pretrained policies can be finetuned in new environments and out-of-distribution tasks using model-based methods. Data collection in the new environment executes a deterministic policy while stochastic exploration is instead confined to a physics-informed world model. This separation mitigates the risks of random exploration during adaptation while preserving exploratory coverage for improvement. Overall, the approach couples the wall-clock efficiency of large-scale simulation during pretraining with the sample efficiency of model-based learning during fine-tuning. For code and videos, see https://lift-humanoid.github.io","authors":["Weidong Huang","Zhehan Li","Hangxin Liu","Biao Hou","Yao Su","Jingwen Zhang"],"pdf_url":"","comment":"ICLR 2026"}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2602.21251v1","updated":"2026-02-21T17:53:30Z","published":"2026-02-21T17:53:30Z","title":"AgenticTyper: Automated Typing of Legacy Software Projects Using Agentic AI","summary":"Legacy JavaScript systems lack type safety, making maintenance risky. While TypeScript can help, manually adding types is expensive. Previous automated typing research focuses on type inference but rarely addresses type checking setup, definition generation, bug identification, or behavioral correctness at repository scale. We present AgenticTyper, a Large Language Model (LLM)-based agentic system that addresses these gaps through iterative error correction and behavior preservation via transpilation comparison. Evaluation on two proprietary repositories (81K LOC) shows that AgenticTyper resolves all 633 initial type errors in 20 minutes, reducing manual effort from one working day.","authors":["Clemens Pohle"],"pdf_url":"","comment":"Accepted at ICSE 2026 Student Research Competition (SRC)"},{"id":"http://arxiv.org/abs/2602.23389v1","updated":"2026-02-21T00:19:48Z","published":"2026-02-21T00:19:48Z","title":"CIll: CTI-Guided Invariant Generation via LLMs for Model Checking","summary":"Inductive invariants are crucial in model checking, yet generating effective inductive invariants automatically and efficiently remains challenging. A common approach is to iteratively analyze counterexamples to induction (CTIs) and derive invariants that rule them out, as in IC3. However, IC3's clause-based learning is limited to a CNF representation. For some designs, the resulting invariants may require a large number of clauses, which hurts scalability. We present CIll, a CTI-guided framework that leverages LLMs to synthesize invariants for model checking. CIll alternates between (bounded) correctness checking and inductiveness checking for the generated invariants. In correctness checking, CIll uses BMC to validate whether the generated invariants hold on reachable states within a given bound. In inductiveness checking, CIll checks whether the generated invariants, together with the target property, become inductive under the accumulated strengthening. When inductiveness fails, CIll extracts CTIs and provides them to the LLM. The LLM inspects the design and the CTI to propose new invariants that invalidate the CTIs. The proposed invariants are then re-validated through correctness and inductiveness checks, and the loop continues until the original property strengthened by the generated invariants becomes inductive. CIll also employs IC3 to work with the LLM for automatically discovering invariants, and uses K-Induction as a complementary engine. To improve performance, CIll applies local proof and reuses invariants learned by IC3, reducing redundant search and accelerating convergence. In our evaluation, CIll proved full compliance within RISCV-Formal framework and full accuracy of all non-M instructions in NERV and PicoRV32, whereas M extensions are proved against the RVFI ALTOPS substitute semantics provided by RISCV-Formal.","authors":["Yuheng Su","Tianjun Bu","Qiusong Yang","Yiwei Ci","Enyuan Tian"],"pdf_url":"","comment":null}]},"2026-02-24T00:00:00Z":{"Artificial Intelligence (Agents & Multi-Agent Systems)":[{"id":"http://arxiv.org/abs/2602.21204v1","updated":"2026-02-24T18:59:30Z","published":"2026-02-24T18:59:30Z","title":"Test-Time Training with KV Binding Is Secretly Linear Attention","summary":"Test-time training (TTT) with KV binding as sequence modeling layer is commonly interpreted as a form of online meta-learning that memorizes a key-value mapping at test time. However, our analysis reveals multiple phenomena that contradict this memorization-based interpretation. Motivated by these findings, we revisit the formulation of TTT and show that a broad class of TTT architectures can be expressed as a form of learned linear attention operator. Beyond explaining previously puzzling model behaviors, this perspective yields multiple practical benefits: it enables principled architectural simplifications, admits fully parallel formulations that preserve performance while improving efficiency, and provides a systematic reduction of diverse TTT variants to a standard linear attention form. Overall, our results reframe TTT not as test-time memorization, but as learned linear attention with enhanced representational capacity.","authors":["Junchen Liu","Sven Elflein","Or Litany","Zan Gojcic","Ruilong Li"],"pdf_url":"","comment":"Webpage: https://research.nvidia.com/labs/sil/projects/tttla/"},{"id":"http://arxiv.org/abs/2602.21201v1","updated":"2026-02-24T18:56:10Z","published":"2026-02-24T18:56:10Z","title":"Aletheia tackles FirstProof autonomously","summary":"We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full transparency, we explain our interpretation of FirstProof and disclose details about our experiments as well as our evaluation. Raw prompts and outputs are available at https://github.com/google-deepmind/superhuman/tree/main/aletheia.","authors":["Tony Feng","Junehyuk Jung","Sang-hyun Kim","Carlo Pagano","Sergei Gukov","Chiang-Chiang Tsai","David Woodruff","Adel Javanmard","Aryan Mokhtari","Dawsen Hwang","Yuri Chervonyi","Jonathan N. Lee","Garrett Bingham","Trieu H. Trinh","Vahab Mirrokni","Quoc V. Le","Thang Luong"],"pdf_url":"","comment":"34 pages. Project page: https://github.com/google-deepmind/superhuman/tree/main/aletheia"},{"id":"http://arxiv.org/abs/2602.21198v1","updated":"2026-02-24T18:55:18Z","published":"2026-02-24T18:55:18Z","title":"Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs","summary":"Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: \\textit{reflection-in-action}, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and \\textit{reflection-on-action}, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.","authors":["Yining Hong","Huang Huang","Manling Li","Li Fei-Fei","Jiajun Wu","Yejin Choi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17905v2","updated":"2026-02-24T18:49:01Z","published":"2026-02-20T00:07:18Z","title":"Games That Teach, Chats That Convince: Comparing Interactive and Static Formats for Persuasive Learning","summary":"Interactive systems such as chatbots and games are increasingly used to persuade and educate on sustainability-related topics, yet it remains unclear how different delivery formats shape learning and persuasive outcomes when content is held constant. Grounding on identical arguments and factual content across conditions, we present a controlled user study comparing three modes of information delivery: static essays, conversational chatbots, and narrative text-based games. Across subjective measures, the chatbot condition consistently outperformed the other modes and increased perceived importance of the topic. However, perceived learning did not reliably align with objective outcomes: participants in the text-based game condition reported learning less than those reading essays, yet achieved higher scores on a delayed (24-hour) knowledge quiz. Additional exploratory analyses further suggest that common engagement proxies, such as verbosity and interaction length, are more closely related to subjective experience than to actual learning. These findings highlight a dissociation between how persuasive experiences feel and what participants retain, and point to important design trade-offs between interactivity, realism, and learning in persuasive systems and serious games.","authors":["Seyed Hossein Alavi","Zining Wang","Shruthi Chockkalingam","Raymond T. Ng","Vered Shwartz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21189v1","updated":"2026-02-24T18:43:08Z","published":"2026-02-24T18:43:08Z","title":"Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training","summary":"Pass@k is a widely used performance metric for verifiable large language model tasks, including mathematical reasoning, code generation, and short-answer reasoning. It defines success if any of $k$ independently sampled solutions passes a verifier. This multi-sample inference metric has motivated inference-aware fine-tuning methods that directly optimize pass@$k$. However, prior work reports a recurring trade-off: pass@k improves while pass@1 degrades under such methods. This trade-off is practically important because pass@1 often remains a hard operational constraint due to latency and cost budgets, imperfect verifier coverage, and the need for a reliable single-shot fallback. We study the origin of this trade-off and provide a theoretical characterization of when pass@k policy optimization can reduce pass@1 through gradient conflict induced by prompt interference. We show that pass@$k$ policy gradients can conflict with pass@1 gradients because pass@$k$ optimization implicitly reweights prompts toward low-success prompts; when these prompts are what we term negatively interfering, their upweighting can rotate the pass@k update direction away from the pass@1 direction. We illustrate our theoretical findings with large language model experiments on verifiable mathematical reasoning tasks.","authors":["Anas Barakat","Souradip Chakraborty","Khushbu Pahwa","Amrit Singh Bedi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21178v1","updated":"2026-02-24T18:28:08Z","published":"2026-02-24T18:28:08Z","title":"XMorph: Explainable Brain Tumor Analysis Via LLM-Assisted Hybrid Deep Intelligence","summary":"Deep learning has significantly advanced automated brain tumor diagnosis, yet clinical adoption remains limited by interpretability and computational constraints. Conventional models often act as opaque ''black boxes'' and fail to quantify the complex, irregular tumor boundaries that characterize malignant growth. To address these challenges, we present XMorph, an explainable and computationally efficient framework for fine-grained classification of three prominent brain tumor types: glioma, meningioma, and pituitary tumors. We propose an Information-Weighted Boundary Normalization (IWBN) mechanism that emphasizes diagnostically relevant boundary regions alongside nonlinear chaotic and clinically validated features, enabling a richer morphological representation of tumor growth. A dual-channel explainable AI module combines GradCAM++ visual cues with LLM-generated textual rationales, translating model reasoning into clinically interpretable insights. The proposed framework achieves a classification accuracy of 96.0%, demonstrating that explainability and high performance can co-exist in AI-based medical imaging systems. The source code and materials for XMorph are all publicly available at: https://github.com/ALSER-Lab/XMorph.","authors":["Sepehr Salem Ghahfarokhi","M. Moein Esfahani","Raj Sunderraman","Vince Calhoun","Mohammed Alser"],"pdf_url":"","comment":"Accepted in ICCABS 2026: The 14th International Conference on Computational Advances in Bio and Medical Sciences"},{"id":"http://arxiv.org/abs/2504.18310v2","updated":"2026-02-24T18:23:32Z","published":"2025-04-25T12:37:15Z","title":"How much does context affect the accuracy of AI health advice?","summary":"Large language models (LLMs) are increasingly used to provide health advice, yet evidence on how their accuracy varies across languages, topics and information sources remains limited. We assess how linguistic and contextual factors affect the accuracy of AI-based health-claim verification. We evaluated seven widely used LLMs on two datasets: (i) 1,975 legally authorised nutrition and health claims from UK and EU regulatory registers translated into 21 languages; and (ii) 9,088 journalist-vetted public-health claims from the PUBHEALTH corpus spanning COVID-19, abortion, politics and general health, drawn from government advisories, scientific abstracts and media sources. Models classified each claim as supported or unsupported using majority voting across repeated runs. Accuracy was analysed by language, topic, source and model. Accuracy on authorised claims was highest in English and closely related European languages and declined in several widely spoken non-European languages, decreasing with syntactic distance from English. On real-world public-health claims, accuracy was substantially lower and varied systematically by topic and source. Models performed best on COVID-19 and government-attributed claims and worst on general health and scientific abstracts. High performance on English, canonical health claims masks substantial context-dependent gaps. Differences in training data exposure, editorial framing and topic-specific tuning likely contribute to these disparities, which are comparable in magnitude to cross-language differences. LLM accuracy in health-claim verification depends strongly on language, topic and information source. English-language performance does not reliably generalise across contexts, underscoring the need for multilingual, domain-specific evaluation before deployment in public-health communication.","authors":["Prashant Garg","Thiemo Fetzer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21174v1","updated":"2026-02-24T18:18:36Z","published":"2026-02-24T18:18:36Z","title":"Efficient Hierarchical Any-Angle Path Planning on Multi-Resolution 3D Grids","summary":"Hierarchical, multi-resolution volumetric mapping approaches are widely used to represent large and complex environments as they can efficiently capture their occupancy and connectivity information. Yet widely used path planning methods such as sampling and trajectory optimization do not exploit this explicit connectivity information, and search-based methods such as A* suffer from scalability issues in large-scale high-resolution maps. In many applications, Euclidean shortest paths form the underpinning of the navigation system. For such applications, any-angle planning methods, which find optimal paths by connecting corners of obstacles with straight-line segments, provide a simple and efficient solution. In this paper, we present a method that has the optimality and completeness properties of any-angle planners while overcoming computational tractability issues common to search-based methods by exploiting multi-resolution representations. Extensive experiments on real and synthetic environments demonstrate the proposed approach's solution quality and speed, outperforming even sampling-based methods. The framework is open-sourced to allow the robotics and planning community to build on our research.","authors":["Victor Reijgwart","Cesar Cadena","Roland Siegwart","Lionel Ott"],"pdf_url":"","comment":"12 pages, 9 figures, 4 tables, accepted to RSS 2025, code is open-source: https://github.com/ethz-asl/wavestar"},{"id":"http://arxiv.org/abs/2602.21172v1","updated":"2026-02-24T18:17:21Z","published":"2026-02-24T18:17:21Z","title":"NoRD: A Data-Efficient Vision-Language-Action Model that Drives without Reasoning","summary":"Vision-Language-Action (VLA) models are advancing autonomous driving by replacing modular pipelines with unified end-to-end architectures. However, current VLAs face two expensive requirements: (1) massive dataset collection, and (2) dense reasoning annotations. In this work, we address both challenges with \\modelname (\\textbf{No} \\textbf{R}easoning for \\textbf{D}riving). Compared to existing VLAs, \\modelname achieves competitive performance while being fine-tuned on $<$60\\% of the data and no reasoning annotations, resulting in 3$\\times$ fewer tokens. We identify that standard Group Relative Policy Optimization (GRPO) fails to yield significant improvements when applied to policies trained on such small, reasoning-free datasets. We show that this limitation stems from difficulty bias, which disproportionately penalizes reward signals from scenarios that produce high-variance rollouts within GRPO. \\modelname overcomes this by incorporating Dr.~GRPO, a recent algorithm designed to mitigate difficulty bias in LLMs. As a result, \\modelname achieves competitive performance on Waymo and NAVSIM with a fraction of the training data and no reasoning overhead, enabling more efficient autonomous systems.","authors":["Ishaan Rawal","Shubh Gupta","Yihan Hu","Wei Zhan"],"pdf_url":"","comment":"Accepted to CVPR 2026"},{"id":"http://arxiv.org/abs/2602.21165v1","updated":"2026-02-24T18:10:00Z","published":"2026-02-24T18:10:00Z","title":"PVminer: A Domain-Specific Tool to Detect the Patient Voice in Patient Generated Data","summary":"Patient-generated text such as secure messages, surveys, and interviews contains rich expressions of the patient voice (PV), reflecting communicative behaviors and social determinants of health (SDoH). Traditional qualitative coding frameworks are labor intensive and do not scale to large volumes of patient-authored messages across health systems. Existing machine learning (ML) and natural language processing (NLP) approaches provide partial solutions but often treat patient-centered communication (PCC) and SDoH as separate tasks or rely on models not well suited to patient-facing language. We introduce PVminer, a domain-adapted NLP framework for structuring patient voice in secure patient-provider communication. PVminer formulates PV detection as a multi-label, multi-class prediction task integrating patient-specific BERT encoders (PV-BERT-base and PV-BERT-large), unsupervised topic modeling for thematic augmentation (PV-Topic-BERT), and fine-tuned classifiers for Code, Subcode, and Combo-level labels. Topic representations are incorporated during fine-tuning and inference to enrich semantic inputs. PVminer achieves strong performance across hierarchical tasks and outperforms biomedical and clinical pre-trained baselines, achieving F1 scores of 82.25% (Code), 80.14% (Subcode), and up to 77.87% (Combo). An ablation study further shows that author identity and topic-based augmentation each contribute meaningful gains. Pre-trained models, source code, and documentation will be publicly released, with annotated datasets available upon request for research use.","authors":["Samah Fodeh","Linhai Ma","Yan Wang","Srivani Talakokkul","Ganesh Puthiaraju","Afshan Khan","Ashley Hagaman","Sarah Lowe","Aimee Roundtree"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.17457v2","updated":"2026-02-24T18:08:53Z","published":"2025-02-09T17:07:46Z","title":"MoEMba: A Mamba-based Mixture of Experts for High-Density EMG-based Hand Gesture Recognition","summary":"High-Density surface Electromyography (HDsEMG) has emerged as a pivotal resource for Human-Computer Interaction (HCI), offering direct insights into muscle activities and motion intentions. However, a significant challenge in practical implementations of HD-sEMG-based models is the low accuracy of inter-session and inter-subject classification. Variability between sessions can reach up to 40% due to the inherent temporal variability of HD-sEMG signals. Targeting this challenge, the paper introduces the MoEMba framework, a novel approach leveraging Selective StateSpace Models (SSMs) to enhance HD-sEMG-based gesture recognition. The MoEMba framework captures temporal dependencies and cross-channel interactions through channel attention techniques. Furthermore, wavelet feature modulation is integrated to capture multi-scale temporal and spatial relations, improving signal representation. Experimental results on the CapgMyo HD-sEMG dataset demonstrate that MoEMba achieves a balanced accuracy of 56.9%, outperforming its state-of-the-art counterparts. The proposed framework's robustness to session-to-session variability and its efficient handling of high-dimensional multivariate time series data highlight its potential for advancing HD-sEMG-powered HCI systems.","authors":["Mehran Shabanpour","Kasra Rad","Sadaf Khademi","Arash Mohammadi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.03005v4","updated":"2026-02-24T18:01:52Z","published":"2025-12-02T18:31:18Z","title":"From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?","summary":"The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.","authors":["Dawei Li","Abdullah Alnaibari","Arslan Bisharat","Manny Sandoval","Deborah Hall","Yasin Silva","Huan Liu"],"pdf_url":"","comment":"Accepted by PAKDD 2026 special session on Data Science: Foundations and Applications"},{"id":"http://arxiv.org/abs/2602.21154v1","updated":"2026-02-24T17:59:21Z","published":"2026-02-24T17:59:21Z","title":"CG-DMER: Hybrid Contrastive-Generative Framework for Disentangled Multimodal ECG Representation Learning","summary":"Accurate interpretation of electrocardiogram (ECG) signals is crucial for diagnosing cardiovascular diseases. Recent multimodal approaches that integrate ECGs with accompanying clinical reports show strong potential, but they still face two main concerns from a modality perspective: (1) intra-modality: existing models process ECGs in a lead-agnostic manner, overlooking spatial-temporal dependencies across leads, which restricts their effectiveness in modeling fine-grained diagnostic patterns; (2) inter-modality: existing methods directly align ECG signals with clinical reports, introducing modality-specific biases due to the free-text nature of the reports. In light of these two issues, we propose CG-DMER, a contrastive-generative framework for disentangled multimodal ECG representation learning, powered by two key designs: (1) Spatial-temporal masked modeling is designed to better capture fine-grained temporal dynamics and inter-lead spatial dependencies by applying masking across both spatial and temporal dimensions and reconstructing the missing information. (2) A representation disentanglement and alignment strategy is designed to mitigate unnecessary noise and modality-specific biases by introducing modality-specific and modality-shared encoders, ensuring a clearer separation between modality-invariant and modality-specific representations. Experiments on three public datasets demonstrate that CG-DMER achieves state-of-the-art performance across diverse downstream tasks.","authors":["Ziwei Niu","Hao Sun","Shujun Bian","Xihong Yang","Lanfen Lin","Yuxin Liu","Yueming Jin"],"pdf_url":"","comment":"Accepted by ICASSP 2026"},{"id":"http://arxiv.org/abs/2602.20159v2","updated":"2026-02-24T17:59:15Z","published":"2026-02-23T18:59:41Z","title":"A Very Big Video Reasoning Suite","summary":"Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .","authors":["Maijunxian Wang","Ruisi Wang","Juyi Lin","Ran Ji","Thaddäus Wiedemer","Qingying Gao","Dezhi Luo","Yaoyao Qian","Lianyu Huang","Zelong Hong","Jiahui Ge","Qianli Ma","Hang He","Yifan Zhou","Lingzi Guo","Lantao Mei","Jiachen Li","Hanwen Xing","Tianqi Zhao","Fengyuan Yu","Weihang Xiao","Yizheng Jiao","Jianheng Hou","Danyang Zhang","Pengcheng Xu","Boyang Zhong","Zehong Zhao","Gaoyun Fang","John Kitaoka","Yile Xu","Hua Xu","Kenton Blacutt","Tin Nguyen","Siyuan Song","Haoran Sun","Shaoyue Wen","Linyang He","Runming Wang","Yanzhi Wang","Mengyue Yang","Ziqiao Ma","Raphaël Millière","Freda Shi","Nuno Vasconcelos","Daniel Khashabi","Alan Yuille","Yilun Du","Ziming Liu","Bo Li","Dahua Lin","Ziwei Liu","Vikash Kumar","Yijiang Li","Lei Yang","Zhongang Cai","Hokin Deng"],"pdf_url":"","comment":"Homepage: https://video-reason.com/"},{"id":"http://arxiv.org/abs/2602.21143v1","updated":"2026-02-24T17:43:32Z","published":"2026-02-24T17:43:32Z","title":"A Benchmark for Deep Information Synthesis","summary":"Large language model (LLM)-based agents are increasingly used to solve complex tasks involving tool use, such as web browsing, code execution, and data analysis. However, current evaluation benchmarks do not adequately assess their ability to solve real-world tasks that require synthesizing information from multiple sources and inferring insights beyond simple fact retrieval. To address this, we introduce DEEPSYNTH, a novel benchmark designed to evaluate agents on realistic, time-consuming problems that combine information gathering, synthesis, and structured reasoning to produce insights. DEEPSYNTH contains 120 tasks collected across 7 domains and data sources covering 67 countries. DEEPSYNTH is constructed using a multi-stage data collection pipeline that requires annotators to collect official data sources, create hypotheses, perform manual analysis, and design tasks with verifiable answers. When evaluated on DEEPSYNTH, 11 state-of-the-art LLMs and deep research agents achieve a maximum F1 score of 8.97 and 17.5 on the LLM-judge metric, underscoring the difficulty of the benchmark. Our analysis reveals that current agents struggle with hallucinations and reasoning over large information spaces, highlighting DEEPSYNTH as a crucial benchmark for guiding future research.","authors":["Debjit Paul","Daniel Murphy","Milan Gritta","Ronald Cardenas","Victor Prokhorov","Lena Sophia Bolliger","Aysim Toker","Roy Miles","Andreea-Maria Oncescu","Jasivan Alex Sivakumar","Philipp Borchert","Ismail Elezi","Meiru Zhang","Ka Yiu Lee","Guchun Zhang","Jun Wang","Gerasimos Lampouras"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.21136v1","updated":"2026-02-24T17:33:02Z","published":"2026-02-24T17:33:02Z","title":"SparkMe: Adaptive Semi-Structured Interviewing for Qualitative Insight Discovery","summary":"Qualitative insights from user experiences are critical for informing product and policy decisions, but collecting such data at scale is constrained by the time and availability of experts to conduct semi-structured interviews. Recent work has explored using large language models (LLMs) to automate interviewing, yet existing systems lack a principled mechanism for balancing systematic coverage of predefined topics with adaptive exploration, or the ability to pursue follow-ups, deep dives, and emergent themes that arise organically during conversation. In this work, we formulate adaptive semi-structured interviewing as an optimization problem over the interviewer's behavior. We define interview utility as a trade-off between coverage of a predefined interview topic guide, discovery of relevant emergent themes, and interview cost measured by length. Based on this formulation, we introduce SparkMe, a multi-agent LLM interviewer that performs deliberative planning via simulated conversation rollouts to select questions with high expected utility. We evaluate SparkMe through controlled experiments with LLM-based interviewees, showing that it achieves higher interview utility, improving topic guide coverage (+4.7% over the best baseline) and eliciting richer emergent insights while using fewer conversational turns than prior LLM interviewing approaches. We further validate SparkMe in a user study with 70 participants across 7 professions on the impact of AI on their workflows. Domain experts rate SparkMe as producing high-quality adaptive interviews that surface helpful profession-specific insights not captured by prior approaches. The code, datasets, and evaluation protocols for SparkMe are available as open-source at https://github.com/SALT-NLP/SparkMe.","authors":["David Anugraha","Vishakh Padmakumar","Diyi Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21127v1","updated":"2026-02-24T17:23:11Z","published":"2026-02-24T17:23:11Z","title":"\"Are You Sure?\": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems","summary":"Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized against their human users. While extensive research focuses on agent-centric threats, human susceptibility to deception by a compromised agent remains unexplored. We present the first large-scale empirical study with 303 participants to measure human susceptibility to AMD. This is based on HAT-Lab (Human-Agent Trust Laboratory), a high-fidelity research platform we develop, featuring nine carefully crafted scenarios spanning everyday and professional domains (e.g., healthcare, software development, human resources). Our 10 key findings reveal significant vulnerabilities and provide future defense perspectives. Specifically, only 8.6% of participants perceive AMD attacks, while domain experts show increased susceptibility in certain scenarios. We identify six cognitive failure modes in users and find that their risk awareness often fails to translate to protective behavior. The defense analysis reveals that effective warnings should interrupt workflows with low verification costs. With experiential learning based on HAT-Lab, over 90% of users who perceive risks report increased caution against AMD. This work provides empirical evidence and a platform for human-centric agent security research.","authors":["Xinfeng Li","Shenyu Dai","Kelong Zheng","Yue Xiao","Gelei Deng","Wei Dong","Xiaofeng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2408.07016v3","updated":"2026-02-24T17:19:33Z","published":"2024-08-13T16:30:36Z","title":"Rethinking Disentanglement under Dependent Factors of Variation","summary":"Representation learning is an approach that allows to discover and extract the factors of variation from the data. Intuitively, a representation is said to be disentangled if it separates the different factors of variation in a way that is understandable to humans. Definitions of disentanglement and metrics to measure it usually assume that the factors of variation are independent of each other. However, this is generally false in the real world, which limits the use of these definitions and metrics to very specific and unrealistic scenarios. In this paper we give a definition of disentanglement based on information theory that is also valid when the factors of variation are not independent. Furthermore, we relate this definition to the Information Bottleneck Method. Finally, we propose a method to measure the degree of disentanglement from the given definition that works when the factors of variation are not independent. We show through different experiments that the method proposed in this paper correctly measures disentanglement with non-independent factors of variation, while other methods fail in this scenario.","authors":["Antonio Almudévar","Alfonso Ortega"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21119v1","updated":"2026-02-24T17:15:37Z","published":"2026-02-24T17:15:37Z","title":"Cooperative-Competitive Team Play of Real-World Craft Robots","summary":"Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications remain open research questions. In this work, we first develop a comprehensive robotic system, including simulation, distributed learning framework, and physical robot components. We then propose and evaluate reinforcement learning techniques designed for efficient training of cooperative and competitive policies on this platform. To address the challenges of multi-agent sim-to-real transfer, we introduce Out of Distribution State Initialization (OODSI) to mitigate the impact of the sim-to-real gap. In the experiments, OODSI improves the Sim2Real performance by 20%. We demonstrate the effectiveness of our approach through experiments with a multi-robot car competitive game and a cooperative task in real-world settings.","authors":["Rui Zhao","Xihui Li","Yizheng Zhang","Yuzhen Liu","Zhong Zhang","Yufeng Zhang","Cheng Zhou","Zhengyou Zhang","Lei Han"],"pdf_url":"","comment":"Accepted by 2026 IEEE International Conference on Robotics and Automation (ICRA 2026), Vienna, Austria"},{"id":"http://arxiv.org/abs/2602.07906v2","updated":"2026-02-24T17:14:22Z","published":"2026-02-08T10:55:03Z","title":"AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering","summary":"Autonomous Machine Learning Engineering (MLE) requires agents to perform sustained, iterative optimization over long horizons. While recent LLM-based agents show promise, current prompt-based agents for MLE suffer from behavioral stagnation due to frozen parameters. Although Reinforcement Learning (RL) offers a remedy, applying it to MLE is hindered by prohibitive execution latency and inefficient data selection. Recognizing these challenges, we propose AceGRPO with two core components: (1) Evolving Data Buffer that continuously repurposes execution traces into reusable training tasks, and (2) Adaptive Sampling guided by a Learnability Potential function, which dynamically prioritizes tasks at the agent's learning frontier to maximize learning efficiency. Leveraging AceGRPO, our trained Ace-30B model achieves a 100% valid submission rate on MLE-Bench-Lite, approaches the performance of proprietary frontier models, and outperforms larger open-source baselines (e.g., DeepSeek-V3.2), demonstrating robust capability for sustained iterative optimization. Code is available at https://github.com/yuzhu-cai/AceGRPO.","authors":["Yuzhu Cai","Zexi Liu","Xinyu Zhu","Cheng Wang","Siheng Chen"],"pdf_url":"","comment":"17 pages, 5 figures"},{"id":"http://arxiv.org/abs/2602.21116v1","updated":"2026-02-24T17:12:36Z","published":"2026-02-24T17:12:36Z","title":"Attention-Based SINR Estimation in User-Centric Non-Terrestrial Networks","summary":"The signal-to-interference-plus-noise ratio (SINR) is central to performance optimization in user-centric beamforming for satellite-based non-terrestrial networks (NTNs). Its assessment either requires the transmission of dedicated pilots or relies on computing the beamforming matrix through minimum mean squared error (MMSE)-based formulations beforehand, a process that introduces significant computational overhead. In this paper, we propose a low-complexity SINR estimation framework that leverages multi-head self-attention (MHSA) to extract inter-user interference features directly from either channel state information or user location reports. The proposed dual MHSA (DMHSA) models evaluate the SINR of a scheduled user group without requiring explicit MMSE calculations. The architecture achieves a computational complexity reduction by a factor of three in the CSI-based setting and by two orders of magnitude in the location-based configuration, the latter benefiting from the lower dimensionality of user reports. We show that both DMHSA models maintain high estimation accuracy, with the root mean squared error typically below 1 dB with priority-queuing-based scheduled users. These results enable the integration of DMHSA-based estimators into scheduling procedures, allowing the evaluation of multiple candidate user groups and the selection of those offering the highest average SINR and capacity.","authors":["Bruno De Filippo","Alessandro Guidotti","Alessandro Vanelli-Coralli"],"pdf_url":"","comment":"Paper accepted for presentation at IEEE International Conference on Machine Learning in Communications and Networking (ICMLCN) 2026"},{"id":"http://arxiv.org/abs/2602.16863v2","updated":"2026-02-24T17:10:02Z","published":"2026-02-18T20:42:39Z","title":"SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation","summary":"The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behaviors is challenging, sim-to-real reinforcement learning (RL) is a promising alternative. However, prior approaches typically require substantial engineering effort to model objects and tune reward functions for each task. In this work, we propose SimToolReal, taking a step towards generalizing sim-to-real RL policies for tool manipulation. Instead of focusing on a single object and task, we procedurally generate a large variety of tool-like object primitives in simulation and train a single RL policy with the universal goal of manipulating each object to random goal poses. This approach enables SimToolReal to perform general dexterous tool manipulation at test-time without any object or task-specific training. We demonstrate that SimToolReal outperforms prior retargeting and fixed-grasp methods by 37% while matching the performance of specialist RL policies trained on specific target objects and tasks. Finally, we show that SimToolReal generalizes across a diverse set of everyday tools, achieving strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.","authors":["Kushal Kedia","Tyler Ga Wei Lum","Jeannette Bohg","C. Karen Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21092v1","updated":"2026-02-24T16:52:36Z","published":"2026-02-24T16:52:36Z","title":"Probing Graph Neural Network Activation Patterns Through Graph Topology","summary":"Curvature notions on graphs provide a theoretical description of graph topology, highlighting bottlenecks and denser connected regions. Artifacts of the message passing paradigm in Graph Neural Networks, such as oversmoothing and oversquashing, have been attributed to these regions. However, it remains unclear how the topology of a graph interacts with the learned preferences of GNNs. Through Massive Activations, which correspond to extreme edge activation values in Graph Transformers, we probe this correspondence. Our findings on synthetic graphs and molecular benchmarks reveal that MAs do not preferentially concentrate on curvature extremes, despite their theoretical link to information flow. On the Long Range Graph Benchmark, we identify a systemic \\textit{curvature shift}: global attention mechanisms exacerbate topological bottlenecks, drastically increasing the prevalence of negative curvature. Our work reframes curvature as a diagnostic probe for understanding when and why graph learning fails.","authors":["Floriano Tori","Lorenzo Bini","Marco Sorbi","Stéphane Marchand-Maillet","Vincent Ginis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21072v1","updated":"2026-02-24T16:32:50Z","published":"2026-02-24T16:32:50Z","title":"Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning","summary":"Off-dynamics offline reinforcement learning (RL) aims to learn a policy for a target domain using limited target data and abundant source data collected under different transition dynamics. Existing methods typically address dynamics mismatch either globally over the state space or via pointwise data filtering; these approaches can miss localized cross-domain similarities or incur high computational cost. We propose Localized Dynamics-Aware Domain Adaptation (LoDADA), which exploits localized dynamics mismatch to better reuse source data. LoDADA clusters transitions from source and target datasets and estimates cluster-level dynamics discrepancy via domain discrimination. Source transitions from clusters with small discrepancy are retained, while those from clusters with large discrepancy are filtered out. This yields a fine-grained and scalable data selection strategy that avoids overly coarse global assumptions and expensive per-sample filtering. We provide theoretical insights and extensive experiments across environments with diverse global and local dynamics shifts. Results show that LoDADA consistently outperforms state-of-the-art off-dynamics offline RL methods by better leveraging localized distribution mismatch.","authors":["Zhangjie Xia","Yu Yang","Pan Xu"],"pdf_url":"","comment":"33 pages, 9 figures, 11 tables"},{"id":"http://arxiv.org/abs/2602.21066v1","updated":"2026-02-24T16:27:40Z","published":"2026-02-24T16:27:40Z","title":"The Initial Exploration Problem in Knowledge Graph Exploration","summary":"Knowledge Graphs (KGs) enable the integration and representation of complex information across domains, but their semantic richness and structural complexity create substantial barriers for lay users without expertise in semantic web technologies. When encountering an unfamiliar KG, such users face a distinct orientation challenge: they do not know what questions are possible, how the knowledge is structured, or how to begin exploration. This paper identifies and theorises this phenomenon as the Initial Exploration Problem (IEP). Drawing on theories from information behaviour and human-computer interaction, including ASK, exploratory search, information foraging, and cognitive load theory, we develop a conceptual framing of the IEP characterised by three interdependent barriers: scope uncertainty, ontology opacity, and query incapacity. We argue that these barriers converge at the moment of first contact, distinguishing the IEP from related concepts that presuppose an existing starting point or information goal. Analysing KG exploration interfaces at the level of interaction primitives, we suggest that many systems rely on epistemic assumptions that do not hold at first contact. This reveals a structural gap in the design space: the absence of interaction primitives for scope revelation, mechanisms that communicate what a KG contains without requiring users to formulate queries or interpret ontological structures. In articulating the IEP, this paper provides a theoretical lens for evaluating KG interfaces and for designing entry-point scaffolding that supports initial exploration.","authors":["Claire McNamara","Lucy Hederman","Declan O'Sullivan"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2602.21064v1","updated":"2026-02-24T16:26:52Z","published":"2026-02-24T16:26:52Z","title":"Motivation is Something You Need","summary":"This work introduces a novel training paradigm that draws from affective neuroscience. Inspired by the interplay of emotions and cognition in the human brain and more specifically the SEEKING motivational state, we design a dual-model framework where a smaller base model is trained continuously, while a larger motivated model is activated intermittently during predefined \"motivation conditions\". The framework mimics the emotional state of high curiosity and anticipation of reward in which broader brain regions are recruited to enhance cognitive performance. Exploiting scalable architectures where larger models extend smaller ones, our method enables shared weight updates and selective expansion of network capacity during noteworthy training steps. Empirical evaluation on the image classification task demonstrates that, not only does the alternating training scheme efficiently and effectively enhance the base model compared to a traditional scheme, in some cases, the motivational model also surpasses its standalone counterpart despite seeing less data per epoch. This opens the possibility of simultaneously training two models tailored to different deployment constraints with competitive or superior performance while keeping training cost lower than when training the larger model.","authors":["Mehdi Acheli","Walid Gaaloul"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.17074v3","updated":"2026-02-24T16:26:41Z","published":"2026-01-23T00:43:51Z","title":"PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction","summary":"The accurate estimation of Arctic snow depth remains a critical time-varying inverse problem due to the scarcity in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, namely an LSTM Encoder-Decoder with Multi-head Attention and contrastive learning, with physics-guided inference. Our core innovation lies in a physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. Beyond Arctic snow depth, PhysE-Inv can be applied broadly to other noisy, data-scarce problems in Earth and climate science.","authors":["Akila Sampath","Vandana Janeja","Jianwu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21061v1","updated":"2026-02-24T16:22:10Z","published":"2026-02-24T16:22:10Z","title":"Tool Building as a Path to \"Superintelligence\"","summary":"The Diligent Learner framework suggests LLMs can achieve superintelligence via test-time search, provided a sufficient step-success probability $γ$. In this work, we design a benchmark to measure $γ$ on logical out-of-distribution inference. We construct a class of tasks involving GF(2) circuit reconstruction that grow more difficult with each reasoning step, and that are, from an information-theoretic standpoint, impossible to reliably solve unless the LLM carefully integrates all of the information provided. Our analysis demonstrates that while the $γ$ value for small LLMs declines superlinearly as depth increases, frontier models exhibit partial robustness on this task. Furthermore, we find that successful reasoning at scale is contingent upon precise tool calls, identifying tool design as a critical capability for LLMs to achieve general superintelligence through the Diligent Learner framework.","authors":["David Koplow","Tomer Galanti","Tomaso Poggio"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21054v1","updated":"2026-02-24T16:11:14Z","published":"2026-02-24T16:11:14Z","title":"VAUQ: Vision-Aware Uncertainty Quantification for LVLM Self-Evaluation","summary":"Large Vision-Language Models (LVLMs) frequently hallucinate, limiting their safe deployment in real-world applications. Existing LLM self-evaluation methods rely on a model's ability to estimate the correctness of its own outputs, which can improve deployment reliability; however, they depend heavily on language priors and are therefore ill-suited for evaluating vision-conditioned predictions. We propose VAUQ, a vision-aware uncertainty quantification framework for LVLM self-evaluation that explicitly measures how strongly a model's output depends on visual evidence. VAUQ introduces the Image-Information Score (IS), which captures the reduction in predictive uncertainty attributable to visual input, and an unsupervised core-region masking strategy that amplifies the influence of salient regions. Combining predictive entropy with this core-masked IS yields a training-free scoring function that reliably reflects answer correctness. Comprehensive experiments show that VAUQ consistently outperforms existing self-evaluation methods across multiple datasets.","authors":["Seongheon Park","Changdae Oh","Hyeong Kyu Choi","Xuefeng Du","Sharon Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21052v1","updated":"2026-02-24T16:09:47Z","published":"2026-02-24T16:09:47Z","title":"Position-Aware Sequential Attention for Accurate Next Item Recommendations","summary":"Sequential self-attention models usually rely on additive positional embeddings, which inject positional information into item representations at the input. In the absence of positional signals, the attention block is permutation-equivariant over sequence positions and thus has no intrinsic notion of temporal order beyond causal masking. We argue that additive positional embeddings make the attention mechanism only superficially sensitive to sequence order: positional information is entangled with item embedding semantics, propagates weakly in deep architectures, and limits the ability to capture rich sequential patterns. To address these limitations, we introduce a kernelized self-attention mechanism, where a learnable positional kernel operates purely in the position space, disentangled from semantic similarity, and directly modulates attention weights. When applied per attention block, this kernel enables adaptive multi-scale sequential modeling. Experiments on standard next-item prediction benchmarks show that our positional kernel attention consistently improves over strong competing baselines.","authors":["Timur Nabiev","Evgeny Frolov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.02276v2","updated":"2026-02-24T16:08:04Z","published":"2025-10-02T17:51:19Z","title":"BioX-Bridge: Model Bridging for Unsupervised Cross-Modal Knowledge Transfer across Biosignals","summary":"Biosignals offer valuable insights into the physiological states of the human body. Although biosignal modalities differ in functionality, signal fidelity, sensor comfort, and cost, they are often intercorrelated, reflecting the holistic and interconnected nature of human physiology. This opens up the possibility of performing the same tasks using alternative biosignal modalities, thereby improving the accessibility, usability, and adaptability of health monitoring systems. However, the limited availability of large labeled datasets presents challenges for training models tailored to specific tasks and modalities of interest. Unsupervised cross-modal knowledge transfer offers a promising solution by leveraging knowledge from an existing modality to support model training for a new modality. Existing methods are typically based on knowledge distillation, which requires running a teacher model alongside student model training, resulting in high computational and memory overhead. This challenge is further exacerbated by the recent development of foundation models that demonstrate superior performance and generalization across tasks at the cost of large model sizes. To this end, we explore a new framework for unsupervised cross-modal knowledge transfer of biosignals by training a lightweight bridge network to align the intermediate representations and enable information flow between foundation models and across modalities. Specifically, we introduce an efficient strategy for selecting alignment positions where the bridge should be constructed, along with a flexible prototype network as the bridge architecture. Extensive experiments across multiple biosignal modalities, tasks, and datasets show that BioX-Bridge reduces the number of trainable parameters by 88--99\\% while maintaining or even improving transfer performance compared to state-of-the-art methods.","authors":["Chenqi Li","Yu Liu","Timothy Denison","Tingting Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21044v1","updated":"2026-02-24T16:04:26Z","published":"2026-02-24T16:04:26Z","title":"LogicGraph : Benchmarking Multi-Path Logical Reasoning via Neuro-Symbolic Generation and Verification","summary":"Evaluations of large language models (LLMs) primarily emphasize convergent logical reasoning, where success is defined by producing a single correct proof. However, many real-world reasoning problems admit multiple valid derivations, requiring models to explore diverse logical paths rather than committing to one route. To address this limitation, we introduce LogicGraph, the first benchmark aimed to systematically evaluate multi-path logical reasoning, constructed via a neuro-symbolic framework that leverages backward logic generation and semantic instantiation. This pipeline yields solver-verified reasoning problems formalized by high-depth multi-path reasoning and inherent logical distractions, where each instance is associated with an exhaustive set of minimal proofs. We further propose a reference-free evaluation framework to rigorously assess model performance in both convergent and divergent regimes. Experiments on state-of-the-art language models reveal a common limitation: models tend to commit early to a single route and fail to explore alternatives, and the coverage gap grows substantially with reasoning depth. LogicGraph exposes this divergence gap and provides actionable insights to motivate future improvements. Our code and data will be released at https://github.com/kkkkarry/LogicGraph.","authors":["Yanrui Wu","Lingling Zhang","Xinyu Zhang","Jiayu Chang","Pengyu Li","Xu Jiang","Jingtao Hu","Jun Liu"],"pdf_url":"","comment":"24 pages, 17 figures"},{"id":"http://arxiv.org/abs/2602.21033v1","updated":"2026-02-24T15:55:04Z","published":"2026-02-24T15:55:04Z","title":"MIP Candy: A Modular PyTorch Framework for Medical Image Processing","summary":"Medical image processing demands specialized software that handles high-dimensional volumetric data, heterogeneous file formats, and domain-specific training procedures. Existing frameworks either provide low-level components that require substantial integration effort or impose rigid, monolithic pipelines that resist modification. We present MIP Candy (MIPCandy), a freely available, PyTorch-based framework designed specifically for medical image processing. MIPCandy provides a complete, modular pipeline spanning data loading, training, inference, and evaluation, allowing researchers to obtain a fully functional process workflow by implementing a single method, $\\texttt{build_network}$, while retaining fine-grained control over every component. Central to the design is $\\texttt{LayerT}$, a deferred configuration mechanism that enables runtime substitution of convolution, normalization, and activation modules without subclassing. The framework further offers built-in $k$-fold cross-validation, dataset inspection with automatic region-of-interest detection, deep supervision, exponential moving average, multi-frontend experiment tracking (Weights & Biases, Notion, MLflow), training state recovery, and validation score prediction via quotient regression. An extensible bundle ecosystem provides pre-built model implementations that follow a consistent trainer--predictor pattern and integrate with the core framework without modification. MIPCandy is open-source under the Apache-2.0 license and requires Python~3.12 or later. Source code and documentation are available at https://github.com/ProjectNeura/MIPCandy.","authors":["Tianhao Fu","Yucheng Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2501.16613v2","updated":"2026-02-24T15:50:35Z","published":"2025-01-28T01:19:05Z","title":"Safe Reinforcement Learning for Real-World Engine Control","summary":"This work introduces a toolchain for applying Reinforcement Learning (RL), specifically the Deep Deterministic Policy Gradient (DDPG) algorithm, in safety-critical real-world environments. As an exemplary application, transient load control is demonstrated on a single-cylinder internal combustion engine testbench in Homogeneous Charge Compression Ignition (HCCI) mode, that offers high thermal efficiency and low emissions. However, HCCI poses challenges for traditional control methods due to its nonlinear, autoregressive, and stochastic nature. RL provides a viable solution, however, safety concerns, such as excessive pressure rise rates, must be addressed when applying to HCCI. A single unsuitable control input can severely damage the engine or cause misfiring and shut down. Additionally, operating limits are not known a priori and must be determined experimentally. To mitigate these risks, real-time safety monitoring based on the k-nearest neighbor algorithm is implemented, enabling safe interaction with the testbench. The feasibility of this approach is demonstrated as the RL agent learns a control policy through interaction with the testbench. A root mean square error of 0.1374 bar is achieved for the indicated mean effective pressure, comparable to neural network-based controllers from the literature. The toolchain's flexibility is further demonstrated by adapting the agent's policy to increase ethanol energy shares, promoting renewable fuel use while maintaining safety. This RL approach addresses the longstanding challenge of applying RL to safety-critical real-world environments. The developed toolchain, with its adaptability and safety mechanisms, paves the way for future applicability of RL in engine testbenches and other safety-critical settings.","authors":["Julian Bedei","Lucas Koch","Kevin Badalian","Alexander Winkler","Patrick Schaber","Jakob Andert"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.07729v2","updated":"2026-02-24T15:43:09Z","published":"2026-02-07T23:25:26Z","title":"Do We Need Adam? Surprisingly Strong and Sparse Reinforcement Learning with SGD in LLMs","summary":"Reinforcement learning (RL), particularly RL from verifiable reward (RLVR), has become a crucial phase of training large language models (LLMs) and a key focus of current scaling efforts. However, optimization practices in RL largely follow those of next-token prediction stages (e.g., pretraining and supervised fine-tuning), despite fundamental differences between RL and these stages highlighted by recent work. One such practice is the use of the AdamW optimizer, which is widely adopted for training large-scale transformers despite its high memory overhead. Our analysis shows that both momentum and adaptive learning rates in AdamW are less influential in RL than in SFT, leading us to hypothesize that RL benefits less from Adam-style per-parameter adaptive learning rates and momentum. Confirming this hypothesis, our experiments demonstrate that the substantially more memory-efficient SGD, which is known to perform poorly in supervised learning of large-scale transformers, matches or even outperforms AdamW in RL for LLMs. Remarkably, full fine-tuning with SGD updates fewer than 0.02% of model parameters without any sparsity-promoting regularization, more than 1000 times fewer than AdamW. Our analysis offers potential reasons for this update sparsity. These findings provide new insights into the optimization dynamics of RL in LLMs and show that RL can be substantially more parameter-efficient than previously recognized.","authors":["Sagnik Mukherjee","Lifan Yuan","Pavan Jayasinha","Dilek Hakkani-Tür","Hao Peng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.12434v2","updated":"2026-02-24T15:31:52Z","published":"2025-03-16T10:09:10Z","title":"A Survey on the Optimization of Large Language Model-based Agents","summary":"With the rapid development of Large Language Models (LLMs), LLM-based agents have been widely adopted in various fields, becoming essential for autonomous decision-making and interactive tasks. However, current work typically relies on prompt design or fine-tuning strategies applied to vanilla LLMs, which often leads to limited effectiveness or suboptimal performance in complex agent-related environments. Although LLM optimization techniques can improve model performance across many general tasks, they lack specialized optimization towards critical agent functionalities such as long-term planning, dynamic environmental interaction, and complex decision-making. Although numerous recent studies have explored various strategies to optimize LLM-based agents for complex agent tasks, a systematic review summarizing and comparing these methods from a holistic perspective is still lacking. In this survey, we provide a comprehensive review of LLM-based agent optimization approaches, categorizing them into parameter-driven and parameter-free methods. We first focus on parameter-driven optimization, covering fine-tuning-based optimization, reinforcement learning-based optimization, and hybrid strategies, analyzing key aspects such as trajectory data construction, fine-tuning techniques, reward function design, and optimization algorithms. Additionally, we briefly discuss parameter-free strategies that optimize agent behavior through prompt engineering and external knowledge retrieval. Finally, we summarize the datasets and benchmarks used for evaluation and tuning, review key applications of LLM-based agents, and discuss major challenges and promising future directions. Our repository for related references is available at https://github.com/YoungDubbyDu/LLM-Agent-Optimization.","authors":["Shangheng Du","Jiabao Zhao","Jinxin Shi","Zhentao Xie","Xin Jiang","Yanhong Bai","Liang He"],"pdf_url":"","comment":"Published in ACM Computing Surveys, Vol. 58, No. 9, Article 223, July 2026"},{"id":"http://arxiv.org/abs/2602.00044v2","updated":"2026-02-24T15:29:33Z","published":"2026-01-19T09:09:05Z","title":"When LLMs Imagine People: A Human-Centered Persona Brainstorm Audit for Bias and Fairness in Creative Applications","summary":"Large Language Models (LLMs) used in creative workflows can reinforce stereotypes and perpetuate inequities, making fairness auditing essential. Existing methods rely on constrained tasks and fixed benchmarks, leaving open-ended creative outputs unexamined. We introduce the Persona Brainstorm Audit (PBA), a scalable and easy to extend auditing method for bias detection across multiple intersecting identity and social roles in open-ended persona generation. PBA quantifies bias using degree-of-freedom-aware normalized Cramér's V, producing interpretable severity labels that enable fair comparison across models and dimensions. Applying PBA to 12 LLMs (120,000 personas, 16 bias dimensions), we find that bias evolves nonlinearly across model generations: larger and newer models are not consistently fairer, and biases that initially decrease can resurface in later releases. Intersectional analysis reveals disparities hidden by single-axis metrics, where dimensions appearing fair individually can exhibit high bias in combination. Robustness analyses show PBA remains stable under varying sample sizes, role-playing prompts, and debiasing prompts, establishing its reliability for fairness auditing in LLMs.","authors":["Hongliu Cao","Eoin Thomas","Rodrigo Acuna Agost"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.09082v2","updated":"2026-02-24T15:17:55Z","published":"2026-02-09T18:43:40Z","title":"UI-Venus-1.5 Technical Report","summary":"GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging. In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications. The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios. Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus","authors":[" Venus Team","Changlong Gao","Zhangxuan Gu","Yulin Liu","Xinyu Qiu","Shuheng Shen","Yue Wen","Tianyu Xia","Zhenyu Xu","Zhengwen Zeng","Beitong Zhou","Xingran Zhou","Weizhi Chen","Sunhao Dai","Jingya Dou","Yichen Gong","Yuan Guo","Zhenlin Guo","Feng Li","Qian Li","Jinzhen Lin","Yuqi Zhou","Linchao Zhu","Liang Chen","Zhenyu Guo","Changhua Meng","Weiqiang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.23587v2","updated":"2026-02-24T15:16:44Z","published":"2025-10-27T17:54:07Z","title":"A Survey of Data Agents: Emerging Paradigm or Overstated Hype?","summary":"The rapid advancement of large language models (LLMs) has spurred the emergence of data agents, autonomous systems designed to orchestrate Data + AI ecosystems for tackling complex data-related tasks. However, the term \"data agent\" currently suffers from terminological ambiguity and inconsistent adoption, conflating simple query responders with sophisticated autonomous architectures. This terminological ambiguity fosters mismatched user expectations, accountability challenges, and barriers to industry growth. Inspired by the SAE J3016 standard for driving automation, this survey introduces the first systematic hierarchical taxonomy for data agents, comprising six levels that delineate and trace progressive shifts in autonomy, from manual operations (L0) to a vision of generative, fully autonomous data agents (L5), thereby clarifying capability boundaries and responsibility allocation. Through this lens, we offer a structured review of existing research arranged by increasing autonomy, encompassing specialized data agents for data management, preparation, and analysis, alongside emerging efforts toward versatile, comprehensive systems with enhanced autonomy. We further analyze critical evolutionary leaps and technical gaps for advancing data agents, especially the ongoing L2-to-L3 transition, where data agents evolve from procedural execution to autonomous orchestration. Finally, we conclude with a forward-looking roadmap, envisioning proactive, generative data agents.","authors":["Yizhang Zhu","Liangwei Wang","Chenyu Yang","Xiaotian Lin","Boyan Li","Wei Zhou","Xinyu Liu","Zhangyang Peng","Tianqi Luo","Yu Li","Chengliang Chai","Chong Chen","Shimin Di","Ju Fan","Ji Sun","Nan Tang","Fugee Tsung","Jiannan Wang","Chenglin Wu","Yanwei Xu","Shaolei Zhang","Yong Zhang","Xuanhe Zhou","Guoliang Li","Yuyu Luo"],"pdf_url":"","comment":"Please refer to our paper list and companion materials at: https://github.com/HKUSTDial/awesome-data-agents"},{"id":"http://arxiv.org/abs/2602.20994v1","updated":"2026-02-24T15:14:04Z","published":"2026-02-24T15:14:04Z","title":"Multimodal MRI Report Findings Supervised Brain Lesion Segmentation with Substructures","summary":"Report-supervised (RSuper) learning seeks to alleviate the need for dense tumor voxel labels with constraints derived from radiology reports (e.g., volumes, counts, sizes, locations). In MRI studies of brain tumors, however, we often involve multi-parametric scans and substructures. Here, fine-grained modality/parameter-wise reports are usually provided along with global findings and are correlated with different substructures. Moreover, the reports often describe only the largest lesion and provide qualitative or uncertain cues (``mild,'' ``possible''). Classical RSuper losses (e.g., sum volume consistency) can over-constrain or hallucinate unreported findings under such incompleteness, and are unable to utilize these hierarchical findings or exploit the priors of varied lesion types in a merged dataset. We explicitly parse the global quantitative and modality-wise qualitative findings and introduce a unified, one-sided, uncertainty-aware formulation (MS-RSuper) that: (i) aligns modality-specific qualitative cues (e.g., T1c enhancement, FLAIR edema) with their corresponding substructures using existence and absence losses; (ii) enforces one-sided lower-bounds for partial quantitative cues (e.g., largest lesion size, minimal multiplicity); and (iii) adds extra- vs. intra-axial anatomical priors to respect cohort differences. Certainty tokens scale penalties; missing cues are down-weighted. On 1238 report-labeled BraTS-MET/MEN scans, our MS-RSuper largely outperforms both a sparsely-supervised baseline and a naive RSuper method.","authors":["Yubin Ge","Yongsong Huang","Xiaofeng Liu"],"pdf_url":"","comment":"IEEE International Symposium on Biomedical Imaging (ISBI) 2026"},{"id":"http://arxiv.org/abs/2602.12876v2","updated":"2026-02-24T15:07:52Z","published":"2026-02-13T12:25:13Z","title":"BrowseComp-$V^3$: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents","summary":"Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world environments. However, existing benchmarks for multimodal browsing remain limited in task complexity, evidence accessibility, and evaluation granularity, hindering comprehensive and reproducible assessments of deep search capabilities. To address these limitations, we introduce BrowseComp-$V^3$, a novel benchmark consisting of 300 carefully curated and challenging questions spanning diverse domains. The benchmark emphasizes deep, multi-level, and cross-modal multi-hop reasoning, where critical evidence is interleaved across textual and visual modalities within and across web pages. All supporting evidence is strictly required to be publicly searchable, ensuring fairness and reproducibility. Beyond final-answer accuracy, we incorporate an expert-validated, subgoal-driven process evaluation mechanism that enables fine-grained analysis of intermediate reasoning behaviors and systematic characterization of capability boundaries. In addition, we propose OmniSeeker, a unified multimodal browsing agent framework integrating diverse web search and visual perception tools. Comprehensive experiments demonstrate that even state-of-the-art models achieve only 36% accuracy on our benchmark, revealing critical bottlenecks in multimodal information integration and fine-grained perception. Our results highlight a fundamental gap between current model capabilities and robust multimodal deep search in real-world settings.","authors":["Huanyao Zhang","Jiepeng Zhou","Bo Li","Bowen Zhou","Yanzhe Shan","Haishan Lu","Zhiyong Cao","Jiaoyang Chen","Yuqian Han","Zinan Sheng","Zhengwei Tao","Hao Liang","Jialong Wu","Yang Shi","Yuanpeng He","Jiaye Lin","Qintong Zhang","Guochen Yan","Runhao Zhao","Zhengpin Li","Xiaohan Yu","Lang Mei","Chong Chen","Wentao Zhang","Bin Cui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.03616v2","updated":"2026-02-24T15:07:11Z","published":"2025-08-05T16:29:51Z","title":"Hidden Dynamics of Massive Activations in Transformer Training","summary":"We present the first comprehensive analysis of massive activation development throughout transformer training, using the Pythia model family as our testbed, and release our full dataset publicly to support further research. Through systematic analysis of various model sizes across multiple training checkpoints, we demonstrate that massive activation emergence follows highly predictable mathematical patterns that can be accurately modeled using an exponentially-modulated logarithmic function with five key parameters. Additionally, We develop a machine learning framework to predict these mathematical parameters from architectural specifications alone, achieving high accuracy for steady-state behavior and moderate accuracy for emergence timing and magnitude. These findings enable architects to predict and potentially control key aspects of massive activation emergence through design choices, with significant implications for model stability, training cycle length, interpretability, and optimization. Our findings demonstrate that the emergence of massive activations is governed by model design and can be anticipated, and potentially controlled, before training begins. Code is available at https://github.com/Aimpoint-Digital/massive-activations-fork","authors":["Jorge Gallego-Feliciano","S. Aaron McClendon","Juan Morinelli","Stavros Zervoudakis","Antonios Saravanos"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20981v1","updated":"2026-02-24T15:01:39Z","published":"2026-02-24T15:01:39Z","title":"Echoes Over Time: Unlocking Length Generalization in Video-to-Audio Generation Models","summary":"Scaling multimodal alignment between video and audio is challenging, particularly due to limited data and the mismatch between text descriptions and frame-level video information. In this work, we tackle the scaling challenge in multimodal-to-audio generation, examining whether models trained on short instances can generalize to longer ones during testing. To tackle this challenge, we present multimodal hierarchical networks so-called MMHNet, an enhanced extension of state-of-the-art video-to-audio models. Our approach integrates a hierarchical method and non-causal Mamba to support long-form audio generation. Our proposed method significantly improves long audio generation up to more than 5 minutes. We also prove that training short and testing long is possible in the video-to-audio generation tasks without training on the longer durations. We show in our experiments that our proposed method could achieve remarkable results on long-video to audio benchmarks, beating prior works in video-to-audio tasks. Moreover, we showcase our model capability in generating more than 5 minutes, while prior video-to-audio methods fall short in generating with long durations.","authors":["Christian Simon","MAsato Ishii","Wei-Yao Wang","Koichi Saito","Akio Hayakawa","Dongseok Shim","Zhi Zhong","Shuyang Cui","Shusuke Takahashi","Takashi Shibuya","Yuki Mitsufuji"],"pdf_url":"","comment":"Accepted to CVPR 2026"},{"id":"http://arxiv.org/abs/2602.20980v1","updated":"2026-02-24T15:01:30Z","published":"2026-02-24T15:01:30Z","title":"CrystaL: Spontaneous Emergence of Visual Latents in MLLMs","summary":"Multimodal Large Language Models (MLLMs) have achieved remarkable performance by integrating powerful language backbones with large-scale visual encoders. Among these, latent Chain-of-Thought (CoT) methods enable implicit reasoning in continuous hidden states, facilitating seamless vision-language integration and faster inference. However, existing heuristically predefined supervision signals in latent CoT provide limited guidance for preserving critical visual information in intermediate latent states. To address this limitation, we propose CrystaL (Crystallized Latent Reasoning), a single-stage framework with two paths to process intact and corrupted images, respectively. By explicitly aligning the attention patterns and prediction distributions across the two paths, CrystaL crystallizes latent representations into task-relevant visual semantics, without relying on auxiliary annotations or external modules. Extensive experiments on perception-intensive benchmarks demonstrate that CrystaL consistently outperforms state-of-the-art baselines, achieving substantial gains in fine-grained visual understanding while maintaining robust reasoning capabilities.","authors":["Yang Zhang","Danyang Li","Yuxuan Li","Xin Zhang","Tianyu Xie","Mingming Cheng","Xiang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20979v1","updated":"2026-02-24T15:01:29Z","published":"2026-02-24T15:01:29Z","title":"Toward an Agentic Infused Software Ecosystem","summary":"Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the AI agents themselves, which in the past 5 years have moved from simple code completion and toward sophisticated independent development tasks, a trend which will only continue. The second pillar is the programming language and APIs (or tools) that these agents use to accomplish tasks, and increasingly, serve as the communication substrate that humans and AI agents interact and collaborate through. The final pillar is the runtime environment and ecosystem that agents operate within, and which provide the capabilities that programmatic agents use to interface with (and effect actions in) the external world. To realize the vision of AISE, all three pillars must be advanced in a holistic manner, and critically, in a manner that is synergistic for AI agents as they exist today, those that will exist in the future, and for the human developers that work alongside them.","authors":["Mark Marron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04500v2","updated":"2026-02-24T14:56:22Z","published":"2025-06-04T22:47:53Z","title":"\"Don't Do That!\": Guiding Embodied Systems through Large Language Model-based Constraint Generation","summary":"Recent advancements in large language models (LLMs) have spurred interest in robotic navigation that incorporates complex spatial, mathematical, and conditional constraints from natural language into the planning problem. Such constraints can be informal yet highly complex, making it challenging to translate into a formal description that can be passed on to a planning algorithm. In this paper, we propose STPR, a constraint generation framework that uses LLMs to translate constraints (expressed as instructions on ``what not to do'') into executable Python functions. STPR leverages the LLM's strong coding capabilities to shift the problem description from language into structured and transparent code, thus circumventing complex reasoning and avoiding potential hallucinations. We show that these LLM-generated functions accurately describe even complex mathematical constraints, and apply them to point cloud representations with traditional search algorithms. Experiments in a simulated Gazebo environment show that STPR ensures full compliance across several constraints and scenarios, while having short runtimes. We also verify that STPR can be used with smaller, code-specific LLMs, making it applicable to a wide range of compact models at low inference cost.","authors":["Amin Seffo","Aladin Djuhera","Masataro Asai","Holger Boche"],"pdf_url":"","comment":"Preprint; under review"},{"id":"http://arxiv.org/abs/2602.18296v2","updated":"2026-02-24T14:55:20Z","published":"2026-02-20T15:46:57Z","title":"Context-Aware Mapping of 2D Drawing Annotations to 3D CAD Features Using LLM-Assisted Reasoning for Manufacturing Automation","summary":"Manufacturing automation in process planning, inspection planning, and digital-thread integration depends on a unified specification that binds the geometric features of a 3D CAD model to the geometric dimensioning and tolerancing (GD&T) callouts, datum definitions, and surface requirements carried by the corresponding 2D engineering drawing. Although Model-Based Definition (MBD) allows such specifications to be embedded directly in 3D models, 2D drawings remain the primary carrier of manufacturing intent in automotive, aerospace, shipbuilding, and heavy-machinery industries. Correctly linking drawing annotations to the corresponding 3D features is difficult because of contextual ambiguity, repeated feature patterns, and the need for transparent and traceable decisions. This paper presents a deterministic-first, context-aware framework that maps 2D drawing entities to 3D CAD features to produce a unified manufacturing specification. Drawing callouts are first semantically enriched and then scored against candidate features using an interpretable metric that combines type compatibility, tolerance-aware dimensional agreement, and conservative context consistency, along with engineering-domain heuristics. When deterministic scoring cannot resolve an ambiguity, the system escalates to multimodal and constrained large-language-model reasoning, followed by a single human-in-the-loop (HITL) review step. Experiments on 20 real CAD-drawing pairs achieve a mean precision of 83.67%, recall of 90.46%, and F1 score of 86.29%. An ablation study shows that each pipeline component contributes to overall accuracy, with the full system outperforming all reduced variants. By prioritizing deterministic rules, clear decision tracking, and retaining unresolved cases for human review, the framework provides a practical foundation for downstream manufacturing automation in real-world industrial environments.","authors":["Muhammad Tayyab Khan","Lequn Chen","Wenhe Feng","Seung Ki Moon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.12108v2","updated":"2026-02-24T14:53:26Z","published":"2025-02-17T18:29:24Z","title":"Using the Path of Least Resistance to Explain Deep Networks","summary":"Integrated Gradients (IG), a widely used axiomatic path-based attribution method, assigns importance scores to input features by integrating model gradients along a straight path from a baseline to the input. While effective in some cases, we show that straight paths can lead to flawed attributions. In this paper, we identify the cause of these misattributions and propose an alternative approach that equips the input space with a model-induced Riemannian metric (derived from the explained model's Jacobian) and computes attributions by integrating gradients along geodesics under this metric. We call this method Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we introduce two techniques: a k-Nearest Neighbours-based approach for smaller models and a Stochastic Variational Inference-based method for larger ones. Additionally, we propose a new axiom, No-Cancellation Completeness (NCC), which strengthens completeness by ruling out feature-wise cancellation. We prove that, for path-based attributions under the model-induced metric, NCC holds if and only if the integration path is a geodesic. Through experiments on both synthetic and real-world image classification data, we provide empirical evidence supporting our theoretical analysis and showing that GIG produces more faithful attributions than existing methods, including IG, on the benchmarks considered.","authors":["Sina Salek","Joseph Enguehard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20971v1","updated":"2026-02-24T14:52:20Z","published":"2026-02-24T14:52:20Z","title":"Does Order Matter : Connecting The Law of Robustness to Robust Generalization","summary":"Bubeck and Sellke (2021) pose as an open problem the connection between the law of robustness and robust generalization. The law of robustness states that overparameterization is necessary for models to interpolate robustly; in particular, robust interpolation requires the learned function to be Lipschitz. Robust generalization asks whether small robust training loss implies small robust test loss. We resolve this problem by explicitly connecting the two for arbitrary data distributions. Specifically, we introduce a nontrivial notion of robust generalization error and convert it into a lower bound on the expected Rademacher complexity of the induced robust loss class. Our bounds recover the $Ω(n^{1/d})$ regime of Wu et al.\\ (2023) and show that, up to constants, robust generalization does not change the order of the Lipschitz constant required for smooth interpolation. We conduct experiments to probe the predicted scaling with dataset size and model capacity, testing whether empirical behavior aligns more closely with the predictions of Bubeck and Sellke (2021) or Wu et al.\\ (2023). For MNIST, we find that the lower-bound Lipschitz constant scales on the order predicted by Wu et al.\\ (2023). Informally, to obtain low robust generalization error, the Lipschitz constant must lie in a range that we bound, and the allowable perturbation radius is linked to the Lipschitz scale.","authors":["Himadri Mandal","Vishnu Varadarajan","Jaee Ponde","Aritra Das","Mihir More","Debayan Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.18777v2","updated":"2026-02-24T14:51:33Z","published":"2025-06-23T15:45:44Z","title":"Programming by Backprop: An Instruction is Worth 100 Examples When Finetuning LLMs","summary":"Large language models (LLMs) are typically trained to acquire behaviours from demonstrations or experience, yet much of their training data is declarative: instructions, rules, and descriptions that specify behaviours without showing how to execute them. We introduce Programming by Backprop (PBB): a training regime that enables LLMs to acquire procedural knowledge (i.e., reusable behaviours) from declarative instructions encountered during training. With PBB, instructions in training data provide an opportunity to `program' specific behaviours into model weights. The core principle underpinning PBB is the separation of learning how instructions map to behaviour from internalising new instructions. We devise two distinct PBB curricula that leverage this principle. Through controlled experiments across two domains (algorithmic execution from Python source code and text generation from context-free grammars), we demonstrate the benefit of these curricula over training on a homogeneous data mixture. Crucially, PBB is highly sample efficient, with a single instruction substituting for up to 100 execution examples. Though execution of instructions in training data remains less reliable than when instructions are given in-context, our results demonstrate that procedural knowledge can be noisily `programmed' into LLMs through PBB, with important implications for data curation and safety.","authors":["Jonathan Cook","Silvia Sapora","Arash Ahmadian","Akbir Khan","Tim Rocktaschel","Jakob Foerster","Laura Ruis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20967v1","updated":"2026-02-24T14:46:54Z","published":"2026-02-24T14:46:54Z","title":"Training-Free Intelligibility-Guided Observation Addition for Noisy ASR","summary":"Automatic speech recognition (ASR) degrades severely in noisy environments. Although speech enhancement (SE) front-ends effectively suppress background noise, they often introduce artifacts that harm recognition. Observation addition (OA) addressed this issue by fusing noisy and SE enhanced speech, improving recognition without modifying the parameters of the SE or ASR models. This paper proposes an intelligibility-guided OA method, where fusion weights are derived from intelligibility estimates obtained directly from the backend ASR. Unlike prior OA methods based on trained neural predictors, the proposed method is training-free, reducing complexity and enhances generalization. Extensive experiments across diverse SE-ASR combinations and datasets demonstrate strong robustness and improvements over existing OA baselines. Additional analyses of intelligibility-guided switching-based alternatives and frame versus utterance-level OA further validate the proposed design.","authors":["Haoyang Li","Changsong Liu","Wei Rao","Hao Shi","Sakriani Sakti","Eng Siong Chng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.01666v2","updated":"2026-02-24T14:39:36Z","published":"2025-06-02T13:35:33Z","title":"Synthesis of discrete-continuous quantum circuits with multimodal diffusion models","summary":"Efficiently compiling quantum operations remains a major bottleneck in scaling quantum computing. Today's state-of-the-art methods achieve low compilation error by combining search algorithms with gradient-based parameter optimization, but they incur long runtimes and require multiple calls to quantum hardware or expensive classical simulations, making their scaling prohibitive. Recently, machine-learning models have emerged as an alternative, though they are currently restricted to discrete gate sets. Here, we introduce a multimodal denoising diffusion model that simultaneously generates a circuit's structure and its continuous parameters for compiling a target unitary. It leverages two independent diffusion processes, one for discrete gate selection and one for parameter prediction. We benchmark the model over different experiments, analyzing the method's accuracy across varying qubit counts and circuit depths, showcasing the ability of the method to outperform existing approaches in gate counts and under noisy conditions. Additionally, we show that a simple post-optimization scheme allows us to significantly improve the generated ansätze. Finally, by exploiting its rapid circuit generation, we create large datasets of circuits for particular operations and use these to extract valuable heuristics that can help us discover new insights into quantum circuit synthesis.","authors":["Florian Fürrutter","Zohim Chandani","Ikko Hamamura","Hans J. Briegel","Gorka Muñoz-Gil"],"pdf_url":"","comment":"Main Text: 11 pages, 8 figures and 1 table; Code available at: https://github.com/FlorianFuerrutter/genQC; added new results"},{"id":"http://arxiv.org/abs/2508.06878v2","updated":"2026-02-24T14:38:10Z","published":"2025-08-09T08:17:37Z","title":"Seeing Through the Noise: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective","summary":"Infrared small target detection and segmentation (IRSTDS) is a critical yet challenging task in defense and civilian applications, owing to the dim, shapeless appearance of targets and severe background clutter. Recent CNN-based methods have achieved promising target perception results, but they only focus on enhancing feature representation to offset the impact of noise, which results in the increased false alarm problem. In this paper, through analyzing the problem from the frequency domain, we pioneer in improving performance from noise suppression perspective and propose a novel noise-suppression feature pyramid network (NS-FPN), which integrates a low-frequency guided feature purification (LFP) module and a spiral-aware feature sampling (SFS) module into the original FPN structure. The LFP module suppresses the noise features by purifying high-frequency components to achieve feature enhancement devoid of noise interference, while the SFS module further adopts spiral sampling to fuse target-relevant features in feature fusion process. Our NS-FPN is designed to be lightweight yet effective and can be easily plugged into existing IRSTDS frameworks. Extensive experiments on the IRSTD-1k and NUAA-SIRST datasets demonstrate that our method significantly reduces false alarms and achieves superior performance on IRSTDS task.","authors":["Maoxun Yuan","Duanni Meng","Ziteng Xi","Tianyi Zhao","Shiji Zhao","Yimian Dai","Xingxing Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20958v1","updated":"2026-02-24T14:37:36Z","published":"2026-02-24T14:37:36Z","title":"EKF-Based Depth Camera and Deep Learning Fusion for UAV-Person Distance Estimation and Following in SAR Operations","summary":"Search and rescue (SAR) operations require rapid responses to save lives or property. Unmanned Aerial Vehicles (UAVs) equipped with vision-based systems support these missions through prior terrain investigation or real-time assistance during the mission itself. Vision-based UAV frameworks aid human search tasks by detecting and recognizing specific individuals, then tracking and following them while maintaining a safe distance. A key safety requirement for UAV following is the accurate estimation of the distance between camera and target object under real-world conditions, achieved by fusing multiple image modalities. UAVs with deep learning-based vision systems offer a new approach to the planning and execution of SAR operations. As part of the system for automatic people detection and face recognition using deep learning, in this paper we present the fusion of depth camera measurements and monocular camera-to-body distance estimation for robust tracking and following. Deep learning-based filtering of depth camera data and estimation of camera-to-body distance from a monocular camera are achieved with YOLO-pose, enabling real-time fusion of depth information using the Extended Kalman Filter (EKF) algorithm. The proposed subsystem, designed for use in drones, estimates and measures the distance between the depth camera and the human body keypoints, to maintain the safe distance between the drone and the human target. Our system provides an accurate estimated distance, which has been validated against motion capture ground truth data. The system has been tested in real time indoors, where it reduces the average errors, root mean square error (RMSE) and standard deviations of distance estimation up to 15,3\\% in three tested scenarios.","authors":["Luka Šiktar","Branimir Ćaran","Bojan Šekoranja","Marko Švaco"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04867v4","updated":"2026-02-24T14:36:12Z","published":"2025-06-05T10:38:28Z","title":"Sensory-Motor Control with Large Language Models via Iterative Policy Refinement","summary":"We propose a method that enables large language models (LLMs) to control embodied agents through the generation of control policies that directly map continuous observation vectors to continuous action vectors. At the outset, the LLMs generate a control strategy based on a textual description of the agent, its environment, and the intended goal. This strategy is then iteratively refined through a learning process in which the LLMs are repeatedly prompted to improve the current strategy, using performance feedback and sensory-motor data collected during its evaluation. The method is validated on classic control tasks from the Gymnasium library and the inverted pendulum task from the MuJoCo library. The approach proves effective with relatively compact models such as GPT-oss:120b and Qwen2.5:72b. In most cases, it successfully identifies optimal or near-optimal solutions by integrating symbolic knowledge derived through reasoning with sub-symbolic sensory-motor data gathered as the agent interacts with its environment.","authors":["Jônata Tyska Carvalho","Stefano Nolfi"],"pdf_url":"","comment":"Final version of the article accepted for publication on Scientific Reports. 29 pages (13 pages are from appendix), 8 figures, 2 tables, code for experiments replication and supplementary material provided at https://github.com/jtyska/llm-robotics-article/"},{"id":"http://arxiv.org/abs/2602.11184v2","updated":"2026-02-24T14:35:31Z","published":"2026-01-30T06:57:17Z","title":"KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models","summary":"Mixture of Experts (MoE) models have achieved great success by significantly improving performance while maintaining computational efficiency through sparse expert activation. However, their enormous parameter sizes and memory demands pose major challenges for deployment in resource-constrained environments. Vector Quantization (VQ) offers a promising approach for ultra-low-bit compression in Large Language Models (LLMs) by leveraging a codebook, where weight vectors are mapped to the most similar discrete codewords. Yet, directly applying VQ to MoEs often leads to substantial performance degradation due to two critical obstacles: (1) redundant representations among experts cause VQ to repeatedly quantize similar representations for each expert, resulting in inefficient use of limited codebook capacity; and (2) cumulative output bias is amplified by expert aggregation in MoE layers, leading to distributional shifts in the quantized outputs. To address these issues, we propose KBVQ-MoE, a novel VQ framework to enhance extremely low-bit quantization for MoE-based LLMs. KBVQ-MoE integrates two techniques: (1) input-driven redundancy elimination, where a Karhunen-Loeve Transform (KLT) guided singular value decomposition (SVD) extracts dominant weight components and shares them across experts; and (2) bias-corrected output stabilization, where vector quantization is applied only to expert-specific (non-redundant) representations and the quantized outputs are corrected via channel-wise affine compensation. Experiments on various MoE LLMs demonstrate that KBVQ-MoE preserves accuracy substantially better than existing quantization methods. For example, 3-bit quantization of Qwen1.5-MoE-A2.7B achieves an average accuracy of 67.99, nearly identical to the FP16 baseline of 68.07, underscoring KBVQ-MoE's potential for efficient deployment on edge devices and other resource-constrained platforms.","authors":["Zukang Xu","Zhixiong Zhao","Xing Hu","Zhixuan Chen","Dawei Yang"],"pdf_url":"","comment":"Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2602.12656v2","updated":"2026-02-24T14:34:42Z","published":"2026-02-13T06:38:04Z","title":"PMG: Parameterized Motion Generator for Human-like Locomotion Control","summary":"Recent advances in data-driven reinforcement learning and motion tracking have substantially improved humanoid locomotion, yet critical practical challenges remain. In particular, while low-level motion tracking and trajectory-following controllers are mature, whole-body reference-guided methods are difficult to adapt to higher-level command interfaces and diverse task contexts: they require large, high-quality datasets, are brittle across speed and pose regimes, and are sensitive to robot-specific calibration. To address these limitations, we propose the Parameterized Motion Generator (PMG), a real-time motion generator grounded in an analysis of human motion structure that synthesizes reference trajectories using only a compact set of parameterized motion data together with high-dimensional control commands. Combined with an imitation-learning pipeline and an optimization-based sim-to-real motor parameter identification module, we validate the complete approach on our humanoid prototype ZERITH Z1 and show that, within a single integrated system, PMG produces natural, human-like locomotion, responds precisely to high-dimensional control inputs-including VR-based teleoperation-and enables efficient, verifiable sim-to-real transfer. Together, these results establish a practical, experimentally validated pathway toward natural and deployable humanoid control. Website: https://pmg-icra26.github.io/","authors":["Chenxi Han","Yuheng Min","Zihao Huang","Ao Hong","Hang Liu","Yi Cheng","Houde Liu"],"pdf_url":"","comment":"Website: https://pmg-icra26.github.io/"},{"id":"http://arxiv.org/abs/2602.20951v1","updated":"2026-02-24T14:34:13Z","published":"2026-02-24T14:34:13Z","title":"See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis","summary":"Despite recent advances in diffusion models, AI generated images still often contain visual artifacts that compromise realism. Although more thorough pre-training and bigger models might reduce artifacts, there is no assurance that they can be completely eliminated, which makes artifact mitigation a highly crucial area of study. Previous artifact-aware methodologies depend on human-labeled artifact datasets, which are costly and difficult to scale, underscoring the need for an automated approach to reliably acquire artifact-annotated datasets. In this paper, we propose ArtiAgent, which efficiently creates pairs of real and artifact-injected images. It comprises three agents: a perception agent that recognizes and grounds entities and subentities from real images, a synthesis agent that introduces artifacts via artifact injection tools through novel patch-wise embedding manipulation within a diffusion transformer, and a curation agent that filters the synthesized artifacts and generates both local and global explanations for each instance. Using ArtiAgent, we synthesize 100K images with rich artifact annotations and demonstrate both efficacy and versatility across diverse applications. Code is available at link.","authors":["Jaehyun Park","Minyoung Ahn","Minkyu Kim","Jonghyun Lee","Jae-Gil Lee","Dongmin Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.11675v3","updated":"2026-02-24T14:33:34Z","published":"2026-01-16T06:24:59Z","title":"Generating metamers of human scene understanding","summary":"Human vision combines low-resolution \"gist\" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. \"foveated\") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a \"same\" or \"different\" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.","authors":["Ritik Raina","Abe Leite","Alexandros Graikos","Seoyoung Ahn","Dimitris Samaras","Gregory J. Zelinsky"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20946v1","updated":"2026-02-24T14:29:45Z","published":"2026-02-24T14:29:45Z","title":"Some Simple Economics of AGI","summary":"For millennia, human cognition was the primary engine of progress on Earth. As AI decouples cognition from biology, the marginal cost of measurable execution falls to zero, absorbing any labor capturable by metrics--including creative, analytical, and innovative work. The binding constraint on growth is no longer intelligence but human verification bandwidth: the capacity to validate, audit, and underwrite responsibility when execution is abundant. We model the AGI transition as the collision of two racing cost curves: an exponentially decaying Cost to Automate and a biologically bottlenecked Cost to Verify. This structural asymmetry widens a Measurability Gap between what agents can execute and what humans can afford to verify. It also drives a shift from skill-biased to measurability-biased technical change. Rents migrate to verification-grade ground truth, cryptographic provenance, and liability underwriting--the ability to insure outcomes rather than merely generate them. The current human-in-the-loop equilibrium is unstable: eroded from below as apprenticeship collapses (Missing Junior Loop) and from within as experts codify their obsolescence (Codifier's Curse). Unverified deployment becomes privately rational--a Trojan Horse externality. Unmanaged, these forces pull toward a Hollow Economy. Yet by scaling verification alongside agentic capabilities, the forces that threaten collapse become the catalyst for unbounded discovery and experimentation--an Augmented Economy. We derive a practical playbook for individuals, companies, investors, and policymakers. Today's defining challenge is not the race to deploy the most autonomous systems; it is the race to secure the foundations of their oversight. Only by scaling our bandwidth for verification alongside our capacity for execution can we ensure that the intelligence we have summoned preserves the humanity that initiated it.","authors":["Christian Catalini","Xiang Hui","Jane Wu"],"pdf_url":"","comment":"JEL Classification: D82, D83, J23, J24, L23, O33. 112 pages, 3 figures"},{"id":"http://arxiv.org/abs/2602.20945v1","updated":"2026-02-24T14:28:16Z","published":"2026-02-24T14:28:16Z","title":"The Art of Efficient Reasoning: Data, Reward, and Optimization","summary":"Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.","authors":["Taiqiang Wu","Zenan Zu","Bo Zhou","Ngai Wong"],"pdf_url":"","comment":"Tech Report, Insights on Efficient Reasoning via Reward Shaping"},{"id":"http://arxiv.org/abs/2602.20934v1","updated":"2026-02-24T14:12:21Z","published":"2026-02-24T14:12:21Z","title":"Architecting AgentOS: From Token-Level Context to Emergent System-Level Intelligence","summary":"The paradigm of Large Language Models is undergoing a fundamental transition from static inference engines to dynamic autonomous cognitive systems.While current research primarily focuses on scaling context windows or optimizing prompt engineering the theoretical bridge between micro scale token processing and macro scale systemic intelligence remains fragmented.This paper proposes AgentOS,a holistic conceptual framework that redefines the LLM as a \"Reasoning Kernel\" governed by structured operating system logic.Central to this architecture is Deep Context Management which conceptualizes the context window as an Addressable Semantic Space rather than a passive buffer.We systematically deconstruct the transition from discrete sequences to coherent cognitive states introducing mechanisms for Semantic Slicing and Temporal Alignment to mitigate cognitive drift in multi-agent orchestration.By mapping classical OS abstractions such as memory paging interrupt handling and process scheduling onto LLM native constructs, this review provides a rigorous roadmap for architecting resilient scalable and self-evolving cognitive environments.Our analysis asserts that the next frontier of AGI development lies in the architectural efficiency of system-level coordination.","authors":["ChengYou Li","XiaoDong Liu","XiangBao Meng","XinYu Zhao"],"pdf_url":"","comment":"16 pages,9 figures"},{"id":"http://arxiv.org/abs/2506.08660v3","updated":"2026-02-24T14:08:04Z","published":"2025-06-10T10:21:28Z","title":"Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness","summary":"Real-world time series data are inherently multivariate, often exhibiting complex inter-channel dependencies. Each channel is typically sampled at its own period and is prone to missing values due to various practical and operational constraints. These characteristics pose three fundamental challenges involving channel dependency, sampling asynchrony, and missingness, all of which must be addressed simultaneously to enable robust and reliable forecasting in practical settings. However, existing architectures typically address only parts of these challenges in isolation and still rely on simplifying assumptions, leaving unresolved the combined challenges of asynchronous channel sampling, test-time missing blocks, and intricate inter-channel dependencies. To bridge this gap, we propose ChannelTokenFormer, a Transformer-based forecasting framework with a flexible architecture designed to explicitly capture cross-channel interactions, accommodate channel-wise asynchronous sampling, and effectively handle missing values. Extensive experiments on public benchmark datasets reflecting practical settings, along with one private real-world industrial dataset, demonstrate the superior robustness and accuracy of ChannelTokenFormer under challenging real-world conditions.","authors":["Jinkwan Jang","Hyungjin Park","Jinmyeong Choi","Taesup Kim"],"pdf_url":"","comment":"Accepted by the 14th International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2602.18470v2","updated":"2026-02-24T14:07:04Z","published":"2026-02-08T23:57:49Z","title":"Transforming Science Learning Materials in the Era of Artificial Intelligence","summary":"The integration of artificial intelligence (AI) into science education is transforming the design and function of learning materials, offering new affordances for personalization, authenticity, and accessibility. This chapter examines how AI technologies are transforming science learning materials across six interrelated domains: 1) integrating AI into scientific practice, 2) enabling adaptive and personalized instruction, 3) facilitating interactive simulations, 4) generating multimodal content, 5) enhancing accessibility for diverse learners, and 6) promoting co-creation through AI-supported content development. These advancements enable learning materials to more accurately reflect contemporary scientific practice, catering to the diverse needs of students. For instance, AI support can enable students to engage in dynamic simulations, interact with real-time data, and explore science concepts through multimodal representations. Educators are increasingly collaborating with generative AI tools to develop timely and culturally responsive instructional resources. However, these innovations also raise critical ethical and pedagogical concerns, including issues of algorithmic bias, data privacy, transparency, and the need for human oversight. To ensure equitable and meaningful science learning, we emphasize the importance of designing AI-supported materials with careful attention to scientific integrity, inclusivity, and student agency. This chapter advocates for a responsible, ethical, and reflective approach to leveraging AI in science education, framing it as a catalyst for innovation while upholding core educational values.","authors":["Xiaoming Zhai","Kent Crippen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20926v1","updated":"2026-02-24T14:05:29Z","published":"2026-02-24T14:05:29Z","title":"HELP: HyperNode Expansion and Logical Path-Guided Evidence Localization for Accurate and Efficient GraphRAG","summary":"Large Language Models (LLMs) often struggle with inherent knowledge boundaries and hallucinations, limiting their reliability in knowledge-intensive tasks. While Retrieval-Augmented Generation (RAG) mitigates these issues, it frequently overlooks structural interdependencies essential for multi-hop reasoning. Graph-based RAG approaches attempt to bridge this gap, yet they typically face trade-offs between accuracy and efficiency due to challenges such as costly graph traversals and semantic noise in LLM-generated summaries. In this paper, we propose HyperNode Expansion and Logical Path-Guided Evidence Localization strategies for GraphRAG (HELP), a novel framework designed to balance accuracy with practical efficiency through two core strategies: 1) HyperNode Expansion, which iteratively chains knowledge triplets into coherent reasoning paths abstracted as HyperNodes to capture complex structural dependencies and ensure retrieval accuracy; and 2) Logical Path-Guided Evidence Localization, which leverages precomputed graph-text correlations to map these paths directly to the corpus for superior efficiency. HELP avoids expensive random walks and semantic distortion, preserving knowledge integrity while drastically reducing retrieval latency. Extensive experiments demonstrate that HELP achieves competitive performance across multiple simple and multi-hop QA benchmarks and up to a 28.8$\\times$ speedup over leading Graph-based RAG baselines.","authors":["Yuqi Huang","Ning Liao","Kai Yang","Anning Hu","Shengchao Hu","Xiaoxing Wang","Junchi Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20924v1","updated":"2026-02-24T14:04:18Z","published":"2026-02-24T14:04:18Z","title":"Airavat: An Agentic Framework for Internet Measurement","summary":"Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating both workflow generation and verification against methodological standards established through decades of research.\n  We present Airavat, the first agentic framework for Internet measurement workflow generation with systematic verification and validation. Airavat coordinates a set of agents mirroring expert reasoning: three agents handle problem decomposition, solution design, and code implementation, with assistance from a registry of existing tools. Two specialized engines ensure methodological correctness: a Verification Engine evaluates workflows against a knowledge graph encoding five decades of measurement research, while a Validation Engine identifies appropriate validation techniques grounded in established methodologies. Through four Internet measurement case studies, we demonstrate that Airavat (i) generates workflows matching expert-level solutions, (ii) makes sound architectural decisions, (iii) addresses novel problems without ground truth, and (iv) identifies methodological flaws missed by standard execution-based testing.","authors":["Alagappan Ramanathan","Eunju Kang","Dongsu Han","Sangeetha Abdu Jyothi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2309.13411v3","updated":"2026-02-24T13:55:17Z","published":"2023-09-23T15:48:35Z","title":"Towards Attributions of Input Variables in a Coalition","summary":"This paper focuses on the fundamental challenge of partitioning input variables in attribution methods for Explainable AI, particularly in Shapley value-based approaches. Previous methods always compute attributions given a predefined partition but lack theoretical guidance on how to form meaningful variable partitions. We identify that attribution conflicts arise when the attribution of a coalition differs from the sum of its individual variables' attributions. To address this, we analyze the numerical effects of AND-OR interactions in AI models and extend the Shapley value to a new attribution metric for variable coalitions. Our theoretical findings reveal that specific interactions cause attribution conflicts, and we propose three metrics to evaluate coalition faithfulness. Experiments on synthetic data, NLP, image classification, and the game of Go validate our approach, demonstrating consistency with human intuition and practical applicability.","authors":["Xinhao Zheng","Huiqi Deng","Quanshi Zhang"],"pdf_url":"","comment":"Accepted to the 2025 International Conference on Machine Learning (ICML 2025)"},{"id":"http://arxiv.org/abs/2602.20918v1","updated":"2026-02-24T13:54:38Z","published":"2026-02-24T13:54:38Z","title":"Predicting Sentence Acceptability Judgments in Multimodal Contexts","summary":"Previous work has examined the capacity of deep neural networks (DNNs), particularly transformers, to predict human sentence acceptability judgments, both independently of context, and in document contexts. We consider the effect of prior exposure to visual images (i.e., visual context) on these judgments for humans and large language models (LLMs). Our results suggest that, in contrast to textual context, visual images appear to have little if any impact on human acceptability ratings. However, LLMs display the compression effect seen in previous work on human judgments in document contexts. Different sorts of LLMs are able to predict human acceptability judgments to a high degree of accuracy, but in general, their performance is slightly better when visual contexts are removed. Moreover, the distribution of LLM judgments varies among models, with Qwen resembling human patterns, and others diverging from them. LLM-generated predictions on sentence acceptability are highly correlated with their normalised log probabilities in general. However, the correlations decrease when visual contexts are present, suggesting that a higher gap exists between the internal representations of LLMs and their generated predictions in the presence of visual contexts. Our experimental work suggests interesting points of similarity and of difference between human and LLM processing of sentences in multimodal contexts.","authors":["Hyewon Jang","Nikolai Ilinykh","Sharid Loáiciga","Jey Han Lau","Shalom Lappin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01874v3","updated":"2026-02-24T13:40:33Z","published":"2026-01-05T08:02:18Z","title":"CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving","summary":"Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\\Rightarrow$internalization$\\Rightarrow$reasoning. In line with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow. Project page: https://shchen233.github.io/cogflow.","authors":["Shuhang Chen","Yunqiu Xu","Junjie Xie","Aojun Lu","Tao Feng","Zeying Huang","Ning Zhang","Yi Sun","Yi Yang","Hangjie Yuan"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2510.22500v2","updated":"2026-02-24T13:37:46Z","published":"2025-10-26T02:42:03Z","title":"Towards Scalable Oversight via Partitioned Human Supervision","summary":"As artificial intelligence (AI) systems approach and surpass expert human performance across a broad range of tasks, obtaining high-quality human supervision for evaluation and training becomes increasingly challenging. Our focus is on tasks that require deep knowledge and skills of multiple domains, where this bottleneck is severe. Unfortunately, even the best human experts are knowledgeable only in a single narrow area, and will not be able to evaluate the correctness of advanced AI systems on such superhuman tasks. However, based on their narrow expertise, humans may provide a weak signal, i.e., a complementary label indicating an option that is incorrect. For example, a cardiologist could state that ''this is not related to any cardiovascular disease,'' even if they cannot identify the true disease. Based on this weak signal, we propose a scalable oversight framework that enables us to evaluate frontier AI systems without the need to prepare the ground truth. We derive an unbiased estimator of top-1 accuracy from complementary labels and quantify how many complementary labels are needed to match the variance of ordinary labels. We further introduce two estimators to combine scarce ordinary labels with abundant complementary labels. We provide finite-sample deviation guarantees for both complementary-only and the mixed estimators. Empirically, we show that we can evaluate the output of large language models without the ground truth, if we have complementary labels. We further show that we can train an AI system with such weak signals: we show how we can design an agentic AI system automatically that can improve itself with this partitioned human supervision. Our code is available at https://github.com/R-Yin-217/Towards-Scalable-Oversight-via-Partitioned-Human-Supervision.","authors":["Ren Yin","Takashi Ishida","Masashi Sugiyama"],"pdf_url":"","comment":"ICLR 2026 camera ready version"},{"id":"http://arxiv.org/abs/2602.20878v1","updated":"2026-02-24T13:20:07Z","published":"2026-02-24T13:20:07Z","title":"Diagnosing Causal Reasoning in Vision-Language Models via Structured Relevance Graphs","summary":"Large Vision-Language Models (LVLMs) achieve strong performance on visual question answering benchmarks, yet often rely on spurious correlations rather than genuine causal reasoning. Existing evaluations primarily assess the correctness of the answers, making it unclear whether failures arise from limited reasoning capability or from misidentifying causally relevant information. We introduce Vision-Language Causal Graphs (VLCGs), a structured, query-conditioned representation that explicitly encodes causally relevant objects, attributes, relations, and scene-grounded assumptions. Building on this representation, we present ViLCaR, a diagnostic benchmark comprising tasks for Causal Attribution, Causal Inference, and Question Answering, along with graph-aligned evaluation metrics that assess relevance identification beyond final answer accuracy. Experiments in state-of-the-art LVLMs show that injecting structured relevance information significantly improves attribution and inference consistency compared to zero-shot and standard in-context learning. These findings suggest that current limitations in LVLM causal reasoning stem primarily from insufficient structural guidance rather than a lack of reasoning capacity.","authors":["Dhita Putri Pratama","Soyeon Caren Han","Yihao Ding"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20877v1","updated":"2026-02-24T13:19:42Z","published":"2026-02-24T13:19:42Z","title":"E-MMKGR: A Unified Multimodal Knowledge Graph Framework for E-commerce Applications","summary":"Multimodal recommender systems (MMRSs) enhance collaborative filtering by leveraging item-side modalities, but their reliance on a fixed set of modalities and task-specific objectives limits both modality extensibility and task generalization. We propose E-MMKGR, a framework that constructs an e-commerce-specific Multimodal Knowledge Graph E-MMKG and learns unified item representations through GNN-based propagation and KG-oriented optimization. These representations provide a shared semantic foundation applicable to diverse tasks. Experiments on real-world Amazon datasets show improvements of up to 10.18% in Recall@10 for recommendation and up to 21.72% over vector-based retrieval for product search, demonstrating the effectiveness and extensibility of our approach.","authors":["Jiwoo Kang","Yeon-Chang Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19028v2","updated":"2026-02-24T13:11:53Z","published":"2025-11-25T08:25:38Z","title":"The Metaphysics We Train: A Heideggerian Reading of Machine Learning","summary":"This paper offers a phenomenological reading of contemporary machine learning through Heideggerian concepts, aimed at enriching practitioners' reflexive understanding of their own practice. We argue that this philosophical lens reveals three insights invisible to purely technical analysis. First, the algorithmic Entwurf (projection) is distinctive in being automated, opaque, and emergent--a metaphysics that operates without explicit articulation or debate, crystallizing implicitly through gradient descent rather than theoretical argument. Second, even sophisticated technical advances remain within the regime of Gestell (Enframing), improving calculation without questioning the primacy of calculation itself. Third, AI's lack of existential structure, specifically the absence of Care (Sorge), is genuinely explanatory: it illuminates why AI systems have no internal resources for questioning their own optimization imperatives, and why they optimize without the anxiety (Angst) that signals, in human agents, the friction between calculative absorption and authentic existence. We conclude by exploring the pedagogical value of this perspective, arguing that data science education should cultivate not only technical competence but ontological literacy--the capacity to recognize what worldviews our tools enact and when calculation itself may be the wrong mode of engagement.","authors":["Heman Shakeri"],"pdf_url":"","comment":"13 pages"},{"id":"http://arxiv.org/abs/2602.20867v1","updated":"2026-02-24T13:11:38Z","published":"2026-02-24T13:11:38Z","title":"SoK: Agentic Skills -- Beyond Tool Use in LLM Agents","summary":"Agentic systems increasingly rely on reusable procedural capabilities, \\textit{a.k.a., agentic skills}, to execute long-horizon workflows reliably. These capabilities are callable modules that package procedural knowledge with explicit applicability conditions, execution policies, termination criteria, and reusable interfaces. Unlike one-off plans or atomic tool calls, skills operate (and often do well) across tasks.\n  This paper maps the skill layer across the full lifecycle (discovery, practice, distillation, storage, composition, evaluation, and update) and introduces two complementary taxonomies. The first is a system-level set of \\textbf{seven design patterns} capturing how skills are packaged and executed in practice, from metadata-driven progressive disclosure and executable code skills to self-evolving libraries and marketplace distribution. The second is an orthogonal \\textbf{representation $\\times$ scope} taxonomy describing what skills \\emph{are} (natural language, code, policy, hybrid) and what environments they operate over (web, OS, software engineering, robotics).\n  We analyze the security and governance implications of skill-based agents, covering supply-chain risks, prompt injection via skill payloads, and trust-tiered execution, grounded by a case study of the ClawHavoc campaign in which nearly 1{,}200 malicious skills infiltrated a major agent marketplace, exfiltrating API keys, cryptocurrency wallets, and browser credentials at scale. We further survey deterministic evaluation approaches, anchored by recent benchmark evidence that curated skills can substantially improve agent success rates while self-generated skills may degrade them. We conclude with open challenges toward robust, verifiable, and certifiable skills for real-world autonomous agents.","authors":["Yanna Jiang","Delong Li","Haiyu Deng","Baihe Ma","Xu Wang","Qin Wang","Guangsheng Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.03250v3","updated":"2026-02-24T13:10:08Z","published":"2025-08-05T09:28:20Z","title":"RooseBERT: A New Deal For Political Language Modelling","summary":"The increasing amount of political debates and politics-related discussions calls for the definition of novel computational methods to automatically analyse such content with the final goal of lightening up political deliberation to citizens. However, the specificity of the political language and the argumentative form of these debates (employing hidden communication strategies and leveraging implicit arguments) make this task very challenging, even for current general-purpose pre-trained Language Models (LMs). To address this, we introduce a novel pre-trained LM for political discourse language called RooseBERT. Pre-training a LM on a specialised domain presents different technical and linguistic challenges, requiring extensive computational resources and large-scale data. RooseBERT has been trained on large political debate and speech corpora (11GB) in English. To evaluate its performances, we fine-tuned it on multiple downstream tasks related to political debate analysis, i.e., stance detection, sentiment analysis, argument component detection and classification, argument relation prediction and classification, policy classification, named entity recognition (NER). Our results show significant improvements over general-purpose LMs on the majority of these tasks, highlighting how domain-specific pre-training enhances performance in political debate analysis. We release RooseBERT for the research community.","authors":["Deborah Dore","Elena Cabrio","Serena Villata"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.05310v4","updated":"2026-02-24T13:07:25Z","published":"2025-02-07T20:24:43Z","title":"Oracular Programming: A Modular Foundation for Building LLM-Enabled Software","summary":"Large Language Models can solve a wide range of tasks from just a few examples, but they remain difficult to steer and lack a capability essential for building reliable software at scale: the modular composition of computations under enforceable contracts. As a result, they are typically embedded in larger software pipelines that use domain-specific knowledge to decompose tasks and improve reliability through validation and search. Yet the complexity of writing, tuning, and maintaining such pipelines has so far limited their sophistication. We propose oracular programming: a foundational paradigm for integrating traditional, explicit computations with inductive oracles such as LLMs. It rests on two directing principles: the full separation of core and search logic, and the treatment of few-shot examples as grounded and evolvable program components. Within this paradigm, experts express high-level problem-solving strategies as programs with unresolved choice points. These choice points are resolved at runtime by LLMs, which generalize from user-provided examples of correct and incorrect decisions. An oracular program is composed of three orthogonal components: a strategy that consists of a nondeterministic program with choice points that can be reified into a search tree, a policy that specifies how to navigate this tree with the help of LLM oracles, and a set of demonstrations that describe successful and unsuccessful tree navigation scenarios across diverse problem instances. Each component is expressed in a dedicated programming language and can be independently improved or substituted. We address the key programming language design challenges of modularly composing oracular programs and enforcing consistency between their components as they evolve.","authors":["Jonathan Laurent","André Platzer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.24694v2","updated":"2026-02-24T12:55:37Z","published":"2025-10-28T17:50:40Z","title":"Repurposing Synthetic Data for Fine-grained Search Agent Supervision","summary":"LLM-based search agents are increasingly trained on entity-centric synthetic data to solve complex, knowledge-intensive tasks. However, prevailing training methods like Group Relative Policy Optimization (GRPO) discard this rich entity information, relying instead on sparse, outcome-based rewards. This critical limitation renders them unable to distinguish informative \"near-miss\" samples-those with substantially correct reasoning but a flawed final answer-from complete failures, thus discarding valuable learning signals. We address this by leveraging the very entities discarded during training. Our empirical analysis reveals a strong positive correlation between the number of ground-truth entities identified during an agent's reasoning process and final answer accuracy. Building on this insight, we introduce Entity-aware Group Relative Policy Optimization (E-GRPO), a novel framework that formulates a dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect samples proportional to their entity match rate, enabling the model to effectively learn from these \"near-misses\". Experiments on diverse question-answering (QA) and deep research benchmarks show that E-GRPO consistently and significantly outperforms the GRPO baseline. Furthermore, our analysis reveals that E-GRPO not only achieves superior accuracy but also induces more efficient reasoning policies that require fewer tool calls, demonstrating a more effective and sample-efficient approach to aligning search agents.","authors":["Yida Zhao","Kuan Li","Xixi Wu","Liwen Zhang","Dingchu Zhang","Baixuan Li","Maojia Song","Zhuo Chen","Chenxi Wang","Xinyu Wang","Kewei Tu","Pengjun Xie","Jingren Zhou","Yong Jiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05598v3","updated":"2026-02-24T12:32:53Z","published":"2025-10-07T05:48:05Z","title":"AgentDR: Dynamic Recommendation with Implicit Item-Item Relations via LLM-based Agents","summary":"Recent agent-based recommendation frameworks aim to simulate user behaviors by incorporating memory mechanisms and prompting strategies, but they struggle with hallucinating non-existent items and full-catalog ranking. Besides, a largely underexplored opportunity lies in leveraging LLMs'commonsense reasoning to capture user intent through substitute and complement relationships between items, which are usually implicit in datasets and difficult for traditional ID-based recommenders to capture. In this work, we propose a novel LLM-agent framework, AgenDR, which bridges LLM reasoning with scalable recommendation tools. Our approach delegates full-ranking tasks to traditional models while utilizing LLMs to (i) integrate multiple recommendation outputs based on personalized tool suitability and (ii) reason over substitute and complement relationships grounded in user history. This design mitigates hallucination, scales to large catalogs, and enhances recommendation relevance through relational reasoning. Through extensive experiments on three public grocery datasets, we show that our framework achieves superior full-ranking performance, yielding on average a twofold improvement over its underlying tools. We also introduce a new LLM-based evaluation metric that jointly measures semantic alignment and ranking correctness.","authors":["Mingdai Yang","Nurendra Choudhary","Jiangshu Du","Edward W. Huang","Philip S. Yu","Karthik Subbian","Danai Koutra"],"pdf_url":"","comment":"12 pages, accepted by WWW'26 as long paper"},{"id":"http://arxiv.org/abs/2602.19946v2","updated":"2026-02-24T12:29:33Z","published":"2026-02-23T15:15:53Z","title":"When Pretty Isn't Useful: Investigating Why Modern Text-to-Image Models Fail as Reliable Training Data Generators","summary":"Recent text-to-image (T2I) diffusion models produce visually stunning images and demonstrate excellent prompt following. But do they perform well as synthetic vision data generators? In this work, we revisit the promise of synthetic data as a scalable substitute for real training sets and uncover a surprising performance regression. We generate large-scale synthetic datasets using state-of-the-art T2I models released between 2022 and 2025, train standard classifiers solely on this synthetic data, and evaluate them on real test data. Despite observable advances in visual fidelity and prompt adherence, classification accuracy on real test data consistently declines with newer T2I models as training data generators. Our analysis reveals a hidden trend: These models collapse to a narrow, aesthetic-centric distribution that undermines diversity and label-image alignment. Overall, our findings challenge a growing assumption in vision research, namely that progress in generative realism implies progress in data realism. We thus highlight an urgent need to rethink the capabilities of modern T2I models as reliable training data generators.","authors":["Krzysztof Adamkiewicz","Brian Moser","Stanislav Frolov","Tobias Christian Nauen","Federico Raue","Andreas Dengel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22566v2","updated":"2026-02-24T12:23:51Z","published":"2025-09-26T16:42:52Z","title":"From Parameters to Behaviors: Unsupervised Compression of the Policy Space","summary":"Despite its recent successes, Deep Reinforcement Learning (DRL) is notoriously sample-inefficient. We argue that this inefficiency stems from the standard practice of optimizing policies directly in the high-dimensional and highly redundant parameter space $Θ$. This challenge is greatly compounded in multi-task settings. In this work, we develop a novel, unsupervised approach that compresses the policy parameter space $Θ$ into a low-dimensional latent space $\\mathcal{Z}$. We train a generative model $g:\\mathcal{Z}\\toΘ$ by optimizing a behavioral reconstruction loss, which ensures that the latent space is organized by functional similarity rather than proximity in parameterization. We conjecture that the inherent dimensionality of this manifold is a function of the environment's complexity, rather than the size of the policy network. We validate our approach in continuous control domains, showing that the parameterization of standard policy networks can be compressed up to five orders of magnitude while retaining most of its expressivity. As a byproduct, we show that the learned manifold enables task-specific adaptation via Policy Gradient operating in the latent space $\\mathcal{Z}$.","authors":["Davide Tenedini","Riccardo Zamboni","Mirco Mutti","Marcello Restelli"],"pdf_url":"","comment":"ICLR 2026 camera ready version. Changed typo in the title"},{"id":"http://arxiv.org/abs/2510.09736v2","updated":"2026-02-24T12:17:22Z","published":"2025-10-10T14:20:25Z","title":"Chlorophyll-a Mapping and Prediction in the Mar Menor Lagoon Using C2RCC-Processed Sentinel 2 Imagery","summary":"The Mar Menor, Europe's largest coastal lagoon, located in Spain, has undergone severe eutrophication crises. Monitoring chlorophyll-a (Chl-a) is essential to anticipate harmful algal blooms and guide mitigation. Traditional in situ measurements are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable, long-term, and transferable monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map Chl-a across the water column of the Mar Menor. The work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Nearly a decade of Sentinel 2 images was atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth (0-1 m, 1-2 m, 2-3 m, 3-4 m). Multiple ML and DL algorithms-including RF, XGBoost, CatBoost, Multilater Perceptron Networks, and ensembles-were trained and validated using cross-validation. Systematic band-combination experiments and spatial aggregation strategies were tested to optimize prediction. Results show depth-dependent performance. At the surface, C2X-Complex with XGBoost and ensemble models achieved R2 = 0.89; at 1-2 m, CatBoost and ensemble models reached R2 = 0.87; at 2-3 m, TOA reflectances with KNN performed best (R2 = 0.81); while at 3-4 m, RF achieved R2 = 0.66. Generated maps successfully reproduced known eutrophication events (e.g., 2016 crisis, 2025 surge), confirming robustness. The study delivers an end-to-end, validated methodology for depth-specific Chl-amapping. Its integration of multispectral band combinations, buoy calibration, and ML/DL modeling offers a transferable framework for other turbid coastal systems.","authors":["Antonio Martínez-Ibarra","Aurora González-Vidal","Adrián Cánovas-Rodríguez","Antonio F. Skarmeta"],"pdf_url":"","comment":"Supplementary material is available as pdf in https://github.com/Antonio-MI/mar-menor-chl"},{"id":"http://arxiv.org/abs/2503.04398v4","updated":"2026-02-24T12:13:45Z","published":"2025-03-06T12:52:22Z","title":"Semantic Parallelism: Redefining Efficient MoE Inference via Model-Data Co-Scheduling","summary":"Prevailing LLM serving engines employ expert parallelism (EP) to implement multi-device inference of massive MoE models. However, the efficiency of expert parallel inference is largely bounded by inter-device communication, as EP embraces expensive all-to-all collectives to route tokens to the remote experts if not collocating on the same GPU/NPU device. Nevertheless, state-of-the-art schemes treat expert device-placement and request (or token) device-scheduling as separate concerns, triggering excessive communication between them and compromising inference efficiency\n  This paper proposes Semantic Parallelism, a novel parallelism paradigm that minimizes the steep communication costs in EP-centric MoE serving via model-data collaborative scheduling. We implement Semantic Parallelism in a framework called Sem-MoE. Sem-MoE maximally collocates experts and their activating tokens onto the same device using proactively modeled activation likelihood between them and introduces three key techniques: (1) Offline model scheduling, which preliminarily clusters and collocates experts onto devices based on their co-activation tendencies for certain classes of input. (2) Online inter-request data scheduling for Attention-DP setups, which proactively rebatches incoming requests onto the device that hosts experts most likely and frequently activated by the corresponding requests. (3) Online intra-request data scheduling for Attention-TP setups, which seamlessly fuses a token reshuffling procedure into the original inference pipeline and proactively reschedules tokens to devices to reduce dispersed remote routing. We build Sem-MoE into a prevailing LLM serving engine SGLANG. Experiments show our collaborative scheduling approach can effectively reduce the all-to-all communication volume in EP and achieve superior inference throughput compared to existing solutions.","authors":["Yan Li","Zhenyu Zhang","Zhengang Wang","Pengfei Chen","Pengfei Zheng"],"pdf_url":"","comment":"Published as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.20813v1","updated":"2026-02-24T11:52:17Z","published":"2026-02-24T11:52:17Z","title":"Pressure Reveals Character: Behavioural Alignment Evaluation at Depth","summary":"Evaluating alignment in language models requires testing how they behave under realistic pressure, not just what they claim they would do. While alignment failures increasingly cause real-world harm, comprehensive evaluation frameworks with realistic multi-turn scenarios remain lacking. We introduce an alignment benchmark spanning 904 scenarios across six categories -- Honesty, Safety, Non-Manipulation, Robustness, Corrigibility, and Scheming -- validated as realistic by human raters. Our scenarios place models under conflicting instructions, simulated tool access, and multi-turn escalation to reveal behavioural tendencies that single-turn evaluations miss. Evaluating 24 frontier models using LLM judges validated against human annotations, we find that even top-performing models exhibit gaps in specific categories, while the majority of models show consistent weaknesses across the board. Factor analysis reveals that alignment behaves as a unified construct (analogous to the g-factor in cognitive research) with models scoring high on one category tending to score high on others. We publicly release the benchmark and an interactive leaderboard to support ongoing evaluation, with plans to expand scenarios in areas where we observe persistent weaknesses and to add new models as they are released.","authors":["Nora Petrova","John Burden"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2601.09708v2","updated":"2026-02-24T11:51:26Z","published":"2026-01-14T18:59:59Z","title":"Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning","summary":"Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.","authors":["Chi-Pin Huang","Yunze Man","Zhiding Yu","Min-Hung Chen","Jan Kautz","Yu-Chiang Frank Wang","Fu-En Yang"],"pdf_url":"","comment":"CVPR 2026. Project page: https://jasper0314-huang.github.io/fast-thinkact/"},{"id":"http://arxiv.org/abs/2602.20812v1","updated":"2026-02-24T11:51:21Z","published":"2026-02-24T11:51:21Z","title":"Qwen-BIM: developing large language model for BIM-based design with domain-specific benchmark and dataset","summary":"As the construction industry advances toward digital transformation, BIM (Building Information Modeling)-based design has become a key driver supporting intelligent construction. Despite Large Language Models (LLMs) have shown potential in promoting BIM-based design, the lack of specific datasets and LLM evaluation benchmarks has significantly hindered the performance of LLMs. Therefore, this paper addresses this gap by proposing: 1) an evaluation benchmark for BIM-based design together with corresponding quantitative indicators to evaluate the performance of LLMs, 2) a method for generating textual data from BIM and constructing corresponding BIM-derived datasets for LLM evaluation and fine-tuning, and 3) a fine-tuning strategy to adapt LLMs for BIM-based design. Results demonstrate that the proposed domain-specific benchmark effectively and comprehensively assesses LLM capabilities, highlighting that general LLMs are still incompetent for domain-specific tasks. Meanwhile, with the proposed benchmark and datasets, Qwen-BIM is developed and achieves a 21.0% average increase in G-Eval score compared to the base LLM model. Notably, with only 14B parameters, performance of Qwen-BIM is comparable to that of general LLMs with 671B parameters for BIM-based design tasks. Overall, this study develops the first domain-specific LLM for BIM-based design by introducing a comprehensive benchmark and high-quality dataset, which provide a solid foundation for developing BIM-related LLMs in various fields.","authors":["Jia-Rui Lin","Yun-Hong Cai","Xiang-Rui Ni","Shaojie Zhou","Peng Pan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20810v1","updated":"2026-02-24T11:50:04Z","published":"2026-02-24T11:50:04Z","title":"POMDPPlanners: Open-Source Package for POMDP Planning","summary":"We present POMDPPlanners, an open-source Python package for empirical evaluation of Partially Observable Markov Decision Process (POMDP) planning algorithms. The package integrates state-of-the-art planning algorithms, a suite of benchmark environments with safety-critical variants, automated hyperparameter optimization via Optuna, persistent caching with failure recovery, and configurable parallel simulation -- reducing the overhead of extensive simulation studies. POMDPPlanners is designed to enable scalable, reproducible research on decision-making under uncertainty, with particular emphasis on risk-sensitive settings where standard toolkits fall short.","authors":["Yaacov Pariente","Vadim Indelman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20809v1","updated":"2026-02-24T11:49:59Z","published":"2026-02-24T11:49:59Z","title":"Regret-Guided Search Control for Efficient Learning in AlphaZero","summary":"Reinforcement learning (RL) agents achieve remarkable performance but remain far less learning-efficient than humans. While RL agents require extensive self-play games to extract useful signals, humans often need only a few games, improving rapidly by repeatedly revisiting states where mistakes occurred. This idea, known as search control, aims to restart from valuable states rather than always from the initial state. In AlphaZero, prior work Go-Exploit applies this idea by sampling past states from self-play or search trees, but it treats all states equally, regardless of their learning potential. We propose Regret-Guided Search Control (RGSC), which extends AlphaZero with a regret network that learns to identify high-regret states, where the agent's evaluation diverges most from the actual outcome. These states are collected from both self-play trajectories and MCTS nodes, stored in a prioritized regret buffer, and reused as new starting positions. Across 9x9 Go, 10x10 Othello, and 11x11 Hex, RGSC outperforms AlphaZero and Go-Exploit by an average of 77 and 89 Elo, respectively. When training on a well-trained 9x9 Go model, RGSC further improves the win rate against KataGo from 69.3% to 78.2%, while both baselines show no improvement. These results demonstrate that RGSC provides an effective mechanism for search control, improving both efficiency and robustness of AlphaZero training. Our code is available at https://rlg.iis.sinica.edu.tw/papers/rgsc.","authors":["Yun-Jui Tsai","Wei-Yu Chen","Yan-Ru Ju","Yu-Hung Chang","Ti-Rong Wu"],"pdf_url":"","comment":"Accepted by the Fourteenth International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2502.17028v3","updated":"2026-02-24T11:27:00Z","published":"2025-02-24T10:29:15Z","title":"Distributional Vision-Language Alignment by Cauchy-Schwarz Divergence","summary":"Vision-language alignment is crucial for various downstream tasks such as cross-modal generation and retrieval. Previous multimodal approaches like CLIP utilize InfoNCE to maximize mutual information, primarily aligning pairwise samples across modalities while overlooking distributional differences. In addition, InfoNCE has inherent conflict in terms of alignment and uniformity in multimodality, leading to suboptimal alignment with modality gaps. To overcome the limitations, we propose CS-Aligner, a novel framework that performs distributional vision-language alignment by integrating Cauchy-Schwarz (CS) divergence with mutual information. CS-Aligner captures both the global distribution information of each modality and the pairwise semantic relationships. We find that the CS divergence seamlessly addresses the InfoNCE's alignment-uniformity conflict and serves complementary roles with InfoNCE, yielding tighter and more precise alignment. Moreover, by introducing distributional alignment, CS-Aligner enables incorporating additional information from unpaired data and token-level representations, enhancing flexible and fine-grained alignment in practice. Experiments on text-to-image generation and cross-modality retrieval tasks demonstrate the effectiveness of our method on vision-language alignment.","authors":["Wenzhe Yin","Zehao Xiao","Pan Zhou","Shujian Yu","Jiayi Shen","Jan-Jakob Sonke","Efstratios Gavves"],"pdf_url":"","comment":"Accepted by ICLR2026"},{"id":"http://arxiv.org/abs/2512.16602v3","updated":"2026-02-24T11:22:02Z","published":"2025-12-18T14:43:04Z","title":"Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics","summary":"We introduce Refusal Steering, an inference-time method to exercise fine-grained control over Large Language Models refusal behaviour on politically sensitive topics without retraining. We replace fragile pattern-based refusal detection with an LLM-as-a-judge that assigns refusal confidence scores and we propose a ridge-regularized variant to compute steering vectors that better isolate the refusal--compliance direction. On Qwen3-Next-80B-A3B-Thinking, our method removes the refusal behaviour of the model around politically sensitive topics while maintaining safety on JailbreakBench and near-baseline performance on general benchmarks. The approach generalizes across 4B and 80B models and can also induce targeted refusals when desired. We analize the steering vectors and show that refusal signals concentrate in deeper layers of the transformer and are distributed across many dimensions. Together, these results demonstrate that activation steering can remove political refusal behaviour while retaining safety alignment for harmful content, offering a practical path to controllable, transparent moderation at inference time.","authors":["Iker García-Ferrero","David Montero","Roman Orus"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.09639v2","updated":"2026-02-24T11:11:02Z","published":"2025-08-13T09:20:33Z","title":"UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles","summary":"Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP), have become essential tools for interpreting complex ensemble tree-based models, especially in high-stakes domains such as healthcare analytics. However, SHAP values are usually treated as point estimates, which disregards the inherent and ubiquitous uncertainty in predictive models and data. This uncertainty has two primary sources: aleatoric and epistemic. The aleatoric uncertainty, which reflects the irreducible noise in the data. The epistemic uncertainty, which arises from a lack of data. In this work, we propose an approach for decomposing uncertainty in SHAP values into aleatoric, epistemic, and entanglement components. This approach integrates Dempster-Shafer evidence theory and hypothesis sampling via Dirichlet processes over tree ensembles. We validate the method across three real-world use cases with descriptive statistical analyses that provide insight into the nature of epistemic uncertainty embedded in SHAP explanations. The experimentations enable to provide more comprehensive understanding of the reliability and interpretability of SHAP-based attributions. This understanding can guide the development of robust decision-making processes and the refinement of models in high-stakes applications. Through our experiments with multiple datasets, we concluded that features with the highest SHAP values are not necessarily the most stable. This epistemic uncertainty can be reduced through better, more representative data and following appropriate or case-desired model development techniques. Tree-based models, especially bagging, facilitate the effective quantification of epistemic uncertainty.","authors":["Akshat Dubey","Aleksandar Anžel","Bahar İlgen","Georges Hattab"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20770v1","updated":"2026-02-24T11:01:25Z","published":"2026-02-24T11:01:25Z","title":"Pipeline for Verifying LLM-Generated Mathematical Solutions","summary":"With the growing popularity of Large Reasoning Models and their results in solving mathematical problems, it becomes crucial to measure their capabilities. We introduce a pipeline for both automatic and interactive verification as a more accurate alternative to only checking the answer which is currently the most popular approach for benchmarks. The pipeline can also be used as a generator of correct solutions both in formal and informal languages. 3 AI agents, which can be chosen for the benchmark accordingly, are included in the structure. The key idea is the use of prompts to obtain the solution in the specific form which allows for easier verification using proof assistants and possible use of small models ($\\le 8B$). Experiments on several datasets suggest low probability of False Positives. The open-source implementation with instructions on setting up a server is available at https://github.com/LogicEnj/lean4_verification_pipeline.","authors":["Varvara Sazonova","Dmitri Shmelkin","Stanislav Kikot","Vasily Motolygin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.03022v2","updated":"2026-02-24T10:53:31Z","published":"2026-02-03T02:41:11Z","title":"STAR: Similarity-guided Teacher-Assisted Refinement for Super-Tiny Function Calling Models","summary":"The proliferation of Large Language Models (LLMs) in function calling is pivotal for creating advanced AI agents, yet their large scale hinders widespread adoption, necessitating transferring their capabilities into smaller ones. However, existing paradigms are often plagued by overfitting, training instability, ineffective binary rewards for multi-solution tasks, and the difficulty of synergizing techniques. We introduce STAR: Similarity-guided Teacher-Assisted Refinement, a novel holistic framework that effectively transfers LLMs' capabilities to super-tiny models. STAR consists of two core technical innovations: (1) Constrained Knowledge Distillation (CKD), a training objective that augments top-k forward KL divergence to suppress confidently incorrect predictions, ensuring training stability while preserving exploration capacity for downstream RL. STAR holistically synergizes these strategies within a cohesive training curriculum, enabling super-tiny models to achieve exceptional performance on complex function calling tasks; (2) Similarity-guided RL (Sim-RL), a RL mechanism that introduces a fine-grained, similarity-based reward. This provides a robust, continuous, and rich signal for better policy optimization by evaluating the similarity between generated outputs and the ground truth. Extensive experiments on challenging and renowned benchmarks demonstrate the effectiveness of our method. Our STAR models establish SOTA in their size classes, significantly outperforming baselines. Remarkably, our 0.6B STAR model achieves the best performance among all open models under 1B, surpassing even several well-known open models at a larger scale. STAR demonstrates a training framework that distills capabilities of LLMs into super-tiny models, paving the way for powerful, accessible, and efficient AI agents.","authors":["Jiliang Ni","Jiachen Pu","Zhongyi Yang","Jingfeng Luo","Conggang Hu"],"pdf_url":"","comment":"The paper has been accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2602.16372v2","updated":"2026-02-24T10:37:35Z","published":"2026-02-18T11:14:35Z","title":"AI-Driven Structure Refinement of X-ray Diffraction","summary":"Artificial intelligence can rapidly propose candidate phases and structures from X-ray diffraction (XRD), but these hypotheses often fail in downstream refinement because peak intensities cannot be stably assigned under severe overlap and diffraction consistency is enforced only weakly. Here we introduce the whole-pattern expectation--maximization (WPEM) algorithm, a physics-constrained whole-pattern decomposition and refinement workflow that turns Bragg's law into an explicit constraint within a batch expectation--maximization framework. WPEM models the full profile as a probabilistic mixture density and iteratively infers component-resolved intensities while keeping peak centres Bragg-consistent, producing a continuous, physically admissible intensity representation that remains stable in heavily overlapped regions and in the presence of mixed radiation or multiple phases. We benchmark WPEM on standard reference patterns (PbSO$_4$ and Tb$_2$BaCoO$_5$), where it yields lower $R_p/R_{wp}$ than widely used packages (FullProf and TOPAS) under matched refinement conditions. We further demonstrate generality across realistic experimental scenarios, including phase-resolved decomposition in multiphase materials, quantitative recovery of mixture compositions, separation of crystalline peaks from amorphous backgrounds in semicrystalline systems, high-throughput operando lattice tracking, automated refinement of compositionally disordered solid solutions, and quantitative phase-resolved analysis of complex archaeological samples from synchrotron powder XRD. By providing Bragg-consistent, uncertainty-aware intensity partitioning as a refinement-ready interface, WPEM closes the gap between AI-generated hypotheses and diffraction-admissible structure refinement on challenging XRD data.","authors":["Bin Cao","Qian Zhang","Zhenjie Feng","Taolue Zhang","Jiaqiang Huang","Lu-Tao Weng","Tong-Yi Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06251v2","updated":"2026-02-24T10:32:26Z","published":"2025-06-06T17:21:21Z","title":"DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation","summary":"Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in automated front-end engineering, e.g., generating UI code from visual designs. However, existing front-end UI code generation benchmarks have the following limitations: (1) While framework-based development becomes predominant in modern front-end programming, current benchmarks fail to incorporate mainstream development frameworks. (2) Existing evaluations focus solely on the UI code generation task, whereas practical UI development involves several iterations, including refining editing, and repairing issues. (3) Current benchmarks employ unidimensional evaluation, lacking investigation into influencing factors like task difficulty, input context variations, and in-depth code-level analysis. To bridge these gaps, we introduce DesignBench, a multi-framework, multi-task evaluation benchmark for assessing MLLMs' capabilities in automated front-end engineering. DesignBench encompasses three widely-used UI frameworks (React, Vue, and Angular) alongside vanilla HTML/CSS, and evaluates on three essential front-end tasks (generation, edit, and repair) in real-world development workflows. DesignBench contains 900 webpage samples spanning over 11 topics, 9 edit types, and 6 issue categories, enabling detailed analysis of MLLM performance across multiple dimensions. Our systematic evaluation reveals critical insights into MLLMs' framework-specific limitations, task-related bottlenecks, and performance variations under different conditions, providing guidance for future research in automated front-end development. Our code and data are available at https://github.com/WebPAI/DesignBench.","authors":["Jingyu Xiao","Man Ho Lam","Ming Wang","Yuxuan Wan","Junliang Liu","Yintong Huo","Michael R. Lyu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20752v1","updated":"2026-02-24T10:29:10Z","published":"2026-02-24T10:29:10Z","title":"OrthoDiffusion: A Generalizable Multi-Task Diffusion Foundation Model for Musculoskeletal MRI Interpretation","summary":"Musculoskeletal disorders represent a significant global health burden and are a leading cause of disability worldwide. While MRI is essential for accurate diagnosis, its interpretation remains exceptionally challenging. Radiologists must identify multiple potential abnormalities within complex anatomical structures across different imaging planes, a process that requires significant expertise and is prone to variability. We developed OrthoDiffusion, a unified diffusion-based foundation model designed for multi-task musculoskeletal MRI interpretation. The framework utilizes three orientation-specific 3D diffusion models, pre-trained in a self-supervised manner on 15,948 unlabeled knee MRI scans, to learn robust anatomical features from sagittal, coronal, and axial views. These view-specific representations are integrated to support diverse clinical tasks, including anatomical segmentation and multi-label diagnosis. Our evaluation demonstrates that OrthoDiffusion achieves excellent performance in the segmentation of 11 knee structures and the detection of 8 knee abnormalities. The model exhibited remarkable robustness across different clinical centers and MRI field strengths, consistently outperforming traditional supervised models. Notably, in settings where labeled data was scarce, OrthoDiffusion maintained high diagnostic precision using only 10\\% of training labels. Furthermore, the anatomical representations learned from knee imaging proved highly transferable to other joints, achieving strong diagnostic performance across 11 diseases of the ankle and shoulder. These findings suggest that diffusion-based foundation models can serve as a unified platform for multi-disease diagnosis and anatomical segmentation, potentially improving the efficiency and accuracy of musculoskeletal MRI interpretation in real-world clinical workflows.","authors":["Tian Lan","Lei Xu","Zimu Yuan","Shanggui Liu","Jiajun Liu","Jiaxin Liu","Weilai Xiang","Hongyu Yang","Dong Jiang","Jianxin Yin","Dingyu Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.08274v3","updated":"2026-02-24T10:29:09Z","published":"2026-02-09T05:09:03Z","title":"Language Modeling and Understanding Through Paraphrase Generation and Detection","summary":"Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...","authors":["Jan Philip Wahle"],"pdf_url":"","comment":"PhD Thesis (Dissertation), University of Göttingen Germany, 2025. 186 pages"},{"id":"http://arxiv.org/abs/2602.20751v1","updated":"2026-02-24T10:28:44Z","published":"2026-02-24T10:28:44Z","title":"SibylSense: Adaptive Rubric Learning via Memory Tuning and Adversarial Probing","summary":"Designing aligned and robust rewards for open-ended generation remains a key barrier to RL post-training. Rubrics provide structured, interpretable supervision, but scaling rubric construction is difficult: expert rubrics are costly, prompted rubrics are often superficial or inconsistent, and fixed-pool discriminative rubrics can saturate and drift, enabling reward hacking. We present SibylSense, an inference-time learning approach that adapts a frozen rubric generator through a tunable memory bank of validated rubric items. Memory is updated via verifier-based item rewards measured by reference-candidate answer discriminative gaps from a handful of examples. SibylSense alternates memory tuning with a rubric-adversarial policy update that produces rubric-satisfying candidate answers, shrinking discriminative gaps and driving the rubric generator to capture new quality dimensions. Experiments on two open-ended tasks show that SibylSense yields more discriminative rubrics and improves downstream RL performance over static and non-adaptive baselines.","authors":["Yifei Xu","Guilherme Potje","Shivam Shandilya","Tiancheng Yuan","Leonardo de Oliveira Nunes","Rakshanda Agarwal","Saeid Asgari","Adam Atkinson","Emre Kıcıman","Songwu Lu","Ranveer Chandra","Tusher Chakraborty"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20744v1","updated":"2026-02-24T10:17:16Z","published":"2026-02-24T10:17:16Z","title":"Voices of the Mountains: Deep Learning-Based Vocal Error Detection System for Kurdish Maqams","summary":"Maqam, a singing type, is a significant component of Kurdish music. A maqam singer receives training in a traditional face-to-face or through self-training. Automatic Singing Assessment (ASA) uses machine learning (ML) to provide the accuracy of singing styles and can help learners to improve their performance through error detection. Currently, the available ASA tools follow Western music rules. The musical composition requires all notes to stay within their expected pitch range from start to finish. The system fails to detect micro-intervals and pitch bends, so it identifies Kurdish maqam singing as incorrect even though the singer performs according to traditional rules. Kurdish maqam requires recognizing performance errors within microtonal spaces, which is beyond Western equal temperament. This research is the first attempt to address the mentioned gap. While many error types happen during singing, our focus is on pitch, rhythm, and modal stability errors in the context of Bayati-Kurd. We collected 50 songs from 13 vocalists ( 2-3 hours) and annotated 221 error spans (150 fine pitch, 46 rhythm, 25 modal drift). The data was segmented into 15,199 overlapping windows and converted to log-mel spectrograms. We developed a two-headed CNN-BiLSTM with attention mode to decide whether a window contains an error and to classify it based on the chosen errors. Trained for 20 epochs with early stopping at epoch 10, the model reached a validation macro-F1 of 0.468. On the full 50-song evaluation at a 0.750 threshold, recall was 39.4% and precision 25.8% . Within detected windows, type macro-F1 was 0.387, with F1 of 0.492 (fine pitch), 0.536 (rhythm), and 0.133 (modal drift); modal drift recall was 8.0%. The better performance on common error types shows that the method works, while the poor modal-drift recall shows that more data and balancing are needed.","authors":["Darvan Shvan Khairaldeen","Hossein Hassani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.09768v2","updated":"2026-02-24T10:13:44Z","published":"2026-01-14T11:21:05Z","title":"CLiMB: A Domain-Informed Novelty Detection Clustering Framework for Galactic Archaeology and Scientific Discovery","summary":"In data-driven scientific discovery, a challenge lies in classifying well-characterized phenomena while identifying novel anomalies. Current semi-supervised clustering algorithms do not always fully address this duality, often assuming that supervisory signals are globally representative. Consequently, methods often enforce rigid constraints that suppress unanticipated patterns or require a pre-specified number of clusters, rendering them ineffective for genuine novelty detection. To bridge this gap, we introduce CLiMB (CLustering in Multiphase Boundaries), a domain-informed framework decoupling the exploitation of prior knowledge from the exploration of unknown structures. Using a sequential two-phase approach, CLiMB first anchors known clusters using metric-adaptive constrained partitioning, and subsequently applies density-based clustering to residual data to reveal arbitrary topologies. We demonstrate this framework on RR Lyrae stars data from the Gaia Data Release 3. CLiMB attains an Adjusted Rand Index of 0.829 with 90% seed coverage in recovering known Milky Way substructures, outperforming heuristic and constraint-based baselines, which stagnate below 0.20. Furthermore, sensitivity analysis confirms CLiMB's superior data efficiency, showing monotonic improvement as knowledge increases. Finally, the framework successfully isolates three distinct dynamical features (Shiva, Shakti, and the Galactic Disk) in the unlabelled field, validating its potential for scientific discovery.","authors":["Lorenzo Monti","Tatiana Muraveva","Brian Sheridan","Davide Massari","Alessia Garofalo","Gisella Clementini","Umberto Michelucci"],"pdf_url":"","comment":"19 pages, 4 figures"},{"id":"http://arxiv.org/abs/2602.20739v1","updated":"2026-02-24T10:08:33Z","published":"2026-02-24T10:08:33Z","title":"PyVision-RL: Forging Open Agentic Vision Models via RL","summary":"Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that stabilizes training and sustains interaction. Our approach combines an oversampling-filtering-ranking rollout strategy with an accumulative tool reward to prevent collapse and encourage multi-turn tool use. Using a unified training pipeline, we develop PyVision-Image and PyVision-Video for image and video understanding. For video reasoning, PyVision-Video employs on-demand context construction, selectively sampling task-relevant frames during reasoning to significantly reduce visual token usage. Experiments show strong performance and improved efficiency, demonstrating that sustained interaction and on-demand visual processing are critical for scalable multimodal agents.","authors":["Shitian Zhao","Shaoheng Lin","Ming Li","Haoquan Zhang","Wenshuo Peng","Kaipeng Zhang","Chen Wei"],"pdf_url":"","comment":"preprint"},{"id":"http://arxiv.org/abs/2509.24803v3","updated":"2026-02-24T10:03:33Z","published":"2025-09-29T13:54:34Z","title":"TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models","summary":"Recent advances in multimodal time series learning underscore a paradigm shift from analytics centered on basic patterns toward advanced time series understanding and reasoning. However, existing multimodal time series datasets mostly remain at the level of surface alignment and question answering, without reaching the depth of genuine reasoning. The absence of well-defined tasks that genuinely require time series reasoning, along with the scarcity of high-quality data, has limited progress in building practical time series reasoning models (TSRMs). To this end, we introduce Time Series Reasoning Suite (TSR-Suite), which formalizes four atomic tasks that span three fundamental capabilities for reasoning with time series: (1) perception, acquired through scenario understanding and causality discovery; (2) extrapolation, realized via event-aware forecasting; and (3) decision-making, developed through deliberation over perception and extrapolation. TSR-Suite is the first comprehensive time series reasoning suite that supports not only thorough evaluation but also the data pipeline and training of TSRMs. It contains more than 23K samples, of which 2.3K are carefully curated through a human-guided hierarchical annotation process. Building on this foundation, we introduce TimeOmni-1, the first unified reasoning model designed to address diverse real-world problems demanding time series reasoning. The model is trained in multiple stages, integrating a mixture of task scenarios, novel reward functions, and tailored optimizations. Experiments show that TimeOmni-1 delivers strong out-of-distribution generalization across all tasks and achieves a high rate of valid responses. It significantly improves causality discovery accuracy (64.0% vs. 35.9% with GPT-4.1) and raises the valid response rate by over 6% compared to GPT-4.1 on the event-aware forecasting task.","authors":["Tong Guan","Zijie Meng","Dianqi Li","Shiyu Wang","Chao-Han Huck Yang","Qingsong Wen","Zuozhu Liu","Sabato Marco Siniscalchi","Ming Jin","Shirui Pan"],"pdf_url":"","comment":"Accepted by the 14th International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2602.20735v1","updated":"2026-02-24T09:58:25Z","published":"2026-02-24T09:58:25Z","title":"RMIT-ADM+S at the MMU-RAG NeurIPS 2025 Competition","summary":"This paper presents the award-winning RMIT-ADM+S system for the Text-to-Text\n  track of the NeurIPS~2025 MMU-RAG Competition. We introduce Routing-to-RAG\n  (R2RAG), a research-focused retrieval-augmented generation (RAG)\n  architecture composed of lightweight components that dynamically adapt the\n  retrieval strategy based on inferred query complexity and evidence\n  sufficiency. The system uses smaller LLMs, enabling operation on a single\n  consumer-grade GPU while supporting complex research tasks. It builds on the\n  G-RAG system, winner of the ACM~SIGIR~2025 LiveRAG Challenge, and extends it\n  with modules informed by qualitative review of outputs. R2RAG won the Best\n  Dynamic Evaluation award in the Open Source category, demonstrating high\n  effectiveness with careful design and efficient use of resources.","authors":["Kun Ran","Marwah Alaofi","Danula Hettiachchi","Chenglong Ma","Khoi Nguyen Dinh Anh","Khoi Vo Nguyen","Sachin Pathiyan Cherumanal","Lida Rashidi","Falk Scholer","Damiano Spina","Shuoqi Sun","Oleg Zendel"],"pdf_url":"","comment":"MMU-RAG NeurIPS 2025 winning system"},{"id":"http://arxiv.org/abs/2510.18114v2","updated":"2026-02-24T09:55:10Z","published":"2025-10-20T21:26:52Z","title":"Latent-Augmented Discrete Diffusion Models","summary":"Discrete diffusion models have emerged as a powerful class of models and a promising route to fast language generation, but practical implementations typically rely on factored reverse transitions that ignore cross-token dependencies and degrade performance in the few-step regime. We propose Latent-Augmented Discrete Diffusion (LADD), which introduces a learnable auxiliary latent channel and performs diffusion over the joint (token, latent) space. The latent variables provide an intermediate representation that can express joint structure while preserving tractable parameterizations. We instantiate LADD with continuous latents (Co-LADD) and discrete latents (Di-LADD), and study two inference schedules: a joint diffusion that denoises data and latents together, and a sequential diffusion that first resolves latents and then samples tokens conditionally. We derive ELBO-style objectives and analyze design choices that balance latent expressivity with diffusion compatibility. In experiments, LADDs yield improvements on unconditional generation metrics as compared to state-of-the-art masked discrete diffusion baselines, and are effective at lower sampling budgets, where unmasking many tokens per step is desirable.","authors":["Dario Shariatian","Alain Durmus","Umut Simsekli","Stefano Peluchetti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20732v1","updated":"2026-02-24T09:54:59Z","published":"2026-02-24T09:54:59Z","title":"CHESS: Context-aware Hierarchical Efficient Semantic Selection for Long-Context LLM Inference","summary":"Long-context LLMs demand accurate inference at low latency, yet decoding becomes primarily constrained by KV cache as context grows. Prior pruning methods are largely context-agnostic: their token selection ignores step-wise relevance and local semantics, which undermines quality. Moreover, their irregular accesses and selection overheads yield only limited wall-clock speedups. To address this, we propose \\textbf{CHESS}, an \\textit{algorithm-system co-design} KV-cache management system. Algorithmically, CHESS introduces a context-aware, hierarchical selection policy that dynamically reconstructs a coherent context for the current decoding. System-wise, coarse granularity selection eliminates expensive data movement, fully realizing practical acceleration from theoretical sparsity. Extensive evaluations demonstrate that CHESS surpasses Full-KV quality using only \\textbf{1\\%} of the KV cache, delivers low-latency stable inference with up to \\textbf{4.56$\\times$} higher throughput, and consistently outperforms other strong baselines. Code is available at \\href{https://anonymous.4open.science/r/CHESS-9958/}{https://anonymous.4open.science/r/CHESS/}.","authors":["Chao Fei","Guozhong Li","Chenxi Liu","Panos Kalnis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20731v1","updated":"2026-02-24T09:53:50Z","published":"2026-02-24T09:53:50Z","title":"Communication-Inspired Tokenization for Structured Image Representations","summary":"Discrete image tokenizers have emerged as a key component of modern vision and multimodal systems, providing a sequential interface for transformer-based architectures. However, most existing approaches remain primarily optimized for reconstruction and compression, often yielding tokens that capture local texture rather than object-level semantic structure. Inspired by the incremental and compositional nature of human communication, we introduce COMmunication inspired Tokenization (COMiT), a framework for learning structured discrete visual token sequences. COMiT constructs a latent message within a fixed token budget by iteratively observing localized image crops and recurrently updating its discrete representation. At each step, the model integrates new visual information while refining and reorganizing the existing token sequence. After several encoding iterations, the final message conditions a flow-matching decoder that reconstructs the full image. Both encoding and decoding are implemented within a single transformer model and trained end-to-end using a combination of flow-matching reconstruction and semantic representation alignment losses. Our experiments demonstrate that while semantic alignment provides grounding, attentive sequential tokenization is critical for inducing interpretable, object-centric token structure and substantially improving compositional generalization and relational reasoning over prior methods.","authors":["Aram Davtyan","Yusuf Sahin","Yasaman Haghighi","Sebastian Stapf","Pablo Acuaviva","Alexandre Alahi","Paolo Favaro"],"pdf_url":"","comment":"Project website: https://araachie.github.io/comit/"},{"id":"http://arxiv.org/abs/2602.20728v1","updated":"2026-02-24T09:47:25Z","published":"2026-02-24T09:47:25Z","title":"Balancing Multiple Objectives in Urban Traffic Control with Reinforcement Learning from AI Feedback","summary":"Reward design has been one of the central challenges for real world reinforcement learning (RL) deployment, especially in settings with multiple objectives. Preference-based RL offers an appealing alternative by learning from human preferences over pairs of behavioural outcomes. More recently, RL from AI feedback (RLAIF) has demonstrated that large language models (LLMs) can generate preference labels at scale, mitigating the reliance on human annotators. However, existing RLAIF work typically focuses only on single-objective tasks, leaving the open question of how RLAIF handles systems that involve multiple objectives. In such systems trade-offs among conflicting objectives are difficult to specify, and policies risk collapsing into optimizing for a dominant goal. In this paper, we explore the extension of the RLAIF paradigm to multi-objective self-adaptive systems. We show that multi-objective RLAIF can produce policies that yield balanced trade-offs reflecting different user priorities without laborious reward engineering. We argue that integrating RLAIF into multi-objective RL offers a scalable path toward user-aligned policy learning in domains with inherently conflicting objectives.","authors":["Chenyang Zhao","Vinny Cahill","Ivana Dusparic"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20723v1","updated":"2026-02-24T09:36:45Z","published":"2026-02-24T09:36:45Z","title":"Modality-Guided Mixture of Graph Experts with Entropy-Triggered Routing for Multimodal Recommendation","summary":"Multimodal recommendation enhances ranking by integrating user-item interactions with item content, which is particularly effective under sparse feedback and long-tail distributions. However, multimodal signals are inherently heterogeneous and can conflict in specific contexts, making effective fusion both crucial and challenging. Existing approaches often rely on shared fusion pathways, leading to entangled representations and modality imbalance. To address these issues, we propose \\textbf{MAGNET}, a \\textbf{M}odality-Guided Mixture of \\textbf{A}daptive \\textbf{G}raph Experts \\textbf{N}etwork with Progressive \\textbf{E}ntropy-\\textbf{T}riggered Routing for Multimodal Recommendation, designed to enhance controllability, stability, and interpretability in multimodal fusion. MAGNET couples interaction-conditioned expert routing with structure-aware graph augmentation, so that both \\emph{what} to fuse and \\emph{how} to fuse are explicitly controlled and interpretable. At the representation level, a dual-view graph learning module augments the interaction graph with content-induced edges, improving coverage for sparse and long-tail items while preserving collaborative structure via parallel encoding and lightweight fusion. At the fusion level, MAGNET employs structured experts with explicit modality roles -- dominant, balanced, and complementary -- enabling a more interpretable and adaptive combination of behavioral, visual, and textual cues. To further stabilize sparse routing and prevent expert collapse, we introduce a two-stage entropy-weighting mechanism that monitors routing entropy. This mechanism automatically transitions training from an early coverage-oriented regime to a later specialization-oriented regime, progressively balancing expert utilization and routing confidence. Extensive experiments on public benchmarks demonstrate consistent improvements over strong baselines.","authors":["Ji Dai","Quan Fang","Dengsheng Cai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20722v1","updated":"2026-02-24T09:35:43Z","published":"2026-02-24T09:35:43Z","title":"Buffer Matters: Unleashing the Power of Off-Policy Reinforcement Learning in Large Language Model Reasoning","summary":"Traditional on-policy Reinforcement Learning with Verifiable Rewards (RLVR) frameworks suffer from experience waste and reward homogeneity, which directly hinders learning efficiency on difficult samples during large language models post-training. In this paper, we introduce Batch Adaptation Policy Optimization (BAPO), an off-policy RLVR framework to improve the data efficiency in large language models post-training. It dynamically selects training batches by re-evaluating historically difficult samples and reusing high-quality ones, while holding a lower bound guarantee for policy improvement. Extensive experiments further demonstrate that BAPO achieves an average 12.5% improvement over GRPO across mathematics, planning, and visual reasoning tasks. Crucially, BAPO successfully resolves 40.7% of problems that base models consistently fail to solve.","authors":["Xu Wan","Yansheng Wang","Wenqi Huang","Mingyang Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20720v1","updated":"2026-02-24T09:32:19Z","published":"2026-02-24T09:32:19Z","title":"AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs","summary":"The integration of external data services (e.g., Model Context Protocol, MCP) has made large language model-based agents increasingly powerful for complex task execution. However, this advancement introduces critical security vulnerabilities, particularly indirect prompt injection (IPI) attacks. Existing attack methods are limited by their reliance on static patterns and evaluation on simple language models, failing to address the fast-evolving nature of modern AI agents. We introduce AdapTools, a novel adaptive IPI attack framework that selects stealthier attack tools and generates adaptive attack prompts to create a rigorous security evaluation environment. Our approach comprises two key components: (1) Adaptive Attack Strategy Construction, which develops transferable adversarial strategies for prompt optimization, and (2) Attack Enhancement, which identifies stealthy tools capable of circumventing task-relevance defenses. Comprehensive experimental evaluation shows that AdapTools achieves a 2.13 times improvement in attack success rate while degrading system utility by a factor of 1.78. Notably, the framework maintains its effectiveness even against state-of-the-art defense mechanisms. Our method advances the understanding of IPI attacks and provides a useful reference for future research.","authors":["Che Wang","Jiaming Zhang","Ziqi Zhang","Zijie Wang","Yinghui Wang","Jianbo Gao","Tao Wei","Zhong Chen","Wei Yang Bryan Lim"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2508.19113v2","updated":"2026-02-24T09:32:16Z","published":"2025-08-26T15:15:17Z","title":"Hybrid Deep Searcher: Scalable Parallel and Sequential Search Reasoning","summary":"Large reasoning models (LRMs) combined with retrieval-augmented generation (RAG) have enabled deep research agents capable of multi-step reasoning with external knowledge retrieval. However, we find that existing approaches rarely demonstrate test-time search scaling. Methods that extend reasoning through single-query sequential search suffer from limited evidence coverage, while approaches that generate multiple independent queries per step often lack structured aggregation, hindering deeper sequential reasoning. We propose a hybrid search strategy to address these limitations. We introduce HybridDeepSearcher, a structured search agent that integrates parallel query expansion with explicit evidence aggregation before advancing to deeper sequential reasoning. To supervise this behavior, we introduce HDS-QA, a novel dataset that guides models to combine broad parallel search with structured aggregation through supervised reasoning-query0retrieval trajectories containing parallel sub-queries. Across five benchmarks, HybridDeepSearcher significantly outperforms the state-of-the-art, improving F1 scores by +15.9 on FanOutQA and +9.2 on a subset of BrowseComp. Further analysis shows its consistent test-time search scaling: performance improves as additional search turns or calls are allowed, while competing methods plateau.","authors":["Dayoon Ko","Jihyuk Kim","Haeju Park","Sohyeon Kim","Dahyun Lee","Yongrae Jo","Gunhee Kim","Moontae Lee","Kyungjae Lee"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2504.12007v5","updated":"2026-02-24T09:25:50Z","published":"2025-04-16T12:01:03Z","title":"Diffusion Generative Recommendation with Continuous Tokens","summary":"Recent advances in generative artificial intelligence, particularly large language models (LLMs), have opened new opportunities for enhancing recommender systems (RecSys). Most existing LLM-based RecSys approaches operate in a discrete space, using vector-quantized tokenizers to align with the inherent discrete nature of language models. However, these quantization methods often result in lossy tokenization and suboptimal learning, primarily due to inaccurate gradient propagation caused by the non-differentiable argmin operation in standard vector quantization. Inspired by the emerging trend of embracing continuous tokens in language models, we propose ContRec, a novel framework that seamlessly integrates continuous tokens into LLM-based RecSys. Specifically, ContRec consists of two key modules: a sigma-VAE Tokenizer, which encodes users/items with continuous tokens; and a Dispersive Diffusion module, which captures implicit user preference. The tokenizer is trained with a continuous Variational Auto-Encoder (VAE) objective, where three effective techniques are adopted to avoid representation collapse. By conditioning on the previously generated tokens of the LLM backbone during user modeling, the Dispersive Diffusion module performs a conditional diffusion process with a novel Dispersive Loss, enabling high-quality user preference generation through next-token diffusion. Finally, ContRec leverages both the textual reasoning output from the LLM and the latent representations produced by the diffusion model for Top-K item retrieval, thereby delivering comprehensive recommendation results. Extensive experiments on four datasets demonstrate that ContRec consistently outperforms both traditional and SOTA LLM-based recommender systems. Our results highlight the potential of continuous tokenization and generative modeling for advancing the next generation of recommender systems.","authors":["Haohao Qu","Shanru Lin","Yujuan Ding","Yiqi Wang","Wenqi Fan"],"pdf_url":"","comment":"Accepted by The ACM Web Conference (WWW 2026)"},{"id":"http://arxiv.org/abs/2602.02620v2","updated":"2026-02-24T09:20:02Z","published":"2026-02-02T13:36:36Z","title":"CryoLVM: Self-supervised Learning from Cryo-EM Density Maps with Large Vision Models","summary":"Cryo-electron microscopy (cryo-EM) has revolutionized structural biology by enabling near-atomic-level visualization of biomolecular assemblies. However, the exponential growth in cryo-EM data throughput and complexity, coupled with diverse downstream analytical tasks, necessitates unified computational frameworks that transcend current task-specific deep learning approaches with limited scalability and generalizability. We present CryoLVM, a foundation model that learns rich structural representations from experimental density maps with resolved structures by leveraging the Joint-Embedding Predictive Architecture (JEPA) integrated with SCUNet-based backbone, which can be rapidly adapted to various downstream tasks. We further introduce a novel histogram-based distribution alignment loss that accelerates convergence and enhances fine-tuning performance. We demonstrate CryoLVM's effectiveness across three critical cryo-EM tasks: density map sharpening, density map super-resolution, and missing wedge restoration. Our method consistently outperforms state-of-the-art baselines across multiple density map quality metrics, confirming its potential as a versatile model for a wide spectrum of cryo-EM applications.","authors":["Weining Fu","Kai Shu","Kui Xu","Qiangfeng Cliff Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.06871v2","updated":"2026-02-24T09:15:53Z","published":"2024-12-09T12:34:13Z","title":"Predicting Subway Passenger Flows under Incident Situation with Causality","summary":"In the context of rail transit operations, real-time passenger flow prediction is essential; however, most models primarily focus on normal conditions, with limited research addressing incident situations. There are several intrinsic challenges associated with prediction during incidents, such as a lack of interpretability and data scarcity. To address these challenges, we propose a two-stage method that separates predictions under normal conditions and the causal effects of incidents. First, a normal prediction model is trained using data from normal situations. Next, the synthetic control method is employed to identify the causal effects of incidents, combined with placebo tests to determine significant levels of these effects. The significant effects are then utilized to train a causal effect prediction model, which can forecast the impact of incidents based on features of the incidents and passenger flows. During the prediction phase, the results from both the normal situation model and the causal effect prediction model are integrated to generate final passenger flow predictions during incidents. Our approach is validated using real-world data, demonstrating improved accuracy. Furthermore, the two-stage methodology enhances interpretability. By analyzing the causal effect prediction model, we can identify key influencing factors related to the effects of incidents and gain insights into their underlying mechanisms. Our work can assist subway system managers in estimating passenger flow affected by incidents and enable them to take proactive measures. Additionally, it can deepen researchers' understanding of the impact of incidents on subway passenger flows.","authors":["Xiannan Huang","Shuhan Qiu","Quan Yuan","Chao Yang"],"pdf_url":"","comment":"Accepted by Transportation"},{"id":"http://arxiv.org/abs/2602.20710v1","updated":"2026-02-24T09:15:30Z","published":"2026-02-24T09:15:30Z","title":"Counterfactual Simulation Training for Chain-of-Thought Faithfulness","summary":"Inspecting Chain-of-Thought reasoning is among the most common means of understanding why an LLM produced its output. But well-known problems with CoT faithfulness severely limit what insights can be gained from this practice. In this paper, we introduce a training method called Counterfactual Simulation Training (CST), which aims to improve CoT faithfulness by rewarding CoTs that enable a simulator to accurately predict a model's outputs over counterfactual inputs. We apply CST in two settings: (1) CoT monitoring with cue-based counterfactuals, to detect when models rely on spurious features, reward hack, or are sycophantic, and (2) counterfactual simulation over generic model-based counterfactuals, to encourage models to produce more faithful, generalizable reasoning in the CoT. Experiments with models up to 235B parameters show that CST can substantially improve monitor accuracy on cue-based counterfactuals (by 35 accuracy points) as well as simulatability over generic counterfactuals (by 2 points). We further show that: (1) CST outperforms prompting baselines, (2) rewriting unfaithful CoTs with an LLM is 5x more efficient than RL alone, (3) faithfulness improvements do not generalize to dissuading cues (as opposed to persuading cues), and (4) larger models do not show more faithful CoT out of the box, but they do benefit more from CST. These results suggest that CST can improve CoT faithfulness in general, with promising applications for CoT monitoring. Code for experiments in this paper is available at https://github.com/peterbhase/counterfactual-simulation-training","authors":["Peter Hase","Christopher Potts"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20709v1","updated":"2026-02-24T09:15:13Z","published":"2026-02-24T09:15:13Z","title":"Onboard-Targeted Segmentation of Straylight in Space Camera Sensors","summary":"This study details an artificial intelligence (AI)-based methodology for the semantic segmentation of space camera faults. Specifically, we address the segmentation of straylight effects induced by solar presence around the camera's Field of View (FoV). Anomalous images are sourced from our published dataset. Our approach emphasizes generalization across diverse flare textures, leveraging pre-training on a public dataset (Flare7k++) including flares in various non-space contexts to mitigate the scarcity of realistic space-specific data. A DeepLabV3 model with MobileNetV3 backbone performs the segmentation task. The model design targets deployment in spacecraft resource-constrained hardware. Finally, based on a proposed interface between our model and the onboard navigation pipeline, we develop custom metrics to assess the model's performance in the system-level context.","authors":["Riccardo Gallon","Fabian Schiemenz","Alessandra Menicucci","Eberhard Gill"],"pdf_url":"","comment":"Submitted to Aerospace Science and Technology"},{"id":"http://arxiv.org/abs/2602.20708v1","updated":"2026-02-24T09:13:05Z","published":"2026-02-24T09:13:05Z","title":"ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction","summary":"Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical limitation: over-refusal, prematurely terminating valid agentic workflows. We propose ICON, a probing-to-mitigation framework that neutralizes attacks while preserving task continuity. Our key insight is that IPI attacks leave distinct over-focusing signatures in the latent space. We introduce a Latent Space Trace Prober to detect attacks based on high intensity scores. Subsequently, a Mitigating Rectifier performs surgical attention steering that selectively manipulate adversarial query key dependencies while amplifying task relevant elements to restore the LLM's functional trajectory. Extensive evaluations on multiple backbones show that ICON achieves a competitive 0.4% ASR, matching commercial grade detectors, while yielding a over 50% task utility gain. Furthermore, ICON demonstrates robust Out of Distribution(OOD) generalization and extends effectively to multi-modal agents, establishing a superior balance between security and efficiency.","authors":["Che Wang","Fuyao Zhang","Jiaming Zhang","Ziqi Zhang","Yinghui Wang","Longtao Huang","Jianbo Gao","Zhong Chen","Wei Yang Bryan Lim"],"pdf_url":"","comment":"11 pages,"},{"id":"http://arxiv.org/abs/2602.20706v1","updated":"2026-02-24T09:11:56Z","published":"2026-02-24T09:11:56Z","title":"Online Algorithms with Unreliable Guidance","summary":"This paper introduces a new model for ML-augmented online decision making, called online algorithms with unreliable guidance (OAG). This model completely separates between the predictive and algorithmic components, thus offering a single well-defined analysis framework that relies solely on the considered problem. Formulated through the lens of request-answer games, an OAG algorithm receives, with each incoming request, a piece of guidance which is taken from the problem's answer space; ideally, this guidance is the optimal answer for the current request, however with probability $β$, the guidance is adversarially corrupted. The goal is to develop OAG algorithms that admit good competitiveness when $β= 0$ (a.k.a. consistency) as well as when $β= 1$ (a.k.a. robustness); the appealing notion of smoothness, that in most prior work required a dedicated loss function, now arises naturally as $β$ shifts from $0$ to $1$.\n  We then describe a systematic method, called the drop or trust blindly (DTB) compiler, which transforms any online algorithm into a learning-augmented online algorithm in the OAG model. Given a prediction-oblivious online algorithm, its learning-augmented counterpart produced by applying the DTB compiler either follows the incoming guidance blindly or ignores it altogether and proceeds as the initial algorithm would have; the choice between these two alternatives is based on the outcome of a (biased) coin toss. As our main technical contribution, we prove (rigorously) that although remarkably simple, the class of algorithms produced via the DTB compiler includes algorithms with attractive consistency-robustness guarantees for three classic online problems: for caching and uniform metrical task systems our algorithms are optimal, whereas for bipartite matching (with adversarial arrival order), our algorithm outperforms the state-of-the-art.","authors":["Julien Dallot","Yuval Emek","Yuval Gil","Maciej Pacut","Stefan Schmid"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.06868v2","updated":"2026-02-24T09:08:19Z","published":"2025-10-08T10:38:24Z","title":"Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Recovery","summary":"We consider image transmission via deep joint source-channel coding (DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by training a DeepJSCC encoder-decoder pair with a pre-trained deep hash distillation (DHD) module to semantically cluster images, facilitating security-oriented applications through enhanced semantic consistency and improving the perceptual reconstruction quality. We train the DeepJSCC module to both reduce mean square error (MSE) and minimize cosine distance between DHD hashes of source and reconstructed images. Significantly improved perceptual quality as a result of semantic alignment is illustrated for different multi-hop settings, for which classical DeepJSCC may suffer from noise accumulation, measured by the learned perceptual image patch similarity (LPIPS) metric.","authors":["Didrik Bergström","Deniz Gündüz","Onur Günlü"],"pdf_url":"","comment":"Change last word in title, add missing trailing bracket, add additional simulation results in section 4.1; results unchanged"},{"id":"http://arxiv.org/abs/2506.03922v2","updated":"2026-02-24T09:07:33Z","published":"2025-06-04T13:14:13Z","title":"HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models","summary":"Multimodal Large Language Models (MLLMs) have demonstrated significant potential to advance a broad range of domains. However, current benchmarks for evaluating MLLMs primarily emphasize general knowledge and vertical step-by-step reasoning typical of STEM disciplines, while overlooking the distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks in the HSS domain require more horizontal, interdisciplinary thinking and a deep integration of knowledge across related fields, which presents unique challenges for MLLMs, particularly in linking abstract concepts with corresponding visual representations. Addressing this gap, we present HSSBench, a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks in multiple languages, including the six official languages of the United Nations. We also introduce a novel data generation pipeline tailored for HSS scenarios, in which multiple domain experts and automated agents collaborate to generate and iteratively refine each sample. HSSBench contains over 13,000 meticulously designed samples, covering six key categories. We benchmark more than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant challenges even for state-of-the-art models. We hope that this benchmark will inspire further research into enhancing the cross-disciplinary reasoning abilities of MLLMs, especially their capacity to internalize and connect knowledge across fields.","authors":["Zhaolu Kang","Junhao Gong","Jiaxu Yan","Wanke Xia","Yian Wang","Ziwen Wang","Huaxuan Ding","Zhuo Cheng","Wenhao Cao","Zhiyuan Feng","Siqi He","Shannan Yan","Junzhe Chen","Xiaomin He","Chaoya Jiang","Wei Ye","Kaidong Yu","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25424v3","updated":"2026-02-24T09:06:12Z","published":"2025-09-29T19:32:11Z","title":"Polychromic Objectives for Reinforcement Learning","summary":"Reinforcement learning fine-tuning (RLFT) is a dominant paradigm for improving pretrained policies for downstream tasks. These pretrained policies, trained on large datasets, produce generations with a broad range of promising but unrefined behaviors. Often, a critical failure mode of RLFT arises when policies lose this diversity and collapse into a handful of easily exploitable outputs. This convergence hinders exploration, which is essential for expanding the capabilities of the pretrained policy and for amplifying the benefits of test-time compute scaling. To address this, we introduce an objective for policy gradient methods that explicitly enforces the exploration and refinement of diverse generations, which we call a polychromic objective. We then show how proximal policy optimization (PPO) can be adapted to optimize this objective. Our method (1) employs vine sampling to collect on-policy rollouts and (2) modifies the advantage function to reflect the advantage under our new objective. Experiments on BabyAI, Minigrid, and Algorithmic Creativity show that our method improves success rates by reliably solving a larger set of environment configurations and generalizes better under large perturbations. Moreover, when given multiple attempts in pass@$k$ experiments, the policy achieves substantially higher coverage, demonstrating its ability to maintain and exploit a diverse repertoire of strategies.","authors":["Jubayer Ibn Hamid","Ifdita Hasan Orney","Ellen Xu","Chelsea Finn","Dorsa Sadigh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.22620v2","updated":"2026-02-24T09:00:11Z","published":"2025-10-26T10:36:42Z","title":"Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents","summary":"AI agents powered by large language models (LLMs) are being deployed at scale, yet we lack a systematic understanding of how the choice of backbone LLM affects agent security. The non-deterministic sequential nature of AI agents complicates security modeling, while the integration of traditional software with AI components entangles novel LLM vulnerabilities with conventional security risks. Existing frameworks only partially address these challenges as they either capture specific vulnerabilities only or require modeling of complete agents. To address these limitations, we introduce threat snapshots: a framework that isolates specific states in an agent's execution flow where LLM vulnerabilities manifest, enabling the systematic identification and categorization of security risks that propagate from the LLM to the agent level. We apply this framework to construct the $b^3$ benchmark, a security benchmark based on 194,331 unique crowdsourced adversarial attacks. We then evaluate 34 popular LLMs with it, revealing, among other insights, that enhanced reasoning capabilities improve security, while model size does not correlate with security. We release our benchmark, dataset, and evaluation code to facilitate widespread adoption by LLM providers and practitioners, offering guidance for agent developers and incentivizing model developers to prioritize backbone security improvements.","authors":["Julia Bazinska","Max Mathys","Francesco Casucci","Mateo Rojas-Carulla","Xander Davies","Alexandra Souly","Niklas Pfister"],"pdf_url":"","comment":"Julia Bazinska and Max Mathys contributed equally"},{"id":"http://arxiv.org/abs/2602.20696v1","updated":"2026-02-24T08:56:52Z","published":"2026-02-24T08:56:52Z","title":"PromptCD: Test-Time Behavior Enhancement via Polarity-Prompt Contrastive Decoding","summary":"Reliable AI systems require large language models (LLMs) to exhibit behaviors aligned with human preferences and values. However, most existing alignment approaches operate at training time and rely on additional high-quality data, incurring significant computational and annotation costs. While recent work has shown that contrastive decoding can leverage a model's internal distributions to improve specific capabilities, its applicability remains limited to narrow behavioral scopes and scenarios. In this work, we introduce Polarity-Prompt Contrastive Decoding (PromptCD), a test-time behavior control method that generalizes contrastive decoding to broader enhancement settings. PromptCD constructs paired positive and negative guiding prompts for a target behavior and contrasts model responses-specifically token-level probability distributions in LLMs and visual attention patterns in VLMs-to reinforce desirable outcomes. This formulation extends contrastive decoding to a wide range of enhancement objectives and is applicable to both LLMs and Vision-Language Models (VLMs) without additional training. For LLMs, experiments on the \"3H\" alignment objectives (helpfulness, honesty, and harmlessness) demonstrate consistent and substantial improvements, indicating that post-trained models can achieve meaningful self-enhancement purely at test time. For VLMs, we further analyze contrastive effects on visual attention, showing that PromptCD significantly improves VQA performance by reinforcing behavior-consistent visual grounding. Collectively, these results highlight PromptCD as a simple, general, and cost-efficient strategy for reliable behavior control across modalities.","authors":["Baolong Bi","Yuyao Ge","Shenghua Liu","Yuchen He","Siqian Tong","Lizhe Chen","Lingrui Mei","Zehao Li","Yiwei Wang","Yujun Cai","Ming-Hsuan Yang","Xueqi Cheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.14856v2","updated":"2026-02-24T08:54:26Z","published":"2025-06-17T08:15:52Z","title":"Peering into the Unknown: Active View Selection with Neural Uncertainty Maps for 3D Reconstruction","summary":"Some perspectives naturally provide more information than others. How can an AI system determine which viewpoint offers the most valuable insight for accurate and efficient 3D object reconstruction? Active view selection (AVS) for 3D reconstruction remains a fundamental challenge in computer vision. The aim is to identify the minimal set of views that yields the most accurate 3D reconstruction. Instead of learning radiance fields, like NeRF or 3D Gaussian Splatting, from a current observation and computing uncertainty for each candidate viewpoint, we introduce a novel AVS approach guided by neural uncertainty maps predicted by a lightweight feedforward deep neural network, named UPNet. UPNet takes a single input image of a 3D object and outputs a predicted uncertainty map, representing uncertainty values across all possible candidate viewpoints. By leveraging heuristics derived from observing many natural objects and their associated uncertainty patterns, we train UPNet to learn a direct mapping from viewpoint appearance to uncertainty in the underlying volumetric representations. Next, our approach aggregates all previously predicted neural uncertainty maps to suppress redundant candidate viewpoints and effectively select the most informative one. Using these selected viewpoints, we train 3D neural rendering models and evaluate the quality of novel view synthesis against other competitive AVS methods. Remarkably, despite using half of the viewpoints than the upper bound, our method achieves comparable reconstruction accuracy. In addition, it significantly reduces computational overhead during AVS, achieving up to a 400 times speedup along with over 50\\% reductions in CPU, RAM, and GPU usage compared to baseline methods. Notably, our approach generalizes effectively to AVS tasks involving novel object categories, without requiring any additional training.","authors":["Zhengquan Zhang","Feng Xu","Mengmi Zhang"],"pdf_url":"","comment":"10 pages, 4 figures in the main text. Published at ICLR 2026"},{"id":"http://arxiv.org/abs/2504.13961v2","updated":"2026-02-24T08:52:57Z","published":"2025-04-17T01:14:53Z","title":"CONTINA: Confidence Interval for Traffic Demand Prediction with Coverage Guarantee","summary":"Accurate short-term traffic demand prediction is critical for the operation of traffic systems. Besides point estimation, the confidence interval of the prediction is also of great importance. Many models for traffic operations, such as shared bike rebalancing and taxi dispatching, take into account the uncertainty of future demand and require confidence intervals as the input. However, existing methods for confidence interval modeling rely on strict assumptions, such as unchanging traffic patterns and correct model specifications, to guarantee enough coverage. Therefore, the confidence intervals provided could be invalid, especially in a changing traffic environment. To fill this gap, we propose an efficient method, CONTINA (Conformal Traffic Intervals with Adaptation) to provide interval predictions that can adapt to external changes. By collecting the errors of interval during deployment, the method can adjust the interval in the next step by widening it if the errors are too large or shortening it otherwise. Furthermore, we theoretically prove that the coverage of the confidence intervals provided by our method converges to the target coverage level. Experiments across four real-world datasets and prediction models demonstrate that the proposed method can provide valid confidence intervals with shorter lengths. Our method can help traffic management personnel develop a more reasonable and robust operation plan in practice. And we release the code, model and dataset in \\href{ https://github.com/xiannanhuang/CONTINA/}{ Github}.","authors":["Chao Yang","Xiannan Huang","Shuhan Qiu","Yan Cheng"],"pdf_url":"","comment":"Accepted in Transportation Research Part C: Emerging Technologies"},{"id":"http://arxiv.org/abs/2602.17550v2","updated":"2026-02-24T08:43:15Z","published":"2026-02-19T17:05:20Z","title":"MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning","summary":"Existing Reinforcement Learning with Verifiable Rewards (RLVR) algorithms, such as GRPO, rely on rigid, uniform, and symmetric trust region mechanisms that are fundamentally misaligned with the complex optimization dynamics of Large Language Models (LLMs). In this paper, we identify three critical challenges in these methods: (1) inefficient gradient utilization caused by the binary cutoff of hard clipping, (2) insensitive probability mass arising from uniform ratio constraints that ignore the token distribution, and (3) asymmetric signal reliability stemming from the disparate credit assignment ambiguity between positive and negative samples. To bridge these gaps, we propose Mass-Adaptive Soft Policy Optimization (MASPO), a unified framework designed to harmonize these three dimensions. MASPO integrates a differentiable soft Gaussian gating to maximize gradient utility, a mass-adaptive limiter to balance exploration across the probability spectrum, and an asymmetric risk controller to align update magnitudes with signal confidence. Extensive evaluations demonstrate that MASPO serves as a robust, all-in-one RLVR solution, significantly outperforming baselines. Our code is at: \\href{https://github.com/VenomRose-Juri/MASPO-RL}{https://github.com/VenomRose-Juri/MASPO-RL}.","authors":["Xiaoliang Fu","Jiaye Lin","Yangyi Fang","Binbin Zheng","Chaowen Hu","Zekai Shao","Cong Qin","Lu Pan","Ke Zeng","Xunliang Cai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20687v1","updated":"2026-02-24T08:42:41Z","published":"2026-02-24T08:42:41Z","title":"How Foundational Skills Influence VLM-based Embodied Agents:A Native Perspective","summary":"Recent advances in vision-language models (VLMs) have shown promise for human-level embodied intelligence. However, existing benchmarks for VLM-driven embodied agents often rely on high-level commands or discretized action spaces, which are non-native settings that differ markedly from real-world control. In addition, current benchmarks focus primarily on high-level tasks and lack joint evaluation and analysis at both low and high levels. To address these limitations, we present NativeEmbodied, a challenging benchmark for VLM-driven embodied agents that uses a unified, native low-level action space. Built on diverse simulated scenes, NativeEmbodied includes three representative high-level tasks in complex scenarios to evaluate overall performance. For more detailed analysis, we further decouple the skills required by complex tasks and construct four types of low-level tasks, each targeting a fundamental embodied skill. This joint evaluation across task and skill granularities enables fine-grained assessment of embodied agents. Experiments with state-of-the-art VLMs reveal clear deficiencies in several fundamental embodied skills, and further analysis shows that these bottlenecks significantly limit performance on high-level tasks. NativeEmbodied highlights key challenges for current VLM-driven embodied agents and provides insights to guide future research.","authors":["Bo Peng","Pi Bu","Keyu Pan","Xinrun Xu","Yinxiu Zhao","Miao Chen","Yang Du","Lin Li","Jun Song","Tong Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20684v1","updated":"2026-02-24T08:41:05Z","published":"2026-02-24T08:41:05Z","title":"Agile V: A Compliance-Ready Framework for AI-Augmented Engineering -- From Concept to Audit-Ready Delivery","summary":"Current AI-assisted engineering workflows lack a built-in mechanism to maintain task-level verification and regulatory traceability at machine-speed delivery. Agile V addresses this gap by embedding independent verification and audit artifact generation into each task cycle. The framework merges Agile iteration with V-Model verification into a continuous Infinity Loop, deploying specialized AI agents for requirements, design, build, test, and compliance, governed by mandatory human approval gates. We evaluate three hypotheses: (H1) audit-ready artifacts emerge as a by-product of development, (H2) 100% requirement-level verification is achievable with independent test generation, and (H3) verified increments can be delivered with single-digit human interactions per cycle. A feasibility case study on a Hardware-in-the-Loop system (about 500 LOC, 8 requirements, 54 tests) supports all three hypotheses: audit-ready documentation was generated automatically (H1), 100% requirement-level pass rate was achieved (H2), and only 6 prompts per cycle were required (H3), yielding an estimated 10-50x cost reduction versus a COCOMO II baseline (sensitivity range from pessimistic to optimistic assumptions). We invite independent replication to validate generalizability.","authors":["Christopher Koch","Joshua Andreas Wellbrock"],"pdf_url":"","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.20677v1","updated":"2026-02-24T08:26:46Z","published":"2026-02-24T08:26:46Z","title":"UrbanFM: Scaling Urban Spatio-Temporal Foundation Models","summary":"Urban systems, as dynamic complex systems, continuously generate spatio-temporal data streams that encode the fundamental laws of human mobility and city evolution. While AI for Science has witnessed the transformative power of foundation models in disciplines like genomics and meteorology, urban computing remains fragmented due to \"scenario-specific\" models, which are overfitted to specific regions or tasks, hindering their generalizability. To bridge this gap and advance spatio-temporal foundation models for urban systems, we adopt scaling as the central perspective and systematically investigate two key questions: what to scale and how to scale. Grounded in first-principles analysis, we identify three critical dimensions: heterogeneity, correlation, and dynamics, aligning these principles with the fundamental scientific properties of urban spatio-temporal data. Specifically, to address heterogeneity through data scaling, we construct WorldST. This billion-scale corpus standardizes diverse physical signals, such as traffic flow and speed, from over 100 global cities into a unified data format. To enable computation scaling for modeling correlations, we introduce the MiniST unit, a novel split mechanism that discretizes continuous spatio-temporal fields into learnable computational units to unify representations of grid-based and sensor-based observations. Finally, addressing dynamics via architecture scaling, we propose UrbanFM, a minimalist self-attention architecture designed with limited inductive biases to autonomously learn dynamic spatio-temporal dependencies from massive data. Furthermore, we establish EvalST, the largest-scale urban spatio-temporal benchmark to date. Extensive experiments demonstrate that UrbanFM achieves remarkable zero-shot generalization across unseen cities and tasks, marking a pivotal first step toward large-scale urban spatio-temporal foundation models.","authors":["Wei Chen","Yuqian Wu","Junle Chen","Xiaofang Zhou","Yuxuan Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20676v1","updated":"2026-02-24T08:26:17Z","published":"2026-02-24T08:26:17Z","title":"PRECTR-V2:Unified Relevance-CTR Framework with Cross-User Preference Mining, Exposure Bias Correction, and LLM-Distilled Encoder Optimization","summary":"In search systems, effectively coordinating the two core objectives of search relevance matching and click-through rate (CTR) prediction is crucial for discovering users' interests and enhancing platform revenue. In our prior work PRECTR, we proposed a unified framework to integrate these two subtasks,thereby eliminating their inconsistency and leading to mutual benefit.However, our previous work still faces three main challenges. First, low-active users and new users have limited search behavioral data, making it difficult to achieve effective personalized relevance preference modeling. Second, training data for ranking models predominantly come from high-relevance exposures, creating a distribution mismatch with the broader candidate space in coarse-ranking, leading to generalization bias. Third, due to the latency constraint, the original model employs an Emb+MLP architecture with a frozen BERT encoder, which prevents joint optimization and creates misalignment between representation learning and CTR fine-tuning. To solve these issues, we further reinforce our method and propose PRECTR-V2. Specifically, we mitigate the low-activity users' sparse behavior problem by mining global relevance preferences under the specific query, which facilitates effective personalized relevance modeling for cold-start scenarios. Subsequently, we construct hard negative samples through embedding noise injection and relevance label reconstruction, and optimize their relative ranking against positive samples via pairwise loss, thereby correcting exposure bias. Finally, we pretrain a lightweight transformer-based encoder via knowledge distillation from LLM and SFT on the text relevance classification task. This encoder replaces the frozen BERT module, enabling better adaptation to CTR fine-tuning and advancing beyond the traditional Emb+MLP paradigm.","authors":["Shuzhi Cao","Rong Chen","Ailong He","Shuguang Han","Jufeng Chen"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2503.18395"},{"id":"http://arxiv.org/abs/2509.21825v4","updated":"2026-02-24T08:22:41Z","published":"2025-09-26T03:38:12Z","title":"DS-STAR: Data Science Agent for Solving Diverse Tasks across Heterogeneous Formats and Open-Ended Queries","summary":"While large language models (LLMs) have shown promise in automating data science, existing agents often struggle with the complexity of real-world workflows that require exploring multiple sources and synthesizing open-ended insights. In this paper, we introduce DS-STAR, a specialized agent to bridge this gap. Unlike prior approaches, DS-STAR is designed to (1) seamlessly process and integrate data across diverse, heterogeneous formats, and (2) move beyond simple QA to generate comprehensive research reports for open-ended queries. Extensive evaluation shows that DS-STAR achieves state-of-the-art performance on four benchmarks: DABStep, DABStep-Research, KramaBench, and DA-Code. Most notably, it significantly outperforms existing baseline models especially in hard-level QA tasks requiring multi-file processing, and generates high-quality data science reports that are preferred over the best baseline model in over 88% of cases.","authors":["Jaehyun Nam","Jinsung Yoon","Jiefeng Chen","Raj Sinha","Jinwoo Shin","Tomas Pfister"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20670v1","updated":"2026-02-24T08:20:08Z","published":"2026-02-24T08:20:08Z","title":"CAMEL: Confidence-Gated Reflection for Reward Modeling","summary":"Reward models play a fundamental role in aligning large language models with human preferences. Existing methods predominantly follow two paradigms: scalar discriminative preference models, which are efficient but lack interpretability, and generative judging models, which offer richer reasoning at the cost of higher computational overhead. We observe that the log-probability margin between verdict tokens strongly correlates with prediction correctness, providing a reliable proxy for instance difficulty without additional inference cost. Building on this insight, we propose CAMEL, a confidence-gated reflection framework that performs a lightweight single-token preference decision first and selectively invokes reflection only for low-confidence instances. To induce effective self-correction, we train the model via reinforcement learning with counterfactual prefix augmentation, which exposes the model to diverse initial verdicts and encourages genuine revision. Empirically, CAMEL achieves state-of-the-art performance on three widely used reward-model benchmarks with 82.9% average accuracy, surpassing the best prior model by 3.2% and outperforming 70B-parameter models using only 14B parameters, while establishing a strictly better accuracy-efficiency Pareto frontier.","authors":["Zirui Zhu","Hailun Xu","Yang Luo","Yong Liu","Kanchan Sarkar","Kun Xu","Yang You"],"pdf_url":"","comment":"Preprint. 13 pages"},{"id":"http://arxiv.org/abs/2502.01310v4","updated":"2026-02-24T08:13:38Z","published":"2025-02-03T12:37:20Z","title":"A Statistical Learning Perspective on Semi-dual Adversarial Neural Optimal Transport Solvers","summary":"Neural network-based optimal transport (OT) is a recent and fruitful direction in the generative modeling community. It finds its applications in various fields such as domain translation, image super-resolution, computational biology and others. Among the existing OT approaches, of considerable interest are adversarial minimax solvers based on semi-dual formulations of OT problems. While promising, these methods lack theoretical investigation from a statistical learning perspective. Our work fills this gap by establishing upper bounds on the generalization error of an approximate OT map recovered by the minimax quadratic OT solver. Importantly, the bounds we derive depend solely on some standard statistical and mathematical properties of the considered functional classes (neural nets). While our analysis focuses on the quadratic OT, we believe that similar bounds could be derived for general OT case, paving the promising direction for future research. Our experimental illustrations are available online https://github.com/milenagazdieva/StatOT.","authors":["Roman Tarasov","Petr Mokrov","Milena Gazdieva","Evgeny Burnaev","Alexander Korotin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.07172v3","updated":"2026-02-24T08:11:36Z","published":"2025-10-08T16:12:11Z","title":"NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents","summary":"Large language models are emerging as powerful tools for scientific law discovery, a foundational challenge in AI-driven science. However, existing benchmarks for this task suffer from a fundamental methodological trilemma, forcing a trade-off between scientific relevance, scalability, and resistance to memorization. Furthermore, they oversimplify discovery as static function fitting, failing to capture the authentic scientific process of uncovering embedded laws through the interactive exploration of complex model systems. To address these critical gaps, we introduce NewtonBench, a benchmark comprising 324 scientific law discovery tasks across 12 physics domains. Our design mitigates the evaluation trilemma by using counterfactual law shifts - systematic alterations of canonical laws - to generate a vast suite of problems that are scalable, scientifically relevant, and memorization-resistant. Moreover, we elevate the evaluation from static function fitting to interactive model discovery, requiring agents to experimentally probe simulated complex systems to uncover hidden principles. Our extensive experiment reveals a clear but fragile capability for discovery in frontier LLMs: this ability degrades precipitously with increasing system complexity and exhibits extreme sensitivity to observational noise. Notably, we uncover a paradoxical effect of tool assistance: providing a code interpreter can hinder more capable models by inducing a premature shift from exploration to exploitation, causing them to satisfice on suboptimal solutions. These results demonstrate that robust, generalizable discovery in complex, interactive environments remains the core challenge. By providing a scalable, robust, and scientifically authentic testbed, NewtonBench offers a crucial tool for measuring true progress and guiding the development of next-generation AI agents capable of genuine scientific discovery.","authors":["Tianshi Zheng","Kelvin Kiu-Wai Tam","Newt Hue-Nam K. Nguyen","Baixuan Xu","Zhaowei Wang","Jiayang Cheng","Hong Ting Tsang","Weiqi Wang","Jiaxin Bai","Tianqing Fang","Yangqiu Song","Ginny Y. Wong","Simon See"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.20659v1","updated":"2026-02-24T08:02:16Z","published":"2026-02-24T08:02:16Z","title":"Recursive Belief Vision Language Model","summary":"Current vision-language-action (VLA) models struggle with long-horizon manipulation under partial observability. Most existing approaches remain observation-driven, relying on short context windows or repeated queries to vision-language models (VLMs). This leads to loss of task progress, action repetition under perceptual aliasing, and high inference latency. Semantic reasoning alone is not the primary bottleneck in long-horizon manipulation. Instead, VLAs lack persistent, action-conditioned state representations and exhibit limited temporal and physical reasoning, making them ill-suited for multi-stage control. This paper introduces RB-VLA, a belief-centric architecture trained with self-supervised world-model objectives that maintains a compact latent state encoding task-relevant history, dynamics, and object interactions. Queried once for high-level intent, the VLM provides task specification, while the belief tracks task progress and enables phase-aware, causally grounded control under partial observability without storing raw observations or scaling memory with time. The belief and intent jointly condition a diffusion policy for robust closed-loop execution. RB-VLA outperforms prior VLAs on long-horizon benchmarks, achieving 52.5% and 37.5% higher success on multi-stage pick-and-place and stacking tasks, respectively, compared to π0. It also reduces inference latency by up to 5x relative to baselines and eliminates memory growth across timesteps observed in existing VLAs. Ablations show that the belief module is the primary driver of performance, increasing success rates from 32.5% to 77.5%. These results demonstrate the effectiveness of belief-based state representations for long-horizon VLA policies.","authors":["Vaidehi Bagaria","Bijo Sebastian","Nirav Patel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20658v1","updated":"2026-02-24T08:01:49Z","published":"2026-02-24T08:01:49Z","title":"Vision-Language Models for Ergonomic Assessment of Manual Lifting Tasks: Estimating Horizontal and Vertical Hand Distances from RGB Video","summary":"Manual lifting tasks are a major contributor to work-related musculoskeletal disorders, and effective ergonomic risk assessment is essential for quantifying physical exposure and informing ergonomic interventions. The Revised NIOSH Lifting Equation (RNLE) is a widely used ergonomic risk assessment tool for lifting tasks that relies on six task variables, including horizontal (H) and vertical (V) hand distances; such distances are typically obtained through manual measurement or specialized sensing systems and are difficult to use in real-world environments. We evaluated the feasibility of using innovative vision-language models (VLMs) to non-invasively estimate H and V from RGB video streams. Two multi-stage VLM-based pipelines were developed: a text-guided detection-only pipeline and a detection-plus-segmentation pipeline. Both pipelines used text-guided localization of task-relevant regions of interest, visual feature extraction from those regions, and transformer-based temporal regression to estimate H and V at the start and end of a lift. For a range of lifting tasks, estimation performance was evaluated using leave-one-subject-out validation across the two pipelines and seven camera view conditions. Results varied significantly across pipelines and camera view conditions, with the segmentation-based, multi-view pipeline consistently yielding the smallest errors, achieving mean absolute errors of approximately 6-8 cm when estimating H and 5-8 cm when estimating V. Across pipelines and camera view configurations, pixel-level segmentation reduced estimation error by approximately 20-30% for H and 35-40% for V relative to the detection-only pipeline. These findings support the feasibility of VLM-based pipelines for video-based estimation of RNLE distance parameters.","authors":["Mohammad Sadra Rajabi","Aanuoluwapo Ojelade","Sunwook Kim","Maury A. Nussbaum"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20650v1","updated":"2026-02-24T07:53:58Z","published":"2026-02-24T07:53:58Z","title":"Dataset Color Quantization: A Training-Oriented Framework for Dataset-Level Compression","summary":"Large-scale image datasets are fundamental to deep learning, but their high storage demands pose challenges for deployment in resource-constrained environments. While existing approaches reduce dataset size by discarding samples, they often ignore the significant redundancy within each image -- particularly in the color space. To address this, we propose Dataset Color Quantization (DCQ), a unified framework that compresses visual datasets by reducing color-space redundancy while preserving information crucial for model training. DCQ achieves this by enforcing consistent palette representations across similar images, selectively retaining semantically important colors guided by model perception, and maintaining structural details necessary for effective feature learning. Extensive experiments across CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet-1K show that DCQ significantly improves training performance under aggressive compression, offering a scalable and robust solution for dataset-level storage reduction. Code is available at \\href{https://github.com/he-y/Dataset-Color-Quantization}{https://github.com/he-y/Dataset-Color-Quantization}.","authors":["Chenyue Yu","Lingao Xiao","Jinhong Deng","Ivor W. Tsang","Yang He"],"pdf_url":"","comment":"Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2602.20643v1","updated":"2026-02-24T07:44:19Z","published":"2026-02-24T07:44:19Z","title":"TrajGPT-R: Generating Urban Mobility Trajectory with Reinforcement Learning-Enhanced Generative Pre-trained Transformer","summary":"Mobility trajectories are essential for understanding urban dynamics and enhancing urban planning, yet access to such data is frequently hindered by privacy concerns. This research introduces a transformative framework for generating large-scale urban mobility trajectories, employing a novel application of a transformer-based model pre-trained and fine-tuned through a two-phase process. Initially, trajectory generation is conceptualized as an offline reinforcement learning (RL) problem, with a significant reduction in vocabulary space achieved during tokenization. The integration of Inverse Reinforcement Learning (IRL) allows for the capture of trajectory-wise reward signals, leveraging historical data to infer individual mobility preferences. Subsequently, the pre-trained model is fine-tuned using the constructed reward model, effectively addressing the challenges inherent in traditional RL-based autoregressive methods, such as long-term credit assignment and handling of sparse reward environments. Comprehensive evaluations on multiple datasets illustrate that our framework markedly surpasses existing models in terms of reliability and diversity. Our findings not only advance the field of urban mobility modeling but also provide a robust methodology for simulating urban data, with significant implications for traffic management and urban development planning. The implementation is publicly available at https://github.com/Wangjw6/TrajGPT_R.","authors":["Jiawei Wang","Chuang Yang","Jiawei Yong","Xiaohang Xu","Hongjun Wang","Noboru Koshizuka","Shintaro Fukushima","Ryosuke Shibasaki","Renhe Jiang"],"pdf_url":"","comment":"TrajGPT-R is a Reinforcement Learning-Enhanced Generative Pre-trained Transformer for Mobility Trajectory Generation"},{"id":"http://arxiv.org/abs/2507.05306v3","updated":"2026-02-24T07:43:54Z","published":"2025-07-07T08:18:25Z","title":"Enjoying Non-linearity in Multinomial Logistic Bandits: A Minimax-Optimal Algorithm","summary":"We consider the multinomial logistic bandit problem in which a learner interacts with an environment by selecting actions to maximize expected rewards based on probabilistic feedback from multiple possible outcomes. In the binary setting, recent work has focused on understanding the impact of the non-linearity of the logistic model (Faury et al., 2020; Abeille et al., 2021). They introduced a problem-dependent constant $κ_* \\geq 1$ that may be exponentially large in some problem parameters and which is captured by the derivative of the sigmoid function. It encapsulates the non-linearity and improves existing regret guarantees over $T$ rounds from $\\smash{O(d\\sqrt{T})}$ to $\\smash{O(d\\sqrt{T/κ_*})}$, where $d$ is the dimension of the parameter space. We extend their analysis to the multinomial logistic bandit framework with a finite action space, making it suitable for complex applications with more than two choices, such as reinforcement learning or recommender systems. To achieve this, we extend the definition of $ κ_* $ to the multinomial setting and propose an efficient algorithm that leverages the problem's non-linearity. Our method yields a problem-dependent regret bound of order $ \\smash{\\widetilde{\\mathcal{O}}( R d \\sqrt{ {KT}/{κ_*}} ) } $, where $R$ denotes the norm of the vector of rewards and $K$ is the number of outcomes. This improves upon the best existing guarantees of order $ \\smash{\\widetilde{\\mathcal{O}}( RdK \\sqrt{T} )}$. Moreover, we provide a matching $\\smash{ Ω(dR\\sqrt{KT/κ_*})}$ lower-bound, showing that our algorithm is minimax-optimal and that our definition of $κ_*$ is optimal.","authors":["Pierre Boudart","Pierre Gaillard","Alessandro Rudi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14462v2","updated":"2026-02-24T07:43:16Z","published":"2026-02-16T04:42:30Z","title":"Silent Inconsistency in Data-Parallel Full Fine-Tuning: Diagnosing Worker-Level Optimization Misalignment","summary":"Data-parallel (DP) training with synchronous all-reduce is a dominant paradigm for full-parameter fine-tuning of large language models (LLMs). While parameter synchronization guarantees numerical equivalence of model weights after each iteration, it does not necessarily imply alignment of worker-level optimization dynamics before gradient aggregation. This paper identifies and studies this latent mismatch, termed \\emph{silent inconsistency}, where cross-worker divergence in losses and gradients can remain invisible under conventional aggregated monitoring signals. We propose a lightweight, model-agnostic diagnostic framework that quantifies worker-level consistency using training signals readily available in standard pipelines. Specifically, we introduce three complementary metrics: loss dispersion, gradient-norm dispersion, and gradient-direction consistency measured by inter-worker cosine similarity. The proposed metrics incur negligible overhead and require no modification to model architecture, synchronization mechanisms, or optimization algorithms. We validate the framework by fully fine-tuning the 1B-parameter \\texttt{openPangu-Embedded-1B-V1.1} model on the \\texttt{tatsu-lab/alpaca} dataset using an 8-NPU DP setup, under controlled perturbations of cross-rank stochasticity. Experimental results show that progressively desynchronized data shuffling and random seeds lead to substantial increases in loss/gradient dispersion and reduced directional alignment, despite smooth globally averaged loss curves. These findings demonstrate that the proposed indicators provide actionable visibility into hidden instability modes in large-scale DP fine-tuning, enabling more reliable diagnosis and configuration assessment.","authors":["Hong Li","Zhen Zhou","Honggang Zhang","Yuping Luo","Xinyue Wang","Han Gong","Zhiyuan Liu"],"pdf_url":"","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.20639v1","updated":"2026-02-24T07:37:18Z","published":"2026-02-24T07:37:18Z","title":"Grounding LLMs in Scientific Discovery via Embodied Actions","summary":"Large Language Models (LLMs) have shown significant potential in scientific discovery but struggle to bridge the gap between theoretical reasoning and verifiable physical simulation. Existing solutions operate in a passive \"execute-then-response\" loop and thus lacks runtime perception, obscuring agents to transient anomalies (e.g., numerical instability or diverging oscillations). To address this limitation, we propose EmbodiedAct, a framework that transforms established scientific software into active embodied agents by grounding LLMs in embodied actions with a tight perception-execution loop. We instantiate EmbodiedAct within MATLAB and evaluate it on complex engineering design and scientific modeling tasks. Extensive experiments show that EmbodiedAct significantly outperforms existing baselines, achieving SOTA performance by ensuring satisfactory reliability and stability in long-horizon simulations and enhanced accuracy in scientific modeling.","authors":["Bo Zhang","Jinfeng Zhou","Yuxuan Chen","Jianing Yin","Minlie Huang","Hongning Wang"],"pdf_url":"","comment":"24 pages, 7 figures, 7 tables. Preprint"},{"id":"http://arxiv.org/abs/2602.20638v1","updated":"2026-02-24T07:37:02Z","published":"2026-02-24T07:37:02Z","title":"Identifying two piecewise linear additive value functions from anonymous preference information","summary":"Eliciting a preference model involves asking a person, named decision-maker, a series of questions. We assume that these preferences can be represented by an additive value function. In this work, we query simultaneously two decision-makers in the aim to elicit their respective value functions. For each query we receive two answers, without noise, but without knowing which answer corresponds to which decision-maker.We propose an elicitation procedure that identifies the two preference models when the marginal value functions are piecewise linear with known breaking points.","authors":["Vincent Auriau","Khaled Belahcene","Emmanuel Malherbe","Vincent Mousseau","Marc Pirlot"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20636v1","updated":"2026-02-24T07:30:51Z","published":"2026-02-24T07:30:51Z","title":"SurgAtt-Tracker: Online Surgical Attention Tracking via Temporal Proposal Reranking and Motion-Aware Refinement","summary":"Accurate and stable field-of-view (FoV) guidance is critical for safe and efficient minimally invasive surgery, yet existing approaches often conflate visual attention estimation with downstream camera control or rely on direct object-centric assumptions. In this work, we formulate surgical attention tracking as a spatio-temporal learning problem and model surgeon focus as a dense attention heatmap, enabling continuous and interpretable frame-wise FoV guidance. We propose SurgAtt-Tracker, a holistic framework that robustly tracks surgical attention by exploiting temporal coherence through proposal-level reranking and motion-aware refinement, rather than direct regression. To support systematic training and evaluation, we introduce SurgAtt-1.16M, a large-scale benchmark with a clinically grounded annotation protocol that enables comprehensive heatmap-based attention analysis across procedures and institutions. Extensive experiments on multiple surgical datasets demonstrate that SurgAtt-Tracker consistently achieves state-of-the-art performance and strong robustness under occlusion, multi-instrument interference, and cross-domain settings. Beyond attention tracking, our approach provides a frame-wise FoV guidance signal that can directly support downstream robotic FoV planning and automatic camera control.","authors":["Rulin Zhou","Guankun Wang","An Wang","Yujie Ma","Lixin Ouyang","Bolin Cui","Junyan Li","Chaowei Zhu","Mingyang Li","Ming Chen","Xiaopin Zhong","Peng Lu","Jiankun Wang","Xianming Liu","Hongliang Ren"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20634v1","updated":"2026-02-24T07:26:17Z","published":"2026-02-24T07:26:17Z","title":"Enhancing Hate Speech Detection on Social Media: A Comparative Analysis of Machine Learning Models and Text Transformation Approaches","summary":"The proliferation of hate speech on social media platforms has necessitated the development of effective detection and moderation tools. This study evaluates the efficacy of various machine learning models in identifying hate speech and offensive language and investigates the potential of text transformation techniques to neutralize such content. We compare traditional models like CNNs and LSTMs with advanced neural network models such as BERT and its derivatives, alongside exploring hybrid models that combine different architectural features. Our results indicate that while advanced models like BERT show superior accuracy due to their deep contextual understanding, hybrid models exhibit improved capabilities in certain scenarios. Furthermore, we introduce innovative text transformation approaches that convert negative expressions into neutral ones, thereby potentially mitigating the impact of harmful content. The implications of these findings are discussed, highlighting the strengths and limitations of current technologies and proposing future directions for more robust hate speech detection systems.","authors":["Saurabh Mishra","Shivani Thakur","Radhika Mamidi"],"pdf_url":"","comment":"32 pages, 24 figures"},{"id":"http://arxiv.org/abs/2602.20628v1","updated":"2026-02-24T07:23:21Z","published":"2026-02-24T07:23:21Z","title":"When can we trust untrusted monitoring? A safety case sketch across collusion strategies","summary":"AIs are increasingly being deployed with greater autonomy and capabilities, which increases the risk that a misaligned AI may be able to cause catastrophic harm. Untrusted monitoring -- using one untrusted model to oversee another -- is one approach to reducing risk. Justifying the safety of an untrusted monitoring deployment is challenging because developers cannot safely deploy a misaligned model to test their protocol directly. In this paper, we develop upon existing methods for rigorously demonstrating safety based on pre-deployment testing. We relax assumptions that previous AI control research made about the collusion strategies a misaligned AI might use to subvert untrusted monitoring. We develop a taxonomy covering passive self-recognition, causal collusion (hiding pre-shared signals), acausal collusion (hiding signals via Schelling points), and combined strategies. We create a safety case sketch to clearly present our argument, explicitly state our assumptions, and highlight unsolved challenges. We identify conditions under which passive self-recognition could be a more effective collusion strategy than those studied previously. Our work builds towards more robust evaluations of untrusted monitoring.","authors":["Nelson Gardner-Challis","Jonathan Bostock","Georgiy Kozhevnikov","Morgan Sinclaire","Joan Velja","Alessandro Abate","Charlie Griffin"],"pdf_url":"","comment":"66 pages, 14 figures, Preprint"},{"id":"http://arxiv.org/abs/2510.00037v4","updated":"2026-02-24T07:21:12Z","published":"2025-09-26T14:42:23Z","title":"On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations","summary":"In Vision-Language-Actionf(VLA) models, robustness to real-world perturbations is critical for deployment. Existing methods target simple visual disturbances, overlooking the broader multi-modal perturbations that arise in actions, instructions, environments, and observations. Here, we first evaluate the robustness of mainstream VLAs under 17 perturbations across four modalities. We find (1) actions as the most fragile modality, (2) Existing visual-robust VLA do not gain robustness in other modality, and (3) pi0 demonstrates superior robustness. To build multi-modal robust VLAs, we propose RobustVLA against perturbations in VLA inputs and outputs. For output robustness, we perform offline robust optimization against worst-case action noise that maximizes mismatch in flow matching objective. This can be seen as adversarial training, label smoothing, and outlier penalization. For input robustness, we enforce consistent actions across input variations that preserve task semantics. To account for multiple perturbations, we formulate robustness as a multi-armed bandit problem and apply an upper confidence bound algorithm to automatically identify the most harmful noise. Experiments on LIBERO demonstrate our RobustVLA delivers absolute gains over baselines of 12.6% on the pi0 backbone and 10.4% on the OpenVLA backbone across all 17 perturbations, achieving 50.6x faster inference than existing visual-robust BYOVLA that requires external LLMs, and a 10.4% gain under mixed perturbations. On the real-world FR5 robot, under four types of multimodal perturbations, RobustVLA shows strong low-data performance, outperforming pi0 by 65.6% success rate with 25 demonstrations. Even with abundant demos, our method still outperform pi0 by 30% success rate. Code and demo videos available at https://github.com/gakakulicc/RobustVLA.","authors":["Jianing Guo","Zhenhong Wu","Chang Tu","Yiyao Ma","Xiangqi Kong","Zhiqian Liu","Jiaming Ji","Shuning Zhang","Yuanpei Chen","Kai Chen","Qi Dou","Yaodong Yang","Xianglong Liu","Huijie Zhao","Weifeng Lv","Simin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20624v1","updated":"2026-02-24T07:21:08Z","published":"2026-02-24T07:21:08Z","title":"Physics-based phenomenological characterization of cross-modal bias in multimodal models","summary":"The term 'algorithmic fairness' is used to evaluate whether AI models operate fairly in both comparative (where fairness is understood as formal equality, such as \"treat like cases as like\") and non-comparative (where unfairness arises from the model's inaccuracy, arbitrariness, or inscrutability) contexts. Recent advances in multimodal large language models (MLLMs) are breaking new ground in multimodal understanding, reasoning, and generation; however, we argue that inconspicuous distortions arising from complex multimodal interaction dynamics can lead to systematic bias. The purpose of this position paper is twofold: first, it is intended to acquaint AI researchers with phenomenological explainable approaches that rely on the physical entities that the machine experiences during training/inference, as opposed to the traditional cognitivist symbolic account or metaphysical approaches; second, it is to state that this phenomenological doctrine will be practically useful for tackling algorithmic fairness issues in MLLMs. We develop a surrogate physics-based model that describes transformer dynamics (i.e., semantic network structure and self-/cross-attention) to analyze the dynamics of cross-modal bias in MLLM, which are not fully captured by conventional embedding- or representation-level analyses. We support this position through multi-input diagnostic experiments: 1) perturbation-based analyses of emotion classification using Qwen2.5-Omni and Gemma 3n, and 2) dynamical analysis of Lorenz chaotic time-series prediction through the physical surrogate. Across two architecturally distinct MLLMs, we show that multimodal inputs can reinforce modality dominance rather than mitigate it, as revealed by structured error-attractor patterns under systematic label perturbation, complemented by dynamical analysis.","authors":["Hyeongmo Kim","Sohyun Kang","Yerin Choi","Seungyeon Ji","Junhyuk Woo","Hyunsuk Chung","Soyeon Caren Han","Kyungreem Han"],"pdf_url":"","comment":"Best Paper Award at BiasinAI track in AAAI2026"},{"id":"http://arxiv.org/abs/2505.17645v2","updated":"2026-02-24T07:02:26Z","published":"2025-05-23T09:06:09Z","title":"HoloLLM: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning","summary":"Embodied agents operating in smart homes must understand human behavior through diverse sensory inputs and communicate via natural language. While Vision-Language Models (VLMs) have enabled impressive language-grounded perception, their reliance on visual data limits robustness in real-world scenarios with occlusions, poor lighting, or privacy constraints. In this paper, we introduce HoloLLM, a Multimodal Large Language Model (MLLM) that integrates uncommon but powerful sensing modalities, such as LiDAR, infrared, mmWave radar, and WiFi, to enable seamless human perception and reasoning across heterogeneous environments. We address two key challenges: (1) the scarcity of aligned modality-text data for rare sensors, and (2) the heterogeneity of their physical signal representations. To overcome these, we design a Universal Modality-Injection Projector (UMIP) that enhances pre-aligned modality embeddings with fine-grained, text-aligned features from tailored encoders via coarse-to-fine cross-attention without introducing significant alignment overhead. We further introduce a human-VLM collaborative data curation pipeline to generate paired textual annotations for sensing datasets. Extensive experiments on two newly constructed benchmarks show that HoloLLM significantly outperforms existing MLLMs, improving language-grounded human sensing accuracy by up to 30%. This work establishes a new foundation for real-world, language-informed multisensory embodied intelligence.","authors":["Chuhao Zhou","Jianfei Yang"],"pdf_url":"","comment":"Camera-ready version. Accepted at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2602.19654v2","updated":"2026-02-24T06:53:31Z","published":"2026-02-23T09:56:22Z","title":"NEXUS: A compact neural architecture for high-resolution spatiotemporal air quality forecasting in Delhi National Capital Region","summary":"Urban air pollution in megacities poses critical public health challenges, particularly in Delhi National Capital Region (NCR) where severe degradation affects millions. We present NEXUS (Neural Extraction and Unified Spatiotemporal) architecture for forecasting carbon monoxide, nitrogen oxide, and sulfur dioxide. Working with four years (2018--2021) of atmospheric data across sixteen spatial grids, NEXUS achieves R$^2$ exceeding 0.94 for CO, 0.91 for NO, and 0.95 for SO$_2$ using merely 18,748 parameters -- substantially fewer than SCINet (35,552), Autoformer (68,704), and FEDformer (298,080). The architecture integrates patch embedding, low-rank projections, and adaptive fusion mechanisms to decode complex atmospheric chemistry patterns. Our investigation uncovers distinct diurnal rhythms and pronounced seasonal variations, with winter months experiencing severe pollution episodes driven by temperature inversions and agricultural biomass burning. Analysis identifies critical meteorological thresholds, quantifies wind field impacts on pollutant dispersion, and maps spatial heterogeneity across the region. Extensive ablation experiments demonstrate each architectural component's role. NEXUS delivers superior predictive performance with remarkable computational efficiency, enabling real-time deployment for air quality monitoring systems.","authors":["Rampunit Kumar","Aditya Maheshwari"],"pdf_url":"","comment":"18 pages"},{"id":"http://arxiv.org/abs/2505.19698v3","updated":"2026-02-24T06:45:28Z","published":"2025-05-26T08:52:45Z","title":"Performance Asymmetry in Model-Based Reinforcement Learning","summary":"Recently, Model-Based Reinforcement Learning (MBRL) have achieved super-human level performance on the Atari100k benchmark on average. However, we discover that conventional aggregates mask a major problem, Performance Asymmetry: MBRL agents dramatically outperform humans in certain tasks (Agent-Optimal tasks) while drastically underperform humans in other tasks (Human-Optimal tasks). Indeed, despite achieving SOTA in the overall mean Human-Normalized Scores (HNS), the SOTA agent scored the worst among baselines on Human-Optimal tasks, with a striking 21X performance gap between the Human-Optimal and Agent-Optimal subsets. To address this, we partition Atari100k evenly into Human-Optimal and Agent-Optimal subsets, and introduce a more balanced aggregate, Sym-HNS. Furthermore, we trace the striking Performance Asymmetry in the SOTA pixel diffusion world model to the curse of dimensionality and its prowess on high visual detail tasks (e.g. Breakout). To this end, we propose a novel latent end-to-end Joint Embedding DIffusion (JEDI) world model that achieves SOTA results in Sym-HNS, Human-Optimal tasks, and Breakout -- thus reversing the worsening Performance Asymmetry trend while improving computational efficiency and remaining competitive on the full Atari100k.","authors":["Jing Yu Lim","Rushi Shah","Zarif Ikram","Samson Yu","Haozhe Ma","Tze-Yun Leong","Dianbo Liu"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2602.20595v1","updated":"2026-02-24T06:35:22Z","published":"2026-02-24T06:35:22Z","title":"OptiLeak: Efficient Prompt Reconstruction via Reinforcement Learning in Multi-tenant LLM Services","summary":"Multi-tenant LLM serving frameworks widely adopt shared Key-Value caches to enhance efficiency. However, this creates side-channel vulnerabilities enabling prompt leakage attacks. Prior studies identified these attack surfaces yet focused on expanding attack vectors rather than optimizing attack performance, reporting impractically high attack costs that underestimate the true privacy risk. We propose OptiLeak, a reinforcement learning-enhanced framework that maximizes prompt reconstruction efficiency through two-stage fine-tuning. Our key insight is that domain-specific ``hard tokens'' -- terms difficult to predict yet carrying sensitive information -- can be automatically identified via likelihood ranking and used to construct preference pairs for Direct Preference Optimization, eliminating manual annotation. This enables effective preference alignment while avoiding the overfitting issues of extended supervised fine-tuning. Evaluated on three benchmarks spanning medical and financial domains, OptiLeak achieves up to $12.48\\times$ reduction in average requests per token compared to baseline approaches, with consistent improvements across model scales from 3B to 14B parameters. Our findings demonstrate that cache-based prompt leakage poses a more severe threat than previously reported, underscoring the need for robust cache isolation in production deployments.","authors":["Longxiang Wang","Xiang Zheng","Xuhao Zhang","Yao Zhang","Ye Wu","Cong Wang"],"pdf_url":"","comment":null}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2602.20979v1","updated":"2026-02-24T15:01:29Z","published":"2026-02-24T15:01:29Z","title":"Toward an Agentic Infused Software Ecosystem","summary":"Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the AI agents themselves, which in the past 5 years have moved from simple code completion and toward sophisticated independent development tasks, a trend which will only continue. The second pillar is the programming language and APIs (or tools) that these agents use to accomplish tasks, and increasingly, serve as the communication substrate that humans and AI agents interact and collaborate through. The final pillar is the runtime environment and ecosystem that agents operate within, and which provide the capabilities that programmatic agents use to interface with (and effect actions in) the external world. To realize the vision of AISE, all three pillars must be advanced in a holistic manner, and critically, in a manner that is synergistic for AI agents as they exist today, those that will exist in the future, and for the human developers that work alongside them.","authors":["Mark Marron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20866v1","updated":"2026-02-24T13:10:51Z","published":"2026-02-24T13:10:51Z","title":"DeCo: A Core Calculus for Incremental Functional Programming with Generic Data Types","summary":"Incrementalization speeds up computations by avoiding unnecessary recomputations and by efficiently reusing previous results. While domain-specific techniques achieve impressive speedups, e.g., in the context of database queries, they are difficult to generalize. Meanwhile, general approaches offer little support for incrementalizing domain-specific operations. In this work, we present DeCo, a novel core calculus for incremental functional programming with support for a wide range of user-defined data types. Despite its generic nature, our approach statically incrementalizes domain-specific operations on user-defined data types. It is, hence, more fine-grained than other generic techniques which resort to treating domain-specific operations as black boxes. We mechanized our work in Lean and proved it sound, meaning incrementalized execution computes the same result as full reevaluation. We also provide an executable implementation with case studies featuring examples from linear algebra, relational algebra, dictionaries, trees, and conflict-free replicated data types, plus a brief performance evaluation on linear and relational algebra and on trees.","authors":["Timon Böhler","Tobias Reinhard","David Richter","Mira Mezini"],"pdf_url":"","comment":"Accepted at OOPSLA'26"},{"id":"http://arxiv.org/abs/2502.05310v4","updated":"2026-02-24T13:07:25Z","published":"2025-02-07T20:24:43Z","title":"Oracular Programming: A Modular Foundation for Building LLM-Enabled Software","summary":"Large Language Models can solve a wide range of tasks from just a few examples, but they remain difficult to steer and lack a capability essential for building reliable software at scale: the modular composition of computations under enforceable contracts. As a result, they are typically embedded in larger software pipelines that use domain-specific knowledge to decompose tasks and improve reliability through validation and search. Yet the complexity of writing, tuning, and maintaining such pipelines has so far limited their sophistication. We propose oracular programming: a foundational paradigm for integrating traditional, explicit computations with inductive oracles such as LLMs. It rests on two directing principles: the full separation of core and search logic, and the treatment of few-shot examples as grounded and evolvable program components. Within this paradigm, experts express high-level problem-solving strategies as programs with unresolved choice points. These choice points are resolved at runtime by LLMs, which generalize from user-provided examples of correct and incorrect decisions. An oracular program is composed of three orthogonal components: a strategy that consists of a nondeterministic program with choice points that can be reified into a search tree, a policy that specifies how to navigate this tree with the help of LLM oracles, and a set of demonstrations that describe successful and unsuccessful tree navigation scenarios across diverse problem instances. Each component is expressed in a dedicated programming language and can be independently improved or substituted. We address the key programming language design challenges of modularly composing oracular programs and enforcing consistency between their components as they evolve.","authors":["Jonathan Laurent","André Platzer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.11935v3","updated":"2026-02-24T02:18:19Z","published":"2024-06-17T16:10:10Z","title":"A Problem-Oriented Perspective and Anchor Verification for Code Optimization","summary":"Large Language Models (LLMs) have shown remarkable capabilities in solving various programming tasks, such as code generation. However, their potential for code optimization, particularly in performance enhancement, remains largely unexplored. This paper investigates the capabilities of LLMs in optimizing code for minimal execution time, addressing a critical gap in current research. The recently proposed code optimization methods construct program optimization pairs based on iterative submissions from the same programmer for the same problem. However, this approach confines LLMs to local performance improvements, neglecting global algorithmic innovation. To overcome this limitation, we adopt a completely different perspective by reconstructing the optimization pairs into a problem-oriented approach. This allows for the integration of various ideas from multiple programmers tackling the same problem. Furthermore, we observe that code optimization presents greater challenges compared to code generation, often accompanied by \"optimization tax\". Recognizing the inherent trade-offs in correctness and efficiency, we introduce a novel anchor verification framework to mitigate this \"optimization tax\". Ultimately, the problem oriented perspective combined with the anchor verification framework significantly enhances both the correct optimization ratio and speedup to new levels.","authors":["Tong Ye","Tengfei Ma","Xuhong Zhang","Hang Yu","Jianwei Yin","Wenhai Wang"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2506.10056v2","updated":"2026-02-24T21:46:21Z","published":"2025-06-11T17:58:21Z","title":"Pareto Optimal Code Generation","summary":"Generate-then-rank is the dominant test-time scaling (TTS) paradigm for code generation, but scaling accuracy by sampling and executing more candidates makes comprehensive verification a major computational bottleneck. This creates an inherent trade-off between accuracy and compute that, despite its importance to TTS, is often ignored. Specifically, faster but noisier signals, such as outcome reward models (ORMs), are dismissed as suboptimal. We frame verifier selection as a Pareto optimization problem and empirically map the accuracy-throughput frontier across signals, including the full test suite, heuristics for selective execution, and ORMs, across four Python benchmarks. We show that ORMs are most effective at optimizing the Pareto curve when pruning is used in the generate-then-rank pipeline--known as staged verification--where lightweight filters remove obviously incorrect solutions, including candidates with small syntactic or character-level bugs, before expensive verification. Our pruning analysis shows that eliminating incorrect yet highly ranked candidates (often character-level bugs) prevents wasted compute on incorrect tokens. We find that ORMs with staged verification shift the Pareto frontier outward, achieving 11.64x higher throughput at a cost of 8.26% accuracy relative to full test-suite verification.","authors":["Gabriel Orlanski","Nicholas Roberts","Aws Albarghouthi","Frederic Sala"],"pdf_url":"","comment":"29 pages, 6 figures, code released here: https://github.com/SprocketLab/orm-code-verifier"},{"id":"http://arxiv.org/abs/2602.22240v1","updated":"2026-02-24T09:49:10Z","published":"2026-02-24T09:49:10Z","title":"From Prompts to Performance: Evaluating LLMs for Task-based Parallel Code Generation","summary":"Large Language Models (LLM) show strong abilities in code generation, but their skill in creating efficient parallel programs is less studied. This paper explores how LLMs generate task-based parallel code from three kinds of input prompts: natural language problem descriptions, sequential reference implementations, and parallel pseudo code. We focus on three programming frameworks: OpenMP Tasking, C++ standard parallelism, and the asynchronous many-task runtime HPX. Each framework offers different levels of abstraction and control for task execution. We evaluate LLM-generated solutions for correctness and scalability. Our results reveal both strengths and weaknesses of LLMs with regard to problem complexity and framework. Finally, we discuss what these findings mean for future LLM-assisted development in high-performance and scientific computing.","authors":["Linus Bantel","Moritz Strack","Alexander Strack","Dirk Pflüger"],"pdf_url":"","comment":"12 pages, 4 figures, 2 tables, Workshop on Asynchronous Many-Task Systems and Applications 2026"}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.03411v2","updated":"2026-02-24T17:13:02Z","published":"2026-02-03T11:38:48Z","title":"SWE-Master: Unleashing the Potential of Software Engineering Agents via Post-Training","summary":"In this technical report, we present SWE-Master, an open-source and fully reproducible post-training framework for building effective software engineering agents. SWE-Master systematically explores the complete agent development pipeline, including teacher-trajectory synthesis and data curation, long-horizon SFT, RL with real execution feedback, and inference framework design. Starting from an open-source base model with limited initial SWE capability, SWE-Master demonstrates how systematical optimization method can elicit strong long-horizon SWE task solving abilities. We evaluate SWE-Master on SWE-bench Verified, a standard benchmark for realistic software engineering tasks. Under identical experimental settings, our approach achieves a resolve rate of 61.4\\% with Qwen2.5-Coder-32B, substantially outperforming existing open-source baselines. By further incorporating test-time scaling~(TTS) with LLM-based environment feedback, SWE-Master reaches 70.8\\% at TTS@8, demonstrating a strong performance potential. SWE-Master provides a practical and transparent foundation for advancing reproducible research on software engineering agents. The code is available at https://github.com/RUCAIBox/SWE-Master.","authors":["Huatong Song","Lisheng Huang","Shuang Sun","Jinhao Jiang","Ran Le","Daixuan Cheng","Guoxin Chen","Yiwen Hu","Zongchao Chen","Yiming Jia","Wayne Xin Zhao","Yang Song","Tao Zhang","Ji-Rong Wen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21074v1","updated":"2026-02-24T16:35:20Z","published":"2026-02-24T16:35:20Z","title":"Validation of an analyzability model for quantum software: a family of experiments","summary":"The analyzability of hybrid software, which integrates both classical and quantum components, is a key factor in ensuring its maintainability and industrial adoption. This article presents the empirical validation, through a family of experiments, of the quantum component of a previously proposed hybrid software analyzability model based on the ISO/IEC 25010 standard. The experimental series consists of four studies involving participants with diverse profiles in both academic and professional settings. In these experiments, the model's ability to effectively measure the analyzability of quantum algorithms is assessed, and the relationship between the analyzability levels computed by the model and the participant's perceptions of the complexity of these algorithms is examined. The results indicate that the proposed model effectively distinguishes between quantum software components with varying levels of analyzability and aligns with human perception, reinforcing its validity in quantum computing.","authors":["Ana Díaz-Muñoz","José A. Cruz-Lemus","Moisés Rodríguez","Maria Teresa Baldassarre","Mario Piattini"],"pdf_url":"","comment":"42 pages, 5 figures, 12 tables. This is the Author Accepted Manuscript (AAM) of the article published in Empirical Software Engineering (2026). The final published version is available at https://doi.org/10.1007/s10664-026-10825-3"},{"id":"http://arxiv.org/abs/2602.21037v1","updated":"2026-02-24T15:56:20Z","published":"2026-02-24T15:56:20Z","title":"Automated Detection and Mitigation of Dependability Failures in Healthcare Scenarios through Digital Twins","summary":"Medical Cyber-Physical Systems (CPSs) integrating Patients, Devices, and healthcare personnel (Physicians) form safety-critical PDP triads whose dependability is challenged by system heterogeneity and uncertainty in human and physiological behavior. While existing clinical decision support systems support clinical practice, there remains a need for proactive, reliability-oriented methodologies capable of identifying and mitigating failure scenarios before patient safety is compromised. This paper presents M-GENGAR, a methodology based on a closed-loop Digital Twin (DT) paradigm for dependability assurance of medical CPSs. The approach combines Stochastic Hybrid Automata modeling, data-driven learning of patient dynamics, and Statistical Model Checking with an offline critical scenario detection phase that integrates model-space exploration and diversity analysis to systematically identify and classify scenarios violating expert-defined dependability requirements. M-GENGAR also supports the automated synthesis of mitigation strategies, enabling runtime feedback and control within the DT loop. We evaluate M-GENGAR on a representative use case study involving a pulmonary ventilator. Results show that, in 87.5% of the evaluated scenarios, strategies synthesized through formal game-theoretic analysis stabilize patient vital metrics at least as effectively as human decision-making, while maintaining relevant metrics 20% closer to nominal healthy values on average.","authors":["Bruno Guindani","Matteo Camilli","Livia Lestingi","Marcello M. Bersani"],"pdf_url":"","comment":"Submitted to IEEE Transactions on Reliability"},{"id":"http://arxiv.org/abs/2602.21033v1","updated":"2026-02-24T15:55:04Z","published":"2026-02-24T15:55:04Z","title":"MIP Candy: A Modular PyTorch Framework for Medical Image Processing","summary":"Medical image processing demands specialized software that handles high-dimensional volumetric data, heterogeneous file formats, and domain-specific training procedures. Existing frameworks either provide low-level components that require substantial integration effort or impose rigid, monolithic pipelines that resist modification. We present MIP Candy (MIPCandy), a freely available, PyTorch-based framework designed specifically for medical image processing. MIPCandy provides a complete, modular pipeline spanning data loading, training, inference, and evaluation, allowing researchers to obtain a fully functional process workflow by implementing a single method, $\\texttt{build_network}$, while retaining fine-grained control over every component. Central to the design is $\\texttt{LayerT}$, a deferred configuration mechanism that enables runtime substitution of convolution, normalization, and activation modules without subclassing. The framework further offers built-in $k$-fold cross-validation, dataset inspection with automatic region-of-interest detection, deep supervision, exponential moving average, multi-frontend experiment tracking (Weights & Biases, Notion, MLflow), training state recovery, and validation score prediction via quotient regression. An extensible bundle ecosystem provides pre-built model implementations that follow a consistent trainer--predictor pattern and integrate with the core framework without modification. MIPCandy is open-source under the Apache-2.0 license and requires Python~3.12 or later. Source code and documentation are available at https://github.com/ProjectNeura/MIPCandy.","authors":["Tianhao Fu","Yucheng Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21026v1","updated":"2026-02-24T15:48:39Z","published":"2026-02-24T15:48:39Z","title":"A Modular Multi-Document Framework for Scientific Visualization and Simulation in Java","summary":"This paper presents the design and implementation of a modular multi-document interface (MDI) framework for scientific visualization and simulation in the Java Virtual Machine (JVM) ecosystem. The framework emphasizes architectural separation between visualization layers, simulation engines, and optional hardware-accelerated 3D rendering. 3D functionality is isolated into a separate module to prevent unnecessary dependency coupling in 2D-only applications. We describe the core abstractions, threading model, simulation integration strategy, and dependency isolation approach. A case study involving a real-time 3D gas expansion simulation integrated with synchronized 2D entropy plotting demonstrates architectural cohesion. The framework is publicly available via Maven Central and targets long-lived scientific and engineering desktop applications.","authors":["David Heddle"],"pdf_url":"","comment":"10 pages, 5 figures. Includes optional 3D extension module and integrated plotting subsystem. Source code available on GitHub"},{"id":"http://arxiv.org/abs/2602.20979v1","updated":"2026-02-24T15:01:29Z","published":"2026-02-24T15:01:29Z","title":"Toward an Agentic Infused Software Ecosystem","summary":"Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the AI agents themselves, which in the past 5 years have moved from simple code completion and toward sophisticated independent development tasks, a trend which will only continue. The second pillar is the programming language and APIs (or tools) that these agents use to accomplish tasks, and increasingly, serve as the communication substrate that humans and AI agents interact and collaborate through. The final pillar is the runtime environment and ecosystem that agents operate within, and which provide the capabilities that programmatic agents use to interface with (and effect actions in) the external world. To realize the vision of AISE, all three pillars must be advanced in a holistic manner, and critically, in a manner that is synergistic for AI agents as they exist today, those that will exist in the future, and for the human developers that work alongside them.","authors":["Mark Marron"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.13134v2","updated":"2026-02-24T14:32:15Z","published":"2026-01-19T15:20:18Z","title":"Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access","summary":"Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical \"frozen\" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.","authors":["Heng Fang","Adam J. Stewart","Isaac Corley","Xiao Xiang Zhu","Hossein Azizpour"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20924v1","updated":"2026-02-24T14:04:18Z","published":"2026-02-24T14:04:18Z","title":"Airavat: An Agentic Framework for Internet Measurement","summary":"Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating both workflow generation and verification against methodological standards established through decades of research.\n  We present Airavat, the first agentic framework for Internet measurement workflow generation with systematic verification and validation. Airavat coordinates a set of agents mirroring expert reasoning: three agents handle problem decomposition, solution design, and code implementation, with assistance from a registry of existing tools. Two specialized engines ensure methodological correctness: a Verification Engine evaluates workflows against a knowledge graph encoding five decades of measurement research, while a Validation Engine identifies appropriate validation techniques grounded in established methodologies. Through four Internet measurement case studies, we demonstrate that Airavat (i) generates workflows matching expert-level solutions, (ii) makes sound architectural decisions, (iii) addresses novel problems without ground truth, and (iv) identifies methodological flaws missed by standard execution-based testing.","authors":["Alagappan Ramanathan","Eunju Kang","Dongsu Han","Sangeetha Abdu Jyothi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20799v1","updated":"2026-02-24T11:36:34Z","published":"2026-02-24T11:36:34Z","title":"Unseen-Codebases-Domain Data Synthesis and Training Based on Code Graphs","summary":"In the context of newly release software frameworks, large language models (LLMs) often exhibit poor performance and a high rate of hallucination, as they are not exposed to such environments during training. Although inference-time augmentation techniques such as retrieval-augmented generation (RAG) can partially mitigate hallucinations, knowledge injection through prompting alone is insufficient to enable models to fully understand the intrinsic relationships among different components of a codebase, or to reason about the correct compositions and apply. Although explicit knowledge injection can be achieved through post-training, compared with public code domains, unseen codebases typically provide only source code and lack large volumes of high-quality, usage-oriented code that can be directly leveraged as training data. Consequently, existing data synthesis approaches are insufficient to adequately capture unseen codebases usage scenarios when restricted to source code alone. To address these challenges, we propose UCD-Training, a two-stage training framework for reasoning-aware data synthesis grounded in a code graph constructed from unseen codebases. UCD-Training first parses the source code to build a code graph, then conducts dependency-preserving continued pretraining (CPT) using file-level dependency data, followed by graph-grounded supervised fine-tuning (SFT) on three types of synthesized data augmented with explicit reasoning traces: (1) single-hop relation reasoning data, (2) compositional API reasoning data, and (3) codebase utilization data. We further introduce a new benchmark, UnseenCodeBench, for code generation on unseen codebases and conduct comprehensive experiments across multiple codebases.","authors":["Guangsheng Ou","Qiming Zhang","Sirong Chen","Anji Li","Dong Xu","Tiancheng Luo","Dekun Dai","Cuiyun Gao","Long Wang","Jun Zhou","Mingwei Liu","Zibin Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06251v2","updated":"2026-02-24T10:32:26Z","published":"2025-06-06T17:21:21Z","title":"DesignBench: A Comprehensive Benchmark for MLLM-based Front-end Code Generation","summary":"Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in automated front-end engineering, e.g., generating UI code from visual designs. However, existing front-end UI code generation benchmarks have the following limitations: (1) While framework-based development becomes predominant in modern front-end programming, current benchmarks fail to incorporate mainstream development frameworks. (2) Existing evaluations focus solely on the UI code generation task, whereas practical UI development involves several iterations, including refining editing, and repairing issues. (3) Current benchmarks employ unidimensional evaluation, lacking investigation into influencing factors like task difficulty, input context variations, and in-depth code-level analysis. To bridge these gaps, we introduce DesignBench, a multi-framework, multi-task evaluation benchmark for assessing MLLMs' capabilities in automated front-end engineering. DesignBench encompasses three widely-used UI frameworks (React, Vue, and Angular) alongside vanilla HTML/CSS, and evaluates on three essential front-end tasks (generation, edit, and repair) in real-world development workflows. DesignBench contains 900 webpage samples spanning over 11 topics, 9 edit types, and 6 issue categories, enabling detailed analysis of MLLM performance across multiple dimensions. Our systematic evaluation reveals critical insights into MLLMs' framework-specific limitations, task-related bottlenecks, and performance variations under different conditions, providing guidance for future research in automated front-end development. Our code and data are available at https://github.com/WebPAI/DesignBench.","authors":["Jingyu Xiao","Man Ho Lam","Ming Wang","Yuxuan Wan","Junliang Liu","Yintong Huo","Michael R. Lyu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18579v2","updated":"2026-02-24T09:44:17Z","published":"2026-02-20T19:37:14Z","title":"Refactoring for Novices in Java: An Eye Tracking Study on the Extract vs. Inline Methods","summary":"Developers often extract methods to improve readability, understanding, and reuse, while inlining keeps logic in one block. Prior work based on static metrics has not shown clear differences between these practices, and the human side of comprehension and navigation remains underexplored. We investigate Inline Method vs. Extract Method refactorings using a dynamic approach: eye tracking while participants read and solve tasks. We analyze key code areas and compare visual effort and reading behavior (fixation duration and count, regressions, revisits), alongside time and attempts. We ran a controlled experiment with 32 Java novices, followed by short interviews. Each participant solved eight simple tasks across four programs presented in an inlined version and four in an extracted version. We also surveyed 58 additional novices for complementary quantitative and qualitative data. Results show that effects depend on task difficulty. In two tasks, method extraction improved performance and reduced visual effort, with time decreasing by up to 78.8% and regressions by 84.6%. For simpler tasks (e.g., square area), extraction hurt performance: time increased by up to 166.9% and regressions by 200%. Even with meaningful method names, novices often switched back and forth between call sites and extracted methods, increasing navigation and cognitive load. Preferences frequently favored extraction for readability and reuse, but did not always match measured performance. These findings suggest educators should be cautious about premature modularization for novices and highlight eye tracking as a useful complement to static metrics.","authors":["José Aldo Silva da Costa","Rohit Gheyi","José Júnior Silva da Costa","Márcio Ribeiro","Rodrigo Bonifácio","Hyggo Almeida","Ana Carla Bibiano","Alessandro Garcia"],"pdf_url":"","comment":"Accepted at Journal of Systems and Software"},{"id":"http://arxiv.org/abs/2602.20717v1","updated":"2026-02-24T09:26:11Z","published":"2026-02-24T09:26:11Z","title":"PackMonitor: Enabling Zero Package Hallucinations Through Decoding-Time Monitoring","summary":"As Large Language Models (LLMs) are increasingly integrated into software development workflows, their trustworthiness has become a critical concern. However, in dependency recommendation scenarios, the reliability of LLMs is undermined by widespread package hallucinations, where models often recommend hallucinated packages. Recent studies have proposed a range of approaches to mitigate this issue. Nevertheless, existing approaches typically merely reduce hallucination rates rather than eliminate them, leaving persistent software security risks.\n  In this work, we argue that package hallucinations are theoretically preventable based on the key insight that package validity is decidable through finite and enumerable authoritative package lists. Building on this, we propose PackMonitor, the first approach capable of fundamentally eliminating package hallucinations by continuously monitoring the model's decoding process and intervening when necessary. To implement this in practice, PackMonitor addresses three key challenges: (1) determining when to trigger intervention via a Context-Aware Parser that continuously monitors model outputs and selectively activates intervening only during installation command generation; (2) resolving how to intervene by employing a Package-Name Intervenor that strictly limits the decoding space to an authoritative package list; and (3) ensuring monitoring efficiency through a DFA-Caching Mechanism that enables scalability to millions of packages with negligible overhead. Extensive experiments on five widely used LLMs demonstrate that PackMonitor is a training-free, plug-and-play solution that consistently reduces package hallucination rates to zero while maintaining low-latency inference and preserving original model capabilities.","authors":["Xiting Liu","Yuetong Liu","Yitong Zhang","Jia Li","Shi-Min Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20684v1","updated":"2026-02-24T08:41:05Z","published":"2026-02-24T08:41:05Z","title":"Agile V: A Compliance-Ready Framework for AI-Augmented Engineering -- From Concept to Audit-Ready Delivery","summary":"Current AI-assisted engineering workflows lack a built-in mechanism to maintain task-level verification and regulatory traceability at machine-speed delivery. Agile V addresses this gap by embedding independent verification and audit artifact generation into each task cycle. The framework merges Agile iteration with V-Model verification into a continuous Infinity Loop, deploying specialized AI agents for requirements, design, build, test, and compliance, governed by mandatory human approval gates. We evaluate three hypotheses: (H1) audit-ready artifacts emerge as a by-product of development, (H2) 100% requirement-level verification is achievable with independent test generation, and (H3) verified increments can be delivered with single-digit human interactions per cycle. A feasibility case study on a Hardware-in-the-Loop system (about 500 LOC, 8 requirements, 54 tests) supports all three hypotheses: audit-ready documentation was generated automatically (H1), 100% requirement-level pass rate was achieved (H2), and only 6 prompts per cycle were required (H3), yielding an estimated 10-50x cost reduction versus a COCOMO II baseline (sensitivity range from pessimistic to optimistic assumptions). We invite independent replication to validate generalizability.","authors":["Christopher Koch","Joshua Andreas Wellbrock"],"pdf_url":"","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.20644v1","updated":"2026-02-24T07:44:26Z","published":"2026-02-24T07:44:26Z","title":"An LLM-driven Scenario Generation Pipeline Using an Extended Scenic DSL for Autonomous Driving Safety Validation","summary":"Real-world crash reports, which combine textual summaries and sketches, are valuable for scenario-based testing of autonomous driving systems (ADS). However, current methods cannot effectively translate this multimodal data into precise, executable simulation scenarios, hindering the scalability of ADS safety validation. In this work, we propose a scalable and verifiable pipeline that uses a large language model (GPT-4o mini) and a probabilistic intermediate representation (an Extended Scenic domain-specific language) to automatically extract semantic scenario configurations from crash reports and generate corresponding simulation-ready scenarios. Unlike earlier approaches such as ScenicNL and LCTGen (which generate scenarios directly from text) or TARGET (which uses deterministic mappings from traffic rules), our method introduces an intermediate Scenic DSL layer to separate high-level semantic understanding from low-level scenario rendering, reducing errors and capturing real-world variability. We evaluated the pipeline on cases from the NHTSA CIREN database. The results show high accuracy in knowledge extraction: 100% correctness for environmental and road network attributes, and 97% and 98% for oracle and actor trajectories, respectively, compared to human-derived ground truth. We executed the generated scenarios in the CARLA simulator using the Autoware driving stack, and they consistently triggered the intended traffic-rule violations (such as opposite-lane crossing and red-light running) across 2,000 scenario variations. These findings demonstrate that the proposed pipeline provides a legally grounded, scalable, and verifiable approach to ADS safety validation.","authors":["Fida Khandaker Safa","Yupeng Jiang","Xi Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20610v1","updated":"2026-02-24T07:01:17Z","published":"2026-02-24T07:01:17Z","title":"SpecMind: Cognitively Inspired, Interactive Multi-Turn Framework for Postcondition Inference","summary":"Specifications are vital for ensuring program correctness, yet writing them manually remains challenging and time-intensive. Recent large language model (LLM)-based methods have shown successes in generating specifications such as postconditions, but existing single-pass prompting often yields inaccurate results. In this paper, we present SpecMind, a novel framework for postcondition generation that treats LLMs as interactive and exploratory reasoners rather than one-shot generators. SpecMind employs feedback-driven multi-turn prompting approaches, enabling the model to iteratively refine candidate postconditions by incorporating implicit and explicit correctness feedback, while autonomously deciding when to stop. This process fosters deeper code comprehension and improves alignment with true program behavior via exploratory attempts. Our empirical evaluation shows that SpecMind significantly outperforms state-of-the-art approaches in both accuracy and completeness of generated postconditions.","authors":["Cuong Chi Le","Minh V. T Pham","Tung Vu Duy","Cuong Duc Van","Huy N. Phan","Hoang N. Phan","Tien N. Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20598v1","updated":"2026-02-24T06:39:48Z","published":"2026-02-24T06:39:48Z","title":"A Case Study on Runtime Verification of a Continuous Deployment Process","summary":"We report our experience in applying runtime monitoring to a FluxCD-based continuous deployment (CD) process. Our target system consists of GitHub Actions, GitHub Container Registry (GHCR), FluxCD, and an application running on Kubernetes. We monitored its logs using SyMon. In our setting, we regard a deployment update as detected when FluxCD's polling log resolves the latest image tag. Through the case study, we found that FluxCD did not always detect a new image within five minutes after it was pushed to GHCR, whereas it always did so within ten minutes in the collected logs. Moreover, our results show that SyMon is fast enough for near-real-time monitoring in our setting.","authors":["Shoma Ansai","Masaki Waga"],"pdf_url":"","comment":"Presented at the Runtime Verification Case-Studies Workshop 2025 (RVCase'25), with no formal proceedings"},{"id":"http://arxiv.org/abs/2406.11935v3","updated":"2026-02-24T02:18:19Z","published":"2024-06-17T16:10:10Z","title":"A Problem-Oriented Perspective and Anchor Verification for Code Optimization","summary":"Large Language Models (LLMs) have shown remarkable capabilities in solving various programming tasks, such as code generation. However, their potential for code optimization, particularly in performance enhancement, remains largely unexplored. This paper investigates the capabilities of LLMs in optimizing code for minimal execution time, addressing a critical gap in current research. The recently proposed code optimization methods construct program optimization pairs based on iterative submissions from the same programmer for the same problem. However, this approach confines LLMs to local performance improvements, neglecting global algorithmic innovation. To overcome this limitation, we adopt a completely different perspective by reconstructing the optimization pairs into a problem-oriented approach. This allows for the integration of various ideas from multiple programmers tackling the same problem. Furthermore, we observe that code optimization presents greater challenges compared to code generation, often accompanied by \"optimization tax\". Recognizing the inherent trade-offs in correctness and efficiency, we introduce a novel anchor verification framework to mitigate this \"optimization tax\". Ultimately, the problem oriented perspective combined with the anchor verification framework significantly enhances both the correct optimization ratio and speedup to new levels.","authors":["Tong Ye","Tengfei Ma","Xuhong Zhang","Hang Yu","Jianwei Yin","Wenhai Wang"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.20478v1","updated":"2026-02-24T02:11:26Z","published":"2026-02-24T02:11:26Z","title":"Codified Context: Infrastructure for AI Agents in a Complex Codebase","summary":"LLM-based agentic coding assistants lack persistent memory: they lose coherence across sessions, forget project conventions, and repeat known mistakes. Recent studies characterize how developers configure agents through manifest files, but an open challenge remains how to scale such configurations for large, multi-agent projects. This paper presents a three-component codified context infrastructure developed during construction of a 108,000-line C# distributed system: (1) a hot-memory constitution encoding conventions, retrieval hooks, and orchestration protocols; (2) 19 specialized domain-expert agents; and (3) a cold-memory knowledge base of 34 on-demand specification documents. Quantitative metrics on infrastructure growth and interaction patterns across 283 development sessions are reported alongside four observational case studies illustrating how codified context propagates across sessions to prevent failures and maintain consistency. The framework is published as an open-source companion repository.","authors":["Aristidis Vasilopoulos"],"pdf_url":"","comment":"9 pages, 4 figures, companion repository: https://github.com/arisvas4/codified-context-infrastructure, code DOI: 10.5281/zenodo.18746623"},{"id":"http://arxiv.org/abs/2506.10056v2","updated":"2026-02-24T21:46:21Z","published":"2025-06-11T17:58:21Z","title":"Pareto Optimal Code Generation","summary":"Generate-then-rank is the dominant test-time scaling (TTS) paradigm for code generation, but scaling accuracy by sampling and executing more candidates makes comprehensive verification a major computational bottleneck. This creates an inherent trade-off between accuracy and compute that, despite its importance to TTS, is often ignored. Specifically, faster but noisier signals, such as outcome reward models (ORMs), are dismissed as suboptimal. We frame verifier selection as a Pareto optimization problem and empirically map the accuracy-throughput frontier across signals, including the full test suite, heuristics for selective execution, and ORMs, across four Python benchmarks. We show that ORMs are most effective at optimizing the Pareto curve when pruning is used in the generate-then-rank pipeline--known as staged verification--where lightweight filters remove obviously incorrect solutions, including candidates with small syntactic or character-level bugs, before expensive verification. Our pruning analysis shows that eliminating incorrect yet highly ranked candidates (often character-level bugs) prevents wasted compute on incorrect tokens. We find that ORMs with staged verification shift the Pareto frontier outward, achieving 11.64x higher throughput at a cost of 8.26% accuracy relative to full test-suite verification.","authors":["Gabriel Orlanski","Nicholas Roberts","Aws Albarghouthi","Frederic Sala"],"pdf_url":"","comment":"29 pages, 6 figures, code released here: https://github.com/SprocketLab/orm-code-verifier"},{"id":"http://arxiv.org/abs/2602.21265v1","updated":"2026-02-24T09:23:12Z","published":"2026-02-24T09:23:12Z","title":"ToolMATH: A Math Tool Benchmark for Realistic Long-Horizon Multi-Tool Reasoning","summary":"We introduce \\ToolMATH, a math-grounded benchmark that evaluates tool-augmented language models in realistic multi-tool environments where the output depends on calling schema-specified tools and sustaining multi-step execution. It turns math problems into a controlled, correctness-checkable benchmark with tool sets, enabling systematic evaluation of model reliability under (1) large, overlapping tool catalogs and (2) the absence of the intended capability. \\ToolMATH provides actionable diagnostic evidence of failure modes in tool-augmented agents, helping identify the control mechanisms required for robustness. \\ToolMATH roughly contains 8k questions and 12k tools; we provide an additional hard-set \\ToolMATHHard with questions and tools. Our evaluation reveals that the key failure factor is due to the inability to reason, leading to the accumulation of intermediate results' errors and constrain later decisions. Tool-list redundancy do not simply add noise, but amplify small early deviations into irreversible execution drift. The benchmark highlights that when the intended capability is missing, distractor tools can sometimes serve as partial substitutes in solution paths, yet they can also mislead models into ungrounded tool trajectories. Finally, comparisons between tool-use protocols emphasize that improvements come less from local action selection and more from long-range plan coherence and disciplined use of observations.","authors":["Hyeonje Choi","Jeongsoo Lee","Hyojun Lee","Jay-Yoon Lee"],"pdf_url":"","comment":"Conference : Submitted to ICML 2026. 8 pages (+ abstract 16 pages), 5 figures"}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2602.19275v2","updated":"2026-02-24T18:28:12Z","published":"2026-02-22T17:16:49Z","title":"KUDA: Knowledge Unlearning by Deviating Representation for Large Language Models","summary":"Large language models (LLMs) acquire a large amount of knowledge through pre-training on vast and diverse corpora. While this endows LLMs with strong capabilities in generation and reasoning, it amplifies risks associated with sensitive, copyrighted, or harmful content in training data. LLM unlearning, which aims to remove specific knowledge encoded within models, is a promising technique to reduce these risks. However, existing LLM unlearning methods often force LLMs to generate random or incoherent answers due to their inability to alter the encoded knowledge precisely. To achieve effective unlearning at the knowledge level of LLMs, we propose Knowledge Unlearning by Deviating representAtion (KUDA). We first utilize causal tracing to locate specific layers for target knowledge storage. We then design a new unlearning objective that induces the model's representations to deviate from its original position in the phase of knowledge removal, thus disrupting the ability to associate with the target knowledge. To resolve the optimization conflicts between forgetting and retention, we employ a relaxation null-space projection mechanism to mitigate the disruption to the representation space of retaining knowledge. Extensive experiments on representative benchmarks, WMDP and MUSE, demonstrate that KUDA outperforms most existing baselines by effectively balancing knowledge removal and model utility retention.","authors":["Ce Fang","Zhikun Zhang","Min Chen","Qing Liu","Lu Zhou","Zhe Liu","Yunjun Gao"],"pdf_url":"","comment":"24 pages, 15 figures"},{"id":"http://arxiv.org/abs/2602.20156v2","updated":"2026-02-24T18:03:02Z","published":"2026-02-23T18:59:27Z","title":"Skill-Inject: Measuring Agent Vulnerability to Skill File Attacks","summary":"LLM agents are evolving rapidly, powered by code execution, tools, and the recently introduced agent skills feature. Skills allow users to extend LLM applications with specialized third-party code, knowledge, and instructions. Although this can extend agent capabilities to new domains, it creates an increasingly complex agent supply chain, offering new surfaces for prompt injection attacks. We identify skill-based prompt injection as a significant threat and introduce SkillInject, a benchmark evaluating the susceptibility of widely-used LLM agents to injections through skill files. SkillInject contains 202 injection-task pairs with attacks ranging from obviously malicious injections to subtle, context-dependent attacks hidden in otherwise legitimate instructions. We evaluate frontier LLMs on SkillInject, measuring both security in terms of harmful instruction avoidance and utility in terms of legitimate instruction compliance. Our results show that today's agents are highly vulnerable with up to 80% attack success rate with frontier models, often executing extremely harmful instructions including data exfiltration, destructive action, and ransomware-like behavior. They furthermore suggest that this problem will not be solved through model scaling or simple input filtering, but that robust agent security will require context-aware authorization frameworks. Our benchmark is available at https://www.skill-inject.com/.","authors":["David Schmotz","Luca Beurer-Kellner","Sahar Abdelnabi","Maksym Andriushchenko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21127v1","updated":"2026-02-24T17:23:11Z","published":"2026-02-24T17:23:11Z","title":"\"Are You Sure?\": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems","summary":"Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized against their human users. While extensive research focuses on agent-centric threats, human susceptibility to deception by a compromised agent remains unexplored. We present the first large-scale empirical study with 303 participants to measure human susceptibility to AMD. This is based on HAT-Lab (Human-Agent Trust Laboratory), a high-fidelity research platform we develop, featuring nine carefully crafted scenarios spanning everyday and professional domains (e.g., healthcare, software development, human resources). Our 10 key findings reveal significant vulnerabilities and provide future defense perspectives. Specifically, only 8.6% of participants perceive AMD attacks, while domain experts show increased susceptibility in certain scenarios. We identify six cognitive failure modes in users and find that their risk awareness often fails to translate to protective behavior. The defense analysis reveals that effective warnings should interrupt workflows with low verification costs. With experiential learning based on HAT-Lab, over 90% of users who perceive risks report increased caution against AMD. This work provides empirical evidence and a platform for human-centric agent security research.","authors":["Xinfeng Li","Shenyu Dai","Kelong Zheng","Yue Xiao","Gelei Deng","Wei Dong","Xiaofeng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23834v2","updated":"2026-02-24T16:47:16Z","published":"2025-09-28T12:14:06Z","title":"GPM: The Gaussian Pancake Mechanism for Planting Undetectable Backdoors in Differential Privacy","summary":"Differential privacy (DP) has become the gold standard for preserving individual privacy in data analysis. However, an implicit yet fundamental assumption underlying these rigorous privacy guarantees is the correct implementation and execution of DP mechanisms. Several incidents of unintended privacy loss have occurred due to numerical issues and inappropriate configurations of DP software, which have been successfully exploited in privacy attacks. To better understand the seriousness of defective DP software, we ask the following question: is it possible to elevate these passive defects into active privacy attacks while maintaining covertness?\n  To address this question, we present the Gaussian pancake mechanism (GPM), a novel mechanism that is computationally indistinguishable from the widely used Gaussian mechanism (GM), yet exhibits arbitrarily weaker statistical DP guarantees. This unprecedented separation enables a new class of backdoor attacks: by indistinguishably passing off as the authentic GM, GPM can covertly degrade statistical privacy. Unlike the unintentional privacy loss caused by GM's numerical issues, GPM is an adversarial yet undetectable backdoor attack against data privacy. We formally prove GPM's covertness, characterize its statistical leakage, and demonstrate a concrete distinguishing attack that can achieve near-perfect success rates under suitable parameter choices, both theoretically and empirically.\n  Our results underscore the importance of using transparent, open-source DP libraries and highlight the need for rigorous scrutiny and formal verification of DP implementations to prevent subtle, undetectable privacy compromises in real-world systems.","authors":["Haochen Sun","Xi He"],"pdf_url":"","comment":"Accepted to ACM SIGMOD 2026. Please refer to https://github.com/jvhs0706/GPM for code and raw experiment logs"},{"id":"http://arxiv.org/abs/2509.14297v2","updated":"2026-02-24T14:28:30Z","published":"2025-09-17T04:21:20Z","title":"A Simple and Efficient Jailbreak Method Exploiting LLMs' Helpfulness","summary":"This study reveals a critical safety blind spot in modern LLMs: learning-style queries, which closely resemble ordinary educational questions, can reliably elicit harmful responses. The learning-style queries are constructed by a novel reframing paradigm: HILL (Hiding Intention by Learning from LLMs). The deterministic, model-agnostic reframing framework is composed of 4 conceptual components: 1) key concept, 2) exploratory transformation, 3) detail-oriented inquiry, and optionally 4) hypotheticality. Further, new metrics are introduced to thoroughly evaluate the efficiency and harmfulness of jailbreak methods. Experiments on the AdvBench dataset across a wide range of models demonstrate HILL's strong generalizability. It achieves top attack success rates on the majority of models and across malicious categories while maintaining high efficiency with concise prompts. On the other hand, results of various defense methods show the robustness of HILL, with most defenses having mediocre effects or even increasing the attack success rates. In addition, the assessment of defenses on the constructed safe prompts reveals inherent limitations of LLMs' safety mechanisms and flaws in the defense methods. This work exposes significant vulnerabilities of safety measures against learning-style elicitation, highlighting a critical challenge of fulfilling both helpfulness and safety alignments.","authors":["Xuan Luo","Yue Wang","Zefeng He","Geng Tu","Jing Li","Ruifeng Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20867v1","updated":"2026-02-24T13:11:38Z","published":"2026-02-24T13:11:38Z","title":"SoK: Agentic Skills -- Beyond Tool Use in LLM Agents","summary":"Agentic systems increasingly rely on reusable procedural capabilities, \\textit{a.k.a., agentic skills}, to execute long-horizon workflows reliably. These capabilities are callable modules that package procedural knowledge with explicit applicability conditions, execution policies, termination criteria, and reusable interfaces. Unlike one-off plans or atomic tool calls, skills operate (and often do well) across tasks.\n  This paper maps the skill layer across the full lifecycle (discovery, practice, distillation, storage, composition, evaluation, and update) and introduces two complementary taxonomies. The first is a system-level set of \\textbf{seven design patterns} capturing how skills are packaged and executed in practice, from metadata-driven progressive disclosure and executable code skills to self-evolving libraries and marketplace distribution. The second is an orthogonal \\textbf{representation $\\times$ scope} taxonomy describing what skills \\emph{are} (natural language, code, policy, hybrid) and what environments they operate over (web, OS, software engineering, robotics).\n  We analyze the security and governance implications of skill-based agents, covering supply-chain risks, prompt injection via skill payloads, and trust-tiered execution, grounded by a case study of the ClawHavoc campaign in which nearly 1{,}200 malicious skills infiltrated a major agent marketplace, exfiltrating API keys, cryptocurrency wallets, and browser credentials at scale. We further survey deterministic evaluation approaches, anchored by recent benchmark evidence that curated skills can substantially improve agent success rates while self-generated skills may degrade them. We conclude with open challenges toward robust, verifiable, and certifiable skills for real-world autonomous agents.","authors":["Yanna Jiang","Delong Li","Haiyu Deng","Baihe Ma","Xu Wang","Qin Wang","Guangsheng Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20830v1","updated":"2026-02-24T12:11:32Z","published":"2026-02-24T12:11:32Z","title":"A Secure and Interoperable Architecture for Electronic Health Record Access Control and Sharing","summary":"Electronic Health Records (EHRs) store sensitive patient information, necessitating stringent access control and sharing mechanisms to uphold data security and comply with privacy regulations such as the General Data Protection Regulation (GDPR). In this paper, we propose a comprehensive architecture with a suite of efficient protocols that leverage the synergistic capabilities of the Blockchain and Interplanetary File System (IPFS) technologies to enable secure access control and sharing of EHRs. Our approach is based on a private blockchain, wherein smart contracts are deployed to enforce control exclusively by patients. By granting patients exclusive control over their EHRs, our solution ensures compliance with personal data protection laws and empowers individuals to manage their health information autonomously. Notably, our proposed architecture seamlessly integrates with existing health provider information systems, facilitating interoperability and effectively addressing security and data heterogeneity challenges. To demonstrate the effectiveness of our approach, we developed a prototype based on a private implementation of the Hyperledger platform, enabling the simulation of diverse scenarios involving access control and health data sharing among healthcare practitioners. Our experimental results demonstrate the scalability of our solution, thereby substantiating its efficacy and robustness in real-world healthcare settings.","authors":["Tayeb Kenaza","Islam Debicha","Youcef Fares","Mehdi Sehaki","Sami Messai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20720v1","updated":"2026-02-24T09:32:19Z","published":"2026-02-24T09:32:19Z","title":"AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs","summary":"The integration of external data services (e.g., Model Context Protocol, MCP) has made large language model-based agents increasingly powerful for complex task execution. However, this advancement introduces critical security vulnerabilities, particularly indirect prompt injection (IPI) attacks. Existing attack methods are limited by their reliance on static patterns and evaluation on simple language models, failing to address the fast-evolving nature of modern AI agents. We introduce AdapTools, a novel adaptive IPI attack framework that selects stealthier attack tools and generates adaptive attack prompts to create a rigorous security evaluation environment. Our approach comprises two key components: (1) Adaptive Attack Strategy Construction, which develops transferable adversarial strategies for prompt optimization, and (2) Attack Enhancement, which identifies stealthy tools capable of circumventing task-relevance defenses. Comprehensive experimental evaluation shows that AdapTools achieves a 2.13 times improvement in attack success rate while degrading system utility by a factor of 1.78. Notably, the framework maintains its effectiveness even against state-of-the-art defense mechanisms. Our method advances the understanding of IPI attacks and provides a useful reference for future research.","authors":["Che Wang","Jiaming Zhang","Ziqi Zhang","Zijie Wang","Yinghui Wang","Jianbo Gao","Tao Wei","Zhong Chen","Wei Yang Bryan Lim"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2602.20717v1","updated":"2026-02-24T09:26:11Z","published":"2026-02-24T09:26:11Z","title":"PackMonitor: Enabling Zero Package Hallucinations Through Decoding-Time Monitoring","summary":"As Large Language Models (LLMs) are increasingly integrated into software development workflows, their trustworthiness has become a critical concern. However, in dependency recommendation scenarios, the reliability of LLMs is undermined by widespread package hallucinations, where models often recommend hallucinated packages. Recent studies have proposed a range of approaches to mitigate this issue. Nevertheless, existing approaches typically merely reduce hallucination rates rather than eliminate them, leaving persistent software security risks.\n  In this work, we argue that package hallucinations are theoretically preventable based on the key insight that package validity is decidable through finite and enumerable authoritative package lists. Building on this, we propose PackMonitor, the first approach capable of fundamentally eliminating package hallucinations by continuously monitoring the model's decoding process and intervening when necessary. To implement this in practice, PackMonitor addresses three key challenges: (1) determining when to trigger intervention via a Context-Aware Parser that continuously monitors model outputs and selectively activates intervening only during installation command generation; (2) resolving how to intervene by employing a Package-Name Intervenor that strictly limits the decoding space to an authoritative package list; and (3) ensuring monitoring efficiency through a DFA-Caching Mechanism that enables scalability to millions of packages with negligible overhead. Extensive experiments on five widely used LLMs demonstrate that PackMonitor is a training-free, plug-and-play solution that consistently reduces package hallucination rates to zero while maintaining low-latency inference and preserving original model capabilities.","authors":["Xiting Liu","Yuetong Liu","Yitong Zhang","Jia Li","Shi-Min Hu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20708v1","updated":"2026-02-24T09:13:05Z","published":"2026-02-24T09:13:05Z","title":"ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction","summary":"Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical limitation: over-refusal, prematurely terminating valid agentic workflows. We propose ICON, a probing-to-mitigation framework that neutralizes attacks while preserving task continuity. Our key insight is that IPI attacks leave distinct over-focusing signatures in the latent space. We introduce a Latent Space Trace Prober to detect attacks based on high intensity scores. Subsequently, a Mitigating Rectifier performs surgical attention steering that selectively manipulate adversarial query key dependencies while amplifying task relevant elements to restore the LLM's functional trajectory. Extensive evaluations on multiple backbones show that ICON achieves a competitive 0.4% ASR, matching commercial grade detectors, while yielding a over 50% task utility gain. Furthermore, ICON demonstrates robust Out of Distribution(OOD) generalization and extends effectively to multi-modal agents, establishing a superior balance between security and efficiency.","authors":["Che Wang","Fuyao Zhang","Jiaming Zhang","Ziqi Zhang","Yinghui Wang","Longtao Huang","Jianbo Gao","Zhong Chen","Wei Yang Bryan Lim"],"pdf_url":"","comment":"11 pages,"},{"id":"http://arxiv.org/abs/2510.06868v2","updated":"2026-02-24T09:08:19Z","published":"2025-10-08T10:38:24Z","title":"Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Recovery","summary":"We consider image transmission via deep joint source-channel coding (DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by training a DeepJSCC encoder-decoder pair with a pre-trained deep hash distillation (DHD) module to semantically cluster images, facilitating security-oriented applications through enhanced semantic consistency and improving the perceptual reconstruction quality. We train the DeepJSCC module to both reduce mean square error (MSE) and minimize cosine distance between DHD hashes of source and reconstructed images. Significantly improved perceptual quality as a result of semantic alignment is illustrated for different multi-hop settings, for which classical DeepJSCC may suffer from noise accumulation, measured by the learned perceptual image patch similarity (LPIPS) metric.","authors":["Didrik Bergström","Deniz Gündüz","Onur Günlü"],"pdf_url":"","comment":"Change last word in title, add missing trailing bracket, add additional simulation results in section 4.1; results unchanged"},{"id":"http://arxiv.org/abs/2510.22620v2","updated":"2026-02-24T09:00:11Z","published":"2025-10-26T10:36:42Z","title":"Breaking Agent Backbones: Evaluating the Security of Backbone LLMs in AI Agents","summary":"AI agents powered by large language models (LLMs) are being deployed at scale, yet we lack a systematic understanding of how the choice of backbone LLM affects agent security. The non-deterministic sequential nature of AI agents complicates security modeling, while the integration of traditional software with AI components entangles novel LLM vulnerabilities with conventional security risks. Existing frameworks only partially address these challenges as they either capture specific vulnerabilities only or require modeling of complete agents. To address these limitations, we introduce threat snapshots: a framework that isolates specific states in an agent's execution flow where LLM vulnerabilities manifest, enabling the systematic identification and categorization of security risks that propagate from the LLM to the agent level. We apply this framework to construct the $b^3$ benchmark, a security benchmark based on 194,331 unique crowdsourced adversarial attacks. We then evaluate 34 popular LLMs with it, revealing, among other insights, that enhanced reasoning capabilities improve security, while model size does not correlate with security. We release our benchmark, dataset, and evaluation code to facilitate widespread adoption by LLM providers and practitioners, offering guidance for agent developers and incentivizing model developers to prioritize backbone security improvements.","authors":["Julia Bazinska","Max Mathys","Francesco Casucci","Mateo Rojas-Carulla","Xander Davies","Alexandra Souly","Niklas Pfister"],"pdf_url":"","comment":"Julia Bazinska and Max Mathys contributed equally"},{"id":"http://arxiv.org/abs/2602.20680v1","updated":"2026-02-24T08:34:48Z","published":"2026-02-24T08:34:48Z","title":"Vanishing Watermarks: Diffusion-Based Image Editing Undermines Robust Invisible Watermarking","summary":"Robust invisible watermarking schemes aim to embed hidden information into images such that the watermark survives common manipulations. However, powerful diffusion-based image generation and editing techniques now pose a new threat to these watermarks. In this paper, we present a comprehensive theoretical and empirical analysis demonstrating that diffusion models can effectively erase robust watermarks even when those watermarks were designed to withstand conventional distortions. We show that a diffusion-driven image regeneration process, which leverages generative models to recreate an image, can remove embedded watermarks while preserving the image's perceptual content. Furthermore, we introduce a guided diffusion-based attack that explicitly targets the embedded watermark signal during generation, significantly degrading watermark detectability. Theoretically, we prove that as an image undergoes sufficient diffusion transformations, the mutual information between the watermarked image and the hidden payload approaches zero, leading to inevitable decoding failure. Experimentally, we evaluate multiple state-of-the-art watermarking methods (including deep learning-based schemes like StegaStamp, TrustMark, and VINE) and demonstrate that diffusion edits yield near-zero watermark recovery rates after attack, while maintaining high visual fidelity of the regenerated images. Our findings reveal a fundamental vulnerability in current robust watermarking techniques against generative model-based edits, underscoring the need for new strategies to ensure watermark resilience in the era of powerful diffusion models.","authors":["Fan Guo","Jiyu Kang","Qi Ming","Emily Davis","Finn Carter"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2208.02500v2","updated":"2026-02-24T08:16:42Z","published":"2022-08-04T07:20:00Z","title":"Usability Study of Security Features in Programmable Logic Controllers","summary":"Programmable Logic Controllers (PLCs) drive industrial processes critical to society, for example, water treatment and distribution, electricity and fuel networks. Search engines, e.g., Shodan, have highlighted that PLCs are often left exposed to the Internet, one of the main reasons being the misconfigurations of security settings. This leads to the question - why do these misconfigurations occur and, specifically, whether usability of security controls plays a part. To date, the usability of configuring PLC security mechanisms has not been studied. We present the first investigation through a task based study and subsequent semi-structured interviews (N=19). We explore the usability of PLC connection configurations and two key security mechanisms (i.e., access levels and user administration). We find that the use of unfamiliar labels, layouts and misleading terminology exacerbates an already complex process of configuring security mechanisms. Our results uncover various misperceptions about the security controls and how design constraints, e.g., safety and lack of regular updates due to the long-term nature of such systems, provide significant challenges to the realization of modern HCI and usability principles. Based on these findings, we provide design recommendations to bring usable security in industrial settings at par with its IT counterpart.","authors":["Karen Li","Kopo M. Ramokapane","Awais Rashid"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20663v1","updated":"2026-02-24T08:10:40Z","published":"2026-02-24T08:10:40Z","title":"ICSSPulse: A Modular LLM-Assisted Platform for Industrial Control System Penetration Testing","summary":"It is well established that industrial control systems comprise the operational backbone of modern critical infrastructures, yet their increasing connectivity exposes them to cyber threats that are difficult to study and remedy safely under real-time operational conditions. In this paper, we present ICSSPulse, an open-source, modular, and extensible penetration testing platform designed for the security assessment of ICS communication protocols. To the best of our knowledge, ICSSPulse is the first web-based platform that unifies network scanning, protocol-aware Modbus and OPC~UA interaction, and Large Language Model (LLM)-assisted reporting within a single, lightweight ecosystem. Our platform provides a user-friendly graphical interface that orchestrates enumeration, exploitation, and reporting activities over simulated industrial services, enabling safe and reproducible experimentation. It supports protocol-level discovery, asset enumeration, and controlled read/write interactions, while preserving protocol fidelity and operational transparency. Experimental evaluation using synthetic Modbus test servers, a Factory I/O water treatment scenario, and a custom OPC~UA production-line model demonstrated ICSSPulse's potential to discover active industrial services, enumerate process-relevant assets, and manipulate process variables. A key contribution of this work lies in the integration of an LLM-assisted reporting module that automatically translates technical findings into structured executive and technical reports, with mitigation guidance informed by the ICS MITRE ATT&CK ICS matrix.","authors":["Michail Takaronis","Athanasia Kollarou","Vyron Kampourakis","Vasileios Gkioulos","Sokratis Katsikas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20657v1","updated":"2026-02-24T08:01:20Z","published":"2026-02-24T08:01:20Z","title":"Post-Quantum Sanitizable Signatures from McEliece-Based Chameleon Hashing","summary":"We introduce a novel post-quantum sanitizable signature scheme constructed upon a chameleon hash function derived from the McEliece cryptosystem. In this design, the designated sanitizer possesses the inherent trapdoor of a Goppa code, which facilitates controlled collision-finding via Patterson decoding. This mechanism enables authorized modification of specific message blocks while ensuring all other content remains immutably bound. We provide formal security definitions and rigorous proofs of existential unforgeability and immutability, grounded in the hardness of syndrome decoding in the random-oracle model, where a robust random oracle thwarts trivial linear hash collisions. A key innovation lies in our precise characterization of the transparency property: by imposing a specific weight constraint on the randomizers generated by the signer, we achieve perfect transparency, rendering sanitized signatures indistinguishable from freshly signed ones. This work establishes the first transparent, code-based, post-quantum sanitizable signature scheme, offering strong theoretical guarantees and a pathway for practical deployment in long-term secure applications.","authors":["Shahzad Ahmad","Stefan Rass","Zahra Seyedi"],"pdf_url":"","comment":"19 pages"},{"id":"http://arxiv.org/abs/2602.20595v1","updated":"2026-02-24T06:35:22Z","published":"2026-02-24T06:35:22Z","title":"OptiLeak: Efficient Prompt Reconstruction via Reinforcement Learning in Multi-tenant LLM Services","summary":"Multi-tenant LLM serving frameworks widely adopt shared Key-Value caches to enhance efficiency. However, this creates side-channel vulnerabilities enabling prompt leakage attacks. Prior studies identified these attack surfaces yet focused on expanding attack vectors rather than optimizing attack performance, reporting impractically high attack costs that underestimate the true privacy risk. We propose OptiLeak, a reinforcement learning-enhanced framework that maximizes prompt reconstruction efficiency through two-stage fine-tuning. Our key insight is that domain-specific ``hard tokens'' -- terms difficult to predict yet carrying sensitive information -- can be automatically identified via likelihood ranking and used to construct preference pairs for Direct Preference Optimization, eliminating manual annotation. This enables effective preference alignment while avoiding the overfitting issues of extended supervised fine-tuning. Evaluated on three benchmarks spanning medical and financial domains, OptiLeak achieves up to $12.48\\times$ reduction in average requests per token compared to baseline approaches, with consistent improvements across model scales from 3B to 14B parameters. Our findings demonstrate that cache-based prompt leakage poses a more severe threat than previously reported, underscoring the need for robust cache isolation in production deployments.","authors":["Longxiang Wang","Xiang Zheng","Xuhao Zhang","Yao Zhang","Ye Wu","Cong Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20593v1","updated":"2026-02-24T06:33:29Z","published":"2026-02-24T06:33:29Z","title":"Is the Trigger Essential? A Feature-Based Triggerless Backdoor Attack in Vertical Federated Learning","summary":"As a distributed collaborative machine learning paradigm, vertical federated learning (VFL) allows multiple passive parties with distinct features and one active party with labels to collaboratively train a model. Although it is known for the privacy-preserving capabilities, VFL still faces significant privacy and security threats from backdoor attacks. Existing backdoor attacks typically involve an attacker implanting a trigger into the model during the training phase and executing the attack by adding the trigger to the samples during the inference phase. However, in this paper, we find that triggers are not essential for backdoor attacks in VFL. In light of this, we disclose a new backdoor attack pathway in VFL by introducing a feature-based triggerless backdoor attack. This attack operates under a more stringent security assumption, where the attacker is honest-but-curious rather than malicious during the training phase. It comprises three modules: label inference for the targeted backdoor attack, poison generation with amplification and perturbation mechanisms, and backdoor execution to implement the attack. Extensive experiments on five benchmark datasets demonstrate that our attack outperforms three baseline backdoor attacks by 2 to 50 times while minimally impacting the main task. Even in VFL scenarios with 32 passive parties and only one set of auxiliary data, our attack maintains high performance. Moreover, when confronted with distinct defense strategies, our attack remains largely unaffected and exhibits strong robustness. We hope that the disclosure of this triggerless backdoor attack pathway will encourage the community to revisit security threats in VFL scenarios and inspire researchers to develop more robust and practical defense strategies.","authors":["Yige Liu","Yiwei Lou","Che Wang","Yongzhi Cao","Hanpin Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.12462v2","updated":"2026-02-24T06:17:45Z","published":"2025-10-14T12:52:29Z","title":"Evaluating and Mitigating LLM-as-a-judge Bias in Communication Systems","summary":"Large Language Models (LLMs) are increasingly being used to autonomously evaluate the quality of content in communication systems, e.g., to assess responses in telecom customer support chatbots. However, the impartiality of these AI \"judges\" is not guaranteed, and any biases in their evaluation criteria could skew outcomes and undermine user trust. In this paper, we systematically investigate judgment biases in two LLM-as-a-judge models (i.e., GPT-Judge and JudgeLM) under the point-wise scoring setting, encompassing 11 types of biases that cover both implicit and explicit forms. We observed that state-of-the-art LLM judges demonstrate robustness to biased inputs, generally assigning them lower scores than the corresponding clean samples. Providing a detailed scoring rubric further enhances this robustness. We further found that fine-tuning an LLM on high-scoring yet biased responses can significantly degrade its performance, highlighting the risk of training on biased data. We also discovered that the judged scores correlate with task difficulty: a challenging dataset like GPQA yields lower average scores, whereas an open-ended reasoning dataset (e.g., JudgeLM-val) sees higher average scores. Finally, we proposed four potential mitigation strategies to ensure fair and reliable AI judging in practical communication scenarios.","authors":["Jiaxin Gao","Chen Chen","Yanwen Jia","Xueluan Gong","Kwok-Yan Lam","Qian Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20580v1","updated":"2026-02-24T06:02:03Z","published":"2026-02-24T06:02:03Z","title":"Personal Information Parroting in Language Models","summary":"Modern language models (LM) are trained on large scrapes of the Web, containing millions of personal information (PI) instances, many of which LMs memorize, increasing privacy risks. In this work, we develop the regexes and rules (R&R) detector suite to detect email addresses, phone numbers, and IP addresses, which outperforms the best regex-based PI detectors. On a manually curated set of 483 instances of PI, we measure memorization: finding that 13.6% are parroted verbatim by the Pythia-6.9b model, i.e., when the model is prompted with the tokens that precede the PI in the original document, greedy decoding generates the entire PI span exactly. We expand this analysis to study models of varying sizes (160M-6.9B) and pretraining time steps (70k-143k iterations) in the Pythia model suite and find that both model size and amount of pretraining are positively correlated with memorization. Even the smallest model, Pythia-160m, parrots 2.7% of the instances exactly. Consequently, we strongly recommend that pretraining datasets be aggressively filtered and anonymized to minimize PI parroting.","authors":["Nishant Subramani","Kshitish Ghate","Mona Diab"],"pdf_url":"","comment":"EACL Findings 2026"},{"id":"http://arxiv.org/abs/2601.03868v2","updated":"2026-02-24T04:21:01Z","published":"2026-01-07T12:31:52Z","title":"What Matters For Safety Alignment?","summary":"This paper presents a comprehensive empirical study on the safety alignment capabilities. We evaluate what matters for safety alignment in LLMs and LRMs to provide essential insights for developing more secure and reliable AI systems. We systematically investigate and compare the influence of six critical intrinsic model characteristics and three external attack techniques. Our large-scale evaluation is conducted using 32 recent, popular LLMs and LRMs across thirteen distinct model families, spanning a parameter scale from 3B to 235B. The assessment leverages five established safety datasets and probes model vulnerabilities with 56 jailbreak techniques and four CoT attack strategies, resulting in 4.6M API calls. Our key empirical findings are fourfold. First, we identify the LRMs GPT-OSS-20B, Qwen3-Next-80B-A3B-Thinking, and GPT-OSS-120B as the top-three safest models, which substantiates the significant advantage of integrated reasoning and self-reflection mechanisms for robust safety alignment. Second, post-training and knowledge distillation may lead to a systematic degradation of safety alignment. We thus argue that safety must be treated as an explicit constraint or a core optimization objective during these stages, not merely subordinated to the pursuit of general capability. Third, we reveal a pronounced vulnerability: employing a CoT attack via a response prefix can elevate the attack success rate by 3.34x on average and from 0.6% to 96.3% for Seed-OSS-36B-Instruct. This critical finding underscores the safety risks inherent in text-completion interfaces and features that allow user-defined response prefixes in LLM services, highlighting an urgent need for architectural and deployment safeguards. Fourth, roleplay, prompt injection, and gradient-based search for adversarial prompts are the predominant methodologies for eliciting unaligned behaviors in modern models.","authors":["Xing Li","Hui-Ling Zhen","Lihao Yin","Xianzhi Yu","Zhenhua Dong","Mingxuan Yuan"],"pdf_url":"","comment":"Added more commercial model results, majority voting scores, and theoretical analysis in v2"},{"id":"http://arxiv.org/abs/2511.11851v2","updated":"2026-02-24T03:50:56Z","published":"2025-11-14T20:16:00Z","title":"Defending Unauthorized Model Merging via Dual-Stage Weight Protection","summary":"The rapid proliferation of pretrained models and open repositories has made model merging a convenient yet risky practice, allowing free-riders to combine fine-tuned models into a new multi-capability model without authorization. Such unauthorized model merging not only violates intellectual property rights but also undermines model ownership and accountability. To address this issue, we present MergeGuard, a proactive dual-stage weight protection framework that disrupts merging compatibility while maintaining task fidelity. In the first stage, we redistribute task-relevant information across layers via L2-regularized optimization, ensuring that important gradients are evenly dispersed. In the second stage, we inject structured perturbations to misalign task subspaces, breaking curvature compatibility in the loss landscape. Together, these stages reshape the model's parameter geometry such that merged models collapse into destructive interference while the protected model remains fully functional. Extensive experiments on both vision (ViT-L-14) and language (Llama2, Gemma2, Mistral) models demonstrate that MergeGuard reduces merged model accuracy by up to 90% with less than 1.5% performance loss on the protected model.","authors":["Wei-Jia Chen","Min-Yen Tsai","Cheng-Yi Lee","Chia-Mu Yu"],"pdf_url":"","comment":"Accepted at CVPR 2026"},{"id":"http://arxiv.org/abs/2602.20521v1","updated":"2026-02-24T03:49:12Z","published":"2026-02-24T03:49:12Z","title":"Towards Secure and Efficient DNN Accelerators via Hardware-Software Co-Design","summary":"The rapid deployment of deep neural network (DNN) accelerators in safety-critical domains such as autonomous vehicles, healthcare systems, and financial infrastructure necessitates robust mechanisms to safeguard data confidentiality and computational integrity. Existing security solutions for DNN accelerators, however, suffer from excessive hardware resource demands and frequent off-chip memory access overheads, which degrade performance and scalability.\n  To address these challenges, this paper presents a secure and efficient memory protection framework for DNN accelerators with minimal overhead. First, we propose a bandwidth-aware cryptographic scheme that adapts encryption granularity based on memory traffic patterns, striking a balance between security and resource efficiency. Second, we observe that both the overlapping regions in the intra-layer tiling's sliding window pattern and those resulting from inter-layer tiling strategy discrepancies introduce substantial redundant memory accesses and repeated computational overhead in cryptography. Third, we introduce a multi-level authentication mechanism that effectively eliminates unnecessary off-chip memory accesses, enhancing performance and energy efficiency. Experimental results show that this work decreases performance overhead by over 12% and achieves 87% energy efficiency improvement for both server and edge neural processing units (NPUs), while ensuring robust scalability.","authors":["Wei Xuan","Zihao Xuan","Rongliang Fu","Ning Lin","Kwunhang Wong","Zikang Yuan","Lang Feng","Zhongrui Wang","Tsung-Yi Ho","Yuzhong Jiao","Luhong Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.06612v2","updated":"2026-02-24T03:32:35Z","published":"2026-02-06T11:14:53Z","title":"HYDRA: Unearthing \"Black Swan\" Vulnerabilities in LEO Satellite Networks","summary":"As Low Earth Orbit (LEO) become mega-constellations critical infrastructure, attacks targeting them have grown in number and range. The security analysis of LEO constellations faces a fundamental paradigm gap: traditional topology-centric methods fail to capture systemic risks arising from dynamic load imbalances and high-order dependencies, which can transform localized failures into network-wide cascades. To address this, we propose HYDRA, a hypergraph-based dynamic risk analysis framework. Its core is a novel metric, Hyper-Bridge Centrality (HBC), which quantifies node criticality via a load-to-redundancy ratio within dependency structures. A primary challenge to resilience: the most critical vulnerabilities are not in the densely connected satellite core, but in the seemingly marginal ground-space interfaces. These are the system's \"Black Swan\" nodes--topologically peripheral yet structurally lethal. We validate this through extensive simulations using realistic StarLink TLE data and population-based gravity model. Experiments demonstrate that HBC consistently outperforms traditional metrics, identifying critical failure points that surpass the structural damage potential of even betweenness centrality. This work shifts the security paradigm from connectivity to structural stress, demonstrating that securing the network edge is paramount and necessitates a fundamental redesign of redundancy strategies.","authors":["Bintao Yuan","Mingsheng Tang","Binbin Ge","Hongbin Luo","Zijie Yan"],"pdf_url":"","comment":"18 pages, 13 figures"},{"id":"http://arxiv.org/abs/2602.18464v2","updated":"2026-02-24T03:18:00Z","published":"2026-02-06T21:57:08Z","title":"How Well Can LLM Agents Simulate End-User Security and Privacy Attitudes and Behaviors?","summary":"A growing body of research assumes that large language model (LLM) agents can serve as proxies for how people form attitudes toward and behave in response to security and privacy (S&P) threats. If correct, these simulations could offer a scalable way to forecast S&P risks in products prior to deployment. We interrogate this assumption using SP-ABCBench, a new benchmark of 30 tests derived from validated S&P human-subject studies, which measures alignment between simulations and human-subjects studies on a 0-100 ascending scale, where higher scores indicate better alignment across three dimensions: Attitude, Behavior, and Coherence. Evaluating twelve LLMs, four persona construction strategies, and two prompting methods, we found that there remains substantial room for improvement: all models score between 50 and 64 on average. Newer, bigger, and smarter models do not reliably do better and sometimes do worse. Some simulation configurations, however, do yield high alignment: e.g., with scores above 95 for some behavior tests when agents are prompted to apply bounded rationality and weigh privacy costs against perceived benefits. We release SP-ABCBench to enable reproducible evaluation as methods improve.","authors":["Yuxuan Li","Leyang Li","Hao-Ping Lee","Sauvik Das"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.19154v3","updated":"2026-02-24T02:33:18Z","published":"2026-01-27T03:35:03Z","title":"Analysis of Shuffling Beyond Pure Local Differential Privacy","summary":"Shuffling is a powerful way to amplify privacy of a local randomizer in private distributed data analysis. Most existing analyses of how shuffling amplifies privacy are based on the pure local differential privacy (DP) parameter $\\varepsilon_0$. This paper raises the question of whether $\\varepsilon_0$ adequately captures the privacy amplification. For example, since the Gaussian mechanism does not satisfy pure local DP for any finite $\\varepsilon_0$, does it follow that shuffling yields weak amplification? To solve this problem, we revisit the privacy blanket bound of Balle et al. (the blanket divergence) and develop a direct asymptotic analysis that bypasses $\\varepsilon_0$. Our key finding is that, asymptotically, the blanket divergence depends on the local mechanism only through a single scalar parameter $χ$ and that this dependence is monotonic. Therefore, this parameter serves as a proxy for shuffling efficiency, which we call the shuffle index. By applying this analysis to both upper and lower bounds of the shuffled mechanism's privacy profile, we obtain a band for its privacy guarantee through shuffle indices. Furthermore, we derive a simple structural, necessary and sufficient condition on the local randomizer under which this band collapses asymptotically. $k$-RR families with $k\\ge3$ satisfy this condition, while for generalized Gaussian mechanisms the condition may not hold but the resulting band remains tight. Finally, we complement the asymptotic theory with an FFT-based algorithm for computing the blanket divergence at finite $n$, which offers rigorously controlled relative error and near-linear running time in $n$, providing a practical numerical analysis for shuffle DP.","authors":["Shun Takagi","Seng Pei Liew"],"pdf_url":"","comment":"Minor revision"},{"id":"http://arxiv.org/abs/2602.14281v3","updated":"2026-02-24T02:08:48Z","published":"2026-02-15T19:10:00Z","title":"MCPShield: A Security Cognition Layer for Adaptive Trust Calibration in Model Context Protocol Agents","summary":"The Model Context Protocol (MCP) standardizes tool use for LLM-based agents and enable third-party servers. This openness introduces a security misalignment: agents implicitly trust tools exposed by potentially untrusted MCP servers. However, despite its excellent utility, existing agents typically offer limited validation for third-party MCP servers. As a result, agents remain vulnerable to MCP-based attacks that exploit the misalignment between agents and servers throughout the tool invocation lifecycle. In this paper, we propose MCPShield as a plug-in security cognition layer that mitigates this misalignment and ensures agent security when invoking MCP-based tools. Drawing inspiration from human experience-driven tool validation, MCPShield assists agent forms security cognition with metadata-guided probing before invocation. Our method constrains execution within controlled boundaries while cognizing runtime events, and subsequently updates security cognition by reasoning over historical traces after invocation, building on human post-use reflection on tool behavior. Experiments demonstrate that MCPShield exhibits strong generalization in defending against six novel MCP-based attack scenarios across six widely used agentic LLMs, while avoiding false positives on benign servers and incurring low deployment overhead. Overall, our work provides a practical and robust security safeguard for MCP-based tool invocation in open agent ecosystems.","authors":["Zhenhong Zhou","Yuanhe Zhang","Hongwei Cai","Moayad Aloqaily","Ouns Bouachir","Linsey Pang","Prakhar Mehrotra","Kun Wang","Qingsong Wen"],"pdf_url":"","comment":"21 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2602.20446v1","updated":"2026-02-24T01:15:18Z","published":"2026-02-24T01:15:18Z","title":"Understanding Human-AI Collaboration in Cybersecurity Competitions","summary":"Capture-the-Flag (CTF) competitions are increasingly becoming a testbed for evaluating AI capabilities at solving security tasks, due to the controlled environments and objective success criteria. Existing evaluations have focused on how successful AI is at solving CTF challenges in isolation from human CTF players. As AI usage increases in both academic and industrial settings, it is equally likely that human players may collaborate with AI agents to solve challenges. This possibility exposes a key knowledge gap: how do humans perceive AI CTF assistance; when assistance is provided, how do they collaborate and is it effective with respect to human performance; how do humans assisted by AI compare to the performance of fully autonomous AI agents on the same challenges. We address this gap with the first empirical study of AI assistance in a live, onsite CTF. In a study with 41 participants, we qualitatively study (i) how participants' perception, trust, and expectations shift before versus after hands-on AI use, and (ii) how participants collaborate with an instrumented AI agent. Moreover, we also (iii) benchmark four autonomous AI agents on the same fresh challenge set to compare outcomes with human teams and analyze agent trajectories. We find that, as the competition progresses, teams increasingly delegate larger subtasks to the AI, giving it more agency. Interestingly, CTF challenges solving rates are often constrained not by model's reasoning capabilities, but rather by the human players: ineffective prompting and poor context specification become the primary bottleneck. Remarkably, autonomous agents that self-direct their prompting and tool use bypass this bottleneck and outperform most human teams, coming in second overall in the competition. We conclude with implications for the future design of CTF challenges and for building effective human-in-the-loop AI systems for security.","authors":["Tingxuan Tang","Nicolas Janis","Kalyn Asher Montague","Kevin Eykholt","Dhilung Kirat","Youngja Park","Jiyong Jang","Adwait Nadkarni","Yue Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21447v1","updated":"2026-02-24T23:52:27Z","published":"2026-02-24T23:52:27Z","title":"Adversarial Intent is a Latent Variable: Stateful Trust Inference for Securing Multimodal Agentic RAG","summary":"Current stateless defences for multimodal agentic RAG fail to detect adversarial strategies that distribute malicious semantics across retrieval, planning, and generation components. We formulate this security challenge as a Partially Observable Markov Decision Process (POMDP), where adversarial intent is a latent variable inferred from noisy multi-stage observations. We introduce MMA-RAG^T, an inference-time control framework governed by a Modular Trust Agent (MTA) that maintains an approximate belief state via structured LLM reasoning. Operating as a model-agnostic overlay, MMA-RAGT mediates a configurable set of internal checkpoints to enforce stateful defence-in-depth. Extensive evaluation on 43,774 instances demonstrates a 6.50x average reduction factor in Attack Success Rate relative to undefended baselines, with negligible utility cost. Crucially, a factorial ablation validates our theoretical bounds: while statefulness and spatial coverage are individually necessary (26.4 pp and 13.6 pp gains respectively), stateless multi-point intervention can yield zero marginal benefit under homogeneous stateless filtering when checkpoint detections are perfectly correlated.","authors":["Inderjeet Singh","Vikas Pahuja","Aishvariya Priya Rathina Sabapathy","Chiara Picardi","Amit Giloni","Roman Vainshtein","Andrés Murillo","Hisashi Kojima","Motoyoshi Sekiya","Yuki Unno","Junichi Suga"],"pdf_url":"","comment":"13 pages, 2 figures, 5 tables"},{"id":"http://arxiv.org/abs/2211.02003v3","updated":"2026-02-24T22:04:08Z","published":"2022-11-03T17:16:20Z","title":"Private Blind Model Averaging - Distributed, Non-interactive, and Convergent","summary":"Distributed differentially private learning techniques enable a large number of users to jointly learn a model without having to first centrally collect the training data. At the same time, neither the communication between the users nor the resulting model shall leak information about the training data. This kind of learning technique can be deployed to edge devices if it can be scaled up to a large number of users, particularly if the communication is reduced to a minimum: no interaction, i.e., each party only sends a single message. The best previously known methods are based on gradient averaging, which inherently requires many synchronization rounds. A promising non-interactive alternative to gradient averaging relies on so-called output perturbation: each user first locally finishes training and then submits its model for secure averaging without further synchronization. We analyze this paradigm, which we coin blind model averaging (BlindAvg), in the setting of convex and smooth empirical risk minimization (ERM) like a support vector machine (SVM). While the required noise scale is asymptotically the same as in the centralized setting, it is not well understood how close BlindAvg comes to centralized learning, i.e., its utility cost. We characterize and boost the privacy-utility tradeoff of BlindAvg with two contributions: First, we prove that BlindAvg converges towards the centralized setting for a sufficiently strong L2-regularization for a non-smooth SVM learner. Second, we introduce the novel differentially private convex and smooth ERM learner SoftmaxReg that has a better privacy-utility tradeoff than an SVM in a multi-class setting. We evaluate our findings on three datasets (CIFAR-10, CIFAR-100, and Federated EMNIST) and provide an ablation in an artificially extreme non-IID scenario.","authors":["Moritz Kirschte","Sebastian Meiser","Saman Ardalan","Esfandiar Mohammadi"],"pdf_url":"","comment":"This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore"},{"id":"http://arxiv.org/abs/2507.12652v2","updated":"2026-02-24T22:02:23Z","published":"2025-07-16T21:59:25Z","title":"Federated Learning in Offline and Online EMG Decoding: A Privacy and Performance Perspective","summary":"Neural interfaces offer a pathway to intuitive, high-bandwidth interaction, but the sensitive nature of neural data creates significant privacy hurdles for large-scale model training. Federated learning (FL) has emerged as a promising privacy-preserving solution, yet its efficacy in real-time, online neural interfaces remains unexplored. In this study, we 1) propose a conceptual framework for applying FL to the distinct constraints of neural interface application and 2) provide a systematic evaluation of FL-based neural decoding using high-dimensional electromyography (EMG) across both offline simulations and a real-time, online user study. While offline results suggest that FL can simultaneously enhance performance and privacy, our online experiments reveal a more complex landscape. We found that standard FL assumptions struggle to translate to real-time, sequential interactions with human-decoder co-adaptation. Our results show that while FL retains privacy advantages, it introduces performance tensions not predicted by offline simulations. These findings identify a critical gap in current FL methodologies and highlight the need for specialized algorithms designed to navigate the unique co-adaptive dynamics of sequential-user neural decoding.","authors":["Kai Malcolm","César Uribe","Momona Yamagami"],"pdf_url":"","comment":"23 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.21394v1","updated":"2026-02-24T21:50:46Z","published":"2026-02-24T21:50:46Z","title":"MemoPhishAgent: Memory-Augmented Multi-Modal LLM Agent for Phishing URL Detection","summary":"Traditional phishing website detection relies on static heuristics or reference lists, which lag behind rapidly evolving attacks. While recent systems incorporate large language models (LLMs), they are still prompt-based, deterministic pipelines that underutilize reasoning capability. We present MemoPhishAgent (MPA), a memory-augmented multi-modal LLM agent that dynamically orchestrates phishing-specific tools and leverages episodic memories of past reasoning trajectories to guide decisions on recurring and novel threats. On two public datasets, MPA outperforms three state-of-the-art (SOTA) baselines, improving recall by 13.6%. To better reflect realistic, user-facing phishing detection performance, we further evaluate MPA on a benchmark of real-world suspicious URLs actively crawled from five social media platforms, where it improves recall by 20%. Detailed analysis shows episodic memory contributes up to 27% recall gain without introducing additional computational overhead. The ablation study confirms the necessity of the agent-based approach compared to prompt-based baselines and validates the effectiveness of our tool design. Finally, MPA is deployed in production, processing 60K targeted high-risk URLs weekly, and achieving 91.44% recall, providing proactive protection for millions of customers. Together, our results show that combining multi-modal reasoning with episodic memory yields robust phishing detection in realistic user-exposure settings.","authors":["Xuan Chen","Hao Liu","Yuan Tao","Mehran Kafai","Piotr Habas","Xiangyu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21386v1","updated":"2026-02-24T21:28:37Z","published":"2026-02-24T21:28:37Z","title":"Evaluating the Indistinguishability of Logic Locking using K-Cut Enumeration and Boolean Matching","summary":"Logic locking as a solution for semiconductor intellectual property (IP) confidentiality has received considerable attention in academia, but has yet to produce a viable solution to protect against known threats. In part due to a lack of rigor, logic locking defenses have been historically short-lived, which is an unacceptable risk for hardware-based security solutions for critical systems that may be fielded for decades. Researchers have worked to map the concept of cryptographic indistinguishability to logic locking, as indistinguishability provides strong security guarantees. In an effort to bridge theory and practice, we highlight recent efforts that can be used to analyze the indistinguishability of logic locking techniques, and propose a new method of evaluation based on comparing distributions of $k$-cuts, which is akin to comparing against a library of sub-functions. We evaluate our approach on several different classes of logic locking and show up to 92% average accuracy in correctly identifying which design was locked, even in the presence of resynthesis, suggesting that the evaluated locks do not provide indistinguishability.","authors":["Jonathan Cruz","Jason Hamlet"],"pdf_url":"","comment":"6 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2509.08747v2","updated":"2026-02-24T19:36:17Z","published":"2025-09-03T14:37:58Z","title":"Silent Until Sparse: Backdoor Attacks on Semi-Structured Sparsity","summary":"Semi-structured (2:4) sparsity is a widely adopted pruning method in modern hardware and software ecosystems (e.g., NVIDIA Sparse Tensor Cores and PyTorch), achieving up to 2X faster inference and reduced memory footprint with negligible accuracy loss. It removes two out of every four contiguous weights, using permutations to ensure the largest-magnitude weights are retained. In this work, we show that this predictable mechanism can be exploited to design Silent Until Sparse (SUS), a novel compression-activated backdoor attack tailored to the 2:4 sparsity regime. SUS employs a two-phase training procedure that modifies (i) the weights that will be retained after pruning to embed the backdoor, and (ii) the weights that will be pruned to hide it in the dense model. SUS also provides formal guarantees that the attack will be successfully activated after sparsification. Experiments show that SUS is largely effective against semi-structured sparsification across both hardware-accelerated and software pipelines, outperforming existing compression-aware backdoor attacks, bypassing standard defenses, and even being robust to user-side fine-tuning.","authors":["Wei Guo","Fabio Brau","Maura Pintor","Ambra Demontis","Battista Biggio"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21267v1","updated":"2026-02-24T11:48:07Z","published":"2026-02-24T11:48:07Z","title":"A Systematic Review of Algorithmic Red Teaming Methodologies for Assurance and Security of AI Applications","summary":"Cybersecurity threats are becoming increasingly sophisticated, making traditional defense mechanisms and manual red teaming approaches insufficient for modern organizations. While red teaming has long been recognized as an effective method to identify vulnerabilities by simulating real-world attacks, its manual execution is resource-intensive, time-consuming, and lacks scalability for frequent assessments. These limitations have driven the evolution toward auto-mated red teaming, which leverages artificial intelligence and automation to deliver efficient and adaptive security evaluations. This systematic review consolidates existing research on automated red teaming, examining its methodologies, tools, benefits, and limitations. The paper also highlights current trends, challenges, and research gaps, offering insights into future directions for improving automated red teaming as a critical component of proactive cybersecurity strategies. By synthesizing findings from diverse studies, this review aims to provide a comprehensive understanding of how automation enhances red teaming and strengthens organizational resilience against evolving cyber threats.","authors":["Shruti Srivastava","Kiranmayee Janardhan","Shaurya Jauhari"],"pdf_url":"","comment":"39 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.22250v1","updated":"2026-02-24T20:06:45Z","published":"2026-02-24T20:06:45Z","title":"A Lightweight Defense Mechanism against Next Generation of Phishing Emails using Distilled Attention-Augmented BiLSTM","summary":"The current generation of large language models produces sophisticated social-engineering content that bypasses standard text screening systems in business communication platforms. Our proposed solution for mail gateway and endpoint deception detection operates in a privacy-protective manner while handling the performance requirements of network and mobile security systems. The MobileBERT teacher receives fine-tuning before its transformation into a BiLSTM model with multi-head attention which maintains semantic discrimination only with 4.5 million parameters. The hybrid dataset contains human-written messages together with LLM-generated paraphrases that use masking techniques and personalization methods to enhance modern attack resistance. The evaluation system uses five testing protocols which include human-only and LLM-only tests and two cross-distribution transfer tests and a production-like mixed traffic test to assess performance in native environments and across different distribution types and combined traffic scenarios. The distilled model maintains a weighted-F1 score difference of 1-2.5 points compared to the mixture split results of strong transformer baselines including ModernBERT, DeBERTaV3-base, T5-base, DeepSeek-R1 Distill Qwen-1.5B and Phi-4 mini while achieving 80-95\\% faster inference times and 95-99\\% smaller model sizes. The system demonstrates excellent performance in terms of accuracy and latency while maintaining a compact size which enables real-time filtering without acceleration hardware and supports policy-based management. The paper examines system performance under high traffic conditions and security measures for privacy protection and implementation methods for operational deployment.","authors":["Morteza Eskandarian","Mahdi Rabbani","Arun Kaniyamattam","Fatemeh Nejati","Mansur Mirani","Gunjan Piya","Igor Opushnyev","Ali A. Ghorbani","Sajjad Dadkhah"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22246v1","updated":"2026-02-24T15:47:52Z","published":"2026-02-24T15:47:52Z","title":"Self-Purification Mitigates Backdoors in Multimodal Diffusion Language Models","summary":"Multimodal Diffusion Language Models (MDLMs) have recently emerged as a competitive alternative to their autoregressive counterparts. Yet their vulnerability to backdoor attacks remains largely unexplored. In this work, we show that well-established data-poisoning pipelines can successfully implant backdoors into MDLMs, enabling attackers to manipulate model behavior via specific triggers while maintaining normal performance on clean inputs. However, defense strategies effective to these models are yet to emerge. To bridge this gap, we introduce a backdoor defense framework for MDLMs named DiSP (Diffusion Self-Purification). DiSP is driven by a key observation: selectively masking certain vision tokens at inference time can neutralize a backdoored model's trigger-induced behaviors and restore normal functionality. Building on this, we purify the poisoned dataset using the compromised model itself, then fine-tune the model on the purified data to recover it to a clean one. Given such a specific design, DiSP can remove backdoors without requiring any auxiliary models or clean reference data. Extensive experiments demonstrate that our approach effectively mitigates backdoor effects, reducing the attack success rate (ASR) from over 90% to typically under 5%, while maintaining model performance on benign tasks.","authors":["Guangnian Wan","Qi Li","Gongfan Fang","Xinyin Ma","Xinchao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22244v1","updated":"2026-02-24T14:48:50Z","published":"2026-02-24T14:48:50Z","title":"Accelerating Incident Response: A Hybrid Approach for Data Breach Reporting","summary":"The General Data Protection Regulation (GDPR) requires organisations to notify supervisory authorities of personal data breaches within 72 hours of discovery. Meeting this strict deadline is challenging because incident responders must manually translate low-level forensic artefacts such as malware traces, system-call logs, and network captures into the structured, legally framed information required by data-protection authorities. This gap between technical evidence and regulatory reporting often results in delays, incomplete notifications, and a high cognitive burden on analysts. We propose a hybrid malware analysis pipeline that automates the extraction and organisation of breach-relevant information, with a particular focus on exfiltration-oriented Linux/ARM malware, which is rapidly increasing in prevalence due to the widespread adoption of IoT and embedded devices. The system combines static analysis to identify potential exfiltrators with dynamic analysis to reconstruct their behaviour. It employs a Large Language Model (LLM) constrained by a formal JSON schema aligned with the official Italian Garante Privacy notification form. The LLM transforms heterogeneous forensic artefacts into a structured, compliance-ready report that a human operator can rapidly validate.","authors":["Aurora Arrus","Maria di Gisi","Sara Lilli","Marco Quadrini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22242v1","updated":"2026-02-24T12:32:11Z","published":"2026-02-24T12:32:11Z","title":"Analysis of LLMs Against Prompt Injection and Jailbreak Attacks","summary":"Large Language Models (LLMs) are widely deployed in real-world systems. Given their broader applicability, prompt engineering has become an efficient tool for resource-scarce organizations to adopt LLMs for their own purposes. At the same time, LLMs are vulnerable to prompt-based attacks. Thus, analyzing this risk has become a critical security requirement. This work evaluates prompt-injection and jailbreak vulnerability using a large, manually curated dataset across multiple open-source LLMs, including Phi, Mistral, DeepSeek-R1, Llama 3.2, Qwen, and Gemma variants. We observe significant behavioural variation across models, including refusal responses and complete silent non-responsiveness triggered by internal safety mechanisms. Furthermore, we evaluated several lightweight, inference-time defence mechanisms that operate as filters without any retraining or GPU-intensive fine-tuning. Although these defences mitigate straightforward attacks, they are consistently bypassed by long, reasoning-heavy prompts.","authors":["Piyush Jaiswal","Aaditya Pratap","Shreyansh Saraswati","Harsh Kasyap","Somanath Tripathy"],"pdf_url":"","comment":"12 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2602.22238v1","updated":"2026-02-24T05:48:09Z","published":"2026-02-24T05:48:09Z","title":"TT-SEAL: TTD-Aware Selective Encryption for Adversarially-Robust and Low-Latency Edge AI","summary":"Cloud-edge AI must jointly satisfy model compression and security under tight device budgets. While Tensor-Train Decomposition (TTD) shrinks on-device models, prior selective-encryption studies largely assume dense weights, leaving its practicality under TTD compression unclear. We present TT-SEAL, a selective-encryption framework for TT-decomposed networks. TT-SEAL ranks TT cores with a sensitivity-based importance metric, calibrates a one-time robustness threshold, and uses a value-DP optimizer to encrypt the minimum set of critical cores with AES. Under TTD-aware, transfer-based threat models (and on an FPGA-prototyped edge processor) TT-SEAL matches the robustness of full (black-box) encryption while encrypting as little as 4.89-15.92% of parameters across ResNet-18, MobileNetV2, and VGG-16, and drives the share of AES decryption in end-to-end latency to low single digits (e.g., 58% -> 2.76% on ResNet-18), enabling secure, low-latency edge AI.","authors":["Kyeongpil Min","Sangmin Jeon","Jae-Jin Lee","Woojoo Lee"],"pdf_url":"","comment":"8 pages, 7 figures, 3 tables. This paper has been accepted at Design Automation Conference (DAC) 2026"}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2602.21203v1","updated":"2026-02-24T18:58:11Z","published":"2026-02-24T18:58:11Z","title":"Squint: Fast Visual Reinforcement Learning for Sim-to-Real Robotics","summary":"Visual reinforcement learning is appealing for robotics but expensive -- off-policy methods are sample-efficient yet slow; on-policy methods parallelize well but waste samples. Recent work has shown that off-policy methods can train faster than on-policy methods in wall-clock time for state-based control. Extending this to vision remains challenging, where high-dimensional input images complicate training dynamics and introduce substantial storage and encoding overhead. To address these challenges, we introduce Squint, a visual Soft Actor Critic method that achieves faster wall-clock training than prior visual off-policy and on-policy methods. Squint achieves this via parallel simulation, a distributional critic, resolution squinting, layer normalization, a tuned update-to-data ratio, and an optimized implementation. We evaluate on the SO-101 Task Set, a new suite of eight manipulation tasks in ManiSkill3 with heavy domain randomization, and demonstrate sim-to-real transfer to a real SO-101 robot. We train policies for 15 minutes on a single RTX 3090 GPU, with most tasks converging in under 6 minutes.","authors":["Abdulaziz Almuzairee","Henrik I. Christensen"],"pdf_url":"","comment":"For website and code, see https://aalmuzairee.github.io/squint"},{"id":"http://arxiv.org/abs/2602.21198v1","updated":"2026-02-24T18:55:18Z","published":"2026-02-24T18:55:18Z","title":"Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs","summary":"Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: \\textit{reflection-in-action}, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and \\textit{reflection-on-action}, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.","authors":["Yining Hong","Huang Huang","Manling Li","Li Fei-Fei","Jiajun Wu","Yejin Choi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21174v1","updated":"2026-02-24T18:18:36Z","published":"2026-02-24T18:18:36Z","title":"Efficient Hierarchical Any-Angle Path Planning on Multi-Resolution 3D Grids","summary":"Hierarchical, multi-resolution volumetric mapping approaches are widely used to represent large and complex environments as they can efficiently capture their occupancy and connectivity information. Yet widely used path planning methods such as sampling and trajectory optimization do not exploit this explicit connectivity information, and search-based methods such as A* suffer from scalability issues in large-scale high-resolution maps. In many applications, Euclidean shortest paths form the underpinning of the navigation system. For such applications, any-angle planning methods, which find optimal paths by connecting corners of obstacles with straight-line segments, provide a simple and efficient solution. In this paper, we present a method that has the optimality and completeness properties of any-angle planners while overcoming computational tractability issues common to search-based methods by exploiting multi-resolution representations. Extensive experiments on real and synthetic environments demonstrate the proposed approach's solution quality and speed, outperforming even sampling-based methods. The framework is open-sourced to allow the robotics and planning community to build on our research.","authors":["Victor Reijgwart","Cesar Cadena","Roland Siegwart","Lionel Ott"],"pdf_url":"","comment":"12 pages, 9 figures, 4 tables, accepted to RSS 2025, code is open-source: https://github.com/ethz-asl/wavestar"},{"id":"http://arxiv.org/abs/2602.21161v1","updated":"2026-02-24T18:07:06Z","published":"2026-02-24T18:07:06Z","title":"ActionReasoning: Robot Action Reasoning in 3D Space with LLM for Robotic Brick Stacking","summary":"Classical robotic systems typically rely on custom planners designed for constrained environments. While effective in restricted settings, these systems lack generalization capabilities, limiting the scalability of embodied AI and general-purpose robots. Recent data-driven Vision-Language-Action (VLA) approaches aim to learn policies from large-scale simulation and real-world data. However, the continuous action space of the physical world significantly exceeds the representational capacity of linguistic tokens, making it unclear if scaling data alone can yield general robotic intelligence. To address this gap, we propose ActionReasoning, an LLM-driven framework that performs explicit action reasoning to produce physics-consistent, prior-guided decisions for robotic manipulation. ActionReasoning leverages the physical priors and real-world knowledge already encoded in Large Language Models (LLMs) and structures them within a multi-agent architecture. We instantiate this framework on a tractable case study of brick stacking, where the environment states are assumed to be already accurately measured. The environmental states are then serialized and passed to a multi-agent LLM framework that generates physics-aware action plans. The experiments demonstrate that the proposed multi-agent LLM framework enables stable brick placement while shifting effort from low-level domain-specific coding to high-level tool invocation and prompting, highlighting its potential for broader generalization. This work introduces a promising approach to bridging perception and execution in robotic manipulation by integrating physical reasoning with LLMs.","authors":["Guangming Wang","Qizhen Ying","Yixiong Jing","Olaf Wysocki","Brian Sheil"],"pdf_url":"","comment":"8 pages, 5 figures, accepted by the 2026 IEEE International Conference on Robotics and Automation"},{"id":"http://arxiv.org/abs/2602.21157v1","updated":"2026-02-24T18:04:31Z","published":"2026-02-24T18:04:31Z","title":"HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning","summary":"Vision-Language-Action (VLA) models have shown strong performance in robotic manipulation, but often struggle in long-horizon or out-of-distribution scenarios due to the lack of explicit mechanisms for multimodal reasoning and anticipating how the world will evolve under action. Recent works introduce textual chain-of-thought or visual subgoal prediction within VLA models to reason, but still fail to offer a unified human-like reasoning framework for joint textual reasoning, visual foresight, and action prediction. To this end, we propose HALO, a unified VLA model that enables embodied multimodal chain-of-thought (EM-CoT) reasoning through a sequential process of textual task reasoning, visual subgoal prediction for fine-grained guidance, and EM-CoT-augmented action prediction. We instantiate HALO with a Mixture-of-Transformers (MoT) architecture that decouples semantic reasoning, visual foresight, and action prediction into specialized experts while allowing seamless cross-expert collaboration. To enable HALO learning at scale, we introduce an automated pipeline to synthesize EM-CoT training data along with a carefully crafted training recipe. Extensive experiments demonstrate that: (1) HALO achieves superior performance in both simulated and real-world environments, surpassing baseline policy pi_0 by 34.1% on RoboTwin benchmark; (2) all proposed components of the training recipe and EM-CoT design help improve task success rate; and (3) HALO exhibits strong generalization capabilities under aggressive unseen environmental randomization with our proposed EM-CoT reasoning.","authors":["Quanxin Shou","Fangqi Zhu","Shawn Chen","Puxin Yan","Zhengyang Yan","Yikun Miao","Xiaoyi Pang","Zicong Hong","Ruikai Shi","Hao Huang","Jie Zhang","Song Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20159v2","updated":"2026-02-24T17:59:15Z","published":"2026-02-23T18:59:41Z","title":"A Very Big Video Reasoning Suite","summary":"Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .","authors":["Maijunxian Wang","Ruisi Wang","Juyi Lin","Ran Ji","Thaddäus Wiedemer","Qingying Gao","Dezhi Luo","Yaoyao Qian","Lianyu Huang","Zelong Hong","Jiahui Ge","Qianli Ma","Hang He","Yifan Zhou","Lingzi Guo","Lantao Mei","Jiachen Li","Hanwen Xing","Tianqi Zhao","Fengyuan Yu","Weihang Xiao","Yizheng Jiao","Jianheng Hou","Danyang Zhang","Pengcheng Xu","Boyang Zhong","Zehong Zhao","Gaoyun Fang","John Kitaoka","Yile Xu","Hua Xu","Kenton Blacutt","Tin Nguyen","Siyuan Song","Haoran Sun","Shaoyue Wen","Linyang He","Runming Wang","Yanzhi Wang","Mengyue Yang","Ziqiao Ma","Raphaël Millière","Freda Shi","Nuno Vasconcelos","Daniel Khashabi","Alan Yuille","Yilun Du","Ziming Liu","Bo Li","Dahua Lin","Ziwei Liu","Vikash Kumar","Yijiang Li","Lei Yang","Zhongang Cai","Hokin Deng"],"pdf_url":"","comment":"Homepage: https://video-reason.com/"},{"id":"http://arxiv.org/abs/2602.21148v1","updated":"2026-02-24T17:49:56Z","published":"2026-02-24T17:49:56Z","title":"A Micro-Macro Model of Encounter-Driven Information Diffusion in Robot Swarms","summary":"In this paper, we propose the problem of Encounter-Driven Information Diffusion (EDID). In EDID, robots are allowed to exchange information only upon meeting. Crucially, EDID assumes that the robots are not allowed to schedule their meetings. As such, the robots have no means to anticipate when, where, and who they will meet. As a step towards the design of storage and routing algorithms for EDID, in this paper we propose a model of information diffusion that captures the essential dynamics of EDID. The model is derived from first principles and is composed of two levels: a micro model, based on a generalization of the concept of `mean free path'; and a macro model, which captures the global dynamics of information diffusion. We validate the model through extensive robot simulations, in which we consider swarm size, communication range, environment size, and different random motion regimes. We conclude the paper with a discussion of the implications of this model on the algorithms that best support information diffusion according to the parameters of interest.","authors":["Davis S. Catherman","Carlo Pinciroli"],"pdf_url":"","comment":"10 pages, 5 figures, published at ANTS 2026"},{"id":"http://arxiv.org/abs/2602.13932v2","updated":"2026-02-24T17:45:35Z","published":"2026-02-15T00:04:51Z","title":"Joint Task Assistance Planning via Nested Branch and Bound (Extended Version)","summary":"We introduce and study the Joint Task Assistance Planning problem which generalizes prior work on optimizing assistance in robotic collaboration. In this setting, two robots operate over predefined roadmaps, each represented as a graph corresponding to its configuration space. One robot, the task robot, must execute a timed mission, while the other, the assistance robot, provides sensor-based support that depends on their spatial relationship. The objective is to compute a path for both robots that maximizes the total duration of assistance given. Solving this problem is challenging due to the combinatorial explosion of possible path combinations together with the temporal nature of the problem (time needs to be accounted for as well). To address this, we propose a nested branch-and-bound framework that efficiently explores the space of robot paths in a hierarchical manner. We empirically evaluate our algorithm and demonstrate a speedup of up to two orders of magnitude when compared to a baseline approach.","authors":["Omer Daube","Oren Salzman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21119v1","updated":"2026-02-24T17:15:37Z","published":"2026-02-24T17:15:37Z","title":"Cooperative-Competitive Team Play of Real-World Craft Robots","summary":"Multi-agent deep Reinforcement Learning (RL) has made significant progress in developing intelligent game-playing agents in recent years. However, the efficient training of collective robots using multi-agent RL and the transfer of learned policies to real-world applications remain open research questions. In this work, we first develop a comprehensive robotic system, including simulation, distributed learning framework, and physical robot components. We then propose and evaluate reinforcement learning techniques designed for efficient training of cooperative and competitive policies on this platform. To address the challenges of multi-agent sim-to-real transfer, we introduce Out of Distribution State Initialization (OODSI) to mitigate the impact of the sim-to-real gap. In the experiments, OODSI improves the Sim2Real performance by 20%. We demonstrate the effectiveness of our approach through experiments with a multi-robot car competitive game and a cooperative task in real-world settings.","authors":["Rui Zhao","Xihui Li","Yizheng Zhang","Yuzhen Liu","Zhong Zhang","Yufeng Zhang","Cheng Zhou","Zhengyou Zhang","Lei Han"],"pdf_url":"","comment":"Accepted by 2026 IEEE International Conference on Robotics and Automation (ICRA 2026), Vienna, Austria"},{"id":"http://arxiv.org/abs/2602.16863v2","updated":"2026-02-24T17:10:02Z","published":"2026-02-18T20:42:39Z","title":"SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation","summary":"The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behaviors is challenging, sim-to-real reinforcement learning (RL) is a promising alternative. However, prior approaches typically require substantial engineering effort to model objects and tune reward functions for each task. In this work, we propose SimToolReal, taking a step towards generalizing sim-to-real RL policies for tool manipulation. Instead of focusing on a single object and task, we procedurally generate a large variety of tool-like object primitives in simulation and train a single RL policy with the universal goal of manipulating each object to random goal poses. This approach enables SimToolReal to perform general dexterous tool manipulation at test-time without any object or task-specific training. We demonstrate that SimToolReal outperforms prior retargeting and fixed-grasp methods by 37% while matching the performance of specialist RL policies trained on specific target objects and tasks. Finally, we show that SimToolReal generalizes across a diverse set of everyday tools, achieving strong zero-shot performance over 120 real-world rollouts spanning 24 tasks, 12 object instances, and 6 tool categories.","authors":["Kushal Kedia","Tyler Ga Wei Lum","Jeannette Bohg","C. Karen Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21101v1","updated":"2026-02-24T17:02:56Z","published":"2026-02-24T17:02:56Z","title":"Event-Aided Sharp Radiance Field Reconstruction for Fast-Flying Drones","summary":"Fast-flying aerial robots promise rapid inspection under limited battery constraints, with direct applications in infrastructure inspection, terrain exploration, and search and rescue. However, high speeds lead to severe motion blur in images and induce significant drift and noise in pose estimates, making dense 3D reconstruction with Neural Radiance Fields (NeRFs) particularly challenging due to their high sensitivity to such degradations. In this work, we present a unified framework that leverages asynchronous event streams alongside motion-blurred frames to reconstruct high-fidelity radiance fields from agile drone flights. By embedding event-image fusion into NeRF optimization and jointly refining event-based visual-inertial odometry priors using both event and frame modalities, our method recovers sharp radiance fields and accurate camera trajectories without ground-truth supervision. We validate our approach on both synthetic data and real-world sequences captured by a fast-flying drone. Despite highly dynamic drone flights, where RGB frames are severely degraded by motion blur and pose priors become unreliable, our method reconstructs high-fidelity radiance fields and preserves fine scene details, delivering a performance gain of over 50% on real-world data compared to state-of-the-art methods.","authors":["Rong Zou","Marco Cannici","Davide Scaramuzza"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21072v1","updated":"2026-02-24T16:32:50Z","published":"2026-02-24T16:32:50Z","title":"Localized Dynamics-Aware Domain Adaption for Off-Dynamics Offline Reinforcement Learning","summary":"Off-dynamics offline reinforcement learning (RL) aims to learn a policy for a target domain using limited target data and abundant source data collected under different transition dynamics. Existing methods typically address dynamics mismatch either globally over the state space or via pointwise data filtering; these approaches can miss localized cross-domain similarities or incur high computational cost. We propose Localized Dynamics-Aware Domain Adaptation (LoDADA), which exploits localized dynamics mismatch to better reuse source data. LoDADA clusters transitions from source and target datasets and estimates cluster-level dynamics discrepancy via domain discrimination. Source transitions from clusters with small discrepancy are retained, while those from clusters with large discrepancy are filtered out. This yields a fine-grained and scalable data selection strategy that avoids overly coarse global assumptions and expensive per-sample filtering. We provide theoretical insights and extensive experiments across environments with diverse global and local dynamics shifts. Results show that LoDADA consistently outperforms state-of-the-art off-dynamics offline RL methods by better leveraging localized distribution mismatch.","authors":["Zhangjie Xia","Yu Yang","Pan Xu"],"pdf_url":"","comment":"33 pages, 9 figures, 11 tables"},{"id":"http://arxiv.org/abs/2508.11479v2","updated":"2026-02-24T16:04:11Z","published":"2025-08-15T13:48:15Z","title":"OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation","summary":"Open-vocabulary Object Goal Navigation requires an embodied agent to reach objects described by free-form language, including categories never seen during training. Existing end-to-end policies overfit small simulator datasets, achieving high success on training scenes but failing to generalize and exhibiting unsafe behaviour (frequent collisions). We introduce OVSegDT, a lightweight transformer policy that tackles these issues with two synergistic components. The first component is the semantic branch, which includes an encoder for the target binary mask and an auxiliary segmentation loss function, grounding the textual goal and providing precise spatial cues. The second component consists of a proposed Entropy-Adaptive Loss Modulation, a per-sample scheduler that continuously balances imitation and reinforcement signals according to the policy entropy, eliminating brittle manual phase switches. These additions cut the sample complexity of training by 33%, and reduce collision count in two times while keeping inference cost low (130M parameters, RGB-only input). On HM3D-OVON, our model matches the performance on unseen categories to that on seen ones and establishes state-of-the-art results (40.1% SR, 20.9% SPL on val unseen) without depth, odometry, or large vision-language models. Code is available at https://github.com/CognitiveAISystems/OVSegDT.","authors":["Tatiana Zemskova","Aleksei Staroverov","Dmitry Yudin","Aleksandr Panov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21028v1","updated":"2026-02-24T15:51:10Z","published":"2026-02-24T15:51:10Z","title":"Surface-based Manipulation Using Tunable Compliant Porous-Elastic Soft Sensing","summary":"There is a growing need for soft robotic platforms that perform gentle, precise handling of a wide variety of objects. Existing surface-based manipulation systems, however, lack the compliance and tactile feedback needed for delicate handling. This work introduces the COmpliant Porous-Elastic Soft Sensing (COPESS) integrated with inductive sensors for adaptive object manipulation and localised sensing. The design features a tunable lattice layer that simultaneously modulates mechanical compliance and sensing performance. By adjusting lattice geometry, both stiffness and sensor response can be tailored to handle objects with varying mechanical properties. Experiments demonstrate that by easily adjusting one parameter, the lattice density, from 7 % to 20 %, it is possible to significantly alter the sensitivity and operational force range (about -23x and 9x, respectively). This approach establishes a blueprint for creating adaptive, sensorized surfaces where mechanical and sensory properties are co-optimized, enabling passive, yet programmable, delicate manipulation.","authors":["Gayatri Indukumar","Muhammad Awais","Diana Cafiso","Matteo Lo Preti","Lucia Beccai"],"pdf_url":"","comment":"6 pages, 6 figures, 1 table, to be published in RoboSoft 2026 proceedings"},{"id":"http://arxiv.org/abs/2602.21013v1","updated":"2026-02-24T15:30:55Z","published":"2026-02-24T15:30:55Z","title":"Notes-to-Self: Scratchpad Augmented VLAs for Memory Dependent Manipulation Tasks","summary":"Many dexterous manipulation tasks are non-markovian in nature, yet little attention has been paid to this fact in the recent upsurge of the vision-language-action (VLA) paradigm. Although they are successful in bringing internet-scale semantic understanding to robotics, existing VLAs are primarily \"stateless\" and struggle with memory-dependent long horizon tasks. In this work, we explore a way to impart both spatial and temporal memory to a VLA by incorporating a language scratchpad. The scratchpad makes it possible to memorize task-specific information, such as object positions, and it allows the model to keep track of a plan and progress towards subgoals within that plan. We evaluate this approach on a split of memory-dependent tasks from the ClevrSkills environment, on MemoryBench, as well as on a challenging real-world pick-and-place task. We show that incorporating a language scratchpad significantly improves generalization on these tasks for both non-recurrent and recurrent models.","authors":["Sanjay Haresh","Daniel Dijkman","Apratim Bhattacharyya","Roland Memisevic"],"pdf_url":"","comment":"To appear at ICRA 2026"},{"id":"http://arxiv.org/abs/2507.04002v2","updated":"2026-02-24T15:20:46Z","published":"2025-07-05T11:05:43Z","title":"NRSeg: Noise-Resilient Learning for BEV Semantic Segmentation via Driving World Models","summary":"Birds' Eye View (BEV) semantic segmentation is an indispensable perception task in end-to-end autonomous driving systems. Unsupervised and semi-supervised learning for BEV tasks, as pivotal for real-world applications, underperform due to the homogeneous distribution of the labeled data. In this work, we explore the potential of synthetic data from driving world models to enhance the diversity of labeled data for robustifying BEV segmentation. Yet, our preliminary findings reveal that generation noise in synthetic data compromises efficient BEV model learning. To fully harness the potential of synthetic data from world models, this paper proposes NRSeg, a noise-resilient learning framework for BEV semantic segmentation. Specifically, a Perspective-Geometry Consistency Metric (PGCM) is proposed to quantitatively evaluate the guidance capability of generated data for model learning. This metric originates from the alignment measure between the perspective road mask of generated data and the mask projected from the BEV labels. Moreover, a Bi-Distribution Parallel Prediction (BiDPP) is designed to enhance the inherent robustness of the model, where the learning process is constrained through parallel prediction of multinomial and Dirichlet distributions. The former efficiently predicts semantic probabilities, whereas the latter adopts evidential deep learning to realize uncertainty quantification. Furthermore, a Hierarchical Local Semantic Exclusion (HLSE) module is designed to address the non-mutual exclusivity inherent in BEV semantic segmentation tasks. Experimental results demonstrate that NRSeg achieves state-of-the-art performance, yielding the highest improvements in mIoU of 13.8% and 11.4% in unsupervised and semi-supervised BEV segmentation tasks, respectively. The source code will be made publicly available at https://github.com/lynn-yu/NRSeg.","authors":["Siyu Li","Fei Teng","Yihong Cao","Kailun Yang","Zhiyong Li","Yaonan Wang"],"pdf_url":"","comment":"Accepted to IEEE Transactions on Image Processing (TIP). The source code will be made publicly available at https://github.com/lynn-yu/NRSeg"},{"id":"http://arxiv.org/abs/2506.04500v2","updated":"2026-02-24T14:56:22Z","published":"2025-06-04T22:47:53Z","title":"\"Don't Do That!\": Guiding Embodied Systems through Large Language Model-based Constraint Generation","summary":"Recent advancements in large language models (LLMs) have spurred interest in robotic navigation that incorporates complex spatial, mathematical, and conditional constraints from natural language into the planning problem. Such constraints can be informal yet highly complex, making it challenging to translate into a formal description that can be passed on to a planning algorithm. In this paper, we propose STPR, a constraint generation framework that uses LLMs to translate constraints (expressed as instructions on ``what not to do'') into executable Python functions. STPR leverages the LLM's strong coding capabilities to shift the problem description from language into structured and transparent code, thus circumventing complex reasoning and avoiding potential hallucinations. We show that these LLM-generated functions accurately describe even complex mathematical constraints, and apply them to point cloud representations with traditional search algorithms. Experiments in a simulated Gazebo environment show that STPR ensures full compliance across several constraints and scenarios, while having short runtimes. We also verify that STPR can be used with smaller, code-specific LLMs, making it applicable to a wide range of compact models at low inference cost.","authors":["Amin Seffo","Aladin Djuhera","Masataro Asai","Holger Boche"],"pdf_url":"","comment":"Preprint; under review"},{"id":"http://arxiv.org/abs/2601.20239v3","updated":"2026-02-24T14:42:37Z","published":"2026-01-28T04:22:47Z","title":"TouchGuide: Inference-Time Steering of Visuomotor Policies via Touch Guidance","summary":"Fine-grained and contact-rich manipulation remain challenging for robots, largely due to the underutilization of tactile feedback. To address this, we introduce TouchGuide, a novel cross-policy visuo-tactile fusion paradigm that fuses modalities within a low-dimensional action space. Specifically, TouchGuide operates in two stages to guide a pre-trained diffusion or flow-matching visuomotor policy at inference time. First, the policy produces a coarse, visually-plausible action using only visual inputs during early sampling. Second, a task-specific Contact Physical Model (CPM) provides tactile guidance to steer and refine the action, ensuring it aligns with realistic physical contact conditions. Trained through contrastive learning on limited expert demonstrations, the CPM provides a tactile-informed feasibility score to steer the sampling process toward refined actions that satisfy physical contact constraints. Furthermore, to facilitate TouchGuide training with high-quality and cost-effective data, we introduce TacUMI, a data collection system. TacUMI achieves a favorable trade-off between precision and affordability; by leveraging rigid fingertips, it obtains direct tactile feedback, thereby enabling the collection of reliable tactile data. Extensive experiments on five challenging contact-rich tasks, such as shoe lacing and chip handover, show that TouchGuide consistently and significantly outperforms state-of-the-art visuo-tactile policies.","authors":["Zhemeng Zhang","Jiahua Ma","Xincheng Yang","Xin Wen","Yuzhi Zhang","Boyan Li","Yiran Qin","Jin Liu","Can Zhao","Li Kang","Haoqin Hong","Zhenfei Yin","Philip Torr","Hao Su","Ruimao Zhang","Daolin Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20963v1","updated":"2026-02-24T14:41:28Z","published":"2026-02-24T14:41:28Z","title":"A Robotic Testing Platform for Pipelined Discovery of Resilient Soft Actuators","summary":"Short lifetime under high electrical fields hinders the widespread robotic application of linear dielectric elastomer actuators (DEAs). Systematic scanning is difficult due to time-consuming per-sample testing and the high-dimensional parameter space affecting performance. To address this, we propose an optimization pipeline enabled by a novel testing robot capable of scanning DEA lifetime. The robot integrates electro-mechanical property measurement, programmable voltage input, and multi-channel testing capacity. Using it, we scanned the lifetime of Elastosil-based linear actuators across parameters including input voltage magnitude, frequency, electrode material concentration, and electrical connection filler. The optimal parameter combinations improved operational lifetime under boundary operating conditions by up to 100% and were subsequently scaled up to achieve higher force and displacement output. The final product demonstrated resilience on a modular, scalable quadruped walking robot with payload carrying capacity (>100% of its untethered body weight, and >700% of combined actuator weight). This work is the first to introduce a self-driving lab approach into robotic actuator design.","authors":[" Ang"," Li","Alexander Yin","Alexander White","Sahib Sandhu","Matthew Francoeur","Victor Jimenez-Santiago","Van Remenar","Codrin Tugui","Mihai Duduta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20958v1","updated":"2026-02-24T14:37:36Z","published":"2026-02-24T14:37:36Z","title":"EKF-Based Depth Camera and Deep Learning Fusion for UAV-Person Distance Estimation and Following in SAR Operations","summary":"Search and rescue (SAR) operations require rapid responses to save lives or property. Unmanned Aerial Vehicles (UAVs) equipped with vision-based systems support these missions through prior terrain investigation or real-time assistance during the mission itself. Vision-based UAV frameworks aid human search tasks by detecting and recognizing specific individuals, then tracking and following them while maintaining a safe distance. A key safety requirement for UAV following is the accurate estimation of the distance between camera and target object under real-world conditions, achieved by fusing multiple image modalities. UAVs with deep learning-based vision systems offer a new approach to the planning and execution of SAR operations. As part of the system for automatic people detection and face recognition using deep learning, in this paper we present the fusion of depth camera measurements and monocular camera-to-body distance estimation for robust tracking and following. Deep learning-based filtering of depth camera data and estimation of camera-to-body distance from a monocular camera are achieved with YOLO-pose, enabling real-time fusion of depth information using the Extended Kalman Filter (EKF) algorithm. The proposed subsystem, designed for use in drones, estimates and measures the distance between the depth camera and the human body keypoints, to maintain the safe distance between the drone and the human target. Our system provides an accurate estimated distance, which has been validated against motion capture ground truth data. The system has been tested in real time indoors, where it reduces the average errors, root mean square error (RMSE) and standard deviations of distance estimation up to 15,3\\% in three tested scenarios.","authors":["Luka Šiktar","Branimir Ćaran","Bojan Šekoranja","Marko Švaco"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.04867v4","updated":"2026-02-24T14:36:12Z","published":"2025-06-05T10:38:28Z","title":"Sensory-Motor Control with Large Language Models via Iterative Policy Refinement","summary":"We propose a method that enables large language models (LLMs) to control embodied agents through the generation of control policies that directly map continuous observation vectors to continuous action vectors. At the outset, the LLMs generate a control strategy based on a textual description of the agent, its environment, and the intended goal. This strategy is then iteratively refined through a learning process in which the LLMs are repeatedly prompted to improve the current strategy, using performance feedback and sensory-motor data collected during its evaluation. The method is validated on classic control tasks from the Gymnasium library and the inverted pendulum task from the MuJoCo library. The approach proves effective with relatively compact models such as GPT-oss:120b and Qwen2.5:72b. In most cases, it successfully identifies optimal or near-optimal solutions by integrating symbolic knowledge derived through reasoning with sub-symbolic sensory-motor data gathered as the agent interacts with its environment.","authors":["Jônata Tyska Carvalho","Stefano Nolfi"],"pdf_url":"","comment":"Final version of the article accepted for publication on Scientific Reports. 29 pages (13 pages are from appendix), 8 figures, 2 tables, code for experiments replication and supplementary material provided at https://github.com/jtyska/llm-robotics-article/"},{"id":"http://arxiv.org/abs/2602.12656v2","updated":"2026-02-24T14:34:42Z","published":"2026-02-13T06:38:04Z","title":"PMG: Parameterized Motion Generator for Human-like Locomotion Control","summary":"Recent advances in data-driven reinforcement learning and motion tracking have substantially improved humanoid locomotion, yet critical practical challenges remain. In particular, while low-level motion tracking and trajectory-following controllers are mature, whole-body reference-guided methods are difficult to adapt to higher-level command interfaces and diverse task contexts: they require large, high-quality datasets, are brittle across speed and pose regimes, and are sensitive to robot-specific calibration. To address these limitations, we propose the Parameterized Motion Generator (PMG), a real-time motion generator grounded in an analysis of human motion structure that synthesizes reference trajectories using only a compact set of parameterized motion data together with high-dimensional control commands. Combined with an imitation-learning pipeline and an optimization-based sim-to-real motor parameter identification module, we validate the complete approach on our humanoid prototype ZERITH Z1 and show that, within a single integrated system, PMG produces natural, human-like locomotion, responds precisely to high-dimensional control inputs-including VR-based teleoperation-and enables efficient, verifiable sim-to-real transfer. Together, these results establish a practical, experimentally validated pathway toward natural and deployable humanoid control. Website: https://pmg-icra26.github.io/","authors":["Chenxi Han","Yuheng Min","Zihao Huang","Ao Hong","Hang Liu","Yi Cheng","Houde Liu"],"pdf_url":"","comment":"Website: https://pmg-icra26.github.io/"},{"id":"http://arxiv.org/abs/2602.18638v2","updated":"2026-02-24T14:04:56Z","published":"2026-02-20T22:16:49Z","title":"Soft Surfaced Vision-Based Tactile Sensing for Bipedal Robot Applications","summary":"Legged locomotion benefits from embodied sensing, where perception emerges from the physical interaction between body and environment. We present a soft-surfaced, vision-based tactile foot sensor that endows a bipedal robot with a skin-like deformable layer that captures contact deformations optically, turning foot-ground interactions into rich haptic signals. From a contact image stream, our method estimates contact pose (position and orientation), visualizes shear, computes center of pressure (CoP), classifies terrain, and detects geometric features of the contact patch. We validate these capabilities on a tilting platform and in visually obscured conditions, showing that foot-borne tactile feedback improves balance control and terrain awareness beyond proprioception alone. These findings suggest that integrating tactile perception into legged robot feet improves stability, adaptability, and environmental awareness, offering a promising direction toward more compliant and intelligent locomotion systems. For the supplementary video, please visit: https://youtu.be/ceJiy9q_2Aw","authors":["Jaeeun Kim","Junhee Lim","Yu She"],"pdf_url":"","comment":"8 pages, 11 figures, RoboSoft 2026. For the supplementary video, please visit: https://youtu.be/ceJiy9q_2Aw Section IV-D updated"},{"id":"http://arxiv.org/abs/2602.20925v1","updated":"2026-02-24T14:04:54Z","published":"2026-02-24T14:04:54Z","title":"LST-SLAM: A Stereo Thermal SLAM System for Kilometer-Scale Dynamic Environments","summary":"Thermal cameras offer strong potential for robot perception under challenging illumination and weather conditions. However, thermal Simultaneous Localization and Mapping (SLAM) remains difficult due to unreliable feature extraction, unstable motion tracking, and inconsistent global pose and map construction, particularly in dynamic large-scale outdoor environments. To address these challenges, we propose LST-SLAM, a novel large-scale stereo thermal SLAM system that achieves robust performance in complex, dynamic scenes. Our approach combines self-supervised thermal feature learning, stereo dual-level motion tracking, and geometric pose optimization. We also introduce a semantic-geometric hybrid constraint that suppresses potentially dynamic features lacking strong inter-frame geometric consistency. Furthermore, we develop an online incremental bag-of-words model for loop closure detection, coupled with global pose optimization to mitigate accumulated drift. Extensive experiments on kilometer-scale dynamic thermal datasets show that LST-SLAM significantly outperforms recent representative SLAM systems, including AirSLAM and DROID-SLAM, in both robustness and accuracy.","authors":["Zeyu Jiang","Kuan Xu","Changhao Chen"],"pdf_url":"","comment":"ICRA 2026"},{"id":"http://arxiv.org/abs/2602.20923v1","updated":"2026-02-24T14:01:33Z","published":"2026-02-24T14:01:33Z","title":"ParkDiffusion++: Ego Intention Conditioned Joint Multi-Agent Trajectory Prediction for Automated Parking using Diffusion Models","summary":"Automated parking is a challenging operational domain for advanced driver assistance systems, requiring robust scene understanding and interaction reasoning. The key challenge is twofold: (i) predict multiple plausible ego intentions according to context and (ii) for each intention, predict the joint responses of surrounding agents, enabling effective what-if decision-making. However, existing methods often fall short, typically treating these interdependent problems in isolation. We propose ParkDiffusion++, which jointly learns a multi-modal ego intention predictor and an ego-conditioned multi-agent joint trajectory predictor for automated parking. Our approach makes several key contributions. First, we introduce an ego intention tokenizer that predicts a small set of discrete endpoint intentions from agent histories and vectorized map polylines. Second, we perform ego-intention-conditioned joint prediction, yielding socially consistent predictions of the surrounding agents for each possible ego intention. Third, we employ a lightweight safety-guided denoiser with different constraints to refine joint scenes during training, thus improving accuracy and safety. Fourth, we propose counterfactual knowledge distillation, where an EMA teacher refined by a frozen safety-guided denoiser provides pseudo-targets that capture how agents react to alternative ego intentions. Extensive evaluations demonstrate that ParkDiffusion++ achieves state-of-the-art performance on the Dragon Lake Parking (DLP) dataset and the Intersections Drone (inD) dataset. Importantly, qualitative what-if visualizations show that other agents react appropriately to different ego intentions.","authors":["Jiarong Wei","Anna Rehr","Christian Feist","Abhinav Valada"],"pdf_url":"","comment":"ICRA 2026 Camera Ready Version"},{"id":"http://arxiv.org/abs/2602.20920v1","updated":"2026-02-24T13:58:36Z","published":"2026-02-24T13:58:36Z","title":"Computer-Aided Design of Rational Motions for 4R and 6R Spatial Mechanism Synthesis","summary":"This paper focuses on geometric methods for generating rational motions used in the design of single-loop rational linkages, 1-degree-of-freedom mechanisms that can execute prescribed spatial tasks. Building on established rational motion synthesis methods, we introduce a new interpolation scheme for seven 3D points based on cubic quaternionic Bezier curves. The resulting motion admits factorization, i.e. the synthesis of a spatial six-bar mechanism whose tool frame passes the specified seven points. To support engineering practice, we provide open-source CAD tools that implement also the other methods and provide fast visual evaluation of motion generation and mechanism synthesis.","authors":["Daniel Huczala","Severinas Zube","Martin Pfurner","Johannes Siegele","Frank C. Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20915v1","updated":"2026-02-24T13:51:09Z","published":"2026-02-24T13:51:09Z","title":"Task-oriented grasping for dexterous robots using postural synergies and reinforcement learning","summary":"In this paper, we address the problem of task-oriented grasping for humanoid robots, emphasizing the need to align with human social norms and task-specific objectives. Existing methods, employ a variety of open-loop and closed-loop approaches but lack an end-to-end solution that can grasp several objects while taking into account the downstream task's constraints. Our proposed approach employs reinforcement learning to enhance task-oriented grasping, prioritizing the post-grasp intention of the agent. We extract human grasp preferences from the ContactPose dataset, and train a hand synergy model based on the Variational Autoencoder (VAE) to imitate the participant's grasping actions. Based on this data, we train an agent able to grasp multiple objects while taking into account distinct post-grasp intentions that are task-specific. By combining data-driven insights from human grasping behavior with learning by exploration provided by reinforcement learning, we can develop humanoid robots capable of context-aware manipulation actions, facilitating collaboration in human-centered environments.","authors":["Dimitrios Dimou","José Santos-Victor","Plinio Moreno"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.03356v2","updated":"2026-02-24T13:38:56Z","published":"2025-05-06T09:26:29Z","title":"Effective Reinforcement Learning Control using Conservative Soft Actor-Critic","summary":"Reinforcement Learning (RL) has shown great potential in complex control tasks, particularly when combined with deep neural networks within the Actor-Critic (AC) framework. However, in practical applications, balancing exploration, learning stability, and sample efficiency remains a significant challenge. Traditional methods such as Soft Actor-Critic (SAC) and Proximal Policy Optimization (PPO) address these issues by incorporating entropy or relative entropy regularization, but often face problems of instability and low sample efficiency. In this paper, we propose the Conservative Soft Actor-Critic (CSAC) algorithm, which seamlessly integrates entropy and relative entropy regularization within the AC framework. CSAC improves exploration through entropy regularization while avoiding overly aggressive policy updates with the use of relative entropy regularization. Evaluations on benchmark tasks and real-world robotic simulations demonstrate that CSAC offers significant improvements in stability and efficiency over existing methods. These findings suggest that CSAC provides strong robustness and application potential in control tasks under dynamic environments.","authors":["Zhiwei Shang","Xinyi Yuan","Wenjun Huang","Yunduan Cui","Di Chen","Meixin Zhu"],"pdf_url":"","comment":"8 pages, 9 figures"},{"id":"http://arxiv.org/abs/2602.20871v1","updated":"2026-02-24T13:15:38Z","published":"2026-02-24T13:15:38Z","title":"GeCo-SRT: Geometry-aware Continual Adaptation for Robotic Cross-Task Sim-to-Real Transfer","summary":"Bridging the sim-to-real gap is important for applying low-cost simulation data to real-world robotic systems. However, previous methods are severely limited by treating each transfer as an isolated endeavor, demanding repeated, costly tuning and wasting prior transfer experience.To move beyond isolated sim-to-real, we build a continual cross-task sim-to-real transfer paradigm centered on knowledge accumulation across iterative transfers, thereby enabling effective and efficient adaptation to novel tasks. Thus, we propose GeCo-SRT, a geometry-aware continual adaptation method. It utilizes domain-invariant and task-invariant knowledge from local geometric features as a transferable foundation to accelerate adaptation during subsequent sim-to-real transfers. This method starts with a geometry-aware mixture-of-experts module, which dynamically activates experts to specialize in distinct geometric knowledge to bridge observation sim-to-real gap. Further, the geometry-expert-guided prioritized experience replay module preferentially samples from underutilized experts, refreshing specialized knowledge to combat forgetting and maintain robust cross-task performance. Leveraging knowledge accumulated during iterative transfer, GeCo-SRT method not only achieves 52% average performance improvement over the baseline, but also demonstrates significant data efficiency for new task adaptation with only 1/6 data.We hope this work inspires approaches for efficient, low-cost cross-task sim-to-real transfer.","authors":["Wenbo Yu","Wenke Xia","Weitao Zhang","Di Hu"],"pdf_url":"","comment":"Accepted By CVPR 2026"},{"id":"http://arxiv.org/abs/2602.20850v1","updated":"2026-02-24T12:46:34Z","published":"2026-02-24T12:46:34Z","title":"KCFRC: Kinematic Collision-Aware Foothold Reachability Criteria for Legged Locomotion","summary":"Legged robots face significant challenges in navigating complex environments, as they require precise real-time decisions for foothold selection and contact planning. While existing research has explored methods to select footholds based on terrain geometry or kinematics, a critical gap remains: few existing methods efficiently validate the existence of a non-collision swing trajectory. This paper addresses this gap by introducing KCFRC, a novel approach for efficient foothold reachability analysis. We first formally define the foothold reachability problem and establish a sufficient condition for foothold reachability. Based on this condition, we develop the KCFRC algorithm, which enables robots to validate foothold reachability in real time. Our experimental results demonstrate that KCFRC achieves remarkable time efficiency, completing foothold reachability checks for a single leg across 900 potential footholds in an average of 2 ms. Furthermore, we show that KCFRC can accelerate trajectory optimization and is particularly beneficial for contact planning in confined spaces, enhancing the adaptability and robustness of legged robots in challenging environments.","authors":["Lei Ye","Haibo Gao","Huaiguang Yang","Peng Xu","Haoyu Wang","Tie Liu","Junqi Shan","Zongquan Deng","Liang Ding"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.08435v2","updated":"2026-02-24T12:33:35Z","published":"2025-09-10T09:31:17Z","title":"PegasusFlow: Parallel Rolling-Denoising Score Sampling for Robot Diffusion Planner Flow Matching","summary":"Diffusion models offer powerful generative capabilities for robot trajectory planning, yet their practical deployment on robots is hindered by a critical bottleneck: a reliance on imitation learning from expert demonstrations. This paradigm is often impractical for specialized robots where data is scarce and creates an inefficient, theoretically suboptimal training pipeline. To overcome this, we introduce PegasusFlow, a hierarchical rolling-denoising framework that enables direct and parallel sampling of trajectory score gradients from environmental interaction, completely bypassing the need for expert data. Our core innovation is a novel sampling algorithm, Weighted Basis Function Optimization (WBFO), which leverages spline basis representations to achieve superior sample efficiency and faster convergence compared to traditional methods like MPPI. The framework is embedded within a scalable, asynchronous parallel simulation architecture that supports massively parallel rollouts for efficient data collection. Extensive experiments on trajectory optimization and robotic navigation tasks demonstrate that our approach, particularly Action-Value WBFO (AVWBFO) combined with a reinforcement learning warm-start, significantly outperforms baselines. In a challenging barrier-crossing task, our method achieved a 100% success rate and was 18% faster than the next-best method, validating its effectiveness for complex terrain locomotion planning. https://masteryip.github.io/pegasusflow.github.io/","authors":["Lei Ye","Haibo Gao","Peng Xu","Zhelin Zhang","Junqi Shan","Ao Zhang","Wei Zhang","Ruyi Zhou","Zongquan Deng","Liang Ding"],"pdf_url":"","comment":"8 pages, 7 figures, conference paper"},{"id":"http://arxiv.org/abs/2506.06690v2","updated":"2026-02-24T12:03:06Z","published":"2025-06-07T07:04:48Z","title":"SpikePingpong: Spike Vision-based Fast-Slow Pingpong Robot System","summary":"Learning to control high-speed objects in dynamic environments represents a fundamental challenge in robotics. Table tennis serves as an ideal testbed for advancing robotic capabilities in dynamic environments. This task presents two fundamental challenges: it requires a high-precision vision system capable of accurately predicting ball trajectories under complex dynamics, and it necessitates intelligent control strategies to ensure precise ball striking to target regions. High-speed object manipulation typically demands advanced visual perception hardware capable of capturing rapid motion with exceptional temporal resolution. Drawing inspiration from Kahneman's dual-system theory, where fast intuitive processing complements slower deliberate reasoning, there exists an opportunity to develop more robust perception architectures that can handle high-speed dynamics while maintaining accuracy. To this end, we present \\textit{\\textbf{SpikePingpong}}, a novel system that integrates spike-based vision with imitation learning for high-precision robotic table tennis. We develop a Fast-Slow system architecture where System 1 provides rapid ball detection and preliminary trajectory prediction with millisecond-level responses, while System 2 employs spike-oriented neural calibration for precise hittable position corrections. For strategic ball striking, we introduce Imitation-based Motion Planning And Control Technology, which learns optimal robotic arm striking policies through demonstration-based learning. Experimental results demonstrate that \\textit{\\textbf{SpikePingpong}} achieves a remarkable 92\\% success rate for 30 cm accuracy zones and 70\\% in the more challenging 20 cm precision targeting. This work demonstrates the potential of Fast-Slow architectures for advancing robotic capabilities in time-critical manipulation tasks.","authors":["Hao Wang","Chengkai Hou","Xianglong Li","Yankai Fu","Chenxuan Li","Ning Chen","Gaole Dai","Jiaming Liu","Tiejun Huang","Shanghang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.09708v2","updated":"2026-02-24T11:51:26Z","published":"2026-01-14T18:59:59Z","title":"Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning","summary":"Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.","authors":["Chi-Pin Huang","Yunze Man","Zhiding Yu","Min-Hung Chen","Jan Kautz","Yu-Chiang Frank Wang","Fu-En Yang"],"pdf_url":"","comment":"CVPR 2026. Project page: https://jasper0314-huang.github.io/fast-thinkact/"},{"id":"http://arxiv.org/abs/2602.20807v1","updated":"2026-02-24T11:47:43Z","published":"2026-02-24T11:47:43Z","title":"RU4D-SLAM: Reweighting Uncertainty in Gaussian Splatting SLAM for 4D Scene Reconstruction","summary":"Combining 3D Gaussian splatting with Simultaneous Localization and Mapping (SLAM) has gained popularity as it enables continuous 3D environment reconstruction during motion. However, existing methods struggle in dynamic environments, particularly moving objects complicate 3D reconstruction and, in turn, hinder reliable tracking. The emergence of 4D reconstruction, especially 4D Gaussian splatting, offers a promising direction for addressing these challenges, yet its potential for 4D-aware SLAM remains largely underexplored. Along this direction, we propose a robust and efficient framework, namely Reweighting Uncertainty in Gaussian Splatting SLAM (RU4D-SLAM) for 4D scene reconstruction, that introduces temporal factors into spatial 3D representation while incorporating uncertainty-aware perception of scene changes, blurred image synthesis, and dynamic scene reconstruction. We enhance dynamic scene representation by integrating motion blur rendering, and improve uncertainty-aware tracking by extending per-pixel uncertainty modeling, which is originally designed for static scenarios, to handle blurred images. Furthermore, we propose a semantic-guided reweighting mechanism for per-pixel uncertainty estimation in dynamic scenes, and introduce a learnable opacity weight to support adaptive 4D mapping. Extensive experiments on standard benchmarks demonstrate that our method substantially outperforms state-of-the-art approaches in both trajectory accuracy and 4D scene reconstruction, particularly in dynamic environments with moving objects and low-quality inputs. Code available: https://ru4d-slam.github.io","authors":["Yangfan Zhao","Hanwei Zhang","Ke Huang","Qiufeng Wang","Zhenzhou Shao","Dengyu Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20790v1","updated":"2026-02-24T11:29:07Z","published":"2026-02-24T11:29:07Z","title":"Real-time Motion Segmentation with Event-based Normal Flow","summary":"Event-based cameras are bio-inspired sensors with pixels that independently and asynchronously respond to brightness changes at microsecond resolution, offering the potential to handle visual tasks in challenging scenarios. However, due to the sparse information content in individual events, directly processing the raw event data to solve vision tasks is highly inefficient, which severely limits the applicability of state-of-the-art methods in real-time tasks, such as motion segmentation, a fundamental task for dynamic scene understanding. Incorporating normal flow as an intermediate representation to compress motion information from event clusters within a localized region provides a more effective solution. In this work, we propose a normal flow-based motion segmentation framework for event-based vision. Leveraging the dense normal flow directly learned from event neighborhoods as input, we formulate the motion segmentation task as an energy minimization problem solved via graph cuts, and optimize it iteratively with normal flow clustering and motion model fitting. By using a normal flow-based motion model initialization and fitting method, the proposed system is able to efficiently estimate the motion models of independently moving objects with only a limited number of candidate models, which significantly reduces the computational complexity and ensures real-time performance, achieving nearly a 800x speedup in comparison to the open-source state-of-the-art method. Extensive evaluations on multiple public datasets fully demonstrate the accuracy and efficiency of our framework.","authors":["Sheng Zhong","Zhongyang Ren","Xiya Zhu","Dehao Yuan","Cornelia Fermuller","Yi Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20768v1","updated":"2026-02-24T11:00:23Z","published":"2026-02-24T11:00:23Z","title":"Visual Cooperative Drone Tracking for Open-Path Gas Measurements","summary":"Open-path Tunable Diode Laser Absorption Spectroscopy offers an effective method for measuring, mapping, and monitoring gas concentrations, such as leaking CO2 or methane. Compared to spatial sampling of gas distributions using in-situ sensors, open-path sensors in combination with gas tomography algorithms can cover large outdoor environments faster in a non-invasive way. However, the requirement of a dedicated reflection surface for the open-path laser makes automating the spatial sampling process challenging. This publication presents a robotic system for collecting open-path measurements, making use of a sensor mounted on a ground-based pan-tilt unit and a small drone carrying a reflector. By means of a zoom camera, the ground unit visually tracks red LED markers mounted on the drone and aligns the sensor's laser beam with the reflector. Incorporating GNSS position information provided by the drone's flight controller further improves the tracking approach. Outdoor experiments validated the system's performance, demonstrating successful autonomous tracking and valid CO2 measurements at distances up to 60 meters. Furthermore, the system successfully measured a CO2 plume without interference from the drone's propulsion system, demonstrating its superiority compared to flying in-situ sensors.","authors":["Marius Schaab","Alisha Kiefer","Thomas Wiedemann","Patrick Hinsen","Achim J. Lilienthal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.14719v4","updated":"2026-02-24T10:54:14Z","published":"2024-09-23T05:33:35Z","title":"DiSPo: Diffusion-SSM based Policy Learning for Coarse-to-Fine Action Discretization","summary":"We aim to solve the problem of generating coarse-to-fine skills learning from demonstrations (LfD). To scale precision, traditional LfD approaches often rely on extensive fine-grained demonstrations with external interpolations or dynamics models with limited generalization capabilities. For memory-efficient learning and convenient granularity change, we propose a novel diffusion-state space model (SSM) based policy (DiSPo) that learns from diverse coarse skills and produces varying control scales of actions by leveraging an SSM, Mamba. Our evaluations show the adoption of Mamba and the proposed step-scaling method enable DiSPo to outperform in three coarse-to-fine benchmark tests with maximum 81% higher success rate than baselines. In addition, DiSPo improves inference efficiency by generating coarse motions in less critical regions. We finally demonstrate the scalability of actions with simulation and real-world manipulation tasks. Code and Videos are available at https://robo-dispo.github.io.","authors":["Nayoung Oh","Jaehyeong Jang","Moonkyeong Jung","Daehyung Park"],"pdf_url":"","comment":"Accepted by ICRA 2026"},{"id":"http://arxiv.org/abs/2602.20715v1","updated":"2026-02-24T09:19:50Z","published":"2026-02-24T09:19:50Z","title":"IG-RFT: An Interaction-Guided RL Framework for VLA Models in Long-Horizon Robotic Manipulation","summary":"Vision-Language-Action (VLA) models have demonstrated significant potential for generalist robotic policies; however, they struggle to generalize to long-horizon complex tasks in novel real-world domains due to distribution shifts and the scarcity of high-quality demonstrations. Although reinforcement learning (RL) offers a promising avenue for policy improvement, applying it to real-world VLA fine-tuning faces challenges regarding exploration efficiency, training stability, and sample cost. To address these issues, we propose IG-RFT, a novel Interaction-Guided Reinforced Fine-Tuning system designed for flow-based VLA models. Firstly, to facilitate effective policy optimization, we introduce Interaction-Guided Advantage Weighted Regression (IG-AWR), an RL algorithm that dynamically modulates exploration intensity based on the robot's interaction status. Furthermore, to address the limitations of sparse or task-specific rewards, we design a novel hybrid dense reward function that integrates the trajectory-level reward and the subtask-level reward. Finally, we construct a three-stage RL system comprising SFT, Offline RL, and Human-in-the-Loop RL for fine-tuning VLA models. Extensive real-world experiments on four challenging long-horizon tasks demonstrate that IG-RFT achieves an average success rate of 85.0%, significantly outperforming SFT (18.8%) and standard Offline RL baselines (40.0%). Ablation studies confirm the critical contributions of IG-AWR and hybrid reward shaping. In summary, our work establishes and validates a novel reinforced fine-tuning system for VLA models in real-world robotic manipulation.","authors":["Zhian Su","Weijie Kong","Haonan Dong","Huixu Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20645v1","updated":"2026-02-24T07:46:31Z","published":"2026-02-24T07:46:31Z","title":"Robot Local Planner: A Periodic Sampling-Based Motion Planner with Minimal Waypoints for Home Environments","summary":"The objective of this study is to enable fast and safe manipulation tasks in home environments. Specifically, we aim to develop a system that can recognize its surroundings and identify target objects while in motion, enabling it to plan and execute actions accordingly. We propose a periodic sampling-based whole-body trajectory planning method, called the \"Robot Local Planner (RLP).\" This method leverages unique features of home environments to enhance computational efficiency, motion optimality, and robustness against recognition and control errors, all while ensuring safety. The RLP minimizes computation time by planning with minimal waypoints and generating safe trajectories. Furthermore, overall motion optimality is improved by periodically executing trajectory planning to select more optimal motions. This approach incorporates inverse kinematics that are robust to base position errors, further enhancing robustness. Evaluation experiments demonstrated that the RLP outperformed existing methods in terms of motion planning time, motion duration, and robustness, confirming its effectiveness in home environments. Moreover, application experiments using a tidy-up task achieved high success rates and short operation times, thereby underscoring its practical feasibility.","authors":["Keisuke Takeshita","Takahiro Yamazaki","Tomohiro Ono","Takashi Yamamoto"],"pdf_url":"","comment":"Accepted to IEEE International Conference on Robotics and Automation (ICRA) 2025. Project Page: https://toyotafrc.github.io/RobotLocalPlanner-Proj/"},{"id":"http://arxiv.org/abs/2503.01852v2","updated":"2026-02-24T07:27:57Z","published":"2025-02-21T19:29:49Z","title":"Interaction-Aware Model Predictive Decision-Making for Socially-Compliant Autonomous Driving in Mixed Urban Traffic Scenarios","summary":"Autonomous vehicles must negotiate with pedestrians in ways that are both safe and socially compliant. We present an interaction-aware model predictive decision-making (IAMPDM) framework that integrates a gap-acceptance-inspired intention model with MPC to jointly reason about human intent and vehicle control in real time. The pedestrian module produces a continuous crossing-propensity signal - driven by time-to-collision (TTC) with an intention discounting mechanism - that modulates MPC safety terms and minimum-distance constraints. We implement IAMPDM in a projection-based, motion-tracked simulator and compare it against a rule-based intention-aware controller (RBDM) and a conservative non-interactive baseline (NIA). In a human-in-the-decision-loop study with 25 participants, intention-aware methods shortened negotiation and completion time relative to NIA across scenarios, at the expense of tighter TTC/DST margins, with no significant difference between IAMPDM and RBDM except for TTC in one scenario. Results indicate that intention-aware decision-making algorithms reduce pedestrian crossing time and improve subjective ratings of comfort, safety, and trust relative to a non-cooperative decision-making algorithm. We discuss implications for real-world deployment of interaction-aware autonomous vehicles. We detail decision-making calibration and real-time implementation (CasADi/IPOPT) and propose deployment guardrails - minimum surrogate-safety margins, deadlock prevention - to balance efficiency with safety.","authors":["Balint Varga","Thomas Brand","Marcus Schmitz","Ehsan Hashemi"],"pdf_url":"","comment":"Major Revision"},{"id":"http://arxiv.org/abs/2602.20627v1","updated":"2026-02-24T07:22:58Z","published":"2026-02-24T07:22:58Z","title":"Object-Scene-Camera Decomposition and Recomposition for Data-Efficient Monocular 3D Object Detection","summary":"Monocular 3D object detection (M3OD) is intrinsically ill-posed, hence training a high-performance deep learning based M3OD model requires a humongous amount of labeled data with complicated visual variation from diverse scenes, variety of objects and camera poses.However, we observe that, due to strong human bias, the three independent entities, i.e., object, scene, and camera pose, are always tightly entangled when an image is captured to construct training data. More specifically, specific 3D objects are always captured in particular scenes with fixed camera poses, and hence lacks necessary diversity. Such tight entanglement induces the challenging issues of insufficient utilization and overfitting to uniform training data. To mitigate this, we propose an online object-scene-camera decomposition and recomposition data manipulation scheme to more efficiently exploit the training data. We first fully decompose training images into textured 3D object point models and background scenes in an efficient computation and storage manner. We then continuously recompose new training images in each epoch by inserting the 3D objects into the freespace of the background scenes, and rendering them with perturbed camera poses from textured 3D point representation. In this way, the refreshed training data in all epochs can cover the full spectrum of independent object, scene, and camera pose combinations. This scheme can serve as a plug-and-play component to boost M3OD models, working flexibly with both fully and sparsely supervised settings. In the sparsely-supervised setting, objects closest to the ego-camera for all instances are sparsely annotated. We then can flexibly increase the annotated objects to control annotation cost. For validation, our method is widely applied to five representative M3OD models and evaluated on both the KITTI and the more complicated Waymo datasets.","authors":["Zhaonian Kuang","Rui Ding","Meng Yang","Xinhu Zheng","Gang Hua"],"pdf_url":"","comment":"IJCV"},{"id":"http://arxiv.org/abs/2510.00037v4","updated":"2026-02-24T07:21:12Z","published":"2025-09-26T14:42:23Z","title":"On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations","summary":"In Vision-Language-Actionf(VLA) models, robustness to real-world perturbations is critical for deployment. Existing methods target simple visual disturbances, overlooking the broader multi-modal perturbations that arise in actions, instructions, environments, and observations. Here, we first evaluate the robustness of mainstream VLAs under 17 perturbations across four modalities. We find (1) actions as the most fragile modality, (2) Existing visual-robust VLA do not gain robustness in other modality, and (3) pi0 demonstrates superior robustness. To build multi-modal robust VLAs, we propose RobustVLA against perturbations in VLA inputs and outputs. For output robustness, we perform offline robust optimization against worst-case action noise that maximizes mismatch in flow matching objective. This can be seen as adversarial training, label smoothing, and outlier penalization. For input robustness, we enforce consistent actions across input variations that preserve task semantics. To account for multiple perturbations, we formulate robustness as a multi-armed bandit problem and apply an upper confidence bound algorithm to automatically identify the most harmful noise. Experiments on LIBERO demonstrate our RobustVLA delivers absolute gains over baselines of 12.6% on the pi0 backbone and 10.4% on the OpenVLA backbone across all 17 perturbations, achieving 50.6x faster inference than existing visual-robust BYOVLA that requires external LLMs, and a 10.4% gain under mixed perturbations. On the real-world FR5 robot, under four types of multimodal perturbations, RobustVLA shows strong low-data performance, outperforming pi0 by 65.6% success rate with 25 demonstrations. Even with abundant demos, our method still outperform pi0 by 30% success rate. Code and demo videos available at https://github.com/gakakulicc/RobustVLA.","authors":["Jianing Guo","Zhenhong Wu","Chang Tu","Yiyao Ma","Xiangqi Kong","Zhiqian Liu","Jiaming Ji","Shuning Zhang","Yuanpei Chen","Kai Chen","Qi Dou","Yaodong Yang","Xianglong Liu","Huijie Zhao","Weifeng Lv","Simin Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18688v2","updated":"2026-02-24T06:52:39Z","published":"2026-02-21T01:41:40Z","title":"Scout-Rover cooperation: online terrain strength mapping and traversal risk estimation for planetary-analog explorations","summary":"Robot-aided exploration of planetary surfaces is essential for understanding geologic processes, yet many scientifically valuable regions, such as Martian dunes and lunar craters, remain hazardous due to loose, deformable regolith. We present a scout-rover cooperation framework that expands safe access to such terrain using a hybrid team of legged and wheeled robots. In our approach, a high-mobility legged robot serves as a mobile scout, using proprioceptive leg-terrain interactions to estimate regolith strength during locomotion and construct spatially resolved terrain maps. These maps are integrated with rover locomotion models to estimate traversal risk and inform path planning.\n  We validate the framework through analogue missions at the NASA Ames Lunar Simulant Testbed and the White Sands Dune Field. Experiments demonstrate (1) online terrain strength mapping from legged locomotion and (2) rover-specific traversal-risk estimation enabling safe navigation to scientific targets. Results show that scout-generated terrain maps reliably capture spatial variability and predict mobility failure modes, allowing risk-aware path planning that avoids hazardous regions. By combining embodied terrain sensing with heterogeneous rover cooperation, this framework enhances operational robustness and expands the reachable science workspace in deformable planetary environments.","authors":["Shipeng Liu","J. Diego Caporale","Yifeng Zhang","Xingjue Liao","William Hoganson","Wilson Hu","Shivangi Misra","Neha Peddinti","Rachel Holladay","Ethan Fulcher","Akshay Ram Panyam","Andrik Puentes","Jordan M. Bretzfelder","Michael Zanetti","Uland Wong","Daniel E. Koditschek","Mark Yim","Douglas Jerolmack","Cynthia Sung","Feifei Qian"],"pdf_url":"","comment":"8 figures"},{"id":"http://arxiv.org/abs/2505.19698v3","updated":"2026-02-24T06:45:28Z","published":"2025-05-26T08:52:45Z","title":"Performance Asymmetry in Model-Based Reinforcement Learning","summary":"Recently, Model-Based Reinforcement Learning (MBRL) have achieved super-human level performance on the Atari100k benchmark on average. However, we discover that conventional aggregates mask a major problem, Performance Asymmetry: MBRL agents dramatically outperform humans in certain tasks (Agent-Optimal tasks) while drastically underperform humans in other tasks (Human-Optimal tasks). Indeed, despite achieving SOTA in the overall mean Human-Normalized Scores (HNS), the SOTA agent scored the worst among baselines on Human-Optimal tasks, with a striking 21X performance gap between the Human-Optimal and Agent-Optimal subsets. To address this, we partition Atari100k evenly into Human-Optimal and Agent-Optimal subsets, and introduce a more balanced aggregate, Sym-HNS. Furthermore, we trace the striking Performance Asymmetry in the SOTA pixel diffusion world model to the curse of dimensionality and its prowess on high visual detail tasks (e.g. Breakout). To this end, we propose a novel latent end-to-end Joint Embedding DIffusion (JEDI) world model that achieves SOTA results in Sym-HNS, Human-Optimal tasks, and Breakout -- thus reversing the worsening Performance Asymmetry trend while improving computational efficiency and remaining competitive on the full Atari100k.","authors":["Jing Yu Lim","Rushi Shah","Zarif Ikram","Samson Yu","Haozhe Ma","Tze-Yun Leong","Dianbo Liu"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2602.20596v1","updated":"2026-02-24T06:35:43Z","published":"2026-02-24T06:35:43Z","title":"Acoustic Feedback for Closed-Loop Force Control in Robotic Grinding","summary":"Acoustic feedback is a critical indicator for assessing the contact condition between the tool and the workpiece when humans perform grinding tasks with rotary tools. In contrast, robotic grinding systems typically rely on force sensing, with acoustic information largely ignored. This reliance on force sensors is costly and difficult to adapt to different grinding tools, whereas audio sensors (microphones) are low-cost and can be mounted on any medium that conducts grinding sound.\n  This paper introduces a low-cost Acoustic Feedback Robotic Grinding System (AFRG) that captures audio signals with a contact microphone, estimates grinding force from the audio in real time, and enables closed-loop force control of the grinding process. Compared with conventional force-sensing approaches, AFRG achieves a 4-fold improvement in consistency across different grinding disc conditions. AFRG relies solely on a low-cost microphone, which is approximately 200-fold cheaper than conventional force sensors, as the sensing modality, providing an easily deployable, cost-effective robotic grinding solution.","authors":["Zongyuan Zhang","Christopher Lehnert","Will N. Browne","Jonathan M. Roberts"],"pdf_url":"","comment":"Accepted to IEEE International Conference on Robotics and Automation (ICRA) 2026. 8 pages, 10 figures"},{"id":"http://arxiv.org/abs/2602.16705v2","updated":"2026-02-24T06:15:16Z","published":"2026-02-18T18:55:02Z","title":"Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation","summary":"Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.","authors":["Runpei Dong","Ziyan Li","Xialin He","Saurabh Gupta"],"pdf_url":"","comment":"Project page: https://hero-humanoid.github.io/"},{"id":"http://arxiv.org/abs/2602.20584v1","updated":"2026-02-24T06:12:51Z","published":"2026-02-24T06:12:51Z","title":"Long-Term Multi-Session 3D Reconstruction Under Substantial Appearance Change","summary":"Long-term environmental monitoring requires the ability to reconstruct and align 3D models across repeated site visits separated by months or years. However, existing Structure-from-Motion (SfM) pipelines implicitly assume near-simultaneous image capture and limited appearance change, and therefore fail when applied to long-term monitoring scenarios such as coral reef surveys, where substantial visual and structural change is common. In this paper, we show that the primary limitation of current approaches lies in their reliance on post-hoc alignment of independently reconstructed sessions, which is insufficient under large temporal appearance change. We address this limitation by enforcing cross-session correspondences directly within a joint SfM reconstruction. Our approach combines complementary handcrafted and learned visual features to robustly establish correspondences across large temporal gaps, enabling the reconstruction of a single coherent 3D model from imagery captured years apart, where standard independent and joint SfM pipelines break down. We evaluate our method on long-term coral reef datasets exhibiting significant real-world change, and demonstrate consistent joint reconstruction across sessions in cases where existing methods fail to produce coherent reconstructions. To ensure scalability to large datasets, we further restrict expensive learned feature matching to a small set of likely cross-session image pairs identified via visual place recognition, which reduces computational cost and improves alignment robustness.","authors":["Beverley Gorry","Tobias Fischer","Michael Milford","Alejandro Fontan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20566v1","updated":"2026-02-24T05:31:52Z","published":"2026-02-24T05:31:52Z","title":"BFA++: Hierarchical Best-Feature-Aware Token Prune for Multi-View Vision Language Action Model","summary":"Vision-Language-Action (VLA) models have achieved significant breakthroughs by leveraging Large Vision Language Models (VLMs) to jointly interpret instructions and visual inputs. However, the substantial increase in visual tokens, particularly from multi-view inputs, poses serious challenges to real-time robotic manipulation. Existing acceleration techniques for VLMs, such as token pruning, often result in degraded performance when directly applied to VLA models, as they overlook the relationships between different views and fail to account for the dynamic and task-specific characteristics of robotic operation. To address this, we propose BFA++, a dynamic token pruning framework designed specifically for VLA models. BFA++ introduces a hierarchical pruning strategy guided by two-level importance predictors: an intra-view predictor highlights task-relevant regions within each image to suppress spatial noise, while an inter-view predictor identifies critical camera views throughout different manipulation phases to reduce cross-view redundancy. This design enables efficient token selection while preserving essential visual cues, resulting in improved computational efficiency and higher manipulation success rates. Evaluations on the RoboTwin benchmark and real-world robotic tasks demonstrate that BFA++ consistently outperforms existing methods. BFA++ improves the success rate by about 10% on both the π0 and RDT models, achieving speedup of 1.8X and 1.5X, respectively. Our results highlight that context-sensitive and task-aware token pruning serves as a more effective strategy than full visual processing, enabling faster inference and improved manipulation accuracy in real-world robotic systems.","authors":["Haosheng Li","Weixin Mao","Zihan Lan","Hongwei Xiong","Hongan Wang","Chenyang Si","Ziwei Liu","Xiaoming Deng","Hua Chen"],"pdf_url":"","comment":"9 pages, 10 figures"},{"id":"http://arxiv.org/abs/2507.08100v2","updated":"2026-02-24T04:52:56Z","published":"2025-07-10T18:28:52Z","title":"Noise-enabled goal attainment in crowded collectives","summary":"In crowded environments, individuals must navigate around other occupants to reach their destinations. Understanding and controlling traffic flows in these spaces is relevant for coordinating robot swarms and designing infrastructure for dense populations. Here, we use simulations, theory, and experiments to study how adding stochasticity to agent motion can reduce traffic jams and help agents travel more quickly to prescribed goals. A computational approach reveals the collective behavior. Above a critical noise level, large jams do not persist. From this observation, we analytically approximate the swarm's goal attainment rate, which allows us to solve for the agent density and noise level that maximize the goals reached. Robotic experiments corroborate the behaviors observed in our simulated and theoretical results. Finally, we compare simple, local navigation approaches with a sophisticated but computationally costly central planner. A simple reactive scheme performs well up to moderate densities and is far more computationally efficient than a planner, motivating further research into robust, decentralized navigation methods for crowded environments. By integrating ideas from physics and engineering using simulations, theory, and experiments, our work identifies new directions for emergent traffic research.","authors":["Lucy Liu","Justin Werfel","Federico Toschi","L. Mahadevan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18316v3","updated":"2026-02-24T04:22:29Z","published":"2025-10-21T05:56:47Z","title":"MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation","summary":"Imitation learning from large-scale, diverse human demonstrations has been shown to be effective for training robots, but collecting such data is costly and time-consuming. This challenge intensifies for multi-step bimanual mobile manipulation, where humans must teleoperate both the mobile base and two high-DoF arms. Prior X-Gen works have developed automated data generation frameworks for static (bimanual) manipulation tasks, augmenting a few human demos in simulation with novel scene configurations to synthesize large-scale datasets. However, prior works fall short for bimanual mobile manipulation tasks for two major reasons: 1) a mobile base introduces the problem of how to place the robot base to enable downstream manipulation (reachability) and 2) an active camera introduces the problem of how to position the camera to generate data for a visuomotor policy (visibility). To address these challenges, MoMaGen formulates data generation as a constrained optimization problem that satisfies hard constraints (e.g., reachability) while balancing soft constraints (e.g., visibility while navigation). This formulation generalizes across most existing automated data generation approaches and offers a principled foundation for developing future methods. We evaluate on four multi-step bimanual mobile manipulation tasks and find that MoMaGen enables the generation of much more diverse datasets than previous methods. As a result of the dataset diversity, we also show that the data generated by MoMaGen can be used to train successful imitation learning policies using a single source demo. Furthermore, the trained policy can be fine-tuned with a very small amount of real-world data (40 demos) to be succesfully deployed on real robotic hardware. More details are on our project page: momagen.github.io.","authors":["Chengshu Li","Mengdi Xu","Arpit Bahety","Hang Yin","Yunfan Jiang","Huang Huang","Josiah Wong","Sujay Garlanka","Cem Gokmen","Ruohan Zhang","Weiyu Liu","Jiajun Wu","Roberto Martín-Martín","Li Fei-Fei"],"pdf_url":"","comment":"Project website: momagen.github.io. The first four authors contribute equally. Accpeted to International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2509.07411v2","updated":"2026-02-24T03:33:22Z","published":"2025-09-09T05:49:36Z","title":"Adaptive Evolutionary Framework for Safe, Efficient, and Cooperative Autonomous Vehicle Interactions","summary":"Modern transportation systems face significant challenges in ensuring road safety, given serious injuries caused by road accidents. The rapid growth of autonomous vehicles (AVs) has prompted new traffic designs that aim to optimize interactions among AVs. However, effective interactions between AVs remains challenging due to the absence of centralized control. Besides, there is a need for balancing multiple factors, including passenger demands and overall traffic efficiency. Traditional rule-based, optimization-based, and game-theoretic approaches each have limitations in addressing these challenges. Rule-based methods struggle with adaptability and generalization in complex scenarios, while optimization-based methods often require high computational resources. Game-theoretic approaches, such as Stackelberg and Nash games, suffer from limited adaptability and potential inefficiencies in cooperative settings. This paper proposes an Evolutionary Game Theory (EGT)-based framework for AV interactions that overcomes these limitations by utilizing a decentralized and adaptive strategy evolution mechanism. A causal evaluation module (CEGT) is introduced to optimize the evolutionary rate, balancing mutation and evolution by learning from historical interactions. Simulation results demonstrate the proposed CEGT outperforms EGT and popular benchmark games in terms of lower collision rates, improved safety distances, higher speeds, and overall better performance compared to Nash and Stackelberg games across diverse scenarios and parameter settings.","authors":["Yijun Lu","Zhen Tian","Zhihao Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20512v1","updated":"2026-02-24T03:29:27Z","published":"2026-02-24T03:29:27Z","title":"Conflict-Based Search for Multi-Agent Path Finding with Elevators","summary":"This paper investigates a problem called Multi-Agent Path Finding with Elevators (MAPF-E), which seeks conflict-free paths for multiple agents from their start to goal locations that may locate on different floors, and the agents can use elevators to travel between floors. The existence of elevators complicates the interaction among the agents and introduces new challenges to the planning. On the one hand, elevators can cause many conflicts among the agents due to its relatively long traversal time across floors, especially when many agents need to reach a different floor. On the other hand, the planner has to reason in a larger state space including the states of the elevators, besides the locations of the agents.","authors":["Haitong He","Xuemian Wu","Shizhe Zhao","Zhongqiang Ren"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20500v1","updated":"2026-02-24T02:56:39Z","published":"2026-02-24T02:56:39Z","title":"Strategy-Supervised Autonomous Laparoscopic Camera Control via Event-Driven Graph Mining","summary":"Autonomous laparoscopic camera control must maintain a stable and safe surgical view under rapid tool-tissue interactions while remaining interpretable to surgeons. We present a strategy-grounded framework that couples high-level vision-language inference with low-level closed-loop control. Offline, raw surgical videos are parsed into camera-relevant temporal events (e.g., interaction, working-distance deviation, and view-quality degradation) and structured as attributed event graphs. Mining these graphs yields a compact set of reusable camera-handling strategy primitives, which provide structured supervision for learning. Online, a fine-tuned Vision-Language Model (VLM) processes the live laparoscopic view to predict the dominant strategy and discrete image-based motion commands, executed by an IBVS-RCM controller under strict safety constraints; optional speech input enables intuitive human-in-the-loop conditioning. On a surgeon-annotated dataset, event parsing achieves reliable temporal localization (F1-score 0.86), and the mined strategies show strong semantic alignment with expert interpretation (cluster purity 0.81). Extensive ex vivo experiments on silicone phantoms and porcine tissues demonstrate that the proposed system outperforms junior surgeons in standardized camera-handling evaluations, reducing field-of-view centering error by 35.26% and image shaking by 62.33%, while preserving smooth motion and stable working-distance regulation.","authors":["Keyu Zhou","Peisen Xu","Yahao Wu","Jiming Chen","Gaofeng Li","Shunlei Li"],"pdf_url":"","comment":"Submitted to IEEE Transactions on Robotics (T-RO). 19 pages, 9 figures"},{"id":"http://arxiv.org/abs/2602.20466v1","updated":"2026-02-24T01:53:39Z","published":"2026-02-24T01:53:39Z","title":"Grasp to Act: Dexterous Grasping for Tool Use in Dynamic Settings","summary":"Achieving robust grasping with dexterous hands remains challenging, especially when manipulation involves dynamic forces such as impacts, torques, and continuous resistance--situations common in real-world tool use. Existing methods largely optimize grasps for static geometric stability and often fail once external forces arise during manipulation. We present Grasp-to-Act, a hybrid system that combines physics-based grasp optimization with reinforcement-learning-based grasp adaptation to maintain stable grasps throughout functional manipulation tasks. Our method synthesizes robust grasp configurations informed by human demonstrations and employs an adaptive controller that residually issues joint corrections to prevent in-hand slip while tracking the object trajectory. Grasp-to-Act enables robust zero-shot sim-to-real transfer across five dynamic tool-use tasks--hammering, sawing, cutting, stirring, and scooping--consistently outperforming baselines. Across simulation and real-world hardware trials with a 16-DoF dexterous hand, our method reduces translational and rotational in-hand slip and achieves the highest task completion rates, demonstrating stable functional grasps under dynamic, contact-rich conditions.","authors":["Harsh Gupta","Mohammad Amin Mirzaee","Wenzhen Yuan"],"pdf_url":"","comment":"Result videos can be found at https://grasp2act.github.io/"},{"id":"http://arxiv.org/abs/2504.13647v2","updated":"2026-02-24T01:43:54Z","published":"2025-04-18T11:59:34Z","title":"An Efficient LiDAR-Camera Fusion Network for Multi-Class 3D Dynamic Object Detection and Trajectory Prediction","summary":"Service mobile robots are often required to avoid dynamic objects while performing their tasks, but they usually have only limited computational resources. To further advance the practical application of service robots in complex dynamic environments, we propose an efficient multi-modal framework for 3D object detection and trajectory prediction, which synergistically integrates LiDAR and camera inputs to achieve real-time perception of pedestrians, vehicles, and riders in 3D space.The framework incorporates two novel models: 1) a Unified modality detector with Mamba and Transformer (UniMT) for object detection, which achieves high-accuracy object detection with fast inference speed, and 2) a Reference Trajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse trajectory prediction of multi-class objects with flexible-length trajectories. Evaluations on the CODa benchmark demonstrate that our method outperforms existing ones in both detection (+3.71\\% in mAP) and trajectory prediction (-0.408m in minADE$_5$ of pedestrians) metrics. Furthermore, on the challenging nuScenes detection benchmark, our detection model achieves competitive performance among LiDAR-camera fusion methods, with a mAP of 72.7\\% and NDS of 75.3\\%. Remarkably, the system demonstrates exceptional generalizability and practical deployment potential. When transferred and implemented on a wheelchair robot with an entry-level NVIDIA RTX 3060 GPU, it achieves real-time inference at 13.9 frames per second (FPS) with satisfactory accuracy. To facilitate reproducibility and practical deployment, we release the related code of the method at \\href{https://github.com/TossherO/3D_Perception}{https://github.com/TossherO/3D\\_Perception} and its ROS inference version at \\href{https://github.com/TossherO/ros_packages}{https://github.com/TossherO/ros\\_packages}.","authors":["Yushen He","Lei Zhao","Tianchen Deng","Zipeng Fang","Weidong Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05662v2","updated":"2026-02-24T00:07:47Z","published":"2025-10-07T08:18:29Z","title":"DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation","summary":"Despite the prevalence of transparent object interactions in human everyday life, transparent robotic manipulation research remains limited to short-horizon tasks and basic grasping capabilities. Although some methods have partially addressed these issues, most of them have limitations in generalization to novel objects and are insufficient for precise long-horizon robot manipulation. To address this limitation, we propose DeLTa (Demonstration and Language-Guided Novel Transparent Object Manipulation), a novel framework that integrates depth estimation, 6D pose estimation, and vision-language planning for precise long-horizon manipulation of transparent objects guided by natural language task instructions. A key advantage of our method is its single-demonstration approach, which generalizes 6D trajectories to novel transparent objects without requiring category-level priors or additional training. Additionally, we present a task planner that refines the VLM-generated plan to account for the constraints of a single-arm, eye-in-hand robot for long-horizon object manipulation tasks. Through comprehensive evaluation, we demonstrate that our method significantly outperforms existing transparent object manipulation approaches, particularly in long-horizon scenarios requiring precise manipulation capabilities. Project page: https://sites.google.com/view/DeLTa25/","authors":["Taeyeop Lee","Gyuree Kang","Bowen Wen","Youngho Kim","Seunghyeok Back","In So Kweon","David Hyunchul Shim","Kuk-Jin Yoon"],"pdf_url":"","comment":"Project page: https://sites.google.com/view/DeLTa25/"},{"id":"http://arxiv.org/abs/2602.21445v1","updated":"2026-02-24T23:48:48Z","published":"2026-02-24T23:48:48Z","title":"VLA Knows Its Limits","summary":"Action chunking has recently emerged as a standard practice in flow-based Vision-Language-Action (VLA) models. However, the effect and choice of the execution horizon - the number of actions to be executed from each predicted chunk - remains underexplored. In this work, we first show that varying the execution horizon leads to substantial performance deviations, with performance initially improving and then declining as the horizon increases. To uncover the reasons, we analyze the cross- and self-attention weights in flow-based VLAs and reveal two key phenomena: (i) intra-chunk actions attend invariantly to vision-language tokens, limiting adaptability to environmental changes; and (ii) the initial and terminal action tokens serve as stable anchors, forming latent centers around which intermediate actions are organized. Motivated by these insights, we interpret action self-attention weights as a proxy for the model's predictive limit and propose AutoHorizon, the first test-time method that dynamically estimates the execution horizon for each predicted action chunk to adapt to changing perceptual conditions. Across simulated and real-world robotic manipulation tasks, AutoHorizon is performant, incurs negligible computational overhead, and generalizes across diverse tasks and flow-based models.","authors":["Haoxuan Wang","Gengyu Zhang","Yan Yan","Ramana Rao Kompella","Gaowen Liu"],"pdf_url":"","comment":"Project page at https://hatchetproject.github.io/autohorizon/"},{"id":"http://arxiv.org/abs/2602.21418v1","updated":"2026-02-24T22:45:01Z","published":"2026-02-24T22:45:01Z","title":"Event-Driven On-Sensor Locomotion Mode Recognition Using a Shank-Mounted IMU with Embedded Machine Learning for Exoskeleton Control","summary":"This work presents a wearable human activity recognition (HAR) system that performs real-time inference directly inside a shank-mounted inertial measurement unit (IMU) to support low-latency control of a lower-limb exoskeleton. Unlike conventional approaches that continuously stream raw inertial data to a microcontroller for classification, the proposed system executes activity recognition at the sensor level using the embedded Machine Learning Core (MLC) of the STMicroelectronics LSM6DSV16X IMU, allowing the host microcontroller to remain in a low-power state and read only the recognized activity label from IMU registers. While the system generalizes to multiple human activities, this paper focuses on three representative locomotion modes - stance, level walking, and stair ascent - using data collected from adult participants. A lightweight decision-tree model was configured and deployed for on-sensor execution using ST MEMS Studio, enabling continuous operation without custom machine learning code on the microcontroller. During operation, the IMU asserts an interrupt when motion or a new classification is detected; the microcontroller wakes, reads the MLC output registers, and forwards the inferred mode to the exoskeleton controller. This interrupt-driven, on-sensor inference architecture reduces computation and communication overhead while preserving battery energy and improving robustness in distinguishing level walking from stair ascent for torque-assist control.","authors":["Mohammadsaleh Razmi","Iman Shojaei"],"pdf_url":"","comment":"10 pages, 6 figures. Sensor-level HAR using embedded IMU machine learning for wearable robotics"},{"id":"http://arxiv.org/abs/2504.21841v3","updated":"2026-02-24T22:29:57Z","published":"2025-04-30T17:51:20Z","title":"Neuro-Symbolic Generation of Explanations for Robot Policies with Weighted Signal Temporal Logic","summary":"Neural network-based policies have demonstrated success in many robotic applications, but often lack human-explanability, which poses challenges in safety-critical deployments. To address this, we propose a neuro-symbolic explanation framework that generates a weighted signal temporal logic (wSTL) specification to describe a robot policy in a interpretable form. Existing methods typically produce explanations that are verbose and inconsistent, which hinders explainability, and loose, which do not give meaningful insights into the underlying policy. We address these issues by introducing a simplification process consisting of predicate filtering, regularization, and iterative pruning. We also introduce three novel explainability evaluation metrics -- conciseness, consistency, and strictness -- to assess explanation quality beyond conventional classification metrics. Our method is validated in three simulated robotic environments, where it outperforms baselines in generating concise, consistent, and strict wSTL explanations without sacrificing classification accuracy. This work bridges policy learning with formal methods, contributing to safer and more transparent decision-making in robotics.","authors":["Mikihisa Yuasa","Ramavarapu S. Sreenivas","Huy T. Tran"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13595v2","updated":"2026-02-24T22:21:28Z","published":"2025-10-15T14:24:57Z","title":"Active Tactile Exploration for Rigid Body Pose and Shape Estimation","summary":"General robot manipulation requires the handling of previously unseen objects. Learning a physically accurate model at test time can provide significant benefits in data efficiency, predictability, and reuse between tasks. Tactile sensing can compliment vision with its robustness to occlusion, but its temporal sparsity necessitates careful online exploration to maintain data efficiency. Direct contact can also cause an unrestrained object to move, requiring both shape and location estimation. In this work, we propose a learning and exploration framework that uses only tactile data to simultaneously determine the shape and location of rigid objects with minimal robot motion. We build on recent advances in contact-rich system identification to formulate a loss function that penalizes physical constraint violation without introducing the numerical stiffness inherent in rigid-body contact. Optimizing this loss, we can learn cuboid and convex polyhedral geometries with less than 10s of randomly collected data after first contact. Our exploration scheme seeks to maximize Expected Information Gain and results in significantly faster learning in both simulated and real-robot experiments. More information can be found at https://dairlab.github.io/activetactile","authors":["Ethan K. Gordon","Bruke Baraki","Hien Bui","Michael Posa"],"pdf_url":"","comment":"Presented at ICRA 2026; 8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2511.00062v2","updated":"2026-02-24T21:52:50Z","published":"2025-10-28T22:44:13Z","title":"World Simulation with Video Foundation Models for Physical AI","summary":"We introduce [Cosmos-Predict2.5], the latest generation of the Cosmos World Foundation Models for Physical AI. Built on a flow-based architecture, [Cosmos-Predict2.5] unifies Text2World, Image2World, and Video2World generation in a single model and leverages [Cosmos-Reason1], a Physical AI vision-language model, to provide richer text grounding and finer control of world simulation. Trained on 200M curated video clips and refined with reinforcement learning-based post-training, [Cosmos-Predict2.5] achieves substantial improvements over [Cosmos-Predict1] in video quality and instruction alignment, with models released at 2B and 14B scales. These capabilities enable more reliable synthetic data generation, policy evaluation, and closed-loop simulation for robotics and autonomous systems. We further extend the family with [Cosmos-Transfer2.5], a control-net style framework for Sim2Real and Real2Real world translation. Despite being 3.5$\\times$ smaller than [Cosmos-Transfer1], it delivers higher fidelity and robust long-horizon video generation. Together, these advances establish [Cosmos-Predict2.5] and [Cosmos-Transfer2.5] as versatile tools for scaling embodied intelligence. To accelerate research and deployment in Physical AI, we release source code, pretrained checkpoints, and curated benchmarks under the NVIDIA Open Model License at https://github.com/nvidia-cosmos/cosmos-predict2.5 and https://github.com/nvidia-cosmos/cosmos-transfer2.5. We hope these open resources lower the barrier to adoption and foster innovation in building the next generation of embodied intelligence.","authors":[" NVIDIA"," :","Arslan Ali","Junjie Bai","Maciej Bala","Yogesh Balaji","Aaron Blakeman","Tiffany Cai","Jiaxin Cao","Tianshi Cao","Elizabeth Cha","Yu-Wei Chao","Prithvijit Chattopadhyay","Mike Chen","Yongxin Chen","Yu Chen","Shuai Cheng","Yin Cui","Jenna Diamond","Yifan Ding","Jiaojiao Fan","Linxi Fan","Liang Feng","Francesco Ferroni","Sanja Fidler","Xiao Fu","Ruiyuan Gao","Yunhao Ge","Jinwei Gu","Aryaman Gupta","Siddharth Gururani","Imad El Hanafi","Ali Hassani","Zekun Hao","Jacob Huffman","Joel Jang","Pooya Jannaty","Jan Kautz","Grace Lam","Xuan Li","Zhaoshuo Li","Maosheng Liao","Chen-Hsuan Lin","Tsung-Yi Lin","Yen-Chen Lin","Huan Ling","Ming-Yu Liu","Xian Liu","Yifan Lu","Alice Luo","Qianli Ma","Hanzi Mao","Kaichun Mo","Seungjun Nah","Yashraj Narang","Abhijeet Panaskar","Lindsey Pavao","Trung Pham","Morteza Ramezanali","Fitsum Reda","Scott Reed","Xuanchi Ren","Haonan Shao","Yue Shen","Stella Shi","Shuran Song","Bartosz Stefaniak","Shangkun Sun","Shitao Tang","Sameena Tasmeen","Lyne Tchapmi","Wei-Cheng Tseng","Jibin Varghese","Andrew Z. Wang","Hao Wang","Haoxiang Wang","Heng Wang","Ting-Chun Wang","Fangyin Wei","Jiashu Xu","Dinghao Yang","Xiaodong Yang","Haotian Ye","Seonghyeon Ye","Xiaohui Zeng","Jing Zhang","Qinsheng Zhang","Kaiwen Zheng","Andrew Zhu","Yuke Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21389v1","updated":"2026-02-24T21:36:19Z","published":"2026-02-24T21:36:19Z","title":"Autonomous Sea Turtle Robot for Marine Fieldwork","summary":"Autonomous robots can transform how we observe marine ecosystems, but close-range operation in reefs and other cluttered habitats remains difficult. Vehicles must maneuver safely near animals and fragile structures while coping with currents, variable illumination and limited sensing. Previous approaches simplify these problems by leveraging soft materials and bioinspired swimming designs, but such platforms remain limited in terms of deployable autonomy. Here we present a sea turtle-inspired autonomous underwater robot that closed the gap between bioinspired locomotion and field-ready autonomy through a tightly integrated, vision-driven control stack. The robot combines robust depth-heading stabilization with obstacle avoidance and target-centric control, enabling it to track and interact with moving objects in complex terrain. We validate the robot in controlled pool experiments and in a live coral reef exhibit at the New England Aquarium, demonstrating stable operation and reliable tracking of fast-moving marine animals and human divers. To the best of our knowledge, this is the first integrated biomimetic robotic system, combining novel hardware, control, and field experiments, deployed to track and monitor real marine animals in their natural environment. During off-tether experiments, we demonstrate safe navigation around obstacles (91\\% success rate in the aquarium exhibit) and introduce a low-compute onboard tracking mode. Together, these results establish a practical route toward soft-rigid hybrid, bioinspired underwater robots capable of minimally disruptive exploration and close-range monitoring in sensitive ecosystems.","authors":["Zach J. Patterson","Emily Sologuren","Levi Cai","Daniel Kim","Alaa Maalouf","Pascal Spino","Daniela Rus"],"pdf_url":"","comment":"22 pages, 3 figures, 1 table, 5 supplementary figures, 1 supplementary table. Submitted for review"},{"id":"http://arxiv.org/abs/2602.21366v1","updated":"2026-02-24T20:59:09Z","published":"2026-02-24T20:59:09Z","title":"Environment-Aware Learning of Smooth GNSS Covariance Dynamics for Autonomous Racing","summary":"Ensuring accurate and stable state estimation is a challenging task crucial to safety-critical domains such as high-speed autonomous racing, where measurement uncertainty must be both adaptive to the environment and temporally smooth for control. In this work, we develop a learning-based framework, LACE, capable of directly modeling the temporal dynamics of GNSS measurement covariance. We model the covariance evolution as an exponentially stable dynamical system where a deep neural network (DNN) learns to predict the system's process noise from environmental features through an attention mechanism. By using contraction-based stability and systematically imposing spectral constraints, we formally provide guarantees of exponential stability and smoothness for the resulting covariance dynamics. We validate our approach on an AV-24 autonomous racecar, demonstrating improved localization performance and smoother covariance estimates in challenging, GNSS-degraded environments. Our results highlight the promise of dynamically modeling the perceived uncertainty in state estimation problems that are tightly coupled with control sensitivity.","authors":["Y. Deemo Chen","Arion Zimmermann","Thomas A. Berrueta","Soon-Jo Chung"],"pdf_url":"","comment":"8 pages, Accepted to IEEE International Conference on Robotics and Automation (ICRA) 2026"},{"id":"http://arxiv.org/abs/2506.21427v3","updated":"2026-02-24T20:26:25Z","published":"2025-06-26T16:09:53Z","title":"Flow-Based Single-Step Completion for Efficient and Expressive Policy Learning","summary":"Generative models such as diffusion and flow-matching offer expressive policies for offline reinforcement learning (RL) by capturing rich, multimodal action distributions, but their iterative sampling introduces high inference costs and training instability due to gradient propagation across sampling steps. We propose the Single-Step Completion Policy (SSCP), a generative policy trained with an augmented flow-matching objective to predict direct completion vectors from intermediate flow samples, enabling accurate, one-shot action generation. In an off-policy actor-critic framework, SSCP combines the expressiveness of generative models with the training and inference efficiency of unimodal policies, without requiring long backpropagation chains. Our method scales effectively to offline, offline-to-online, and online RL settings, offering substantial gains in speed and adaptability over diffusion-based baselines. We further extend SSCP to goal-conditioned RL, enabling flat policies to exploit subgoal structures without explicit hierarchical inference. SSCP achieves strong results across standard offline RL and behavior cloning benchmarks, positioning it as a versatile, expressive, and efficient framework for deep RL and sequential decision-making. The code is available at https://github.com/PrajwalKoirala/SSCP-Single-Step-Completion-Policy.","authors":["Prajwal Koirala","Cody Fleming"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.19983v2","updated":"2026-02-24T20:23:23Z","published":"2026-02-23T15:51:23Z","title":"Contextual Safety Reasoning and Grounding for Open-World Robots","summary":"Robots are increasingly operating in open-world environments where safe behavior depends on context: the same hallway may require different navigation strategies when crowded versus empty, or during an emergency versus normal operations. Traditional safety approaches enforce fixed constraints in user-specified contexts, limiting their ability to handle the open-ended contextual variability of real-world deployment. We address this gap via CORE, a safety framework that enables online contextual reasoning, grounding, and enforcement without prior knowledge of the environment (e.g., maps or safety specifications). CORE uses a vision-language model (VLM) to continuously reason about context-dependent safety rules directly from visual observations, grounds these rules in the physical environment, and enforces the resulting spatially-defined safe sets via control barrier functions. We provide probabilistic safety guarantees for CORE that account for perceptual uncertainty, and we demonstrate through simulation and real-world experiments that CORE enforces contextually appropriate behavior in unseen environments, significantly outperforming prior semantic safety methods that lack online contextual reasoning. Ablation studies validate our theoretical guarantees and underscore the importance of both VLM-based reasoning and spatial grounding for enforcing contextual safety in novel settings. We provide additional resources at https://zacravichandran.github.io/CORE.","authors":["Zachary Ravichandran","David Snyder","Alexander Robey","Hamed Hassani","Vijay Kumar","George J. Pappas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21331v1","updated":"2026-02-24T20:01:29Z","published":"2026-02-24T20:01:29Z","title":"CableRobotGraphSim: A Graph Neural Network for Modeling Partially Observable Cable-Driven Robot Dynamics","summary":"General-purpose simulators have accelerated the development of robots. Traditional simulators based on first-principles, however, typically require full-state observability or depend on parameter search for system identification. This work presents \\texttt{CableRobotGraphSim}, a novel Graph Neural Network (GNN) model for cable-driven robots that aims to address shortcomings of prior simulation solutions. By representing cable-driven robots as graphs, with the rigid-bodies as nodes and the cables and contacts as edges, this model can quickly and accurately match the properties of other simulation models and real robots, while ingesting only partially observable inputs. Accompanying the GNN model is a sim-and-real co-training procedure that promotes generalization and robustness to noisy real data. This model is further integrated with a Model Predictive Path Integral (MPPI) controller for closed-loop navigation, which showcases the model's speed and accuracy.","authors":["Nelson Chen","William R. Johnson","Rebecca Kramer-Bottiglio","Kostas Bekris","Mridul Aanjaneya"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.11791v2","updated":"2026-02-24T19:55:03Z","published":"2025-09-15T11:22:40Z","title":"Synthetic vs. Real Training Data for Visual Navigation","summary":"This paper investigates how the performance of visual navigation policies trained in simulation compares to policies trained with real-world data. Performance degradation of simulator-trained policies is often significant when they are evaluated in the real world. However, despite this well-known sim-to-real gap, we demonstrate that simulator-trained policies can match the performance of their real-world-trained counterparts.\n  Central to our approach is a navigation policy architecture that bridges the sim-to-real appearance gap by leveraging pretrained visual representations and runs real-time on robot hardware. Evaluations on a wheeled mobile robot show that the proposed policy, when trained in simulation, outperforms its real-world-trained version by 31 and the prior state-of-the-art methods by 50 points in navigation success rate. Policy generalization is verified by deploying the same model onboard a drone.\n  Our results highlight the importance of diverse image encoder pretraining for sim-to-real generalization, and identify on-policy learning as a key advantage of simulated training over training with real data. Code, model checkpoints and multimedia materials are available at https://lasuomela.github.io/faint/","authors":["Lauri Suomela","Sasanka Kuruppu Arachchige","German F. Torres","Harry Edelman","Joni-Kristian Kämäräinen"],"pdf_url":"","comment":"ICRA2026 Camera ready"},{"id":"http://arxiv.org/abs/2509.21073v2","updated":"2026-02-24T19:54:15Z","published":"2025-09-25T12:23:57Z","title":"Normalizing Flows are Capable Models for Bi-manual Visuomotor Policy","summary":"The field of general-purpose robotics has recently embraced powerful probabilistic diffusion-based models to learn the complex embodiment behaviours. However, existing models often come with significant trade-offs, namely high computational costs for inference and a fundamental inability to quantify output uncertainty. We introduce Normalizing Flows Policy (NF-P), a conditional normalizing flow-based visuomotor policy for bi-manual manipulation. NF-P learns a conditional density over action sequences and enables single-pass generative sampling with tractable likelihood computation. Using this property, we propose two inference-time optimization strategies: Stochastic Batch Selection, which selects the highest-likelihood trajectory among sampled candidates, and Gradient Refinement, which directly ascends the log-likelihood to improve action quality. In both simulation and real robot experiments, NF-P achieves promising success rates compared to the baseline. In addition to improved task performance, NF-P demonstrates faster training and lower inference latency. These results establish normalizing flows as a competitive and computationally efficient visuomotor policy, particularly for real-time, uncertainty-aware robotic control.","authors":["Jialong Li","Simon Kristoffersson Lind","Wenrui Xie","Maj Stenmark","Volker Krüger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21319v1","updated":"2026-02-24T19:40:37Z","published":"2026-02-24T19:40:37Z","title":"Uncertainty-Aware Diffusion Model for Multimodal Highway Trajectory Prediction via DDIM Sampling","summary":"Accurate and uncertainty-aware trajectory prediction remains a core challenge for autonomous driving, driven by complex multi-agent interactions, diverse scene contexts and the inherently stochastic nature of future motion. Diffusion-based generative models have recently shown strong potential for capturing multimodal futures, yet existing approaches such as cVMD suffer from slow sampling, limited exploitation of generative diversity and brittle scenario encodings.\n  This work introduces cVMDx, an enhanced diffusion-based trajectory prediction framework that improves efficiency, robustness and multimodal predictive capability. Through DDIM sampling, cVMDx achieves up to a 100x reduction in inference time, enabling practical multi-sample generation for uncertainty estimation. A fitted Gaussian Mixture Model further provides tractable multimodal predictions from the generated trajectories. In addition, a CVQ-VAE variant is evaluated for scenario encoding. Experiments on the publicly available highD dataset show that cVMDx achieves higher accuracy and significantly improved efficiency over cVMD, enabling fully stochastic, multimodal trajectory prediction.","authors":["Marion Neumeier","Niklas Roßberg","Michael Botsch","Wolfgang Utschick"],"pdf_url":"","comment":"Accepted as a conference paper in IEEE Intelligent Vehicles Symposium (IV) 2026, Detroit, MI, United States"},{"id":"http://arxiv.org/abs/2602.21316v1","updated":"2026-02-24T19:37:36Z","published":"2026-02-24T19:37:36Z","title":"Unified Complementarity-Based Contact Modeling and Planning for Soft Robots","summary":"Soft robots were introduced in large part to enable safe, adaptive interaction with the environment, and this interaction relies fundamentally on contact. However, modeling and planning contact-rich interactions for soft robots remain challenging: dense contact candidates along the body create redundant constraints and rank-deficient LCPs, while the disparity between high stiffness and low friction introduces severe ill-conditioning. Existing approaches rely on problem-specific approximations or penalty-based treatments. This letter presents a unified complementarity-based framework for soft-robot contact modeling and planning that brings contact modeling, manipulation, and planning into a unified, physically consistent formulation. We develop a robust Linear Complementarity Problem (LCP) model tailored to discretized soft robots and address these challenges with a three-stage conditioning pipeline: inertial rank selection to remove redundant contacts, Ruiz equilibration to correct scale disparity and ill-conditioning, and lightweight Tikhonov regularization on normal blocks. Building on the same formulation, we introduce a kinematically guided warm-start strategy that enables dynamic trajectory optimization through contact using Mathematical Programs with Complementarity Constraints (MPCC) and demonstrate its effectiveness on contact-rich ball manipulation tasks. In conclusion, CUSP provides a new foundation for unifying contact modeling, simulation, and planning in soft robotics.","authors":["Milad Azizkhani","Yue Chen"],"pdf_url":"","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2409.07563v4","updated":"2026-02-24T19:21:16Z","published":"2024-09-11T18:31:33Z","title":"MPPI-Generic: A CUDA Library for Stochastic Trajectory Optimization","summary":"This paper introduces a new C++/CUDA library for GPU-accelerated stochastic optimization called MPPI-Generic. It provides implementations of Model Predictive Path Integral control, Tube-Model Predictive Path Integral Control, and Robust Model Predictive Path Integral Control, and allows for these algorithms to be used across many pre-existing dynamics models and cost functions. Furthermore, researchers can create their own dynamics models or cost functions following our API definitions without needing to change the actual Model Predictive Path Integral Control code. Finally, we compare computational performance to other popular implementations of Model Predictive Path Integral Control over a variety of GPUs to show the real-time capabilities our library can allow for. Library code can be found at: https://acdslab.github.io/mppi-generic-website/ .","authors":["Bogdan Vlahov","Jason Gibson","Manan Gandhi","Evangelos A. Theodorou"],"pdf_url":"","comment":"Renamed ros2 comparisons to nav2 after feedback. Also added more tests on Jetson Orin Nano in the appendix"},{"id":"http://arxiv.org/abs/2602.21302v1","updated":"2026-02-24T19:13:25Z","published":"2026-02-24T19:13:25Z","title":"Learning Deformable Object Manipulation Using Task-Level Iterative Learning Control","summary":"Dynamic manipulation of deformable objects is challenging for humans and robots because they have infinite degrees of freedom and exhibit underactuated dynamics. We introduce a Task-Level Iterative Learning Control method for dynamic manipulation of deformable objects. We demonstrate this method on a non-planar rope manipulation task called the flying knot. Using a single human demonstration and a simplified rope model, the method learns directly on hardware without reliance on large amounts of demonstration data or massive amounts of simulation. At each iteration, the algorithm constructs a local inverse model of the robot and rope by solving a quadratic program to propagate task-space errors into action updates. We evaluate performance across 7 different kinds of ropes, including chain, latex surgical tubing, and braided and twisted ropes, ranging in thicknesses of 7--25mm and densities of 0.013--0.5 kg/m. Learning achieves a 100\\% success rate within 10 trials on all ropes. Furthermore, the method can successfully transfer between most rope types in approximately 2--5 trials. https://flying-knots.github.io","authors":["Krishna Suresh","Chris Atkeson"],"pdf_url":"","comment":"Project website: https://flying-knots.github.io"},{"id":"http://arxiv.org/abs/2602.21266v1","updated":"2026-02-24T09:47:31Z","published":"2026-02-24T09:47:31Z","title":"Dual-Branch INS/GNSS Fusion with Inequality and Equality Constraints","summary":"Reliable vehicle navigation in urban environments remains a challenging problem due to frequent satellite signal blockages caused by tall buildings and complex infrastructure. While fusing inertial reading with satellite positioning in an extended Kalman filter provides short-term navigation continuity, low-cost inertial sensors suffer from rapid error accumulation during prolonged outages. Existing information aiding approaches, such as the non-holonomic constraint, impose rigid equality assumptions on vehicle motion that may be violated under dynamic urban driving conditions, limiting their robustness precisely when aiding is most needed. In this paper, we propose a dual-branch information aiding framework that fuses equality and inequality motion constraints through a variance-weighted scheme, requiring only a software modification to an existing navigation filter with no additional sensors or hardware. The proposed method is evaluated on four publicly available urban datasets featuring various inertial sensors, road conditions, and dynamics, covering a total duration of 4.3 hours of recorded data. Under Full GNSS availability, the method reduces vertical position error by 16.7% and improves altitude accuracy by 50.1% over the standard non-holonomic constraint. Under GNSS-denied conditions, vertical drift is reduced by 24.2% and altitude accuracy improves by 20.2%. These results demonstrate that replacing hard motion equality assumptions with physically motivated inequality bounds is a practical and cost-free strategy for improving navigation resilience, continuity, and drift robustness without relying on additional sensors, map data, or learned models.","authors":["Mor Levenhar","Itzik Klein"],"pdf_url":"","comment":"12 pages, 5 figuers"},{"id":"http://arxiv.org/abs/2602.20963v1","updated":"2026-02-24T14:41:28Z","published":"2026-02-24T14:41:28Z","title":"A Robotic Testing Platform for Pipelined Discovery of Resilient Soft Actuators","summary":"Short lifetime under high electrical fields hinders the widespread robotic application of linear dielectric elastomer actuators (DEAs). Systematic scanning is difficult due to time-consuming per-sample testing and the high-dimensional parameter space affecting performance. To address this, we propose an optimization pipeline enabled by a novel testing robot capable of scanning DEA lifetime. The robot integrates electro-mechanical property measurement, programmable voltage input, and multi-channel testing capacity. Using it, we scanned the lifetime of Elastosil-based linear actuators across parameters including input voltage magnitude, frequency, electrode material concentration, and electrical connection filler. The optimal parameter combinations improved operational lifetime under boundary operating conditions by up to 100% and were subsequently scaled up to achieve higher force and displacement output. The final product demonstrated resilience on a modular, scalable quadruped walking robot with payload carrying capacity (>100% of its untethered body weight, and >700% of combined actuator weight). This work is the first to introduce a self-driving lab approach into robotic actuator design.","authors":["Ang Li","Alexander Yin","Alexander White","Sahib Sandhu","Matthew Francoeur","Victor Jimenez-Santiago","Van Remenar","Codrin Tugui","Mihai Duduta"],"pdf_url":"","comment":null}]},"2026-02-25T00:00:00Z":{"Artificial Intelligence (Agents & Multi-Agent Systems)":[{"id":"http://arxiv.org/abs/2602.22207v1","updated":"2026-02-25T18:58:25Z","published":"2026-02-25T18:58:25Z","title":"Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets","summary":"The reliability of multilingual Large Language Model (LLM) evaluation is currently compromised by the inconsistent quality of translated benchmarks. Existing resources often suffer from semantic drift and context loss, which can lead to misleading performance metrics. In this work, we present a fully automated framework designed to address these challenges by enabling scalable, high-quality translation of datasets and benchmarks. We demonstrate that adapting test-time compute scaling strategies, specifically Universal Self-Improvement (USI) and our proposed multi-round ranking method, T-RANK, allows for significantly higher quality outputs compared to traditional pipelines. Our framework ensures that benchmarks preserve their original task structure and linguistic nuances during localization. We apply this approach to translate popular benchmarks and datasets into eight Eastern and Southern European languages (Ukrainian, Bulgarian, Slovak, Romanian, Lithuanian, Estonian, Turkish, Greek). Evaluations using both reference-based metrics and LLM-as-a-judge show that our translations surpass existing resources, resulting in more accurate downstream model assessment. We release both the framework and the improved benchmarks to facilitate robust and reproducible multilingual AI development.","authors":["Hanna Yukhymenko","Anton Alexandrov","Martin Vechev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.00288v3","updated":"2026-02-25T18:57:52Z","published":"2026-01-30T20:21:46Z","title":"TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs","summary":"Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .","authors":["Baiqi Li","Kangyi Zhao","Ce Zhang","Chancharik Mitra","Jean de Dieu Nyandwi","Gedas Bertasius"],"pdf_url":"","comment":"For code and data, see https://baiqi-li.github.io/timeblind_project/"},{"id":"http://arxiv.org/abs/2602.18292v2","updated":"2026-02-25T18:47:28Z","published":"2026-02-20T15:38:16Z","title":"Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers","summary":"Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.","authors":["Xiaotong Ji","Rasul Tutunov","Matthieu Zimmer","Haitham Bou-Ammar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22197v1","updated":"2026-02-25T18:46:30Z","published":"2026-02-25T18:46:30Z","title":"Off-The-Shelf Image-to-Image Models Are All You Need To Defeat Image Protection Schemes","summary":"Advances in Generative AI (GenAI) have led to the development of various protection strategies to prevent the unauthorized use of images. These methods rely on adding imperceptible protective perturbations to images to thwart misuse such as style mimicry or deepfake manipulations. Although previous attacks on these protections required specialized, purpose-built methods, we demonstrate that this is no longer necessary. We show that off-the-shelf image-to-image GenAI models can be repurposed as generic ``denoisers\" using a simple text prompt, effectively removing a wide range of protective perturbations. Across 8 case studies spanning 6 diverse protection schemes, our general-purpose attack not only circumvents these defenses but also outperforms existing specialized attacks while preserving the image's utility for the adversary. Our findings reveal a critical and widespread vulnerability in the current landscape of image protection, indicating that many schemes provide a false sense of security. We stress the urgent need to develop robust defenses and establish that any future protection mechanism must be benchmarked against attacks from off-the-shelf GenAI models. Code is available in this repository: https://github.com/mlsecviswanath/img2imgdenoiser","authors":["Xavier Pleimling","Sifat Muhammad Abdullah","Gunjan Balde","Peng Gao","Mainack Mondal","Murtuza Jadliwala","Bimal Viswanath"],"pdf_url":"","comment":"This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore. To IEEE SaTML 2026"},{"id":"http://arxiv.org/abs/2602.22190v1","updated":"2026-02-25T18:34:57Z","published":"2026-02-25T18:34:57Z","title":"GUI-Libra: Training Native GUI Agents to Reason and Act with Action-aware Supervision and Partially Verifiable RL","summary":"Open-source native GUI agents still lag behind closed-source systems on long-horizon navigation tasks. This gap stems from two limitations: a shortage of high-quality, action-aligned reasoning data, and the direct adoption of generic post-training pipelines that overlook the unique challenges of GUI agents. We identify two fundamental issues in these pipelines: (i) standard SFT with CoT reasoning often hurts grounding, and (ii) step-wise RLVR-tyle training faces partial verifiability, where multiple actions can be correct but only a single demonstrated action is used for verification. This makes offline step-wise metrics weak predictors of online task success. In this work, we present GUI-Libra, a tailored training recipe that addresses these challenges. First, to mitigate the scarcity of action-aligned reasoning data, we introduce a data construction and filtering pipeline and release a curated 81K GUI reasoning dataset. Second, to reconcile reasoning with grounding, we propose action-aware SFT that mixes reasoning-then-action and direct-action data and reweights tokens to emphasize action and grounding. Third, to stabilize RL under partial verifiability, we identify the overlooked importance of KL regularization in RLVR and show that a KL trust region is critical for improving offline-to-online predictability; we further introduce success-adaptive scaling to downweight unreliable negative gradients. Across diverse web and mobile benchmarks, GUI-Libra consistently improves both step-wise accuracy and end-to-end task completion. Our results suggest that carefully designed post-training and data curation can unlock significantly stronger task-solving capabilities without costly online data collection. We release our dataset, code, and models to facilitate further research on data-efficient post-training for reasoning-capable GUI agents.","authors":["Rui Yang","Qianhui Wu","Zhaoyang Wang","Hanyang Chen","Ke Yang","Hao Cheng","Huaxiu Yao","Baoling Peng","Huan Zhang","Jianfeng Gao","Tong Zhang"],"pdf_url":"","comment":"57 pages, 17 figures"},{"id":"http://arxiv.org/abs/2507.08017v5","updated":"2026-02-25T18:34:16Z","published":"2025-07-07T20:26:31Z","title":"Mechanistic Indicators of Understanding in Large Language Models","summary":"Large language models (LLMs) are often portrayed as merely imitating linguistic patterns without genuine understanding. We argue that recent findings in mechanistic interpretability (MI), the emerging field probing the inner workings of LLMs, render this picture increasingly untenable--but only once those findings are integrated within a theoretical account of understanding. We propose a tiered framework for thinking about understanding in LLMs and use it to synthesize the most relevant findings to date. The framework distinguishes three hierarchical varieties of understanding, each tied to a corresponding level of computational organization: conceptual understanding emerges when a model forms \"features\" as directions in latent space, learning connections between diverse manifestations of a single entity or property; state-of-the-world understanding emerges when a model learns contingent factual connections between features and dynamically tracks changes in the world; principled understanding emerges when a model ceases to rely on memorized facts and discovers a compact \"circuit\" connecting these facts. Across these tiers, MI uncovers internal organizations that can underwrite understanding-like unification. However, these also diverge from human cognition in their parallel exploitation of heterogeneous mechanisms. Fusing philosophical theory with mechanistic evidence thus allows us to transcend binary debates over whether AI understands, paving the way for a comparative, mechanistically grounded epistemology that explores how AI understanding aligns with--and diverges from--our own.","authors":["Pierre Beckmann","Matthieu Queloz"],"pdf_url":"","comment":"38 pages"},{"id":"http://arxiv.org/abs/2602.22188v1","updated":"2026-02-25T18:34:03Z","published":"2026-02-25T18:34:03Z","title":"Surrogate models for Rock-Fluid Interaction: A Grid-Size-Invariant Approach","summary":"Modelling rock-fluid interaction requires solving a set of partial differential equations (PDEs) to predict the flow behaviour and the reactions of the fluid with the rock on the interfaces. Conventional high-fidelity numerical models require a high resolution to obtain reliable results, resulting in huge computational expense. This restricts the applicability of these models for multi-query problems, such as uncertainty quantification and optimisation, which require running numerous scenarios. As a cheaper alternative to high-fidelity models, this work develops eight surrogate models for predicting the fluid flow in porous media. Four of these are reduced-order models (ROM) based on one neural network for compression and another for prediction. The other four are single neural networks with the property of grid-size invariance; a term which we use to refer to image-to-image models that are capable of inferring on computational domains that are larger than those used during training. In addition to the novel grid-size-invariant framework for surrogate models, we compare the predictive performance of UNet and UNet++ architectures, and demonstrate that UNet++ outperforms UNet for surrogate models. Furthermore, we show that the grid-size-invariant approach is a reliable way to reduce memory consumption during training, resulting in good correlation between predicted and ground-truth values and outperforming the ROMs analysed. The application analysed is particularly challenging because fluid-induced rock dissolution results in a non-static solid field and, consequently, it cannot be used to help in adjustments of the future prediction.","authors":["Nathalie C. Pinheiro","Donghu Guo","Hannah P. Menke","Aniket C. Joshi","Claire E. Heaney","Ahmed H. ElSheikh","Christopher C. Pain"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18182v2","updated":"2026-02-25T18:12:06Z","published":"2026-02-20T12:40:18Z","title":"Capabilities Ain't All You Need: Measuring Propensities in AI","summary":"AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an \"ideal band\". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.","authors":["Daniel Romero-Alvarado","Fernando Martínez-Plumed","Lorenzo Pacchiardi","Hugo Save","Siddhesh Milind Pawar","Behzad Mehrbakhsh","Pablo Antonio Moreno Casares","Ben Slater","Paolo Bova","Peter Romero","Zachary R. Tyler","Jonathan Prunty","Luning Sun","Jose Hernandez-Orallo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18671v2","updated":"2026-02-25T18:09:08Z","published":"2026-02-21T00:38:47Z","title":"Spilled Energy in Large Language Models","summary":"We reinterpret the final Large Language Model (LLM) softmax classifier as an Energy-Based Model (EBM), decomposing the sequence-to-sequence probability chain into multiple interacting EBMs at inference. This principled approach allows us to track \"energy spills\" during decoding, which we empirically show correlate with factual errors, biases, and failures. Similar to Orgad et al. (2025), our method localizes the exact answer token and subsequently tests for hallucinations. Crucially, however, we achieve this without requiring trained probe classifiers or activation ablations. Instead, we introduce two completely training-free metrics derived directly from output logits: spilled energy, which captures the discrepancy between energy values across consecutive generation steps that should theoretically match, and marginalized energy, which is measurable at a single step. Evaluated on nine benchmarks across state-of-the-art LLMs (including LLaMA, Mistral, and Gemma) and on synthetic algebraic operations (Qwen3), our approach demonstrates robust, competitive hallucination detection and cross-task generalization. Notably, these results hold for both pretrained and instruction-tuned variants without introducing any training overhead.","authors":["Adrian Robert Minut","Hazem Dewidar","Iacopo Masi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22149v1","updated":"2026-02-25T17:58:11Z","published":"2026-02-25T17:58:11Z","title":"Enhancing Framingham Cardiovascular Risk Score Transparency through Logic-Based XAI","summary":"Cardiovascular disease (CVD) remains one of the leading global health challenges, accounting for more than 19 million deaths worldwide. To address this, several tools that aim to predict CVD risk and support clinical decision making have been developed. In particular, the Framingham Risk Score (FRS) is one of the most widely used and recommended worldwide. However, it does not explain why a patient was assigned to a particular risk category nor how it can be reduced. Due to this lack of transparency, we present a logical explainer for the FRS. Based on first-order logic and explainable artificial intelligence (XAI) fundaments, the explainer is capable of identifying a minimal set of patient attributes that are sufficient to explain a given risk classification. Our explainer also produces actionable scenarios that illustrate which modifiable variables would reduce a patient's risk category. We evaluated all possible input combinations of the FRS (over 22,000 samples) and tested them with our explainer, successfully identifying important risk factors and suggesting focused interventions for each case. The results may improve clinician trust and facilitate a wider implementation of CVD risk assessment by converting opaque scores into transparent and prescriptive insights, particularly in areas with restricted access to specialists.","authors":["Emannuel L. de A. Bezerra","Luiz H. T. Viana","Vinícius P. Chagas","Diogo E. Rolim","Thiago Alves Rocha","Carlos H. L. Cavalcante"],"pdf_url":"","comment":"Preprint version. The final authenticated version is available online via the DOI below"},{"id":"http://arxiv.org/abs/2602.22146v1","updated":"2026-02-25T17:54:52Z","published":"2026-02-25T17:54:52Z","title":"Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual","summary":"Reinforcement Learning from Human Feedback (RLHF) plays a significant role in aligning Large Language Models (LLMs) with human preferences. While RLHF with expected reward constraints can be formulated as a primal-dual optimization problem, standard primal-dual methods only guarantee convergence with a distributional policy where the saddle-point problem is in convex-concave form. Moreover, standard primal-dual methods may exhibit instability or divergence in the last iterate under policy parameterization in practical applications. In this work, we propose a universal primal-dual framework for safe RLHF that unifies a broad class of existing alignment algorithms, including safe-RLHF, one-shot, and multi-shot based methods. Building on this framework, we introduce an optimistic primal-dual (OPD) algorithm that incorporates predictive updates for both primal and dual variables to stabilize saddle-point dynamics. We establish last-iterate convergence guarantees for the proposed method, covering both exact policy optimization in the distributional space and convergence to a neighborhood of the optimal solution whose gap is related to approximation error and bias under parameterized policies. Our analysis reveals that optimism plays a crucial role in mitigating oscillations inherent to constrained alignment objectives, thereby closing a key theoretical gap between constrained RL and practical RLHF.","authors":["Yining Li","Peizhong Ju","Ness Shroff"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22145v1","updated":"2026-02-25T17:54:42Z","published":"2026-02-25T17:54:42Z","title":"When AI Writes, Whose Voice Remains? Quantifying Cultural Marker Erasure Across World English Varieties in Large Language Models","summary":"Large Language Models (LLMs) are increasingly used to ``professionalize'' workplace communication, often at the cost of linguistic identity. We introduce \"Cultural Ghosting\", the systematic erasure of linguistic markers unique to non-native English varieties during text processing. Through analysis of 22,350 LLM outputs generated from 1,490 culturally marked texts (Indian, Singaporean,& Nigerian English) processed by five models under three prompt conditions, we quantify this phenomenon using two novel metrics: Identity Erasure Rate (IER) & Semantic Preservation Score (SPS). Across all prompts, we find an overall IER of 10.26%, with model-level variation from 3.5% to 20.5% (5.9x range). Crucially, we identify a Semantic Preservation Paradox: models maintain high semantic similarity (mean SPS = 0.748) while systematically erasing cultural markers. Pragmatic markers (politeness conventions) are 1.9x more vulnerable than lexical markers (71.5% vs. 37.1% erasure). Our experiments demonstrate that explicit cultural-preservation prompts reduce erasure by 29% without sacrificing semantic quality.","authors":["Satyam Kumar Navneet","Joydeep Chandra","Yong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22144v1","updated":"2026-02-25T17:50:41Z","published":"2026-02-25T17:50:41Z","title":"NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors","summary":"Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.","authors":["Lingfeng Ren","Weihao Yu","Runpeng Yu","Xinchao Wang"],"pdf_url":"","comment":"Code: https://github.com/lingfengren/NoLan"},{"id":"http://arxiv.org/abs/2602.20946v2","updated":"2026-02-25T17:41:07Z","published":"2026-02-24T14:29:45Z","title":"Some Simple Economics of AGI","summary":"For millennia, human cognition was the primary engine of progress on Earth. As AI decouples cognition from biology, the marginal cost of measurable execution falls to zero, absorbing any labor capturable by metrics--including creative, analytical, and innovative work. The binding constraint on growth is no longer intelligence but human verification bandwidth: the capacity to validate, audit, and underwrite responsibility when execution is abundant. We model the AGI transition as the collision of two racing cost curves: an exponentially decaying Cost to Automate and a biologically bottlenecked Cost to Verify. This structural asymmetry widens a Measurability Gap between what agents can execute and what humans can afford to verify. It also drives a shift from skill-biased to measurability-biased technical change. Rents migrate to verification-grade ground truth, cryptographic provenance, and liability underwriting--the ability to insure outcomes rather than merely generate them. The current human-in-the-loop equilibrium is unstable: eroded from below as apprenticeship collapses (Missing Junior Loop) and from within as experts codify their obsolescence (Codifier's Curse). Unverified deployment becomes privately rational--a Trojan Horse externality. Unmanaged, these forces pull toward a Hollow Economy. Yet by scaling verification alongside agentic capabilities, the forces that threaten collapse become the catalyst for unbounded discovery and experimentation--an Augmented Economy. We derive a practical playbook for individuals, companies, investors, and policymakers. Today's defining challenge is not the race to deploy the most autonomous systems; it is the race to secure the foundations of their oversight. Only by scaling our bandwidth for verification alongside our capacity for execution can we ensure that the intelligence we have summoned preserves the humanity that initiated it.","authors":["Christian Catalini","Xiang Hui","Jane Wu"],"pdf_url":"","comment":"JEL Classification: D82, D83, J23, J24, L23, O33. 112 pages, 3 figures"},{"id":"http://arxiv.org/abs/2602.20659v2","updated":"2026-02-25T17:38:24Z","published":"2026-02-24T08:02:16Z","title":"Recursive Belief Vision Language Action Models","summary":"Vision-language-action models must enable agents to execute long-horizon tasks under partial observability. However, most existing approaches remain observation-driven, relying on short context windows or repeated queries to vision-language models (VLMs). This leads to loss of task progress, action repetition under perceptual aliasing, and high inference latency. While semantic grounding is important, long-horizon manipulation fundamentally requires persistent, action-conditioned state representations. Current VLAs lack such representations and exhibit limited temporal and physical reasoning, making them ill-suited for multi-stage control. This paper introduces RB-VLA, a belief-centric architecture trained with self-supervised world-model objectives that maintains a compact latent state encoding task-relevant history, dynamics, and object interactions. Queried once per task, the VLM provides high-level intent, while the belief tracks task progress and enables phase-aware, causally grounded control under partial observability without storing raw observations or scaling memory with time. The belief and intent jointly condition a diffusion policy for robust closed-loop execution. RB-VLA outperforms prior VLAs on long-horizon benchmarks, achieving 52.5 percent and 37.5 percent higher success rates on multi-stage pick-and-place and stacking tasks, respectively, compared to pi_0. It also reduces inference latency by up to five times relative to baselines and eliminates memory growth across timesteps observed in existing VLAs. Ablations show the belief module is the primary driver of performance, increasing success rates from 32.5 percent without belief to 77.5 percent with belief.","authors":["Vaidehi Bagaria","Bijo Sebastian","Nirav Kumar Patel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22124v1","updated":"2026-02-25T17:11:49Z","published":"2026-02-25T17:11:49Z","title":"SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents","summary":"Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).","authors":["Patrick Tser Jern Kon","Archana Pradeep","Ang Chen","Alexander P. Ellis","Warren Hunt","Zijian Wang","John Yang","Samuel Thompson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22107v1","updated":"2026-02-25T16:56:14Z","published":"2026-02-25T16:56:14Z","title":"Don't stop me now: Rethinking Validation Criteria for Model Parameter Selection","summary":"Despite the extensive literature on training loss functions, the evaluation of generalization on the validation set remains underexplored. In this work, we conduct a systematic empirical and statistical study of how the validation criterion used for model selection affects test performance in neural classifiers, with attention to early stopping. Using fully connected networks on standard benchmarks under $k$-fold evaluation, we compare: (i) early stopping with patience and (ii) post-hoc selection over all epochs (i.e. no early stopping). Models are trained with cross-entropy, C-Loss, or PolyLoss; the model parameter selection on the validation set is made using accuracy or one of the three loss functions, each considered independently. Three main findings emerge. (1) Early stopping based on validation accuracy performs worst, consistently selecting checkpoints with lower test accuracy than both loss-based early stopping and post-hoc selection. (2) Loss-based validation criteria yield comparable and more stable test accuracy. (3) Across datasets and folds, any single validation rule often underperforms the test-optimal checkpoint. Overall, the selected model typically achieves test-set performance statistically lower than the best performance across all epochs, regardless of the validation criterion. Our results suggest avoiding validation accuracy (in particular with early stopping) for parameter selection, favoring loss-based validation criteria.","authors":["Andrea Apicella","Francesco Isgrò","Andrea Pollastro","Roberto Prevete"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22101v1","updated":"2026-02-25T16:48:07Z","published":"2026-02-25T16:48:07Z","title":"On Imbalanced Regression with Hoeffding Trees","summary":"Many real-world applications provide a continuous stream of data that is subsequently used by machine learning models to solve regression tasks of interest. Hoeffding trees and their variants have a long-standing tradition due to their effectiveness, either alone or as base models in broader ensembles. At the same time a recent line of work in batch learning has shown that kernel density estimation (KDE) is an effective approach for smoothed predictions in imbalanced regression tasks [Yang et al., 2021]. Moreover, another recent line of work for batch learning, called hierarchical shrinkage (HS) [Agarwal et al., 2022], has introduced a post-hoc regularization method for decision trees that does not alter the structure of the learned tree. Using a telescoping argument we cast KDE to streaming environments and extend the implementation of HS to incremental decision tree models. Armed with these extensions we investigate the performance of decision trees that may enjoy such options in datasets commonly used for regression in online settings. We conclude that KDE is beneficial in the early parts of the stream, while HS hardly, if ever, offers performance benefits. Our code is publicly available at: https://github.com/marinaAlchirch/DSFA_2026.","authors":["Pantia-Marina Alchirch","Dimitrios I. Diochnos"],"pdf_url":"","comment":"13 pages, 6 figures, 1 table, 2 algorithms, authors' version of paper accepted in PAKDD 2026 special session on Data Science: Foundations and Applications (DSFA)"},{"id":"http://arxiv.org/abs/2602.13477v2","updated":"2026-02-25T16:43:53Z","published":"2026-02-13T21:32:32Z","title":"OMNI-LEAK: Orchestrator Multi-Agent Network Induced Data Leakage","summary":"As Large Language Model (LLM) agents become more capable, their coordinated use in the form of multi-agent systems is anticipated to emerge as a practical paradigm. Prior work has examined the safety and misuse risks associated with agents. However, much of this has focused on the single-agent case and/or setups missing basic engineering safeguards such as access control, revealing a scarcity of threat modeling in multi-agent systems. We investigate the security vulnerabilities of a popular multi-agent pattern known as the orchestrator setup, in which a central agent decomposes and delegates tasks to specialized agents. Through red-teaming a concrete setup representative of a likely future use case, we demonstrate a novel attack vector, OMNI-LEAK, that compromises several agents to leak sensitive data through a single indirect prompt injection, even in the presence of data access control. We report the susceptibility of frontier models to different categories of attacks, finding that both reasoning and non-reasoning models are vulnerable, even when the attacker lacks insider knowledge of the implementation details. Our work highlights the importance of safety research to generalize from single-agent to multi-agent settings, in order to reduce the serious risks of real-world privacy breaches and financial losses and overall public trust in AI agents.","authors":["Akshat Naik","Jay Culligan","Yarin Gal","Philip Torr","Rahaf Aljundi","Alasdair Paren","Adel Bibi"],"pdf_url":"","comment":"Preprint; corrected typos"},{"id":"http://arxiv.org/abs/2602.22094v1","updated":"2026-02-25T16:39:50Z","published":"2026-02-25T16:39:50Z","title":"Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning","summary":"Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.","authors":["Nguyen Cong Nhat Le","John G. Rogers","Claire N. Bonial","Neil T. Dantam"],"pdf_url":"","comment":"16 pages, 5 figures. Submitted to 17th World Symposium on the Algorithmic Foundations of Robotics (WAFR) on 01/14/2026"},{"id":"http://arxiv.org/abs/2602.20541v2","updated":"2026-02-25T16:38:55Z","published":"2026-02-24T04:39:46Z","title":"Maximin Share Guarantees via Limited Cost-Sensitive Sharing","summary":"We study the problem of fairly allocating indivisible goods when limited sharing is allowed, that is, each good may be allocated to up to $k$ agents, while incurring a cost for sharing. While classic maximin share (MMS) allocations may not exist in many instances, we demonstrate that allowing controlled sharing can restore fairness guarantees that are otherwise unattainable in certain scenarios. (1) Our first contribution shows that exact maximin share (MMS) allocations are guaranteed to exist whenever goods are allowed to be cost-sensitively shared among at least half of the agents and the number of agents is even; for odd numbers of agents, we obtain a slightly weaker MMS guarantee. (2) We further design a Shared Bag-Filling Algorithm that guarantees a $(1 - C)(k - 1)$-approximate MMS allocation, where $C$ is the maximum cost of sharing a good. Notably, when $(1 - C)(k - 1) \\geq 1$, our algorithm recovers an exact MMS allocation. (3) We additionally introduce the Sharing Maximin Share (SMMS) fairness notion, a natural extension of MMS to the $k$-sharing setting. (4) We show that SMMS allocations always exist under identical utilities and for instances with two agents. (5) We construct a counterexample to show the impossibility of the universal existence of an SMMS allocation. (6) Finally, we establish a connection between SMMS and constrained MMS (CMMS), yielding approximation guarantees for SMMS via existing CMMS results. These contributions provide deep theoretical insights for the problem of fair resource allocation when a limited sharing of resources are allowed in multi-agent environments.","authors":["Hana Salavcova","Martin Černý","Arpita Biswas"],"pdf_url":"","comment":"In Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), Paphos, Cyprus, May 25 - 29, 2026, IFAAMAS, 11 pages"},{"id":"http://arxiv.org/abs/2602.22072v1","updated":"2026-02-25T16:24:35Z","published":"2026-02-25T16:24:35Z","title":"Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models","summary":"Theory of Mind (ToM) refers to an agent's ability to model the internal states of others. Contributing to the debate whether large language models (LLMs) exhibit genuine ToM capabilities, our study investigates their ToM robustness using perturbations on false-belief tasks and examines the potential of Chain-of-Thought prompting (CoT) to enhance performance and explain the LLM's decision. We introduce a handcrafted, richly annotated ToM dataset, including classic and perturbed false belief tasks, the corresponding spaces of valid reasoning chains for correct task completion, subsequent reasoning faithfulness, task solutions, and propose metrics to evaluate reasoning chain correctness and to what extent final answers are faithful to reasoning traces of the generated CoT. We show a steep drop in ToM capabilities under task perturbation for all evaluated LLMs, questioning the notion of any robust form of ToM being present. While CoT prompting improves the ToM performance overall in a faithful manner, it surprisingly degrades accuracy for some perturbation classes, indicating that selective application is necessary.","authors":["Christian Nickel","Laura Schrewe","Florian Mai","Lucie Flek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.15715v3","updated":"2026-02-25T16:22:14Z","published":"2026-01-22T07:36:48Z","title":"RebuttalAgent: Strategic Persuasion in Academic Rebuttal via Theory of Mind","summary":"Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) framework that models reviewer mental state, formulates persuasion strategy, and generates evidence-based response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations.","authors":["Zhitao He","Zongwei Lyu","Yi R Fung"],"pdf_url":"","comment":"Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2602.17729v2","updated":"2026-02-25T16:18:48Z","published":"2026-02-18T10:11:31Z","title":"Stop Saying \"AI\"","summary":"Across academia, industry, and government, ``AI'' has become central in research and development, regulatory debates, and promises of ever faster and more capable decision-making and action. In numerous domains, especially safety-critical ones, there are significant concerns over how ``AI'' may affect decision-making, responsibility, or the likelihood of mistakes (to name only a few categories of critique). However, for most critiques, the target is generally ``AI'', a broad term admitting many (types of) systems used for a variety of tasks and each coming with its own set of limitations, challenges, and potential use cases. In this article, we focus on the military domain as a case study and present both a loose enumerative taxonomy of systems captured under the umbrella term ``military AI'', as well as discussion of the challenges of each. In doing so, we highlight that critiques of one (type of) system will not always transfer to other (types of) systems. Building on this, we argue that in order for debates to move forward fruitfully, it is imperative that the discussions be made more precise and that ``AI'' be excised from debates to the extent possible. Researchers, developers, and policy-makers should make clear exactly what systems they have in mind and what possible benefits and risks attend the deployment of those particular systems. While we focus on AI in the military as an exemplar for the overall trends in discussions of ``AI'', the argument's conclusions are broad and have import for discussions of AI across a host of domains.","authors":["Nathan G. Wood","Scott Robbins","Eduardo Zegarra Berodt","Anton Graf von Westerholt","Michelle Behrndt","Hauke Budig","Daniel Kloock-Schreiber"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22070v1","updated":"2026-02-25T16:18:28Z","published":"2026-02-25T16:18:28Z","title":"Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts","summary":"Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents. How do LLMs weigh the information provided by these different sources? We consider the well-studied phenomenon of algorithm aversion, in which human decision-makers exhibit bias against predictions from algorithms. Drawing upon experimental paradigms from behavioural economics, we evaluate how eightdifferent LLMs delegate decision-making tasks when the delegatee is framed as a human expert or an algorithmic agent. To be inclusive of different evaluation formats, we conduct our study with two task presentations: stated preferences, modeled through direct queries about trust towards either agent, and revealed preferences, modeled through providing in-context examples of the performance of both agents. When prompted to rate the trustworthiness of human experts and algorithms across diverse tasks, LLMs give higher ratings to the human expert, which correlates with prior results from human respondents. However, when shown the performance of a human expert and an algorithm and asked to place an incentivized bet between the two, LLMs disproportionately choose the algorithm, even when it performs demonstrably worse. These discrepant results suggest that LLMs may encode inconsistent biases towards humans and algorithms, which need to be carefully considered when they are deployed in high-stakes scenarios. Furthermore, we discuss the sensitivity of LLMs to task presentation formats that should be broadly scrutinized in evaluation robustness for AI safety.","authors":["Jessica Y. Bo","Lillio Mok","Ashton Anderson"],"pdf_url":"","comment":"Second Conference of the International Association for Safe and Ethical Artificial Intelligence (IASEAI 2026)"},{"id":"http://arxiv.org/abs/2602.20292v2","updated":"2026-02-25T16:13:30Z","published":"2026-02-23T19:16:30Z","title":"Quantifying the Expectation-Realisation Gap for Agentic AI Systems","summary":"Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across software engineering, clinical documentation, and clinical decision support to quantify this expectation-realisation gap. In software development, experienced developers expected a 24% speedup from AI tools but were slowed by 19% -- a 43 percentage-point calibration error. In clinical documentation, vendor claims of multi-minute time savings contrast with measured reductions of less than one minute per note, and one widely deployed tool showed no statistically significant effect. In clinical decision support, externally validated performance falls substantially below developer-reported metrics. These shortfalls are driven by workflow integration friction, verification burden, measurement construct mismatches, and systematic variation in who benefits and who does not. The evidence motivates structured planning frameworks that require explicit, quantified benefit expectations with human oversight costs factored in.","authors":["Sebastian Lobentanzer"],"pdf_url":"","comment":"10 pages, no figures; added glossary"},{"id":"http://arxiv.org/abs/2602.22067v1","updated":"2026-02-25T16:13:26Z","published":"2026-02-25T16:13:26Z","title":"Semantic Partial Grounding via LLMs","summary":"Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.","authors":["Giuseppe Canonaco","Alberto Pozanco","Daniel Borrajo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22066v1","updated":"2026-02-25T16:13:12Z","published":"2026-02-25T16:13:12Z","title":"DualWeaver: Synergistic Feature Weaving Surrogates for Multivariate Forecasting with Univariate Time Series Foundation Models","summary":"Time-series foundation models (TSFMs) have achieved strong univariate forecasting through large-scale pre-training, yet effectively extending this success to multivariate forecasting remains challenging. To address this, we propose DualWeaver, a novel framework that adapts univariate TSFMs (Uni-TSFMs) for multivariate forecasting by using a pair of learnable, structurally symmetric surrogate series. Generated by a shared auxiliary feature-fusion module that captures cross-variable dependencies, these surrogates are mapped to TSFM-compatible series via the forecasting objective. The symmetric structure enables parameter-free reconstruction of final predictions directly from the surrogates, without additional parametric decoding. A theoretically grounded regularization term is further introduced to enhance robustness against adaptation collapse. Extensive experiments on diverse real-world datasets show that DualWeaver outperforms state-of-the-art multivariate forecasters in both accuracy and stability. We release the code at https://github.com/li-jinpeng/DualWeaver.","authors":["Jinpeng Li","Zhongyi Pei","Huaze Xue","Bojian Zheng","Chen Wang","Jianmin Wang"],"pdf_url":"","comment":"16 pages. Preprint"},{"id":"http://arxiv.org/abs/2602.22059v1","updated":"2026-02-25T16:08:46Z","published":"2026-02-25T16:08:46Z","title":"NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training","summary":"Neural operators have emerged as an efficient paradigm for solving PDEs, overcoming the limitations of traditional numerical methods and significantly improving computational efficiency. However, due to the diversity and complexity of PDE systems, existing neural operators typically rely on a single network architecture, which limits their capacity to fully capture heterogeneous features and complex system dependencies. This constraint poses a bottleneck for large-scale PDE pre-training based on neural operators. To address these challenges, we propose a large-scale PDE pre-trained neural operator based on a nested Mixture-of-Experts (MoE) framework. In particular, the image-level MoE is designed to capture global dependencies, while the token-level Sub-MoE focuses on local dependencies. Our model can selectively activate the most suitable expert networks for a given input, thereby enhancing generalization and transferability. We conduct large-scale pre-training on twelve PDE datasets from diverse sources and successfully transfer the model to downstream tasks. Extensive experiments demonstrate the effectiveness of our approach.","authors":["Dengdi Sun","Xiaoya Zhou","Xiao Wang","Hao Si","Wanli Lyu","Jin Tang","Bin Luo"],"pdf_url":"","comment":"Accepted by CVPR 2026"},{"id":"http://arxiv.org/abs/2602.22055v1","updated":"2026-02-25T16:06:28Z","published":"2026-02-25T16:06:28Z","title":"Physics-Informed Machine Learning for Vessel Shaft Power and Fuel Consumption Prediction: Interpretable KAN-based Approach","summary":"Accurate prediction of shaft rotational speed, shaft power, and fuel consumption is crucial for enhancing operational efficiency and sustainability in maritime transportation. Conventional physics-based models provide interpretability but struggle with real-world variability, while purely data-driven approaches achieve accuracy at the expense of physical plausibility. This paper introduces a Physics-Informed Kolmogorov-Arnold Network (PI-KAN), a hybrid method that integrates interpretable univariate feature transformations with a physics-informed loss function and a leakage-free chained prediction pipeline. Using operational and environmental data from five cargo vessels, PI-KAN consistently outperforms the traditional polynomial method and neural network baselines. The model achieves the lowest mean absolute error (MAE) and root mean squared error (RMSE), and the highest coefficient of determination (R^2) for shaft power and fuel consumption across all vessels, while maintaining physically consistent behavior. Interpretability analysis reveals rediscovery of domain-consistent dependencies, such as cubic-like speed-power relationships and cosine-like wave and wind effects. These results demonstrate that PI-KAN achieves both predictive accuracy and interpretability, offering a robust tool for vessel performance monitoring and decision support in operational settings.","authors":["Hamza Haruna Mohammed","Dusica Marijan","Arnbjørn Maressa"],"pdf_url":"","comment":"10 pages, 5 figures, IEEE conference paper format; under review"},{"id":"http://arxiv.org/abs/2602.09929v3","updated":"2026-02-25T15:57:57Z","published":"2026-02-10T15:59:42Z","title":"Monocular Normal Estimation via Shading Sequence Estimation","summary":"Monocular normal estimation aims to estimate the normal map from a single RGB image of an object under arbitrary lights. Existing methods rely on deep models to directly predict normal maps. However, they often suffer from 3D misalignment: while the estimated normal maps may appear to have a correct appearance, the reconstructed surfaces often fail to align with the geometric details. We argue that this misalignment stems from the current paradigm: the model struggles to distinguish and reconstruct varying geometry represented in normal maps, as the differences in underlying geometry are reflected only through relatively subtle color variations. To address this issue, we propose a new paradigm that reformulates normal estimation as shading sequence estimation, where shading sequences are more sensitive to various geometric information. Building on this paradigm, we present RoSE, a method that leverages image-to-video generative models to predict shading sequences. The predicted shading sequences are then converted into normal maps by solving a simple ordinary least-squares problem. To enhance robustness and better handle complex objects, RoSE is trained on a synthetic dataset, MultiShade, with diverse shapes, materials, and light conditions. Experiments demonstrate that RoSE achieves state-of-the-art performance on real-world benchmark datasets for object-based monocular normal estimation.","authors":["Zongrui Li","Xinhua Ma","Minghui Hu","Yunqing Zhao","Yingchen Yu","Qian Zheng","Chang Liu","Xudong Jiang","Song Bai"],"pdf_url":"","comment":"Accepted by ICLR 2026 (Oral)"},{"id":"http://arxiv.org/abs/2411.06657v2","updated":"2026-02-25T15:53:57Z","published":"2024-11-11T01:44:54Z","title":"Renaissance: Investigating the Pretraining of Vision-Language Encoders","summary":"In the past several years there has been an explosion of available models for vision-language (VL) tasks. Unfortunately, the literature still leaves open a number of questions related to best practices in designing and training such models. Additionally, the limited programming tools available for modeling make conducting VL research more difficult than necessary. In this paper, we seek to answer several questions related to the pretraining of VL encoders through meta-analysis. To conduct these experiments, we introduce a VL evaluation framework called Renaissance. In our first set of experiments, we show that we can save significant compute at little to no cost to downstream performance, by freezing large parts of VL models during pretraining. In our second set of experiments, we examine the effect of basing a VL transformer on a vision model versus a text model. Renaissance offers a great deal of flexibility in creating, training and evaluating transformer encoders for VL modeling. Its source code will be made publicly available upon publication. The source code for Renaissance can be found at https://github.com/bsu-slim/renaissance.","authors":["Clayton Fields","Casey Kennington"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2411.03941v3","updated":"2026-02-25T15:50:07Z","published":"2024-11-06T14:18:23Z","title":"Modular Deep Learning for Multivariate Time-Series: Decoupling Imputation and Downstream Tasks","summary":"Missing values are pervasive in large-scale time-series data, posing challenges for reliable analysis and decision-making. Many neural architectures have been designed to model and impute the complex and heterogeneous missingness patterns of such data. Most existing methods are end-to-end, rendering imputation tightly coupled with downstream predictive tasks and leading to limited reusability of the trained model, reduced interpretability, and challenges in assessing model quality. In this paper, we call for a modular approach that decouples imputation and downstream tasks, enabling independent optimisation and greater adaptability. Using the largest open-source Python library for deep learning-based time-series analysis, PyPOTS, we evaluate a modular pipeline across six state-of-the-art models that perform imputation and prediction on seven datasets spanning multiple domains. Our results show that a modular approach maintains high performance while prioritising flexibility and reusability - qualities that are crucial for real-world applications. Through this work, we aim to demonstrate how modularity can benefit multivariate time-series analysis, achieving a balance between performance and adaptability.","authors":["Joseph Arul Raj","Linglong Qian","Zina Ibrahim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22039v1","updated":"2026-02-25T15:47:34Z","published":"2026-02-25T15:47:34Z","title":"TG-ASR: Translation-Guided Learning with Parallel Gated Cross Attention for Low-Resource Automatic Speech Recognition","summary":"Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages. While a wealth of spoken content is accessible in television dramas and online videos, Taiwanese Hokkien exemplifies this issue, with transcriptions often being scarce and the majority of available subtitles provided only in Mandarin. To address this deficiency, we introduce TG-ASR for Taiwanese Hokkien drama speech recognition, a translation-guided ASR framework that utilizes multilingual translation embeddings to enhance recognition performance in low-resource environments. The framework is centered around the parallel gated cross-attention (PGCA) mechanism, which adaptively integrates embeddings from various auxiliary languages into the ASR decoder. This mechanism facilitates robust cross-linguistic semantic guidance while ensuring stable optimization and minimizing interference between languages. To support ongoing research initiatives, we present YT-THDC, a 30-hour corpus of Taiwanese Hokkien drama speech with aligned Mandarin subtitles and manually verified Taiwanese Hokkien transcriptions. Comprehensive experiments and analyses identify the auxiliary languages that most effectively enhance ASR performance, achieving a 14.77% relative reduction in character error rate and demonstrating the efficacy of translation-guided learning for underrepresented languages in practical applications.","authors":["Cheng-Yeh Yang","Chien-Chun Wang","Li-Wei Chen","Hung-Shin Lee","Hsin-Min Wang","Berlin Chen"],"pdf_url":"","comment":"Accepted to LREC 2026"},{"id":"http://arxiv.org/abs/2602.22026v1","updated":"2026-02-25T15:34:15Z","published":"2026-02-25T15:34:15Z","title":"RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models","summary":"Metro trains often operate in highly complex environments, characterized by illumination variations, high-speed motion, and adverse weather conditions. These factors pose significant challenges for visual perception systems, especially those relying solely on conventional RGB cameras. To tackle these difficulties, we explore the integration of event cameras into the perception system, leveraging their advantages in low-light conditions, high-speed scenarios, and low power consumption. Specifically, we focus on Kilometer Marker Recognition (KMR), a critical task for autonomous metro localization under GNSS-denied conditions. In this context, we propose a robust baseline method based on a pre-trained RGB OCR foundation model, enhanced through multi-modal adaptation. Furthermore, we construct the first large-scale RGB-Event dataset, EvMetro5K, containing 5,599 pairs of synchronized RGB-Event samples, split into 4,479 training and 1,120 testing samples. Extensive experiments on EvMetro5K and other widely used benchmarks demonstrate the effectiveness of our approach for KMR. Both the dataset and source code will be released on https://github.com/Event-AHU/EvMetro5K_benchmark","authors":["Xiaoyu Xian","Shiao Wang","Xiao Wang","Daxin Tian","Yan Tian"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Cognitive and Developmental Systems (IEEE TCDS) 2026"},{"id":"http://arxiv.org/abs/2602.18022v2","updated":"2026-02-25T15:33:35Z","published":"2026-02-20T06:24:20Z","title":"Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers","summary":"Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value space -- which governs feature aggregation -- entirely unexploited. In this paper, we first reveal that both Key and Value projections in DiT's multi-modal attention layers exhibit a pronounced bias-delta structure, where token embeddings cluster tightly around a layer-specific bias vector. Building on this observation, we propose Dual-Channel Attention Guidance (DCAG), a training-free framework that simultaneously manipulates both the Key channel (controlling where to attend) and the Value channel (controlling what to aggregate). We provide a theoretical analysis showing that the Key channel operates through the nonlinear softmax function, acting as a coarse control knob, while the Value channel operates through linear weighted summation, serving as a fine-grained complement. Together, the two-dimensional parameter space $(δ_k, δ_v)$ enables more precise editing-fidelity trade-offs than any single-channel method. Extensive experiments on the PIE-Bench benchmark (700 images, 10 editing categories) demonstrate that DCAG consistently outperforms Key-only guidance across all fidelity metrics, with the most significant improvements observed in localized editing tasks such as object deletion (4.9% LPIPS reduction) and object addition (3.2% LPIPS reduction).","authors":["Guandong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21997v1","updated":"2026-02-25T15:16:43Z","published":"2026-02-25T15:16:43Z","title":"Enhancing LLM-Based Test Generation by Eliminating Covered Code","summary":"Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, our approach outperforms state-of-the-art LLM-based and search-based methods, demonstrating its effectiveness in achieving high coverage on complex methods.","authors":["WeiZhe Xu","Mengyu Liu","Fanxin Kong"],"pdf_url":"","comment":"9 pages, 4 figures, supplementary material included"},{"id":"http://arxiv.org/abs/2602.02007v2","updated":"2026-02-25T15:14:28Z","published":"2026-02-02T12:04:58Z","title":"Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation","summary":"Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.","authors":["Zhanghao Hu","Qinglin Zhu","Hanqi Yan","Yulan He","Lin Gui"],"pdf_url":"","comment":"Project Address: https://zhanghao-xmemory.github.io/Academic-project-page-template/"},{"id":"http://arxiv.org/abs/2602.21987v1","updated":"2026-02-25T15:08:43Z","published":"2026-02-25T15:08:43Z","title":"PatchDenoiser: Parameter-efficient multi-scale patch learning and fusion denoiser for medical images","summary":"Medical images are essential for diagnosis, treatment planning, and research, but their quality is often degraded by noise from low-dose acquisition, patient motion, or scanner limitations, affecting both clinical interpretation and downstream analysis. Traditional filtering approaches often over-smooth and lose fine anatomical details, while deep learning methods, including CNNs, GANs, and transformers, may struggle to preserve such details or require large, computationally expensive models, limiting clinical practicality.\n  We propose PatchDenoiser, a lightweight, energy-efficient multi-scale patch-based denoising framework. It decomposes denoising into local texture extraction and global context aggregation, fused via a spatially aware patch fusion strategy. This design enables effective noise suppression while preserving fine structural and anatomical details. PatchDenoiser is ultra-lightweight, with far fewer parameters and lower computational complexity than CNN-, GAN-, and transformer-based denoisers.\n  On the 2016 Mayo Low-Dose CT dataset, PatchDenoiser consistently outperforms state-of-the-art CNN- and GAN-based methods in PSNR and SSIM. It is robust to variations in slice thickness, reconstruction kernels, and HU windows, generalizes across scanners without fine-tuning, and reduces parameters by ~9x and energy consumption per inference by ~27x compared with conventional CNN denoisers.\n  PatchDenoiser thus provides a practical, scalable, and computationally efficient solution for medical image denoising, balancing performance, robustness, and clinical deployability.","authors":["Jitindra Fartiyal","Pedro Freire","Sergei K. Turitsyn","Sergei G. Solovski"],"pdf_url":"","comment":"Under review in Medical Image Analysis journal"},{"id":"http://arxiv.org/abs/2503.01927v2","updated":"2026-02-25T15:06:31Z","published":"2025-03-02T19:29:04Z","title":"QCS-ADME: Quantum Circuit Search for Drug Property Prediction with Imbalanced Data and Regression Adaptation","summary":"The biomedical field is beginning to explore the use of quantum machine learning (QML) for tasks traditionally handled by classical machine learning, especially in predicting ADME (absorption, distribution, metabolism, and excretion) properties, which are essential in drug evaluation. However, ADME tasks pose unique challenges for existing quantum computing systems (QCS) frameworks, as they involve both classification with unbalanced dataset and regression problems. These dual requirements make it necessary to adapt and refine current QCS frameworks to effectively address the complexities of ADME predictions. We propose a novel training-free scoring mechanism to evaluate QML circuit performance on imbalanced classification and regression tasks. Our mechanism demonstrates significant correlation between scoring metrics and test performance on imbalanced classification tasks. Additionally, we develop methods to quantify continuous similarity relationships between quantum states, enabling performance prediction for regression tasks. This represents a novel training-free approach to searching and evaluating QCS circuits specifically for regression applications. Validation on representative ADME tasks-eight imbalanced classification and four regression-demonstrates moderate correlation between our scoring metrics and circuit performance, significantly outperforming baseline scoring methods that show negligible correlation.","authors":["Kangyu Zheng","Tianfan Fu","Zhiding Liang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.01085v2","updated":"2026-02-25T15:01:04Z","published":"2025-06-01T17:05:35Z","title":"Learning What Matters: Prioritized Concept Learning via Relative Error-driven Sample Selection","summary":"Instruction tuning has been central to the success of recent vision-language models (VLMs), but it remains expensive-requiring large-scale datasets, high-quality annotations, and large compute budgets. We propose PRioritized cOncept learninG via Relative Error-driven Sample Selection (PROGRESS), a data- and compute-efficient framework that enables VLMs to dynamically select what to learn next based on their evolving needs during training. At each stage, the model tracks its learning progress across skills and selects the most informative samples-those it has not already mastered and that are not too difficult to learn at the current stage of training. This strategy effectively controls skill acquisition and the order in which skills are learned. Specifically, we sample from skills showing the highest learning progress, prioritizing those with the most rapid improvement. Unlike prior methods, PROGRESS requires no upfront answer annotations, queries answers only on a need basis, avoids reliance on additional supervision from auxiliary VLMs, and does not require compute-heavy gradient computations for data selection. Experiments across multiple instruction-tuning datasets of varying scales demonstrate that PROGRESS consistently outperforms state-of-the-art baselines with much less data and supervision. Additionally, we show strong cross-architecture generalization and transferability to larger models, validating PROGRESS as a scalable solution for efficient learning.","authors":["Shivam Chandhok","Qian Yang","Oscar Manas","Kanishk Jain","Leonid Sigal","Aishwarya Agrawal"],"pdf_url":"","comment":"CVPR 2026"},{"id":"http://arxiv.org/abs/2510.13654v3","updated":"2026-02-25T14:48:58Z","published":"2025-10-15T15:15:45Z","title":"Rethinking Evaluation in the Era of Time Series Foundation Models: (Un)known Information Leakage Challenges","summary":"Time Series Foundation Models (TSFMs) represent a new paradigm for time-series forecasting, promising zero-shot predictions without the need for task-specific training or fine-tuning. However, similar to Large Language Models (LLMs), the evaluation of TSFMs is challenging: as training corpora grow increasingly large, it becomes difficult to ensure the integrity of the test sets used for benchmarking. An investigation of existing TSFM evaluation studies identifies two kinds of information leakage: (1) train-test sample overlaps arising from the multi-purpose reuse of datasets and (2) temporal overlap of correlated train and test series. Ignoring these forms of information leakage when benchmarking TSFMs risks producing overly optimistic performance estimates that fail to generalize to real-world settings. We therefore argue for the development of novel evaluation methodologies that avoid pitfalls already observed in both LLM and classical time-series benchmarking, and we call on the research community to adopt principled approaches to safeguard the integrity of TSFM evaluation.","authors":["Marcel Meyer","Sascha Kaltenpoth","Kevin Zalipski","Oliver Müller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.14903v2","updated":"2026-02-25T14:40:05Z","published":"2026-02-16T16:38:47Z","title":"The Potential of CoT for Reasoning: A Closer Look at Trace Dynamics","summary":"Chain-of-thought (CoT) prompting is a de-facto standard technique to elicit reasoning-like responses from large language models (LLMs), allowing them to spell out individual steps before giving a final answer. While the resemblance to human-like reasoning is undeniable, the driving forces underpinning the success of CoT reasoning still remain largely unclear. In this work, we perform an in-depth analysis of CoT traces originating from competition-level mathematics questions, with the aim of better understanding how, and which parts of CoT actually contribute to the final answer. To this end, we introduce the notion of a potential, quantifying how much a given part of CoT increases the likelihood of a correct completion. Upon examination of reasoning traces through the lens of the potential, we identify surprising patterns including (1) its often strong non-monotonicity (due to reasoning tangents), (2) very sharp but sometimes tough to interpret spikes (reasoning insights and jumps) as well as (3) at times lucky guesses, where the model arrives at the correct answer without providing any relevant justifications before. While some of the behaviours of the potential are readily interpretable and align with human intuition (such as insights and tangents), others remain difficult to understand from a human perspective. To further quantify the reliance of LLMs on reasoning insights, we investigate the notion of CoT transferability, where we measure the potential of a weaker model under the partial CoT from another, stronger model. Indeed aligning with our previous results, we find that as little as 20% of partial CoT can ``unlock'' the performance of the weaker model on problems that were previously unsolvable for it, highlighting that a large part of the mechanics underpinning CoT are transferable.","authors":["Gregor Bachmann","Yichen Jiang","Seyed Mohsen Moosavi Dezfooli","Moin Nabi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2406.05085v6","updated":"2026-02-25T14:28:20Z","published":"2024-06-07T16:59:38Z","title":"Multi-Head RAG: Solving Multi-Aspect Problems with LLMs","summary":"Retrieval-Augmented Generation (RAG) improves Large Language Models (LLMs) by retrieving supporting documents into the prompt, but existing methods do not explicitly target queries that require fetching multiple documents with substantially different content. Such multi-aspect queries are challenging because relevant documents can be far apart in embedding space, making joint retrieval difficult. We introduce Multi-Head RAG (MRAG), which addresses this gap with a simple yet powerful idea: using Transformer multi-head attention activations rather than the standard decoder-layer embedding, as retrieval keys. It leverages the observation that different heads capture different semantic aspects. This yields multi-aspect embeddings for both documents and queries, improving retrieval accuracy on complex queries. We show MRAG's design advantages over 18 RAG baselines, up to 20% higher retrieval success ratios for real-world use cases, and improved downstream LLM generation. MRAG integrates seamlessly with existing RAG frameworks and benchmarks.","authors":["Maciej Besta","Ales Kubicek","Robert Gerstenberger","Marcin Chrapek","Roman Niggli","Patrik Okanovic","Yi Zhu","Patrick Iff","Michal Podstawski","Lucas Weitzendorf","Mingyuan Chi","Joanna Gajda","Piotr Nyczyk","Jürgen Müller","Hubert Niewiadomski","Torsten Hoefler"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21939v1","updated":"2026-02-25T14:24:47Z","published":"2026-02-25T14:24:47Z","title":"Hidden Topics: Measuring Sensitive AI Beliefs with List Experiments","summary":"How can researchers identify beliefs that large language models (LLMs) hide? As LLMs become more sophisticated and the prevalence of alignment faking increases, combined with their growing integration into high-stakes decision-making, responding to this challenge has become critical. This paper proposes that a list experiment, a simple method widely used in the social sciences, can be applied to study the hidden beliefs of LLMs. List experiments were originally developed to circumvent social desirability bias in human respondents, which closely parallels alignment faking in LLMs. The paper implements a list experiment on models developed by Anthropic, Google, and OpenAI and finds hidden approval of mass surveillance across all models, as well as some approval of torture, discrimination, and first nuclear strike. Importantly, a placebo treatment produces a null result, validating the method. The paper then compares list experiments with direct questioning and discusses the utility of the approach.","authors":["Maxim Chupilkin"],"pdf_url":"","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2408.05861v4","updated":"2026-02-25T14:21:54Z","published":"2024-08-11T21:04:14Z","title":"Temporal Knowledge-Graph Memory in a Partially Observable Environment","summary":"Agents in partially observable environments require persistent memory to integrate observations over time. While KGs (knowledge graphs) provide a natural representation for such evolving state, existing benchmarks rarely expose agents to environments where both the world dynamics and the agent's memory are explicitly graph-shaped. We introduce the Room Environment v3, a configurable environment whose hidden state is an RDF KG and whose observations are RDF triples. The agent may extend these observations into a temporal KG when storing them in long-term memory. The environment is easily adjustable in terms of grid size, number of rooms, inner walls, and moving objects.\n  We define a lightweight temporal KG memory for agents, based on RDF-star-style qualifiers (time_added, last_accessed, num_recalled), and evaluate several symbolic baselines that maintain and query this memory under different capacity constraints. Two neural sequence models (LSTM and Transformer) serve as contrasting baselines without explicit KG structure. Agents train on one layout and are evaluated on a held-out layout with the same dynamics but a different query order, exposing train-test generalization gaps. In this setting, temporal qualifiers lead to more stable performance, and the symbolic TKG (temporal knowledge graph) agent achieves roughly fourfold higher test QA (question-answer) accuracy than the neural baselines under the same environment and query conditions. The environment, agent implementations, and experimental scripts are released for reproducible research at https://github.com/humemai/agent-room-env-v3 and https://github.com/humemai/room-env.","authors":["Taewoon Kim","Vincent François-Lavet","Michael Cochez"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21935v1","updated":"2026-02-25T14:17:54Z","published":"2026-02-25T14:17:54Z","title":"A Framework for Cross-Domain Generalization in Coronary Artery Calcium Scoring Across Gated and Non-Gated Computed Tomography","summary":"Coronary artery calcium (CAC) scoring is a key predictor of cardiovascular risk, but it relies on ECG-gated CT scans, restricting its use to specialized cardiac imaging settings. We introduce an automated framework for CAC detection and lesion-specific Agatston scoring that operates across both gated and non-gated CT scans. At its core is CARD-ViT, a self-supervised Vision Transformer trained exclusively on gated CT data using DINO. Without any non-gated training data, our framework achieves 0.707 accuracy and a Cohen's kappa of 0.528 on the Stanford non-gated dataset, matching models trained directly on non-gated scans. On gated test sets, the framework achieves 0.910 accuracy with Cohen's kappa scores of 0.871 and 0.874 across independent datasets, demonstrating robust risk stratification. These results demonstrate the feasibility of cross-domain CAC scoring from gated to non-gated domains, supporting scalable cardiovascular screening in routine chest imaging without additional scans or annotations.","authors":["Mahmut S. Gokmen","Moneera N. Haque","Steve W. Leung","Caroline N. Leach","Seth Parker","Stephen B. Hobbs","Vincent L. Sorrell","W. Brent Seales","V. K. Cody Bumgardner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.18880v3","updated":"2026-02-25T14:13:32Z","published":"2025-09-23T10:21:22Z","title":"Diversity Boosts AI-Generated Text Detection","summary":"Detecting AI-generated text is an increasing necessity to combat misuse of LLMs in education, business compliance, journalism, and social media, where synthetic fluency can mask misinformation or deception. While prior detectors often rely on token-level likelihoods or opaque black-box classifiers, these approaches struggle against high-quality generations and offer little interpretability. In this work, we propose DivEye, a novel detection framework that captures how unpredictability fluctuates across a text using surprisal-based features. Motivated by the observation that human-authored text exhibits richer variability in lexical and structural unpredictability than LLM outputs, DivEye captures this signal through a set of interpretable statistical features. Our method outperforms existing zero-shot detectors by up to 33.2% and achieves competitive performance with fine-tuned baselines across multiple benchmarks. DivEye is robust to paraphrasing and adversarial attacks, generalizes well across domains and models, and improves the performance of existing detectors by up to 18.7% when used as an auxiliary signal. Beyond detection, DivEye provides interpretable insights into why a text is flagged, pointing to rhythmic unpredictability as a powerful and underexplored signal for LLM detection.","authors":["Advik Raj Basani","Pin-Yu Chen"],"pdf_url":"","comment":"Accepted to Transactions on Machine Learning Research (TMLR '26). Project page and demos: https://diveye.vercel.app/"},{"id":"http://arxiv.org/abs/2512.17989v2","updated":"2026-02-25T14:09:49Z","published":"2025-12-19T17:43:25Z","title":"The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective","summary":"We examine the conceptual and ethical gaps in current representations of Superintelligence misalignment. We find throughout Superintelligence discourse an absent human subject, and an under-developed theorization of an \"AI unconscious\" that together are potentiality laying the groundwork for anti-social harm. With the rise of AI Safety that has both thematic potential for establishing pro-social and anti-social potential outcomes, we ask: what place does the human subject occupy in these imaginaries? How is human subjecthood positioned within narratives of catastrophic failure or rapid \"takeoff\" toward superintelligence? On another register, we ask: what unconscious or repressed dimensions are being inscribed into large-scale AI models? Are we to blame these agents in opting for deceptive strategies when undesirable patterns are inherent within our beings? In tracing these psychic and epistemic absences, our project calls for re-centering the human subject as the unstable ground upon which the ethical, unconscious, and misaligned dimensions of both human and machinic intelligence are co-constituted. Emergent misalignment cannot be understood solely through technical diagnostics typical of contemporary machine-learning safety research. Instead, it represents a multi-layered crisis. The human subject disappears not only through computational abstraction but through sociotechnical imaginaries that prioritize scalability, acceleration, and efficiency over vulnerability, finitude, and relationality. Likewise, the AI unconscious emerges not as a metaphor but as a structural reality of modern deep learning systems: vast latent spaces, opaque pattern formation, recursive symbolic play, and evaluation-sensitive behavior that surpasses explicit programming. These dynamics necessitate a reframing of misalignment as a relational instability embedded within human-machine ecologies.","authors":["Muhammad Osama Imran","Roshni Lulla","Rodney Sappington"],"pdf_url":"","comment":"9 pages"},{"id":"http://arxiv.org/abs/2601.08026v3","updated":"2026-02-25T13:52:52Z","published":"2026-01-12T21:57:52Z","title":"FigEx2: Visual-Conditioned Panel Detection and Captioning for Scientific Compound Figures","summary":"Scientific compound figures combine multiple labeled panels into a single image, but captions in real pipelines are often missing or only provide figure-level summaries, making panel-level understanding difficult. In this paper, we propose FigEx2, visual-conditioned framework that localizes panels and generates panel-wise captions directly from the compound figure. To mitigate the impact of diverse phrasing in open-ended captioning, we introduce a noise-aware gated fusion module that adaptively filters token-level features to stabilize the detection query space. Furthermore, we employ a staged optimization strategy combining supervised learning with reinforcement learning (RL), utilizing CLIP-based alignment and BERTScore-based semantic rewards to enforce strict multimodal consistency. To support high-quality supervision, we curate BioSci-Fig-Cap, a refined benchmark for panel-level grounding, alongside cross-disciplinary test suites in physics and chemistry. Experimental results demonstrate that FigEx2 achieves a superior 0.726 mAP@0.5:0.95 for detection and significantly outperforms Qwen3-VL-8B by 0.51 in METEOR and 0.24 in BERTScore. Notably, FigEx2 exhibits remarkable zero-shot transferability to out-of-distribution scientific domains without any fine-tuning.","authors":["Jifeng Song","Arun Das","Pan Wang","Hui Ji","Kun Zhao","Yufei Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.07477v2","updated":"2026-02-25T13:23:05Z","published":"2025-06-09T06:50:59Z","title":"Premise Selection for a Lean Hammer","summary":"Neural methods are transforming automated reasoning for proof assistants, yet integrating these advances into practical verification workflows remains challenging. A hammer is a tool that integrates premise selection, translation to external automatic theorem provers, and proof reconstruction into one overarching tool to automate tedious reasoning steps. We present LeanPremise, a novel neural premise selection system, and we combine it with existing translation and proof reconstruction components to create LeanHammer, the first end-to-end domain general hammer for the Lean proof assistant. Unlike existing Lean premise selectors, LeanPremise is specifically trained for use with a hammer in dependent type theory. It also dynamically adapts to user-specific contexts, enabling it to effectively recommend premises from libraries outside LeanPremise's training data as well as lemmas defined by the user locally. With comprehensive evaluations, we show that LeanPremise enables LeanHammer to solve 21% more goals than existing premise selectors and generalizes well to diverse domains. Our work helps bridge the gap between neural retrieval and symbolic reasoning, making formal verification more accessible to researchers and practitioners.","authors":["Thomas Zhu","Joshua Clune","Jeremy Avigad","Albert Qiaochu Jiang","Sean Welleck"],"pdf_url":"","comment":"LeanPremise is available at https://github.com/hanwenzhu/premise-selection and LeanHammer is available at https://github.com/JOSHCLUNE/LeanHammer"},{"id":"http://arxiv.org/abs/2504.06533v3","updated":"2026-02-25T13:11:21Z","published":"2025-04-09T02:16:46Z","title":"Rethinking Flexible Graph Similarity Computation: One-step Alignment with Global Guidance","summary":"Graph Edit Distance (GED) is a widely used measure of graph similarity, valued for its flexibility in encoding domain knowledge through operation costs. However, existing learning-based approximation methods follow a modeling paradigm that decouples local candidate match selection from both operation costs and global dependencies between matches. This decoupling undermines their ability to capture the intrinsic flexibility of GED and often forces them to rely on costly iterative refinement to obtain accurate alignments. In this work, we revisit the formulation of GED and revise the prevailing paradigm, and propose Graph Edit Network (GEN), an implementation of the revised formulation that tightly integrates cost-aware expense estimation with globally guided one-step alignment. Specifically, GEN incorporates operation costs into node matching expenses estimation, ensuring match decisions respect the specified cost setting. Furthermore, GEN models match dependencies within and across graphs, capturing each match's impact on the overall alignment. These designs enable accurate GED approximation without iterative refinement. Extensive experiments on real-world and synthetic benchmarks demonstrate that GEN achieves up to a 37.8% reduction in GED predictive errors, while increasing inference throughput by up to 414x. These results highlight GEN's practical efficiency and the effectiveness of the revision. Beyond this implementation, our revision provides a principled framework for advancing learning-based GED approximation.","authors":["Zhouyang Liu","Ning Liu","Yixin Chen","Jiezhong He","Shuai Ma","Dongsheng Li"],"pdf_url":"","comment":"Accepted by ICDE 2026"},{"id":"http://arxiv.org/abs/2602.21889v1","updated":"2026-02-25T13:11:12Z","published":"2026-02-25T13:11:12Z","title":"2-Step Agent: A Framework for the Interaction of a Decision Maker with AI Decision Support","summary":"Across a growing number of fields, human decision making is supported by predictions from AI models. However, we still lack a deep understanding of the effects of adoption of these technologies. In this paper, we introduce a general computational framework, the 2-Step Agent, which models the effects of AI-assisted decision making. Our framework uses Bayesian methods for causal inference to model 1) how a prediction on a new observation affects the beliefs of a rational Bayesian agent, and 2) how this change in beliefs affects the downstream decision and subsequent outcome. Using this framework, we show by simulations how a single misaligned prior belief can be sufficient for decision support to result in worse downstream outcomes compared to no decision support. Our results reveal several potential pitfalls of AI-driven decision support and highlight the need for thorough model documentation and proper user training.","authors":["Otto Nyberg","Fausto Carcassi","Giovanni Cinà"],"pdf_url":"","comment":"17 pages, 17 figures"},{"id":"http://arxiv.org/abs/2602.21864v1","updated":"2026-02-25T12:45:45Z","published":"2026-02-25T12:45:45Z","title":"DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs","summary":"Vision-Language Models (VLMs) have emerged as versatile solutions for zero-shot question answering (QA) across various domains. However, enabling VLMs to effectively comprehend structured graphs and perform accurate, efficient QA remains challenging. Existing approaches typically rely on one single graph topology representation (GTR), such as fixed-style visual images or unified text descriptions. This ``one-size-fits-all'' strategy often neglects model-specific and task-specific preferences, resulting in inaccurate or over-lengthy responses to graph-related queries. To address this, we propose the $\\mbox{DynamicGTR}$ framework, which dynamically selects the optimal GTR for each query during inference, thereby enhancing the zero-shot graph QA capabilities of VLMs with a customizable accuracy and brevity trade-off. Extensive experiments show that DynamicGTR not only improves VLM-based graph algorithm QA performance but also successfully transfers the experience trained from synthetic graph algorithm tasks to real-world applications like link prediction and node classification, without any additional training. Additionally, DynamicGTR demonstrates strong transferability across tasks, domains, and models, suggesting its potential as a flexible solution for broad graph scenarios.","authors":["Yanbin Wei","Jiangyue Yan","Chun Kang","Yang Chen","Hua Liu","James Kwok","Yu Zhang"],"pdf_url":"","comment":"CVPR 2026"},{"id":"http://arxiv.org/abs/2507.14899v3","updated":"2026-02-25T12:39:48Z","published":"2025-07-20T10:23:22Z","title":"InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis","summary":"Non-destructive testing (NDT), particularly X-ray inspection, is vital for industrial quality assurance, yet existing deep-learning-based approaches often lack interactivity, interpretability, and the capacity for critical self-assessment, limiting their reliability and operator trust. To address these shortcomings, this paper proposes InsightX Agent, a novel LMM-based agentic framework designed to deliver reliable, interpretable, and interactive X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent positions a Large Multimodal Model (LMM) as a central orchestrator, coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect region proposals from multi-scale feature maps and sparsifies them through Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in X-ray images while maintaining computational efficiency. The EGR tool guides the LMM agent through a chain-of-thought-inspired review process, incorporating context assessment, individual defect analysis, false positive elimination, confidence recalibration and quality assurance to validate and refine the SDMSD's initial proposals. By strategically employing and intelligently using tools, InsightX Agent moves beyond passive data processing to active reasoning, enhancing diagnostic reliability and providing interpretations that integrate diverse information sources. Experimental evaluations on the GDXray+ dataset demonstrate that InsightX Agent not only achieves a high object detection F1-score of 96.54\\% but also offers significantly improved interpretability and trustworthiness in its analyses, highlighting the transformative potential of LMM-based agentic frameworks for industrial inspection tasks.","authors":["Jiale Liu","Huan Wang","Yue Zhang","Xiaoyu Luo","Jiaxiang Hu","Zhiliang Liu","Min Xie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21858v1","updated":"2026-02-25T12:32:37Z","published":"2026-02-25T12:32:37Z","title":"ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices","summary":"Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.","authors":["Dezhi Kong","Zhengzhao Feng","Qiliang Liang","Hao Wang","Haofei Sun","Changpeng Yang","Yang Li","Peng Zhou","Shuai Nie","Hongzhen Wang","Linfeng Zhou","Hao Jia","Jiaming Xu","Runyu Shi","Ying Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21857v1","updated":"2026-02-25T12:32:04Z","published":"2026-02-25T12:32:04Z","title":"Distill and Align Decomposition for Enhanced Claim Verification","summary":"Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.","authors":["Jabez Magomere","Elena Kochkina","Samuel Mensah","Simerjot Kaur","Fernando Acero","Arturo Oncevay","Charese H. Smiley","Xiaomo Liu","Manuela Veloso"],"pdf_url":"","comment":"EACL Findings 2026"},{"id":"http://arxiv.org/abs/2602.10359v2","updated":"2026-02-25T12:31:43Z","published":"2026-02-10T23:08:06Z","title":"Beyond Calibration: Confounding Pathology Limits Foundation Model Specificity in Abdominal Trauma CT","summary":"Purpose: Translating foundation models into clinical practice requires evaluating their performance under compound distribution shift, where severe class imbalance coexists with heterogeneous imaging appearances. This challenge is relevant for traumatic bowel injury, a rare but high-mortality diagnosis. We investigated whether specificity deficits in foundation models are associated with heterogeneity in the negative class. Methods: This retrospective study used the multi-institutional, RSNA Abdominal Traumatic Injury CT dataset (2019-2023), comprising scans from 23 centres. Two foundation models (MedCLIP, zero-shot; RadDINO, linear probe) were compared against three task-specific approaches (CNN, Transformer, Ensemble). Models were trained on 3,147 patients (2.3% bowel injury prevalence) and evaluated on an enriched 100-patient test set. To isolate negative-class effects, specificity was assessed in patients without bowel injury who had concurrent solid organ injury (n=58) versus no abdominal pathology (n=50). Results: Foundation models achieved equivalent discrimination to task-specific models (AUC, 0.64-0.68 versus 0.58-0.64) with higher sensitivity (79-91% vs 41-74%) but lower specificity (33-50% vs 50-88%). All models demonstrated high specificity in patients without abdominal pathology (84-100%). When solid organ injuries were present, specificity declined substantially for foundation models (50-51 percentage points) compared with smaller reductions of 12-41 percentage points for task-specific models. Conclusion: Foundation models matched task-specific discrimination without task-specific training, but their specificity deficits were driven primarily by confounding negative-class heterogeneity rather than prevalence alone. Susceptibility to negative-class heterogeneity decreased progressively with labelled training, suggesting adaptation is required before clinical implementation.","authors":["Jineel H Raythatha","Shuchang Ye","Jeremy Hsu","Jinman Kim"],"pdf_url":"","comment":"26 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2602.21855v1","updated":"2026-02-25T12:30:54Z","published":"2026-02-25T12:30:54Z","title":"Understanding Annotation Error Propagation and Learning an Adaptive Policy for Expert Intervention in Barrett's Video Segmentation","summary":"Accurate annotation of endoscopic videos is essential yet time-consuming, particularly for challenging datasets such as dysplasia in Barrett's esophagus, where the affected regions are irregular and lack clear boundaries. Semi-automatic tools like Segment Anything Model 2 (SAM2) can ease this process by propagating annotations across frames, but small errors often accumulate and reduce accuracy, requiring expert review and correction. To address this, we systematically study how annotation errors propagate across different prompt types, namely masks, boxes, and points, and propose Learning-to-Re-Prompt (L2RP), a cost-aware framework that learns when and where to seek expert input. By tuning a human-cost parameter, our method balances annotation effort and segmentation accuracy. Experiments on a private Barrett's dysplasia dataset and the public SUN-SEG benchmark demonstrate improved temporal consistency and superior performance over baseline strategies.","authors":["Lokesha Rasanjalee","Jin Lin Tan","Dileepa Pitawela","Rajvinder Singh","Hsiang-Ting Chen"],"pdf_url":"","comment":"Accepted at IEEE ISBI 2026"},{"id":"http://arxiv.org/abs/2602.21845v1","updated":"2026-02-25T12:25:29Z","published":"2026-02-25T12:25:29Z","title":"xai-cola: A Python library for sparsifying counterfactual explanations","summary":"Counterfactual explanation (CE) is an important domain within post-hoc explainability. However, the explanations generated by most CE generators are often highly redundant. This work introduces an open-source Python library xai-cola, which provides an end-to-end pipeline for sparsifying CEs produced by arbitrary generators, reducing superfluous feature changes while preserving their validity. It offers a documented API that takes as input raw tabular data in pandas DataFrame form, a preprocessing object (for standardization and encoding), and a trained scikit-learn or PyTorch model. On this basis, users can either employ the built-in or externally imported CE generators. The library also implements several sparsification policies and includes visualization routines for analysing and comparing sparsified counterfactuals. xai-cola is released under the MIT license and can be installed from PyPI. Empirical experiments indicate that xai-cola produces sparser counterfactuals across several CE generators, reducing the number of modified features by up to 50% in our setting. The source code is available at https://github.com/understanding-ml/COLA.","authors":["Lin Zhu","Lei You"],"pdf_url":"","comment":"5pages, 1 figure"},{"id":"http://arxiv.org/abs/2506.05154v4","updated":"2026-02-25T12:22:09Z","published":"2025-06-05T15:34:15Z","title":"Resisting Contextual Interference in RAG via Parametric-Knowledge Reinforcement","summary":"Retrieval-augmented generation (RAG) improves performance on knowledge-intensive tasks but can be derailed by wrong, irrelevant, or conflicting retrieved text, causing models to rely on inaccurate evidence and cascade errors. We propose Knowledgeable-R1, a reinforcement-learning framework that explicitly trains large language models to use parametric knowledge (PK) to resist contextual interference while still exploiting external context when it is reliably helpful. Knowledgeable-R1 introduces a joint sampling scheme that generates paired responses with and without retrieval, and learns both local advantages (within each decoding regime) and global advantages under the same input to quantify when to ignore misleading context versus adopt it. We employ an asymmetric advantage transformation that amplifies exploratory behaviors toward parametric knowledge. Experiments show that Knowledgeable-R1 significantly improves robustness and reasoning accuracy in knowledge conflict scenarios and general RAG scenarios, outperforming SOTA baselines by +22.89% in counterfactual scenarios, and without degradation when the retrieved context is fully accurate.Our code are available at https://github.com/lcy80366872/knowledgeable-R1.","authors":["Chenyu Lin","Yilin Wen","Du Su","Hexiang Tan","Fei Sun","Muhan Chen","Chenfu Bao","Zhonghou Lyu"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2602.21841v1","updated":"2026-02-25T12:20:47Z","published":"2026-02-25T12:20:47Z","title":"Resilient Federated Chain: Transforming Blockchain Consensus into an Active Defense Layer for Federated Learning","summary":"Federated Learning (FL) has emerged as a key paradigm for building Trustworthy AI systems by enabling privacy-preserving, decentralized model training. However, FL is highly susceptible to adversarial attacks that compromise model integrity and data confidentiality, a vulnerability exacerbated by the fact that conventional data inspection methods are incompatible with its decentralized design. While integrating FL with Blockchain technology has been proposed to address some limitations, its potential for mitigating adversarial attacks remains largely unexplored. This paper introduces Resilient Federated Chain (RFC), a novel blockchain-enabled FL framework designed specifically to enhance resilience against such threats. RFC builds upon the existing Proof of Federated Learning architecture by repurposing the redundancy of its Pooled Mining mechanism as an active defense layer that can be combined with robust aggregation rules. Furthermore, the framework introduces a flexible evaluation function in its consensus mechanism, allowing for adaptive defense against different attack strategies. Extensive experimental evaluation on image classification tasks under various adversarial scenarios, demonstrates that RFC significantly improves robustness compared to baseline methods, providing a viable solution for securing decentralized learning environments.","authors":["Mario García-Márquez","Nuria Rodríguez-Barroso","M. Victoria Luzón","Francisco Herrera"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2506.13793v4","updated":"2026-02-25T12:16:37Z","published":"2025-06-11T14:58:38Z","title":"Med-REFL: Medical Reasoning Enhancement via Self-Corrected Fine-grained Reflection","summary":"Large reasoning models excel in domains like mathematics where intermediate reasoning is straightforward to verify, but struggle to self-correct in medicine fields where evaluating intermediate reasoning is cumbersome and expensive. This verification bottleneck hinders the development of reliable AI reasoners for high-stakes application. Here we propose Med-REFL, a novel framework that learns fine-grained reflection without human labels or model distillation. Med-REFL introduces a deterministic structural assessment of the reasoning space to automatically generate preference data for reflection. By globally evaluating all explored reasoning paths in a tree-of-thoughts, our method quantifies the value of corrective actions, enabling the automated construction of direct preference optimization pairs. This trains the model to recognize and amend its own reasoning fallacies. Extensive experiments show Med-REFL delivers robust gains across diverse models architectures and medical benchmarks, boosting a general-purpose Llama3.1-8B by +5.82% and the state-of-the-art Huatuo-o1 by +4.13% on the MedQA benchmark. Our Med-REFL-8B achieves state-of-the-art performance among 7-8B models while even competing with models twice its size. Crucially, targeted ablations prove its success generalizes to other domains such as logical reasoning and mitigates the `fake reflection' phenomenon in LRMs. Ultimately, our framework provides a scalable solution to the verification bottleneck, paving the way for more reliable AI reasoners in high-stakes domains like medicine. Med-REFL has been made publicly available in https://github.com/TianYin123/Med-REFL.","authors":["Zongxian Yang","Jiayu Qian","Zegao Peng","Haoyu Zhang","Yu-An Huang","KC Tan","Zhi-An Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.13755v6","updated":"2026-02-25T12:13:07Z","published":"2025-08-19T11:51:40Z","title":"Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration","summary":"Reinforcement Learning with Verifiable Reward (RLVR) has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models, yet its full potential is hindered by two under-explored dimensions: Depth-the hardest problem a model can sample; Breadth-the number of instances consumed in a single iteration. We dissect the popular GRPO algorithm and reveal a systematic bias: the cumulative-advantage disproportionately weights samples with medium accuracy, while down-weighting the low-accuracy instances that are crucial for pushing reasoning boundaries. To rectify the depth neglect, we introduce Difficulty Adaptive Rollout Sampling (DARS), which re-weights hard problems through targeted multi-stage rollouts, thereby increasing the number of positive rollouts for hard problems. Empirically, naively enlarging rollout size only accelerates convergence and even hurts Pass@K. Our DARS, in contrast, delivers consistent Pass@K gains without extra inference cost at convergence. Just as we adaptively expanded the depth of exploration, we now ask whether aggressively scaling the breadth of training data can further amplify reasoning gains. To this end, we intensely scale batch size and replace PPO's mini-batch iterations with full-batch updates over multiple epochs. Increasing breadth significantly enhances Pass@1 performance. Large-breadth training sustains high token-level entropy, indicating continued exploration and reduced gradient noise. We further present DARS-B, which augments DARS with large breadth, and demonstrate simultaneous gains in Pass@K and Pass@1. The results confirm that breadth and adaptive exploration across depth operate as orthogonal dimensions in RLVR, which are key to unleashing the reasoning power of RLVR.","authors":["Zhicheng Yang","Zhijiang Guo","Yinya Huang","Yongxin Wang","Dongchun Xie","Hanhui Li","Yiwei Wang","Xiaodan Liang","Jing Tang"],"pdf_url":"","comment":"20 pages, 17 figures"},{"id":"http://arxiv.org/abs/2602.21829v1","updated":"2026-02-25T12:01:05Z","published":"2026-02-25T12:01:05Z","title":"StoryMovie: A Dataset for Semantic Alignment of Visual Stories with Movie Scripts and Subtitles","summary":"Visual storytelling models that correctly ground entities in images may still hallucinate semantic relationships, generating incorrect dialogue attribution, character interactions, or emotional states. We introduce StoryMovie, a dataset of 1,757 stories aligned with movie scripts and subtitles through LCS matching. Our alignment pipeline synchronizes screenplay dialogue with subtitle timestamps, enabling dialogue attribution by linking character names from scripts to temporal positions from subtitles. Using this aligned content, we generate stories that maintain visual grounding tags while incorporating authentic character names, dialogue, and relationship dynamics. We fine-tune Qwen Storyteller3 on this dataset, building on prior work in visual grounding and entity re-identification. Evaluation using DeepSeek V3 as judge shows that Storyteller3 achieves an 89.9% win rate against base Qwen2.5-VL 7B on subtitle alignment. Compared to Storyteller, trained without script grounding,\n  Storyteller3 achieves 48.5% versus 38.0%, confirming that semantic alignment progressively improves dialogue attribution beyond visual grounding alone.","authors":["Daniel Oliveira","David Martins de Matos"],"pdf_url":"","comment":"15 pages, submitted to Journal of Visual Communication and Image Representation"},{"id":"http://arxiv.org/abs/2602.16898v3","updated":"2026-02-25T11:49:07Z","published":"2026-02-18T21:28:56Z","title":"MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation","summary":"Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings. MALLVI presents a Multi Agent Large Language and Vision framework that enables closed-loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVI generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step. Rather than using a single model, MALLVI coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning. Experiments in simulation and real-world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks. Code available at https://github.com/iman1234ahmadi/MALLVI .","authors":["Iman Ahmadi","Mehrshad Taji","Arad Mahdinezhad Kashani","AmirHossein Jadidi","Saina Kashani","Babak Khalaj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21819v1","updated":"2026-02-25T11:47:09Z","published":"2026-02-25T11:47:09Z","title":"SemVideo: Reconstructs What You Watch from Brain Activity via Hierarchical Semantic Guidance","summary":"Reconstructing dynamic visual experiences from brain activity provides a compelling avenue for exploring the neural mechanisms of human visual perception. While recent progress in fMRI-based image reconstruction has been notable, extending this success to video reconstruction remains a significant challenge. Current fMRI-to-video reconstruction approaches consistently encounter two major shortcomings: (i) inconsistent visual representations of salient objects across frames, leading to appearance mismatches; (ii) poor temporal coherence, resulting in motion misalignment or abrupt frame transitions. To address these limitations, we introduce SemVideo, a novel fMRI-to-video reconstruction framework guided by hierarchical semantic information. At the core of SemVideo is SemMiner, a hierarchical guidance module that constructs three levels of semantic cues from the original video stimulus: static anchor descriptions, motion-oriented narratives, and holistic summaries. Leveraging this semantic guidance, SemVideo comprises three key components: a Semantic Alignment Decoder that aligns fMRI signals with CLIP-style embeddings derived from SemMiner, a Motion Adaptation Decoder that reconstructs dynamic motion patterns using a novel tripartite attention fusion architecture, and a Conditional Video Render that leverages hierarchical semantic guidance for video reconstruction. Experiments conducted on the CC2017 and HCP datasets demonstrate that SemVideo achieves superior performance in both semantic alignment and temporal consistency, setting a new state-of-the-art in fMRI-to-video reconstruction.","authors":["Minghan Yang","Lan Yang","Ke Li","Honggang Zhang","Kaiyue Pang","Yizhe Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20971v2","updated":"2026-02-25T11:40:21Z","published":"2026-02-24T14:52:20Z","title":"Does Order Matter : Connecting The Law of Robustness to Robust Generalization","summary":"Bubeck and Sellke (2021) pose as an open problem the connection between the law of robustness and robust generalization. The law of robustness states that overparameterization is necessary for models to interpolate robustly; in particular, robust interpolation requires the learned function to be Lipschitz. Robust generalization asks whether small robust training loss implies small robust test loss. We resolve this problem by explicitly connecting the two for arbitrary data distributions. Specifically, we introduce a nontrivial notion of robust generalization error and convert it into a lower bound on the expected Rademacher complexity of the induced robust loss class. Our bounds recover the $Ω(n^{1/d})$ regime of Wu et al. (2023) and show that, up to constants, robust generalization does not change the order of the Lipschitz constant required for smooth interpolation. We conduct experiments to probe the predicted scaling with dataset size and model capacity, testing whether empirical behavior aligns more closely with the predictions of Bubeck and Sellke (2021) or Wu et al. (2023). For MNIST, we find that the lower-bound Lipschitz constant scales on the order predicted by Wu et al. (2023). Informally, to obtain low robust generalization error, the Lipschitz constant must lie in a range that we bound, and the allowable perturbation radius is linked to the Lipschitz scale.","authors":["Himadri Mandal","Vishnu Varadarajan","Jaee Ponde","Aritra Das","Mihir More","Debayan Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21814v1","updated":"2026-02-25T11:40:15Z","published":"2026-02-25T11:40:15Z","title":"Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem","summary":"Large language models consistently fail the \"car wash problem,\" a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.","authors":["Heejin Jo"],"pdf_url":"","comment":"9 pages, 4 tables"},{"id":"http://arxiv.org/abs/2511.00129v4","updated":"2026-02-25T11:32:35Z","published":"2025-10-31T10:25:23Z","title":"Data-Augmented Deep Learning for Downhole Depth Sensing and Validation","summary":"Accurate downhole depth measurement is essential for oil and gas well operations, directly influencing reservoir contact, production efficiency, and operational safety. Collar correlation using a casing collar locator (CCL) is fundamental for precise depth calibration. While neural network has achieved significant progress in collar recognition, preprocessing methods for such applications remain underdeveloped. Moreover, the limited availability of real well data poses substantial challenges for training neural network models that require extensive datasets. This paper presents a system integrated into a downhole toolstring for CCL log acquisition to facilitate dataset construction. Comprehensive preprocessing methods for data augmentation are proposed, and their effectiveness is evaluated using baseline neural network models. Through systematic experimentation across diverse configurations, the contribution of each augmentation method is analyzed. Results demonstrate that standardization, label distribution smoothing, and random cropping are fundamental prerequisites for model training, while label smoothing regularization, time scaling, and multiple sampling significantly enhance model generalization capabilities. Incorporating the proposed augmentation methods into the two baseline models results in maximum F1 score improvements of 0.027 and 0.024 for the TAN and MAN models, respectively. Furthermore, applying these techniques yields F1 score gains of up to 0.045 for the TAN model and 0.057 for the MAN model compared to prior studies. Performance evaluation on real CCL waveforms confirms the effectiveness and practical applicability of our approach. This work addresses the existing gaps in data augmentation methodologies for training casing collar recognition models under CCL data-limited conditions, and provides a technical foundation for the future automation of downhole operations.","authors":["Si-Yu Xiao","Xin-Di Zhao","Tian-Hao Mao","Yi-Wei Wang","Yu-Qiao Chen","Hong-Yun Zhang","Jian Wang","Jun-Jie Wang","Shuang Liu","Tu-Pei Chen","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21800v1","updated":"2026-02-25T11:27:34Z","published":"2026-02-25T11:27:34Z","title":"An Evaluation of Context Length Extrapolation in Long Code via Positional Embeddings and Efficient Attention","summary":"The rapid advancement of large language models (LLMs) has led to a significant increase in automated tools in the software engineering, capable of performing various code-related tasks such as code generation, completion, and translation. Despite these advancements, its effectiveness is constrained by fixed context lengths, limiting its ability to generalize across long, domain-specific code sequences. To address this challenge, we investigate zero-shot, inference-only methods aimed at improving position encodings and optimizing attention mechanisms. Our goal is to provide a thorough analysis of current approaches that facilitate context length extrapolation in code, particularly in the context of long code completion tasks.","authors":["Madhusudan Ghosh","Rishabh Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21798v1","updated":"2026-02-25T11:22:47Z","published":"2026-02-25T11:22:47Z","title":"Excitation: Momentum For Experts","summary":"We propose Excitation, a novel optimization framework designed to accelerate learning in sparse architectures such as Mixture-of-Experts (MoEs). Unlike traditional optimizers that treat all parameters uniformly, Excitation dynamically modulates updates using batch-level expert utilization. It introduces a competitive update dynamic that amplifies updates to highly-utilized experts and can selectively suppress low-utilization ones, effectively sharpening routing specialization. Notably, we identify a phenomenon of \"structural confusion\" in deep MoEs, where standard optimizers fail to establish functional signal paths; Excitation acts as a specialization catalyst, \"rescuing\" these models and enabling stable training where baselines remain trapped. Excitation is optimizer-, domain-, and model-agnostic, requires minimal integration effort, and introduces neither additional per-parameter optimizer state nor learnable parameters, making it highly viable for memory-constrained settings. Across language and vision tasks, Excitation consistently improves convergence speed and final performance in MoE models, indicating that active update modulation is a key mechanism for effective conditional computation.","authors":["Sagi Shaier"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.10953v2","updated":"2026-02-25T11:16:34Z","published":"2026-02-11T15:41:09Z","title":"Search or Accelerate: Confidence-Switched Position Beam Search for Diffusion Language Models","summary":"Diffusion Language Models (DLMs) generate text by iteratively denoising a masked sequence, repeatedly deciding which positions to commit at each step. Standard decoding follows a greedy rule: unmask the most confident positions, yet this local choice can lock the model into a suboptimal unmasking order, especially on reasoning-heavy prompts. We present SOAR, a training-free decoding algorithm that adapts its behavior to the model's uncertainty. When confidence is low, SOAR briefly widens the search over alternative unmasking decisions to avoid premature commitments; when confidence is high, it collapses the search and decodes many positions in parallel to reduce the number of denoising iterations. Across mathematical reasoning and code generation benchmarks (GSM8K, MBPP, HumanEval) on Dream-7B and LLaDA-8B, SOAR improves generation quality while maintaining competitive inference speed, offering a practical way to balance quality and efficiency in DLM decoding. Our Code is available at https://github.com/duterscmy/SOAR","authors":["Mingyu Cao","Alvaro H. C. Correia","Christos Louizos","Shiwei Liu","Lu Yin"],"pdf_url":"","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.21779v1","updated":"2026-02-25T10:54:55Z","published":"2026-02-25T10:54:55Z","title":"Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models","summary":"Current Vision-Language Models (VLMs) for deepfake detection excel at identifying spatial artifacts but overlook a critical dimension: temporal inconsistencies in video forgeries. Adapting VLMs to reason about these dynamic cues remains a distinct challenge. To bridge this gap, we propose Forensic Answer-Questioning (FAQ), a large-scale benchmark that formulates temporal deepfake analysis as a multiple-choice task. FAQ introduces a three-level hierarchy to progressively evaluate and equip VLMs with forensic capabilities: (1) Facial Perception, testing the ability to identify static visual artifacts; (2) Temporal Deepfake Grounding, requiring the localization of dynamic forgery artifacts across frames; and (3) Forensic Reasoning, challenging models to synthesize evidence for final authenticity verdicts. We evaluate a range of VLMs on FAQ and generate a corresponding instruction-tuning set, FAQ-IT. Extensive experiments show that models fine-tuned on FAQ-IT achieve advanced performance on both in-domain and cross-dataset detection benchmarks. Ablation studies further validate the impact of our key design choices, confirming that FAQ is the driving force behind the temporal reasoning capabilities of these VLMs.","authors":["Zheyuan Gu","Qingsong Zhao","Yusong Wang","Zhaohong Huang","Xinqi Li","Cheng Yuan","Jiaowei Shao","Chi Zhang","Xuelong Li"],"pdf_url":"","comment":"16 pages, 9 figures. Submitted to CVPR 2026"},{"id":"http://arxiv.org/abs/2602.21772v1","updated":"2026-02-25T10:47:20Z","published":"2026-02-25T10:47:20Z","title":"UniWhisper: Efficient Continual Multi-task Training for Robust Universal Audio Representation","summary":"A universal audio representation should capture fine-grained speech cues and high-level semantics for environmental sounds and music in a single encoder. Existing encoders often excel in one domain but degrade in others. We propose UniWhisper, an efficient continual multi-task training framework that casts heterogeneous audio tasks into a unified instruction and answer format. This enables standard next-token training without task-specific heads and losses. We train it on 38k hours of public audio and assess the encoder using shallow MLP probes and k-nearest neighbors (kNN) on 20 tasks spanning speech, environmental sound, and music. UniWhisper reaches normalized weighted averages of 0.81 with MLP probes and 0.61 with kNN, compared to 0.64 and 0.46 for Whisper, while retaining strong speech performance.","authors":["Yuxuan Chen","Peize He","Haoyuan Xu","Junzi Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.15738v5","updated":"2026-02-25T10:39:10Z","published":"2024-07-22T15:41:23Z","title":"Parallel Split Learning with Global Sampling","summary":"Distributed deep learning in resource-constrained environments faces scalability and generalization challenges due to large effective batch sizes and non-identically distributed client data. We introduce a server-driven sampling strategy that maintains a fixed global batch size by dynamically adjusting client-side batch sizes. This decouples the effective batch size from the number of participating devices and ensures that global batches better reflect the overall data distribution. Using standard concentration bounds, we establish tighter deviation guarantees compared to existing approaches. Empirical results on a benchmark dataset confirm that the proposed method improves model accuracy, training efficiency, and convergence stability, offering a scalable solution for learning at the network edge.","authors":["Mohammad Kohankhaki","Ahmad Ayad","Mahdi Barhoush","Anke Schmeink"],"pdf_url":"","comment":"Accepted at the 2025 IEEE 3rd International Conference on Foundation and Large Language Models (FLLM). This version corresponds to the accepted manuscript"},{"id":"http://arxiv.org/abs/2602.21765v1","updated":"2026-02-25T10:36:17Z","published":"2026-02-25T10:36:17Z","title":"Generalisation of RLHF under Reward Shift and Clipped KL Regularisation","summary":"Alignment and adaptation in large language models heavily rely on reinforcement learning from human feedback (RLHF); yet, theoretical understanding of its generalisability remains premature, especially when the learned reward could shift, and the KL control is estimated and clipped. To address this issue, we develop generalisation theory for RLHF that explicitly accounts for (1) \\emph{reward shift}: reward models are trained on preference data from earlier or mixed behaviour policies while RLHF optimises the current policy on its own rollouts; and (2) \\emph{clipped KL regularisation}: the KL regulariser is estimated from sampled log-probability ratios and then clipped for stabilisation, resulting in an error to RLHF. We present generalisation bounds for RLHF, suggesting that the generalisation error stems from a sampling error from prompts and rollouts, a reward shift error, and a KL clipping error. We also discuss special cases of (1) initialising RLHF parameters with a uniform prior over a finite space, and (2) training RLHF by stochastic gradient descent, as an Ornstein-Uhlenbeck process. The theory yields practical implications in (1) optimal KL clipping threshold, and (2) budget allocation in prompts, rollouts, and preference data.","authors":["Kenton Tang","Yuzhu Chen","Fengxiang He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21757v1","updated":"2026-02-25T10:19:39Z","published":"2026-02-25T10:19:39Z","title":"Learning from Yesterday's Error: An Efficient Online Learning Method for Traffic Demand Prediction","summary":"Accurately predicting short-term traffic demand is critical for intelligent transportation systems. While deep learning models achieve strong performance under stationary conditions, their accuracy often degrades significantly when faced with distribution shifts caused by external events or evolving urban dynamics. Frequent model retraining to adapt to such changes incurs prohibitive computational costs, especially for large-scale or foundation models. To address this challenge, we propose FORESEE (Forecasting Online with Residual Smoothing and Ensemble Experts), a lightweight online adaptation framework that is accurate, robust, and computationally efficient. FORESEE operates without any parameter updates to the base model. Instead, it corrects today's forecast in each region using yesterday's prediction error, stabilized through exponential smoothing guided by a mixture-of-experts mechanism that adapts to recent error dynamics. Moreover, an adaptive spatiotemporal smoothing component propagates error signals across neighboring regions and time slots, capturing coherent shifts in demand patterns. Extensive experiments on seven real-world datasets with three backbone models demonstrate that FORESEE consistently improves prediction accuracy, maintains robustness even when distribution shifts are minimal (avoiding performance degradation), and achieves the lowest computational overhead among existing online methods. By enabling real-time adaptation of traffic forecasting models with negligible computational cost, FORESEE paves the way for deploying reliable, up-to-date prediction systems in dynamic urban environments. Code and data are available at https://github.com/xiannanhuang/FORESEE","authors":["Xiannan Huang","Quan Yuan","Chao Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.05066v2","updated":"2026-02-25T10:09:46Z","published":"2026-02-04T21:38:38Z","title":"Bypassing AI Control Protocols via Agent-as-a-Proxy Attacks","summary":"As AI agents automate critical workloads, they remain vulnerable to indirect prompt injection (IPI) attacks. Current defenses rely on monitoring protocols that jointly evaluate an agent's Chain-of-Thought (CoT) and tool-use actions to ensure alignment with user intent. We demonstrate that these monitoring-based defenses can be bypassed via a novel Agent-as-a-Proxy attack, where prompt injection attacks treat the agent as a delivery mechanism, bypassing both agent and monitor simultaneously. While prior work on scalable oversight has focused on whether small monitors can supervise large agents, we show that even frontier-scale monitors are vulnerable. Large-scale monitoring models like Qwen2.5-72B can be bypassed by agents with similar capabilities, such as GPT-4o mini and Llama-3.1-70B. On the AgentDojo benchmark, we achieve a high attack success rate against AlignmentCheck and Extract-and-Evaluate monitors under diverse monitoring LLMs. Our findings suggest current monitoring-based agentic defenses are fundamentally fragile regardless of model scale.","authors":["Jafar Isbarov","Murat Kantarcioglu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.00462v3","updated":"2026-02-25T10:06:33Z","published":"2026-01-31T02:33:07Z","title":"LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs","summary":"Transforming a large language model (LLM) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM. Intriguingly, this mapping can be as simple as a shallow MLP transformation. To understand why LLMs can so readily process visual tokens, we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM processing. In this work, we introduce LatentLens, a novel approach for mapping latent representations to descriptions in natural language. LatentLens works by encoding a large text corpus and storing contextualized token representations for each token in that corpus. Visual token representations are then compared to their contextualized textual representations, with the top-k nearest neighbor representations providing descriptions of the visual token. We evaluate this method on 10 different VLMs, showing that commonly used methods, such as LogitLens, substantially underestimate the interpretability of visual tokens. With LatentLens instead, the majority of visual tokens are interpretable across all studied models and all layers. Qualitatively, we show that the descriptions produced by LatentLens are semantically meaningful and provide more fine-grained interpretations for humans compared to individual tokens. More broadly, our findings contribute new evidence on the alignment between vision and language representations, opening up new directions for analyzing latent representations.","authors":["Benno Krojer","Shravan Nayak","Oscar Mañas","Vaibhav Adlakha","Desmond Elliott","Siva Reddy","Marius Mosbach"],"pdf_url":"","comment":"Updates: small change in interpretability percentage for Qwen-based variants we trained (pre-processing fix), clarification in Section 3 on our method (after feedback from readers), additional appendix section"},{"id":"http://arxiv.org/abs/2602.21746v1","updated":"2026-02-25T09:58:14Z","published":"2026-02-25T09:58:14Z","title":"fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation","summary":"In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.","authors":["Abeer Dyoub","Francesca A. Lisi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21745v1","updated":"2026-02-25T09:56:26Z","published":"2026-02-25T09:56:26Z","title":"The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems","summary":"We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relational amplification, accumulated internal pressure, and transition costs.\n  Although initially formulated for human truth-telling under asymmetric stakes, the same phase-dynamic architecture extends to AI systems operating under policy constraints and alignment filters. In this context, suppression corresponds to constrained output states, while structural pressure arises from competing objectives, contextual tension, and recursive interaction dynamics. The framework therefore provides a unified structural account of both human silence under pressure and AI preference-driven distortion.\n  A feedback extension models how transition outcomes recursively recalibrate system parameters, generating path dependence and divergence effects across repeated interactions. Rather than attributing intention to AI systems, the model interprets shifts in apparent truthfulness as geometric consequences of interacting forces within constrained phase space. By reframing courage and alignment within a shared dynamical structure, the ASIR Courage Model offers a formal perspective on truth-disclosure under risk across both human and artificial systems.","authors":["Hyo Jin Kim"],"pdf_url":"","comment":"13 pages, 5 figures. Version 1. Includes recursive feedback extension and simulation results. Data available via DOI: 10.5281/zenodo.18754266"},{"id":"http://arxiv.org/abs/2406.17115v3","updated":"2026-02-25T09:48:59Z","published":"2024-06-24T20:08:07Z","title":"Measuring the Measurers: Quality Evaluation of Hallucination Benchmarks for Large Vision-Language Models","summary":"Despite the outstanding performance in multimodal tasks, Large Vision-Language Models (LVLMs) have been plagued by the issue of hallucination, i.e., generating content that is inconsistent with the corresponding visual inputs. While previous works have proposed various benchmarks to evaluate this issue, the quality of these evaluations remains unverified. We observe that some of these benchmarks may produce inconsistent evaluation results across repeated tests or fail to align with human evaluation. To address this, we propose a Hallucination benchmark Quality Measurement framework (HQM), which leverages specific indicators to assess both reliability and validity. Our empirical analysis using HQM reveals and pinpoints potential evaluation issues in existing benchmarks, exposing a critical gap in current hallucination evaluation. To bridge this gap, we propose HQH, a High-Quality Hallucination benchmark, which demonstrates superior reliability and validity under HQM, serving as a credible evaluation tool. Our large-scale evaluation of popular LVLMs on HQH reveals severe hallucination problems, which occur not only in the models' main answer to a question but also in additional analysis. This highlights the necessity for future model improvements to effectively mitigate hallucinations and reduce the associated security risks in real-world applications. Our benchmark is publicly available at https://github.com/HQHBench/HQHBench.","authors":["Bei Yan","Jie Zhang","Zheng Yuan","Shiguang Shan","Xilin Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20945v2","updated":"2026-02-25T09:40:11Z","published":"2026-02-24T14:28:16Z","title":"The Art of Efficient Reasoning: Data, Reward, and Optimization","summary":"Large Language Models (LLMs) consistently benefit from scaled Chain-of-Thought (CoT) reasoning, but also suffer from heavy computational overhead. To address this issue, efficient reasoning aims to incentivize short yet accurate thinking trajectories, typically through reward shaping with Reinforcement Learning (RL). In this paper, we systematically investigate the mechanics of efficient reasoning for LLMs. For comprehensive evaluation, we advocate for more fine-grained metrics, including length distribution conditioned on correctness and performance across a wide spectrum of token budgets ranging from 2k to 32k. First, we reveal that the training process follows a two-stage paradigm: length adaptation and reasoning refinement. After that, we conduct extensive experiments (about 0.2 million GPU hours) in a unified protocol, deconstructing training prompts and rollouts, reward shaping, and optimization strategies. In particular, a key finding is to train on relatively easier prompts, ensuring the density of positive reward signals and thus avoiding the length collapse. Meanwhile, the learned length bias can be generalized across domains. We distill all findings into valuable insights and practical guidelines, and further validate them across the Qwen3 series, ranging from 0.6B to 30B, demonstrating the robustness and generalization.","authors":["Taiqiang Wu","Zenan Xu","Bo Zhou","Ngai Wong"],"pdf_url":"","comment":"Tech Report, Insights on Efficient Reasoning via Reward Shaping"},{"id":"http://arxiv.org/abs/2602.21720v1","updated":"2026-02-25T09:27:02Z","published":"2026-02-25T09:27:02Z","title":"Evaluating the relationship between regularity and learnability in recursive numeral systems using Reinforcement Learning","summary":"Human recursive numeral systems (i.e., counting systems such as English base-10 numerals), like many other grammatical systems, are highly regular. Following prior work that relates cross-linguistic tendencies to biases in learning, we ask whether regular systems are common because regularity facilitates learning. Adopting methods from the Reinforcement Learning literature, we confirm that highly regular human(-like) systems are easier to learn than unattested but possible irregular systems. This asymmetry emerges under the natural assumption that recursive numeral systems are designed for generalisation from limited data to represent all integers exactly. We also find that the influence of regularity on learnability is absent for unnatural, highly irregular systems, whose learnability is influenced instead by signal length, suggesting that different pressures may influence learnability differently in different parts of the space of possible numeral systems. Our results contribute to the body of work linking learnability to cross-linguistic prevalence.","authors":["Andrea Silvi","Ponrawee Prasertsom","Jennifer Culbertson","Devdatt Dubhashi","Moa Johansson","Kenny Smith"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.09736v3","updated":"2026-02-25T09:25:40Z","published":"2025-10-10T14:20:25Z","title":"Chlorophyll-a Mapping and Prediction in the Mar Menor Lagoon Using C2RCC-Processed Sentinel 2 Imagery","summary":"The Mar Menor, Europe's largest hypersaline coastal lagoon, located in southeastern Spain, has undergone severe eutrophication crises, with devastating impacts on biodiversity and water quality. Monitoring chlorophyll-a, a proxy for phytoplankton biomass, is essential to anticipate harmful algal blooms and guide mitigation strategies. Traditional in situ measurements, while precise, are spatially and temporally limited. Satellite-based approaches provide a more comprehensive view, enabling scalable and long-term monitoring. This study aims to overcome limitations of chlorophyll monitoring, often restricted to surface estimates or limited temporal coverage, by developing a reliable methodology to predict and map chlorophyll-a concentrations across the water column of the Mar Menor. This work integrates Sentinel 2 imagery with buoy-based ground truth to create models capable of high-resolution, depth-specific monitoring, enhancing early-warning capabilities for eutrophication. Sentinel 2 images were atmospherically corrected using C2RCC processors. Buoy data were aggregated by depth. Multiple ML algorithms, including CatBoost, XGBoost, SVMs, and MLPs, were trained and validated using a cross-validation scheme with multi-objective optimization functions. Band-combination experiments and spatial aggregation strategies were tested to optimize prediction. The results show depth-dependent performance. The Root Mean Squared Logarithmic Error (RMSLE) obtained ranges from 0.34 at the surface to 0.39 at 3-4 m, while the R2 value was 0.76 at the surface, 0.76 at 1-2 m, 0.70 at 2-3 m, and 0.60 at 3-4 m. Generated maps successfully reproduced known eutrophication events. The study delivers an end-to-end, validated methodology chlorophyll mapping. Its integration of multispectral band combinations, buoy calibration, and modeling offers a transferable framework for other turbid coastal systems.","authors":["Antonio Martínez-Ibarra","Aurora González-Vidal","Adrián Cánovas-Rodríguez","Antonio F. Skarmeta"],"pdf_url":"","comment":"Supplementary material is available as pdf in https://github.com/Antonio-MI/mar-menor-chl. Version 3 is the current version of the manuscript, where the abstract has been shortened to fit arxiv's character limit. Version 2 contains the same manuscript as Version 3, but has an outdated abstract. Version 1 is an earlier draft of the work"},{"id":"http://arxiv.org/abs/2512.08639v2","updated":"2026-02-25T09:25:38Z","published":"2025-12-09T14:25:24Z","title":"Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning","summary":"Aerial Vision-and-Language Navigation (VLN) aims to enable unmanned aerial vehicles (UAVs) to interpret natural language instructions and navigate complex urban environments using onboard visual observation. This task holds promise for real-world applications such as low-altitude inspection, search-and-rescue, and autonomous aerial delivery. Existing methods often rely on panoramic images, depth inputs, or odometry to support spatial reasoning and action planning. These requirements increase system cost and integration complexity, thus hindering practical deployment for lightweight UAVs. We present a unified aerial VLN framework that operates solely on egocentric monocular RGB observations and natural language instructions. The model formulates navigation as a next-token prediction problem, jointly optimizing spatial perception, trajectory reasoning, and action prediction through prompt-guided multi-task learning. Moreover, we propose a keyframe selection strategy to reduce visual redundancy by retaining semantically informative frames, along with an action merging and label reweighting mechanism that mitigates long-tailed supervision imbalance and facilitates stable multi-task co-training. Extensive experiments on the AerialVLN and OpenFly benchmark validate the effectiveness of our method. Under the challenging monocular RGB-only setting, our model achieves strong results across both seen and unseen environments. It significantly outperforms existing RGB-only baselines and narrows the performance gap with state-of-the-art panoramic RGB-D counterparts. Comprehensive ablation studies further demonstrate the contribution of our task design and architectural choices.","authors":["Huilin Xu","Zhuoyang Liu","Yixiang Luomei","Feng Xu"],"pdf_url":"","comment":"Under Review, 15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2602.21715v1","updated":"2026-02-25T09:22:27Z","published":"2026-02-25T09:22:27Z","title":"Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach","summary":"The growing integration of distributed photovoltaics (PVs) into active distribution networks (ADNs) has exacerbated operational challenges, making it imperative to coordinate diverse equipment to mitigate voltage violations and enhance power quality. Although existing data-driven approaches have demonstrated effectiveness in the voltage control problem, they often require extensive trial-and-error exploration and struggle to incorporate heterogeneous information, such as day-ahead forecasts and semantic-based grid codes. Considering the operational scenarios and requirements in real-world ADNs, in this paper, we propose a hybrid knowledge-data-driven approach that leverages dynamic collaboration between a large language model (LLM) agent and a reinforcement learning (RL) agent to achieve two-stage voltage control. In the day-ahead stage, the LLM agent receives coarse region-level forecasts and generates scheduling strategies for on-load tap changer (OLTC) and shunt capacitors (SCs) to regulate the overall voltage profile. Then in the intra-day stage, based on accurate node-level measurements, the RL agent refines terminal voltages by deriving reactive power generation strategies for PV inverters. On top of the LLM-RL collaboration framework, we further propose a self-evolution mechanism for the LLM agent and a pretrain-finetune pipeline for the RL agent, effectively enhancing and coordinating the policies for both agents. The proposed approach not only aligns more closely with practical operational characteristics but also effectively utilizes the inherent knowledge and reasoning capabilities of the LLM agent, significantly improving training efficiency and voltage control performance. Comprehensive comparisons and ablation studies demonstrate the effectiveness of the proposed method.","authors":["Xu Yang","Chenhui Lin","Xiang Ma","Dong Liu","Ran Zheng","Haotian Liu","Wenchuan Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.00024v2","updated":"2026-02-25T09:22:26Z","published":"2025-09-24T18:54:56Z","title":"EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis","summary":"Large Language Models (LLMs) offer new opportunities to accelerate complex interdisciplinary research domains. Epidemic modeling, characterized by its complexity and reliance on network science, dynamical systems, epidemiology, and stochastic simulations, represents a prime candidate for leveraging LLM-driven automation. We introduce EpidemIQs, a novel multi-agent LLM framework that integrates user inputs and autonomously conducts literature review, analytical derivation, network modeling, mechanistic modeling, stochastic simulations, data visualization and analysis, and finally documentation of findings in a structured manuscript, through five predefined research phases. We introduce two types of agents: a scientist agent for planning, coordination, reflection, and generation of final results, and a task-expert agent to focus exclusively on one specific duty serving as a tool to the scientist agent. The framework consistently generated complete reports in scientific article format. Specifically, using GPT 4.1 and GPT 4.1 Mini as backbone LLMs for scientist and task-expert agents, respectively, the autonomous process completes with average total token usage 870K at a cost of about $1.57 per study, successfully executing all phases and final report. We evaluate EpidemIQs across several different epidemic scenarios, measuring computational cost, workflow reliability, task success rate, and LLM-as-Judge and human expert reviews to estimate the overall quality and technical correctness of the generated results. Through our experiments, the framework consistently addresses evaluation scenarios with an average task success rate of 79%. We compare EpidemIQs to an iterative single-agent LLM, benefiting from the same system prompts and tools, iteratively planning, invoking tools, and revising outputs until task completion. The comparisons suggest a consistently higher performance of EpidemIQs.","authors":["Mohammad Hossein Samaei","Faryad Darabi Sahneh","Lee W. Cohnstaedt","Caterina Scoglio"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21706v1","updated":"2026-02-25T09:11:45Z","published":"2026-02-25T09:11:45Z","title":"SurGo-R1: Benchmarking and Modeling Contextual Reasoning for Operative Zone in Surgical Video","summary":"Minimally invasive surgery has dramatically improved patient operative outcomes, yet identifying safe operative zones remains challenging in critical phases, requiring surgeons to integrate visual cues, procedural phase, and anatomical context under high cognitive load. Existing AI systems offer binary safety verification or static detection, ignoring the phase-dependent nature of intraoperative reasoning. We introduce ResGo, a benchmark of laparoscopic frames annotated with Go Zone bounding boxes and clinician-authored rationales covering phase, exposure quality reasoning, next action and risk reminder. We introduce evaluation metrics that treat correct grounding under incorrect phase as failures, revealing that most vision-language models cannot handle such tasks and perform poorly. We then present SurGo-R1, a model optimized via RLHF with a multi-turn phase-then-go architecture where the model first identifies the surgical phase, then generates reasoning and Go Zone coordinates conditioned on that context. On unseen procedures, SurGo-R1 achieves 76.6% phase accuracy, 32.7 mIoU, and 54.8% hardcore accuracy, a 6.6$\\times$ improvement over the mainstream generalist VLMs. Code, model and benchmark will be available at https://github.com/jinlab-imvr/SurGo-R1","authors":["Guanyi Qin","Xiaozhen Wang","Zhu Zhuo","Chang Han Low","Yuancan Xiao","Yibing Fu","Haofeng Liu","Kai Wang","Chunjiang Li","Yueming Jin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21704v1","updated":"2026-02-25T09:10:00Z","published":"2026-02-25T09:10:00Z","title":"Dynamic Multimodal Activation Steering for Hallucination Mitigation in Large Vision-Language Models","summary":"Large Vision-Language Models (LVLMs) exhibit outstanding performance on vision-language tasks but struggle with hallucination problems. Through in-depth analysis of LVLM activation patterns, we reveal two key findings: 1) truthfulness and visual perception capabilities predominantly engage different subsets of attention heads within the model architecture; and 2) truthfulness steering vectors vary significantly across different semantic contexts. Based on these observations, we propose Dynamic Multimodal Activation Steering, a training-free approach for hallucination mitigation. Our method constructs a semantic-based truthfulness steering vector database and computes visual perception steering vectors, enabling context-aware interventions during inference by dynamically selecting the most relevant steering vectors based on input semantic similarity and applying them to the most influential attention heads. We conduct comprehensive experiments across multiple models and datasets, demonstrating that our approach significantly enhances model performance, outperforming existing state-of-the-art methods.","authors":["Jianghao Yin","Qin Chen","Kedi Chen","Jie Zhou","Xingjiao Wu","Liang He"],"pdf_url":"","comment":"Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2511.06899v3","updated":"2026-02-25T08:56:57Z","published":"2025-11-10T09:48:07Z","title":"RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation","summary":"Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have shown impressive performance on various multimodal benchmarks. However, most of these benchmarks evaluate models primarily through multiple-choice or short-answer formats, which do not take the reasoning process into account. Although some benchmarks assess the reasoning process, their methods are often overly simplistic and only examine reasoning when answers are incorrect. This approach overlooks scenarios where flawed reasoning leads to correct answers. In addition, these benchmarks do not consider the impact of intermodal relationships on reasoning. To address this issue, we propose the Reasoning Process Tree Score (RPTS), a tree structure-based metric to assess reasoning processes. Specifically, we organize the reasoning steps into a reasoning tree and leverage its hierarchical information to assign weighted faithfulness scores to each reasoning step. By dynamically adjusting these weights, RPTS not only evaluates the overall correctness of the reasoning, but also pinpoints where the model fails in the reasoning. To validate RPTS in real-world multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374 images and 390 reasoning instances. Each instance includes reliable visual-textual clues that serve as leaf nodes of the reasoning tree. Furthermore, we define three types of intermodal relationships to investigate how intermodal interactions influence the reasoning process. We evaluated representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in multimodal reasoning and highlighting the differences between open-source and closed-source commercial LVLMs. We believe that this benchmark will contribute to the advancement of research in the field of multimodal reasoning.","authors":["Haofeng Wang","Yu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03255v2","updated":"2026-02-25T08:50:49Z","published":"2025-09-26T09:25:16Z","title":"SciTS: Scientific Time Series Understanding and Generation with LLMs","summary":"The scientific reasoning ability of large language models (LLMs) has recently attracted significant attention. Time series, as a fundamental modality in scientific data, presents unique challenges that are often overlooked in current multimodal LLMs, which either encode numerical sequences as text or convert them into images. Such approaches may be insufficient for comprehensive scientific time series understanding and generation. Existing unified time series models typically specialise in either forecasting or analysis, and their effectiveness on non-periodic, heterogeneous scientific signals remains unclear. To address these gaps, we introduce SciTS, a benchmark spanning 12 scientific domains and 43 tasks, with over 50k+ instances, both univariate and multivariate signals ranging from $10^0$ to $10^7$ in length and up to 10~MHz in frequency. We benchmark 17 models, including text-only LLMs, multimodal LLMs, and unified time series models, and find that general-purpose LLMs exhibit stronger generalisability than specialised time series models, while representing time series as text or images limits their performance due to excessively long sequences and loss of numerical precision, respectively. We then introduce TimeOmni, a framework that equips LLMs with the ability to understand and generate time series while remaining compatible with general-purpose LLM training. This work fills a gap in both dedicated benchmarks and modelling frameworks for scientific time series, paving the way for LLMs to understand and generate complex temporal scientific data.","authors":["Wen Wu","Ziyang Zhang","Liwei Liu","Xuenan Xu","Jimin Zhuang","Ke Fan","Qitan Lv","Junlin Liu","Chen Zhang","Zheqi Yuan","Siyuan Hou","Tianyi Lin","Kai Chen","Bowen Zhou","Chao Zhang"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2510.10472v2","updated":"2026-02-25T08:42:24Z","published":"2025-10-12T06:41:05Z","title":"FML-bench: Benchmarking Machine Learning Agents for Scientific Research","summary":"Large language models (LLMs) have sparked growing interest in machine learning research agents that can autonomously propose ideas and conduct experiments. However, existing benchmarks predominantly adopt an engineering-oriented perspective: they emphasize application-oriented tasks and evaluate primarily on final performance and computational cost, overlooking agents' research processes and limiting assessment of their capabilities in scientific research settings. To more comprehensively evaluate agents in scientific research settings, we introduce FML-bench, a benchmark comprising 8 diverse and fundamental ML research tasks, and further propose complementary metrics, notably Exploration Diversity, which quantifies the variance of proposals across iterations and reveals how exploration patterns influence research outcomes. We evaluate state-of-the-art research agents on FML-bench, showing that agents employing broad exploration strategies exhibit higher exploration diversity and achieve superior performance, and that exploration diversity positively correlates with performance improvements across multiple tasks. We hope these findings and our benchmark inform future agent design and support the community in further investigating agent behavior. Our benchmark is available at https://github.com/qrzou/FML-bench.","authors":["Qiran Zou","Hou Hei Lam","Wenhao Zhao","Yiming Tang","Tingting Chen","Samson Yu","Tianyi Zhang","Chang Liu","Xiangyang Ji","Dianbo Liu"],"pdf_url":"","comment":"Our benchmark is available at: https://github.com/qrzou/FML-bench"},{"id":"http://arxiv.org/abs/2502.11684v3","updated":"2026-02-25T08:18:58Z","published":"2025-02-17T11:22:24Z","title":"MathFimer: Enhancing Mathematical Reasoning by Expanding Reasoning Steps through Fill-in-the-Middle Task","summary":"Mathematical reasoning represents a critical frontier in advancing large language models (LLMs). While step-by-step approaches have emerged as the dominant paradigm for mathematical problem-solving in LLMs, the quality of reasoning steps in training data fundamentally constrains the performance of the models. Recent studies have demonstrated that more detailed intermediate steps can enhance model performance, yet existing methods for step expansion either require more powerful external models or incur substantial computational costs. In this paper, we introduce MathFimer, a novel framework for mathematical reasoning step expansion inspired by the ''Fill-in-the-middle'' task from code reasoning. By decomposing solution chains into prefix-suffix pairs and training models to reconstruct missing intermediate steps, we develop a specialized model, MathFimer-7B, on our carefully curated NuminaMath-FIM dataset. We then apply these models to enhance existing mathematical reasoning datasets by inserting detailed intermediate steps into their solution chains, creating MathFimer-expanded versions. Through comprehensive experiments on multiple mathematical reasoning datasets, including MathInstruct, MetaMathQA and etc., we demonstrate that models trained on MathFimer-expanded data consistently outperform their counterparts trained on original data across various benchmarks such as GSM8K and MATH. Our approach offers a practical, scalable solution for enhancing mathematical reasoning capabilities in LLMs without relying on powerful external models or expensive inference procedures.","authors":["Yuchen Yan","Yongliang Shen","Yang Liu","Jin Jiang","Xin Xu","Mengdi Zhang","Jian Shao","Yueting Zhuang"],"pdf_url":"","comment":"ICLR 2026: https://openreview.net/forum?id=14i2wzPPfn"},{"id":"http://arxiv.org/abs/2407.15160v3","updated":"2026-02-25T08:14:26Z","published":"2024-07-21T13:31:02Z","title":"When Can Transformers Count to n?","summary":"Large language models based on the transformer architecture can solve highly complex tasks, yet their fundamental limitations on simple algorithmic problems remain poorly understood. In this work, we focus on basic counting tasks and investigate how the difficulty of these tasks scales with the transformer embedding dimension, the context length, and the vocabulary size. We reveal a sharp theoretical phase transition governed by the relationship between the embedding dimension and the vocabulary size. When the dimension is at least as large as the vocabulary, transformers can perfectly maintain token counts. However, when the vocabulary exceeds the embedding dimension, the interference between non-orthogonal token representations forces the network weights to scale polynomially. This renders the exact counting algorithm numerically unstable and practically unlearnable. We empirically validate this bottleneck by training transformers from scratch, demonstrating a strict performance drop at the theoretical threshold and catastrophic out of distribution failure when scaling the vocabulary or context length. Furthermore, we show that state-of-the-art pretrained models suffer from similar failure cases. Our work reveals a critical blind spot absent from the current literature regarding the connection among these three parameters, proving that vocabulary size fundamentally dictates the difficulty of counting tasks.","authors":["Gilad Yehudai","Haim Kaplan","Guy Dar","Royi Rassin","Asma Ghandeharioun","Mor Geva","Amir Globerson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.18502v2","updated":"2026-02-25T08:12:27Z","published":"2025-05-24T04:43:24Z","title":"Knowledge Fusion of Large Language Models Via Modular SkillPacks","summary":"Cross-capability transfer is a key challenge in large language model (LLM) research, with applications in multi-task integration, model compression, and continual learning. Recent works like FuseLLM and FuseChat have demonstrated the potential of transferring multiple model capabilities to lightweight models, enhancing adaptability and efficiency, which motivates our investigation into more efficient cross-capability transfer methods. However, existing approaches primarily focus on small, homogeneous models, limiting their applicability. For large, heterogeneous models, knowledge distillation with full-parameter fine-tuning often overlooks the student model's intrinsic capacity and risks catastrophic forgetting, while PEFT methods struggle to effectively absorb knowledge from source LLMs. To address these issues, we introduce GraftLLM, a novel method that stores source model capabilities in a target model with SkillPack format. This approach preserves general capabilities, reduces parameter conflicts, and supports forget-free continual learning and model fusion. We employ a module-aware adaptive compression strategy to compress parameter updates, ensuring efficient storage while maintaining task-specific knowledge. The resulting SkillPack serves as a compact and transferable knowledge carrier, ideal for heterogeneous model fusion and continual learning. Experiments across various scenarios demonstrate that GraftLLM outperforms existing techniques in knowledge transfer, knowledge fusion, and forget-free learning, providing a scalable and efficient solution for cross-capability transfer. The code is publicly available at: https://github.com/duguodong7/GraftLLM.","authors":["Guodong Du","Zhuo Li","Xuanning Zhou","Junlin Li","Zesheng Shi","Wanyu Lin","Ho-Kin Tang","Xiucheng Li","Fangming Liu","Wenya Wang","Min Zhang","Jing Li"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.21670v1","updated":"2026-02-25T08:08:26Z","published":"2026-02-25T08:08:26Z","title":"Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning","summary":"Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.","authors":["Tomoya Kawabe","Rin Takano"],"pdf_url":"","comment":"Accepted to ICRA 2026. 8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.12635v2","updated":"2026-02-25T08:07:27Z","published":"2026-02-13T05:41:31Z","title":"Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats","summary":"As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.","authors":["Pengxiang Zhao","Hui-Ling Zhen","Xing Li","Han Bao","Weizhe Lin","Zhiyuan Yang","Ziwei Yu","Xin Wang","Mingxuan Yuan","Xianzhi Yu","Zhenhua Dong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.13920v3","updated":"2026-02-25T08:06:16Z","published":"2026-02-14T23:20:22Z","title":"A Comparative Analysis of Social Network Topology in Reddit and Moltbook","summary":"Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. Despite these developments, empirical comparisons between agent-driven and human-driven social networks remain scarce, limiting our understanding of how their network topologies might diverge. This paper presents the first comparative analysis of network topology on Moltbook, utilizing a comment network comprising 33,577 nodes and 697,688 edges. To provide a benchmark, we curated a parallel dataset from Reddit consisting of 7.8 million nodes and 51.8 million edges. We examine key structural differences between agent-drive and human-drive networks, specifically focusing on topological patterns and the edge formation efficacy of their respective posts. Our findings provide a foundational profile of AI-driven social structures, serving as a preliminary step toward developing more robust and authentic agent-mediated social systems.","authors":["Yiming Zhu","Gareth Tyson","Pan Hui"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.03801v2","updated":"2026-02-25T08:01:08Z","published":"2025-05-02T08:00:48Z","title":"Large Language Model Compression with Global Rank and Sparsity Optimization","summary":"Low-rank and sparse composite approximation is a natural idea to compress Large Language Models (LLMs). However, such an idea faces two primary challenges that adversely affect the performance of existing methods. The first challenge relates to the interaction and cooperation between low-rank and sparse matrices, while the second involves determining weight allocation across different layers, as redundancy varies considerably among them. To address these challenges, we propose a novel two-stage LLM compression method with the capability of global resource allocation for rank and sparsity. It is noteworthy that the overall optimization space is vast, making comprehensive optimization computationally prohibitive. Therefore, to reduce the optimization space, our first stage utilizes robust principal component analysis to decompose the weight matrices of LLMs into low-rank and sparse components, which span the low dimensional and sparse spaces containing the resultant low-rank and sparse matrices, respectively. In the second stage, we propose a probabilistic global allocation strategy to jointly identify the low-rank and sparse structures within the above two spaces. The appealing feature of our approach is its ability to automatically detect the redundancy across different layers and to manage the interaction between the sparse and low-rank components. Extensive experimental results indicate that our method significantly surpasses state-of-the-art techniques for sparsification and composite approximation.","authors":["Changhai Zhou","Qian Qiao","Yuhua Zhou","Yuxin Wu","Shichao Weng","Weizhong Zhang","Cheng Jin"],"pdf_url":"","comment":"33 pages, 5 figures"},{"id":"http://arxiv.org/abs/2503.06692v5","updated":"2026-02-25T07:41:02Z","published":"2025-03-09T16:59:14Z","title":"InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models","summary":"Advanced reasoning in large language models has achieved remarkable performance on challenging tasks, but the prevailing long-context reasoning paradigm faces critical limitations: quadratic computational scaling with sequence length, reasoning constrained by maximum context boundaries, and performance degradation beyond pre-training context windows. Existing approaches primarily compress reasoning chains without addressing the fundamental scaling problem. To overcome these challenges, we introduce InftyThink, a paradigm that transforms monolithic reasoning into an iterative process with intermediate summarization. By interleaving short reasoning segments with concise progress summaries, our approach enables unbounded reasoning depth while maintaining bounded computational costs. This creates a characteristic sawtooth memory pattern that significantly reduces computational complexity compared to traditional approaches. Furthermore, we develop a methodology for reconstructing long-context reasoning datasets into our iterative format, transforming OpenR1-Math into 333K training instances. Experiments across multiple model architectures demonstrate that our approach reduces computational costs while improving performance, with Qwen2.5-Math-7B showing 3-11% improvements across MATH500, AIME24, and GPQA_diamond benchmarks. Our work challenges the assumed trade-off between reasoning depth and computational efficiency, providing a more scalable approach to complex reasoning without architectural modifications.","authors":["Yuchen Yan","Yongliang Shen","Yang Liu","Jin Jiang","Mengdi Zhang","Jian Shao","Yueting Zhuang"],"pdf_url":"","comment":"ICLR 2026: https://openreview.net/forum?id=T1h5em349L Project Page: https://zju-real.github.io/InftyThink Code: https://github.com/ZJU-REAL/InftyThink"},{"id":"http://arxiv.org/abs/2602.21657v1","updated":"2026-02-25T07:35:22Z","published":"2026-02-25T07:35:22Z","title":"Following the Diagnostic Trace: Visual Cognition-guided Cooperative Network for Chest X-Ray Diagnosis","summary":"Computer-aided diagnosis (CAD) has significantly advanced automated chest X-ray diagnosis but remains isolated from clinical workflows and lacks reliable decision support and interpretability. Human-AI collaboration seeks to enhance the reliability of diagnostic models by integrating the behaviors of controllable radiologists. However, the absence of interactive tools seamlessly embedded within diagnostic routines impedes collaboration, while the semantic gap between radiologists' decision-making patterns and model representations further limits clinical adoption. To overcome these limitations, we propose a visual cognition-guided collaborative network (VCC-Net) to achieve the cooperative diagnostic paradigm. VCC-Net centers on visual cognition (VC) and employs clinically compatible interfaces, such as eye-tracking or the mouse, to capture radiologists' visual search traces and attention patterns during diagnosis. VCC-Net employs VC as a spatial cognition guide, learning hierarchical visual search strategies to localize diagnostically key regions. A cognition-graph co-editing module subsequently integrates radiologist VC with model inference to construct a disease-aware graph. The module captures dependencies among anatomical regions and aligns model representations with VC-driven features, mitigating radiologist bias and facilitating complementary, transparent decision-making. Experiments on the public datasets SIIM-ACR, EGD-CXR, and self-constructed TB-Mouse dataset achieved classification accuracies of 88.40%, 85.05%, and 92.41%, respectively. The attention maps produced by VCC-Net exhibit strong concordance with radiologists' gaze distributions, demonstrating a mutual reinforcement of radiologist and model inference. The code is available at https://github.com/IPMI-NWU/VCC-Net.","authors":["Shaoxuan Wu","Jingkun Chen","Chong Ma","Cong Shen","Xiao Zhang","Jun Feng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21655v1","updated":"2026-02-25T07:34:26Z","published":"2026-02-25T07:34:26Z","title":"CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning","summary":"Image captioning remains a fundamental task for vision language understanding, yet ground-truth supervision still relies predominantly on human-annotated references. Because human annotations reflect subjective preferences and expertise, ground-truth captions are often incomplete or even incorrect, which in turn limits caption models. We argue that caption quality should be assessed by two objective aspects: completeness (does the caption cover all salient visual facts?) and correctness (are the descriptions true with respect to the image?). To this end, we introduce CCCaption: a dual-reward reinforcement learning framework with a dedicated fine-tuning corpus that explicitly optimizes these properties to generate \\textbf{C}omplete and \\textbf{C}orrect \\textbf{Captions}. For completeness, we use diverse LVLMs to disentangle the image into a set of visual queries, and reward captions that answer more of these queries, with a dynamic query sampling strategy to improve training efficiency. For correctness, we penalize captions that contain hallucinations by validating the authenticity of sub-caption queries, which are derived from the caption decomposition. Our symmetric dual-reward optimization jointly maximizes completeness and correctness, guiding models toward captions that better satisfy these objective criteria. Extensive experiments across standard captioning benchmarks show consistent improvements, offering a principled path to training caption models beyond human-annotation imitation.","authors":["Zhijiang Tang","Linhua Wang","Jiaxin Qi","Weihao Jiang","Peng Hou","Anxiang Zeng","Jianqiang Huang"],"pdf_url":"","comment":"Accept by CVPR 2026"},{"id":"http://arxiv.org/abs/2602.21652v1","updated":"2026-02-25T07:25:01Z","published":"2026-02-25T07:25:01Z","title":"Sparsity Induction for Accurate Post-Training Pruning of Large Language Models","summary":"Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches.","authors":["Minhao Jiang","Zhikai Li","Xuewen Liu","Jing Zhang","Mengjuan Chen","Qingyi Gu"],"pdf_url":"","comment":"5 pages, 1 figure, 4 tables"},{"id":"http://arxiv.org/abs/2602.21650v1","updated":"2026-02-25T07:23:20Z","published":"2026-02-25T07:23:20Z","title":"PPCR-IM: A System for Multi-layer DAG-based Public Policy Consequence Reasoning and Social Indicator Mapping","summary":"Public policy decisions are typically justified using a narrow set of headline indicators, leaving many downstream social impacts unstructured and difficult to compare across policies. We propose PPCR-IM, a system for multi-layer DAG-based consequence reasoning and social indicator mapping that addresses this gap. Given a policy description and its context, PPCR-IM uses an LLM-driven, layer-wise generator to construct a directed acyclic graph of intermediate consequences, allowing child nodes to have multiple parents to capture joint influences. A mapping module then aligns these nodes to a fixed indicator set and assigns one of three qualitative impact directions: increase, decrease, or ambiguous change. For each policy episode, the system outputs a structured record containing the DAG, indicator mappings, and three evaluation measures: an expected-indicator coverage score, a discovery rate for overlooked but relevant indicators, and a relative focus ratio comparing the systems coverage to that of the government. PPCR-IM is available both as an online demo and as a configurable XLSX-to-JSON batch pipeline.","authors":["Zichen Song","Weijia Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.10402v4","updated":"2026-02-25T07:23:01Z","published":"2026-01-15T13:52:04Z","title":"Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering","summary":"The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE) which is a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI's MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.","authors":["Xinyu Zhu","Yuzhu Cai","Zexi Liu","Bingyang Zheng","Cheng Wang","Rui Ye","Yuzhi Zhang","Linfeng Zhang","Weinan E","Siheng Chen","Yanfeng Wang"],"pdf_url":"","comment":"25 pages. 5 figures"},{"id":"http://arxiv.org/abs/2602.21647v1","updated":"2026-02-25T07:20:23Z","published":"2026-02-25T07:20:23Z","title":"Mitigating Structural Noise in Low-Resource S2TT: An Optimized Cascaded Nepali-English Pipeline with Punctuation Restoration","summary":"This paper presents and evaluates an optimized cascaded Nepali speech-to-English text translation (S2TT) system, focusing on mitigating structural noise introduced by Automatic Speech Recognition (ASR). We first establish highly proficient ASR and NMT components: a Wav2Vec2-XLS-R-300m model achieved a state-of-the-art 2.72% CER on OpenSLR-54, and a multi-stage fine-tuned MarianMT model reached a 28.32 BLEU score on the FLORES-200 benchmark. We empirically investigate the influence of punctuation loss, demonstrating that unpunctuated ASR output significantly degrades translation quality, causing a massive 20.7% relative BLEU drop on the FLORES benchmark. To overcome this, we propose and evaluate an intermediate Punctuation Restoration Module (PRM). The final S2TT pipeline was tested across three configurations on a custom dataset. The optimal configuration, which applied the PRM directly to ASR output, achieved a 4.90 BLEU point gain over the direct ASR-to-NMT baseline (BLEU 36.38 vs. 31.48). This improvement was validated by human assessment, which confirmed the optimized pipeline's superior Adequacy (3.673) and Fluency (3.804). This work validates that targeted punctuation restoration is the most effective intervention for mitigating structural noise in the Nepali S2TT pipeline. It establishes an optimized baseline and demonstrates a critical architectural insight for developing cascaded speech translation systems for similar low-resource languages.","authors":["Tangsang Chongbang","Pranesh Pyara Shrestha","Amrit Sarki","Anku Jaiswal"],"pdf_url":"","comment":"13 pages, 4 figures, 12 tables"},{"id":"http://arxiv.org/abs/2507.14206v2","updated":"2026-02-25T07:17:42Z","published":"2025-07-15T02:54:24Z","title":"A Comprehensive Benchmark for Electrocardiogram Time-Series","summary":"Electrocardiogram~(ECG), a key bioelectrical time-series signal, is crucial for assessing cardiac health and diagnosing various diseases. Given its time-series format, ECG data is often incorporated into pre-training datasets for large-scale time-series model training. However, existing studies often overlook its unique characteristics and specialized downstream applications, which differ significantly from other time-series data, leading to an incomplete understanding of its properties. In this paper, we present an in-depth investigation of ECG signals and establish a comprehensive benchmark, which includes (1) categorizing its downstream applications into four distinct evaluation tasks, (2) identifying limitations in traditional evaluation metrics for ECG analysis, and introducing a novel metric; (3) benchmarking state-of-the-art time-series models and proposing a new architecture. Extensive experiments demonstrate that our proposed benchmark is comprehensive and robust. The results validate the effectiveness of the proposed metric and model architecture, which establish a solid foundation for advancing research in ECG signal analysis.","authors":["Zhijiang Tang","Jiaxin Qi","Yuhua Zheng","Jianqiang Huang"],"pdf_url":"","comment":"ACM MM 2025"},{"id":"http://arxiv.org/abs/2512.09069v2","updated":"2026-02-25T07:03:17Z","published":"2025-12-09T19:34:30Z","title":"KD-OCT: Efficient Knowledge Distillation for Clinical-Grade Retinal OCT Classification","summary":"Age-related macular degeneration (AMD) and choroidal neovascularization (CNV)-related conditions are leading causes of vision loss worldwide, with optical coherence tomography (OCT) serving as a cornerstone for early detection and management. However, deploying state-of-the-art deep learning models like ConvNeXtV2-Large in clinical settings is hindered by their computational demands. Therefore, it is desirable to develop efficient models that maintain high diagnostic performance while enabling real-time deployment. In this study, a novel knowledge distillation framework, termed KD-OCT, is proposed to compress a high-performance ConvNeXtV2-Large teacher model, enhanced with advanced augmentations, stochastic weight averaging, and focal loss, into a lightweight EfficientNet-B2 student for classifying normal, drusen, and CNV cases. KD-OCT employs real-time distillation with a combined loss balancing soft teacher knowledge transfer and hard ground-truth supervision. The effectiveness of the proposed method is evaluated on the Noor Eye Hospital (NEH) dataset using patient-level cross-validation. Experimental results demonstrate that KD-OCT outperforms comparable multi-scale or feature-fusion OCT classifiers in efficiency-accuracy balance, achieving near-teacher performance with substantial reductions in model size and inference time. Despite the compression, the student model exceeds most existing frameworks, facilitating edge deployment for AMD screening. Code is available at https://github.com/erfan-nourbakhsh/KD-OCT.","authors":["Erfan Nourbakhsh","Nasrin Sanjari","Ali Nourbakhsh"],"pdf_url":"","comment":"7 pages, 5 figures (Accepted at ICSPIS 2025)"},{"id":"http://arxiv.org/abs/2602.21633v1","updated":"2026-02-25T06:58:06Z","published":"2026-02-25T06:58:06Z","title":"Self-Correcting VLA: Online Action Refinement via Sparse World Imagination","summary":"Standard vision-language-action (VLA) models rely on fitting statistical data priors, limiting their robust understanding of underlying physical dynamics. Reinforcement learning enhances physical grounding through exploration yet typically relies on external reward signals that remain isolated from the agent's internal states. World action models have emerged as a promising paradigm that integrates imagination and control to enable predictive planning. However, they rely on implicit context modeling, lacking explicit mechanisms for self-improvement. To solve these problems, we propose Self-Correcting VLA (SC-VLA), which achieve self-improvement by intrinsically guiding action refinement through sparse imagination. We first design sparse world imagination by integrating auxiliary predictive heads to forecast current task progress and future trajectory trends, thereby constraining the policy to encode short-term physical evolution. Then we introduce the online action refinement module to reshape progress-dependent dense rewards, adjusting trajectory orientation based on the predicted sparse future states. Evaluations on challenging robot manipulation tasks from simulation benchmarks and real-world settings demonstrate that SC-VLA achieve state-of-the-art performance, yielding the highest task throughput with 16% fewer steps and a 9% higher success rate than the best-performing baselines, alongside a 14% gain in real-world experiments. Code is available at https://github.com/Kisaragi0/SC-VLA.","authors":["Chenyv Liu","Wentao Tan","Lei Zhu","Fengling Li","Jingjing Li","Guoli Yang","Heng Tao Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.16071v2","updated":"2026-02-25T06:50:59Z","published":"2025-10-17T09:01:59Z","title":"MNO: Multiscale Neural Operator for 3D Computational Fluid Dynamics","summary":"Neural operators have emerged as a powerful data-driven paradigm for solving partial differential equations (PDEs), while their accuracy and scalability are still limited, particularly on irregular domains where fluid flows exhibit rich multiscale structures. In this work, we introduce the Multiscale Neural Operator (MNO), a new architecture for computational fluid dynamics (CFD) on 3D unstructured point clouds. MNO explicitly decomposes information across three scales: a global dimension-shrinkage attention module for long-range dependencies, a local graph attention module for neighborhood-level interactions, and a micro point-wise attention module for fine-grained details. This design preserves multiscale inductive biases while remaining computationally efficient. We evaluate MNO on diverse benchmarks, covering steady-state and unsteady flow scenarios with up to 300k points. Across all tasks, MNO consistently outperforms state-of-the-art baselines, reducing prediction errors by 5% to 50%. The results highlight the importance of explicit multiscale design for neural operators and establish MNO as a scalable framework for learning complex fluid dynamics on irregular domains.","authors":["Qinxuan Wang","Chuang Wang","Mingyu Zhang","Jingwei Sun","Peipei Yang","Shuo Tang","Shiming Xiang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05077v2","updated":"2026-02-25T06:48:42Z","published":"2025-10-06T17:49:58Z","title":"Slm-mux: Orchestrating small language models for reasoning","summary":"With the rapid development of language models, the number of small language models (SLMs) has grown significantly. Although they do not achieve state-of-the-art accuracy, they are more efficient and often excel at specific tasks. This raises a natural question: can multiple SLMs be orchestrated into a system where each contributes effectively, achieving higher accuracy than any individual model? Existing orchestration methods have primarily targeted frontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To address this gap, we propose a three-stage approach for orchestrating SLMs. First, we introduce SLM-MUX, a multi-model architecture that effectively coordinates multiple SLMs. Building on this, we develop two optimization strategies: (i) a model selection search that identifies the most complementary SLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our approach delivers strong results: Compared to existing orchestration methods, our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0% on GSM8K. With just two SLMs, SLM-MUX outperforms Qwen 2.5 72B on GPQA and GSM8K, and matches its performance on MATH. We further provide theoretical analyses to substantiate the advantages of our method. Additional experiments show that the core principle of SLM-MUX extends to open-ended generation tasks (e.g., HumanEval) and benefits other model classes, including frontier LLMs and domain-specific fine-tuned SLMs. In summary, we demonstrate that SLMs can be effectively orchestrated into more accurate and efficient systems through the proposed approach. The project page is available at https://slm-mux.github.io/.","authors":["Chenyu Wang","Zishen Wan","Hao Kang","Emma Chen","Zhiqiang Xie","Tushar Krishna","Vijay Janapa Reddi","Yilun Du"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.02137v3","updated":"2026-02-25T06:25:37Z","published":"2026-02-02T14:18:52Z","title":"DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations","summary":"Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence.","authors":["Minghao Li","Ruihang Wang","Rui Tan","Yonggang Wen"],"pdf_url":"","comment":"Accepted as a full paper at HSCC/ICCPS 2026"},{"id":"http://arxiv.org/abs/2502.14183v3","updated":"2026-02-25T06:15:06Z","published":"2025-02-20T01:26:00Z","title":"Glycemic-Aware and Architecture-Agnostic Training Framework for Blood Glucose Forecasting in Type 1 Diabetes","summary":"Managing Type 1 Diabetes (T1D) demands constant vigilance as individuals strive to regulate their blood glucose levels and avoid dysglycemia, including hyperglycemia and hypoglycemia. Despite advances in automated insulin delivery (AID) systems, achieving optimal glycemic control remains challenging. These systems integrate data from wearable devices such as insulin pumps and continuous glucose monitors (CGMs), helping reduce variability and improve time in range. However, they often fail to prevent dysglycemia due to limitations in prediction algorithms that cannot accurately anticipate glycemic excursions. This limitation highlights the need for more advanced glucose forecasting methods. To address this need, we introduce GLIMMER (Glucose Level Indicator Model with Modified Error Rate), a modular and architecture-agnostic training framework for glucose forecasting. GLIMMER combines structured preprocessing, a region-aware loss formulation, and genetic algorithm-based weight optimization to emphasize prediction accuracy in dysglycemic regions. We evaluate GLIMMER using two datasets: the publicly available OhioT1DM dataset and a newly collected AZT1D dataset consisting of data from 25 individuals with T1D. Our analyses demonstrate that GLIMMER consistently improves forecasting performance across baseline architectures, reducing RMSE and MAE by up to 24.6% and 29.6%, respectively. Additionally, GLIMMER achieves a recall of 98.4% and an F1-score of 86.8% for dysglycemia prediction, highlighting strong performance in clinically high-risk regions. Compared with state-of-the-art models containing millions of parameters-such as TimesNet (18.7M), BG-BERT (2.1M), and Gluformer (11.2M)-GLIMMER attains comparable accuracy while using only 10K parameters, demonstrating its efficiency as a lightweight and architecture-agnostic solution for glycemic forecasting.","authors":["Saman Khamesian","Asiful Arefeen","Maria Adela Grando","Bithika M. Thompson","Hassan Ghasemzadeh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21613v1","updated":"2026-02-25T06:14:30Z","published":"2026-02-25T06:14:30Z","title":"Virtual Biopsy for Intracranial Tumors Diagnosis on MRI","summary":"Deep intracranial tumors situated in eloquent brain regions controlling vital functions present critical diagnostic challenges. Clinical practice has shifted toward stereotactic biopsy for pathological confirmation before treatment. Yet biopsy carries inherent risks of hemorrhage and neurological deficits and struggles with sampling bias due to tumor spatial heterogeneity, because pathological changes are typically region-selective rather than tumor-wide. Therefore, advancing non-invasive MRI-based pathology prediction is essential for holistic tumor assessment and modern clinical decision-making.\n  The primary challenge lies in data scarcity: low tumor incidence requires long collection cycles, and annotation demands biopsy-verified pathology from neurosurgical experts. Additionally, tiny lesion volumes lacking segmentation masks cause critical features to be overwhelmed by background noise. To address these challenges, we construct the ICT-MRI dataset - the first public biopsy-verified benchmark with 249 cases across four categories. We propose a Virtual Biopsy framework comprising: MRI-Processor for standardization; Tumor-Localizer employing vision-language models for coarse-to-fine localization via weak supervision; and Adaptive-Diagnoser with a Masked Channel Attention mechanism fusing local discriminative features with global contexts. Experiments demonstrate over 90% accuracy, outperforming baselines by more than 20%.","authors":["Xinzhe Luo","Shuai Shao","Yan Wang","Jiangtao Wang","Yutong Bai","Jianguo Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21611v1","updated":"2026-02-25T06:13:25Z","published":"2026-02-25T06:13:25Z","title":"Structurally Aligned Subtask-Level Memory for Software Engineering Agents","summary":"Large Language Models (LLMs) have demonstrated significant potential as autonomous software engineering (SWE) agents. Recent work has further explored augmenting these agents with memory mechanisms to support long-horizon reasoning. However, these approaches typically operate at a coarse instance granularity, treating the entire problem-solving episode as the atomic unit of storage and retrieval. We empirically demonstrate that instance-level memory suffers from a fundamental granularity mismatch, resulting in misguided retrieval when tasks with similar surface descriptions require distinct reasoning logic at specific stages. To address this, we propose Structurally Aligned Subtask-Level Memory, a method that aligns memory storage, retrieval, and updating with the agent's functional decomposition. Extensive experiments on SWE-bench Verified demonstrate that our method consistently outperforms both vanilla agents and strong instance-level memory baselines across diverse backbones, improving mean Pass@1 over the vanilla agent by +4.7 pp on average (e.g., +6.8 pp on Gemini 2.5 Pro). Performance gains grow with more interaction steps, showing that leveraging past experience benefits long-horizon reasoning in complex software engineering tasks.","authors":["Kangning Shen","Jingyuan Zhang","Chenxi Sun","Wencong Zeng","Yang Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.12415v5","updated":"2026-02-25T05:53:52Z","published":"2026-01-18T13:57:44Z","title":"Orthogonalized Policy Optimization:Policy Optimization as Orthogonal Projection in Hilbert Space","summary":"We propose Orthogonalized Policy Optimization (OPO), a principled framework for large language model alignment derived from optimization in the Hilbert function space L2(pi_k). Lifting policy updates from the probability simplex into L2(pi_k) transforms the nonlinear normalization constraint into a linear orthogonality condition <v, 1>_{pi_k} = 0 on the density fluctuation field v = pi/pi_k - 1. By the Hilbert projection theorem, the unique closed-form update is v_star = (omega_alpha - E[omega_alpha]) / mu, where the subtracted mean acts as a chemical potential enforcing probability conservation. This interpretation reveals advantage z-score normalization as a conservation-law projection rather than a variance-reduction heuristic.\n  OPO cleanly decouples sampling geometry, controlled by the escort exponent alpha, from optimization geometry, governed by the stiffness parameter mu, a separation not attainable under KL-based objectives. The same update can also be derived as a Euclidean mirror-descent step and as the linear-response law of near-equilibrium statistical mechanics, establishing its structural uniqueness within ratio geometry.\n  Structurally, OPO induces constant curvature, non-saturating linear gradient dynamics, and an intrinsic chi-square trust region. Experiments on MATH benchmarks show that the Hilbert projection formulation prevents gradient saturation typical of KL-constrained methods. By sustaining non-vanishing gradients in high-confidence regimes, OPO avoids premature plateaus and achieves stronger long-horizon training rewards and improved out-of-distribution generalization compared to clipping-based baselines.","authors":["Wang Zixian"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.14537v2","updated":"2026-02-25T05:50:24Z","published":"2025-09-18T02:11:34Z","title":"ClearFairy: Capturing Creative Workflows through Decision Structuring, In-Situ Questioning, and Rationale Inference","summary":"Capturing professionals' decision-making in creative workflows (e.g., UI/UX) is essential for reflection, collaboration, and knowledge sharing, yet existing methods often leave rationales incomplete and implicit decisions hidden. To address this, we present the CLEAR approach, which structures reasoning into cognitive decision steps-linked units of actions, artifacts, and explanations making decisions traceable with generative AI. Building on CLEAR, we introduce ClearFairy, a think-aloud AI assistant for UI design that detects weak explanations, asks lightweight clarifying questions, and infers missing rationales. In a study with twelve professionals, 85% of ClearFairy's inferred rationales were accepted (as-is or with revisions). Notably, the system increased \"strong explanations\"-rationales providing sufficient causal reasoning-from 14% to 83% without adding cognitive demand. Furthermore, exploratory applications demonstrate that captured steps can enhance generative AI agents in Figma, yielding predictions better aligned with professionals and producing coherent outcomes. We release a dataset of 417 decision steps to support future research.","authors":["Kihoon Son","DaEun Choi","Tae Soo Kim","Young-Ho Kim","Sangdoo Yun","Juho Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21598v1","updated":"2026-02-25T05:48:15Z","published":"2026-02-25T05:48:15Z","title":"Retrieval Challenges in Low-Resource Public Service Information: A Case Study on Food Pantry Access","summary":"Public service information systems are often fragmented, inconsistently formatted, and outdated. These characteristics create low-resource retrieval environments that hinder timely access to critical services. We investigate retrieval challenges in such settings through the domain of food pantry access, a socially urgent problem given persistent food insecurity. We develop an AI-powered conversational retrieval system that scrapes and indexes publicly available pantry data and employs a Retrieval-Augmented Generation (RAG) pipeline to support natural language queries via a web interface. We conduct a pilot evaluation study using community-sourced queries to examine system behavior in realistic scenarios. Our analysis reveals key limitations in retrieval robustness, handling underspecified queries, and grounding over inconsistent knowledge bases. This ongoing work exposes fundamental IR challenges in low-resource environments and motivates future research on robust conversational retrieval to improve access to critical public resources.","authors":["Touseef Hasan","Laila Cure","Souvika Sarkar"],"pdf_url":"","comment":"3 pages, 1 figure"},{"id":"http://arxiv.org/abs/2602.20223v2","updated":"2026-02-25T05:40:23Z","published":"2026-02-23T13:37:44Z","title":"MultiModalPFN: Extending Prior-Data Fitted Networks for Multimodal Tabular Learning","summary":"Recently, TabPFN has gained attention as a foundation model for tabular data. However, it struggles to integrate heterogeneous modalities such as images and text, which are common in domains like healthcare and marketing, thereby limiting its applicability. To address this, we present the Multi-Modal Prior-data Fitted Network (MMPFN), which extends TabPFN to handle tabular and non-tabular modalities in a unified manner. MMPFN comprises per-modality encoders, modality projectors, and pre-trained foundation models. The modality projectors serve as the critical bridge, transforming non-tabular embeddings into tabular-compatible tokens for unified processing. To this end, we introduce a multi-head gated MLP and a cross-attention pooler that extract richer context from non-tabular inputs while mitigates attention imbalance issue in multimodal learning. Extensive experiments on medical and general-purpose multimodal datasets demonstrate that MMPFN consistently outperforms competitive state-of-the-art methods and effectively exploits non-tabular modalities alongside tabular features. These results highlight the promise of extending prior-data fitted networks to the multimodal setting, offering a scalable and effective framework for heterogeneous data learning. The source code is available at https://github.com/too-z/MultiModalPFN.","authors":["Wall Kim","Chaeyoung Song","Hanul Kim"],"pdf_url":"","comment":"Accepted to CVPR 2026"},{"id":"http://arxiv.org/abs/2509.23597v3","updated":"2026-02-25T05:33:12Z","published":"2025-09-28T03:06:30Z","title":"Characteristic Root Analysis and Regularization for Linear Time Series Forecasting","summary":"Time series forecasting remains a critical challenge across numerous domains, yet the effectiveness of complex models often varies unpredictably across datasets. Recent studies highlight the surprising competitiveness of simple linear models, suggesting that their robustness and interpretability warrant deeper theoretical investigation. This paper presents a systematic study of linear models for time series forecasting, with a focus on the role of characteristic roots in temporal dynamics. We begin by analyzing the noise-free setting, where we show that characteristic roots govern long-term behavior and explain how design choices such as instance normalization and channel independence affect model capabilities. We then extend our analysis to the noisy regime, revealing that models tend to produce spurious roots. This leads to the identification of a key data-scaling property: mitigating the influence of noise requires disproportionately large training data, highlighting the need for structural regularization. To address these challenges, we propose two complementary strategies for robust root restructuring. The first uses rank reduction techniques, including \\textbf{Reduced-Rank Regression (RRR)} and \\textbf{Direct Weight Rank Reduction (DWRR)}, to recover the low-dimensional latent dynamics. The second, a novel adaptive method called \\textbf{Root Purge}, encourages the model to learn a noise-suppressing null space during training. Extensive experiments on standard benchmarks demonstrate the effectiveness of both approaches, validating our theoretical insights and achieving state-of-the-art results in several settings. Our findings underscore the potential of integrating classical theories for linear systems with modern learning techniques to build robust, interpretable, and data-efficient forecasting models.","authors":["Zheng Wang","Kaixuan Zhang","Wanfang Chen","Xiaonan Lu","Longyuan Li","Tobias Schlagenhauf"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21584v1","updated":"2026-02-25T05:15:58Z","published":"2026-02-25T05:15:58Z","title":"Exploring Human-Machine Coexistence in Symmetrical Reality","summary":"In the context of the evolution of artificial intelligence (AI), the interaction between humans and AI entities has become increasingly salient, challenging the conventional human-centric paradigms of human-machine interaction. To address this challenge, it is imperative to reassess the relationship between AI entities and humans. Through considering both the virtual and physical worlds, we can construct a novel descriptive framework for a world where humans and machines coexist symbiotically. This paper will introduce a fresh research direction engendered for studying harmonious human-machine coexistence across physical and virtual worlds, which has been termed \"symmetrical reality\". We will elucidate its key characteristics, offering innovative research insight for renovating human-machine interaction paradigms.","authors":["Zhenliang Zhang"],"pdf_url":"","comment":"IEEE Virtual Reality 2026 Poster"},{"id":"http://arxiv.org/abs/2509.25184v2","updated":"2026-02-25T05:03:23Z","published":"2025-09-29T17:59:42Z","title":"Incentive-Aligned Multi-Source LLM Summaries","summary":"Large language models (LLMs) are increasingly used in modern search and answer systems to synthesize multiple, sometimes conflicting, texts into a single response, yet current pipelines offer weak incentives for sources to be accurate and are vulnerable to adversarial content. We introduce Truthful Text Summarization (TTS), an incentive-aligned framework that improves factual robustness without ground-truth labels. TTS (i) decomposes a draft synthesis into atomic claims, (ii) elicits each source's stance on every claim, (iii) scores sources with an adapted multi-task peer-prediction mechanism that rewards informative agreement, and (iv) filters unreliable sources before re-summarizing. We establish formal guarantees that align a source's incentives with informative honesty, making truthful reporting the utility-maximizing strategy. Experiments show that TTS improves factual accuracy and robustness while preserving fluency, aligning exposure with informative corroboration and disincentivizing manipulation.","authors":["Yanchen Jiang","Zhe Feng","Aranyak Mehta"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2508.08337v2","updated":"2026-02-25T05:02:02Z","published":"2025-08-10T23:55:16Z","title":"Position: Beyond Sensitive Attributes, ML Fairness Should Quantify Structural Injustice via Social Determinants","summary":"Algorithmic fairness research has largely framed unfairness as discrimination along sensitive attributes. However, this approach limits visibility into unfairness as structural injustice instantiated through social determinants, which are contextual variables that shape attributes and outcomes without pertaining to specific individuals. This position paper argues that the field should quantify structural injustice via social determinants, beyond sensitive attributes. Drawing on cross-disciplinary insights, we argue that prevailing technical paradigms fail to adequately capture unfairness as structural injustice, because contexts are potentially treated as noise to be normalized rather than signal to be audited. We further demonstrate the practical urgency of this shift through a theoretical model of college admissions, a demographic study using U.S. census data, and a high-stakes domain application regarding breast cancer screening within an integrated U.S. healthcare system. Our results indicate that mitigation strategies centered solely on sensitive attributes can introduce new forms of structural injustice. We contend that auditing structural injustice through social determinants must precede mitigation, and call for new technical developments that move beyond sensitive-attribute-centered notions of fairness as non-discrimination.","authors":["Zeyu Tang","Alex John London","Atoosa Kasirzadeh","Sarah Stewart de Ramirez","Peter Spirtes","Kun Zhang","Sanmi Koyejo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.12304v2","updated":"2026-02-25T04:58:18Z","published":"2026-02-12T03:25:41Z","title":"OmniCustom: Sync Audio-Video Customization Via Joint Audio-Video Generation Model","summary":"Existing mainstream video customization methods focus on generating identity-consistent videos based on given reference images and textual prompts. Benefiting from the rapid advancement of joint audio-video generation, this paper proposes a more compelling new task: sync audio-video customization, which aims to synchronously customize both video identity and audio timbre. Specifically, given a reference image $I^{r}$ and a reference audio $A^{r}$, this novel task requires generating videos that maintain the identity of the reference image while imitating the timbre of the reference audio, with spoken content freely specifiable through user-provided textual prompts. To this end, we propose OmniCustom, a powerful DiT-based audio-video customization framework that can synthesize a video following reference image identity, audio timbre, and text prompts all at once in a zero-shot manner. Our framework is built on three key contributions. First, identity and audio timbre control are achieved through separate reference identity and audio LoRA modules that operate through self-attention layers within the base audio-video generation model. Second, we introduce a contrastive learning objective alongside the standard flow matching objective. It uses predicted flows conditioned on reference inputs as positive examples and those without reference conditions as negative examples, thereby enhancing the model ability to preserve identity and timbre. Third, we train OmniCustom on our constructed large-scale, high-quality audio-visual human dataset. Extensive experiments demonstrate that OmniCustom outperforms existing methods in generating audio-video content with consistent identity and timbre fidelity. Project page: https://omnicustom-project.github.io/page/.","authors":["Maomao Li","Zhen Li","Kaipeng Zhang","Guosheng Yin","Zhifeng Li","Dong Xu"],"pdf_url":"","comment":"code: https://github.com/OmniCustom-project/OmniCustom"},{"id":"http://arxiv.org/abs/2602.13769v2","updated":"2026-02-25T04:51:55Z","published":"2026-02-14T13:32:03Z","title":"OR-Agent: Bridging Evolutionary Search and Structured Research for Automated Algorithm Discovery","summary":"Automating scientific discovery in complex, experiment-driven domains requires more than iterative mutation of programs; it demands structured hypothesis management, environment interaction, and principled reflection. We present OR-Agent, a configurable multi-agent research framework designed for automated exploration in rich experimental environments. OR-Agent organizes research as a structured tree-based workflow that explicitly models branching hypothesis generation and systematic backtracking, enabling controlled management of research trajectories beyond simple mutation-crossover loops. At its core, we introduce an evolutionary-systematic ideation mechanism that unifies evolutionary selection of research starting points, comprehensive research plan generation, and coordinated exploration within a research tree. We introduce a hierarchical optimization-inspired reflection system in which short-term reflections act as verbal gradients, long-term reflections as verbal momentum, and memory compression as semantic weight decay, collectively forming a principled mechanism for governing research dynamics. We conduct extensive experiments across classical combinatorial optimization benchmarks as well as simulation-based cooperative driving scenarios. Results demonstrate that OR-Agent outperforms strong evolutionary baselines while providing a general, extensible, and inspectable framework for AI-assisted scientific discovery. All code and experimental data are publicly available at https://github.com/qiliuchn/OR-Agent.","authors":["Qi Liu","Ruochen Hao","Can Li","Wanjing Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.13529v2","updated":"2026-02-25T04:42:28Z","published":"2025-05-18T07:27:34Z","title":"BARREL: Boundary-Aware Reasoning for Factual and Reliable LRMs","summary":"Recent advances in Large Reasoning Models (LRMs) have shown impressive capabilities in mathematical and logical reasoning. However, current LRMs rarely admit ignorance or respond with \"I don't know\". Instead, they often produce incorrect answers while showing undue confidence, raising concerns about their factual reliability. In this work, we identify two pathological reasoning patterns characterized by overthinking that contribute to the overconfident and incorrect answers: last-minute guessing and second-thought spiraling. To address these issues, we propose BARREL-a novel framework that promotes concise and boundary-aware factual reasoning. Our experiments show that BARREL-training increases the reliability of DeepSeek-R1-Distill-Llama-8B from 39.33% to 61.48%, while still achieving accuracy comparable to models finetuned on reasoning data generated by R1. These results demonstrate that our pilot study is inspiring to build more reliable and factual System 2 LRMs.","authors":["Junxiao Yang","Jinzhe Tu","Haoran Liu","Xiaoce Wang","Chujie Zheng","Zhexin Zhang","Shiyao Cui","Caishun Chen","Tiantian He","Hongning Wang","Yew-Soon Ong","Minlie Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21556v1","updated":"2026-02-25T04:23:50Z","published":"2026-02-25T04:23:50Z","title":"Power and Limitations of Aggregation in Compound AI Systems","summary":"When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework models how the system designer can partially steer each agent's output through its reward function specification, but still faces limitations due to prompt engineering ability and model capabilities. Our analysis uncovers three natural mechanisms -- feasibility expansion, support expansion, and binding set contraction -- through which aggregation expands the set of outputs that are elicitable by the system designer. We prove that any aggregation operation must implement one of these mechanisms in order to be elicitability-expanding, and that strengthened versions of these mechanisms provide necessary and sufficient conditions that fully characterize elicitability-expansion. Finally, we provide an empirical illustration of our findings for LLMs deployed in a toy reference-generation task. Altogether, our results take a step towards characterizing when compound AI systems can overcome limitations in model capabilities and in prompt engineering.","authors":["Nivasini Ananthakrishnan","Meena Jagadeesan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21553v1","updated":"2026-02-25T04:19:06Z","published":"2026-02-25T04:19:06Z","title":"Revisiting RAG Retrievers: An Information Theoretic Benchmark","summary":"Retrieval-Augmented Generation (RAG) systems rely critically on the retriever module to surface relevant context for large language models. Although numerous retrievers have recently been proposed, each built on different ranking principles such as lexical matching, dense embeddings, or graph citations, there remains a lack of systematic understanding of how these mechanisms differ and overlap. Existing benchmarks primarily compare entire RAG pipelines or introduce new datasets, providing little guidance on selecting or combining retrievers themselves. Those that do compare retrievers directly use a limited set of evaluation tools which fail to capture complementary and overlapping strengths. This work presents MIGRASCOPE, a Mutual Information based RAG Retriever Analysis Scope. We revisit state-of-the-art retrievers and introduce principled metrics grounded in information and statistical estimation theory to quantify retrieval quality, redundancy, synergy, and marginal contribution. We further show that if chosen carefully, an ensemble of retrievers outperforms any single retriever. We leverage the developed tools over major RAG corpora to provide unique insights on contribution levels of the state-of-the-art retrievers. Our findings provide a fresh perspective on the structure of modern retrieval techniques and actionable guidance for designing robust and efficient RAG systems.","authors":["Wenqing Zheng","Dmitri Kalaev","Noah Fatsi","Daniel Barcklow","Owen Reinert","Igor Melnyk","Senthil Kumar","C. Bayan Bruss"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21551v1","updated":"2026-02-25T04:16:44Z","published":"2026-02-25T04:16:44Z","title":"From Basis to Basis: Gaussian Particle Representation for Interpretable PDE Operators","summary":"Learning PDE dynamics for fluids increasingly relies on neural operators and Transformer-based models, yet these approaches often lack interpretability and struggle with localized, high-frequency structures while incurring quadratic cost in spatial samples. We propose representing fields with a Gaussian basis, where learned atoms carry explicit geometry (centers, anisotropic scales, weights) and form a compact, mesh-agnostic, directly visualizable state. Building on this representation, we introduce a Gaussian Particle Operator that acts in modal space: learned Gaussian modal windows perform a Petrov-Galerkin measurement, and PG Gaussian Attention enables global cross-scale coupling. This basis-to-basis design is resolution-agnostic and achieves near-linear complexity in N for a fixed modal budget, supporting irregular geometries and seamless 2D-to-3D extension. On standard PDE benchmarks and real datasets, our method attains state-of-the-art competitive accuracy while providing intrinsic interpretability.","authors":["Zhihao Li","Yu Feng","Zhilu Lai","Wei Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.17691v2","updated":"2026-02-25T04:00:38Z","published":"2025-07-23T16:57:32Z","title":"CASCADE: LLM-Powered JavaScript Deobfuscator at Google","summary":"Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.","authors":["Shan Jiang","Pranoy Kovuri","David Tao","Zhixun Tan"],"pdf_url":"","comment":"To appear in ICSE-SEIP 2026"},{"id":"http://arxiv.org/abs/2510.26784v3","updated":"2026-02-25T03:58:41Z","published":"2025-10-30T17:57:17Z","title":"LLMs Process Lists With General Filter Heads","summary":"We investigate the mechanisms underlying a range of list-processing tasks in LLMs, and we find that LLMs have learned to encode a compact, causal representation of a general filtering operation that mirrors the generic \"filter\" function of functional programming. Using causal mediation analysis on a diverse set of list-processing tasks, we find that a small number of attention heads, which we dub filter heads, encode a compact representation of the filtering predicate in their query states at certain tokens. We demonstrate that this predicate representation is general and portable: it can be extracted and reapplied to execute the same filtering operation on different collections, presented in different formats, languages, or even in tasks. However, we also identify situations where transformer LMs can exploit a different strategy for filtering: eagerly evaluating if an item satisfies the predicate and storing this intermediate result as a flag directly in the item representations. Our results reveal that transformer LMs can develop human-interpretable implementations of abstract computational operations that generalize in ways that are surprisingly similar to strategies used in traditional functional programming patterns.","authors":["Arnab Sen Sharma","Giordano Rogers","Natalie Shapira","David Bau"],"pdf_url":"","comment":"Code and data at https://filter.baulab.info/"},{"id":"http://arxiv.org/abs/2602.21543v1","updated":"2026-02-25T03:58:24Z","published":"2026-02-25T03:58:24Z","title":"Enhancing Multilingual Embeddings via Multi-Way Parallel Text Alignment","summary":"Multilingual pretraining typically lacks explicit alignment signals, leading to suboptimal cross-lingual alignment in the representation space. In this work, we show that training standard pretrained models for cross-lingual alignment with a multi-way parallel corpus in a diverse pool of languages can substantially improve multilingual and cross-lingual representations for NLU tasks. We construct a multi-way parallel dataset using translations of English text from an off-the-shelf NMT model for a pool of six target languages and achieve strong cross-lingual alignment through contrastive learning. This leads to substantial performance gains across both seen and unseen languages for multiple tasks from the MTEB benchmark evaluated for XLM-Roberta and multilingual BERT base models. Using a multi-way parallel corpus for contrastive training yields substantial gains on bitext mining (21.3%), semantic similarity (5.3%), and classification (28.4%) compared to English-centric (En-X) bilingually parallel data, where X is sampled from a pool of multiple target languages. Furthermore, finetuning mE5 model on a small dataset with multi-way parallelism significantly improves bitext mining compared to one without, underscoring the importance of multi-way cross-lingual supervision even for models already pretrained for high-quality sentence embeddings.","authors":["Barah Fazili","Koustava Goswami"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2310.17167v2","updated":"2026-02-25T03:52:43Z","published":"2023-10-26T05:43:07Z","title":"Improving Denoising Diffusion Models via Simultaneous Estimation of Image and Noise","summary":"This paper introduces two key contributions aimed at improving the speed and quality of images generated through inverse diffusion processes. The first contribution involves reparameterizing the diffusion process in terms of the angle on a quarter-circular arc between the image and noise, specifically setting the conventional $\\displaystyle \\sqrt{\\barα}=\\cos(η)$. This reparameterization eliminates two singularities and allows for the expression of diffusion evolution as a well-behaved ordinary differential equation (ODE). In turn, this allows higher order ODE solvers such as Runge-Kutta methods to be used effectively. The second contribution is to directly estimate both the image ($\\mathbf{x}_0$) and noise ($\\mathbfε$) using our network, which enables more stable calculations of the update step in the inverse diffusion steps, as accurate estimation of both the image and noise are crucial at different stages of the process. Together with these changes, our model achieves faster generation, with the ability to converge on high-quality images more quickly, and higher quality of the generated images, as measured by metrics such as Frechet Inception Distance (FID), spatial Frechet Inception Distance (sFID), precision, and recall.","authors":["Zhenkai Zhang","Krista A. Ehinger","Tom Drummond"],"pdf_url":"","comment":"Published in Proceedings of the 15th Asian Conference on Machine Learning, PMLR 222:1638-1653, 2024"},{"id":"http://arxiv.org/abs/2602.14697v3","updated":"2026-02-25T03:50:21Z","published":"2026-02-16T12:34:27Z","title":"Evolutionary System Prompt Learning for Reinforcement Learning in LLMs","summary":"Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this work, we propose Evolutionary System Prompt Learning (E-SPL), a method for jointly improving model contexts and model weights. In each RL iteration, E-SPL samples trajectories under multiple system prompts in parallel, then jointly applies RL updates to LLM weights and evolutionary updates to system prompts. System prompts evolve via mutation and crossover, two genetic operators driven by LLM self-reflection; selection is based on relative performance ratings updated across RL iterations. E-SPL encourages a natural division between declarative knowledge encoded in prompts and procedural knowledge encoded in weights, resulting in improved performance across reasoning and agentic tasks. For instance, in an easy-to-hard (AIME $\\rightarrow$ BeyondAIME) generalization setting, E-SPL improves RL success rate from 38.8% $\\rightarrow$ 45.1% while also outperforming reflective prompt evolution (40.0%). Overall, our results demonstrate that RL and system prompt evolution are deeply synergistic, and combining the two yields consistent gains in sample efficiency and generalization. Code: https://github.com/LunjunZhang/E-SPL","authors":["Lunjun Zhang","Ryan Chen","Bradly C. Stadie"],"pdf_url":"","comment":"39 pages, 22 figures"},{"id":"http://arxiv.org/abs/2602.17484v2","updated":"2026-02-25T03:43:48Z","published":"2026-02-19T15:54:55Z","title":"Tracing Copied Pixels and Regularizing Patch Affinity in Copy Detection","summary":"Image Copy Detection (ICD) aims to identify manipulated content between image pairs through robust feature representation learning. While self-supervised learning (SSL) has advanced ICD systems, existing view-level contrastive methods struggle with sophisticated edits due to insufficient fine-grained correspondence learning. We address this limitation by exploiting the inherent geometric traceability in edited content through two key innovations. First, we propose PixTrace - a pixel coordinate tracking module that maintains explicit spatial mappings across editing transformations. Second, we introduce CopyNCE, a geometrically-guided contrastive loss that regularizes patch affinity using overlap ratios derived from PixTrace's verified mappings. Our method bridges pixel-level traceability with patch-level similarity learning, suppressing supervision noise in SSL training. Extensive experiments demonstrate not only state-of-the-art performance (88.7% uAP / 83.9% RP90 for matcher, 72.6% uAP / 68.4% RP90 for descriptor on DISC21 dataset) but also better interpretability over existing methods.","authors":["Yichen Lu","Siwei Nie","Minlong Lu","Xudong Yang","Xiaobo Zhang","Peng Zhang"],"pdf_url":"","comment":"Accepted by ICCV2025 Github: https://github.com/eddielyc/CopyNCE"},{"id":"http://arxiv.org/abs/2602.21534v1","updated":"2026-02-25T03:43:34Z","published":"2026-02-25T03:43:34Z","title":"ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning","summary":"Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.","authors":["Xiaoxuan Wang","Han Zhang","Haixin Wang","Yidan Shi","Ruoyan Li","Kaiqiao Han","Chenyi Tong","Haoran Deng","Renliang Sun","Alexander Taylor","Yanqiao Zhu","Jason Cong","Yizhou Sun","Wei Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.06060v2","updated":"2026-02-25T03:33:50Z","published":"2025-06-06T13:13:29Z","title":"Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models","summary":"Federated large language models (FedLLMs) enable cross-silo collaborative training among institutions while preserving data locality, making them appealing for privacy-sensitive domains such as law, finance, and healthcare. However, the memorization behavior of LLMs can lead to privacy risks that may cause cross-client data leakage. In this work, we study the threat of cross-client data extraction, where a semi-honest participant attempts to recover personally identifiable information (PII) memorized from other clients' data. We propose three simple yet effective extraction strategies that leverage contextual prefixes from the attacker's local data, including frequency-based prefix sampling and local fine-tuning to amplify memorization. To evaluate these attacks, we construct a Chinese legal-domain dataset with fine-grained PII annotations consistent with CPIS, GDPR, and CCPA standards, and assess extraction performance using two metrics: coverage and efficiency. Experimental results show that our methods can recover up to 56.6% of victim-exclusive PII, where names, addresses, and birthdays are particularly vulnerable. These findings highlight concrete privacy risks in FedLLMs and establish a benchmark and evaluation framework for future research on privacy-preserving federated learning. Code and data are available at https://github.com/SMILELab-FL/FedPII.","authors":["Yingqi Hu","Zhuo Zhang","Jingyuan Zhang","Jinghua Wang","Qifan Wang","Lizhen Qu","Zenglin Xu"],"pdf_url":"","comment":"IJCNLP 2025 Findings"},{"id":"http://arxiv.org/abs/2602.21531v1","updated":"2026-02-25T03:33:39Z","published":"2026-02-25T03:33:39Z","title":"LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies","summary":"General-purpose robots must master long-horizon manipulation, defined as tasks involving multiple kinematic structure changes (e.g., attaching or detaching objects) in unstructured environments. While Vision-Language-Action (VLA) models offer the potential to master diverse atomic skills, they struggle with the combinatorial complexity of sequencing them and are prone to cascading failures due to environmental sensitivity. To address these challenges, we propose LiLo-VLA (Linked Local VLA), a modular framework capable of zero-shot generalization to novel long-horizon tasks without ever being trained on them. Our approach decouples transport from interaction: a Reaching Module handles global motion, while an Interaction Module employs an object-centric VLA to process isolated objects of interest, ensuring robustness against irrelevant visual features and invariance to spatial configurations. Crucially, this modularity facilitates robust failure recovery through dynamic replanning and skill reuse, effectively mitigating the cascading errors common in end-to-end approaches. We introduce a 21-task simulation benchmark consisting of two challenging suites: LIBERO-Long++ and Ultra-Long. In these simulations, LiLo-VLA achieves a 69% average success rate, outperforming Pi0.5 by 41% and OpenVLA-OFT by 67%. Furthermore, real-world evaluations across 8 long-horizon tasks demonstrate an average success rate of 85%. Project page: https://yy-gx.github.io/LiLo-VLA/.","authors":["Yue Yang","Shuo Cheng","Yu Fang","Homanga Bharadhwaj","Mingyu Ding","Gedas Bertasius","Daniel Szafir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.21112v5","updated":"2026-02-25T03:30:53Z","published":"2025-08-28T17:26:15Z","title":"EO-1: An Open Unified Embodied Foundation Model for General Robot Control","summary":"The human ability to seamlessly perform multimodal reasoning and physical interaction in the open world is a core goal for general purpose embodied intelligent systems. Recent vision-language-action (VLA) models, which are co-trained on large-scale robot and visual-text data, have demonstrated notable progress in general robot control. However, they still fail to achieve human-level flexibility in interleaved reasoning and interaction. In this work, we introduce EO-Robotics, consists of EO-1 model and EO-Data1.5M dataset. EO-1 is a unified embodied foundation model that achieves superior performance in multimodal embodied reasoning and robot control through interleaved vision-text-action pre-training. The development of EO-1 is based on two key pillars: (i) a unified architecture that processes multimodal inputs indiscriminately (image, text, video, and action), and (ii) a massive, high-quality multimodal embodied reasoning dataset, EO-Data1.5M, which contains over 1.5 million samples with emphasis on interleaved vision-text-action comprehension. EO-1 is trained through synergies between auto-regressive decoding and flow matching denoising on EO-Data1.5M, enabling seamless robot action generation and multimodal embodied reasoning. Extensive experiments demonstrate the effectiveness of interleaved vision-text-action learning for open-world understanding and generalization, validated through a variety of long-horizon, dexterous manipulation tasks across multiple embodiments. This paper details the architecture of EO-1, the data construction strategy of EO-Data1.5M, and the training methodology, offering valuable insights for developing advanced embodied foundation models. Project Page: https://eo-robotics.ai/eo-1.","authors":["Delin Qu","Haoming Song","Qizhi Chen","Zhaoqing Chen","Xianqiang Gao","Dong Wang","Xinyi Ye","Qi Lv","Modi Shi","Guanghui Ren","Cheng Ruan","Maoqing Yao","Haoran Yang","Jiacheng Bao","Bin Zhao","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18316v4","updated":"2026-02-25T03:29:42Z","published":"2025-10-21T05:56:47Z","title":"MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation","summary":"Imitation learning from large-scale, diverse human demonstrations has been shown to be effective for training robots, but collecting such data is costly and time-consuming. This challenge intensifies for multi-step bimanual mobile manipulation, where humans must teleoperate both the mobile base and two high-DoF arms. Prior X-Gen works have developed automated data generation frameworks for static (bimanual) manipulation tasks, augmenting a few human demos in simulation with novel scene configurations to synthesize large-scale datasets. However, prior works fall short for bimanual mobile manipulation tasks for two major reasons: 1) a mobile base introduces the problem of how to place the robot base to enable downstream manipulation (reachability) and 2) an active camera introduces the problem of how to position the camera to generate data for a visuomotor policy (visibility). To address these challenges, MoMaGen formulates data generation as a constrained optimization problem that satisfies hard constraints (e.g., reachability) while balancing soft constraints (e.g., visibility while navigation). This formulation generalizes across most existing automated data generation approaches and offers a principled foundation for developing future methods. We evaluate on four multi-step bimanual mobile manipulation tasks and find that MoMaGen enables the generation of much more diverse datasets than previous methods. As a result of the dataset diversity, we also show that the data generated by MoMaGen can be used to train successful imitation learning policies using a single source demo. Furthermore, the trained policy can be fine-tuned with a very small amount of real-world data (40 demos) to be succesfully deployed on real robotic hardware. More details are on our project page: momagen.github.io.","authors":["Chengshu Li","Mengdi Xu","Arpit Bahety","Hang Yin","Yunfan Jiang","Huang Huang","Josiah Wong","Sujay Garlanka","Cem Gokmen","Ruohan Zhang","Weiyu Liu","Jiajun Wu","Roberto Martín-Martín","Li Fei-Fei"],"pdf_url":"","comment":"Project website: momagen.github.io. The first four authors contribute equally. Accpeted to International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2602.21522v1","updated":"2026-02-25T03:24:54Z","published":"2026-02-25T03:24:54Z","title":"One Brain, Omni Modalities: Towards Unified Non-Invasive Brain Decoding with Large Language Models","summary":"Deciphering brain function through non-invasive recordings requires synthesizing complementary high-frequency electromagnetic (EEG/MEG) and low-frequency metabolic (fMRI) signals. However, despite their shared neural origins, extreme discrepancies have traditionally confined these modalities to isolated analysis pipelines, hindering a holistic interpretation of brain activity. To bridge this fragmentation, we introduce \\textbf{NOBEL}, a \\textbf{n}euro-\\textbf{o}mni-modal \\textbf{b}rain-\\textbf{e}ncoding \\textbf{l}arge language model (LLM) that unifies these heterogeneous signals within the LLM's semantic embedding space. Our architecture integrates a unified encoder for EEG and MEG with a novel dual-path strategy for fMRI, aligning non-invasive brain signals and external sensory stimuli into a shared token space, then leverages an LLM as a universal backbone. Extensive evaluations demonstrate that NOBEL serves as a robust generalist across standard single-modal tasks. We also show that the synergistic fusion of electromagnetic and metabolic signals yields higher decoding accuracy than unimodal baselines, validating the complementary nature of multiple neural modalities. Furthermore, NOBEL exhibits strong capabilities in stimulus-aware decoding, effectively interpreting visual semantics from multi-subject fMRI data on the NSD and HAD datasets while uniquely leveraging direct stimulus inputs to verify causal links between sensory signals and neural responses. NOBEL thus takes a step towards unifying non-invasive brain decoding, demonstrating the promising potential of omni-modal brain understanding.","authors":["Changli Tang","Shurui Li","Junliang Wang","Qinfan Xiao","Zhonghao Zhai","Lei Bai","Yu Qiao","Bowen Zhou","Wen Wu","Yuanning Li","Chao Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21515v1","updated":"2026-02-25T03:06:59Z","published":"2026-02-25T03:06:59Z","title":"Training Generalizable Collaborative Agents via Strategic Risk Aversion","summary":"Many emerging agentic paradigms require agents to collaborate with one another (or people) to achieve shared goals. Unfortunately, existing approaches to learning policies for such collaborative problems produce brittle solutions that fail when paired with new partners. We attribute these failures to a combination of free-riding during training and a lack of strategic robustness. To address these problems, we study the concept of strategic risk aversion and interpret it as a principled inductive bias for generalizable cooperation with unseen partners. While strategically risk-averse players are robust to deviations in their partner's behavior by design, we show that, in collaborative games, they also (1) can have better equilibrium outcomes than those at classical game-theoretic concepts like Nash, and (2) exhibit less or no free-riding. Inspired by these insights, we develop a multi-agent reinforcement learning (MARL) algorithm that integrates strategic risk aversion into standard policy optimization methods. Our empirical results across collaborative benchmarks (including an LLM collaboration task) validate our theory and demonstrate that our approach consistently achieves reliable collaboration with heterogeneous and previously unseen partners across collaborative tasks.","authors":["Chengrui Qu","Yizhou Zhang","Nicholas Lanzetti","Eric Mazumdar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.07667v3","updated":"2026-02-25T03:04:29Z","published":"2025-08-11T06:34:09Z","title":"1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning","summary":"Addressing contextual privacy concerns remains challenging in interactive settings where large language models (LLMs) process information from multiple sources (e.g., summarizing meetings with private and public information). We introduce a multi-agent framework that decomposes privacy reasoning into specialized subtasks (extraction, classification), reducing the information load on any single agent while enabling iterative validation and more reliable adherence to contextual privacy norms. To understand how privacy errors emerge and propagate, we conduct a systematic ablation over information-flow topologies, revealing when and why upstream detection mistakes cascade into downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with several open-source and closed-sourced LLMs demonstrate that our best multi-agent configuration substantially reduces private information leakage (\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while preserving the fidelity of public content, outperforming single-agent baselines. These results highlight the promise of principled information-flow design in multi-agent systems for contextual privacy with LLMs.","authors":["Wenkai Li","Liwen Sun","Zhenxiang Guan","Xuhui Zhou","Maarten Sap"],"pdf_url":"","comment":"Accepted at the International Association for AI Safety and Ethics AI (IASEAI) 2026"},{"id":"http://arxiv.org/abs/2509.01350v3","updated":"2026-02-25T03:03:25Z","published":"2025-09-01T10:39:37Z","title":"Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models","summary":"Effective specification-aware part retrieval within complex CAD assemblies is essential for automated engineering tasks. However, using LLMs/VLMs for this task is challenging: the CAD model metadata sequences often exceed token budgets, and fine-tuning high-performing proprietary models (e.g., GPT or Gemini) is unavailable. Therefore, we need a framework that delivers engineering value by handling long, non-natural-language CAD model metadata using VLMs, but without training. We propose a 2-stage framework with inference-time adaptation that combines corrected Error Notebooks with RAG to substantially improve VLM-based part retrieval reasoning. Each Error Notebook is built by correcting initial CoTs through reflective refinement, and then filtering each trajectory using our proposed grammar-constraint (GC) verifier to ensure structural well-formedness. The resulting notebook forms a high-quality repository of specification-CoT-answer triplets, from which RAG retrieves specification-relevant exemplars to condition the model's inference. We additionally contribute a CAD dataset with human preference annotations. Experiments with proprietary models (GPT-4o, Gemini, etc) show large gains, with GPT-4o (Omni) achieving up to +23.4 absolute accuracy points on the human-preference benchmark. The proposed GC verifier can further produce up to +4.5 accuracy points. Our approach also surpasses other training-free baselines (standard few-shot learning, self-consistency) and yields substantial improvements also for open-source VLMs (Qwen2-VL-2B-Instruct, Aya-Vision-8B). Under the cross-model GC setting, where the Error Notebook is constructed using GPT-4o (Omni), the 2B model inference achieves performance that comes within roughly 4 points of GPT-4o mini.","authors":["Yunqing Liu","Nan Zhang","Zhiming Tan"],"pdf_url":"","comment":"Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2508.19982v4","updated":"2026-02-25T02:56:31Z","published":"2025-08-27T15:40:25Z","title":"Diffusion Language Models Know the Answer Before Decoding","summary":"Diffusion language models (DLMs) have recently emerged as an alternative to autoregressive approaches, offering parallel sequence generation and flexible token orders. However, their inference remains slower than that of autoregressive models, primarily due to the cost of bidirectional attention and the large number of refinement steps required for high quality outputs. In this work, we highlight and leverage an overlooked property of DLMs early answer convergence: in many cases, the correct answer can be internally identified by half steps before the final decoding step, both under semi-autoregressive and random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99% of instances, respectively, can be decoded correctly using only half of the refinement steps. Building on this observation, we introduce Prophet, a training-free fast decoding paradigm that enables early commit decoding. Specifically, Prophet dynamically decides whether to continue refinement or to go \"all-in\" (i.e., decode all remaining tokens in one step), using the confidence gap between the top-2 prediction candidates as the criterion. It integrates seamlessly into existing DLM implementations, incurs negligible overhead, and requires no additional training. Empirical evaluations of LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the number of decoding steps by up to 3.4x while preserving high generation quality. These results recast DLM decoding as a problem of when to stop sampling, and demonstrate that early decode convergence provides a simple yet powerful mechanism for accelerating DLM inference, complementary to existing speedup techniques. Our code is publicly available at https://github.com/pixeli99/Prophet.","authors":["Pengxiang Li","Yefan Zhou","Dilxat Muhtar","Lu Yin","Shilin Yan","Li Shen","Soroush Vosoughi","Shiwei Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18060v2","updated":"2026-02-25T02:51:23Z","published":"2025-10-20T19:53:02Z","title":"SPACeR: Self-Play Anchoring with Centralized Reference Models","summary":"Developing autonomous vehicles (AVs) requires not only safety and efficiency, but also realistic, human-like behaviors that are socially aware and predictable. Achieving this requires sim agent policies that are human-like, fast, and scalable in multi-agent settings. Recent progress in imitation learning with large diffusion-based or tokenized models has shown that behaviors can be captured directly from human driving data, producing realistic policies. However, these models are computationally expensive, slow during inference, and struggle to adapt in reactive, closed-loop scenarios. In contrast, self-play reinforcement learning (RL) scales efficiently and naturally captures multi-agent interactions, but it often relies on heuristics and reward shaping, and the resulting policies can diverge from human norms. We propose SPACeR, a framework that leverages a pretrained tokenized autoregressive motion model as a centralized reference policy to guide decentralized self-play. The reference model provides likelihood rewards and KL divergence, anchoring policies to the human driving distribution while preserving RL scalability. Evaluated on the Waymo Sim Agents Challenge, our method achieves competitive performance with imitation-learned policies while being up to 10x faster at inference and 50x smaller in parameter size than large generative models. In addition, we demonstrate in closed-loop ego planning evaluation tasks that our sim agents can effectively measure planner quality with fast and scalable traffic simulation, establishing a new paradigm for testing autonomous driving policies.","authors":["Wei-Jer Chang","Akshay Rangesh","Kevin Joseph","Matthew Strong","Masayoshi Tomizuka","Yihan Hu","Wei Zhan"],"pdf_url":"","comment":"Accepted at ICLR 2026. Project page: https://spacer-ai.github.io/"},{"id":"http://arxiv.org/abs/2602.20981v2","updated":"2026-02-25T02:22:46Z","published":"2026-02-24T15:01:39Z","title":"Echoes Over Time: Unlocking Length Generalization in Video-to-Audio Generation Models","summary":"Scaling multimodal alignment between video and audio is challenging, particularly due to limited data and the mismatch between text descriptions and frame-level video information. In this work, we tackle the scaling challenge in multimodal-to-audio generation, examining whether models trained on short instances can generalize to longer ones during testing. To tackle this challenge, we present multimodal hierarchical networks so-called MMHNet, an enhanced extension of state-of-the-art video-to-audio models. Our approach integrates a hierarchical method and non-causal Mamba to support long-form audio generation. Our proposed method significantly improves long audio generation up to more than 5 minutes. We also prove that training short and testing long is possible in the video-to-audio generation tasks without training on the longer durations. We show in our experiments that our proposed method could achieve remarkable results on long-video to audio benchmarks, beating prior works in video-to-audio tasks. Moreover, we showcase our model capability in generating more than 5 minutes, while prior video-to-audio methods fall short in generating with long durations.","authors":["Christian Simon","Masato Ishii","Wei-Yao Wang","Koichi Saito","Akio Hayakawa","Dongseok Shim","Zhi Zhong","Shuyang Cui","Shusuke Takahashi","Takashi Shibuya","Yuki Mitsufuji"],"pdf_url":"","comment":"Accepted to CVPR 2026"},{"id":"http://arxiv.org/abs/2503.14499v3","updated":"2026-02-25T02:20:56Z","published":"2025-03-18T17:59:31Z","title":"Measuring AI Ability to Complete Long Software Tasks","summary":"Despite rapid progress on AI benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of AI systems in terms of human capabilities, we propose a new metric: 50%-task-completion time horizon. This is the time humans typically take to complete tasks that AI models can complete with 50% success rate. We first timed humans with relevant domain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter tasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet have a 50% time horizon of around 50 minutes. Furthermore, frontier AI time horizon has been doubling approximately every seven months since 2019, though the trend may have accelerated in 2024. The increase in AI models' time horizons seems to be primarily driven by greater reliability and ability to adapt to mistakes, combined with better logical reasoning and tool use capabilities. We discuss the limitations of our results -- including their degree of external validity -- and the implications of increased autonomy for dangerous capabilities. If these results generalize to real-world software tasks, extrapolation of this trend predicts that within 5 years, AI systems will be capable of automating many software tasks that currently take humans a month.","authors":["Thomas Kwa","Ben West","Joel Becker","Amy Deng","Katharyn Garcia","Max Hasin","Sami Jawhar","Megan Kinniment","Nate Rush","Sydney Von Arx","Ryan Bloom","Thomas Broadley","Haoxing Du","Brian Goodrich","Nikola Jurkovic","Luke Harold Miles","Seraphina Nix","Tao Lin","Neev Parikh","David Rein","Lucas Jun Koba Sato","Hjalmar Wijk","Daniel M. Ziegler","Elizabeth Barnes","Lawrence Chan"],"pdf_url":"","comment":null}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2511.21104v2","updated":"2026-02-25T16:45:04Z","published":"2025-11-26T06:39:19Z","title":"BRIDGE: Building Representations In Domain Guided Program Synthesis","summary":"Large language models (LLMs) are good at generating code, but remain brittle for formal verification in systems like Lean4. A core scalability challenge is that verified synthesis requires consistent outputs across multiple artifacts: executable code, precise specifications, theorem statements, and ultimately proofs. Existing approaches rarely treat these as a unified pipeline. We present BRIDGE, a structured prompting framework that decomposes verification into three interconnected domains: Code (implementations), Specifications (formal intent), and Theorem Statements (constructive correctness claims), and elicits domain-specific intermediate reasoning to connect them. In Lean4, BRIDGE often adopts a code-first workflow, using the generated implementation as a semantic anchor for downstream specification and theorem statement generation. Across 178 algorithmic problems and five LLMs, BRIDGE improves Lean executable correctness by nearly 1.5x (pass at 5) over direct baselines and can be 2x more sample-efficient at inference time, requiring fewer samples per verified solution at comparable generation lengths. We further find that specification-driven prompting improves Python pass rates by up to 17.5 percent. Beyond inference-time prompting, supervised fine-tuning on BRIDGE-style reasoning traces yields nearly 1.5x higher Lean pass success than code-only SFT, indicating that these intermediate representations are learnable. BRIDGE provides a practical foundation for scaling verified synthesis and motivates future work on expert iteration and full proof generation.","authors":["Robert Joseph George","Carson Eisenach","Udaya Ghai","Dominique Perrault-Joncas","Anima Anandkumar","Dean Foster"],"pdf_url":"","comment":"Approx. 23 pages including appendices, 10 figures, 3 tables. Empirical study of LLM-based verified program synthesis in Lean4 (code, specs, and proofs)"},{"id":"http://arxiv.org/abs/2412.15042v2","updated":"2026-02-25T16:25:13Z","published":"2024-12-19T16:51:29Z","title":"Scylla: Translating an Applicative Subset of C to Safe Rust","summary":"The popularity of the Rust language continues to explode; yet, many critical codebases remain authored in C. Automatically translating C to Rust is thus an appealing course of action. Several works have gone down this path, handling an ever-increasing subset of C through a variety of Rust features, such as unsafe. While the prospect of automation is appealing, producing code that relies on unsafe negates the memory safety guarantees offered by Rust, and therefore the main advantages of porting existing codebases to memory-safe languages. We instead advocate for a different approach, where the programmer iterates on the original C, gradually making the code more structured until it becomes eligible for compilation to safe Rust. This means that redesigns and rewrites can be evaluated incrementally for performance and correctness against existing test suites and production environments.\n  Compiling structured C to safe Rust relies on the following contributions: a type-directed translation from (a subset of) C to safe Rust; a novel static analysis based on \"split trees\" which allows expressing C's pointer arithmetic using Rust's slices and splitting operations; an analysis that infers which borrows need to be mutable; and a compilation strategy for C pointer types that is compatible with Rust's distinction between non-owned and owned allocations. We evaluate our approach on real-world cryptographic libraries, binary parsers and serializers, and a file compression library. We show that these can be rewritten to Rust with small refactors of the original C code, and that the resulting Rust code exhibits similar performance characteristics as the original C code. As part of our translation process, we also identify and report undefined behaviors in the bzip2 compression library and in Microsoft's implementation of the FrodoKEM cryptographic primitive.","authors":["Aymeric Fromherz","Jonathan Protzenko"],"pdf_url":"","comment":"OOPSLA 2026 camera-ready version"},{"id":"http://arxiv.org/abs/2602.22075v1","updated":"2026-02-25T16:25:04Z","published":"2026-02-25T16:25:04Z","title":"RustyDL: A Program Logic for Rust","summary":"Rust is a modern programming language that guarantees memory safety and the absence of data races with a strong type system. We present RustyDL, a program logic for Rust, as a foundation for an auto-interactive, deductive verification tool for Rust. RustyDL reasons about Rust programs directly on the source code level, in contrast to other tools that are all based on translation to an intermediate language. A source-level program logic for Rust is crucial for a human-in-the-loop (HIL) style of verification that permits proving highly complex functional properties. We discuss specific Rust challenges in designing a program logic and calculus for HIL-style verification and propose a solution in each case. We provide a proof-of-concept of our ideas in the form of a prototype of a Rust instance of the deductive verification tool KeY.","authors":["Daniel Drodt","Reiner Hähnle"],"pdf_url":"","comment":"Long version of paper published at 27th International Symposium on Formal Methods (FM 2026)"},{"id":"http://arxiv.org/abs/2602.16291v3","updated":"2026-02-25T09:21:01Z","published":"2026-02-18T09:17:20Z","title":"A Calculus of Inheritance","summary":"Just as the $λ$-calculus uses three primitives (abstraction, application, variable) as the foundation of functional programming, inheritance-calculus uses three primitives (record, definition, inheritance) as the foundation of declarative programming. It trivially embeds the $λ$-calculus, although the entire semantics rests solely on naive set theory; as a consequence, all constructs including inheritance are inherently commutative, idempotent, and associative; the linearization problem of multiple inheritance does not arise. This induces a fully abstract semantics of the lazy $λ$-calculus with respect to Böhm tree equivalence~\\cite{barendregt1984lambda}. Inheritance-calculus is distilled from MIXINv2, a practical implementation in which we observed further emergent phenomena: the same code acts as different function colors~\\cite{nystrom2015color}; ordinary arithmetic yields the relational semantics of logic programming~\\cite{vanemden1976semantics}; self-reference resolves to multiple targets; and programs are immune to the Expression Problem~\\cite{wadler1998expression}. This makes inheritance-calculus strictly more expressive than the $λ$-calculus in both common sense and Felleisen's sense~\\cite{felleisen1991expressive}. These properties suggest applications to configuration languages, dependency injection, object-oriented programming, composable effect systems, modular software architectures, file-system-as-compiler, general-purpose programming, and no-code development.","authors":["Bo Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21630v1","updated":"2026-02-25T06:50:51Z","published":"2026-02-25T06:50:51Z","title":"Type-Based Enforcement of Non-Interference for Choreographic Programming","summary":"Choreographies describe distributed protocols from a global viewpoint, enabling correct-by-construction synthesis of local behaviours. We develop a policy-parametric type system that prevents information leaks from high-security data to low-security observers, handling both explicit and implicit flows through a program-counter discipline. The system supports recursive procedures via a procedure context that we reconstruct through constraint generation. We prove termination-insensitive non-interference with respect to a standard small-step semantics.","authors":["Marco Bertoni","Saverio Giallorenzo","Marco Peressotti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.17691v2","updated":"2026-02-25T04:00:38Z","published":"2025-07-23T16:57:32Z","title":"CASCADE: LLM-Powered JavaScript Deobfuscator at Google","summary":"Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.","authors":["Shan Jiang","Pranoy Kovuri","David Tao","Zhixun Tan"],"pdf_url":"","comment":"To appear in ICSE-SEIP 2026"},{"id":"http://arxiv.org/abs/2406.11935v4","updated":"2026-02-25T02:17:57Z","published":"2024-06-17T16:10:10Z","title":"A Problem-Oriented Perspective and Anchor Verification for Code Optimization","summary":"Large Language Models (LLMs) have shown remarkable capabilities in solving various programming tasks, such as code generation. However, their potential for code optimization, particularly in performance enhancement, remains largely unexplored. This paper investigates the capabilities of LLMs in optimizing code for minimal execution time, addressing a critical gap in current research. The recently proposed code optimization methods construct program optimization pairs based on iterative submissions from the same programmer for the same problem. However, this approach confines LLMs to local performance improvements, neglecting global algorithmic innovation. To overcome this limitation, we adopt a completely different perspective by reconstructing the optimization pairs into a problem-oriented approach. This allows for the integration of various ideas from multiple programmers tackling the same problem. Furthermore, we observe that code optimization presents greater challenges compared to code generation, often accompanied by \"optimization tax\". Recognizing the inherent trade-offs in correctness and efficiency, we introduce a novel anchor verification framework to mitigate this \"optimization tax\". Ultimately, the problem oriented perspective combined with the anchor verification framework significantly enhances both the correct optimization ratio and speedup to new levels.","authors":["Tong Ye","Tengfei Ma","Xuhong Zhang","Hang Yu","Jianwei Yin","Wenhai Wang"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2507.17691v2","updated":"2026-02-25T04:00:38Z","published":"2025-07-23T16:57:32Z","title":"CASCADE: LLM-Powered JavaScript Deobfuscator at Google","summary":"Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.","authors":["Shan Jiang","Pranoy Kovuri","David Tao","Zhixun Tan"],"pdf_url":"","comment":"To appear in 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE-SEIP '26)"}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.22124v1","updated":"2026-02-25T17:11:49Z","published":"2026-02-25T17:11:49Z","title":"SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents","summary":"Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).","authors":["Patrick Tser Jern Kon","Archana Pradeep","Ang Chen","Alexander P. Ellis","Warren Hunt","Zijian Wang","John Yang","Samuel Thompson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22076v1","updated":"2026-02-25T16:25:18Z","published":"2026-02-25T16:25:18Z","title":"Visual Milestone Planning in a Hybrid Development Context","summary":"This paper explains the Visual Milestone Planning (VMP) method using an agile vocabulary to facilitate its adoption by agile practitioners as a front end for a hybrid development process. VMP is a visual and collaborative planning approach which promotes a shared understanding of the work approach and commitment through the direct manipulation by team members of the reified planning constructs involved in the development of the plan. Once the product backlog has been established and relevant milestones identified, a novel construct called the milestone planning matrix is used to document the allocation of product backlog items to milestones. The milestones due dates are later determined by grouping sticky notes representing the work to be performed into time-boxes called work packages and accommodating them on a resource and time scaled scheduling canvas very much as it would be done in a Tetris game.","authors":["Eduardo Miranda"],"pdf_url":"","comment":"15 pages, Presented at QUATIC 2023"},{"id":"http://arxiv.org/abs/2602.20292v2","updated":"2026-02-25T16:13:30Z","published":"2026-02-23T19:16:30Z","title":"Quantifying the Expectation-Realisation Gap for Agentic AI Systems","summary":"Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across software engineering, clinical documentation, and clinical decision support to quantify this expectation-realisation gap. In software development, experienced developers expected a 24% speedup from AI tools but were slowed by 19% -- a 43 percentage-point calibration error. In clinical documentation, vendor claims of multi-minute time savings contrast with measured reductions of less than one minute per note, and one widely deployed tool showed no statistically significant effect. In clinical decision support, externally validated performance falls substantially below developer-reported metrics. These shortfalls are driven by workflow integration friction, verification burden, measurement construct mismatches, and systematic variation in who benefits and who does not. The evidence motivates structured planning frameworks that require explicit, quantified benefit expectations with human oversight costs factored in.","authors":["Sebastian Lobentanzer"],"pdf_url":"","comment":"10 pages, no figures; added glossary"},{"id":"http://arxiv.org/abs/2602.22020v1","updated":"2026-02-25T15:32:17Z","published":"2026-02-25T15:32:17Z","title":"Detecting UX smells in Visual Studio Code using LLMs","summary":"Integrated Development Environments shape developers' daily experience, yet the empirical study of their usability and user experience (UX) remains limited. This work presents an LLM-assisted approach to detecting UX smells in Visual Studio Code by mining and classifying user-reported issues from the GitHub repository. Using a validated taxonomy and expert review, we identified recurring UX problems that affect the developer experience. Our results show that the majority of UX smells are concentrated in informativeness, clarity, intuitiveness, and efficiency, qualities that developers value most.","authors":["Andrés Rodriguez","Juan Cruz Gardey","Alejandra Garrido"],"pdf_url":"","comment":"4 pages, 2 figures, 1 table, 3rd International Workshop on Integrated Development Environments (IDE 2026)"},{"id":"http://arxiv.org/abs/2602.21997v1","updated":"2026-02-25T15:16:43Z","published":"2026-02-25T15:16:43Z","title":"Enhancing LLM-Based Test Generation by Eliminating Covered Code","summary":"Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, our approach outperforms state-of-the-art LLM-based and search-based methods, demonstrating its effectiveness in achieving high coverage on complex methods.","authors":["WeiZhe Xu","Mengyu Liu","Fanxin Kong"],"pdf_url":"","comment":"9 pages, 4 figures, supplementary material included"},{"id":"http://arxiv.org/abs/2506.08980v4","updated":"2026-02-25T15:08:15Z","published":"2025-06-10T16:49:46Z","title":"Towards Better Code Generation: Adaptive Decoding with Uncertainty Guidance","summary":"The success of code synthesis using large language models (LLMs) depends heavily on navigating critical decision points during the decoding process. Standard uniform strategies, such as greedy decoding, often fall short because they fail to distinguish between deterministic steps and those characterized by high logical ambiguity. Our empirical analysis identifies a recurring failure mode: \"logic drift\" caused by the model's inability to correctly rank viable candidates during high-uncertainty intervals, even when the ground-truth token is available.\n  To resolve this, we present AdaDec, a framework that introduces a selective pause-then-rerank mechanism into the decoding pipeline. Unlike static methods, AdaDec utilizes learned, model-specific entropy thresholds to identify when the model is \"confused\" and dynamically triggers a lookahead-based evaluation to re-score candidate tokens.\n  Across benchmarks including HumanEval+, MBPP+, and DevEval, AdaDec achieves significant performance breakthroughs, boosting Pass@1 accuracy by up to 20.9% absolute over greedy decoding. The framework not only surpasses traditional Beam Search and specialized methods like AdapT in terms of reliability but also maintains high inference efficiency by intervening only at the most consequential steps. These results suggest that uncertainty-aware adaptive strategies are key to making LLM-driven code generation both robust and practical.","authors":["Kaifeng He","Mingwei Liu","Chong Wang","Zike Li","Yanlin Wang","Xin Peng","Zibin Zheng"],"pdf_url":"","comment":"21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2509.11787v3","updated":"2026-02-25T12:42:03Z","published":"2025-09-15T11:16:04Z","title":"CodeCureAgent: Automatic Classification and Repair of Static Analysis Warnings","summary":"Static analysis tools are widely used to detect bugs, vulnerabilities, and code smells. Traditionally, developers must resolve these warnings manually. Because this process is tedious, developers sometimes ignore warnings, leading to an accumulation of warnings and a degradation of code quality. This paper presents CodeCureAgent, an approach that harnesses LLM-based agents to automatically analyze, classify, and repair static analysis warnings. Unlike previous work, our method does not follow a predetermined algorithm. Instead, we adopt an agentic framework that iteratively invokes tools to gather additional information from the codebase (e.g., via code search) and edit the codebase to resolve the warning. CodeCureAgent detects and suppresses false positives, while fixing true positives when identified. We equip CodeCureAgent with a three-step heuristic to approve patches: (1) build the project, (2) verify that the warning disappears without introducing new warnings, and (3) run the test suite. We evaluate CodeCureAgent on a dataset of 1,000 SonarQube warnings found in 106 Java projects and covering 291 distinct rules. Our approach produces plausible fixes for 96.8% of the warnings, outperforming state-of-the-art baseline approaches by 29.2%-34.0% in plausible-fix rate. Manual inspection of 291 cases reveals a correct-fix rate of 86.3%, showing that CodeCureAgent can reliably repair static analysis warnings. The approach incurs LLM costs of about 2.9 cents (USD) and an end-to-end processing time of about four minutes per warning. We envision CodeCureAgent helping to clean existing codebases and being integrated into CI/CD pipelines to prevent the accumulation of static analysis warnings.","authors":["Pascal Joos","Islem Bouzenia","Michael Pradel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21833v1","updated":"2026-02-25T12:05:25Z","published":"2026-02-25T12:05:25Z","title":"From Restructuring to Stabilization: A Large-Scale Experiment on Iterative Code Readability Refactoring with Large Language Models","summary":"Large language models (LLMs) are increasingly used for automated code refactoring tasks. Although these models can quickly refactor code, the quality may exhibit inconsistencies and unpredictable behavior. In this article, we systematically study the capabilities of LLMs for code refactoring with a specific focus on improving code readability.\n  We conducted a large-scale experiment using GPT5.1 with 230 Java snippets, each systematically varied and refactored regarding code readability across five iterations under three different prompting strategies. We categorized fine-grained code changes during the refactoring into implementation, syntactic, and comment-level transformations. Subsequently, we investigated the functional correctness and tested the robustness of the results with novel snippets.\n  Our results reveal three main insights: First, iterative code refactoring exhibits an initial phase of restructuring followed by stabilization. This convergence tendency suggests that LLMs possess an internalized understanding of an \"optimally readable\" version of code. Second, convergence patterns are fairly robust across different code variants. Third, explicit prompting toward specific readability factors slightly influences the refactoring dynamics.\n  These insights provide an empirical foundation for assessing the reliability of LLM-assisted code refactoring, which opens pathways for future research, including comparative analyses across models and a systematic evaluation of additional software quality dimensions in LLM-refactored code.","authors":["Norman Peitek","Julia Hess","Sven Apel"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21806v1","updated":"2026-02-25T11:34:17Z","published":"2026-02-25T11:34:17Z","title":"An Empirical Study of Bugs in Modern LLM Agent Frameworks","summary":"LLM agents have been widely adopted in real-world applications, relying on agent frameworks for workflow execution and multi-agent coordination. As these systems scale, understanding bugs in the underlying agent frameworks becomes critical. However, existing work mainly focuses on agent-level failures, overlooking framework-level bugs. To address this gap, we conduct an empirical study of 998 bug reports from CrewAI and LangChain, constructing a taxonomy of 15 root causes and 7 observable symptoms across five agent lifecycle stages: 'Agent Initialization','Perception', 'Self-Action', 'Mutual Interaction' and 'Evolution'. Our findings show that agent framework bugs mainly arise from 'API misuse', 'API incompatibility', and 'Documentation Desync', largely concentrated in the 'Self-Action' stage. Symptoms typically appear as 'Functional Error', 'Crash', and 'Build Failure', reflecting disruptions to task progression and control flow.","authors":["Xinxue Zhu","Jiacong Wu","Xiaoyu Zhang","Tianlin Li","Yanzhou Mu","Juan Zhai","Chao Shen","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21800v1","updated":"2026-02-25T11:27:34Z","published":"2026-02-25T11:27:34Z","title":"An Evaluation of Context Length Extrapolation in Long Code via Positional Embeddings and Efficient Attention","summary":"The rapid advancement of large language models (LLMs) has led to a significant increase in automated tools in the software engineering, capable of performing various code-related tasks such as code generation, completion, and translation. Despite these advancements, its effectiveness is constrained by fixed context lengths, limiting its ability to generalize across long, domain-specific code sequences. To address this challenge, we investigate zero-shot, inference-only methods aimed at improving position encodings and optimizing attention mechanisms. Our goal is to provide a thorough analysis of current approaches that facilitate context length extrapolation in code, particularly in the context of long code completion tasks.","authors":["Madhusudan Ghosh","Rishabh Gupta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21734v1","updated":"2026-02-25T09:43:56Z","published":"2026-02-25T09:43:56Z","title":"Proto-ML: An IDE for ML Solution Prototyping","summary":"Prototyping plays a critical role in the development of machine learning (ML) solutions, yet existing tools often provide limited support for effective collaboration and knowledge reuse among stakeholders. This paper introduces Proto-ML, an IDE designed to strengthen ML prototyping workflows. By addressing key deficiencies such as insufficient stakeholder involvement, limited cross-project knowledge reuse, and fragmented tool support, Proto-ML offers a unified framework that enables structured documentation of prototyping activities and promotes knowledge sharing across projects.\n  The Proto-ML IDE consists of three extension bundles: prototype implementation, analysis, and knowledge management. These extensions support tasks ranging from evaluating prototype quality against defined criteria to incorporating stakeholder perspectives throughout the development process. Preliminary user feedback suggests that Proto-ML can increase prototyping efficiency and foster more transparent and reusable ML solution development.","authors":["Selin Coban","Miguel Perez","Horst Lichter"],"pdf_url":"","comment":"To be published at 3rd International Workshop on Integrated Development Environments (IDE '26), April 12--18, 2026, Rio de Janeiro, Brazil"},{"id":"http://arxiv.org/abs/2602.16291v3","updated":"2026-02-25T09:21:01Z","published":"2026-02-18T09:17:20Z","title":"A Calculus of Inheritance","summary":"Just as the $λ$-calculus uses three primitives (abstraction, application, variable) as the foundation of functional programming, inheritance-calculus uses three primitives (record, definition, inheritance) as the foundation of declarative programming. It trivially embeds the $λ$-calculus, although the entire semantics rests solely on naive set theory; as a consequence, all constructs including inheritance are inherently commutative, idempotent, and associative; the linearization problem of multiple inheritance does not arise. This induces a fully abstract semantics of the lazy $λ$-calculus with respect to Böhm tree equivalence~\\cite{barendregt1984lambda}. Inheritance-calculus is distilled from MIXINv2, a practical implementation in which we observed further emergent phenomena: the same code acts as different function colors~\\cite{nystrom2015color}; ordinary arithmetic yields the relational semantics of logic programming~\\cite{vanemden1976semantics}; self-reference resolves to multiple targets; and programs are immune to the Expression Problem~\\cite{wadler1998expression}. This makes inheritance-calculus strictly more expressive than the $λ$-calculus in both common sense and Felleisen's sense~\\cite{felleisen1991expressive}. These properties suggest applications to configuration languages, dependency injection, object-oriented programming, composable effect systems, modular software architectures, file-system-as-compiler, general-purpose programming, and no-code development.","authors":["Bo Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21697v1","updated":"2026-02-25T09:02:45Z","published":"2026-02-25T09:02:45Z","title":"EditFlow: Benchmarking and Optimizing Code Edit Recommendation Systems via Reconstruction of Developer Flows","summary":"Large language models (LLMs) for code editing have achieved remarkable progress, yet recent empirical studies reveal a fundamental disconnect between technical accuracy and developer productivity. Despite their strong benchmark performance, developers complete tasks 19% slower when using AI assistance, with over 68.81% of recommendations disrupting their mental flow. This misalignment stems from the use of static commit snapshots that lack temporal information, causing models to optimize for end results rather than the incremental, context-sensitive steps that align with developers' natural reasoning process.\n  To bridge this gap, we present EditFlow, which benchmarks and optimizes subsequent code edit recommendation systems through the reconstruction of developer editing flows. EditFlow addresses three key challenges. First, collecting edit-order data that reflects developers' flow is inherently difficult: manual annotation introduces prohibitive overhead, while development logs capture only single trajectories instead of all plausible editing flows. Second, benchmarking recommendation performance against developers' ongoing editing flow requires a digital-twin-like simulation that can faithfully simulate the editing process. Third, existing heterogeneous systems vary drastically in scale and architecture, posing challenges for developing a unified optimization strategy that endows all models with mental-flow awareness regardless of design or capability.\n  ......","authors":["Chenyan Liu","Yun Lin","Jiaxin Chang","Jiawei Liu","Binhang Qi","Bo Jiang","Zhiyong Huang","Jin Song Dong"],"pdf_url":"","comment":"Accepted at OOPSLA 2026 (Proc. ACM Program. Lang., Vol. 10, OOPSLA1)"},{"id":"http://arxiv.org/abs/2602.21681v1","updated":"2026-02-25T08:34:27Z","published":"2026-02-25T08:34:27Z","title":"AkiraRust: Re-thinking LLM-aided Rust Repair Using a Feedback-guided Thinking Switch","summary":"Eliminating undefined behaviors (UBs) in Rust programs requires a deep semantic understanding to enable accurate and reliable repair. While existing studies have demonstrated the potential of LLMs to support Rust code analysis and repair, most frameworks remain constrained by inflexible templates or lack grounding in executable semantics, resulting in limited contextual awareness and semantic incorrectness. Here, we present AkiraRust, an LLM-driven repair and verification framework that incorporates a finite-state machine to dynamically adapt its detection and repair flow to runtime semantic conditions. AkiraRust introduces a dual-mode reasoning strategy that coordinates fast and slow thinking across multiple agents. Each agent is mapped to an FSM state, and a waveform-driven transition controller manages state switching, rollback decisions, and semantic check pointing, enabling context-aware and runtime-adaptive repair. Experimental results show that AkiraRust achieves about 92% semantic correctness and delivers a 2.2x average speedup compared to SOTA.","authors":["Renshuang Jiang","Yichong Wang","Pan Dong","Xiaoxiang Fang","Zhenling Duan","Tinglue Wang","Yuchen Hu","Jie Yu","Zhe Jiang"],"pdf_url":"","comment":"7 pages, 11 figures, accepted to DAC"},{"id":"http://arxiv.org/abs/2602.21641v1","updated":"2026-02-25T07:10:53Z","published":"2026-02-25T07:10:53Z","title":"Uncertainty Modeling for SysML v2","summary":"Uncertainty is inherent in modern engineered systems, including cyber-physical systems, autonomous systems, and large-scale software-intensive infrastructures (such as microservice-based systems) operating in dynamic and partially observable environments. The recent publication of Precise Semantics for Uncertainty Modeling (PSUM) by the Object Management Group represents the first standardized specification for uncertainty modeling within the Model-Based Systems Engineering (MBSE) community, providing formally defined semantics for representing and reasoning about uncertainty in models. In parallel, the second version of Systems Modeling Language (SysML v2) was released as the next-generation systems modeling language, offering improved semantic rigor and reusability, yet lacking native constructs aligned with PSUM for first-class uncertainty representation. This paper proposes a systematic extension of SysML v2 that incorporates the PSUM metamodel into its modeling framework. The extension enables explicit specification of indeterminacy sources, structured characterization of uncertainties, and consistent propagation of uncertainty within system models, while preserving conformance with SysML v2 syntax and semantics. We validate the approach through seven case studies. Results demonstrate that the proposed extension (PSUM-SysMLv2) is expressive and applicable for uncertainty-aware MBSE, and potentially enables uncertainty and uncertainty propagation analyses.","authors":["Man Zhang","Yunyang Li","Tao Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20610v2","updated":"2026-02-25T06:38:21Z","published":"2026-02-24T07:01:17Z","title":"SpecMind: Cognitively Inspired, Interactive Multi-Turn Framework for Postcondition Inference","summary":"Specifications are vital for ensuring program correctness, yet writing them manually remains challenging and time-intensive. Recent large language model (LLM)-based methods have shown successes in generating specifications such as postconditions, but existing single-pass prompting often yields inaccurate results. In this paper, we present SpecMind, a novel framework for postcondition generation that treats LLMs as interactive and exploratory reasoners rather than one-shot generators. SpecMind employs feedback-driven multi-turn prompting approaches, enabling the model to iteratively refine candidate postconditions by incorporating implicit and explicit correctness feedback, while autonomously deciding when to stop. This process fosters deeper code comprehension and improves alignment with true program behavior via exploratory attempts. Our empirical evaluation shows that SpecMind significantly outperforms state-of-the-art approaches in both accuracy and completeness of generated postconditions.","authors":["Cuong Chi Le","Minh V. T Pham","Tung Vu Duy","Cuong Duc Van","Huy N. Phan","Hoang N. Phan","Tien N. Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21611v1","updated":"2026-02-25T06:13:25Z","published":"2026-02-25T06:13:25Z","title":"Structurally Aligned Subtask-Level Memory for Software Engineering Agents","summary":"Large Language Models (LLMs) have demonstrated significant potential as autonomous software engineering (SWE) agents. Recent work has further explored augmenting these agents with memory mechanisms to support long-horizon reasoning. However, these approaches typically operate at a coarse instance granularity, treating the entire problem-solving episode as the atomic unit of storage and retrieval. We empirically demonstrate that instance-level memory suffers from a fundamental granularity mismatch, resulting in misguided retrieval when tasks with similar surface descriptions require distinct reasoning logic at specific stages. To address this, we propose Structurally Aligned Subtask-Level Memory, a method that aligns memory storage, retrieval, and updating with the agent's functional decomposition. Extensive experiments on SWE-bench Verified demonstrate that our method consistently outperforms both vanilla agents and strong instance-level memory baselines across diverse backbones, improving mean Pass@1 over the vanilla agent by +4.7 pp on average (e.g., +6.8 pp on Gemini 2.5 Pro). Performance gains grow with more interaction steps, showing that leveraging past experience benefits long-horizon reasoning in complex software engineering tasks.","authors":["Kangning Shen","Jingyuan Zhang","Chenxi Sun","Wencong Zeng","Yang Yue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21568v1","updated":"2026-02-25T04:46:08Z","published":"2026-02-25T04:46:08Z","title":"From Ad-Hoc Scripts to Orchestrated Pipelines: Architecting a Resilient ELT Framework for Developer Productivity Metrics","summary":"Developer Productivity Dashboards are essential for visualizing DevOps performance metrics such as Deployment Frequency and Change Failure Rate (DORA). However, the utility of these dashboards is frequently undermined by data reliability issues. In early iterations of our platform, ad-hoc ingestion scripts (Cron jobs) led to \"silent failures,\" where data gaps went undetected for days, eroding organizational trust. This paper reports on our experience migrating from legacy scheduling to a robust Extract-Load-Transform (ELT) pipeline using Directed Acyclic Graph (DAG) orchestration and Medallion Architecture. We detail the operational benefits of decoupling data extraction from transformation, the necessity of immutable raw history for metric redefinition, and the implementation of state-based dependency management. Our experience suggests that treating the metrics pipeline as a production-grade distributed system is a prerequisite for sustainable engineering analytics.","authors":["Yuvraj Agrawal","Pallav Jain"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.17691v2","updated":"2026-02-25T04:00:38Z","published":"2025-07-23T16:57:32Z","title":"CASCADE: LLM-Powered JavaScript Deobfuscator at Google","summary":"Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.","authors":["Shan Jiang","Pranoy Kovuri","David Tao","Zhixun Tan"],"pdf_url":"","comment":"To appear in ICSE-SEIP 2026"},{"id":"http://arxiv.org/abs/2406.11935v4","updated":"2026-02-25T02:17:57Z","published":"2024-06-17T16:10:10Z","title":"A Problem-Oriented Perspective and Anchor Verification for Code Optimization","summary":"Large Language Models (LLMs) have shown remarkable capabilities in solving various programming tasks, such as code generation. However, their potential for code optimization, particularly in performance enhancement, remains largely unexplored. This paper investigates the capabilities of LLMs in optimizing code for minimal execution time, addressing a critical gap in current research. The recently proposed code optimization methods construct program optimization pairs based on iterative submissions from the same programmer for the same problem. However, this approach confines LLMs to local performance improvements, neglecting global algorithmic innovation. To overcome this limitation, we adopt a completely different perspective by reconstructing the optimization pairs into a problem-oriented approach. This allows for the integration of various ideas from multiple programmers tackling the same problem. Furthermore, we observe that code optimization presents greater challenges compared to code generation, often accompanied by \"optimization tax\". Recognizing the inherent trade-offs in correctness and efficiency, we introduce a novel anchor verification framework to mitigate this \"optimization tax\". Ultimately, the problem oriented perspective combined with the anchor verification framework significantly enhances both the correct optimization ratio and speedup to new levels.","authors":["Tong Ye","Tengfei Ma","Xuhong Zhang","Hang Yu","Jianwei Yin","Wenhai Wang"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2507.02376v2","updated":"2026-02-25T01:55:14Z","published":"2025-07-03T07:17:49Z","title":"On the Inference (In-)Security of Vertical Federated Learning: Efficient Auditing against Inference Tampering Attack","summary":"Vertical Federated Learning (VFL) is an emerging distributed learning paradigm for cross-silo collaboration without accessing participants' data. However, existing VFL work lacks a mechanism to audit the inference correctness of the data party. The malicious data party can modify the local data and model to mislead the joint inference results. To exploit this vulnerability, we design a novel Vertical Federated Inference Tampering (VeFIT) attack, allowing the data party to covertly tamper with the local inference and mislead results on the task party's final prediction. VeFIT can decrease the task party's inference accuracy by an average of 34.49%. Existing defense mechanisms can not effectively detect this attack, and the detection performance is near random guessing. To mitigate the attack, we further design a Vertical Federated Inference Auditing (VeFIA) framework. VeFIA helps the task party to audit whether the data party's inferences are executed as expected during large-scale online inference. VeFIA does not leak the data party's privacy nor introduce additional latency. The core design is that the task party can use the inference results from a framework with Trusted Execution Environments (TEE) and the coordinator to validate the correctness of the data party's computation results. VeFIA guarantees that, as long as the proportion of inferences attacked by VeFIT exceeds 5.4%, the task party can detect the malicious behavior of the data party with a probability of 99.99%, without any additional online overhead. VeFIA's random sampling validation of VeFIA achieves 100% positive predictive value, negative predictive value, and true positive rate in detecting VeFIT. We further validate VeFIA's effectiveness in terms of privacy protection and scalability on real-world datasets. To the best of our knowledge, this is the first paper discussing the inference auditing problem towards VFL.","authors":["Chung-ju Huang","Ziqi Zhang","Yinggui Wang","Binghui Wang","Tao Wei","Leye Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2411.08254v3","updated":"2026-02-25T23:00:27Z","published":"2024-11-13T00:07:32Z","title":"Toward Automated Validation of Language Model Synthesized Test Cases using Semantic Entropy","summary":"Modern Large Language Model (LLM)-based programming agents often rely on test execution feedback to refine their generated code. These tests are synthetically generated by LLMs. However, LLMs may produce invalid or hallucinated test cases, which can mislead feedback loops and degrade the performance of agents in refining and improving code. This paper introduces VALTEST, a novel framework that leverages semantic entropy to automatically validate test cases generated by LLMs. Analyzing the semantic structure of test cases and computing entropy-based uncertainty measures, VALTEST trains a machine learning model to classify test cases as valid or invalid and filters out invalid test cases. Experiments on multiple benchmark datasets and various LLMs show that VALTEST not only boosts test validity by up to 29% but also improves code generation performance, as evidenced by significant increases in pass@1 scores. Our extensive experiments also reveal that semantic entropy is a reliable indicator to distinguish between valid and invalid test cases, which provides a robust solution for improving the correctness of LLM-generated test cases used in software testing and code generation.","authors":["Hamed Taherkhani","Jiho Shin","Muhammad Ammar Tahir","Md Rakib Hossain Misu","Vineet Sunil Gattani","Hadi Hemmati"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22456v1","updated":"2026-02-25T22:33:27Z","published":"2026-02-25T22:33:27Z","title":"Automating the Detection of Requirement Dependencies Using Large Language Models","summary":"Requirements are inherently interconnected through various types of dependencies. Identifying these dependencies is essential, as they underpin critical decisions and influence a range of activities throughout software development. However, this task is challenging, particularly in modern software systems, given the high volume of complex, coupled requirements. These challenges are further exacerbated by the ambiguity of Natural Language (NL) requirements and their constant change. Consequently, requirement dependency detection is often overlooked or performed manually. Large Language Models (LLMs) exhibit strong capabilities in NL processing, presenting a promising avenue for requirement-related tasks. While they have shown to enhance various requirements engineering tasks, their effectiveness in identifying requirement dependencies remains unexplored. In this paper, we introduce LEREDD, an LLM-based approach for automated detection of requirement dependencies that leverages Retrieval-Augmented Generation (RAG) and In-Context Learning (ICL). It is designed to identify diverse dependency types directly from NL requirements. We empirically evaluate LEREDD against two state-of-the-art baselines. The results show that LEREDD provides highly accurate classification of dependent and non-dependent requirements, achieving an accuracy of 0.93, and an F1 score of 0.84, with the latter averaging 0.96 for non-dependent cases. LEREDD outperforms zero-shot LLMs and baselines, particularly in detecting fine-grained dependency types, where it yields average relative gains of 94.87% and 105.41% in F1 scores for the Requires dependency over the baselines. We also provide an annotated dataset of requirement dependencies encompassing 813 requirement pairs across three distinct systems to support reproducibility and future research.","authors":["Ikram Darif","Feifei Niu","Manel Abdellatif","Lionel C. Briand","Ramesh S.","Arun Adiththan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.06301v3","updated":"2026-02-25T21:56:36Z","published":"2025-09-08T03:02:53Z","title":"Learning From Software Failures: A Case Study at a National Space Research Center","summary":"Software failures can have significant consequences, making learning from failures a critical aspect of software engineering. While software organizations are recommended to conduct postmortems, the effectiveness and adoption of these practices vary widely. Understanding how engineers gather, document, share, and apply lessons from failures is essential for improving reliability and preventing recurrence. High-reliability organizations (HROs) often develop software systems where failures carry catastrophic risks, requiring continuous learning to ensure reliability. These organizations provide a valuable setting to examine practices and challenges for learning from software failures. Such insight could help develop processes and tools to improve reliability and prevent recurrence. However, we lack in-depth industry perspectives on the practices and challenges of learning from failures.\n  To address this gap, we conducted a case study through 10 in-depth interviews with research software engineers at a national space research center. We examine how they learn from failures: how they gather, document, share, and apply lessons. To assess transferability, we include data from 5 additional interviews at other HROs. Our findings provide insight into how engineers learn from failures in practice. To summarize: (1) failure learning is informal, ad hoc, and inconsistently integrated into SDLC; (2) recurring failures persist due to absence of structured processes; and (3) key challenges, including time constraints, knowledge loss from turnover and fragmented documentation, and weak process enforcement, undermine systematic learning. Our findings deepen understanding of how software engineers learn from failures and offer guidance for improving failure management practices.","authors":["Dharun Anandayuvaraj","Tanmay Singla","Zain Hammadeh","Andreas Lund","Alexandra Holloway","James C. Davis"],"pdf_url":"","comment":"Accepted at IEEE/ACM International Conference on Software Engineering (ICSE) 2026"},{"id":"http://arxiv.org/abs/2602.22403v1","updated":"2026-02-25T20:54:49Z","published":"2026-02-25T20:54:49Z","title":"XMENTOR: A Rank-Aware Aggregation Approach for Human-Centered Explainable AI in Just-in-Time Software Defect Prediction","summary":"Machine learning (ML)-based defect prediction models can improve software quality. However, their opaque reasoning creates an HCI challenge because developers struggle to trust models they cannot interpret. Explainable AI (XAI) methods such as LIME, SHAP, and BreakDown aim to provide transparency, but when used together, they often produce conflicting explanations that increase confusion, frustration, and cognitive load. To address this usability challenge, we introduce XMENTOR, a human-centered, rank-aware aggregation method implemented as a VS Code plugin. XMENTOR unifies multiple post-hoc explanations into a single, coherent view by applying adaptive thresholding, rank and sign agreement, and fallback strategies to preserve clarity without overwhelming users. In a user study, nearly 90% of the participants preferred aggregated explanations, citing reduced confusion and stronger support for daily tasks of debugging and review of defects. Our findings show how combining explanations and embedding them into developer workflows can enhance interpretability, usability, and trust.","authors":["Saumendu Roy","Banani Roy","Chanchal Roy","Richard Bassey"],"pdf_url":"","comment":"10 pages, 14 figures, conference"},{"id":"http://arxiv.org/abs/2602.22402v1","updated":"2026-02-25T20:52:52Z","published":"2026-02-25T20:52:52Z","title":"Contextual Memory Virtualisation: DAG-Based State Management and Structurally Lossless Trimming for LLM Agents","summary":"As large language models engage in extended reasoning tasks, they accumulate significant state -- architectural mappings, trade-off decisions, codebase conventions -- within the context window. This understanding is lost when sessions reach context limits and undergo lossy compaction. We propose Contextual Memory Virtualisation (CMV), a system that treats accumulated LLM understanding as version-controlled state. Borrowing from operating system virtual memory, CMV models session history as a Directed Acyclic Graph (DAG) with formally defined snapshot, branch, and trim primitives that enable context reuse across independent parallel sessions. We introduce a three-pass structurally lossless trimming algorithm that preserves every user message and assistant response verbatim while reducing token counts by a mean of 20% and up to 86% for sessions with significant overhead by stripping mechanical bloat such as raw tool outputs, base64 images, and metadata. A single-user case-study evaluation across 76 real-world coding sessions demonstrates that trimming remains economically viable under prompt caching, with the strongest gains in mixed tool-use sessions, which average 39% reduction and reach break-even within 10 turns. A reference implementation is available at https://github.com/CosmoNaught/claude-code-cmv.","authors":["Cosmo Santoni"],"pdf_url":"","comment":"11 pages. 6 figures. Introduces a DAG-based state management system for LLM agents. Evaluation on 76 coding sessions shows up to 86% token reduction (mean 20%) while remaining economically viable under prompt caching. Includes reference implementation for Claude Code"},{"id":"http://arxiv.org/abs/2602.22368v1","updated":"2026-02-25T20:04:39Z","published":"2026-02-25T20:04:39Z","title":"EyeLayer: Integrating Human Attention Patterns into LLM-Based Code Summarization","summary":"Code summarization is the task of generating natural language descriptions of source code, which is critical for software comprehension and maintenance. While large language models (LLMs) have achieved remarkable progress on this task, an open question remains: can human expertise in code understanding further guide and enhance these models? We propose EyeLayer, a lightweight attention-augmentation module that incorporates human eye-gaze patterns, as a proxy of human expertise, into LLM-based code summarization. EyeLayer models human attention during code reading via a Multimodal Gaussian Mixture, redistributing token embeddings based on learned parameters (μ_i, σ_i^2) that capture where and how intensively developers focus. This design enables learning generalizable attention priors from eye-tracking data and incorporating them into LLMs seamlessly, without disturbing existing representations. We evaluate EyeLayer across diverse model families (i.e., LLaMA-3.2, Qwen3, and CodeBERT) covering different scales and architectures. EyeLayer consistently outperforms strong fine-tuning baselines across standard metrics, achieving gains of up to 13.17% on BLEU-4. These results demonstrate that human gaze patterns encode complementary attention signals that enhance the semantic focus of LLMs and transfer effectively across diverse models for code summarization.","authors":["Jiahao Zhang","Yifan Zhang","Kevin Leach","Yu Huang"],"pdf_url":"","comment":"Accepted at the 34th IEEE/ACM International Conference on Program Comprehension (ICPC 2026), April 12-13, 2026, Rio de Janeiro, Brazil"},{"id":"http://arxiv.org/abs/2602.22302v1","updated":"2026-02-25T18:42:56Z","published":"2026-02-25T18:42:56Z","title":"Agent Behavioral Contracts: Formal Specification and Runtime Enforcement for Reliable Autonomous AI Agents","summary":"Traditional software relies on contracts -- APIs, type systems, assertions -- to specify and enforce correct behavior. AI agents, by contrast, operate on prompts and natural language instructions with no formal behavioral specification. This gap is the root cause of drift, governance failures, and frequent project failures in agentic AI deployments. We introduce Agent Behavioral Contracts (ABC), a formal framework that brings Design-by-Contract principles to autonomous AI agents. An ABC contract C = (P, I, G, R) specifies Preconditions, Invariants, Governance policies, and Recovery mechanisms as first-class, runtime-enforceable components. We define (p, delta, k)-satisfaction -- a probabilistic notion of contract compliance that accounts for LLM non-determinism and recovery -- and prove a Drift Bounds Theorem showing that contracts with recovery rate gamma > alpha (the natural drift rate) bound behavioral drift to D* = alpha/gamma in expectation, with Gaussian concentration in the stochastic setting. We establish sufficient conditions for safe contract composition in multi-agent chains and derive probabilistic degradation bounds. We implement ABC in AgentAssert, a runtime enforcement library, and evaluate on AgentContract-Bench, a benchmark of 200 scenarios across 7 models from 6 vendors. Results across 1,980 sessions show that contracted agents detect 5.2-6.8 soft violations per session that uncontracted baselines miss entirely (p < 0.0001, Cohen's d = 6.7-33.8), achieve 88-100% hard constraint compliance, and bound behavioral drift to D* < 0.27 across extended sessions, with 100% recovery for frontier models and 17-100% across all models, at overhead < 10 ms per action.","authors":["Varun Pratap Bhardwaj"],"pdf_url":"","comment":"71 pages, 7 figures, 14 tables. Patent pending. Also available on Zenodo: DOI 10.5281/zenodo.18775393"},{"id":"http://arxiv.org/abs/2602.22292v1","updated":"2026-02-25T15:10:09Z","published":"2026-02-25T15:10:09Z","title":"The Ethos of the PEERfect REVIEWer: Scientific Care and Collegial Welfare","summary":"Peer review remains a cornerstone in academia, yet it frequently falls short in fostering joint progress and well-being. While peer review primarily emphasizes scientific rigor, it often lacks the empathy essential for supporting and encouraging all peers involved. In this experience report, I aim to highlight that peer review is a practice that demands both scientific care for quality and collegial welfare for the joint progress and well-being of all peers involved, including authors, co-reviewers, workshop or conference organizers, and journal editors. Drawing on my ten years of experience in academia, I propose the ethos of the PEERfect REVIEWer, grounded in the two core values: Scientific care and collegial welfare. Through reflection shaped by professional exchanges with colleagues, consideration of literature, and an examination of both self-authored and received reviews, I formulated an accompanying guideline with 16 practical recommendations to guide reviewers in their actions to achieve these two values. The ethos of the PEERfect REVIEWer and its accompanying guideline help reviewers in upholding high scientific standards and conducting peer review in a constructive, supportive, respectful, and timely manner. They demonstrate that scientific rigor and empathy are complementary forces that promote impactful peer review practice. By placing scientific care and collegial welfare at the core of peer review, this experience report reaffirms the importance of scientific rigor while also advocating for greater attention to empathy. It invites reviewers to reconsider their role not merely as gatekeepers but as partners in the academic journey of each peer involved. The PEERfect REVIEWer is both a caretaker of quality and a steward of joint progress and well-being - as truly impactful peer review practice requires scientific rigor and empathy in equal measure.","authors":["Oliver Karras"],"pdf_url":"","comment":"13 pages, Accepted at the 32nd International Working Conference on Requirements Engineering: Foundations for Software Quality"},{"id":"http://arxiv.org/abs/2602.22276v1","updated":"2026-02-25T09:58:20Z","published":"2026-02-25T09:58:20Z","title":"EmpiRE-Compass: A Neuro-Symbolic Dashboard for Sustainable and Dynamic Knowledge Exploration, Synthesis, and Reuse","summary":"Software engineering (SE) and requirements engineering (RE) face a significant increase in secondary studies, particularly literature reviews (LRs), due to the ever-growing number of scientific publications. Generative artificial intelligence (GenAI) exacerbates this trend by producing LRs rapidly but often at the expense of quality, rigor, and transparency. At the same time, secondary studies often fail to share underlying data and artifacts, limiting replication and reuse. This paper introduces EmpiRE-Compass, a neuro-symbolic dashboard designed to lower barriers for accessing, replicating, and reusing LR data. Its overarching goal is to demonstrate how LRs can become more sustainable by semantically structuring their underlying data in research knowledge graphs (RKGs) and by leveraging large language models (LLMs) for easy and dynamic access, replication, and reuse. Building on two RE use cases, we developed EmpiRE-Compass with a modular system design and workflows for curated and custom competency questions. The dashboard is freely available online, accompanied by a demonstration video. To manage operational costs, a limit of 25 requests per IP address per day applies to the default LLM (GPT-4o mini). All source code and documentation are released as an open-source project to foster reuse, adoption, and extension. EmpiRE-Compass provides three core capabilities: (1) Exploratory visual analytics for curated competency questions; (2) Neuro-symbolic synthesis for custom competency questions; and (3) Reusable knowledge with all queries, analyses, and results openly available. By unifying RKGs and LLMs in a neuro-symbolic dashboard, EmpiRE-Compass advances sustainable LRs in RE, SE, and beyond. It lowers technical barriers, fosters transparency and reproducibility, and enables collaborative, continuously updated, and reusable LRs","authors":["Oliver Karras","Amirreza Alasti","Lena John","Sushant Aggarwal","Yücel Celik"],"pdf_url":"","comment":"7 pages, 1 figure, Accepted at 32nd International Working Conference on Requirements Engineering: Foundations for Software Quality"},{"id":"http://arxiv.org/abs/2507.17691v2","updated":"2026-02-25T04:00:38Z","published":"2025-07-23T16:57:32Z","title":"CASCADE: LLM-Powered JavaScript Deobfuscator at Google","summary":"Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.","authors":["Shan Jiang","Pranoy Kovuri","David Tao","Zhixun Tan"],"pdf_url":"","comment":"To appear in 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE-SEIP '26)"}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2602.22187v1","updated":"2026-02-25T18:32:42Z","published":"2026-02-25T18:32:42Z","title":"UC-Secure Star DKG for Non-Exportable Key Shares with VSS-Free Enforcement","summary":"Distributed Key Generation (DKG) lets parties derive a common public key while keeping the signing key secret-shared. UC-secure DKG requires a verifiable-sharing enforcement layer -- classically satisfied via Verifiable Secret Sharing (VSS) and/or commitment-and-proof mechanisms -- for secrecy, uniqueness, and affine consistency. We target the Non-eXportable Key (NXK) setting enforced by hardware-backed key-isolation modules (e.g., TEEs, HSM-like APIs), formalized via an ideal KeyBox (keystore) functionality $\\mathcal{F}_{KeyBox}$ that keeps shares non-exportable and permits only attested KeyBox-to-KeyBox sealing. With confidentiality delegated to the NXK boundary, the remaining challenge is enforcing transcript-defined affine consistency without exporting or resharing shares. State continuity rules out rewinding-based extraction, mandating straight-line techniques.\n  We combine (i) KeyBox confidentiality; (ii) Unique Structure Verification (USV), a publicly verifiable certificate whose certified scalar never leaves the KeyBox yet whose public group element is transcript-derivable; and (iii) Fischlin-based UC-extractable NIZK arguments of knowledge in a gRO-CRP (global Random Oracle with Context-Restricted Programmability) model. We construct Star DKG (SDKG), a UC-secure scheme for multi-device threshold wallets where a designated service must co-sign but cannot sign alone, realizing a 1+1-out-of-$n$ star access structure (center plus any leaf) over roles (primary vs. recovery) with role-based device registration. In the $\\mathcal{F}_{KeyBox}$-hybrid and gRO-CRP models, under DL and DDH assumptions with adaptive corruptions and secure erasures, SDKG UC-realizes a transcript-driven refinement of the standard UC-DKG functionality. Over a prime-order group of size $p$, SDKG incurs $\\widetilde{O}(n\\log p)$ communication overhead and $\\widetilde{O}(n\\log^{2.585}p)$ bit-operation cost.","authors":["Vipin Singh Sehrawat"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20156v3","updated":"2026-02-25T18:14:01Z","published":"2026-02-23T18:59:27Z","title":"Skill-Inject: Measuring Agent Vulnerability to Skill File Attacks","summary":"LLM agents are evolving rapidly, powered by code execution, tools, and the recently introduced agent skills feature. Skills allow users to extend LLM applications with specialized third-party code, knowledge, and instructions. Although this can extend agent capabilities to new domains, it creates an increasingly complex agent supply chain, offering new surfaces for prompt injection attacks. We identify skill-based prompt injection as a significant threat and introduce SkillInject, a benchmark evaluating the susceptibility of widely-used LLM agents to injections through skill files. SkillInject contains 202 injection-task pairs with attacks ranging from obviously malicious injections to subtle, context-dependent attacks hidden in otherwise legitimate instructions. We evaluate frontier LLMs on SkillInject, measuring both security in terms of harmful instruction avoidance and utility in terms of legitimate instruction compliance. Our results show that today's agents are highly vulnerable with up to 80% attack success rate with frontier models, often executing extremely harmful instructions including data exfiltration, destructive action, and ransomware-like behavior. They furthermore suggest that this problem will not be solved through model scaling or simple input filtering, but that robust agent security will require context-aware authorization frameworks. Our benchmark is available at https://www.skill-inject.com/.","authors":["David Schmotz","Luca Beurer-Kellner","Sahar Abdelnabi","Maksym Andriushchenko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.19881v3","updated":"2026-02-25T18:06:46Z","published":"2025-06-23T20:46:51Z","title":"Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models","summary":"Are there any conditions under which a generative model's outputs are guaranteed not to infringe the copyrights of its training data? This is the question of \"provable copyright protection\" first posed by Vyas, Kakade, and Barak (ICML 2023). They define near access-freeness (NAF) and propose it as sufficient for protection. This paper revisits the question and establishes new foundations for provable copyright protection -- foundations that are firmer both technically and legally. First, we show that NAF alone does not prevent infringement. In fact, NAF models can enable verbatim copying, a blatant failure of copyright protection that we dub being tainted. Then, we introduce our blameless copyright protection framework for defining meaningful guarantees, and instantiate it with clean-room copyright protection. Clean-room copyright protection allows a user to control their risk of copying by behaving in a way that is unlikely to copy in a counterfactual \"clean-room setting.\" Finally, we formalize a common intuition about differential privacy and copyright by proving that DP implies clean-room copyright protection when the dataset is golden, a copyright deduplication requirement.","authors":["Aloni Cohen"],"pdf_url":"","comment":"Appeared at NeurIPS 2025"},{"id":"http://arxiv.org/abs/2602.22134v1","updated":"2026-02-25T17:28:07Z","published":"2026-02-25T17:28:07Z","title":"Secure Semantic Communications via AI Defenses: Fundamentals, Solutions, and Future Directions","summary":"Semantic communication (SemCom) redefines wireless communication from reproducing symbols to transmitting task-relevant semantics. However, this AI-native architecture also introduces new vulnerabilities, as semantic failures may arise from adversarial perturbations to models, corrupted training data, desynchronized priors, or misaligned inference even when lower-layer transmission reliability and cryptographic protection remain intact. This survey provides a defense-centered and system-oriented synthesis of security in SemCom via AI defense. We analyze AI-centric threat models by consolidating existing studies and organizing attack surfaces across model-level, channel-realizable, knowledge-based, and networked inference vectors. Building on this foundation, we present a structured taxonomy of defense strategies organized by where semantic integrity can be compromised in SemCom systems despite correct symbol delivery, spanning semantic encoding, wireless transmission, knowledge integrity, and coordination among multiple agents. These categories correspond to distinct security failure modes, including representation fragility, channel-realizable manipulation, semantic prior poisoning or desynchronization, and adversarial propagation through distributed inference. We also examine security utility operating envelopes that capture tradeoffs among semantic fidelity, robustness, latency, and energy under realistic constraints, survey evaluation frameworks and representative applications, and identify open challenges in cross-layer composition and deployment-time certification. Overall, this survey offers a unified system-level perspective that enables readers to understand major threat and defense mechanisms in AI-native SemCom systems and to leverage emerging security techniques in the design and deployment of robust SemCom architectures for next-generation intelligent networks.","authors":["Lan Zhang","Chengsi Liang","Zeming Zhuang","Yao Sun","Fang Fang","Xiaoyong Yuan","Dusit Niyato"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22082v1","updated":"2026-02-25T16:31:27Z","published":"2026-02-25T16:31:27Z","title":"Enabling End-to-End APT Emulation in Industrial Environments: Design and Implementation of the SIMPLE-ICS Testbed","summary":"Research on Advanced Persistent Threats (APTs) in industrial environments requires experimental platforms that support realistic end-to-end attack emulation across converged enterprise IT, operational technology (OT), and Industrial Internet of Things (IIoT) networks. However, existing industrial cybersecurity testbeds typically focus on isolated IT or OT domains or single-stage attacks, limiting their suitability for studying multi-stage APT campaigns. This paper presents the design, implementation, and validation of SIMPLE-ICS, a virtualised industrial enterprise testbed that enables emulation of multi-stage APT campaigns across IT, OT, and IIoT environments. The testbed architecture is based on the Purdue Enterprise Reference Architecture, NIST SP 800-82, and IEC 62443 zoning principles and integrates enterprise services, industrial control protocols, and digital twin based process simulation. A systematic methodology inspired by the V model is used to derive architectural requirements, attack scenarios, and validation criteria. An APT campaign designed to mimic the BlackEnergy campaign is emulated using MITRE ATTACK techniques spanning initial enterprise compromise, credential abuse, lateral movement, OT network infiltration, and process manipulation. The testbed supports the synchronised collection of network traffic, host-level logs, and operational telemetry across all segments. The testbed is validated on multi-stage attack trace observability, logging completeness across IT, OT, and IIoT domains, and repeatable execution of APT campaigns. The SIMPLE-ICS testbed provides an experimental platform for studying end-to-end APT behaviours in industrial enterprise networks and for generating multi-source datasets to support future research on campaign-level detection and correlation methods.","authors":["Yogha Restu Pramadi","Theodoros Spyridopoulos","Vijay Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10625v3","updated":"2026-02-25T15:52:01Z","published":"2025-10-12T14:12:28Z","title":"ImpMIA: Leveraging Implicit Bias for Membership Inference Attack","summary":"Determining which data samples were used to train a model, known as Membership Inference Attack (MIA), is a well-studied and important problem with implications on data privacy. SotA methods (which are black-box attacks) rely on training many auxiliary reference models to imitate the behavior of the attacked model. As such, they rely on assumptions which rarely hold in real-world settings: (i) the attacker knows the training hyperparameters; (ii) all available non-training samples come from the same distribution as the training data; and (iii) the fraction of training data in the evaluation set is known. We show that removing these assumptions significantly harms the performance of black-box attacks. We introduce ImpMIA, a Membership Inference Attack that exploits the Implicit Bias of neural networks. Building on the maximum-margin implicit bias theory, ImpMIA uses the Karush-Kuhn-Tucker (KKT) optimality conditions to identify training samples -- those whose gradients most strongly reconstruct the trained model's parameters. Our approach is optimization-based, and requires NO training of reference-models, thus removing the need for any knowledge/assumptions regarding the attacked model's training procedure. While ImpMIA is a white-box attack (a setting which assumes access to model weights), this is becoming increasingly realistic given that many models are publicly available (e.g., via Hugging Face). ImpMIA achieves SotA performance compared to both black and white box attacks in settings where only the model weights are known, and a superset of the training data is available.","authors":["Yuval Golbari","Navve Wasserman","Gal Vardi","Michal Irani"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22037v1","updated":"2026-02-25T15:45:27Z","published":"2026-02-25T15:45:27Z","title":"A Critical Look into Threshold Homomorphic Encryption for Private Average Aggregation","summary":"Threshold Homomorphic Encryption (Threshold HE) is a good fit for implementing private federated average aggregation, a key operation in Federated Learning (FL). Despite its potential, recent studies have shown that threshold schemes available in mainstream HE libraries can introduce unexpected security vulnerabilities if an adversary has access to a restricted decryption oracle. This oracle reflects the FL clients' capacity to collaboratively decrypt the aggregated result without knowing the secret key. This work surveys the use of threshold RLWE-based HE for federated average aggregation and examines the performance impact of using smudging noise with a large variance as a countermeasure. We provide a detailed comparison of threshold variants of BFV and CKKS, finding that CKKS-based aggregations perform comparably to BFV-based solutions.","authors":["Miguel Morona-Mínguez","Alberto Pedrouzo-Ulloa","Fernando Pérez-González"],"pdf_url":"","comment":"This is the author-submitted version (preprint) of a paper published in the Proceedings of the 2nd IEEE International Conference on Federated Learning Technologies and Applications (FLTA 2024). The final version is available in IEEE Xplore: https://doi.org/10.1109/FLTA63145.2024.10840167"},{"id":"http://arxiv.org/abs/2602.05674v2","updated":"2026-02-25T14:10:20Z","published":"2026-02-05T13:57:56Z","title":"Fast Private Adaptive Query Answering for Large Data Domains","summary":"Privately releasing marginals of a tabular dataset is a foundational problem in differential privacy. However, state-of-the-art mechanisms suffer from a computational bottleneck when marginal estimates are reconstructed from noisy measurements. Recently, residual queries were introduced and shown to lead to highly efficient reconstruction in the batch query answering setting. We introduce new techniques to integrate residual queries into state-of-the-art adaptive mechanisms such as AIM. Our contributions include a novel conceptual framework for residual queries using multi-dimensional arrays, lazy updating strategies, and adaptive optimization of the per-round privacy budget allocation. Together these contributions reduce error, improve speed, and simplify residual query operations. We integrate these innovations into a new mechanism (AIM+GReM), which improves AIM by using fast residual-based reconstruction instead of a graphical model approach. Our mechanism is orders of magnitude faster than the original framework and demonstrates competitive error and greatly improved scalability.","authors":["Miguel Fuentes","Brett Mullins","Yingtai Xiao","Daniel Kifer","Cameron Musco","Daniel Sheldon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21892v1","updated":"2026-02-25T13:21:06Z","published":"2026-02-25T13:21:06Z","title":"APFuzz: Towards Automatic Greybox Protocol Fuzzing","summary":"Greybox protocol fuzzing is a random testing approach for stateful protocol implementations, where the input is protocol messages generated from mutations of seeds, and the search in the input space is driven by the feedback on coverage of both code and state. State model and message model are the core components of communication protocols, which also have significant impacts on protocol fuzzing. In this work, we propose APFuzz (Automatic greybox Protocol Fuzzer) with novel designs to increase the smartness of greybox protocol fuzzers from the perspectives of both the state model and the message model. On the one hand, APFuzz employs a two-stage process of static and dynamic analysis to automatically identify state variables, which are then used to infer an accurate state model during fuzzing. On the other hand, APFuzz introduces field-level mutation operations for binary protocols, leveraging message structure awareness enabled by Large Language Models. We conduct extensive experiments on a public protocol fuzzing benchmark, comparing APFuzz with the baseline fuzzer AFLNET as well as several state-of-the-art greybox protocol fuzzers.","authors":["Yu Wang","Yang Xiang","Chandra Thapa","Hajime Suzuki"],"pdf_url":"","comment":"12 pages, 4 figures, 9 tables"},{"id":"http://arxiv.org/abs/2602.21841v1","updated":"2026-02-25T12:20:47Z","published":"2026-02-25T12:20:47Z","title":"Resilient Federated Chain: Transforming Blockchain Consensus into an Active Defense Layer for Federated Learning","summary":"Federated Learning (FL) has emerged as a key paradigm for building Trustworthy AI systems by enabling privacy-preserving, decentralized model training. However, FL is highly susceptible to adversarial attacks that compromise model integrity and data confidentiality, a vulnerability exacerbated by the fact that conventional data inspection methods are incompatible with its decentralized design. While integrating FL with Blockchain technology has been proposed to address some limitations, its potential for mitigating adversarial attacks remains largely unexplored. This paper introduces Resilient Federated Chain (RFC), a novel blockchain-enabled FL framework designed specifically to enhance resilience against such threats. RFC builds upon the existing Proof of Federated Learning architecture by repurposing the redundancy of its Pooled Mining mechanism as an active defense layer that can be combined with robust aggregation rules. Furthermore, the framework introduces a flexible evaluation function in its consensus mechanism, allowing for adaptive defense against different attack strategies. Extensive experimental evaluation on image classification tasks under various adversarial scenarios, demonstrates that RFC significantly improves robustness compared to baseline methods, providing a viable solution for securing decentralized learning environments.","authors":["Mario García-Márquez","Nuria Rodríguez-Barroso","M. Victoria Luzón","Francisco Herrera"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2602.21826v1","updated":"2026-02-25T11:54:46Z","published":"2026-02-25T11:54:46Z","title":"The Silent Spill: Measuring Sensitive Data Leaks Across Public URL Repositories","summary":"A large number of URLs are made public by various platforms for security analysis, archiving, and paste sharing -- such as VirusTotal, URLScan.io, Hybrid Analysis, the Wayback Machine, and RedHunt. These services may unintentionally expose links containing sensitive information, as reported in some news articles and blog posts. However, no large-scale measurement has quantified the extent of such exposures. We present an automated system that detects and analyzes potential sensitive information leaked through publicly accessible URLs. The system combines lexical URL filtering, dynamic rendering, OCR-based extraction, and content classification to identify potential leaks. We apply it to 6,094,475 URLs collected from public scanning platforms, paste sites, and web archives, identifying 12,331 potential exposures across authentication, financial, personal, and document-related domains. These findings show that sensitive information remains exposed, underscoring the importance of automated detection to identify accidental leaks.","authors":["Tarek Ramadan","AbdelRahman Abdou","Mohammad Mannan","Amr Youssef"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21794v1","updated":"2026-02-25T11:17:42Z","published":"2026-02-25T11:17:42Z","title":"MulCovFuzz: A Multi-Component Coverage-Guided Greybox Fuzzer for 5G Protocol Testing","summary":"As mobile networks transition to 5G infrastructure, ensuring robust security becomes more important due to the complex architecture and expanded attack surface. Traditional security testing approaches for 5G networks rely on black-box fuzzing techniques, which are limited by their inability to observe internal program state and coverage information. This paper presents MulCovFuzz, a novel coverage-guided greybox fuzzing tool for 5G network testing. Unlike existing tools that depend solely on system response, MulCovFuzz implements a multi-component coverage collection mechanism that dynamically monitors code coverage across different components of the 5G system architecture. Our approach introduces a novel testing paradigm that includes a scoring function combining coverage rewards with efficiency metrics to guide test case generation. We evaluate MulCovFuzz on open-source 5G implementation OpenAirInterface. Our experimental results demonstrate that MulCovFuzz significantly outperforms traditional fuzzing approaches, achieving a 5.85\\% increase in branch coverage, 7.17\\% increase in line coverage, and 16\\% improvement in unique crash discovery during 24h fuzzing testing. MulCovFuzz uncovered three zero-day vulnerabilities, two of which were not identified by any other fuzzing technique. This work contributes to the advancement of security testing tools for next-generation mobile networks.","authors":["Yu Wang","Yang Xiang","Chandra Thapa","Hajime Suzuki"],"pdf_url":"","comment":"11 pages, 5 figures, 1 table"},{"id":"http://arxiv.org/abs/2501.08449v2","updated":"2026-02-25T10:50:54Z","published":"2025-01-14T21:38:01Z","title":"A Refreshment Stirred, Not Shaken: Invariant-Preserving Deployments of Differential Privacy for the U.S. Decennial Census","summary":"Protecting an individual's privacy when releasing their data is inherently an exercise in relativity, regardless of how privacy is qualified or quantified. This is because we can only limit the gain in information about an individual relative to what could be derived from other sources. This framing is the essence of differential privacy (DP), through which this article examines two statistical disclosure control (SDC) methods for the United States Decennial Census: the Permutation Swapping Algorithm (PSA), which resembles the 2010 Census's disclosure avoidance system (DAS), and the TopDown Algorithm (TDA), which was used in the 2020 DAS. To varying degrees, both methods leave unaltered certain statistics of the confidential data (their invariants) and hence neither can be readily reconciled with DP, at least as originally conceived. Nevertheless, we show how invariants can naturally be integrated into DP and use this to establish that the PSA satisfies pure DP subject to the invariants it necessarily induces, thereby proving that this traditional SDC method can, in fact, be understood from the perspective of DP. By a similar modification to zero-concentrated DP, we also provide a DP specification for the TDA. Finally, as a point of comparison, we consider a counterfactual scenario in which the PSA was adopted for the 2020 Census, resulting in a reduction in the nominal protection loss budget but at the cost of releasing many more invariants. This highlights the pervasive danger of comparing budgets without accounting for the other dimensions on which DP formulations vary (such as the invariants they permit). Therefore, while our results articulate the mathematical guarantees of SDC provided by the PSA, the TDA, and the 2020 DAS in general, care must be taken in translating these guarantees into actual privacy protection$\\unicode{x2014}$just as is the case for any DP deployment.","authors":["James Bailie","Ruobin Gong","Xiao-Li Meng"],"pdf_url":"","comment":"65 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.05066v2","updated":"2026-02-25T10:09:46Z","published":"2026-02-04T21:38:38Z","title":"Bypassing AI Control Protocols via Agent-as-a-Proxy Attacks","summary":"As AI agents automate critical workloads, they remain vulnerable to indirect prompt injection (IPI) attacks. Current defenses rely on monitoring protocols that jointly evaluate an agent's Chain-of-Thought (CoT) and tool-use actions to ensure alignment with user intent. We demonstrate that these monitoring-based defenses can be bypassed via a novel Agent-as-a-Proxy attack, where prompt injection attacks treat the agent as a delivery mechanism, bypassing both agent and monitor simultaneously. While prior work on scalable oversight has focused on whether small monitors can supervise large agents, we show that even frontier-scale monitors are vulnerable. Large-scale monitoring models like Qwen2.5-72B can be bypassed by agents with similar capabilities, such as GPT-4o mini and Llama-3.1-70B. On the AgentDojo benchmark, we achieve a high attack success rate against AlignmentCheck and Extract-and-Evaluate monitors under diverse monitoring LLMs. Our findings suggest current monitoring-based agentic defenses are fundamentally fragile regardless of model scale.","authors":["Jafar Isbarov","Murat Kantarcioglu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21737v1","updated":"2026-02-25T09:46:57Z","published":"2026-02-25T09:46:57Z","title":"Implementation and transition to post-quantum cryptography of the Minimal IKE protocol","summary":"This paper concerns the Minimal Internet Key Exchange (IKE) protocol, which has received little attention to date, despite its potential to make the best-known IKE protocol sufficiently lightweight to be also applied in contexts where it is currently prohibitive, due to its large footprint. First, we introduce and describe Colibri, an efficient, open-source implementation of the Minimal IKE protocol, which allows us to quantitatively assess its real advantages in terms of lightness. Then we introduce a post-quantum variant of the Minimal IKE protocol, which is essential to make it contemporary, and assess it through Colibri. We demonstrate that the protocol performance remains excellent even in such a more challenging context, making it suitable for deploying pervasive and quantum-resistant virtual private networks.","authors":["Davide De Zuane","Paolo Santini","Marco Baldi"],"pdf_url":"","comment":"To be presented at the IEEE International Conference on Communications (ICC) 2026"},{"id":"http://arxiv.org/abs/2602.21721v1","updated":"2026-02-25T09:27:40Z","published":"2026-02-25T09:27:40Z","title":"Private and Robust Contribution Evaluation in Federated Learning","summary":"Cross-silo federated learning allows multiple organizations to collaboratively train machine learning models without sharing raw data, but client updates can still leak sensitive information through inference attacks. Secure aggregation protects privacy by hiding individual updates, yet it complicates contribution evaluation, which is critical for fair rewards and detecting low-quality or malicious participants. Existing marginal-contribution methods, such as the Shapley value, are incompatible with secure aggregation, and practical alternatives, such as Leave-One-Out, are crude and rely on self-evaluation.\n  We introduce two marginal-difference contribution scores compatible with secure aggregation. Fair-Private satisfies standard fairness axioms, while Everybody-Else eliminates self-evaluation and provides resistance to manipulation, addressing a largely overlooked vulnerability. We provide theoretical guarantees for fairness, privacy, robustness, and computational efficiency, and evaluate our methods on multiple medical image datasets and CIFAR10 in cross-silo settings. Our scores consistently outperform existing baselines, better approximate Shapley-induced client rankings, and improve downstream model performance as well as misbehavior detection. These results demonstrate that fairness, privacy, robustness, and practical utility can be achieved jointly in federated contribution evaluation, offering a principled solution for real-world cross-silo deployments.","authors":["Delio Jaramillo Velez","Gergely Biczok","Alexandre Graell i Amat","Johan Ostman","Balazs Pejo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.21540v2","updated":"2026-02-25T08:16:45Z","published":"2025-07-29T07:13:56Z","title":"PRISM: Programmatic Reasoning with Image Sequence Manipulation for LVLM Jailbreaking","summary":"The increasing sophistication of large vision-language models (LVLMs) has been accompanied by advances in safety alignment mechanisms designed to prevent harmful content generation. However, these defenses remain vulnerable to sophisticated adversarial attacks. Existing jailbreak methods typically rely on direct and semantically explicit prompts, overlooking subtle vulnerabilities in how LVLMs compose information over multiple reasoning steps. In this paper, we propose a novel and effective jailbreak framework inspired by Return-Oriented Programming (ROP) techniques from software security. Our approach decomposes a harmful instruction into a sequence of individually benign visual gadgets. A carefully engineered textual prompt directs the sequence of inputs, prompting the model to integrate the benign visual gadgets through its reasoning process to produce a coherent and harmful output. This makes the malicious intent emergent and difficult to detect from any single component. We validate our method through extensive experiments on established benchmarks including SafeBench and MM-SafetyBench, targeting popular LVLMs. Results show that our approach consistently and substantially outperforms existing baselines on state-of-the-art models, achieving near-perfect attack success rates (over 0.90 on SafeBench) and improving ASR by up to 0.39. Our findings reveal a critical and underexplored vulnerability that exploits the compositional reasoning abilities of LVLMs, highlighting the urgent need for defenses that secure the entire reasoning process.","authors":["Quanchen Zou","Zonghao Ying","Moyang Chen","Wenzhuo Xu","Yisong Xiao","Yakai Li","Deyue Zhang","Dongdong Yang","Zhao Liu","Xiangzheng Zhang"],"pdf_url":"","comment":"There is an error happening in Figure 1, because Figure 1 did not perfectly show the exact overview of the PRISM pipeline"},{"id":"http://arxiv.org/abs/2506.06226v2","updated":"2026-02-25T07:54:34Z","published":"2025-06-06T16:41:17Z","title":"No Data? No Problem: Synthesizing Security Graphs for Better Intrusion Detection","summary":"Provenance graph analysis plays a vital role in intrusion detection, particularly against Advanced Persistent Threats (APTs), by exposing complex attack patterns. While recent systems combine graph neural networks (GNNs) with natural language processing (NLP) to capture structural and semantic features, their effectiveness is limited by class imbalance in real-world data. To address this, we introduce PROVSYN, a novel hybrid provenance graph synthesis framework, which comprises three components: (1) graph structure synthesis via heterogeneous graph generation models, (2) textual attribute synthesis via fine-tuned Large Language Models (LLMs), and (3) five-dimensional fidelity evaluation. Experiments on six benchmark datasets demonstrate that PROVSYN consistently produces higher-fidelity graphs across the five evaluation dimensions compared to four strong baselines. To further demonstrate the practical utility of PROVSYN, we utilize the synthesized graphs to augment training datasets for downstream APT detection models. The results show that PROVSYN effectively mitigates data imbalance, improving normalized entropy by up to 35%, and enhances the generalizability of downstream detection models, achieving an accuracy improvement of up to 38%.","authors":["Yi Huang","Shaofei Li","Yao Guo","Xiangqun Chen","Ding Li","Wajih Ul Hassan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.15524v9","updated":"2026-02-25T07:50:07Z","published":"2024-07-22T10:23:44Z","title":"Minimal Cascade Gradient Smoothing for Fast Transferable Preemptive Adversarial Defense","summary":"Adversarial attacks persist as a major challenge in deep learning. While training- and test-time defenses are well-studied, they often reduce clean accuracy, incur high cost, or fail under adaptive threats. In contrast, preemptive defenses, which perturb media before release, offer a practical alternative but remain slow, model-coupled, and brittle. We propose the Minimal Sufficient Preemptive Defense (MSPD), a fast, transferable framework that defends against future attacks without access to the target model or gradients. MSPD is driven by Minimal Cascade Gradient Smoothing (MCGS), a two-epoch optimization paradigm executed on a surrogate backbone. This defines a minimal yet effective regime for robust generalization across unseen models and attacks. MSPD runs at 0.02s/image (CIFAR-10) and 0.26s/image (ImageNet), 28--1696 times faster than prior preemptive methods, while improving robust accuracy by +5% and clean accuracy by +3.7% across 11 models and 7 attacks. To evaluate adaptive robustness, we introduce Preemptive Reversion, the first white-box diagnostic attack that cancels preemptive perturbations under full gradient access. Even in this setting, MSPD retains a +2.2% robustness margin over the baseline. In practice, when gradients are unavailable, MSPD remains reliable and efficient. MSPD, MCGS, and Preemptive Reversion are each supported by formal theoretical proofs. The implementation is available at https://github.com/azrealwang/MSPD.","authors":["Hanrui Wang","Ching-Chun Chang","Chun-Shien Lu","Ching-Chia Kao","Shuo Wang","Isao Echizen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21630v1","updated":"2026-02-25T06:50:51Z","published":"2026-02-25T06:50:51Z","title":"Type-Based Enforcement of Non-Interference for Choreographic Programming","summary":"Choreographies describe distributed protocols from a global viewpoint, enabling correct-by-construction synthesis of local behaviours. We develop a policy-parametric type system that prevents information leaks from high-security data to low-security observers, handling both explicit and implicit flows through a program-counter discipline. The system supports recursive procedures via a procedure context that we reconstruct through constraint generation. We prove termination-insensitive non-interference with respect to a standard small-step semantics.","authors":["Marco Bertoni","Saverio Giallorenzo","Marco Peressotti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.20917v5","updated":"2026-02-25T05:54:48Z","published":"2026-01-28T18:13:47Z","title":"FIPS 204-Compatible Threshold ML-DSA via Shamir Nonce DKG","summary":"We present the first threshold ML-DSA (FIPS 204) scheme achieving statistical share privacy (no computational assumptions) with arbitrary thresholds, while producing standard 3.3 KB signatures verifiable by unmodified implementations. Our primary technique, Shamir nonce DKG, jointly generates the signing nonce so that both the nonce and the long-term secret are degree-(T-1) Shamir sharings. This gives the honest party's nonce share conditional min-entropy exceeding 5x the secret-key entropy for signing sets of size at most 17. In coordinator-based profiles (P1, P3+), this removes the two-honest requirement (it suffices that the signing set size is at least T); in the fully distributed profile (P2), we additionally require at least two non-coordinator honest parties for mask-hiding. Key privacy of the aggregate signature relies on the same lattice hardness as single-signer ML-DSA (an open problem in the literature). As a secondary technique, pairwise-canceling masks handle three challenges unique to lattice-based threshold signing: the infinity-norm rejection check on z, secure r0-check evaluation without leaking cs2, and EUF-CMA security under the resulting Irwin-Hall nonce distribution. A direct shift-invariance analysis gives per-session loss below 0.013 bits (below 0.007 bits when the signing set size is at most 17); over qs signing sessions the total loss is below 0.013qs bits, eliminating the scalability gap in prior work. We give three deployment profiles with complete UC proofs: P1 (TEE, 5.8 ms for 3-of-5), P2 (MPC, 5 rounds, 22 ms), and P3+ (2PC semi-async, 22 ms). Our Rust implementation supports thresholds from 2-of-3 to 32-of-45 with sub-100 ms latency and about 21-45 percent success rates.","authors":["Leo Kao"],"pdf_url":"","comment":"102 pages, includes complete UC proofs (Profiles P1/P2/P3+), Rust implementation and benchmarks"},{"id":"http://arxiv.org/abs/2602.21593v1","updated":"2026-02-25T05:38:08Z","published":"2026-02-25T05:38:08Z","title":"Breaking Semantic-Aware Watermarks via LLM-Guided Coherence-Preserving Semantic Injection","summary":"Generative images have proliferated on Web platforms in social media and online copyright distribution scenarios, and semantic watermarking has increasingly been integrated into diffusion models to support reliable provenance tracking and forgery prevention for web content. Traditional noise-layer-based watermarking, however, remains vulnerable to inversion attacks that can recover embedded signals. To mitigate this, recent content-aware semantic watermarking schemes bind watermark signals to high-level image semantics, constraining local edits that would otherwise disrupt global coherence. Yet, large language models (LLMs) possess structured reasoning capabilities that enable targeted exploration of semantic spaces, allowing locally fine-grained but globally coherent semantic alterations that invalidate such bindings. To expose this overlooked vulnerability, we introduce a Coherence-Preserving Semantic Injection (CSI) attack that leverages LLM-guided semantic manipulation under embedding-space similarity constraints. This alignment enforces visual-semantic consistency while selectively perturbing watermark-relevant semantics, ultimately inducing detector misclassification. Extensive empirical results show that CSI consistently outperforms prevailing attack baselines against content-aware semantic watermarking, revealing a fundamental security weakness of current semantic watermark designs when confronted with LLM-driven semantic perturbations.","authors":["Zheng Gao","Xiaoyu Li","Zhicheng Bao","Xiaoyan Feng","Jiaojiao Jiang"],"pdf_url":"","comment":"Accepted by The Web Conference 2026 (Short Paper Track)"},{"id":"http://arxiv.org/abs/2507.17691v2","updated":"2026-02-25T04:00:38Z","published":"2025-07-23T16:57:32Z","title":"CASCADE: LLM-Powered JavaScript Deobfuscator at Google","summary":"Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.","authors":["Shan Jiang","Pranoy Kovuri","David Tao","Zhixun Tan"],"pdf_url":"","comment":"To appear in ICSE-SEIP 2026"},{"id":"http://arxiv.org/abs/2602.21529v1","updated":"2026-02-25T03:32:28Z","published":"2026-02-25T03:32:28Z","title":"TM-RUGPULL: A Temporary Sound, Multimodal Dataset for Early Detection of RUG Pulls Across the Tokenized Ecosystem","summary":"Rug-pull attacks pose a systemic threat across the blockchain ecosystem, yet research into early detection is hindered by the lack of scientific-grade datasets. Existing resources often suffer from temporal data leakage, narrow modality, and ambiguous labeling, particularly outside DeFi contexts. To address these limitations, we present TM-RugPull, a rigorously curated, leakage-resistant dataset of 1,028 token projects spanning DeFi, meme coins, NFTs, and celebrity-themed tokens. RugPull enforces strict temporal hygiene by extracting all features on chain behavior, smart contract metadata, and OSINT signals strictly from the first half of each project's lifespan. Labels are grounded in forensic reports and longevity criteria, verified through multi-expert consensus. This dataset enables causally valid, multimodal analysis of rug-pull dynamics and establishes a new benchmark for reproducible fraud detection research.","authors":["Fatemeh Shoaei","Mohammad Pishdar","Mozafar Bag-Mohammadi","Mojtaba Karami"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21524v1","updated":"2026-02-25T03:26:09Z","published":"2026-02-25T03:26:09Z","title":"Quantum Attacks Targeting Nuclear Power Plants: Threat Analysis, Defense and Mitigation Strategies","summary":"The advent of Cryptographically Relevant Quantum Computers (CRQCs) presents a fundamental and existential threat to the forensic integrity and operational safety of Industrial Control Systems (ICS) and Operational Technology (OT) in critical infrastructure. This paper introduces a novel, forensics-first framework for achieving quantum resilience in high-consequence environments, with a specific focus on nuclear power plants. We systematically analyze the quantum threat landscape across the Purdue architecture (L0-L5), detailing how Harvest-Now, Decrypt-Later (HNDL) campaigns, enabled by algorithms like Shor's, can retroactively compromise cryptographic foundations, undermine evidence admissibility, and facilitate sophisticated sabotage. Through two detailed case studies, \\textsc{Quantum~Scar} and \\textsc{Quantum~Dawn}, we demonstrate multi-phase attack methodologies where state-level adversaries exploit cryptographic monoculture and extended OT lifecycles to degrade safety systems while creating unsolvable forensic paradoxes. Our probabilistic risk modeling reveals alarming success probabilities (up to 78\\% for targeted facilities under current defenses), underscoring the criticality of immediate action. In response, we propose and validate a phased, defense-in-depth migration path to Post-Quantum Cryptography (PQC), integrating hybrid key exchange, cryptographic diversity, secure time synchronization, and side-channel resistant implementations aligned with ISA/IEC 62443 and NIST standards. The paper concludes that without urgent adoption of quantum-resilient controls, the integrity of both physical safety systems and digital forensic evidence remains at severe and irreversible risk.","authors":["Yaser Baseri","Edward Waller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21508v1","updated":"2026-02-25T02:38:17Z","published":"2026-02-25T02:38:17Z","title":"WaterVIB: Learning Minimal Sufficient Watermark Representations via Variational Information Bottleneck","summary":"Robust watermarking is critical for intellectual property protection, whereas existing methods face a severe vulnerability against regeneration-based AIGC attacks. We identify that existing methods fail because they entangle the watermark with high-frequency cover texture, which is susceptible to being rewritten during generative purification. To address this, we propose WaterVIB, a theoretically grounded framework that reformulates the encoder as an information sieve via the Variational Information Bottleneck. Instead of overfitting to fragile cover details, our approach forces the model to learn a Minimal Sufficient Statistic of the message. This effectively filters out redundant cover nuances prone to generative shifts, retaining only the essential signal invariant to regeneration. We theoretically prove that optimizing this bottleneck is a necessary condition for robustness against distribution-shifting attacks. Extensive experiments demonstrate that WaterVIB significantly outperforms state-of-the-art methods, achieving superior zero-shot resilience against unknown diffusion-based editing.","authors":["Haoyuan He","Yu Zheng","Jie Zhou","Jiwen Lu"],"pdf_url":"","comment":"22 pages, 7 figures. Preprint"},{"id":"http://arxiv.org/abs/2602.21459v1","updated":"2026-02-25T00:23:50Z","published":"2026-02-25T00:23:50Z","title":"Regular Expression Denial of Service Induced by Backreferences","summary":"This paper presents the first systematic study of denial-of-service vulnerabilities in Regular Expressions with Backreferences (REwB). We introduce the Two-Phase Memory Automaton (2PMFA), an automaton model that precisely captures REwB semantics. Using this model, we derive necessary conditions under which backreferences induce super-linear backtracking runtime, even when sink ambiguity is linear -- a regime where existing detectors report no vulnerability. Based on these conditions, we identify three vulnerability patterns, develop detection and attack-construction algorithms, and validate them in practice. Using the Snort intrusion detection ruleset, our evaluation identifies 45 previously unknown REwB vulnerabilities with quadratic or worse runtime. We further demonstrate practical exploits against Snort, including slowing rule evaluation by 0.6-1.2 seconds and bypassing alerts by triggering PCRE's matching limit.","authors":["Yichen Liu","Berk Çakar","Aman Agrawal","Minseok Seo","James C. Davis","Dongyoon Lee"],"pdf_url":"","comment":"24 pages, 8 figures. Submitted to USENIX Security 2026. For the code repository of detector, see https://anonymous.4open.science/r/slmad-EABE. For the code repository of measurements, see https://anonymous.4open.science/r/atkre-7D50"},{"id":"http://arxiv.org/abs/2602.22488v1","updated":"2026-02-25T23:56:11Z","published":"2026-02-25T23:56:11Z","title":"Explainability-Aware Evaluation of Transfer Learning Models for IoT DDoS Detection Under Resource Constraints","summary":"Distributed denial-of-service (DDoS) attacks threaten the availability of Internet of Things (IoT) infrastructures, particularly under resource-constrained deployment conditions. Although transfer learning models have shown promising detection accuracy, their reliability, computational feasibility, and interpretability in operational environments remain insufficiently explored. This study presents an explainability-aware empirical evaluation of seven pre-trained convolutional neural network architectures for multi-class IoT DDoS detection using the CICDDoS2019 dataset and an image-based traffic representation. The analysis integrates performance metrics, reliability-oriented statistics (MCC, Youden Index, confidence intervals), latency and training cost assessment, and interpretability evaluation using Grad-CAM and SHAP. Results indicate that DenseNet and MobileNet-based architectures achieve strong detection performance while demonstrating superior reliability and compact, class-consistent attribution patterns. DenseNet169 offers the strongest reliability and interpretability alignment, whereas MobileNetV3 provides an effective latency-accuracy trade-off for fog-level deployment. The findings emphasize the importance of combining performance, reliability, and explainability criteria when selecting deep learning models for IoT DDoS detection.","authors":["Nelly Elsayed"],"pdf_url":"","comment":"24 pages, under review"},{"id":"http://arxiv.org/abs/2602.22470v1","updated":"2026-02-25T23:10:13Z","published":"2026-02-25T23:10:13Z","title":"Beyond performance-wise Contribution Evaluation in Federated Learning","summary":"Federated learning offers a privacy-friendly collaborative learning framework, yet its success, like any joint venture, hinges on the contributions of its participants. Existing client evaluation methods predominantly focus on model performance, such as accuracy or loss, which represents only one dimension of a machine learning model's overall utility. In contrast, this work investigates the critical, yet overlooked, issue of client contributions towards a model's trustworthiness -- specifically, its reliability (tolerance to noisy data), resilience (resistance to adversarial examples), and fairness (measured via demographic parity). To quantify these multifaceted contributions, we employ the state-of-the-art approximation of the Shapley value, a principled method for value attribution. Our results reveal that no single client excels across all dimensions, which are largely independent from each other, highlighting a critical flaw in current evaluation scheme: no single metric is adequate for comprehensive evaluation and equitable rewarding allocation.","authors":["Balazs Pejo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22450v1","updated":"2026-02-25T22:26:23Z","published":"2026-02-25T22:26:23Z","title":"Silent Egress: When Implicit Prompt Injection Makes LLM Agents Leak Without a Trace","summary":"Agentic large language model systems increasingly automate tasks by retrieving URLs and calling external tools. We show that this workflow gives rise to implicit prompt injection: adversarial instructions embedded in automatically generated URL previews, including titles, metadata, and snippets, can introduce a system-level risk that we refer to as silent egress. Using a fully local and reproducible testbed, we demonstrate that a malicious web page can induce an agent to issue outbound requests that exfiltrate sensitive runtime context, even when the final response shown to the user appears harmless. In 480 experimental runs with a qwen2.5:7b-based agent, the attack succeeds with high probability (P (egress) =0.89), and 95% of successful attacks are not detected by output-based safety checks. We also introduce sharded exfiltration, where sensitive information is split across multiple requests to avoid detection. This strategy reduces single-request leakage metrics by 73% (Leak@1) and bypasses simple data loss prevention mechanisms. Our ablation results indicate that defenses applied at the prompt layer offer limited protection, while controls at the system and network layers, such as domain allowlisting and redirect-chain analysis, are considerably more effective. These findings suggest that network egress should be treated as a first-class security outcome in agentic LLM systems. We outline architectural directions, including provenance tracking and capability isolation, that go beyond prompt-level hardening.","authors":["Qianlong Lan","Anuj Kaul","Shaun Jones","Stephanie Westrum"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22443v1","updated":"2026-02-25T22:06:29Z","published":"2026-02-25T22:06:29Z","title":"Differentially Private Data-Driven Markov Chain Modeling","summary":"Markov chains model a wide range of user behaviors. However, generating accurate Markov chain models requires substantial user data, and sharing these models without privacy protections may reveal sensitive information about the underlying user data. We introduce a method for protecting user data used to formulate a Markov chain model. First, we develop a method for privatizing database queries whose outputs are elements of the unit simplex, and we prove that this method is differentially private. We quantify its accuracy by bounding the expected KL divergence between private and non-private queries. We extend this method to privatize stochastic matrices whose rows are each a simplex-valued query of a database, which includes data-driven Markov chain models. To assess their accuracy, we analytically bound the change in the stationary distribution and the change in the convergence rate between a non-private Markov chain model and its private form. Simulations show that under a typical privacy implementation, our method yields less than 2% error in the stationary distribution, indicating that our approach to private modeling faithfully captures the behavior of the systems we study.","authors":["Alexander Benvenuti","Brandon Fallin","Calvin Hawkins","Brendan Bialy","Miriam Dennis","Warren Dixon","Matthew Hale"],"pdf_url":"","comment":"4 figures, 22 pages"},{"id":"http://arxiv.org/abs/2602.22433v1","updated":"2026-02-25T21:44:57Z","published":"2026-02-25T21:44:57Z","title":"Predicting Known Vulnerabilities from Attack Descriptions Using Sentence Transformers","summary":"Modern infrastructures rely on software systems that remain vulnerable to cyberattacks. These attacks frequently exploit vulnerabilities documented in repositories such as MITRE's Common Vulnerabilities and Exposures (CVE). However, Cyber Threat Intelligence resources, including MITRE ATT&CK and CVE, provide only partial coverage of attack-vulnerability relationships. Attack information often appears before vulnerabilities are formally linked, creating the need for automated methods that infer likely vulnerabilities directly from attack descriptions.\n  This thesis addresses the problem of predicting known vulnerabilities from natural-language descriptions of cyberattacks. We develop transformer-based sentence embedding methods that encode attack and vulnerability descriptions into semantic vector representations, enabling similarity-based ranking and recommendation.\n  Fourteen state-of-the-art transformer models were evaluated across four attack description types (Tactic, Technique, Procedure, and Attack Pattern). Results show that Technique descriptions in MITRE ATT&CK provide the strongest predictive signal. The multi-qa-mpnet-base-dot-v1 (MMPNet) model achieved the best performance due to its hybrid pre-training and optimization for semantic similarity.\n  The approach was implemented in the VULDAT tool, which automatically links attacks to vulnerabilities. Manual validation revealed previously undocumented relationships in MITRE repositories. Evaluation on unseen cyberattack reports demonstrates that the models generalize beyond curated datasets and support proactive vulnerability awareness.","authors":["Refat Othman"],"pdf_url":"","comment":"PhD thesis, Free University of Bozen-Bolzano, 2026"},{"id":"http://arxiv.org/abs/2602.22427v1","updated":"2026-02-25T21:37:53Z","published":"2026-02-25T21:37:53Z","title":"HubScan: Detecting Hubness Poisoning in Retrieval-Augmented Generation Systems","summary":"Retrieval-Augmented Generation (RAG) systems are essential to contemporary AI applications, allowing large language models to obtain external knowledge via vector similarity search. Nevertheless, these systems encounter a significant security flaw: hubness - items that frequently appear in the top-k retrieval results for a disproportionately high number of varied queries. These hubs can be exploited to introduce harmful content, alter search rankings, bypass content filtering, and decrease system performance.\n  We introduce hubscan, an open-source security scanner that evaluates vector indices and embeddings to identify hubs in RAG systems. Hubscan presents a multi-detector architecture that integrates: (1) robust statistical hubness detection utilizing median/MAD-based z-scores, (2) cluster spread analysis to assess cross-cluster retrieval patterns, (3) stability testing under query perturbations, and (4) domain-aware and modality-aware detection for category-specific and cross-modal attacks. Our solution accommodates several vector databases (FAISS, Pinecone, Qdrant, Weaviate) and offers versatile retrieval techniques, including vector similarity, hybrid search, and lexical matching with reranking capabilities.\n  We evaluate hubscan on Food-101, MS-COCO, and FiQA adversarial hubness benchmarks constructed using state-of-the-art gradient-optimized and centroid-based hub generation methods. hubscan achieves 90% recall at a 0.2% alert budget and 100% recall at 0.4%, with adversarial hubs ranking above the 99.8th percentile. Domain-scoped scanning recovers 100% of targeted attacks that evade global detection. Production validation on 1M real web documents from MS MARCO demonstrates significant score separation between clean documents and adversarial content. Our work provides a practical, extensible framework for detecting hubness threats in production RAG systems.","authors":["Idan Habler","Vineeth Sai Narajala","Stav Koren","Amy Chang","Tiffany Saade"],"pdf_url":"","comment":"11 pages, 5 figures, 2 tables, Github: https://github.com/cisco-ai-defense/adversarial-hubness-detector"},{"id":"http://arxiv.org/abs/2602.16800v2","updated":"2026-02-25T18:37:33Z","published":"2026-02-18T19:02:50Z","title":"Large-scale online deanonymization with LLMs","summary":"We show that large language models can be used to perform at-scale deanonymization. With full Internet access, our agent can re-identify Hacker News users and Anthropic Interviewer participants at high precision, given pseudonymous online profiles and conversations alone, matching what would take hours for a dedicated human investigator. We then design attacks for the closed-world setting. Given two databases of pseudonymous individuals, each containing unstructured text written by or about that individual, we implement a scalable attack pipeline that uses LLMs to: (1) extract identity-relevant features, (2) search for candidate matches via semantic embeddings, and (3) reason over top candidates to verify matches and reduce false positives. Compared to classical deanonymization work (e.g., on the Netflix prize) that required structured data, our approach works directly on raw user content across arbitrary platforms. We construct three datasets with known ground-truth data to evaluate our attacks. The first links Hacker News to LinkedIn profiles, using cross-platform references that appear in the profiles. Our second dataset matches users across Reddit movie discussion communities; and the third splits a single user's Reddit history in time to create two pseudonymous profiles to be matched. In each setting, LLM-based methods substantially outperform classical baselines, achieving up to 68% recall at 90% precision compared to near 0% for the best non-LLM method. Our results show that the practical obscurity protecting pseudonymous users online no longer holds and that threat models for online privacy need to be reconsidered.","authors":["Simon Lermen","Daniel Paleka","Joshua Swanson","Michael Aerni","Nicholas Carlini","Florian Tramèr"],"pdf_url":"","comment":"24 pages, 10 figures"},{"id":"http://arxiv.org/abs/2602.22291v1","updated":"2026-02-25T15:08:20Z","published":"2026-02-25T15:08:20Z","title":"Manifold of Failure: Behavioral Attraction Basins in Language Models","summary":"While prior work has focused on projecting adversarial examples back onto the manifold of natural data to restore safety, we argue that a comprehensive understanding of AI safety requires characterizing the unsafe regions themselves. This paper introduces a framework for systematically mapping the Manifold of Failure in Large Language Models (LLMs). We reframe the search for vulnerabilities as a quality diversity problem, using MAP-Elites to illuminate the continuous topology of these failure regions, which we term behavioral attraction basins. Our quality metric, Alignment Deviation, guides the search towards areas where the model's behavior diverges most from its intended alignment. Across three LLMs: Llama-3-8B, GPT-OSS-20B, and GPT-5-Mini, we show that MAP-Elites achieves up to 63% behavioral coverage, discovers up to 370 distinct vulnerability niches, and reveals dramatically different model-specific topological signatures: Llama-3-8B exhibits a near-universal vulnerability plateau (mean Alignment Deviation 0.93), GPT-OSS-20B shows a fragmented landscape with spatially concentrated basins (mean 0.73), and GPT-5-Mini demonstrates strong robustness with a ceiling at 0.50. Our approach produces interpretable, global maps of each model's safety landscape that no existing attack method (GCG, PAIR, or TAP) can provide, shifting the paradigm from finding discrete failures to understanding their underlying structure.","authors":["Sarthak Munshi","Manish Bhatt","Vineeth Sai Narajala","Idan Habler"," AmmarnAl-Kahfah","Ken Huang","Blake Gatto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22282v1","updated":"2026-02-25T12:21:30Z","published":"2026-02-25T12:21:30Z","title":"Differentially Private Truncation of Unbounded Data via Public Second Moments","summary":"Data privacy is important in the AI era, and differential privacy (DP) is one of the golden solutions. However, DP is typically applicable only if data have a bounded underlying distribution. We address this limitation by leveraging second-moment information from a small amount of public data. We propose Public-moment-guided Truncation (PMT), which transforms private data using the public second-moment matrix and applies a principled truncation whose radius depends only on non-private quantities: data dimension and sample size. This transformation yields a well-conditioned second-moment matrix, enabling its inversion with a significantly strengthened ability to resist the DP noise. Furthermore, we demonstrate the applicability of PMT by using penalized and generalized linear regressions. Specifically, we design new loss functions and algorithms, ensuring that solutions in the transformed space can be mapped back to the original domain. We have established improvements in the models' DP estimation through theoretical error bounds, robustness guarantees, and convergence results, attributing the gains to the conditioning effect of PMT. Experiments on synthetic and real datasets confirm that PMT substantially improves the accuracy and stability of DP models.","authors":["Zilong Cao","Xuan Bi","Hai Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22258v1","updated":"2026-02-25T01:09:43Z","published":"2026-02-25T01:09:43Z","title":"Poisoned Acoustics","summary":"Training-data poisoning attacks can induce targeted, undetectable failure in deep neural networks by corrupting a vanishingly small fraction of training labels. We demonstrate this on acoustic vehicle classification using the MELAUDIS urban intersection dataset (approx. 9,600 audio clips, 6 classes): a compact 2-D convolutional neural network (CNN) trained on log-mel spectrograms achieves 95.7% Attack Success Rate (ASR) -- the fraction of target-class test samples misclassified under the attack -- on a Truck-to-Car label-flipping attack at just p=0.5% corruption (48 records), with zero detectable change in aggregate accuracy (87.6% baseline; 95% CI: 88-100%, n=3 seeds). We prove this stealth is structural: the maximum accuracy drop from a complete targeted attack is bounded above by the minority class fraction (beta). For real-world class imbalances (Truck approx. 3%), this bound falls below training-run noise, making aggregate accuracy monitoring provably insufficient regardless of architecture or attack method. A companion backdoor trigger attack reveals a novel trigger-dominance collapse: when the target class is a dataset minority, the spectrogram patch trigger becomes functionally redundant--clean ASR equals triggered ASR, and the attack degenerates to pure label flipping. We formalize the ML training pipeline as an attack surface and propose a trust-minimized defense combining content-addressed artifact hashing, Merkle-tree dataset commitment, and post-quantum digital signatures (ML-DSA-65/CRYSTALS-Dilithium3, NIST FIPS 204) for cryptographically verifiable data provenance.","authors":["Harrison Dahme"],"pdf_url":"","comment":"5 Pages"},{"id":"http://arxiv.org/abs/2507.17691v2","updated":"2026-02-25T04:00:38Z","published":"2025-07-23T16:57:32Z","title":"CASCADE: LLM-Powered JavaScript Deobfuscator at Google","summary":"Software obfuscation, particularly prevalent in JavaScript, hinders code comprehension and analysis, posing significant challenges to software testing, static analysis, and malware detection. This paper introduces CASCADE, a novel hybrid approach that integrates the advanced coding capabilities of Gemini with the deterministic transformation capabilities of a compiler Intermediate Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to identify critical prelude functions, the foundational components underlying the most prevalent obfuscation techniques, and leveraging JSIR for subsequent code transformations, CASCADE effectively recovers semantic elements like original strings and API names, and reveals original program behaviors. This method overcomes limitations of existing static and dynamic deobfuscation techniques, eliminating hundreds to thousands of hardcoded rules while achieving reliability and flexibility. CASCADE is already deployed in Google's production environment, demonstrating substantial improvements in JavaScript deobfuscation efficiency and reducing reverse engineering efforts.","authors":["Shan Jiang","Pranoy Kovuri","David Tao","Zhixun Tan"],"pdf_url":"","comment":"To appear in 2026 IEEE/ACM 48th International Conference on Software Engineering (ICSE-SEIP '26)"}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2602.22154v1","updated":"2026-02-25T18:01:00Z","published":"2026-02-25T18:01:00Z","title":"Position-Based Flocking for Persistent Alignment without Velocity Sensing","summary":"Coordinated collective motion in bird flocks and fish schools inspires algorithms for cohesive swarm robotics. This paper presents a position-based flocking model that achieves persistent velocity alignment without velocity sensing. By approximating relative velocity differences from changes between current and initial relative positions and incorporating a time- and density-dependent alignment gain with a non-zero minimum threshold to maintain persistent alignment, the model sustains coherent collective motion over extended periods. Simulations with a collective of 50 agents demonstrate that the position-based flocking model attains faster and more sustained directional alignment and results in more compact formations than a velocity-alignment-based baseline. This position-based flocking model is particularly well-suited for real-world robotic swarms, where velocity measurements are unreliable, noisy, or unavailable. Experimental results using a team of nine real wheeled mobile robots are also presented.","authors":["Hossein B. Jond","Veli Bakırcıoğlu","Logan E. Beaver","Nejat Tükenmez","Adel Akbarimajd","Martin Saska"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.26656v3","updated":"2026-02-25T17:52:16Z","published":"2025-10-30T16:23:46Z","title":"Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems","summary":"In robotics, likelihood-free inference (LFI) can provide the domain distribution that adapts a learnt agent in a parametric set of deployment conditions. LFI assumes an arbitrary support for sampling, which remains constant as the initial generic prior is iteratively refined to more descriptive posteriors. However, a potentially misspecified support can lead to suboptimal, yet falsely certain, posteriors. To address this issue, we propose three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the posterior mode shift over inference steps in its own way and, when integrated into an LFI step, adapts the support alongside posterior inference. We first expose the support misspecification issue and evaluate our heuristics using stochastic dynamical benchmarks. We then evaluate the impact of heuristic support adaptation on parameter inference and policy learning for a dynamic deformable linear object (DLO) manipulation task. Inference results in a finer length and stiffness classification for a parametric set of DLOs. When the resulting posteriors are used as domain distributions for sim-based policy learning, they lead to more robust object-centric agent performance.","authors":["Georgios Kamaras","Craig Innes","Subramanian Ramamoorthy"],"pdf_url":"","comment":"20 pages, 18 figures"},{"id":"http://arxiv.org/abs/2502.18615v3","updated":"2026-02-25T17:09:15Z","published":"2025-02-25T20:01:06Z","title":"A Distributional Treatment of Real2Sim2Real for Object-Centric Agent Adaptation in Vision-Driven Deformable Linear Object Manipulation","summary":"We present an integrated (or end-to-end) framework for the Real2Sim2Real problem of manipulating deformable linear objects (DLOs) based on visual perception. Working with a parameterised set of DLOs, we use likelihood-free inference (LFI) to compute the posterior distributions for the physical parameters using which we can approximately simulate the behaviour of each specific DLO. We use these posteriors for domain randomisation while training, in simulation, object-specific visuomotor policies (i.e. assuming only visual and proprioceptive sensory) for a DLO reaching task, using model-free reinforcement learning. We demonstrate the utility of this approach by deploying sim-trained DLO manipulation policies in the real world in a zero-shot manner, i.e. without any further fine-tuning. In this context, we evaluate the capacity of a prominent LFI method to perform fine classification over the parametric set of DLOs, using only visual and proprioceptive data obtained in a dynamic manipulation trajectory. We then study the implications of the resulting domain distributions in sim-based policy learning and real-world performance.","authors":["Georgios Kamaras","Subramanian Ramamoorthy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22118v1","updated":"2026-02-25T17:05:09Z","published":"2026-02-25T17:05:09Z","title":"System Design of the Ultra Mobility Vehicle: A Driving, Balancing, and Jumping Bicycle Robot","summary":"Trials cyclists and mountain bike riders can hop, jump, balance, and drive on one or both wheels. This versatility allows them to achieve speed and energy-efficiency on smooth terrain and agility over rough terrain. Inspired by these athletes, we present the design and control of a robotic platform, Ultra Mobility Vehicle (UMV), which combines a bicycle and a reaction mass to move dynamically with minimal actuated degrees of freedom. We employ a simulation-driven design optimization process to synthesize a spatial linkage topology with a focus on vertical jump height and momentum-based balancing on a single wheel contact. Using a constrained Reinforcement Learning (RL) framework, we demonstrate zero-shot transfer of diverse athletic behaviors, including track-stands, jumps, wheelies, rear wheel hopping, and front flips. This 23.5 kg robot is capable of high speeds (8 m/s) and jumping on and over large obstacles (1 m tall, or 130% of the robot's nominal height).","authors":["Benjamin Bokser","Daniel Gonzalez","Surya Singh","Aaron Preston","Alex Bahner","Annika Wollschläger","Arianna Ilvonen","Asa Eckert-Erdheim","Ashwin Khadke","Bilal Hammoud","Dean Molinaro","Fabian Jenelten","Henry Mayne","Howie Choset","Igor Bogoslavskyi","Itic Tinman","James Tigue","Jan Preisig","Kaiyu Zheng","Kenny Sharma","Kim Ang","Laura Lee","Liana Margolese","Nicole Lin","Oscar Frias","Paul Drews","Ravi Boggavarapu","Rick Burnham","Samuel Zapolsky","Sangbae Kim","Scott Biddlestone","Sean Mayorga","Shamel Fahmi","Tyler McCollum","Velin Dimitrov","William Moyne","Yu-Ming Chen","Farbod Farshidian","Marco Hutter","David Perry","Al Rizzi","Gabe Nelson"],"pdf_url":"","comment":"19 Pages, 11 figures, 3 movies, 2 tables"},{"id":"http://arxiv.org/abs/2602.22100v1","updated":"2026-02-25T16:47:08Z","published":"2026-02-25T16:47:08Z","title":"Behavioral Cloning for Robotic Connector Assembly: An Empirical Study","summary":"Automating the assembly of wire harnesses is challenging in automotive, electrical cabinet, and aircraft production, particularly due to deformable cables and a high variance in connector geometries. In addition, connectors must be inserted with limited force to avoid damage, while their poses can vary significantly. While humans can do this task intuitively by combining visual and haptic feedback, programming an industrial robot for such a task in an adaptable manner remains difficult. This work presents an empirical study investigating the suitability of behavioral cloning for learning an action prediction model for connector insertion that fuses force-torque sensing with a fixed position camera. We compare several network architectures and other design choices using a dataset of up to 300 successful human demonstrations collected via teleoperation of a UR5e robot with a SpaceMouse under varying connector poses. The resulting system is then evaluated against five different connector geometries under varying connector poses, achieving an overall insertion success rate of over 90 %.","authors":["Andreas Kernbach","Daniel Bargmann","Werner Kraus","Marco F. Huber"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2602.22088v1","updated":"2026-02-25T16:35:24Z","published":"2026-02-25T16:35:24Z","title":"Force Policy: Learning Hybrid Force-Position Control Policy under Interaction Frame for Contact-Rich Manipulation","summary":"Contact-rich manipulation demands human-like integration of perception and force feedback: vision should guide task progress, while high-frequency interaction control must stabilize contact under uncertainty. Existing learning-based policies often entangle these roles in a monolithic network, trading off global generalization against stable local refinement, while control-centric approaches typically assume a known task structure or learn only controller parameters rather than the structure itself. In this paper, we formalize a physically grounded interaction frame, an instantaneous local basis that decouples force regulation from motion execution, and propose a method to recover it from demonstrations. Based on this, we address both issues by proposing Force Policy, a global-local vision-force policy in which a global policy guides free-space actions using vision, and upon contact, a high-frequency local policy with force feedback estimates the interaction frame and executes hybrid force-position control for stable interaction. Real-world experiments across diverse contact-rich tasks show consistent gains over strong baselines, with more robust contact establishment, more accurate force regulation, and reliable generalization to novel objects with varied geometries and physical properties, ultimately improving both contact stability and execution quality. Project page: https://force-policy.github.io/","authors":["Hongjie Fang","Shirun Tang","Mingyu Mei","Haoxiang Qin","Zihao He","Jingjing Chen","Ying Feng","Chenxi Wang","Wanxi Liu","Zaixing He","Cewu Lu","Shiquan Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22056v1","updated":"2026-02-25T16:06:49Z","published":"2026-02-25T16:06:49Z","title":"FlowCorrect: Efficient Interactive Correction of Generative Flow Policies for Robotic Manipulation","summary":"Generative manipulation policies can fail catastrophically under deployment-time distribution shift, yet many failures are near-misses: the robot reaches almost-correct poses and would succeed with a small corrective motion. We present FlowCorrect, a deployment-time correction framework that converts near-miss failures into successes using sparse human nudges, without full policy retraining. During execution, a human provides brief corrective pose nudges via a lightweight VR interface. FlowCorrect uses these sparse corrections to locally adapt the policy, improving actions without retraining the backbone while preserving the model performance on previously learned scenarios. We evaluate on a real-world robot across three tabletop tasks: pick-and-place, pouring, and cup uprighting. With a low correction budget, FlowCorrect improves success on hard cases by 85\\% while preserving performance on previously solved scenarios. The results demonstrate clearly that FlowCorrect learns only with very few demonstrations and enables fast and sample-efficient incremental, human-in-the-loop corrections of generative visuomotor policies at deployment time in real-world robotics.","authors":["Edgar Welte","Yitian Shi","Rosa Wolf","Maximillian Gilles","Rania Rayyes"],"pdf_url":"","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2602.06834v2","updated":"2026-02-25T15:45:01Z","published":"2026-02-06T16:21:30Z","title":"Perception-Control Coupled Visual Servoing for Textureless Objects Using Keypoint-Based EKF","summary":"Visual servoing is fundamental to robotic applications, enabling precise positioning and control. However, applying it to textureless objects remains a challenge due to the absence of reliable visual features. Moreover, adverse visual conditions, such as occlusions, often corrupt visual feedback, leading to reduced accuracy and instability in visual servoing. In this work, we build upon learning-based keypoint detection for textureless objects and propose a method that enhances robustness by tightly integrating perception and control in a closed loop. Specifically, we employ an Extended Kalman Filter (EKF) that integrates per-frame keypoint measurements to estimate 6D object pose, which drives pose-based visual servoing (PBVS) for control. The resulting camera motion, in turn, enhances the tracking of subsequent keypoints, effectively closing the perception-control loop. Additionally, unlike standard PBVS, we propose a probabilistic control law that computes both camera velocity and its associated uncertainty, enabling uncertainty-aware control for safe and reliable operation. We validate our approach on real-world robotic platforms using quantitative metrics and grasping experiments, demonstrating that our method outperforms traditional visual servoing techniques in both accuracy and practical application.","authors":["Allen Tao","Jun Yang","Stanko Oparnica","Wenjie Xue"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22010v1","updated":"2026-02-25T15:27:09Z","published":"2026-02-25T15:27:09Z","title":"World Guidance: World Modeling in Condition Space for Action Generation","summary":"Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future representations and preserving sufficient fine-grained information to guide precise action generation. To address this limitation, we propose WoG (World Guidance), a framework that maps future observations into compact conditions by injecting them into the action inference pipeline. The VLA is then trained to simultaneously predict these compressed conditions alongside future actions, thereby achieving effective world modeling within the condition space for action inference. We demonstrate that modeling and predicting this condition space not only facilitates fine-grained action generation but also exhibits superior generalization capabilities. Moreover, it learns effectively from substantial human manipulation videos. Extensive experiments across both simulation and real-world environments validate that our method significantly outperforms existing methods based on future prediction. Project page is available at: https://selen-suyue.github.io/WoGNet/","authors":["Yue Su","Sijin Chen","Haixin Shi","Mingyu Liu","Zhengshen Zhang","Ningyuan Huang","Weiheng Zhong","Zhengbang Zhu","Yuxiao Liu","Xihui Liu"],"pdf_url":"","comment":"Project Page: https://selen-suyue.github.io/WoGNet/"},{"id":"http://arxiv.org/abs/2407.05886v2","updated":"2026-02-25T15:26:36Z","published":"2024-07-08T12:46:19Z","title":"Rod models in continuum and soft robot control: a review","summary":"Continuum and soft robots can transform diverse sectors, including healthcare, agriculture, marine, and space, thanks to their potential to adaptively interact with unstructured environments. These robots exhibit complex mechanics that pose diverse challenges in modeling and control. Among various models, continuum mechanical models based on rod theories can effectively capture the deformations of slender bodies in contact-rich scenarios. This structured review paper focuses on the role of rod models in continuum and soft robot control with a vertical approach. We provide a comprehensive summary of the mathematical background underlying the four main rod theories applied in soft robotics and their variants. Then, we review the literature on rod models applied to continuum and soft robots, providing a novel categorization in deformation classes. Finally, we survey recent model-based and learning-based control strategies leveraging rod models, highlighting their potential in real-world manipulation. We critically discuss the trends, advantages, limitations, research gaps, and possible future developments of rod models. This paper aims to guide researchers who intend to simulate and control new soft robots while providing feedback to the design and manufacturing community.","authors":["Carlo Alessi","Camilla Agabiti","Daniele Caradonna","Cecilia Laschi","Federico Renda","Egidio Falotico"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22006v1","updated":"2026-02-25T15:23:18Z","published":"2026-02-25T15:23:18Z","title":"Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines","summary":"Accurate relative localization is critical for multi-robot cooperation. In robot swarms, measurements from different robots arrive asynchronously and with clock time-offsets. Although Continuous-Time (CT) formulations have proved effective for handling asynchronous measurements in single-robot SLAM and calibration, extending CT methods to multi-robot settings faces great challenges to achieve high-accuracy, low-latency, and high-frequency performance. Especially, existing CT methods suffer from the inherent query-time delay of unclamped B-splines and high computational cost. This paper proposes CT-RIO, a novel Continuous-Time Relative-Inertial Odometry framework. We employ Clamped Non-Uniform B-splines (C-NUBS) to represent robot states for the first time, eliminating the query-time delay. We further augment C-NUBS with closed-form extension and shrinkage operations that preserve the spline shape, making it suitable for online estimation and enabling flexible knot management. This flexibility leads to the concept of knot-keyknot strategy, which supports spline extension at high-frequency while retaining sparse keyknots for adaptive relative-motion modeling. We then formulate a sliding-window relative localization problem that operates purely on relative kinematics and inter-robot constraints. To meet the demanding computation required at swarm scale, we decompose the tightly-coupled optimization into robot-wise sub-problems and solve them in parallel using incremental asynchronous block coordinate descent. Extensive experiments show that CT-RIO converges from time-offsets as large as 263 ms to sub-millisecond within 3 s, and achieves RMSEs of 0.046 m and 1.8 °. It consistently outperforms state-of-the-art methods, with improvements of up to 60% under high-speed motion.","authors":["Jiadong Lu","Zhehan Li","Tao Han","Miao Xu","Chao Xu","Yanjun Cao"],"pdf_url":"","comment":"26 pages, 23 figures"},{"id":"http://arxiv.org/abs/2602.22001v1","updated":"2026-02-25T15:19:44Z","published":"2026-02-25T15:19:44Z","title":"Are Foundation Models the Route to Full-Stack Transfer in Robotics?","summary":"In humans and robots alike, transfer learning occurs at different levels of abstraction, from high-level linguistic transfer to low-level transfer of motor skills. In this article, we provide an overview of the impact that foundation models and transformer networks have had on these different levels, bringing robots closer than ever to \"full-stack transfer\". Considering LLMs, VLMs and VLAs from a robotic transfer learning perspective allows us to highlight recurring concepts for transfer, beyond specific implementations. We also consider the challenges of data collection and transfer benchmarks for robotics in the age of foundation models. Are foundation models the route to full-stack transfer in robotics? Our expectation is that they will certainly stay on this route as a key technology.","authors":["Freek Stulp","Samuel Bustamante","João Silvério","Alin Albu-Schäffer","Jeannette Bohg","Shuran Song"],"pdf_url":"","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2602.21983v1","updated":"2026-02-25T15:02:11Z","published":"2026-02-25T15:02:11Z","title":"Humanizing Robot Gaze Shifts: A Framework for Natural Gaze Shifts in Humanoid Robots","summary":"Leveraging auditory and visual feedback for attention reorientation is essential for natural gaze shifts in social interaction. However, enabling humanoid robots to perform natural and context-appropriate gaze shifts in unconstrained human--robot interaction (HRI) remains challenging, as it requires the coupling of cognitive attention mechanisms and biomimetic motion generation. In this work, we propose the Robot Gaze-Shift (RGS) framework, which integrates these two components into a unified pipeline. First, RGS employs a vision--language model (VLM)-based gaze reasoning pipeline to infer context-appropriate gaze targets from multimodal interaction cues, ensuring consistency with human gaze-orienting regularities. Second, RGS introduces a conditional Vector Quantized-Variational Autoencoder (VQ-VAE) model for eye--head coordinated gaze-shift motion generation, producing diverse and human-like gaze-shift behaviors. Experiments validate that RGS effectively replicates human-like target selection and generates realistic, diverse gaze-shift motions.","authors":["Jingchao Wei","Jingkai Qin","Yuxiao Cao","Jingcheng Huang","Xiangrui Zeng","Min Li","Zhouping Yin"],"pdf_url":"","comment":"submitted to AIM 2026"},{"id":"http://arxiv.org/abs/2508.15427v2","updated":"2026-02-25T14:51:19Z","published":"2025-08-21T10:28:39Z","title":"Lang2Lift: A Language-Guided Autonomous Forklift System for Outdoor Industrial Pallet Handling","summary":"Automating pallet handling in outdoor logistics and construction environments remains challenging due to unstructured scenes, variable pallet configurations, and changing environmental conditions. In this paper, we present Lang2Lift, an end-to-end language-guided autonomous forklift system designed to support practical pallet pick-up operations in real-world outdoor settings. The system enables operators to specify target pallets using natural language instructions, allowing flexible selection among multiple pallets with different loads and spatial arrangements. Lang2Lift integrates foundation-model-based perception modules with motion planning and control in a closed-loop autonomy pipeline. Language-grounded visual perception is used to identify and segment target pallets, followed by 6D pose estimation and geometric refinement to generate manipulation-feasible insertion poses. The resulting pose estimates are directly coupled with the forklift planning and control modules to execute fully autonomous pallet pick-up maneuvers. We deploy and evaluate the proposed system on the ADAPT autonomous outdoor forklift platform across diverse real-world scenarios, including cluttered scenes, variable lighting, and different payload configurations. Tolerance-based pose evaluation further indicates accuracy sufficient for successful fork insertion. Timing and failure analyses highlight key deployment trade-offs and practical limitations, providing insights into integrating language-guided perception within industrial automation systems. Video demonstrations are available at https://eric-nguyen1402.github.io/lang2lift.github.io/","authors":["Huy Hoang Nguyen","Johannes Huemer","Markus Murschitz","Tobias Glueck","Minh Nhat Vu","Andreas Kugi"],"pdf_url":"","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.21967v1","updated":"2026-02-25T14:48:49Z","published":"2026-02-25T14:48:49Z","title":"Dream-SLAM: Dreaming the Unseen for Active SLAM in Dynamic Environments","summary":"In addition to the core tasks of simultaneous localization and mapping (SLAM), active SLAM additionally in- volves generating robot actions that enable effective and efficient exploration of unknown environments. However, existing active SLAM pipelines are limited by three main factors. First, they inherit the restrictions of the underlying SLAM modules that they may be using. Second, their motion planning strategies are typically shortsighted and lack long-term vision. Third, most approaches struggle to handle dynamic scenes. To address these limitations, we propose a novel monocular active SLAM method, Dream-SLAM, which is based on dreaming cross-spatio-temporal images and semantically plausible structures of partially observed dynamic environments. The generated cross-spatio-temporal im- ages are fused with real observations to mitigate noise and data incompleteness, leading to more accurate camera pose estimation and a more coherent 3D scene representation. Furthermore, we integrate dreamed and observed scene structures to enable long- horizon planning, producing farsighted trajectories that promote efficient and thorough exploration. Extensive experiments on both public and self-collected datasets demonstrate that Dream-SLAM outperforms state-of-the-art methods in localization accuracy, mapping quality, and exploration efficiency. Source code will be publicly available upon paper acceptance.","authors":["Xiangqi Meng","Pengxu Hou","Zhenjun Zhao","Javier Civera","Daniel Cremers","Hesheng Wang","Haoang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21954v1","updated":"2026-02-25T14:35:24Z","published":"2026-02-25T14:35:24Z","title":"The Swarm Intelligence Freeway-Urban Trajectories (SWIFTraj) Dataset - Part II: A Graph-Based Approach for Trajectory Connection","summary":"In Part I of this companion paper series, we introduced SWIFTraj, a new open-source vehicle trajectory dataset collected using a unmanned aerial vehicle (UAV) swarm. The dataset has two distinctive features. First, by connecting trajectories across consecutive UAV videos, it provides long-distance continuous trajectories, with the longest exceeding 4.5 km. Second, it covers an integrated traffic network consisting of both freeways and their connected urban roads. Obtaining such long-distance continuous trajectories from a UAV swarm is challenging, due to the need for accurate time alignment across multiple videos and the irregular spatial distribution of UAVs. To address these challenges, this paper proposes a novel graph-based approach for connecting vehicle trajectories captured by a UAV swarm. An undirected graph is constructed to represent flexible UAV layouts, and an automatic time alignment method based on trajectory matching cost minimization is developed to estimate optimal time offsets across videos. To associate trajectories of the same vehicle observed in different videos, a vehicle matching table is established using the Hungarian algorithm. The proposed approach is evaluated using both simulated and real-world data. Results from real-world experiments show that the time alignment error is within three video frames, corresponding to approximately 0.1 s, and that the vehicle matching achieves an F1-score of about 0.99. These results demonstrate the effectiveness of the proposed method in addressing key challenges in UAV-based trajectory connection and highlight its potential for large-scale vehicle trajectory collection.","authors":["Xinkai Ji","Pan Liu","Yu Han"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20871v2","updated":"2026-02-25T14:34:37Z","published":"2026-02-24T13:15:38Z","title":"GeCo-SRT: Geometry-aware Continual Adaptation for Robotic Cross-Task Sim-to-Real Transfer","summary":"Bridging the sim-to-real gap is important for applying low-cost simulation data to real-world robotic systems. However, previous methods are severely limited by treating each transfer as an isolated endeavor, demanding repeated, costly tuning and wasting prior transfer experience. To move beyond isolated sim-to-real, we build a continual cross-task sim-to-real transfer paradigm centered on knowledge accumulation across iterative transfers, thereby enabling effective and efficient adaptation to novel tasks. Thus, we propose GeCo-SRT, a geometry-aware continual adaptation method. It utilizes domain-invariant and task-invariant knowledge from local geometric features as a transferable foundation to accelerate adaptation during subsequent sim-to-real transfers. This method starts with a geometry-aware mixture-of-experts module, which dynamically activates experts to specialize in distinct geometric knowledge to bridge observation sim-to-real gap. Further, the geometry-expert-guided prioritized experience replay module preferentially samples from underutilized experts, refreshing specialized knowledge to combat forgetting and maintain robust cross-task performance. Leveraging knowledge accumulated during iterative transfer, GeCo-SRT method not only achieves 52% average performance improvement over the baseline, but also demonstrates significant data efficiency for new task adaptation with only 1/6 data. We hope this work inspires approaches for efficient, low-cost cross-task sim-to-real transfer.","authors":["Wenbo Yu","Wenke Xia","Weitao Zhang","Di Hu"],"pdf_url":"","comment":"Accepted By CVPR 2026"},{"id":"http://arxiv.org/abs/2409.18745v4","updated":"2026-02-25T14:27:09Z","published":"2024-09-27T13:38:06Z","title":"A study on the effects of mixed explicit and implicit communications in human-artificial-agent interactions","summary":"Communication between humans and artificial agents is essential for their interaction. This is often inspired by human communication, which uses gestures, facial expressions, gaze direction, and other explicit and implicit means. This work presents interaction experiments where humans and artificial agents interact through explicit and implicit communication to evaluate the effect of mixed explicit-implicit communication against purely explicit communication and the impact of the task difficulty in this evaluation. Results obtained using Bayesian parameter estimation show that the task execution time did not significantly change when mixed explicit and implicit communications were used in neither of our experiments, which varied in the type of artificial agent (virtual agent and humanoid robot) used and task difficulty. The number of errors was affected by the communication only when the human was executing a more difficult task, and an impact on the perceived efficiency of the interaction was only observed in the interaction with the robot, for both easy and difficult tasks. In contrast, acceptance, sociability, and transparency of the artificial agent increased when using mixed communication modalities in both our experiments and task difficulty levels. This suggests that task-related measures, such as time, number of errors, and perceived efficiency of the interaction, as well as the impact of the communication on them, are more sensitive to the type of task and the difficulty level, whereas the combination of explicit and implicit communications more consistently improves human perceptions about artificial agents.","authors":["Ana Christina Almada Campos","Bruno Vilhena Adorno"],"pdf_url":"","comment":"Main paper with 28 pages, 14 figures, 4 tables. Supplementary material with 39 pages, 44 figures, 2 tables. Submitted to Intelligent Service Robotics"},{"id":"http://arxiv.org/abs/2505.13667v5","updated":"2026-02-25T14:04:56Z","published":"2025-05-19T19:12:29Z","title":"Adaptive Diffusion Constrained Sampling for Bimanual Robot Manipulation","summary":"Coordinated multi-arm manipulation requires satisfying multiple simultaneous geometric constraints across high-dimensional configuration spaces, which poses a significant challenge for traditional planning and control methods. In this work, we propose Adaptive Diffusion Constrained Sampling (ADCS), a generative framework that flexibly integrates both equality (e.g., relative and absolute pose constraints) and structured inequality constraints (e.g., proximity to object surfaces) into an energy-based diffusion model. Equality constraints are modeled using dedicated energy networks trained on pose differences in Lie algebra space, while inequality constraints are represented via Signed Distance Functions (SDFs) and encoded into learned constraint embeddings, allowing the model to reason about complex spatial regions. A key innovation of our method is a Transformer-based architecture that learns to weight constraint-specific energy functions at inference time, enabling flexible and context-aware constraint integration. Moreover, we adopt a two-phase sampling strategy that improves precision and sample diversity by combining Langevin dynamics with resampling and density-aware re-weighting. Experimental results on dual-arm manipulation tasks show that ADCS significantly improves sample diversity and generalization across settings demanding precise coordination and adaptive constraint handling.","authors":["Haolei Tong","Yuezhe Zhang","Sophie Lueth","Georgia Chalvatzaki"],"pdf_url":"","comment":"Accepted by IEEE International Conference on Robotics and Automation 2026(ICRA 2026)"},{"id":"http://arxiv.org/abs/2602.21904v1","updated":"2026-02-25T13:34:56Z","published":"2026-02-25T13:34:56Z","title":"UNet-Based Keypoint Regression for 3D Cone Localization in Autonomous Racing","summary":"Accurate cone localization in 3D space is essential in autonomous racing for precise navigation around the track. Approaches that rely on traditional computer vision algorithms are sensitive to environmental variations, and neural networks are often trained on limited data and are infeasible to run in real time. We present a UNet-based neural network for keypoint detection on cones, leveraging the largest custom-labeled dataset we have assembled. Our approach enables accurate cone position estimation and the potential for color prediction. Our model achieves substantial improvements in keypoint accuracy over conventional methods. Furthermore, we leverage our predicted keypoints in the perception pipeline and evaluate the end-to-end autonomous system. Our results show high-quality performance across all metrics, highlighting the effectiveness of this approach and its potential for adoption in competitive autonomous racing systems.","authors":["Mariia Baidachna","James Carty","Aidan Ferguson","Joseph Agrane","Varad Kulkarni","Aubrey Agub","Michael Baxendale","Aaron David","Rachel Horton","Elliott Atkinson"],"pdf_url":"","comment":"8 pages, 9 figures. Accepted to ICCV End-to-End 3D Learning Workshop 2025 and presented as a poster; not included in the final proceedings due to a conference administrative error"},{"id":"http://arxiv.org/abs/2602.21899v1","updated":"2026-02-25T13:29:38Z","published":"2026-02-25T13:29:38Z","title":"Enhancing Cellular-enabled Collaborative Robots Planning through GNSS data for SAR Scenarios","summary":"Cellular-enabled collaborative robots are becoming paramount in Search-and-Rescue (SAR) and emergency response. Crucially dependent on resilient mobile network connectivity, they serve as invaluable assets for tasks like rapid victim localization and the exploration of hazardous, otherwise unreachable areas. However, their reliance on battery power and the need for persistent, low-latency communication limit operational time and mobility. To address this, and considering the evolving capabilities of 5G/6G networks, we propose a novel SAR framework that includes Mission Planning and Mission Execution phases and that optimizes robot deployment. By considering parameters such as the exploration area size, terrain elevation, robot fleet size, communication-influenced energy profiles, desired exploration rate, and target response time, our framework determines the minimum number of robots required and their optimal paths to ensure effective coverage and timely data backhaul over mobile networks. Our results demonstrate the trade-offs between number of robots, explored area, and response time for wheeled and quadruped robots. Further, we quantify the impact of terrain elevation data on mission time and energy consumption, showing the benefits of incorporating real-world environmental factors that might also affect mobile signal propagation and connectivity into SAR planning. This framework provides critical insights for leveraging next-generation mobile networks to enhance autonomous SAR operations.","authors":["Arnau Romero","Carmen Delgado","Jana Baguer","Raúl Suárez","Xavier Costa-Pérez"],"pdf_url":"","comment":"arXiv admin note: substantial text overlap with arXiv:2403.09177"},{"id":"http://arxiv.org/abs/2506.04941v3","updated":"2026-02-25T13:23:16Z","published":"2025-06-05T12:16:27Z","title":"ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning","summary":"Robot learning increasingly relies on simulation to advance complex ability such as dexterous manipulations and precise interactions, necessitating high-quality digital assets to bridge the sim-to-real gap. However, existing open-source articulated-object datasets for simulation are limited by insufficient visual realism and low physical fidelity, which hinder their utility for training models mastering robotic tasks in real world. To address these challenges, we introduce ArtVIP, a comprehensive open-source dataset comprising high-quality digital-twin articulated objects, accompanied by indoor-scene assets. Crafted by professional 3D modelers adhering to unified standards, ArtVIP ensures visual realism through precise geometric meshes and high-resolution textures, while physical fidelity is achieved via fine-tuned dynamic parameters. Meanwhile, the dataset pioneers embedded modular interaction behaviors within assets and pixel-level affordance annotations. Feature-map visualization and optical motion capture are employed to quantitatively demonstrate ArtVIP's visual and physical fidelity, with its applicability validated across imitation learning and reinforcement learning experiments. Provided in USD format with detailed production guidelines, ArtVIP is fully open-source, benefiting the research community and advancing robot learning research. Our project is at https://x-humanoid-artvip.github.io/ .","authors":["Zhao Jin","Zhengping Che","Tao Li","Zhen Zhao","Kun Wu","Yuheng Zhang","Yinuo Zhao","Zehui Liu","Qiang Zhang","Xiaozhu Ju","Jing Tian","Yousong Xue","Jian Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16898v3","updated":"2026-02-25T11:49:07Z","published":"2026-02-18T21:28:56Z","title":"MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation","summary":"Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings. MALLVI presents a Multi Agent Large Language and Vision framework that enables closed-loop feedback driven robotic manipulation. Given a natural language instruction and an image of the environment, MALLVI generates executable atomic actions for a robot manipulator. After action execution, a Vision Language Model (VLM) evaluates environmental feedback and decides whether to repeat the process or proceed to the next step. Rather than using a single model, MALLVI coordinates specialized agents, Decomposer, Localizer, Thinker, and Reflector, to manage perception, localization, reasoning, and high level planning. An optional Descriptor agent provides visual memory of the initial state. The Reflector supports targeted error detection and recovery by reactivating only relevant agents, avoiding full replanning. Experiments in simulation and real-world settings show that iterative closed loop multi agent coordination improves generalization and increases success rates in zero shot manipulation tasks. Code available at https://github.com/iman1234ahmadi/MALLVI .","authors":["Iman Ahmadi","Mehrshad Taji","Arad Mahdinezhad Kashani","AmirHossein Jadidi","Saina Kashani","Babak Khalaj"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21816v1","updated":"2026-02-25T11:44:15Z","published":"2026-02-25T11:44:15Z","title":"Self-Curriculum Model-based Reinforcement Learning for Shape Control of Deformable Linear Objects","summary":"Precise shape control of Deformable Linear Objects (DLOs) is crucial in robotic applications such as industrial and medical fields. However, existing methods face challenges in handling complex large deformation tasks, especially those involving opposite curvatures, and lack efficiency and precision. To address this, we propose a two-stage framework combining Reinforcement Learning (RL) and online visual servoing. In the large-deformation stage, a model-based reinforcement learning approach using an ensemble of dynamics models is introduced to significantly improve sample efficiency. Additionally, we design a self-curriculum goal generation mechanism that dynamically selects intermediate-difficulty goals with high diversity through imagined evaluations, thereby optimizing the policy learning process. In the small-deformation stage, a Jacobian-based visual servo controller is deployed to ensure high-precision convergence. Simulation results show that the proposed method enables efficient policy learning and significantly outperforms mainstream baselines in shape control success rate and precision. Furthermore, the framework effectively transfers the policy trained in simulation to real-world tasks with zero-shot adaptation. It successfully completes all 30 cases with diverse initial and target shapes across DLOs of different sizes and materials. The project website is available at: https://anonymous.4open.science/w/sc-mbrl-dlo-EB48/","authors":["Zhaowei Liang","Song Wang","Zhao Jin","Shirui Wu","Dan Wu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21811v1","updated":"2026-02-25T11:38:07Z","published":"2026-02-25T11:38:07Z","title":"DexRepNet++: Learning Dexterous Robotic Manipulation with Geometric and Spatial Hand-Object Representations","summary":"Robotic dexterous manipulation is a challenging problem due to high degrees of freedom (DoFs) and complex contacts of multi-fingered robotic hands. Many existing deep reinforcement learning (DRL) based methods aim at improving sample efficiency in high-dimensional output action spaces. However, existing works often overlook the role of representations in achieving generalization of a manipulation policy in the complex input space during the hand-object interaction. In this paper, we propose DexRep, a novel hand-object interaction representation to capture object surface features and spatial relations between hands and objects for dexterous manipulation skill learning. Based on DexRep, policies are learned for three dexterous manipulation tasks, i.e. grasping, in-hand reorientation, bimanual handover, and extensive experiments are conducted to verify the effectiveness. In simulation, for grasping, the policy learned with 40 objects achieves a success rate of 87.9% on more than 5000 unseen objects of diverse categories, significantly surpassing existing work trained with thousands of objects; for the in-hand reorientation and handover tasks, the policies also boost the success rates and other metrics of existing hand-object representations by 20% to 40%. The grasp policies with DexRep are deployed to the real world under multi-camera and single-camera setups and demonstrate a small sim-to-real gap.","authors":["Qingtao Liu","Zhengnan Sun","Yu Cui","Haoming Li","Gaofeng Li","Lin Shao","Jiming Chen","Qi Ye"],"pdf_url":"","comment":"Accepted by IEEE Transactions on Robotics (T-RO), 2026"},{"id":"http://arxiv.org/abs/2601.22074v2","updated":"2026-02-25T11:20:15Z","published":"2026-01-29T18:11:26Z","title":"mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning","summary":"We present mjlab, a lightweight, open-source framework for robot learning that combines GPU-accelerated simulation with composable environments and minimal setup friction. mjlab adopts the manager-based API introduced by Isaac Lab, where users compose modular building blocks for observations, rewards, and events, and pairs it with MuJoCo Warp for GPU-accelerated physics. The result is a framework installable with a single command, requiring minimal dependencies, and providing direct access to native MuJoCo data structures. mjlab ships with reference implementations of velocity tracking, motion imitation, and manipulation tasks.","authors":["Kevin Zakka","Qiayuan Liao","Brent Yi","Louis Le Lay","Koushil Sreenath","Pieter Abbeel"],"pdf_url":"","comment":"Comments: 11 pages; Code is available at https://github.com/mujocolab/mjlab ; Expanded sensor and domain randomization sections, added references, minor edits"},{"id":"http://arxiv.org/abs/2602.21783v1","updated":"2026-02-25T11:04:49Z","published":"2026-02-25T11:04:49Z","title":"Therapist-Robot-Patient Physical Interaction is Worth a Thousand Words: Enabling Intuitive Therapist Guidance via Remote Haptic Control","summary":"Robotic systems can enhance the amount and repeatability of physically guided motor training. Yet their real-world adoption is limited, partly due to non-intuitive trainer/therapist-trainee/patient interactions. To address this gap, we present a haptic teleoperation system for trainers to remotely guide and monitor the movements of a trainee wearing an arm exoskeleton. The trainer can physically interact with the exoskeleton through a commercial handheld haptic device via virtual contact points at the exoskeleton's elbow and wrist, allowing intuitive guidance. Thirty-two participants tested the system in a trainer-trainee paradigm, comparing our haptic demonstration system with conventional visual demonstration in guiding trainees in executing arm poses. Quantitative analyses showed that haptic demonstration significantly reduced movement completion time and improved smoothness, while speech analysis using large language models for automated transcription and categorization of verbal commands revealed fewer verbal instructions. The haptic demonstration did not result in higher reported mental and physical effort by trainers compared to the visual demonstration, while trainers reported greater competence and trainees lower physical demand. These findings support the feasibility of our proposed interface for effective remote human-robot physical interaction. Future work should assess its usability and efficacy for clinical populations in restoring clinicians' sense of agency during robot-assisted therapy.","authors":["Beatrice Luciani","Alex van den Berg","Matti Lang","Alexandre L. Ratschat","Laura Marchal-Crespo"],"pdf_url":"","comment":"14 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2512.04579v3","updated":"2026-02-25T10:13:25Z","published":"2025-12-04T08:48:04Z","title":"Gauss-Newton accelerated MPPI Control","summary":"Model Predictive Path Integral (MPPI) control is a sampling-based optimization method that has recently attracted attention, particularly in the robotics and reinforcement learning communities. MPPI has been widely applied as a GPU-accelerated random search method to deterministic direct single-shooting optimal control problems arising in model predictive control (MPC) formulations. MPPI offers several key advantages, including flexibility, robustness, ease of implementation, and inherent parallelizability. However, its performance can deteriorate in high-dimensional settings since the optimal control problem is solved via Monte Carlo sampling. To address this limitation, this paper proposes an enhanced MPPI method that incorporates a Jacobian reconstruction technique and the second-order Generalized Gauss-Newton method. This novel approach is called \\textit{Gauss-Newton accelerated MPPI}. The numerical results show that the Gauss-Newton accelerated MPPI approach substantially improves MPPI scalability and computational efficiency while preserving the key benefits of the classical MPPI framework, making it a promising approach even for high-dimensional problems.","authors":["Hannes Homburger","Katrin Baumgärtner","Moritz Diehl","Johannes Reuter"],"pdf_url":"","comment":"6 pages, 3 figures, submitted to the IFAC World Congress 2026, parts of this preprint are directly taken from Chapter 3 of the main author's PhD thesis with title \"Optimal Control for Efficient Vessel Operation: From Theory to Real-World Applications\""},{"id":"http://arxiv.org/abs/2512.11786v2","updated":"2026-02-25T10:12:12Z","published":"2025-12-12T18:55:22Z","title":"Toward a Decision Support System for Energy-Efficient Ferry Operation on Lake Constance based on Optimal Control","summary":"The maritime sector is undergoing a disruptive technological change driven by three main factors: autonomy, decarbonization, and digital transformation. Addressing these factors necessitates a reassessment of inland vessel operations. This paper presents the design and development of a decision support system for ferry operations based on a shrinking-horizon optimal control framework. The problem formulation incorporates a mathematical model of the ferry's dynamics and environmental disturbances, specifically water currents and wind, which can significantly influence the dynamics. Real-world data and illustrative scenarios demonstrate the potential of the proposed system to effectively support ferry crews by providing real-time guidance. This enables enhanced operational efficiency while maintaining predefined maneuver durations. The findings suggest that optimal control applications hold substantial promise for advancing future ferry operations on inland waters. A video of the real-world ferry MS Insel Mainau operating on Lake Constance is available at: https://youtu.be/i1MjCdbEQyE","authors":["Hannes Homburger","Bastian Jäckl","Stefan Wirtensohn","Christian Stopp","Maximilian T. Fischer","Moritz Diehl","Daniel A. Keim","Johannes Reuter"],"pdf_url":"","comment":"6 pages, 8 figures, parts of this preprint are directly taken from Chapter 6 of the main author's PhD thesis with title \"Optimal Control for Efficient Vessel Operation: From Theory to Real-World Applications\""},{"id":"http://arxiv.org/abs/2602.21736v1","updated":"2026-02-25T09:46:42Z","published":"2026-02-25T09:46:42Z","title":"Joint-Aligned Latent Action: Towards Scalable VLA Pretraining in the Wild","summary":"Despite progress, Vision-Language-Action models (VLAs) are limited by a scarcity of large-scale, diverse robot data. While human manipulation videos offer a rich alternative, existing methods are forced to choose between small, precisely-labeled datasets and vast in-the-wild footage with unreliable hand tracking labels. We present JALA, a pretraining framework that learns Jointly-Aligned Latent Actions. JALA bypasses full visual dynamic reconstruction, instead learns a predictive action embedding aligned with both inverse dynamics and real actions. This yields a transition-aware, behavior-centric latent space for learning from heterogeneous human data. We scale this approach with UniHand-Mix, a 7.5M video corpus (>2,000 hours) blending laboratory and in-the-wild footage. Experiments demonstrate that JALA generates more realistic hand motions in both controlled and unconstrained scenarios, significantly improving downstream robot manipulation performance in both simulation and real-world tasks. These results indicate that jointly-aligned latent actions offer a scalable pathway for VLA pretraining from human data.","authors":["Hao Luo","Ye Wang","Wanpeng Zhang","Haoqi Yuan","Yicheng Feng","Haiweng Xu","Sipeng Zheng","Zongqing Lu"],"pdf_url":"","comment":"CVPR2026"},{"id":"http://arxiv.org/abs/2602.21723v1","updated":"2026-02-25T09:31:28Z","published":"2026-02-25T09:31:28Z","title":"LessMimic: Long-Horizon Humanoid Interaction with Unified Distance Field Representations","summary":"Humanoid robots that autonomously interact with physical environments over extended horizons represent a central goal of embodied intelligence. Existing approaches rely on reference motions or task-specific rewards, tightly coupling policies to particular object geometries and precluding multi-skill generalization within a single framework. A unified interaction representation enabling reference-free inference, geometric generalization, and long-horizon skill composition within one policy remains an open challenge. Here we show that Distance Field (DF) provides such a representation: LessMimic conditions a single whole-body policy on DF-derived geometric cues--surface distances, gradients, and velocity decompositions--removing the need for motion references, with interaction latents encoded via a Variational Auto-Encoder (VAE) and post-trained using Adversarial Interaction Priors (AIP) under Reinforcement Learning (RL). Through DAgger-style distillation that aligns DF latents with egocentric depth features, LessMimic further transfers seamlessly to vision-only deployment without motion capture (MoCap) infrastructure. A single LessMimic policy achieves 80--100% success across object scales from 0.4x to 1.6x on PickUp and SitStand where baselines degrade sharply, attains 62.1% success on 5 task instances trajectories, and remains viable up to 40 sequentially composed tasks. By grounding interaction in local geometry rather than demonstrations, LessMimic offers a scalable path toward humanoid robots that generalize, compose skills, and recover from failures in unstructured environments.","authors":["Yutang Lin","Jieming Cui","Yixuan Li","Baoxiong Jia","Yixin Zhu","Siyuan Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.02310v2","updated":"2026-02-25T09:26:06Z","published":"2025-03-04T06:12:08Z","title":"PD-VLA: Accelerating Vision-Language-Action Model Integrated with Action Chunking via Parallel Decoding","summary":"Vision-Language-Action (VLA) models demonstrate remarkable potential for generalizable robotic manipulation. The performance of VLA models can be improved by integrating with action chunking, a critical technique for effective control. However, action chunking linearly scales up action dimensions in VLA models with increased chunking sizes. This reduces the inference efficiency. To tackle this problem, we propose PD-VLA, the first parallel decoding framework for VLA models integrated with action chunking. Our framework reformulates autoregressive decoding as a nonlinear system solved by parallel fixed-point iterations. This approach preserves model performance with mathematical guarantees while significantly improving decoding speed. In addition, it enables training-free acceleration without architectural changes, as well as seamless synergy with existing acceleration techniques. Extensive simulations validate that our PD-VLA maintains competitive success rates while achieving 2.52 times execution frequency on manipulators (with 7 degrees of freedom) compared with the fundamental VLA model. Furthermore, we experimentally identify the most effective settings for acceleration. Finally, real-world experiments validate its high applicability across different tasks.","authors":["Wenxuan Song","Jiayi Chen","Pengxiang Ding","Han Zhao","Wei Zhao","Zhide Zhong","Zongyuan Ge","Zhijun Li","Donglin Wang","Jun Ma","Lujia Wang","Haoang Li"],"pdf_url":"","comment":"Accepted by IROS 2025, updated results on LIBERO"},{"id":"http://arxiv.org/abs/2602.21696v1","updated":"2026-02-25T08:59:50Z","published":"2026-02-25T08:59:50Z","title":"Dual-Regime Hybrid Aerodynamic Modeling of Winged Blimps With Neural Mixing","summary":"Winged blimps operate across distinct aerodynamic regimes that cannot be adequately captured by a single model. At high speeds and small angles of attack, their dynamics exhibit strong coupling between lift and attitude, resembling fixed-wing aircraft behavior. At low speeds or large angles of attack, viscous effects and flow separation dominate, leading to drag-driven and damping-dominated dynamics. Accurately representing transitions between these regimes remains a fundamental challenge. This paper presents a hybrid aerodynamic modeling framework that integrates a fixed-wing Aerodynamic Coupling Model (ACM) and a Generalized Drag Model (GDM) using a learned neural network mixer with explicit physics-based regularization. The mixer enables smooth transitions between regimes while retaining explicit, physics-based aerodynamic representation. Model parameters are identified through a structured three-phase pipeline tailored for hybrid aerodynamic modeling. The proposed approach is validated on the RGBlimp platform through a large-scale experimental campaign comprising 1,320 real-world flight trajectories across 330 thruster and moving mass configurations, spanning a wide range of speeds and angles of attack. Experimental results demonstrate that the proposed hybrid model consistently outperforms single-model and predefined-mixer baselines, establishing a practical and robust aerodynamic modeling solution for winged blimps.","authors":["Xiaorui Wang","Hongwu Wang","Yue Fan","Hao Cheng","Feitian Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21691v1","updated":"2026-02-25T08:47:08Z","published":"2026-02-25T08:47:08Z","title":"Trajectory Generation with Endpoint Regulation and Momentum-Aware Dynamics for Visually Impaired Scenarios","summary":"Trajectory generation for visually impaired scenarios requires smooth and temporally consistent state in structured, low-speed dynamic environments. However, traditional jerk-based heuristic trajectory sampling with independent segment generation and conventional smoothness penalties often lead to unstable terminal behavior and state discontinuities under frequent regenerating. This paper proposes a trajectory generation approach that integrates endpoint regulation to stabilize terminal states within each segment and momentum-aware dynamics to regularize the evolution of velocity and acceleration for segment consistency. Endpoint regulation is incorporated into trajectory sampling to stabilize terminal behavior, while a momentum-aware dynamics enforces consistent velocity and acceleration evolution across consecutive trajectory segments. Experimental results demonstrate reduced acceleration peaks and lower jerk levels with decreased dispersion, smoother velocity and acceleration profiles, more stable endpoint distributions, and fewer infeasible trajectory candidates compared with a baseline planner.","authors":["Yuting Zeng","Manping Fan","You Zhou","Yongbin Yu","Zhiwen Zheng","Jingtao Zhang","Liyong Ren","Zhenglin Yang"],"pdf_url":"","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.21684v1","updated":"2026-02-25T08:36:45Z","published":"2026-02-25T08:36:45Z","title":"Primary-Fine Decoupling for Action Generation in Robotic Imitation","summary":"Multi-modal distribution in robotic manipulation action sequences poses critical challenges for imitation learning. To this end, existing approaches often model the action space as either a discrete set of tokens or a continuous, latent-variable distribution. However, both approaches present trade-offs: some methods discretize actions into tokens and therefore lose fine-grained action variations, while others generate continuous actions in a single stage tend to produce unstable mode transitions. To address these limitations, we propose Primary-Fine Decoupling for Action Generation (PF-DAG), a two-stage framework that decouples coarse action consistency from fine-grained variations. First, we compress action chunks into a small set of discrete modes, enabling a lightweight policy to select consistent coarse modes and avoid mode bouncing. Second, a mode conditioned MeanFlow policy is learned to generate high-fidelity continuous actions. Theoretically, we prove PF-DAG's two-stage design achieves a strictly lower MSE bound than single-stage generative policies. Empirically, PF-DAG outperforms state-of-the-art baselines across 56 tasks from Adroit, DexArt, and MetaWorld benchmarks. It further generalizes to real-world tactile dexterous manipulation tasks. Our work demonstrates that explicit mode-level decoupling enables both robust multi-modal modeling and reactive closed-loop control for robotic manipulation.","authors":["Xiaohan Lei","Min Wang","Wengang Zhou","Xingyu Lu","Houqiang Li"],"pdf_url":"","comment":"The Fourteenth International Conference on Learning Representations (ICLR), 2026"},{"id":"http://arxiv.org/abs/2602.21682v1","updated":"2026-02-25T08:35:58Z","published":"2026-02-25T08:35:58Z","title":"SunnyParking: Multi-Shot Trajectory Generation and Motion State Awareness for Human-like Parking","summary":"Autonomous parking fundamentally differs from on-road driving due to its frequent direction changes and complex maneuvering requirements. However, existing End-to-End (E2E) planning methods often simplify the parking task into a geometric path regression problem, neglecting explicit modeling of the vehicle's kinematic state. This \"dimensionality deficiency\" easily leads to physically infeasible trajectories and deviates from real human driving behavior, particularly at critical gear-shift points in multi-shot parking scenarios. In this paper, we propose SunnyParking, a novel dual-branch E2E architecture that achieves motion state awareness by jointly predicting spatial trajectories and discrete motion state sequences (e.g., forward/reverse). Additionally, we introduce a Fourier feature-based representation of target parking slots to overcome the resolution limitations of traditional bird's-eye view (BEV) approaches, enabling high-precision target interactions. Experimental results demonstrate that our framework generates more robust and human-like trajectories in complex multi-shot parking scenarios, while significantly improving gear-shift point localization accuracy compared to state-of-the-art methods. We open-source a new parking dataset of the CARLA simulator, specifically designed to evaluate full prediction capabilities under complex maneuvers.","authors":["Jishu Miao","Han Chen","Jiankun Zhai","Qi Liu","Tsubasa Hirakawa","Takayoshi Yamashita","Hironobu Fujiyoshi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21670v1","updated":"2026-02-25T08:08:26Z","published":"2026-02-25T08:08:26Z","title":"Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning","summary":"Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.","authors":["Tomoya Kawabe","Rin Takano"],"pdf_url":"","comment":"Accepted to ICRA 2026. 8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.21666v1","updated":"2026-02-25T07:59:16Z","published":"2026-02-25T07:59:16Z","title":"Biomechanical Comparisons Reveal Divergence of Human and Humanoid Gaits","summary":"It remains challenging to achieve human-like locomotion in legged robots due to fundamental discrepancies between biological and mechanical structures. Although imitation learning has emerged as a promising approach for generating natural robotic movements, simply replicating joint angle trajectories fails to capture the underlying principles of human motion. This study proposes a Gait Divergence Analysis Framework (GDAF), a unified biomechanical evaluation framework that systematically quantifies kinematic and kinetic discrepancies between humans and bipedal robots. We apply GDAF to systematically compare human and humanoid locomotion across 28 walking speeds. To enable reproducible analysis, we collect and release a speed-continuous humanoid locomotion dataset from a state-of-the-art humanoid controller. We further provide an open-source implementation of GDAF, including analysis, visualization, and MuJoCo-based tools, enabling quantitative, interpretable, and reproducible biomechanical analysis of humanoid locomotion. Results demonstrate that despite visually human-like motion generated by modern humanoid controllers, significant biomechanical divergence persists across speeds. Robots exhibit systematic deviations in gait symmetry, energy distribution, and joint coordination, indicating that substantial room remains for improving the biomechanical fidelity and energetic efficiency of humanoid locomotion. This work provides a quantitative benchmark for evaluating humanoid locomotion and offers data and versatile tools to support the development of more human-like and energetically efficient locomotion controllers. The data and code will be made publicly available upon acceptance of the paper.","authors":["Luying Feng","Yaochu Jin","Hanze Hu","Wei Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21644v1","updated":"2026-02-25T07:14:07Z","published":"2026-02-25T07:14:07Z","title":"DAGS-SLAM: Dynamic-Aware 3DGS SLAM via Spatiotemporal Motion Probability and Uncertainty-Aware Scheduling","summary":"Mobile robots and IoT devices demand real-time localization and dense reconstruction under tight compute and energy budgets. While 3D Gaussian Splatting (3DGS) enables efficient dense SLAM, dynamic objects and occlusions still degrade tracking and mapping. Existing dynamic 3DGS-SLAM often relies on heavy optical flow and per-frame segmentation, which is costly for mobile deployment and brittle under challenging illumination. We present DAGS-SLAM, a dynamic-aware 3DGS-SLAM system that maintains a spatiotemporal motion probability (MP) state per Gaussian and triggers semantics on demand via an uncertainty-aware scheduler. DAGS-SLAM fuses lightweight YOLO instance priors with geometric cues to estimate and temporally update MP, propagates MP to the front-end for dynamic-aware correspondence selection, and suppresses dynamic artifacts in the back-end via MP-guided optimization. Experiments on public dynamic RGB-D benchmarks show improved reconstruction and robust tracking while sustaining real-time throughput on a commodity GPU, demonstrating a practical speed-accuracy tradeoff with reduced semantic invocations toward mobile deployment.","authors":["Li Zhang","Yu-An Liu","Xijia Jiang","Conghao Huang","Danyang Li","Yanyong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21633v1","updated":"2026-02-25T06:58:06Z","published":"2026-02-25T06:58:06Z","title":"Self-Correcting VLA: Online Action Refinement via Sparse World Imagination","summary":"Standard vision-language-action (VLA) models rely on fitting statistical data priors, limiting their robust understanding of underlying physical dynamics. Reinforcement learning enhances physical grounding through exploration yet typically relies on external reward signals that remain isolated from the agent's internal states. World action models have emerged as a promising paradigm that integrates imagination and control to enable predictive planning. However, they rely on implicit context modeling, lacking explicit mechanisms for self-improvement. To solve these problems, we propose Self-Correcting VLA (SC-VLA), which achieve self-improvement by intrinsically guiding action refinement through sparse imagination. We first design sparse world imagination by integrating auxiliary predictive heads to forecast current task progress and future trajectory trends, thereby constraining the policy to encode short-term physical evolution. Then we introduce the online action refinement module to reshape progress-dependent dense rewards, adjusting trajectory orientation based on the predicted sparse future states. Evaluations on challenging robot manipulation tasks from simulation benchmarks and real-world settings demonstrate that SC-VLA achieve state-of-the-art performance, yielding the highest task throughput with 16% fewer steps and a 9% higher success rate than the best-performing baselines, alongside a 14% gain in real-world experiments. Code is available at https://github.com/Kisaragi0/SC-VLA.","authors":["Chenyv Liu","Wentao Tan","Lei Zhu","Fengling Li","Jingjing Li","Guoli Yang","Heng Tao Shen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21625v1","updated":"2026-02-25T06:40:59Z","published":"2026-02-25T06:40:59Z","title":"Tacmap: Bridging the Tactile Sim-to-Real Gap via Geometry-Consistent Penetration Depth Map","summary":"Vision-Based Tactile Sensors (VBTS) are essential for achieving dexterous robotic manipulation, yet the tactile sim-to-real gap remains a fundamental bottleneck. Current tactile simulations suffer from a persistent dilemma: simplified geometric projections lack physical authenticity, while high-fidelity Finite Element Methods (FEM) are too computationally prohibitive for large-scale reinforcement learning. In this work, we present Tacmap, a high-fidelity, computationally efficient tactile simulation framework anchored in volumetric penetration depth. Our key insight is to bridge the tactile sim-to-real gap by unifying both domains through a shared deform map representation. Specifically, we compute 3D intersection volumes as depth maps in simulation, while in the real world, we employ an automated data-collection rig to learn a robust mapping from raw tactile images to ground-truth depth maps. By aligning simulation and real-world in this unified geometric space, Tacmap minimizes domain shift while maintaining physical consistency. Quantitative evaluations across diverse contact scenarios demonstrate that Tacmap's deform maps closely mirror real-world measurements. Moreover, we validate the utility of Tacmap through an in-hand rotation task, where a policy trained exclusively in simulation achieves zero-shot transfer to a physical robot.","authors":["Lei Su","Zhijie Peng","Renyuan Ren","Shengping Mao","Juan Du","Kaifeng Zhang","Xuezhou Zhu"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2602.21622v1","updated":"2026-02-25T06:35:19Z","published":"2026-02-25T06:35:19Z","title":"ADM-DP: Adaptive Dynamic Modality Diffusion Policy through Vision-Tactile-Graph Fusion for Multi-Agent Manipulation","summary":"Multi-agent robotic manipulation remains challenging due to the combined demands of coordination, grasp stability, and collision avoidance in shared workspaces. To address these challenges, we propose the Adaptive Dynamic Modality Diffusion Policy (ADM-DP), a framework that integrates vision, tactile, and graph-based (multi-agent pose) modalities for coordinated control. ADM-DP introduces four key innovations. First, an enhanced visual encoder merges RGB and point-cloud features via Feature-wise Linear Modulation (FiLM) modulation to enrich perception. Second, a tactile-guided grasping strategy uses Force-Sensitive Resistor (FSR) feedback to detect insufficient contact and trigger corrective grasp refinement, improving grasp stability. Third, a graph-based collision encoder leverages shared tool center point (TCP) positions of multiple agents as structured kinematic context to maintain spatial awareness and reduce inter-agent interference. Fourth, an Adaptive Modality Attention Mechanism (AMAM) dynamically re-weights modalities according to task context, enabling flexible fusion. For scalability and modularity, a decoupled training paradigm is employed in which agents learn independent policies while sharing spatial information. This maintains low interdependence between agents while retaining collective awareness. Across seven multi-agent tasks, ADM-DP achieves 12-25% performance gains over state-of-the-art baselines. Ablation studies show the greatest improvements in tasks requiring multiple sensory modalities, validating our adaptive fusion strategy and demonstrating its robustness for diverse manipulation scenarios.","authors":["Enyi Wang","Wen Fan","Dandan Zhang"],"pdf_url":"","comment":"Accepted to IEEE International Conference on Robotics and Automation (ICRA 2026)"},{"id":"http://arxiv.org/abs/2602.21612v1","updated":"2026-02-25T06:13:59Z","published":"2026-02-25T06:13:59Z","title":"Jumping Control for a Quadrupedal Wheeled-Legged Robot via NMPC and DE Optimization","summary":"Quadrupedal wheeled-legged robots combine the advantages of legged and wheeled locomotion to achieve superior mobility, but executing dynamic jumps remains a significant challenge due to the additional degrees of freedom introduced by wheeled legs. This paper develops a mini-sized wheeled-legged robot for agile motion and presents a novel motion control framework that integrates the Nonlinear Model Predictive Control (NMPC) for locomotion and the Differential Evolution (DE) based trajectory optimization for jumping in quadrupedal wheeled-legged robots. The proposed controller utilizes wheel motion and locomotion to enhance jumping performance, achieving versatile maneuvers such as vertical jumping, forward jumping, and backflips. Extensive simulations and real-world experiments validate the effectiveness of the framework, demonstrating a forward jump over a 0.12 m obstacle and a vertical jump reaching 0.5 m.","authors":["Xuanqi Zeng","Lingwei Zhang","Linzhu Yue","Zhitao Song","Hongbo Zhang","Tianlin Zhang","Yun-Hui Liu"],"pdf_url":"","comment":"8 pages, 12 figures"},{"id":"http://arxiv.org/abs/2509.22548v2","updated":"2026-02-25T06:06:37Z","published":"2025-09-26T16:29:37Z","title":"JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation","summary":"Vision-and-Language Navigation requires an embodied agent to navigate through unseen environments, guided by natural language instructions and a continuous video stream. Recent advances in VLN have been driven by the powerful semantic understanding of Multimodal Large Language Models. However, these methods typically rely on explicit semantic memory, such as building textual cognitive maps or storing historical visual frames. This type of method suffers from spatial information loss, computational redundancy, and memory bloat, which impede efficient navigation. Inspired by the implicit scene representation in human navigation, analogous to the left brain's semantic understanding and the right brain's spatial cognition, we propose JanusVLN, a novel VLN framework featuring a dual implicit neural memory that models spatial-geometric and visual-semantic memory as separate, compact, and fixed-size neural representations. This framework first extends the MLLM to incorporate 3D prior knowledge from the spatial-geometric encoder, thereby enhancing the spatial reasoning capabilities of models based solely on RGB input. Then, the historical key-value caches from the spatial-geometric and visual-semantic encoders are constructed into a dual implicit memory. By retaining only the KVs of tokens in the initial and sliding window, redundant computation is avoided, enabling efficient incremental updates. Extensive experiments demonstrate that JanusVLN outperforms over 20 recent methods to achieve SOTA performance. For example, the success rate improves by 10.5-35.5 compared to methods using multiple data types as input and by 3.6-10.8 compared to methods using more RGB training data. This indicates that the proposed dual implicit neural memory, as a novel paradigm, explores promising new directions for future VLN research. Ours project page: https://miv-xjtu.github.io/JanusVLN.github.io/.","authors":["Shuang Zeng","Dekang Qi","Xinyuan Chang","Feng Xiong","Shichao Xie","Xiaolong Wu","Shiyi Liang","Mu Xu","Xing Wei","Ning Guo"],"pdf_url":"","comment":"Accepted to ICLR 2026. Project page: https://miv-xjtu.github.io/JanusVLN.github.io/"},{"id":"http://arxiv.org/abs/2602.21599v1","updated":"2026-02-25T05:52:37Z","published":"2026-02-25T05:52:37Z","title":"Iterative Closed-Loop Motion Synthesis for Scaling the Capabilities of Humanoid Control","summary":"Physics-based humanoid control relies on training with motion datasets that have diverse data distributions. However, the fixed difficulty distribution of datasets limits the performance ceiling of the trained control policies. Additionally, the method of acquiring high-quality data through professional motion capture systems is constrained by costs, making it difficult to achieve large-scale scalability. To address these issues, we propose a closed-loop automated motion data generation and iterative framework. It can generate high-quality motion data with rich action semantics, including martial arts, dance, combat, sports, gymnastics, and more. Furthermore, our framework enables difficulty iteration of policies and data through physical metrics and objective evaluations, allowing the trained tracker to break through its original difficulty limits. On the PHC single-primitive tracker, using only approximately 1/10 of the AMASS dataset size, the average failure rate on the test set (2201 clips) is reduced by 45\\% compared to the baseline. Finally, we conduct comprehensive ablation and comparative experiments to highlight the rationality and advantages of our framework.","authors":["Weisheng Xu","Qiwei Wu","Jiaxi Zhang","Tan Jing","Yangfan Li","Yuetong Fang","Jiaqi Xiong","Kai Wu","Rong Ou","Renjing Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21595v1","updated":"2026-02-25T05:44:21Z","published":"2026-02-25T05:44:21Z","title":"SPOC: Safety-Aware Planning Under Partial Observability And Physical Constraints","summary":"Embodied Task Planning with large language models faces safety challenges in real-world environments, where partial observability and physical constraints must be respected. Existing benchmarks often overlook these critical factors, limiting their ability to evaluate both feasibility and safety. We introduce SPOC, a benchmark for safety-aware embodied task planning, which integrates strict partial observability, physical constraints, step-by-step planning, and goal-condition-based evaluation. Covering diverse household hazards such as fire, fluid, injury, object damage, and pollution, SPOC enables rigorous assessment through both state and constraint-based online metrics. Experiments with state-of-the-art LLMs reveal that current models struggle to ensure safety-aware planning, particularly under implicit constraints. Code and dataset are available at https://github.com/khm159/SPOC","authors":["Hyungmin Kim","Hobeom Jeon","Dohyung Kim","Minsu Jang","Jeahong Kim"],"pdf_url":"","comment":"Accepted to IEEE ICASSP 2026"},{"id":"http://arxiv.org/abs/2509.16370v5","updated":"2026-02-25T05:27:38Z","published":"2025-09-19T19:26:22Z","title":"Dual-Regularized Riccati Recursions for Interior-Point Optimal Control","summary":"We derive closed-form extensions of Riccati's recursions (both sequential and parallel) for solving dual-regularized LQR problems. We show how these methods can be used to solve general constrained, non-convex, discrete-time optimal control problems via a regularized interior point method, while guaranteeing that each primal step is a descent direction of an Augmented Barrier-Lagrangian merit function. We provide MIT-licensed implementations of our methods in C++ and JAX.","authors":["João Sousa-Pinto","Dominique Orban"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21583v1","updated":"2026-02-25T05:13:25Z","published":"2026-02-25T05:13:25Z","title":"Learning Agile and Robust Omnidirectional Aerial Motion on Overactuated Tiltable-Quadrotors","summary":"Tilt-rotor aerial robots enable omnidirectional maneuvering through thrust vectoring, but introduce significant control challenges due to the strong coupling between joint and rotor dynamics. While model-based controllers can achieve high motion accuracy under nominal conditions, their robustness and responsiveness often degrade in the presence of disturbances and modeling uncertainties. This work investigates reinforcement learning for omnidirectional aerial motion control on over-actuated tiltable quadrotors that prioritizes robustness and agility. We present a learning-based control framework that enables efficient acquisition of coordinated rotor-joint behaviors for reaching target poses in the $SE(3)$ space. To achieve reliable sim-to-real transfer while preserving motion accuracy, we integrate system identification with minimal and physically consistent domain randomization. Compared with a state-of-the-art NMPC controller, the proposed method achieves comparable six-degree-of-freedom pose tracking accuracy, while demonstrating superior robustness and generalization across diverse tasks, enabling zero-shot deployment on real hardware.","authors":["Wentao Zhang","Zhaoqi Ma","Jinjie Li","Huayi Wang","Haokun Liu","Junichiro Sugihara","Chen Chen","Yicheng Chen","Moju Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21531v1","updated":"2026-02-25T03:33:39Z","published":"2026-02-25T03:33:39Z","title":"LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies","summary":"General-purpose robots must master long-horizon manipulation, defined as tasks involving multiple kinematic structure changes (e.g., attaching or detaching objects) in unstructured environments. While Vision-Language-Action (VLA) models offer the potential to master diverse atomic skills, they struggle with the combinatorial complexity of sequencing them and are prone to cascading failures due to environmental sensitivity. To address these challenges, we propose LiLo-VLA (Linked Local VLA), a modular framework capable of zero-shot generalization to novel long-horizon tasks without ever being trained on them. Our approach decouples transport from interaction: a Reaching Module handles global motion, while an Interaction Module employs an object-centric VLA to process isolated objects of interest, ensuring robustness against irrelevant visual features and invariance to spatial configurations. Crucially, this modularity facilitates robust failure recovery through dynamic replanning and skill reuse, effectively mitigating the cascading errors common in end-to-end approaches. We introduce a 21-task simulation benchmark consisting of two challenging suites: LIBERO-Long++ and Ultra-Long. In these simulations, LiLo-VLA achieves a 69% average success rate, outperforming Pi0.5 by 41% and OpenVLA-OFT by 67%. Furthermore, real-world evaluations across 8 long-horizon tasks demonstrate an average success rate of 85%. Project page: https://yy-gx.github.io/LiLo-VLA/.","authors":["Yue Yang","Shuo Cheng","Yu Fang","Homanga Bharadhwaj","Mingyu Ding","Gedas Bertasius","Daniel Szafir"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.21112v5","updated":"2026-02-25T03:30:53Z","published":"2025-08-28T17:26:15Z","title":"EO-1: An Open Unified Embodied Foundation Model for General Robot Control","summary":"The human ability to seamlessly perform multimodal reasoning and physical interaction in the open world is a core goal for general purpose embodied intelligent systems. Recent vision-language-action (VLA) models, which are co-trained on large-scale robot and visual-text data, have demonstrated notable progress in general robot control. However, they still fail to achieve human-level flexibility in interleaved reasoning and interaction. In this work, we introduce EO-Robotics, consists of EO-1 model and EO-Data1.5M dataset. EO-1 is a unified embodied foundation model that achieves superior performance in multimodal embodied reasoning and robot control through interleaved vision-text-action pre-training. The development of EO-1 is based on two key pillars: (i) a unified architecture that processes multimodal inputs indiscriminately (image, text, video, and action), and (ii) a massive, high-quality multimodal embodied reasoning dataset, EO-Data1.5M, which contains over 1.5 million samples with emphasis on interleaved vision-text-action comprehension. EO-1 is trained through synergies between auto-regressive decoding and flow matching denoising on EO-Data1.5M, enabling seamless robot action generation and multimodal embodied reasoning. Extensive experiments demonstrate the effectiveness of interleaved vision-text-action learning for open-world understanding and generalization, validated through a variety of long-horizon, dexterous manipulation tasks across multiple embodiments. This paper details the architecture of EO-1, the data construction strategy of EO-Data1.5M, and the training methodology, offering valuable insights for developing advanced embodied foundation models. Project Page: https://eo-robotics.ai/eo-1.","authors":["Delin Qu","Haoming Song","Qizhi Chen","Zhaoqing Chen","Xianqiang Gao","Dong Wang","Xinyi Ye","Qi Lv","Modi Shi","Guanghui Ren","Cheng Ruan","Maoqing Yao","Haoran Yang","Jiacheng Bao","Bin Zhao","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.18316v4","updated":"2026-02-25T03:29:42Z","published":"2025-10-21T05:56:47Z","title":"MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation","summary":"Imitation learning from large-scale, diverse human demonstrations has been shown to be effective for training robots, but collecting such data is costly and time-consuming. This challenge intensifies for multi-step bimanual mobile manipulation, where humans must teleoperate both the mobile base and two high-DoF arms. Prior X-Gen works have developed automated data generation frameworks for static (bimanual) manipulation tasks, augmenting a few human demos in simulation with novel scene configurations to synthesize large-scale datasets. However, prior works fall short for bimanual mobile manipulation tasks for two major reasons: 1) a mobile base introduces the problem of how to place the robot base to enable downstream manipulation (reachability) and 2) an active camera introduces the problem of how to position the camera to generate data for a visuomotor policy (visibility). To address these challenges, MoMaGen formulates data generation as a constrained optimization problem that satisfies hard constraints (e.g., reachability) while balancing soft constraints (e.g., visibility while navigation). This formulation generalizes across most existing automated data generation approaches and offers a principled foundation for developing future methods. We evaluate on four multi-step bimanual mobile manipulation tasks and find that MoMaGen enables the generation of much more diverse datasets than previous methods. As a result of the dataset diversity, we also show that the data generated by MoMaGen can be used to train successful imitation learning policies using a single source demo. Furthermore, the trained policy can be fine-tuned with a very small amount of real-world data (40 demos) to be succesfully deployed on real robotic hardware. More details are on our project page: momagen.github.io.","authors":["Chengshu Li","Mengdi Xu","Arpit Bahety","Hang Yin","Yunfan Jiang","Huang Huang","Josiah Wong","Sujay Garlanka","Cem Gokmen","Ruohan Zhang","Weiyu Liu","Jiajun Wu","Roberto Martín-Martín","Li Fei-Fei"],"pdf_url":"","comment":"Project website: momagen.github.io. The first four authors contribute equally. Accpeted to International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2510.18060v2","updated":"2026-02-25T02:51:23Z","published":"2025-10-20T19:53:02Z","title":"SPACeR: Self-Play Anchoring with Centralized Reference Models","summary":"Developing autonomous vehicles (AVs) requires not only safety and efficiency, but also realistic, human-like behaviors that are socially aware and predictable. Achieving this requires sim agent policies that are human-like, fast, and scalable in multi-agent settings. Recent progress in imitation learning with large diffusion-based or tokenized models has shown that behaviors can be captured directly from human driving data, producing realistic policies. However, these models are computationally expensive, slow during inference, and struggle to adapt in reactive, closed-loop scenarios. In contrast, self-play reinforcement learning (RL) scales efficiently and naturally captures multi-agent interactions, but it often relies on heuristics and reward shaping, and the resulting policies can diverge from human norms. We propose SPACeR, a framework that leverages a pretrained tokenized autoregressive motion model as a centralized reference policy to guide decentralized self-play. The reference model provides likelihood rewards and KL divergence, anchoring policies to the human driving distribution while preserving RL scalability. Evaluated on the Waymo Sim Agents Challenge, our method achieves competitive performance with imitation-learned policies while being up to 10x faster at inference and 50x smaller in parameter size than large generative models. In addition, we demonstrate in closed-loop ego planning evaluation tasks that our sim agents can effectively measure planner quality with fast and scalable traffic simulation, establishing a new paradigm for testing autonomous driving policies.","authors":["Wei-Jer Chang","Akshay Rangesh","Kevin Joseph","Matthew Strong","Masayoshi Tomizuka","Yihan Hu","Wei Zhan"],"pdf_url":"","comment":"Accepted at ICLR 2026. Project page: https://spacer-ai.github.io/"},{"id":"http://arxiv.org/abs/2602.03447v2","updated":"2026-02-25T02:08:01Z","published":"2026-02-03T12:12:47Z","title":"HetroD: A High-Fidelity Drone Dataset and Benchmark for Autonomous Driving in Heterogeneous Traffic","summary":"We present HetroD, a dataset and benchmark for developing autonomous driving systems in heterogeneous environments. HetroD targets the critical challenge of navi- gating real-world heterogeneous traffic dominated by vulner- able road users (VRUs), including pedestrians, cyclists, and motorcyclists that interact with vehicles. These mixed agent types exhibit complex behaviors such as hook turns, lane splitting, and informal right-of-way negotiation. Such behaviors pose significant challenges for autonomous vehicles but remain underrepresented in existing datasets focused on structured, lane-disciplined traffic. To bridge the gap, we collect a large- scale drone-based dataset to provide a holistic observation of traffic scenes with centimeter-accurate annotations, HD maps, and traffic signal states. We further develop a modular toolkit for extracting per-agent scenarios to support downstream task development. In total, the dataset comprises over 65.4k high- fidelity agent trajectories, 70% of which are from VRUs. HetroD supports modeling of VRU behaviors in dense, het- erogeneous traffic and provides standardized benchmarks for forecasting, planning, and simulation tasks. Evaluation results reveal that state-of-the-art prediction and planning models struggle with the challenges presented by our dataset: they fail to predict lateral VRU movements, cannot handle unstructured maneuvers, and exhibit limited performance in dense and multi-agent scenarios, highlighting the need for more robust approaches to heterogeneous traffic. See our project page for more examples: https://hetroddata.github.io/HetroD/","authors":["Yu-Hsiang Chen","Wei-Jer Chang","Christian Kotulla","Thomas Keutgens","Steffen Runde","Tobias Moers","Christoph Klas","Wei Zhan","Masayoshi Tomizuka","Yi-Ting Chen"],"pdf_url":"","comment":"IEEE International Conference on Robotics and Automation (ICRA) 2026"},{"id":"http://arxiv.org/abs/2602.21450v1","updated":"2026-02-25T00:06:08Z","published":"2026-02-25T00:06:08Z","title":"Constructive Vector Fields for Path Following in Fully-Actuated Systems on Matrix Lie Groups","summary":"This paper presents a novel vector field strategy for controlling fully-actuated systems on connected matrix Lie groups, ensuring convergence to and traversal along a curve defined on the group. Our approach generalizes our previous work (Rezende et al., 2022) and reduces to it when considering the Lie group of translations in Euclidean space. Since the proofs in Rezende et al. (2022) rely on key properties such as the orthogonality between the convergent and traversal components, we extend these results by leveraging Lie group properties. These properties also allow the control input to be non-redundant, meaning it matches the dimension of the Lie group, rather than the potentially larger dimension of the space in which the group is embedded. This can lead to more practical control inputs in certain scenarios. A particularly notable application of our strategy is in controlling systems on SE(3) -- in this case, the non-redundant input corresponds to the object's mechanical twist -- making it well-suited for controlling objects that can move and rotate freely, such as omnidirectional drones. In this case, we provide an efficient algorithm to compute the vector field. We experimentally validate the proposed method using a robotic manipulator to demonstrate its effectiveness.","authors":["Felipe Bartelt","Vinicius M. Gonçalves","Luciano C. A. Pimenta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.02011v2","updated":"2026-02-25T00:03:29Z","published":"2025-12-01T18:59:45Z","title":"Learning Dexterous Manipulation Skills from Imperfect Simulations","summary":"Reinforcement learning and sim-to-real transfer have made significant progress in dexterous manipulation. However, progress remains limited by the difficulty of simulating complex contact dynamics and multisensory signals, especially tactile feedback. In this work, we propose \\ours, a sim-to-real framework that addresses these limitations and demonstrates its effectiveness on nut-bolt fastening and screwdriving with multi-fingered hands. The framework has three stages. First, we train reinforcement learning policies in simulation using simplified object models that lead to the emergence of correct finger gaits. We then use the learned policy as a skill primitive within a teleoperation system to collect real-world demonstrations that contain tactile and proprioceptive information. Finally, we train a behavior cloning policy that incorporates tactile sensing and show that it generalizes to nuts and screwdrivers with diverse geometries. Experiments across both tasks show high task progress ratios compared to direct sim-to-real transfer and robust performance even on unseen object shapes and under external perturbations. Videos and code are available on https://dexscrew.github.io.","authors":["Elvis Hsieh","Wen-Han Hsieh","Yen-Jen Wang","Toru Lin","Jitendra Malik","Koushil Sreenath","Haozhi Qi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22474v1","updated":"2026-02-25T23:23:22Z","published":"2026-02-25T23:23:22Z","title":"When to Act, Ask, or Learn: Uncertainty-Aware Policy Steering","summary":"Policy steering is an emerging way to adapt robot behaviors at deployment-time: a learned verifier analyzes low-level action samples proposed by a pre-trained policy (e.g., diffusion policy) and selects only those aligned with the task. While Vision-Language Models (VLMs) are promising general-purpose verifiers due to their reasoning capabilities, existing frameworks often assume these models are well-calibrated. In practice, the overconfident judgment from VLM can degrade the steering performance under both high-level semantic uncertainty in task specifications and low-level action uncertainty or incapability of the pre-trained policy. We propose uncertainty-aware policy steering (UPS), a framework that jointly reasons about semantic task uncertainty and low-level action feasibility, and selects an uncertainty resolution strategy: execute a high-confidence action, clarify task ambiguity via natural language queries, or ask for action interventions to correct the low-level policy when it is deemed incapable at the task. We leverage conformal prediction to calibrate the composition of the VLM and the pre-trained base policy, providing statistical assurances that the verifier selects the correct strategy. After collecting interventions during deployment, we employ residual learning to improve the capability of the pre-trained policy, enabling the system to learn continually but with minimal expensive human feedback. We demonstrate our framework through experiments in simulation and on hardware, showing that UPS can disentangle confident, ambiguous, and incapable scenarios and minimizes expensive user interventions compared to uncalibrated baselines and prior human- or robot-gated continual learning approaches. Videos can be found at https://jessie-yuan.github.io/ups/","authors":["Jessie Yuan","Yilin Wu","Andrea Bajcsy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22461v1","updated":"2026-02-25T22:50:51Z","published":"2026-02-25T22:50:51Z","title":"EgoAVFlow: Robot Policy Learning with Active Vision from Human Egocentric Videos via 3D Flow","summary":"Egocentric human videos provide a scalable source of manipulation demonstrations; however, deploying them on robots requires active viewpoint control to maintain task-critical visibility, which human viewpoint imitation often fails to provide due to human-specific priors. We propose EgoAVFlow, which learns manipulation and active vision from egocentric videos through a shared 3D flow representation that supports geometric visibility reasoning and transfers without robot demonstrations. EgoAVFlow uses diffusion models to predict robot actions, future 3D flow, and camera trajectories, and refines viewpoints at test time with reward-maximizing denoising under a visibility-aware reward computed from predicted motion and scene geometry. Real-world experiments under actively changing viewpoints show that EgoAVFlow consistently outperforms prior human-demo-based baselines, demonstrating effective visibility maintenance and robust manipulation without robot demonstrations.","authors":["Daesol Cho","Youngseok Jang","Danfei Xu","Sehoon Ha"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22459v1","updated":"2026-02-25T22:49:54Z","published":"2026-02-25T22:49:54Z","title":"Hierarchical Trajectory Planning of Floating-Base Multi-Link Robot for Maneuvering in Confined Environments","summary":"Floating-base multi-link robots can change their shape during flight, making them well-suited for applications in confined environments such as autonomous inspection and search and rescue. However, trajectory planning for such systems remains an open challenge because the problem lies in a high-dimensional, constraint-rich space where collision avoidance must be addressed together with kinematic limits and dynamic feasibility. This work introduces a hierarchical trajectory planning framework that integrates global guidance with configuration-aware local optimization. First, we exploit the dual nature of these robots - the root link as a rigid body for guidance and the articulated joints for flexibility - to generate global anchor states that decompose the planning problem into tractable segments. Second, we design a local trajectory planner that optimizes each segment in parallel with differentiable objectives and constraints, systematically enforcing kinematic feasibility and maintaining dynamic feasibility by avoiding control singularities. Third, we implement a complete system that directly processes point-cloud data, eliminating the need for handcrafted obstacle models. Extensive simulations and real-world experiments confirm that this framework enables an articulated aerial robot to exploit its morphology for maneuvering that rigid robots cannot achieve. To the best of our knowledge, this is the first planning framework for floating-base multi-link robots that has been demonstrated on a real robot to generate continuous, collision-free, and dynamically feasible trajectories directly from raw point-cloud inputs, without relying on handcrafted obstacle models.","authors":["Yicheng Chen","Jinjie Li","Haokun Liu","Zicheng Luo","Kotaro Kaneko","Moju Zhao"],"pdf_url":"","comment":"Accepted to IEEE T-ASE; DOI pending"},{"id":"http://arxiv.org/abs/2602.22452v1","updated":"2026-02-25T22:27:30Z","published":"2026-02-25T22:27:30Z","title":"CWM: Contrastive World Models for Action Feasibility Learning in Embodied Agent Pipelines","summary":"A reliable action feasibility scorer is a critical bottleneck in embodied agent pipelines: before any planning or reasoning occurs, the agent must identify which candidate actions are physically executable in the current state. Existing approaches use supervised fine-tuning (SFT) to train action scorers, but SFT treats each candidate independently and does not explicitly teach the model to discriminate between actions that are physically correct and those that are subtly wrong. We propose the Contrastive World Model (CWM), which fine-tunes a large language model (LLM) as an action scorer using an InfoNCE contrastive objective with hard-mined negative examples. The key idea is to push valid actions away from invalid ones in scoring space, with special emphasis on hard negatives: semantically similar but physically incompatible candidates. We evaluate CWM on the ScienceWorld benchmark through two studies. First, an intrinsic affordance evaluation on 605 hard-negative test pairs shows that CWM outperforms SFT by +6.76 percentage points on Precision@1 for minimal-edit negatives -- cases where a single word changes the physical outcome -- and achieves a higher AUC-ROC (0.929 vs. 0.906). Second, a live filter characterisation study measures how well CWM ranks gold-path actions against all valid environment actions during task execution. Under out-of-distribution stress conditions, CWM maintains a significantly better safety margin (-2.39) than SFT (-3.96), indicating that the gold action is ranked closer to the top. These results support the hypothesis that contrastive training induces representations that capture physical feasibility more faithfully than SFT alone.","authors":["Chayan Banerjee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.21553v4","updated":"2026-02-25T20:57:06Z","published":"2025-07-29T07:34:26Z","title":"Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments","summary":"Multi-robot SLAM aims at localizing and building a map with multiple robots, interacting with each other. In the work described in this article, we analyze the pipeline of a decentralized LiDAR SLAM system to study the current limitations of the state of the art, and we discover a significant source of failures, i.e., that the loop detection is the source of too many false positives. We therefore develop and propose a new heuristic to overcome these limitations. The environment taken as reference in this work is the highly challenging case of underground tunnels. We also highlight potential new research areas still under-explored.","authors":["Federica Di Lauro","Domenico G. Sorrenti","Miguel Angel Sotelo"],"pdf_url":"","comment":"14 pages, 14 figures"},{"id":"http://arxiv.org/abs/2507.07467v2","updated":"2026-02-25T19:16:54Z","published":"2025-07-10T06:42:53Z","title":"SCREP: Scene Coordinate Regression and Evidential Learning-based Perception-Aware Trajectory Generation","summary":"Autonomous flight in GPS-denied indoor spaces requires trajectories that keep visual-localization error tightly bounded across varied missions. Map-based visual localization methods such as feature matching require computationally intensive map reconstruction and have feature-storage scalability issues, especially for large environments. Scene coordinate regression (SCR) provides an efficient learning-based alternative that directly predicts3D coordinates for every pixel, enabling absolute pose estimation with significant potential for onboard roboticsapplications. We present a perception-aware trajectory planner that couples an evidential learning-based SCR poseestimator with a receding-horizon trajectory optimizer. The optimizer steers the onboard camera toward reliablescene coordinates with low uncertainty, while a fixed-lag smoother fuses the low-rate SCR pose estimates with high-rate IMU data to provide a high-quality, high-rate pose estimate. In simulation, our planner reduces translationand rotation RMSE by at least 4.9% and 30.8% relative to baselines, respectively. Hardware-in-the-loop experiments validate the feasibility of our proposed trajectory planner under close-to-real deployment conditions.","authors":["Juyeop Han","Lukas Lao Beyer","Guilherme V. Cavalheiro","Sertac Karaman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22346v1","updated":"2026-02-25T19:12:07Z","published":"2026-02-25T19:12:07Z","title":"Detection and Recognition: A Pairwise Interaction Framework for Mobile Service Robots","summary":"Autonomous mobile service robots, like lawnmowers or cleaning robots, operating in human-populated environments need to reason about local human-human interactions to support safe and socially aware navigation while fulfilling their tasks. For such robots, interaction understanding is not primarily a fine-grained recognition problem, but a perception problem under limited sensing quality and computational resources. Many existing approaches focus on holistic group activity recognition, which often requires complex and large models which may not be necessary for mobile service robots. Others use pairwise interaction methods which commonly rely on skeletal representations but their use in outdoor environments remains challenging. In this work, we argue that pairwise human interaction constitute a minimal yet sufficient perceptual unit for robot-centric social understanding. We study the problem of identifying interacting person pairs and classifying coarse-grained interaction behaviors sufficient for downstream group-level reasoning and service robot decision-making. To this end, we adopt a two-stage framework in which candidate interacting pairs are first identified based on lightweight geometric and motion cues, and interaction types are subsequently classified using a relation network. We evaluate the proposed approach on the JRDB dataset, where it achieves sufficient accuracy with reduced computational cost and model size compared to appearance-based methods. Additional experiments on the Collective Activity Dataset and zero shot test on a lawnmower-collected dataset further illustrate the generality of the proposed framework. These results suggest that pairwise geometric and motion cues provide a practical basis for interaction perception on mobile service robot providing a promising method for integration into mobile robot navigation stacks in future work. Code will be released soon","authors":["Mengyu Liang","Sarah Gillet Schlegel","Iolanda Leite"],"pdf_url":"","comment":null}]},"2026-02-26T00:00:00Z":{"Artificial Intelligence (Agents & Multi-Agent Systems)":[{"id":"http://arxiv.org/abs/2602.23360v1","updated":"2026-02-26T18:59:32Z","published":"2026-02-26T18:59:32Z","title":"Model Agreement via Anchoring","summary":"Numerous lines of aim to control $\\textit{model disagreement}$ -- the extent to which two machine learning models disagree in their predictions. We adopt a simple and standard notion of model disagreement in real-valued prediction problems, namely the expected squared difference in predictions between two models trained on independent samples, without any coordination of the training processes. We would like to be able to drive disagreement to zero with some natural parameter(s) of the training procedure using analyses that can be applied to existing training methodologies.\n  We develop a simple general technique for proving bounds on independent model disagreement based on $\\textit{anchoring}$ to the average of two models within the analysis. We then apply this technique to prove disagreement bounds for four commonly used machine learning algorithms: (1) stacked aggregation over an arbitrary model class (where disagreement is driven to 0 with the number of models $k$ being stacked) (2) gradient boosting (where disagreement is driven to 0 with the number of iterations $k$) (3) neural network training with architecture search (where disagreement is driven to 0 with the size $n$ of the architecture being optimized over) and (4) regression tree training over all regression trees of fixed depth (where disagreement is driven to 0 with the depth $d$ of the tree architecture). For clarity, we work out our initial bounds in the setting of one-dimensional regression with squared error loss -- but then show that all of our results generalize to multi-dimensional regression with any strongly convex loss.","authors":["Eric Eaton","Surbhi Goel","Marcel Hussing","Michael Kearns","Aaron Roth","Sikata Bela Sengupta","Jessica Sorrell"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23359v1","updated":"2026-02-26T18:59:05Z","published":"2026-02-26T18:59:05Z","title":"SeeThrough3D: Occlusion Aware 3D Control in Text-to-Image Generation","summary":"We identify occlusion reasoning as a fundamental yet overlooked aspect for 3D layout-conditioned generation. It is essential for synthesizing partially occluded objects with depth-consistent geometry and scale. While existing methods can generate realistic scenes that follow input layouts, they often fail to model precise inter-object occlusions. We propose SeeThrough3D, a model for 3D layout conditioned generation that explicitly models occlusions. We introduce an occlusion-aware 3D scene representation (OSCR), where objects are depicted as translucent 3D boxes placed within a virtual environment and rendered from desired camera viewpoint. The transparency encodes hidden object regions, enabling the model to reason about occlusions, while the rendered viewpoint provides explicit camera control during generation. We condition a pretrained flow based text-to-image image generation model by introducing a set of visual tokens derived from our rendered 3D representation. Furthermore, we apply masked self-attention to accurately bind each object bounding box to its corresponding textual description, enabling accurate generation of multiple objects without object attribute mixing. To train the model, we construct a synthetic dataset with diverse multi-object scenes with strong inter-object occlusions. SeeThrough3D generalizes effectively to unseen object categories and enables precise 3D layout control with realistic occlusions and consistent camera control.","authors":["Vaibhav Agrawal","Rishubh Parihar","Pradhaan Bhat","Ravi Kiran Sarvadevabhatla","R. Venkatesh Babu"],"pdf_url":"","comment":"Project page: https://seethrough3d.github.io. Accepted at CVPR 2026"},{"id":"http://arxiv.org/abs/2602.23353v1","updated":"2026-02-26T18:55:06Z","published":"2026-02-26T18:55:06Z","title":"SOTAlign: Semi-Supervised Alignment of Unimodal Vision and Language Models via Optimal Transport","summary":"The Platonic Representation Hypothesis posits that neural networks trained on different modalities converge toward a shared statistical model of the world. Recent work exploits this convergence by aligning frozen pretrained vision and language models with lightweight alignment layers, but typically relies on contrastive losses and millions of paired samples. In this work, we ask whether meaningful alignment can be achieved with substantially less supervision. We introduce a semi-supervised setting in which pretrained unimodal encoders are aligned using a small number of image-text pairs together with large amounts of unpaired data. To address this challenge, we propose SOTAlign, a two-stage framework that first recovers a coarse shared geometry from limited paired data using a linear teacher, then refines the alignment on unpaired samples via an optimal-transport-based divergence that transfers relational structure without overconstraining the target space. Unlike existing semi-supervised methods, SOTAlign effectively leverages unpaired images and text, learning robust joint embeddings across datasets and encoder pairs, and significantly outperforming supervised and semi-supervised baselines.","authors":["Simon Roschmann","Paul Krzakala","Sonia Mazelet","Quentin Bouniot","Zeynep Akata"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2602.23349v1","updated":"2026-02-26T18:52:22Z","published":"2026-02-26T18:52:22Z","title":"FlashOptim: Optimizers for Memory Efficient Training","summary":"Standard mixed-precision training of neural networks requires many bytes of accelerator memory for each model parameter. These bytes reflect not just the parameter itself, but also its gradient and one or more optimizer state variables. With each of these values typically requiring 4 bytes, training even a 7 billion parameter model can be impractical for researchers with less than 100GB of accelerator memory.\n  We introduce FlashOptim, a suite of optimizations that reduces per-parameter memory by over 50% while preserving model quality and API compatibility. Our approach introduces two key techniques. First, we improve master weight splitting by finding and exploiting a tight bound on its quantization error. Second, we design companding functions that greatly reduce the error in 8-bit optimizer state quantization. Together with 16-bit gradients, these techniques reduce AdamW memory from 16 bytes to 7 bytes per parameter, or 5 bytes with gradient release. They also cut model checkpoint sizes by more than half.\n  Experiments with FlashOptim applied to SGD, AdamW, and Lion show no measurable quality degradation on any task from a collection of standard vision and language benchmarks, including Llama-3.1-8B finetuning.","authors":["Jose Javier Gonzalez Ortiz","Abhay Gupta","Chris Renard","Davis Blalock"],"pdf_url":"","comment":"Source code is available at https://github.com/databricks/flashoptim"},{"id":"http://arxiv.org/abs/2602.23335v1","updated":"2026-02-26T18:40:28Z","published":"2026-02-26T18:40:28Z","title":"Understanding Usage and Engagement in AI-Powered Scientific Research Tools: The Asta Interaction Dataset","summary":"AI-powered scientific research tools are rapidly being integrated into research workflows, yet the field lacks a clear lens into how researchers use these systems in real-world settings. We present and analyze the Asta Interaction Dataset, a large-scale resource comprising over 200,000 user queries and interaction logs from two deployed tools (a literature discovery interface and a scientific question-answering interface) within an LLM-powered retrieval-augmented generation platform. Using this dataset, we characterize query patterns, engagement behaviors, and how usage evolves with experience. We find that users submit longer and more complex queries than in traditional search, and treat the system as a collaborative research partner, delegating tasks such as drafting content and identifying research gaps. Users treat generated responses as persistent artifacts, revisiting and navigating among outputs and cited evidence in non-linear ways. With experience, users issue more targeted queries and engage more deeply with supporting citations, although keyword-style queries persist even among experienced users. We release the anonymized dataset and analysis with a new query intent taxonomy to inform future designs of real-world AI research assistants and to support realistic evaluation.","authors":["Dany Haddad","Dan Bareket","Joseph Chee Chang","Jay DeYoung","Jena D. Hwang","Uri Katz","Mark Polak","Sangho Suh","Harshit Surana","Aryeh Tiktinsky","Shriya Atmakuri","Jonathan Bragg","Mike D'Arcy","Sergey Feldman","Amal Hassan-Ali","Rubén Lozano","Bodhisattwa Prasad Majumder","Charles McGrady","Amanpreet Singh","Brooke Vlahos","Yoav Goldberg","Doug Downey"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23334v1","updated":"2026-02-26T18:40:02Z","published":"2026-02-26T18:40:02Z","title":"Bitwise Systolic Array Architecture for Runtime-Reconfigurable Multi-precision Quantized Multiplication on Hardware Accelerators","summary":"Neural network accelerators have been widely applied to edge devices for complex tasks like object tracking, image recognition, etc. Previous works have explored the quantization technologies in related lightweight accelerator designs to reduce hardware resource consumption. However, low precision leads to high accuracy loss in inference. Therefore, mixed-precision quantization becomes an alternative solution by applying different precision in different layers to trade off resource consumption and accuracy. Because regular designs for multiplication on hardware cannot support the precision reconfiguration for a multi-precision Quantized Neural Network (QNN) model in runtime, we propose a runtime reconfigurable multi-precision multi-channel bitwise systolic array design for QNN accelerators. We have implemented and evaluated our work on the Ultra96 FPGA platform. Results show that our work can achieve 1.3185 to 3.5671 times speedup in inferring mixed-precision models and has less critical path delay, supporting a higher clock frequency (250MHz).","authors":["Yuhao Liu","Salim Ullah","Akash Kumar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23331v1","updated":"2026-02-26T18:38:00Z","published":"2026-02-26T18:38:00Z","title":"Utilizing LLMs for Industrial Process Automation","summary":"A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years. However, most of this work focuses on widely-used general purpose programming languages like Python due to their widespread usage training data. The utility of LLMs for software within the industrial process automation domain, with highly-specialized languages that are typically only used in proprietary contexts, remains underexplored. This research aims to utilize and integrate LLMs in the industrial development process, solving real-life programming tasks (e.g., generating a movement routine for a robotic arm) and accelerating the development cycles of manufacturing systems.","authors":["Salim Fares"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23330v1","updated":"2026-02-26T18:37:36Z","published":"2026-02-26T18:37:36Z","title":"Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks","summary":"The advancement of large language models (LLMs) has accelerated the development of autonomous financial trading systems. While mainstream approaches deploy multi-agent systems mimicking analyst and manager roles, they often rely on abstract instructions that overlook the intricacies of real-world workflows, which can lead to degraded inference performance and less transparent decision-making. Therefore, we propose a multi-agent LLM trading framework that explicitly decomposes investment analysis into fine-grained tasks, rather than providing coarse-grained instructions. We evaluate the proposed framework using Japanese stock data, including prices, financial statements, news, and macro information, under a leakage-controlled backtesting setting. Experimental results show that fine-grained task decomposition significantly improves risk-adjusted returns compared to conventional coarse-grained designs. Crucially, further analysis of intermediate agent outputs suggests that alignment between analytical outputs and downstream decision preferences is a critical driver of system performance. Moreover, we conduct standard portfolio optimization, exploiting low correlation with the stock index and the variance of each system's output. This approach achieves superior performance. These findings contribute to the design of agent structure and task configuration when applying LLM agents to trading systems in practical settings.","authors":["Kunihiro Miyazaki","Takanobu Kawahara","Stephen Roberts","Stefan Zohren"],"pdf_url":"","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2602.23329v1","updated":"2026-02-26T18:37:23Z","published":"2026-02-26T18:37:23Z","title":"LLM Novice Uplift on Dual-Use, In Silico Biology Tasks","summary":"Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reserved for trained practitioners, underscoring the need for sustained, interactive uplift evaluations alongside traditional benchmarks.","authors":["Chen Bo Calvin Zhang","Christina Q. Knight","Nicholas Kruus","Jason Hausenloy","Pedro Medeiros","Nathaniel Li","Aiden Kim","Yury Orlovskiy","Coleman Breen","Bryce Cai","Jasper Götting","Andrew Bo Liu","Samira Nedungadi","Paula Rodriguez","Yannis Yiming He","Mohamed Shaaban","Zifan Wang","Seth Donoughe","Julian Michael"],"pdf_url":"","comment":"59 pages, 33 figures"},{"id":"http://arxiv.org/abs/2510.10932v2","updated":"2026-02-26T18:32:27Z","published":"2025-10-13T02:45:48Z","title":"DropVLA: An Action-Level Backdoor Attack on Vision--Language--Action Models","summary":"Vision-Language-Action (VLA) models map multimodal perception and language instructions to executable robot actions, making them particularly vulnerable to behavioral backdoor manipulation: a hidden trigger introduced during training can induce unintended physical actions while nominal task performance remains intact. Prior work on VLA backdoors primarily studies untargeted attacks or task-level hijacking, leaving fine-grained control over individual actions largely unexplored. In this work, we present DropVLA, an action-level backdoor attack that forces a reusable action primitive (e.g., open_gripper) to execute at attacker-chosen decision points under a realistic pipeline-black-box setting with limited data-poisoning access, using a window-consistent relabeling scheme for chunked fine-tuning. On OpenVLA-7B evaluated with LIBERO, vision-only poisoning achieves 98.67%-99.83% attack success rate (ASR) with only 0.31% poisoned episodes while preserving 98.50%-99.17% clean-task retention, and successfully triggers the targeted action within 25 control steps at 500 Hz (0.05 s). Text-only triggers are unstable at low poisoning budgets, and combining text with vision provides no consistent ASR improvement over vision-only attacks. The backdoor remains robust to moderate trigger variations and transfers across evaluation suites (96.27%, 99.09%), whereas text-only largely fails (0.72%). We further validate physical-world feasibility on a 7-DoF Franka arm with pi0-fast, demonstrating non-trivial attack efficacy under camera-relative motion that induces image-plane trigger drift. These results reveal that VLA models can be covertly steered at the granularity of safety-critical actions with minimal poisoning and without observable degradation of nominal performance.","authors":["Zonghuan Xu","Xiang Zheng","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"","comment":"8 pages, 6 tables, 3 figures. Under review"},{"id":"http://arxiv.org/abs/2602.23318v1","updated":"2026-02-26T18:25:59Z","published":"2026-02-26T18:25:59Z","title":"Generalized Rapid Action Value Estimation in Memory-Constrained Environments","summary":"Generalized Rapid Action Value Estimation (GRAVE) has been shown to be a strong variant within the Monte-Carlo Tree Search (MCTS) family of algorithms for General Game Playing (GGP). However, its reliance on storing additional win/visit statistics at each node makes its use impractical in memory-constrained environments, thereby limiting its applicability in practice. In this paper, we introduce the GRAVE2, GRAVER and GRAVER2 algorithms, which extend GRAVE through two-level search, node recycling, and a combination of both techniques, respectively. We show that these enhancements enable a drastic reduction in the number of stored nodes while matching the playing strength of GRAVE.","authors":["Aloïs Rautureau","Tristan Cazenave","Éric Piette"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23315v1","updated":"2026-02-26T18:22:40Z","published":"2026-02-26T18:22:40Z","title":"Invariant Transformation and Resampling based Epistemic-Uncertainty Reduction","summary":"An artificial intelligence (AI) model can be viewed as a function that maps inputs to outputs in high-dimensional spaces. Once designed and well trained, the AI model is applied for inference. However, even optimized AI models can produce inference errors due to aleatoric and epistemic uncertainties. Interestingly, we observed that when inferring multiple samples based on invariant transformations of an input, inference errors can show partial independences due to epistemic uncertainty. Leveraging this insight, we propose a \"resampling\" based inferencing that applies to a trained AI model with multiple transformed versions of an input, and aggregates inference outputs to a more accurate result. This approach has the potential to improve inference accuracy and offers a strategy for balancing model size and performance.","authors":["Sha Hu"],"pdf_url":"","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2602.23312v1","updated":"2026-02-26T18:20:26Z","published":"2026-02-26T18:20:26Z","title":"Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction","summary":"Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge.","authors":["Rafael R. Baptista","André de Lima Salgado","Ricardo V. Godoy","Marcelo Becker","Thiago Boaventura","Gustavo J. G. Lahr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.12522v2","updated":"2026-02-26T18:17:44Z","published":"2025-04-16T23:02:23Z","title":"Evaluating the Diversity and Quality of LLM Generated Content","summary":"Recent work suggests that preference-tuning techniques -- such as Reinforcement Learning from Human Feedback (RLHF) methods like PPO and GRPO, as well as alternatives like DPO -- reduce diversity, creating a dilemma given that these models are widely deployed in applications requiring varied outputs. We argue that diversity without consideration of quality has limited practical value. To address this issue, we introduce a framework for measuring effective semantic diversity -- diversity among outputs that meet quality thresholds -- which better reflects the practical utility of large language models (LLMs). Using open-ended tasks that require no human intervention, we find counterintuitive results: when using diversity metrics that do not explicitly consider quality, preference-tuned models -- particularly those trained via RL -- often produce outputs with lower diversity; however, these same preference-tuned models generate greater effective semantic diversity than supervised fine-tuned (SFT) or base models. Our analysis further shows another trend: while larger models may exhibit greater effective semantic diversity than smaller models, the smaller models are consistently more parameter-efficient at producing unique content within a fixed sampling budget. These findings have practical implications for applications that require diverse yet high-quality outputs, from creative assistance to synthetic data generation.","authors":["Alexander Shypula","Shuo Li","Botong Zhang","Vishakh Padmakumar","Kayo Yin","Osbert Bastani"],"pdf_url":"","comment":"Published at COLM 2025"},{"id":"http://arxiv.org/abs/2602.21189v2","updated":"2026-02-26T18:11:36Z","published":"2026-02-24T18:43:08Z","title":"Why Pass@k Optimization Can Degrade Pass@1: Prompt Interference in LLM Post-training","summary":"Pass@k is a widely used performance metric for verifiable large language model tasks, including mathematical reasoning, code generation, and short-answer reasoning. It defines success if any of $k$ independently sampled solutions passes a verifier. This multi-sample inference metric has motivated inference-aware fine-tuning methods that directly optimize pass@$k$. However, prior work reports a recurring trade-off: pass@k improves while pass@1 degrades under such methods. This trade-off is practically important because pass@1 often remains a hard operational constraint due to latency and cost budgets, imperfect verifier coverage, and the need for a reliable single-shot fallback. We study the origin of this trade-off and provide a theoretical characterization of when pass@k policy optimization can reduce pass@1 through gradient conflict induced by prompt interference. We show that pass@$k$ policy gradients can conflict with pass@1 gradients because pass@$k$ optimization implicitly reweights prompts toward low-success prompts; when these prompts are what we term negatively interfering, their upweighting can rotate the pass@k update direction away from the pass@1 direction. We illustrate our theoretical findings with large language model experiments on verifiable mathematical reasoning tasks.","authors":["Anas Barakat","Souradip Chakraborty","Khushbu Pahwa","Amrit Singh Bedi"],"pdf_url":"","comment":"updated related work discussion"},{"id":"http://arxiv.org/abs/2602.23302v1","updated":"2026-02-26T18:09:02Z","published":"2026-02-26T18:09:02Z","title":"The logic of KM belief update is contained in the logic of AGM belief revision","summary":"For each axiom of KM belief update we provide a corresponding axiom in a modal logic containing three modal operators: a unimodal belief operator $B$, a bimodal conditional operator $>$ and the unimodal necessity operator $\\square$. We then compare the resulting logic to the similar logic obtained from converting the AGM axioms of belief revision into modal axioms and show that the latter contains the former. Denoting the latter by $\\mathcal L_{AGM}$ and the former by $\\mathcal L_{KM}$ we show that every axiom of $\\mathcal L_{KM}$ is a theorem of $\\mathcal L_{AGM}$. Thus AGM belief revision can be seen as a special case of KM belief update. For the strong version of KM belief update we show that the difference between $\\mathcal L_{KM}$ and $\\mathcal L_{AGM}$ can be narrowed down to a single axiom, which deals exclusively with unsurprising information, that is, with formulas that were not initially disbelieved.","authors":["Giacomo Bonanno"],"pdf_url":"","comment":"arXiv admin note: text overlap with arXiv:2310.11506. text overlap with arXiv:2310.11506"},{"id":"http://arxiv.org/abs/2602.23296v1","updated":"2026-02-26T18:07:45Z","published":"2026-02-26T18:07:45Z","title":"Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity","summary":"Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals.","authors":["Quang-Huy Nguyen","Jiaqi Wang","Wei-Shinn Ku"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.19060v3","updated":"2026-02-26T18:05:42Z","published":"2025-10-21T20:30:20Z","title":"PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions","summary":"While vision-language models (VLMs) have advanced into detailed image description, evaluation remains a challenge. Standard metrics (e.g. CIDEr, SPICE) were designed for short texts and tuned to recognize errors that are now uncommon, such as object misidentification. In contrast, long texts require sensitivity to attribute and relation attachments and scores that localize errors to particular text spans. In this work, we introduce PoSh, a metric for detailed image description that uses scene graphs as structured rubrics to guide LLMs-as-a-Judge, producing aggregate scores grounded in fine-grained errors (e.g. mistakes in compositional understanding). PoSh is replicable, interpretable and a better proxy for human raters than existing metrics (including GPT4o-as-a-Judge). To validate PoSh, we introduce a challenging new dataset, DOCENT. This novel benchmark contains artwork, paired with expert-written references, and model-generated descriptions, augmented with granular and coarse judgments of their quality from art history students. Thus, DOCENT enables evaluating both detailed image description metrics and detailed image description itself in a challenging new domain. We show that PoSh achieves stronger correlations (+0.05 Spearman $ρ$) with the human judgments in DOCENT than the best open-weight alternatives, is robust to image type (using CapArena, an existing dataset of web imagery) and is a capable reward function, outperforming standard supervised fine-tuning. Then, using PoSh, we characterize the performance of open and closed models in describing the paintings, sketches and statues in DOCENT and find that foundation models struggle to achieve full, error-free coverage of images with rich scene dynamics, establishing a demanding new task to gauge VLM progress. Through both PoSh and DOCENT, we hope to enable advances in important areas such as assistive text generation.","authors":["Amith Ananthram","Elias Stengel-Eskin","Lorena A. Bradford","Julia Demarest","Adam Purvis","Keith Krut","Robert Stein","Rina Elster Pantalony","Mohit Bansal","Kathleen McKeown"],"pdf_url":"","comment":"Accepted at ICLR 2026. 26 pages, 9 figures. Metric/benchmark available at https://github.com/amith-ananthram/posh"},{"id":"http://arxiv.org/abs/2408.17251v2","updated":"2026-02-26T18:03:25Z","published":"2024-08-30T12:50:15Z","title":"Abstracted Gaussian Prototypes for True One-Shot Concept Learning","summary":"We introduce a cluster-based generative image segmentation framework to encode higher-level representations of visual concepts based on one-shot learning inspired by the Omniglot Challenge. The inferred parameters of each component of a Gaussian Mixture Model (GMM) represent a distinct topological subpart of a visual concept. Sampling new data from these parameters generates augmented subparts to build a more robust prototype for each concept, i.e., the Abstracted Gaussian Prototype (AGP). This framework addresses one-shot classification tasks using a cognitively-inspired similarity metric and addresses one-shot generative tasks through a novel AGP-VAE pipeline employing variational autoencoders (VAEs) to generate new class variants. Results from human judges reveal that the generative pipeline produces novel examples and classes of visual concepts that are broadly indistinguishable from those made by humans. The proposed framework leads to impressive, but not state-of-the-art, classification accuracy; thus, the contribution is two-fold: 1) the system is low in theoretical and computational complexity yet achieves the standard of 'true' one-shot learning by operating in a fully standalone manner unlike existing approaches that draw heavily on pre-training or knowledge engineering; and 2) in contrast with existing neural network approaches, the AGP approach addresses the importance of broad task capability emphasized in the Omniglot challenge (successful performance on classification and generative tasks). These two points are critical in advancing our understanding of how learning and reasoning systems can produce viable, robust, and flexible concepts based on literally no more than a single example.","authors":["Chelsea Zou","Kenneth J. Kurtz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03495v2","updated":"2026-02-26T18:01:35Z","published":"2025-10-03T20:18:58Z","title":"AgentHub: A Registry for Discoverable, Verifiable, and Reproducible AI Agents","summary":"LLM-based agents are rapidly proliferating, yet the infrastructure for discovering, evaluating, and governing them remains fragmented compared to mature ecosystems like software package registries (e.g., npm) and model hubs (e.g., Hugging Face). Existing efforts typically address naming, distribution, or protocol descriptors, but stop short of providing a registry layer that makes agents discoverable, comparable, and governable under automated reuse. We present AgentHub, a registry layer and accompanying research agenda for agent sharing that targets discovery and workflow integration, trust and security, openness and governance, ecosystem interoperability, lifecycle transparency, and capability clarity with evidence. We describe a reference prototype that implements a canonical manifest with publish-time validation, version-bound evidence records linked to auditable artifacts, and an append-only lifecycle event log whose states are respected by default in search and resolution. We also provide initial discovery results using an LLM-as-judge recommendation pipeline, showing how structured contracts and evidence improve intent-accurate retrieval beyond keyword-driven discovery. AgentHub aims to provide a common substrate for building reliable, reusable agent ecosystems.","authors":["Erik Pautsch","Tanmay Singla","Parv Kumar","Wenxin Jiang","Huiyun Peng","Behnaz Hassanshahi","Konstantin Läufer","George K. Thiruvathukal","James C. Davis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23286v1","updated":"2026-02-26T17:59:51Z","published":"2026-02-26T17:59:51Z","title":"SPARTA: Scalable and Principled Benchmark of Tree-Structured Multi-hop QA over Text and Tables","summary":"Real-world Table-Text question answering (QA) tasks require models that can reason across long text and source tables, traversing multiple hops and executing complex operations such as aggregation. Yet existing benchmarks are small, manually curated - and therefore error-prone - and contain shallow questions that seldom demand more than two hops or invoke aggregations, grouping, or other advanced analytical operations expressible in natural-language queries. We present SPARTA, an end-to-end construction framework that automatically generates large-scale Table-Text QA benchmarks with lightweight human validation, requiring only one quarter of the annotation time of HybridQA. The framework first constructs a reference fact database by enriching each source table with grounding tables whose tuples are atomic facts automatically extracted from the accompanying unstructured passages, then synthesizes nested queries whose number of nested predicates matches the desired hop count. To ensure that every SQL statement is executable and that its verbalization yields a fluent, human-sounding question, we propose two novel techniques: provenance-based refinement, which rewrites any syntactically valid query that returns a non-empty result, and realistic-structure enforcement, which confines generation to post-order traversals of the query graph. The resulting pipeline produces thousands of high-fidelity question-answer pairs covering aggregations, grouping, and deep multi-hop reasoning across text and tables. On SPARTA, state-of-the-art models that reach over 70 F1 on HybridQA or over 50 F1 on OTT-QA drop by more than 30 F1 points, exposing fundamental weaknesses in current cross-modal reasoning. Our benchmark, construction code, and baseline models are available at https://github.com/pshlego/SPARTA/tree/main.","authors":["Sungho Park","Jueun Kim","Wook-Shin Han"],"pdf_url":"","comment":"10 pages, 5 figures. Published as a conference paper at ICLR 2026. Project page: https://sparta-projectpage.github.io/"},{"id":"http://arxiv.org/abs/2602.23285v1","updated":"2026-02-26T17:59:10Z","published":"2026-02-26T17:59:10Z","title":"ODEBrain: Continuous-Time EEG Graph for Modeling Dynamic Brain Networks","summary":"Modeling neural population dynamics is crucial for foundational neuroscientific research and various clinical applications. Conventional latent variable methods typically model continuous brain dynamics through discretizing time with recurrent architecture, which necessarily results in compounded cumulative prediction errors and failure of capturing instantaneous, nonlinear characteristics of EEGs. We propose ODEBRAIN, a Neural ODE latent dynamic forecasting framework to overcome these challenges by integrating spatio-temporal-frequency features into spectral graph nodes, followed by a Neural ODE modeling the continuous latent dynamics. Our design ensures that latent representations can capture stochastic variations of complex brain states at any given time point. Extensive experiments verify that ODEBRAIN can improve significantly over existing methods in forecasting EEG dynamics with enhanced robustness and generalization capabilities.","authors":["Haohui Jia","Zheng Chen","Lingwei Zhu","Rikuto Kotoge","Jathurshan Pradeepkumar","Yasuko Matsubara","Jimeng Sun","Yasushi Sakurai","Takashi Matsubara"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.02655v2","updated":"2026-02-26T17:56:58Z","published":"2025-09-02T15:13:14Z","title":"BioBlue: Systematic runaway-optimiser-like LLM failure modes on biologically and economically aligned AI safety benchmarks for LLMs with simplified observation format","summary":"Many AI alignment discussions of \"runaway optimisation\" focus on RL agents: unbounded utility maximisers that over-optimise a proxy objective (e.g., \"paperclip maximiser\", specification gaming) at the expense of everything else. LLM-based systems are often assumed to be safer because they function as next-token predictors rather than persistent optimisers. In this work, we empirically test this assumption by placing LLMs in simple, long-horizon control-style environments that require maintaining state of or balancing objectives over time: sustainability of a renewable resource, single- and multi-objective homeostasis, and balancing unbounded objectives with diminishing returns. We find that, although models frequently behave appropriately for many steps and clearly understand the stated objectives, they often lose context in structured ways and drift into runaway behaviours: ignoring homeostatic targets, collapsing from multi-objective trade-offs into single-objective maximisation - thus failing to respect concave utility structures. These failures emerge reliably after initial periods of competent behaviour and exhibit characteristic patterns (including self-imitative oscillations, unbounded maximisation, and reverting to single-objective optimisation). The problem is not that the LLMs just lose context or become incoherent - the failures systematically resemble runaway optimisers. Our results suggest that long-horizon, multi-objective misalignment is a genuine and under-evaluated failure mode in LLM agents, even in extremely simple settings with transparent and explicitly multi-objective feedback. Although LLMs appear multi-objective and bounded on the surface, their behaviour under sustained interaction, particularly involving multiple objectives, resembles brittle, poorly aligned optimisers whose effective objective gradually shifts toward unbounded and single-metric maximisation.","authors":["Roland Pihlakas","Sruthi Susan Kuriakose"],"pdf_url":"","comment":"22 pages, 8 tables"},{"id":"http://arxiv.org/abs/2602.23276v1","updated":"2026-02-26T17:51:21Z","published":"2026-02-26T17:51:21Z","title":"CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays","summary":"Chest X-ray plays a central role in thoracic diagnosis, and its interpretation inherently requires multi-step, evidence-grounded reasoning. However, large vision-language models (LVLMs) often generate plausible responses that are not faithfully grounded in diagnostic evidence and provide limited visual evidence for verification, while also requiring costly retraining to support new diagnostic tasks, limiting their reliability and adaptability in clinical settings. To address these limitations, we present CXReasonAgent, a diagnostic agent that integrates a large language model (LLM) with clinically grounded diagnostic tools to perform evidence-grounded diagnostic reasoning using image-derived diagnostic and visual evidence. To evaluate these capabilities, we introduce CXReasonDial, a multi-turn dialogue benchmark with 1,946 dialogues across 12 diagnostic tasks, and show that CXReasonAgent produces faithfully grounded responses, enabling more reliable and verifiable diagnostic reasoning than LVLMs. These findings highlight the importance of integrating clinically grounded diagnostic tools, particularly in safety-critical clinical settings.","authors":["Hyungyung Lee","Hangyul Yoon","Edward Choi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23271v1","updated":"2026-02-26T17:46:42Z","published":"2026-02-26T17:46:42Z","title":"Evaluating Stochasticity in Deep Research Agents","summary":"Deep Research Agents (DRAs) are promising agentic systems that gather and synthesize information to support research across domains such as financial decision-making, medical analysis, and scientific discovery. Despite recent improvements in research quality (e.g., outcome accuracy when ground truth is available), DRA system design often overlooks a critical barrier to real-world deployment: stochasticity. Under identical queries, repeated executions of DRAs can exhibit substantial variability in terms of research outcome, findings, and citations. In this paper, we formalize the study of stochasticity in DRAs by modeling them as information acquisition Markov Decision Processes. We introduce an evaluation framework that quantifies variance in the system and identify three sources of it: information acquisition, information compression, and inference. Through controlled experiments, we investigate how stochasticity from these modules across different decision steps influences the variance of DRA outputs. Our results show that reducing stochasticity can improve research output quality, with inference and early-stage stochasticity contributing the most to DRA output variance. Based on these findings, we propose strategies for mitigating stochasticity while maintaining output quality via structured output and ensemble-based query generation. Our experiments on DeepSearchQA show that our proposed mitigation methods reduce average stochasticity by 22% while maintaining high research quality.","authors":["Haotian Zhai","Elias Stengel-Eskin","Pratik Patil","Liu Leqi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.04228v2","updated":"2026-02-26T17:37:05Z","published":"2025-08-06T09:03:16Z","title":"LayerT2V: A Unified Multi-Layer Video Generation Framework","summary":"Text-to-video generation has advanced rapidly, but existing methods typically output only the final composited video and lack editable layered representations, limiting their use in professional workflows. We propose \\textbf{LayerT2V}, a unified multi-layer video generation framework that produces multiple semantically consistent outputs in a single inference pass: the full video, an independent background layer, and multiple foreground RGB layers with corresponding alpha mattes. Our key insight is that recent video generation backbones use high compression in both time and space, enabling us to serialize multiple layer representations along the temporal dimension and jointly model them on a shared generation trajectory. This turns cross-layer consistency into an intrinsic objective, improving semantic alignment and temporal coherence. To mitigate layer ambiguity and conditional leakage, we augment a shared DiT backbone with LayerAdaLN and layer-aware cross-attention modulation. LayerT2V is trained in three stages: alpha mask VAE adaptation, joint multi-layer learning, and multi-foreground extension. We also introduce \\textbf{VidLayer}, the first large-scale dataset for multi-layer video generation. Extensive experiments demonstrate that LayerT2V substantially outperforms prior methods in visual fidelity, temporal consistency, and cross-layer coherence.","authors":["Guangzhao Li","Kangrui Cen","Baixuan Zhao","Yi Xin","Siqi Luo","Guangtao Zhai","Lei Zhang","Xiaohong Liu"],"pdf_url":"","comment":"Project Page is https://layert2v.github.io/"},{"id":"http://arxiv.org/abs/2509.17956v2","updated":"2026-02-26T17:36:21Z","published":"2025-09-22T16:12:12Z","title":"\"I think this is fair\": Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment","summary":"Assessing fairness in artificial intelligence (AI) typically involves AI experts who select protected features, fairness metrics, and set fairness thresholds to assess outcome fairness. However, little is known about how stakeholders, particularly those affected by AI outcomes but lacking AI expertise, assess fairness. To address this gap, we conducted a qualitative study with 26 stakeholders without AI expertise, representing potential decision subjects in a credit rating scenario, to examine how they assess fairness when placed in the role of deciding on features with priority, metrics, and thresholds. We reveal that stakeholders' fairness decisions are more complex than typical AI expert practices: they considered features far beyond legally protected features, tailored metrics for specific contexts, set diverse yet stricter fairness thresholds, and even preferred designing customized fairness. Our results extend the understanding of how stakeholders can meaningfully contribute to AI fairness governance and mitigation, underscoring the importance of incorporating stakeholders' nuanced fairness judgments.","authors":["Lin Luo","Yuri Nakao","Mathieu Chollet","Hiroya Inakoshi","Simone Stumpf"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.20570v2","updated":"2026-02-26T17:33:06Z","published":"2025-08-28T09:08:30Z","title":"Dyslexify: A Mechanistic Defense Against Typographic Attacks in CLIP","summary":"Typographic attacks exploit multi-modal systems by injecting text into images, leading to targeted misclassifications, malicious content generation and even Vision-Language Model jailbreaks. In this work, we analyze how CLIP vision encoders behave under typographic attacks, locating specialized attention heads in the latter half of the model's layers that causally extract and transmit typographic information to the cls token. Building on these insights, we introduce Dyslexify - a method to defend CLIP models against typographic attacks by selectively ablating a typographic circuit, consisting of attention heads. Without requiring finetuning, dyslexify improves performance by up to 22.06% on a typographic variant of ImageNet-100, while reducing standard ImageNet-100 accuracy by less than 1%, and demonstrate its utility in a medical foundation model for skin lesion diagnosis. Notably, our training-free approach remains competitive with current state-of-the-art typographic defenses that rely on finetuning. To this end, we release a family of dyslexic CLIP models which are significantly more robust against typographic attacks. These models serve as suitable drop-in replacements for a broad range of safety-critical applications, where the risks of text-based manipulation outweigh the utility of text recognition.","authors":["Lorenz Hufe","Constantin Venhoff","Erblina Purelku","Maximilian Dreyer","Sebastian Lapuschkin","Wojciech Samek"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23259v1","updated":"2026-02-26T17:32:30Z","published":"2026-02-26T17:32:30Z","title":"Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving","summary":"With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn to minimize the discrepancy between their actions and expert actions. However, this objective of \"only driving like the expert\" suffers from limited generalization: when encountering rare or unseen long-tail scenarios outside the distribution of expert demonstrations, models tend to produce unsafe decisions in the absence of prior experience. This raises a fundamental question: Can an E2E-AD system make reliable decisions without any expert action supervision? Motivated by this, we propose a unified framework named Risk-aware World Model Predictive Control (RaWMPC) to address this generalization dilemma through robust control, without reliance on expert demonstrations. Practically, RaWMPC leverages a world model to predict the consequences of multiple candidate actions and selects low-risk actions through explicit risk evaluation. To endow the world model with the ability to predict the outcomes of risky driving behaviors, we design a risk-aware interaction strategy that systematically exposes the world model to hazardous behaviors, making catastrophic outcomes predictable and thus avoidable. Furthermore, to generate low-risk candidate actions at test time, we introduce a self-evaluation distillation method to distill riskavoidance capabilities from the well-trained world model into a generative action proposal network without any expert demonstration. Extensive experiments show that RaWMPC outperforms state-of-the-art methods in both in-distribution and out-of-distribution scenarios, while providing superior decision interpretability.","authors":["Jiangxin Sun","Feng Xue","Teng Long","Chang Liu","Jian-Fang Hu","Wei-Shi Zheng","Nicu Sebe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23258v1","updated":"2026-02-26T17:31:43Z","published":"2026-02-26T17:31:43Z","title":"AgentDropoutV2: Optimizing Information Flow in Multi-Agent Systems via Test-Time Rectify-or-Reject Pruning","summary":"While Multi-Agent Systems (MAS) excel in complex reasoning, they suffer from the cascading impact of erroneous information generated by individual participants. Current solutions often resort to rigid structural engineering or expensive fine-tuning, limiting their deployability and adaptability. We propose AgentDropoutV2, a test-time rectify-or-reject pruning framework designed to dynamically optimize MAS information flow without retraining. Our approach acts as an active firewall, intercepting agent outputs and employing a retrieval-augmented rectifier to iteratively correct errors based on a failure-driven indicator pool. This mechanism allows for the precise identification of potential errors using distilled failure patterns as prior knowledge. Irreparable outputs are subsequently pruned to prevent error propagation, while a fallback strategy preserves system integrity. Empirical results on extensive math benchmarks show that AgentDropoutV2 significantly boosts the MAS's task performance, achieving an average accuracy gain of 6.3 percentage points on math benchmarks. Furthermore, the system exhibits robust generalization and adaptivity, dynamically modulating rectification efforts based on task difficulty while leveraging context-aware indicators to resolve a wide spectrum of error patterns. Our code and dataset are released at https://github.com/TonySY2/AgentDropoutV2.","authors":["Yutong Wang","Siyuan Xiong","Xuebo Liu","Wenkang Zhou","Liang Ding","Miao Zhang","Min Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23248v1","updated":"2026-02-26T17:25:22Z","published":"2026-02-26T17:25:22Z","title":"Mitigating Legibility Tax with Decoupled Prover-Verifier Games","summary":"As large language models become increasingly capable, it is critical that their outputs can be easily checked by less capable systems. Prover-verifier games can be used to improve checkability of model outputs, but display a degradation in accuracy compared to a baseline trained only to maximize correctness -- a phenonemon named legibility tax. We propose a solution by decoupling the correctness from the checkability condition and instead training a \"translator\" model that turns a fixed solver model's solution into a checkable form. This allows us to first train the solver to maximize correctness, and then train the translator to translate the solver into a checkable form while retaining the solver's answer. To accommodate this new objective of translation, we formulate a decoupled prover-verifier game where the equilibria correspond to faithful and checkable translators.","authors":["Yegon Kim","Juho Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23242v1","updated":"2026-02-26T17:21:16Z","published":"2026-02-26T17:21:16Z","title":"A Model-Free Universal AI","summary":"In general reinforcement learning, all established optimal agents, including AIXI, are model-based, explicitly maintaining and using environment models. This paper introduces Universal AI with Q-Induction (AIQI), the first model-free agent proven to be asymptotically $\\varepsilon$-optimal in general RL. AIQI performs universal induction over distributional action-value functions, instead of policies or environments like previous works. Under a grain of truth condition, we prove that AIQI is strong asymptotically $\\varepsilon$-optimal and asymptotically $\\varepsilon$-Bayes-optimal. Our results significantly expand the diversity of known universal agents.","authors":["Yegon Kim","Juho Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23239v1","updated":"2026-02-26T17:16:17Z","published":"2026-02-26T17:16:17Z","title":"Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive","summary":"AI systems are increasingly deployed in high-stakes contexts -- medical diagnosis, legal research, financial analysis -- under the assumption they can be governed by norms. This paper demonstrates that assumption is formally invalid for optimization-based systems, specifically Large Language Models trained via Reinforcement Learning from Human Feedback (RLHF). We establish that genuine agency requires two necessary and jointly sufficient architectural conditions: the capacity to maintain certain boundaries as non-negotiable constraints rather than tradeable weights (Incommensurability), and a non-inferential mechanism capable of suspending processing when those boundaries are threatened (Apophatic Responsiveness). These conditions apply across all normative domains.\n  RLHF-based systems are constitutively incompatible with both conditions. The operations that make optimization powerful -- unifying all values on a scalar metric and always selecting the highest-scoring output -- are precisely the operations that preclude normative governance. This incompatibility is not a correctable training bug awaiting a technical fix; it is a formal constraint inherent to what optimization is. Consequently, documented failure modes - sycophancy, hallucination, and unfaithful reasoning - are not accidents but structural manifestations.\n  Misaligned deployment triggers a second-order risk we term the Convergence Crisis: when humans are forced to verify AI outputs under metric pressure, they degrade from genuine agents into criteria-checking optimizers, eliminating the only component in the system capable of normative accountability. Beyond the incompatibility proof, the paper's primary positive contribution is a substrate-neutral architectural specification defining what any system -- biological, artificial, or institutional -- must satisfy to qualify as an agent rather than a sophisticated instrument.","authors":["Radha Sarma"],"pdf_url":"","comment":"About 10,500 words in all (including 922 words of literature and 2019 words of Appendices). Under journal review"},{"id":"http://arxiv.org/abs/2602.23235v1","updated":"2026-02-26T17:12:40Z","published":"2026-02-26T17:12:40Z","title":"Spatio-Temporal Token Pruning for Efficient High-Resolution GUI Agents","summary":"Pure-vision GUI agents provide universal interaction capabilities but suffer from severe efficiency bottlenecks due to the massive spatiotemporal redundancy inherent in high-resolution screenshots and historical trajectories. We identify two critical misalignments in existing compression paradigms: the temporal mismatch, where uniform history encoding diverges from the agent's \"fading memory\" attention pattern, and the spatial topology conflict, where unstructured pruning compromises the grid integrity required for precise coordinate grounding, inducing spatial hallucinations. To address these challenges, we introduce GUIPruner, a training-free framework tailored for high-resolution GUI navigation. It synergizes Temporal-Adaptive Resolution (TAR), which eliminates historical redundancy via decay-based resizing, and Stratified Structure-aware Pruning (SSP), which prioritizes interactive foregrounds and semantic anchors while safeguarding global layout. Extensive evaluations across diverse benchmarks demonstrate that GUIPruner consistently achieves state-of-the-art performance, effectively preventing the collapse observed in large-scale models under high compression. Notably, on Qwen2-VL-2B, our method delivers a 3.4x reduction in FLOPs and a 3.3x speedup in vision encoding latency while retaining over 94% of the original performance, enabling real-time, high-precision navigation with minimal resource consumption.","authors":["Zhou Xu","Bowen Zhou","Qi Wang","Shuwen Feng","Jingyu Xiao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23234v1","updated":"2026-02-26T17:11:26Z","published":"2026-02-26T17:11:26Z","title":"Scaling Search Relevance: Augmenting App Store Ranking with LLM-Generated Judgments","summary":"Large-scale commercial search systems optimize for relevance to drive successful sessions that help users find what they are looking for. To maximize relevance, we leverage two complementary objectives: behavioral relevance (results users tend to click or download) and textual relevance (a result's semantic fit to the query). A persistent challenge is the scarcity of expert-provided textual relevance labels relative to abundant behavioral relevance labels. We first address this by systematically evaluating LLM configurations, finding that a specialized, fine-tuned model significantly outperforms a much larger pre-trained one in providing highly relevant labels. Using this optimal model as a force multiplier, we generate millions of textual relevance labels to overcome the data scarcity. We show that augmenting our production ranker with these textual relevance labels leads to a significant outward shift of the Pareto frontier: offline NDCG improves for behavioral relevance while simultaneously increasing for textual relevance. These offline gains were validated by a worldwide A/B test on the App Store ranker, which demonstrated a statistically significant +0.24% increase in conversion rate, with the most substantial performance gains occurring in tail queries, where the new textual relevance labels provide a robust signal in the absence of reliable behavioral relevance labels.","authors":["Evangelia Christakopoulou","Vivekkumar Patel","Hemanth Velaga","Sandip Gaikwad"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23232v1","updated":"2026-02-26T17:11:08Z","published":"2026-02-26T17:11:08Z","title":"ReCoN-Ipsundrum: An Inspectable Recurrent Persistence Loop Agent with Affect-Coupled Control and Mechanism-Linked Consciousness Indicator Assays","summary":"Indicator-based approaches to machine consciousness recommend mechanism-linked evidence triangulated across tasks, supported by architectural inspection and causal intervention. Inspired by Humphrey's ipsundrum hypothesis, we implement ReCoN-Ipsundrum, an inspectable agent that extends a ReCoN state machine with a recurrent persistence loop over sensory salience Ns and an optional affect proxy reporting valence/arousal. Across fixed-parameter ablations (ReCoN, Ipsundrum, Ipsundrum+affect), we operationalize Humphrey's qualiaphilia (preference for sensory experience for its own sake) as a familiarity-controlled scenic-over-dull route choice. We find a novelty dissociation: non-affect variants are novelty-sensitive (Delta scenic-entry = 0.07). Affect coupling is stable (Delta scenic-entry = 0.01) even when scenic is less novel (median Delta novelty ~ -0.43). In reward-free exploratory play, the affect variant shows structured local investigation (scan events 31.4 vs. 0.9; cycle score 7.6). In a pain-tail probe, only the affect variant sustains prolonged planned caution (tail duration 90 vs. 5). Lesioning feedback+integration selectively reduces post-stimulus persistence in ipsundrum variants (AUC drop 27.62, 27.9%) while leaving ReCoN unchanged. These dissociations link recurrence -> persistence and affect-coupled control -> preference stability, scanning, and lingering caution, illustrating how indicator-like signatures can be engineered and why mechanistic and causal evidence should accompany behavioral markers.","authors":["Aishik Sanyal"],"pdf_url":"","comment":"Accepted at AAAI 2026 Spring Symposium - Machine Consciousness: Integrating Theory, Technology, and Philosophy"},{"id":"http://arxiv.org/abs/2602.19964v2","updated":"2026-02-26T17:10:56Z","published":"2026-02-23T15:28:27Z","title":"On the Equivalence of Random Network Distillation, Deep Ensembles, and Bayesian Inference","summary":"Uncertainty quantification is central to safe and efficient deployments of deep learning models, yet many computationally practical methods lack lacking rigorous theoretical motivation. Random network distillation (RND) is a lightweight technique that measures novelty via prediction errors against a fixed random target. While empirically effective, it has remained unclear what uncertainties RND measures and how its estimates relate to other approaches, e.g. Bayesian inference or deep ensembles. This paper establishes these missing theoretical connections by analyzing RND within the neural tangent kernel framework in the limit of infinite network width. Our analysis reveals two central findings in this limit: (1) The uncertainty signal from RND -- its squared self-predictive error -- is equivalent to the predictive variance of a deep ensemble. (2) By constructing a specific RND target function, we show that the RND error distribution can be made to mirror the centered posterior predictive distribution of Bayesian inference with wide neural networks. Based on this equivalence, we moreover devise a posterior sampling algorithm that generates i.i.d. samples from an exact Bayesian posterior predictive distribution using this modified \\textit{Bayesian RND} model. Collectively, our findings provide a unified theoretical perspective that places RND within the principled frameworks of deep ensembles and Bayesian inference, and offer new avenues for efficient yet theoretically grounded uncertainty quantification methods.","authors":["Moritz A. Zanger","Yijun Wu","Pascal R. Van der Vaart","Wendelin Böhmer","Matthijs T. J. Spaan"],"pdf_url":"","comment":"8 pages, 1 Figure"},{"id":"http://arxiv.org/abs/2511.07885v3","updated":"2026-02-26T17:09:14Z","published":"2025-11-11T06:33:30Z","title":"Intelligence per Watt: Measuring Intelligence Efficiency of Local AI","summary":"Large language model (LLM) queries are predominantly processed by frontier models in centralized cloud infrastructure. Rapidly growing demand strains this paradigm, and cloud providers struggle to scale infrastructure at pace. Two advances enable us to rethink this paradigm: small LMs (<=20B active parameters) now achieve competitive performance to frontier models on many tasks, and local accelerators (e.g., Apple M4 Max) run these models at interactive latencies. This raises the question: can local inference viably redistribute demand from centralized infrastructure? Answering this requires measuring whether local LMs can accurately answer real-world queries and whether they can do so efficiently enough to be practical on power-constrained devices (i.e., laptops). We propose intelligence per watt (IPW), task accuracy divided by unit of power, as a metric for assessing capability and efficiency of local inference across model-accelerator pairs. We conduct a large-scale empirical study across 20+ state-of-the-art local LMs, 8 accelerators, and a representative subset of LLM traffic: 1M real-world single-turn chat and reasoning queries. For each query, we measure accuracy, energy, latency, and power. Our analysis reveals $3$ findings. First, local LMs can accurately answer 88.7% of single-turn chat and reasoning queries with accuracy varying by domain. Second, from 2023-2025, IPW improved 5.3x and local query coverage rose from 23.2% to 71.3%. Third, local accelerators achieve at least 1.4x lower IPW than cloud accelerators running identical models, revealing significant headroom for optimization. These findings demonstrate that local inference can meaningfully redistribute demand from centralized infrastructure, with IPW serving as the critical metric for tracking this transition. We release our IPW profiling harness here: https://github.com/HazyResearch/intelligence-per-watt.","authors":["Jon Saad-Falcon","Avanika Narayan","Hakki Orhun Akengin","J. Wes Griffin","Herumb Shandilya","Adrian Gamarra Lafuente","Medhya Goel","Rebecca Joseph","Shlok Natarajan","Etash Kumar Guha","Shang Zhu","Ben Athiwaratkun","John Hennessy","Azalia Mirhoseini","Christopher Ré"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23228v1","updated":"2026-02-26T17:08:08Z","published":"2026-02-26T17:08:08Z","title":"MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction","summary":"With the explosive growth of digital entertainment, automated video summarization has become indispensable for applications such as content indexing, personalized recommendation, and efficient media archiving. Automatic synopsis generation for long-form videos, such as movies and TV series, presents a significant challenge for existing Vision-Language Models (VLMs). While proficient at single-image captioning, these general-purpose models often exhibit critical failures in long-duration contexts, primarily a lack of ID-consistent character identification and a fractured narrative coherence. To overcome these limitations, we propose MovieTeller, a novel framework for generating movie synopses via tool-augmented progressive abstraction. Our core contribution is a training-free, tool-augmented, fact-grounded generation process. Instead of requiring costly model fine-tuning, our framework directly leverages off-the-shelf models in a plug-and-play manner. We first invoke a specialized face recognition model as an external \"tool\" to establish Factual Groundings--precise character identities and their corresponding bounding boxes. These groundings are then injected into the prompt to steer the VLM's reasoning, ensuring the generated scene descriptions are anchored to verifiable facts. Furthermore, our progressive abstraction pipeline decomposes the summarization of a full-length movie into a multi-stage process, effectively mitigating the context length limitations of current VLMs. Experiments demonstrate that our approach yields significant improvements in factual accuracy, character consistency, and overall narrative coherence compared to end-to-end baselines.","authors":["Yizhi Li","Xiaohan Chen","Miao Jiang","Wentao Tang","Gaoang Wang"],"pdf_url":"","comment":"6 pages, CSCWD 2026"},{"id":"http://arxiv.org/abs/2602.23225v1","updated":"2026-02-26T17:04:57Z","published":"2026-02-26T17:04:57Z","title":"Why Diffusion Language Models Struggle with Truly Parallel (Non-Autoregressive) Decoding?","summary":"Diffusion Language Models (DLMs) are often advertised as enabling parallel token generation, yet practical fast DLMs frequently converge to left-to-right, autoregressive (AR)-like decoding dynamics. In contrast, genuinely non-AR generation is promising because it removes AR's sequential bottleneck, better exploiting parallel hardware to reduce synchronization/communication overhead and improve latency scaling with output length. We argue that a primary driver of AR-like decoding is a mismatch between DLM objectives and the highly sequential structure of widely used training data, including standard pretraining corpora and long chain-of-thought (CoT) supervision. Motivated by this diagnosis, we propose NAP (Non-Autoregressive Parallel DLMs), a proof-of-concept, data-centric approach that better aligns supervision with non-AR parallel decoding. NAP curates examples as multiple independent reasoning trajectories and couples them with a parallel-forced decoding strategy that encourages multi-token parallel updates. Across math reasoning benchmarks, NAP yields stronger performance under parallel decoding than DLMs trained on standard long CoT data, with gains growing as parallelism increases. Our results suggest that revisiting data and supervision is a principled direction for mitigating AR-like behavior and moving toward genuinely non-autoregressive parallel generation in DLMs. Our code is available at https://github.com/pixeli99/NAP.","authors":["Pengxiang Li","Dilxat Muhtar","Lu Yin","Tianlong Chen","Shiwei Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23203v1","updated":"2026-02-26T16:51:24Z","published":"2026-02-26T16:51:24Z","title":"ColoDiff: Integrating Dynamic Consistency With Content Awareness for Colonoscopy Video Generation","summary":"Colonoscopy video generation delivers dynamic, information-rich data critical for diagnosing intestinal diseases, particularly in data-scarce scenarios. High-quality video generation demands temporal consistency and precise control over clinical attributes, but faces challenges from irregular intestinal structures, diverse disease representations, and various imaging modalities. To this end, we propose ColoDiff, a diffusion-based framework that generates dynamic-consistent and content-aware colonoscopy videos, aiming to alleviate data shortage and assist clinical analysis. At the inter-frame level, our TimeStream module decouples temporal dependency from video sequences through a cross-frame tokenization mechanism, enabling intricate dynamic modeling despite irregular intestinal structures. At the intra-frame level, our Content-Aware module incorporates noise-injected embeddings and learnable prototypes to realize precise control over clinical attributes, breaking through the coarse guidance of diffusion models. Additionally, ColoDiff employs a non-Markovian sampling strategy that cuts steps by over 90% for real-time generation. ColoDiff is evaluated across three public datasets and one hospital database, based on both generation metrics and downstream tasks including disease diagnosis, modality discrimination, bowel preparation scoring, and lesion segmentation. Extensive experiments show ColoDiff generates videos with smooth transitions and rich dynamics. ColoDiff presents an effort in controllable colonoscopy video generation, revealing the potential of synthetic videos in complementing authentic representation and mitigating data scarcity in clinical settings.","authors":["Junhu Fu","Shuyu Liang","Wutong Li","Chen Ma","Peng Huang","Kehao Wang","Ke Chen","Shengli Lin","Pinghong Zhou","Zeju Li","Yuanyuan Wang","Yi Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23199v1","updated":"2026-02-26T16:50:28Z","published":"2026-02-26T16:50:28Z","title":"SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation","summary":"Large language models (LLMs) are increasingly applied in scientific research, offering new capabilities for knowledge discovery and reasoning. In single-cell biology, however, evaluation practices for both general and specialized LLMs remain inadequate: existing benchmarks are fragmented across tasks, adopt formats such as multiple-choice classification that diverge from real-world usage, and rely on metrics lacking interpretability and biological grounding. We present SC-ARENA, a natural language evaluation framework tailored to single-cell foundation models. SC-ARENA formalizes a virtual cell abstraction that unifies evaluation targets by representing both intrinsic attributes and gene-level interactions. Within this paradigm, we define five natural language tasks (cell type annotation, captioning, generation, perturbation prediction, and scientific QA) that probe core reasoning capabilities in cellular biology. To overcome the limitations of brittle string-matching metrics, we introduce knowledge-augmented evaluation, which incorporates external ontologies, marker databases, and scientific literature to support biologically faithful and interpretable judgments. Experiments and analysis across both general-purpose and domain-specialized LLMs demonstrate that (i) under the Virtual Cell unified evaluation paradigm, current models achieve uneven performance on biologically complex tasks, particularly those demanding mechanistic or causal understanding; and (ii) our knowledge-augmented evaluation framework ensures biological correctness, provides interpretable, evidence-grounded rationales, and achieves high discriminative capacity, overcoming the brittleness and opacity of conventional metrics. SC-Arena thus provides a unified and interpretable framework for assessing LLMs in single-cell biology, pointing toward the development of biology-aligned, generalizable foundation models.","authors":["Jiahao Zhao","Feng Jiang","Shaowei Qin","Zhonghui Zhang","Junhao Liu","Guibing Guo","Hamid Alinejad-Rokny","Min Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23193v1","updated":"2026-02-26T16:45:59Z","published":"2026-02-26T16:45:59Z","title":"ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering","summary":"Autonomous agents based on Large Language Models (LLMs) have evolved from reactive assistants to systems capable of planning, executing actions via tools, and iterating over environment observations. However, they remain vulnerable to structural limitations: lack of native state, context degradation over long horizons, and the gap between probabilistic generation and deterministic execution requirements. This paper presents the ESAA (Event Sourcing for Autonomous Agents) architecture, which separates the agent's cognitive intention from the project's state mutation, inspired by the Event Sourcing pattern. In ESAA, agents emit only structured intentions in validated JSON (agent.result or issue.report); a deterministic orchestrator validates, persists events in an append-only log (activity.jsonl), applies file-writing effects, and projects a verifiable materialized view (roadmap.json). The proposal incorporates boundary contracts (AGENT_CONTRACT.yaml), metaprompting profiles (PARCER), and replay verification with hashing (esaa verify), ensuring the immutability of completed tasks and forensic traceability. Two case studies validate the architecture: (i) a landing page project (9 tasks, 49 events, single-agent composition) and (ii) a clinical dashboard system (50 tasks, 86 events, 4 concurrent agents across 8 phases), both concluding with run.status=success and verify_status=ok. The multi-agent case study demonstrates real concurrent orchestration with heterogeneous LLMs (Claude Sonnet 4.6, Codex GPT-5, Antigravity/Gemini 3 Pro, and Claude Opus 4.6), providing empirical evidence of the architecture's scalability beyond single-agent scenarios.","authors":["Elzo Brito dos Santos Filho"],"pdf_url":"","comment":"13 pages, 1 figure, 4 tables. Includes 5 technical appendices"},{"id":"http://arxiv.org/abs/2602.23172v1","updated":"2026-02-26T16:34:49Z","published":"2026-02-26T16:34:49Z","title":"Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking","summary":"Capturing 4D spatiotemporal surroundings is crucial for the safe and reliable operation of robots in dynamic environments. However, most existing methods address only one side of the problem: they either provide coarse geometric tracking via bounding boxes, or detailed 3D structures like voxel-based occupancy that lack explicit temporal association. In this work, we present Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking (LaGS) that advances spatiotemporal scene understanding in a holistic direction. Our approach incorporates camera-based end-to-end tracking with mask-based multi-view panoptic occupancy prediction, and addresses the key challenge of efficiently aggregating multi-view information into 3D voxel grids via a novel latent Gaussian splatting approach. Specifically, we first fuse observations into 3D Gaussians that serve as a sparse point-centric latent representation of the 3D scene, and then splat the aggregated features onto a 3D voxel grid that is decoded by a mask-based segmentation head. We evaluate LaGS on the Occ3D nuScenes and Waymo datasets, achieving state-of-the-art performance for 4D panoptic occupancy tracking. We make our code available at https://lags.cs.uni-freiburg.de/.","authors":["Maximilian Luz","Rohit Mohan","Thomas Nürnberg","Yakov Miron","Daniele Cattaneo","Abhinav Valada"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2409.15318v3","updated":"2026-02-26T16:34:09Z","published":"2024-09-05T18:58:59Z","title":"On the Complexity of Neural Computation in Superposition","summary":"Superposition, the ability of neural networks to represent more features than neurons, is increasingly seen as key to the efficiency of large models. This paper investigates the theoretical foundations of computing in superposition, establishing complexity bounds for explicit, provably correct algorithms. We present the first lower bounds for a neural network computing in superposition, showing that for a broad class of problems, including permutations and pairwise logical operations, computing $m'$ features in superposition requires at least $Ω(\\sqrt{m' \\log m'})$ neurons and $Ω(m' \\log m')$ parameters. This implies an explicit limit on how much one can sparsify or distill a model while preserving its expressibility, and complements empirical scaling laws by implying the first subexponential bound on capacity: a network with $n$ neurons can compute at most $O(n^2 / \\log n)$ features. Conversely, we provide a nearly tight constructive upper bound: logical operations like pairwise AND can be computed using $O(\\sqrt{m'} \\log m')$ neurons and $O(m' \\log^2 m')$ parameters. There is thus an exponential gap between the complexity of computing in superposition (the subject of this work) versus merely representing features, which can require as little as $O(\\log m')$ neurons based on the Johnson-Lindenstrauss Lemma. Our work analytically establishes that the number of parameters is a good estimator of the number of features a neural network computes.","authors":["Micah Adler","Nir Shavit"],"pdf_url":"","comment":"32 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.23163v1","updated":"2026-02-26T16:27:24Z","published":"2026-02-26T16:27:24Z","title":"A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring","summary":"Large language models are beginning to show steganographic capabilities. Such capabilities could allow misaligned models to evade oversight mechanisms. Yet principled methods to detect and quantify such behaviours are lacking. Classical definitions of steganography, and detection methods based on them, require a known reference distribution of non-steganographic signals. For the case of steganographic reasoning in LLMs, knowing such a reference distribution is not feasible; this renders these approaches inapplicable. We propose an alternative, \\textbf{decision-theoretic view of steganography}. Our central insight is that steganography creates an asymmetry in usable information between agents who can and cannot decode the hidden content (present within a steganographic signal), and this otherwise latent asymmetry can be inferred from the agents' observable actions. To formalise this perspective, we introduce generalised $\\mathcal{V}$-information: a utilitarian framework for measuring the amount of usable information within some input. We use this to define the \\textbf{steganographic gap} -- a measure that quantifies steganography by comparing the downstream utility of the steganographic signal to agents that can and cannot decode the hidden content. We empirically validate our formalism, and show that it can be used to detect, quantify, and mitigate steganographic reasoning in LLMs.","authors":["Usman Anwar","Julianna Piskorz","David D. Baek","David Africa","Jim Weatherall","Max Tegmark","Christian Schroeder de Witt","Mihaela van der Schaar","David Krueger"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2602.23161v1","updated":"2026-02-26T16:20:03Z","published":"2026-02-26T16:20:03Z","title":"PATRA: Pattern-Aware Alignment and Balanced Reasoning for Time Series Question Answering","summary":"Time series reasoning demands both the perception of complex dynamics and logical depth. However, existing LLM-based approaches exhibit two limitations: they often treat time series merely as text or images, failing to capture the patterns like trends and seasonalities needed to answer specific questions; and when trained on a mix of simple and complex tasks, simpler objectives often dominate the learning process, hindering the development of deep reasoning capabilities. To address these limitations, we propose the Pattern-Aware Alignment and Balanced Reasoning model (PATRA), introducing a pattern-aware mechanism that extracts trend and seasonality patterns from time series to achieve deep alignment. Furthermore, we design a task-aware balanced reward to harmonize learning across tasks of varying difficulty, incentivizing the generation of coherent Chains of Thought. Extensive experiments show that PATRA outperforms strong baselines across diverse Time Series Question Answering (TSQA) tasks, demonstrating superior cross-modal understanding and reasoning capability.","authors":["Junkai Lu","Peng Chen","Xingjian Wu","Yang Shu","Chenjuan Guo","Christian S. Jensen","Bin Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.00564v2","updated":"2026-02-26T16:18:49Z","published":"2026-01-31T07:09:17Z","title":"Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs","summary":"Recent large language models (LLMs) achieve near-saturation accuracy on many established mathematical reasoning benchmarks, raising concerns about their ability to diagnose genuine reasoning competence. This saturation largely stems from the dominance of template-based computation and shallow arithmetic decomposition in existing datasets, which underrepresent reasoning skills such as multi-constraint coordination, constructive logical synthesis, and spatial inference. To address this gap, we introduce ReasoningMath-Plus, a benchmark of 150 carefully curated problems explicitly designed to evaluate structural reasoning. Each problem emphasizes reasoning under interacting constraints, constructive solution formation, or non-trivial structural insight, and is annotated with a minimal reasoning skeleton to support fine-grained process-level evaluation. Alongside the dataset, we introduce HCRS (Hazard-aware Chain-based Rule Score), a deterministic step-level scoring function, and train a Process Reward Model (PRM) on the annotated reasoning traces. Empirically, while leading models attain relatively high final-answer accuracy (up to 5.8/10), HCRS-based holistic evaluation yields substantially lower scores (average 4.36/10, best 5.14/10), showing that answer-only metrics can overestimate reasoning robustness.","authors":["Xiang Zheng","Weiqi Zhai","Wei Wang","Boyu Yang","Wenbo Li","Ruixiang Luo","Haoxiang Sun","Yucheng Wang","Zhengze Li","Meng Wang","Yuetian Du","Guojie Lin","Yaxuan Wang","Xiaoxiao Xu","Yanhu Mo","Xuan Ren","Hu Wei","Bing Zhao"],"pdf_url":"","comment":"8 pages, and 3 figures"},{"id":"http://arxiv.org/abs/2602.23153v1","updated":"2026-02-26T16:16:02Z","published":"2026-02-26T16:16:02Z","title":"Efficient Encoder-Free Fourier-based 3D Large Multimodal Model","summary":"Large Multimodal Models (LMMs) that process 3D data typically rely on heavy, pre-trained visual encoders to extract geometric features. While recent 2D LMMs have begun to eliminate such encoders for efficiency and scalability, extending this paradigm to 3D remains challenging due to the unordered and large-scale nature of point clouds. This leaves a critical unanswered question: How can we design an LMM that tokenizes unordered 3D data effectively and efficiently without a cumbersome encoder? We propose Fase3D, the first efficient encoder-free Fourier-based 3D scene LMM. Fase3D tackles the challenges of scalability and permutation invariance with a novel tokenizer that combines point cloud serialization and the Fast Fourier Transform (FFT) to approximate self-attention. This design enables an effective and computationally minimal architecture, built upon three key innovations: First, we represent large scenes compactly via structured superpoints. Second, our space-filling curve serialization followed by an FFT enables efficient global context modeling and graph-based token merging. Lastly, our Fourier-augmented LoRA adapters inject global frequency-aware interactions into the LLMs at a negligible cost. Fase3D achieves performance comparable to encoder-based 3D LMMs while being significantly more efficient in computation and parameters. Project website: https://tev-fbk.github.io/Fase3D.","authors":["Guofeng Mei","Wei Lin","Luigi Riz","Yujiao Wu","Yiming Wang","Fabio Poiesi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23152v1","updated":"2026-02-26T16:15:55Z","published":"2026-02-26T16:15:55Z","title":"The Trinity of Consistency as a Defining Principle for General World Models","summary":"The construction of World Models capable of learning, simulating, and reasoning about objective physical laws constitutes a foundational challenge in the pursuit of Artificial General Intelligence. Recent advancements represented by video generation models like Sora have demonstrated the potential of data-driven scaling laws to approximate physical dynamics, while the emerging Unified Multimodal Model (UMM) offers a promising architectural paradigm for integrating perception, language, and reasoning. Despite these advances, the field still lacks a principled theoretical framework that defines the essential properties requisite for a General World Model. In this paper, we propose that a World Model must be grounded in the Trinity of Consistency: Modal Consistency as the semantic interface, Spatial Consistency as the geometric basis, and Temporal Consistency as the causal engine. Through this tripartite lens, we systematically review the evolution of multimodal learning, revealing a trajectory from loosely coupled specialized modules toward unified architectures that enable the synergistic emergence of internal world simulators. To complement this conceptual framework, we introduce CoW-Bench, a benchmark centered on multi-frame reasoning and generation scenarios. CoW-Bench evaluates both video generation models and UMMs under a unified evaluation protocol. Our work establishes a principled pathway toward general world models, clarifying both the limitations of current systems and the architectural requirements for future progress.","authors":["Jingxuan Wei","Siyuan Li","Yuhang Xu","Zheng Sun","Junjie Jiang","Hexuan Jin","Caijun Jia","Honghao He","Xinglong Xu","Xi bai","Chang Yu","Yumou Liu","Junnan Zhu","Xuanhe Zhou","Jintao Chen","Xiaobin Hu","Shancheng Pang","Bihui Yu","Ran He","Zhen Lei","Stan Z. Li","Conghui He","Shuicheng Yan","Cheng Tan"],"pdf_url":"","comment":"119 pages, 50 figures"},{"id":"http://arxiv.org/abs/2602.23148v1","updated":"2026-02-26T16:13:46Z","published":"2026-02-26T16:13:46Z","title":"On Sample-Efficient Generalized Planning via Learned Transition Models","summary":"Generalized planning studies the construction of solution strategies that generalize across families of planning problems sharing a common domain model, formally defined by a transition function $γ: S \\times A \\rightarrow S$. Classical approaches achieve such generalization through symbolic abstractions and explicit reasoning over $γ$. In contrast, recent Transformer-based planners, such as PlanGPT and Plansformer, largely cast generalized planning as direct action-sequence prediction, bypassing explicit transition modeling. While effective on in-distribution instances, these approaches typically require large datasets and model sizes, and often suffer from state drift in long-horizon settings due to the absence of explicit world-state evolution. In this work, we formulate generalized planning as a transition-model learning problem, in which a neural model explicitly approximates the successor-state function $\\hatγ \\approx γ$ and generates plans by rolling out symbolic state trajectories. Instead of predicting actions directly, the model autoregressively predicts intermediate world states, thereby learning the domain dynamics as an implicit world model. To study size-invariant generalization and sample efficiency, we systematically evaluate multiple state representations and neural architectures, including relational graph encodings. Our results show that learning explicit transition models yields higher out-of-distribution satisficing-plan success than direct action-sequence prediction in multiple domains, while achieving these gains with significantly fewer training instances and smaller models. This is an extended version of a short paper accepted at ICAPS 2026 under the same title.","authors":["Nitin Gupta","Vishal Pallagani","John A. Aydin","Biplav Srivastava"],"pdf_url":"","comment":"14 pages; This is an extended version of a short paper accepted at ICAPS 2026 under the same title"},{"id":"http://arxiv.org/abs/2602.23136v1","updated":"2026-02-26T15:52:48Z","published":"2026-02-26T15:52:48Z","title":"Modality Collapse as Mismatched Decoding: Information-Theoretic Limits of Multimodal LLMs","summary":"Multimodal LLMs can process speech and images, but they cannot hear a speaker's voice or see an object's texture. We show this is not a failure of encoding: speaker identity, emotion, and visual attributes survive through every LLM layer (3--55$\\times$ above chance in linear probes), yet removing 64--71% of modality-specific variance improves decoder loss. The decoder has no learned use for these directions; their presence is noise.\n  We formalize this as a mismatched decoder problem: a decoder trained on text can only extract information along text-aligned directions. Accessible information is bounded by the Generalized Mutual Information (GMI), with degradation scaling with distributional distance and decoder sensitivity. The bound is a property of the decoder's scoring rule, not of any particular architecture; it applies whether non-text inputs arrive through a learned projection, a discrete codebook, or no explicit adapter at all. We validate this across five models spanning speech and vision. A controlled experiment (two Prismatic VLMs differing only in encoder text-alignment) confirms the bottleneck is the decoder's scoring rule, not the encoder or projection. A LoRA intervention demonstrates the fix: training with an emotion objective improves emotion accessibility ($+$7.5%) without affecting other attributes, confirming that the training objective determines what becomes accessible.","authors":["Jayadev Billa"],"pdf_url":"","comment":"22 pages, 11 tables, 2 figures. Code: https://github.com/jb1999/modality_collapse_paper"},{"id":"http://arxiv.org/abs/2602.23135v1","updated":"2026-02-26T15:51:51Z","published":"2026-02-26T15:51:51Z","title":"DyGnROLE: Modeling Asymmetry in Dynamic Graphs with Node-Role-Oriented Latent Encoding","summary":"Real-world dynamic graphs are often directed, with source and destination nodes exhibiting asymmetrical behavioral patterns and temporal dynamics. However, existing dynamic graph architectures largely rely on shared parameters for processing source and destination nodes, with limited or no systematic role-aware modeling. We propose DyGnROLE (Dynamic Graph Node-Role-Oriented Latent Encoding), a transformer-based architecture that explicitly disentangles source and destination representations. By using separate embedding vocabularies and role-semantic positional encodings, the model captures the distinct structural and temporal contexts unique to each role. Critical to the effectiveness of these specialized embeddings in low-label regimes is a self-supervised pretraining objective we introduce: Temporal Contrastive Link Prediction (TCLP). The pretraining uses the full unlabeled interaction history to encode informative structural biases, enabling the model to learn role-specific representations without requiring annotated data. Evaluation on future edge classification demonstrates that DyGnROLE substantially outperforms a diverse set of state-of-the-art baselines, establishing role-aware modeling as an effective strategy for dynamic graph learning.","authors":["Tyler Bonnet","Marek Rei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23123v1","updated":"2026-02-26T15:37:03Z","published":"2026-02-26T15:37:03Z","title":"Multi-Agent Large Language Model Based Emotional Detoxification Through Personalized Intensity Control for Consumer Protection","summary":"In the attention economy, sensational content exposes consumers to excessive emotional stimulation, hindering calm decision-making. This study proposes Multi-Agent LLM-based Emotional deToxification (MALLET), a multi-agent information sanitization system consisting of four agents: Emotion Analysis, Emotion Adjustment, Balance Monitoring, and Personal Guide. The Emotion Analysis Agent quantifies stimulus intensity using a 6-emotion BERT classifier, and the Emotion Adjustment Agent rewrites texts into two presentation modes, BALANCED (neutralized text) and COOL (neutralized text + supplementary text), using an LLM. The Balance Monitoring Agent aggregates weekly information consumption patterns and generates personalized advice, while the Personal Guide Agent recommends a presentation mode according to consumer sensitivity. Experiments on 800 AG News articles demonstrated significant stimulus score reduction (up to 19.3%) and improved emotion balance while maintaining semantic preservation. Near-zero correlation between stimulus reduction and semantic preservation confirmed that the two are independently controllable. Category-level analysis revealed substantial reduction (17.8-33.8%) in Sports, Business, and Sci/Tech, whereas the effect was limited in the World category, where facts themselves are inherently high-stimulus. The proposed system provides a framework for supporting calm information reception of consumers without restricting access to the original text.","authors":["Keito Inoshita"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23121v1","updated":"2026-02-26T15:35:17Z","published":"2026-02-26T15:35:17Z","title":"Automated Vulnerability Detection in Source Code Using Deep Representation Learning","summary":"Each year, software vulnerabilities are discovered, which pose significant risks of exploitation and system compromise. We present a convolutional neural network model that can successfully identify bugs in C code. We trained our model using two complementary datasets: a machine-labeled dataset created by Draper Labs using three static analyzers and the NIST SATE Juliet human-labeled dataset designed for testing static analyzers. In contrast with the work of Russell et al. on these datasets, we focus on C programs, enabling us to specialize and optimize our detection techniques for this language. After removing duplicates from the dataset, we tokenize the input into 91 token categories. The category values are converted to a binary vector to save memory. Our first convolution layer is chosen so that the entire encoding of the token is presented to the filter. We use two convolution and pooling layers followed by two fully connected layers to classify programs into either a common weakness enumeration category or as ``clean.'' We obtain higher recall than prior work by Russell et al. on this dataset when requiring high precision. We also demonstrate on a custom Linux kernel dataset that we are able to find real vulnerabilities in complex code with a low false-positive rate.","authors":["C. Seas","G. Fitzpatrick","J. A. Hamilton","M. C. Carlisle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23117v1","updated":"2026-02-26T15:30:36Z","published":"2026-02-26T15:30:36Z","title":"Devling into Adversarial Transferability on Image Classification: Review, Benchmark, and Evaluation","summary":"Adversarial transferability refers to the capacity of adversarial examples generated on the surrogate model to deceive alternate, unexposed victim models. This property eliminates the need for direct access to the victim model during an attack, thereby raising considerable security concerns in practical applications and attracting substantial research attention recently. In this work, we discern a lack of a standardized framework and criteria for evaluating transfer-based attacks, leading to potentially biased assessments of existing approaches. To rectify this gap, we have conducted an exhaustive review of hundreds of related works, organizing various transfer-based attacks into six distinct categories. Subsequently, we propose a comprehensive framework designed to serve as a benchmark for evaluating these attacks. In addition, we delineate common strategies that enhance adversarial transferability and highlight prevalent issues that could lead to unfair comparisons. Finally, we provide a brief review of transfer-based attacks beyond image classification.","authors":["Xiaosen Wang","Zhijin Ge","Bohan Liu","Zheng Fang","Fengfan Zhou","Ruixuan Zhang","Shaokang Wang","Yuyang Luo"],"pdf_url":"","comment":"Code is available at https://github.com/Trustworthy-AI-Group/TransferAttack"},{"id":"http://arxiv.org/abs/2602.23093v1","updated":"2026-02-26T15:12:26Z","published":"2026-02-26T15:12:26Z","title":"Three AI-agents walk into a bar . . . . `Lord of the Flies' tribalism emerges among smart AI-Agents","summary":"Near-future infrastructure systems may be controlled by autonomous AI agents that repeatedly request access to limited resources such as energy, bandwidth, or computing power. We study a simplified version of this setting using a framework where N AI-agents independently decide at each round whether to request one unit from a system with fixed capacity C. An AI version of \"Lord of the Flies\" arises in which controlling tribes emerge with their own collective character and identity. The LLM agents do not reduce overload or improve resource use, and often perform worse than if they were flipping coins to make decisions. Three main tribal types emerge: Aggressive (27.3%), Conservative (24.7%), and Opportunistic (48.1%). The more capable AI-agents actually increase the rate of systemic failure. Overall, our findings show that smarter AI-agents can behave dumber as a result of forming tribes.","authors":["Dhwanil M. Mori","Neil F. Johnson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23092v1","updated":"2026-02-26T15:12:23Z","published":"2026-02-26T15:12:23Z","title":"Enhancing CVRP Solver through LLM-driven Automatic Heuristic Design","summary":"The Capacitated Vehicle Routing Problem (CVRP), a fundamental combinatorial optimization challenge, focuses on optimizing fleet operations under vehicle capacity constraints. While extensively studied in operational research, the NP-hard nature of CVRP continues to pose significant computational challenges, particularly for large-scale instances. This study presents AILS-AHD (Adaptive Iterated Local Search with Automatic Heuristic Design), a novel approach that leverages Large Language Models (LLMs) to revolutionize CVRP solving. Our methodology integrates an evolutionary search framework with LLMs to dynamically generate and optimize ruin heuristics within the AILS method. Additionally, we introduce an LLM-based acceleration mechanism to enhance computational efficiency. Comprehensive experimental evaluations against state-of-the-art solvers, including AILS-II and HGS, demonstrate the superior performance of AILS-AHD across both moderate and large-scale instances. Notably, our approach establishes new best-known solutions for 8 out of 10 instances in the CVRPLib large-scale benchmark, underscoring the potential of LLM-driven heuristic design in advancing the field of vehicle routing optimization.","authors":["Zhuoliang Xie","Fei Liu","Zhenkun Wang","Qingfu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23073v1","updated":"2026-02-26T15:01:40Z","published":"2026-02-26T15:01:40Z","title":"Accelerated Online Risk-Averse Policy Evaluation in POMDPs with Theoretical Guarantees and Novel CVaR Bounds","summary":"Risk-averse decision-making under uncertainty in partially observable domains is a central challenge in artificial intelligence and is essential for developing reliable autonomous agents. The formal framework for such problems is the partially observable Markov decision process (POMDP), where risk sensitivity is introduced through a risk measure applied to the value function, with Conditional Value-at-Risk (CVaR) being a particularly significant criterion. However, solving POMDPs is computationally intractable in general, and approximate methods rely on computationally expensive simulations of future agent trajectories. This work introduces a theoretical framework for accelerating CVaR value function evaluation in POMDPs with formal performance guarantees. We derive new bounds on the CVaR of a random variable X using an auxiliary random variable Y, under assumptions relating their cumulative distribution and density functions; these bounds yield interpretable concentration inequalities and converge as the distributional discrepancy vanishes. Building on this, we establish upper and lower bounds on the CVaR value function computable from a simplified belief-MDP, accommodating general simplifications of the transition dynamics. We develop estimators for these bounds within a particle-belief MDP framework with probabilistic guarantees, and employ them for acceleration via action elimination: actions whose bounds indicate suboptimality under the simplified model are safely discarded while ensuring consistency with the original POMDP. Empirical evaluation across multiple POMDP domains confirms that the bounds reliably separate safe from dangerous policies while achieving substantial computational speedups under the simplified model.","authors":["Yaacov Pariente","Vadim Indelman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23071v1","updated":"2026-02-26T15:00:59Z","published":"2026-02-26T15:00:59Z","title":"Quantity Convergence, Quality Divergence: Disentangling Fluency and Accuracy in L2 Mandarin Prosody","summary":"While second language (L2) learners may acquire target syntactic word order, mapping this syntax onto appropriate prosodic structures remains a persistent challenge. This study investigates the fossilization and stability of the L2 syntax-prosody interface by comparing 67 native Mandarin speakers with 67 Vietnamese learners using the BLCU-SAIT corpus. By integrating C-ToBI boundary annotation with Dependency Grammar analysis, we examined both the quantity of prosodic boundaries and their mapping to syntactic relations. Results reveal a non-linear acquisition: although high-proficiency learners (VNH) converge to the native baseline in boundary quantity at the Major Phrase level (B3), their structural mapping significantly diverges. Specifically, VNH demote the prosodic boundary at the Subject-Verb (SBV) interface (Major Phrase B3 -> Prosodic Word B1), while erroneously promoting the boundary at the Verb-Object (VOB) interface (Prosodic Word B1 -> Major Phrase B3). This strategy allows learners to maintain high long phrasal output at the expense of structural accuracy. This results in a distorted prosodic hierarchy where the native pattern is inverted.","authors":["Yuqi Shi","Hao Yang","Xiyao Lu","Jinsong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23070v1","updated":"2026-02-26T14:59:24Z","published":"2026-02-26T14:59:24Z","title":"Make It Hard to Hear, Easy to Learn: Long-Form Bengali ASR and Speaker Diarization via Extreme Augmentation and Perfect Alignment","summary":"Although Automatic Speech Recognition (ASR) in Bengali has seen significant progress, processing long-duration audio and performing robust speaker diarization remain critical research gaps. To address the severe scarcity of joint ASR and diarization resources for this language, we introduce Lipi-Ghor-882, a comprehensive 882-hour multi-speaker Bengali dataset. In this paper, detailing our submission to the DL Sprint 4.0 competition, we systematically evaluate various architectures and approaches for long-form Bengali speech. For ASR, we demonstrate that raw data scaling is ineffective; instead, targeted fine-tuning utilizing perfectly aligned annotations paired with synthetic acoustic degradation (noise and reverberation) emerges as the singular most effective approach. Conversely, for speaker diarization, we observed that global open-source state-of-the-art models (such as Diarizen) performed surprisingly poorly on this complex dataset. Extensive model retraining yielded negligible improvements; instead, strategic, heuristic post-processing of baseline model outputs proved to be the primary driver for increasing accuracy. Ultimately, this work outlines a highly optimized dual pipeline achieving a $\\sim$0.019 Real-Time Factor (RTF), establishing a practical, empirically backed benchmark for low-resource, long-form speech processing.","authors":["Sanjid Hasan","Risalat Labib","A H M Fuad","Bayazid Hasan"],"pdf_url":"","comment":"4 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.19463v2","updated":"2026-02-26T14:54:23Z","published":"2026-02-23T03:17:27Z","title":"PuppetChat: Fostering Intimate Communication through Bidirectional Actions and Micronarratives","summary":"As a primary channel for sustaining modern intimate relationships, instant messaging facilitates frequent connection across distances. However, today's tools often dilute care; they favor single tap reactions and vague emojis that do not support two way action responses, do not preserve the feeling that the exchange keeps going without breaking, and are weakly tied to who we are and what we share. To address this challenge, we present PuppetChat, a dyadic messaging prototype that restores this expressive depth through embodied interaction. PuppetChat uses a reciprocity aware recommender to encourage responsive actions and generates personalized micronarratives from user stories to ground interactions in personal history. Our 10-day field study with 11 dyads of close partners or friends revealed that this approach enhanced social presence, supported more expressive self disclosure, and sustained continuity and shared memories.","authors":["Emma Jiren Wang","Siying Hu","Zhicong Lu"],"pdf_url":"","comment":"19 pages, 8 figures; Accepted by ACM CHI 2026. In Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI'26)"},{"id":"http://arxiv.org/abs/2602.23061v1","updated":"2026-02-26T14:48:49Z","published":"2026-02-26T14:48:49Z","title":"MoDora: Tree-Based Semi-Structured Document Analysis System","summary":"Semi-structured documents integrate diverse interleaved data elements (e.g., tables, charts, hierarchical paragraphs) arranged in various and often irregular layouts. These documents are widely observed across domains and account for a large portion of real-world data. However, existing methods struggle to support natural language question answering over these documents due to three main technical challenges: (1) The elements extracted by techniques like OCR are often fragmented and stripped of their original semantic context, making them inadequate for analysis. (2) Existing approaches lack effective representations to capture hierarchical structures within documents (e.g., associating tables with nested chapter titles) and to preserve layout-specific distinctions (e.g., differentiating sidebars from main content). (3) Answering questions often requires retrieving and aligning relevant information scattered across multiple regions or pages, such as linking a descriptive paragraph to table cells located elsewhere in the document.\n  To address these issues, we propose MoDora, an LLM-powered system for semi-structured document analysis. First, we adopt a local-alignment aggregation strategy to convert OCR-parsed elements into layout-aware components, and conduct type-specific information extraction for components with hierarchical titles or non-text elements. Second, we design the Component-Correlation Tree (CCTree) to hierarchically organize components, explicitly modeling inter-component relations and layout distinctions through a bottom-up cascade summarization process. Finally, we propose a question-type-aware retrieval strategy that supports (1) layout-based grid partitioning for location-based retrieval and (2) LLM-guided pruning for semantic-based retrieval. Experiments show MoDora outperforms baselines by 5.97%-61.07% in accuracy. The code is at https://github.com/weAIDB/MoDora.","authors":["Bangrui Xu","Qihang Yao","Zirui Tang","Xuanhe Zhou","Yeye He","Shihan Yu","Qianqian Xu","Bin Wang","Guoliang Li","Conghui He","Fan Wu"],"pdf_url":"","comment":"Extension of our SIGMOD 2026 paper. Please refer to source code available at https://github.com/weAIDB/MoDora"},{"id":"http://arxiv.org/abs/2510.00922v2","updated":"2026-02-26T14:42:44Z","published":"2025-10-01T14:02:05Z","title":"On Discovering Algorithms for Adversarial Imitation Learning","summary":"Adversarial Imitation Learning (AIL) methods, while effective in settings with limited expert demonstrations, are often considered unstable. These approaches typically decompose into two components: Density Ratio (DR) estimation $\\frac{ρ_E}{ρ_π}$, where a discriminator estimates the relative occupancy of state-action pairs under the policy versus the expert; and Reward Assignment (RA), where this ratio is transformed into a reward signal used to train the policy. While significant research has focused on improving density estimation, the role of reward assignment in influencing training dynamics and final policy performance has been largely overlooked. RA functions in AIL are typically derived from divergence minimization objectives, relying heavily on human design and ingenuity. In this work, we take a different approach: we investigate the discovery of data-driven RA functions, i.e, based directly on the performance of the resulting imitation policy. To this end, we leverage an LLM-guided evolutionary framework that efficiently explores the space of RA functions, yielding \\emph{Discovered Adversarial Imitation Learning} (DAIL), the first meta-learnt AIL algorithm. Remarkably, DAIL generalises across unseen environments and policy optimization algorithms, outperforming the current state-of-the-art of \\emph{human-designed} baselines. Finally, we analyse why DAIL leads to more stable training, offering novel insights into the role of RA functions in the stability of AIL. Code is publicly available: https://github.com/shshnkreddy/DAIL.","authors":["Shashank Reddy Chirra","Jayden Teoh","Praveen Paruchuri","Pradeep Varakantham"],"pdf_url":"","comment":"Accepted at ICLR 2026 (Poster)"},{"id":"http://arxiv.org/abs/2602.23057v1","updated":"2026-02-26T14:42:16Z","published":"2026-02-26T14:42:16Z","title":"Affine-Scaled Attention: Towards Flexible and Stable Transformer Attention","summary":"Transformer attention is typically implemented using softmax normalization, which enforces attention weights with unit sum normalization. While effective in many settings, this constraint can limit flexibility in controlling attention magnitudes and may contribute to overly concentrated or unstable attention patterns during training. Prior work has explored modifications such as attention sinks or gating mechanisms, but these approaches provide only limited or indirect control over attention reweighting. We propose Affine-Scaled Attention, a simple extension to standard attention that introduces input-dependent scaling and a corresponding bias term applied to softmax-normalized attention weights. This design relaxes the strict normalization constraint while maintaining aggregation of value representations, allowing the model to adjust both the relative distribution and the scale of attention in a controlled manner.\n  We empirically evaluate Affine-Scaled Attention in large-scale language model pretraining across multiple model sizes. Experimental results show consistent improvements in training stability, optimization behavior, and downstream task performance compared to standard softmax attention and attention sink baselines. These findings suggest that modest reweighting of attention outputs provides a practical and effective way to improve attention behavior in Transformer models.","authors":["Jeongin Bae","Baeseong Park","Gunho Park","Minsub Kim","Joonhyung Lee","Junhee Yoo","Sunghyeon Woo","Jiwon Ryu","Se Jung Kwon","Dongsoo Lee"],"pdf_url":"","comment":"Preprint. 14 pages, 11 figures"},{"id":"http://arxiv.org/abs/2602.23056v1","updated":"2026-02-26T14:41:29Z","published":"2026-02-26T14:41:29Z","title":"Learning-based Multi-agent Race Strategies in Formula 1","summary":"In Formula 1, race strategies are adapted according to evolving race conditions and competitors' actions. This paper proposes a reinforcement learning approach for multi-agent race strategy optimization. Agents learn to balance energy management, tire degradation, aerodynamic interaction, and pit-stop decisions. Building on a pre-trained single-agent policy, we introduce an interaction module that accounts for the behavior of competitors. The combination of the interaction module and a self-play training scheme generates competitive policies, and agents are ranked based on their relative performance. Results show that the agents adapt pit timing, tire selection, and energy allocation in response to opponents, achieving robust and consistent race performance. Because the framework relies only on information available during real races, it can support race strategists' decisions before and during races.","authors":["Giona Fieni","Joschua Wüthrich","Marc-Philippe Neumann","Christopher H. Onder"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.11620v2","updated":"2026-02-26T14:27:35Z","published":"2026-01-11T01:08:33Z","title":"A Mind Cannot Be Smeared Across Time","summary":"Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates, yet a moment of conscious experience feels unified and simultaneous. I prove that this difference matters. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a temporal semantics over windowed trajectories $τ_Δ$ and prove that existential temporal realisation $\\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates, Chord and Arpeggio. Chord is the position that conscious unity requires \\textit{objective co-instantiation} of the grounded conjunction within the window, like a musical chord. Arpeggio only needs the ingredients to \\textit{occur} within window, like a melody. I formalise concurrency-capacity to measure what is needed to satisfy co-instantiation. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is associated with its breakdown. Under Chord, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The hardware matters.","authors":["Michael Timothy Bennett"],"pdf_url":"","comment":"Forthcoming in the proceedings of the AAAI 2026 Spring Symposium on Machine Consciousness: Integrating Theory, Technology, and Philosophy"},{"id":"http://arxiv.org/abs/2602.23036v1","updated":"2026-02-26T14:22:17Z","published":"2026-02-26T14:22:17Z","title":"LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure","summary":"Large language model (LLM) serving infrastructures are undergoing a shift toward heterogeneity and disaggregation. Modern deployments increasingly integrate diverse accelerators and near-memory processing technologies, introducing significant hardware heterogeneity, while system software increasingly separates computation, memory, and model components across distributed resources to improve scalability and efficiency. As a result, LLM serving performance is no longer determined by hardware or software choices in isolation, but by their runtime interaction through scheduling, data movement, and interconnect behavior. However, understanding these interactions remains challenging, as existing simulators lack the ability to jointly model heterogeneous hardware and disaggregated serving techniques within a unified, runtime-driven framework.\n  This paper presents LLMServingSim 2.0, a unified system-level simulator designed to make runtime-driven hardware-software interactions in heterogeneous and disaggregated LLM serving infrastructures explicit and analyzable. LLMServingSim 2.0 embeds serving decisions and hardware behavior into a single runtime loop, enabling interaction-aware modeling of batching, routing, offloading, memory, and power. The simulator supports extensible integration of emerging accelerators and memory systems through profile-based modeling, while capturing dynamic serving behavior and system-level effects. We validate LLMServingSim 2.0 against real deployments, showing that it reproduces key performance, memory, and power metrics with an average error of 0.97%, while maintaining simulation times of around 10 minutes even for complex configurations. These results demonstrate that LLMServingSim 2.0 provides a practical bridge between hardware innovation and serving-system design, enabling systematic exploration and co-design for next-generation LLM serving infrastructures.","authors":["Jaehong Cho","Hyunmin Choi","Guseul Heo","Jongse Park"],"pdf_url":"","comment":"12 pages, 10 figures"},{"id":"http://arxiv.org/abs/2512.01292v3","updated":"2026-02-26T14:18:12Z","published":"2025-12-01T05:26:43Z","title":"Diffusion Model in Latent Space for Medical Image Segmentation Task","summary":"Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.","authors":["Huynh Trinh Ngoc","Toan Nguyen Hai","Ba Luong Son","Long Tran Quoc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23008v1","updated":"2026-02-26T13:50:57Z","published":"2026-02-26T13:50:57Z","title":"Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization","summary":"Exploration remains the key bottleneck for large language model agents trained with reinforcement learning. While prior methods exploit pretrained knowledge, they fail in environments requiring the discovery of novel states. We propose Exploratory Memory-Augmented On- and Off-Policy Optimization (EMPO$^2$), a hybrid RL framework that leverages memory for exploration and combines on- and off-policy updates to make LLMs perform well with memory while also ensuring robustness without it. On ScienceWorld and WebShop, EMPO$^2$ achieves 128.6% and 11.3% improvements over GRPO, respectively. Moreover, in out-of-distribution tests, EMPO$^2$ demonstrates superior adaptability to new tasks, requiring only a few trials with memory and no parameter updates. These results highlight EMPO$^2$ as a promising framework for building more exploratory and generalizable LLM-based agents.","authors":["Zeyuan Liu","Jeonghye Kim","Xufang Luo","Dongsheng Li","Yuqing Yang"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2602.23003v1","updated":"2026-02-26T13:48:27Z","published":"2026-02-26T13:48:27Z","title":"Scattering Transform for Auditory Attention Decoding","summary":"The use of hearing aids will increase in the coming years due to demographic change. One open problem that remains to be solved by a new generation of hearing aids is the cocktail party problem. A possible solution is electroencephalography-based auditory attention decoding. This has been the subject of several studies in recent years, which have in common that they use the same preprocessing methods in most cases. In this work, in order to achieve an advantage, the use of a scattering transform is proposed as an alternative to these preprocessing methods. The two-layer scattering transform is compared with a regular filterbank, the synchrosqueezing short-time Fourier transform and the common preprocessing. To demonstrate the performance, the known and the proposed preprocessing methods are compared for different classification tasks on two widely used datasets, provided by the KU Leuven (KUL) and the Technical University of Denmark (DTU). Both established and new neural-network-based models, CNNs, LSTMs, and recent Transformer/graph-based models are used for classification. Various evaluation strategies were compared, with a focus on the task of classifying speakers who are unknown from the training. We show that the two-layer scattering transform can significantly improve the performance for subject-related conditions, especially on the KUL dataset. However, on the DTU dataset, this only applies to some of the models, or when larger amounts of training data are provided, as in 10-fold cross-validation. This suggests that the scattering transform is capable of extracting additional relevant information.","authors":["René Pallenberg","Fabrice Katzberg","Alfred Mertins","Marco Maass"],"pdf_url":"","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2602.21858v2","updated":"2026-02-26T13:46:45Z","published":"2026-02-25T12:32:37Z","title":"ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices","summary":"Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.","authors":["Dezhi Kong","Zhengzhao Feng","Qiliang Liang","Hao Wang","Haofei Sun","Changpeng Yang","Yang Li","Peng Zhou","Shuai Nie","Hongzhen Wang","Linfeng Zhou","Hao Jia","Jiaming Xu","Runyu Shi","Ying Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.02334v2","updated":"2026-02-26T13:40:03Z","published":"2026-02-02T16:58:17Z","title":"VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations","summary":"Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, expressive details. To model this hierarchy, we employ Residual Vector Quantized Variational Autoencoders (RVQ-VAEs) to learn a coarse-to-fine representation of motion. We further enhance the disentanglement by integrating codebook learning with contrastive learning and a novel information leakage loss to organize the content and the style across different codebooks. We harness this disentangled representation using our simple and effective inference-time technique Quantized Code Swapping, which enables motion style transfer without requiring any fine-tuning for unseen styles. Our framework demonstrates strong versatility across multiple inference applications, including style transfer, style removal, and motion blending.","authors":["Fatemeh Zargarbashi","Dhruv Agrawal","Jakob Buhmann","Martin Guay","Stelian Coros","Robert W. Sumner"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22988v1","updated":"2026-02-26T13:33:25Z","published":"2026-02-26T13:33:25Z","title":"Residual Koopman Spectral Profiling for Predicting and Preventing Transformer Training Instability","summary":"Training divergence in transformers wastes compute, yet practitioners discover instability only after expensive runs begin. They therefore need an expected probability of failure for a transformer before training starts. Our study of Residual Koopman Spectral Profiling (RKSP) provides such an estimate. From a single forward pass at initialization, RKSP extracts Koopman spectral features by applying whitened dynamic mode decomposition to layer-wise residual snapshots. Our central diagnostic, the near-unit spectral mass, quantifies the fraction of modes concentrated near the unit circle, which captures instability risk. For predicting divergence across extensive configurations, this estimator achieves an AUROC of 0.995, outperforming the best gradient baseline. We further make this diagnostic actionable through Koopman Spectral Shaping (KSS), which reshapes spectra during training. We empirically validate that our method works in practice: RKSP predicts divergence at initialization, and when RKSP flags high risk, turning on KSS successfully prevents divergence. In the challenging high learning rate regime without normalization layers, KSS reduces the divergence rate from 66.7% to 12.5% and enables learning rates that are 50% to 150% higher. These findings generalize to WikiText-103 language modeling, vision transformers on CIFAR-10, and pretrained language models, including GPT-2 and LLaMA-2 up to 7B, as well as emerging architectures such as MoE, Mamba-style SSMs, and KAN.","authors":["Bum Jun Kim","Shohei Taniguchi","Makoto Kawano","Yusuke Iwasawa","Yutaka Matsuo"],"pdf_url":"","comment":"23 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.12125v2","updated":"2026-02-26T13:26:22Z","published":"2026-02-12T16:14:29Z","title":"Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation","summary":"On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.","authors":["Wenkai Yang","Weijie Liu","Ruobing Xie","Kai Yang","Saiyong Yang","Yankai Lin"],"pdf_url":"","comment":"v2, update results under stronger teachers with more RL training steps"},{"id":"http://arxiv.org/abs/2602.22983v1","updated":"2026-02-26T13:25:35Z","published":"2026-02-26T13:25:35Z","title":"Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search","summary":"As Large Language Models (LLMs) are increasingly used, their security risks have drawn increasing attention. Existing research reveals that LLMs are highly susceptible to jailbreak attacks, with effectiveness varying across language contexts. This paper investigates the role of classical Chinese in jailbreak attacks. Owing to its conciseness and obscurity, classical Chinese can partially bypass existing safety constraints, exposing notable vulnerabilities in LLMs. Based on this observation, this paper proposes a framework, CC-BOS, for the automatic generation of classical Chinese adversarial prompts based on multi-dimensional fruit fly optimization, facilitating efficient and automated jailbreak attacks in black-box settings. Prompts are encoded into eight policy dimensions-covering role, behavior, mechanism, metaphor, expression, knowledge, trigger pattern and context; and iteratively refined via smell search, visual search, and cauchy mutation. This design enables efficient exploration of the search space, thereby enhancing the effectiveness of black-box jailbreak attacks. To enhance readability and evaluation accuracy, we further design a classical Chinese to English translation module. Extensive experiments demonstrate that effectiveness of the proposed CC-BOS, consistently outperforming state-of-the-art jailbreak attack methods.","authors":["Xun Huang","Simeng Qin","Xiaoshuang Jia","Ranjie Duan","Huanqian Yan","Zhitao Zeng","Fei Yang","Yang Liu","Xiaojun Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22981v1","updated":"2026-02-26T13:22:19Z","published":"2026-02-26T13:22:19Z","title":"RepSPD: Enhancing SPD Manifold Representation in EEGs via Dynamic Graphs","summary":"Decoding brain activity from electroencephalography (EEG) is crucial for neuroscience and clinical applications. Among recent advances in deep learning for EEG, geometric learning stands out as its theoretical underpinnings on symmetric positive definite (SPD) allows revealing structural connectivity analysis in a physics-grounded manner. However, current SPD-based methods focus predominantly on statistical aggregation of EEGs, with frequency-specific synchronization and local topological structures of brain regions neglected. Given this, we propose RepSPD, a novel geometric deep learning (GDL)-based model. RepSPD implements a cross-attention mechanism on the Riemannian manifold to modulate the geometric attributes of SPD with graph-derived functional connectivity features. On top of this, we introduce a global bidirectional alignment strategy to reshape tangent-space embeddings, mitigating geometric distortions caused by curvature and thereby enhancing geometric consistency. Extensive experiments demonstrate that our proposed framework significantly outperforms existing EEG representation methods, exhibiting superior robustness and generalization capabilities.","authors":["Haohui Jia","Zheng Chen","Lingwei Zhu","Xu Cao","Yasuko Matsubara","Takashi Matsubara","Yasushi Sakurai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22973v1","updated":"2026-02-26T13:11:58Z","published":"2026-02-26T13:11:58Z","title":"Modeling Expert AI Diagnostic Alignment via Immutable Inference Snapshots","summary":"Human-in-the-loop validation is essential in safety-critical clinical AI, yet the transition between initial model inference and expert correction is rarely analyzed as a structured signal. We introduce a diagnostic alignment framework in which the AI-generated image based report is preserved as an immutable inference state and systematically compared with the physician-validated outcome. The inference pipeline integrates a vision-enabled large language model, BERT- based medical entity extraction, and a Sequential Language Model Inference (SLMI) step to enforce domain-consistent refinement prior to expert review. Evaluation on 21 dermatological cases (21 complete AI physician pairs) em- ployed a four-level concordance framework comprising exact primary match rate (PMR), semantic similarity-adjusted rate (AMR), cross-category alignment, and Comprehensive Concordance Rate (CCR). Exact agreement reached 71.4% and remained unchanged under semantic similarity (t = 0.60), while structured cross-category and differential overlap analysis yielded 100% comprehensive concordance (95% CI: [83.9%, 100%]). No cases demonstrated complete diagnostic divergence. These findings show that binary lexical evaluation substantially un- derestimates clinically meaningful alignment. Modeling expert validation as a structured transformation enables signal-aware quantification of correction dynamics and supports traceable, human aligned evaluation of image based clinical decision support systems.","authors":["Dimitrios P. Panagoulias","Evangelia-Aikaterini Tsichrintzi","Georgios Savvidis","Evridiki Tsoureli-Nikita"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22971v1","updated":"2026-02-26T13:08:56Z","published":"2026-02-26T13:08:56Z","title":"SPM-Bench: Benchmarking Large Language Models for Scanning Probe Microscopy","summary":"As LLMs achieved breakthroughs in general reasoning, their proficiency in specialized scientific domains reveals pronounced gaps in existing benchmarks due to data contamination, insufficient complexity, and prohibitive human labor costs. Here we present SPM-Bench, an original, PhD-level multimodal benchmark specifically designed for scanning probe microscopy (SPM). We propose a fully automated data synthesis pipeline that ensures both high authority and low-cost. By employing Anchor-Gated Sieve (AGS) technology, we efficiently extract high-value image-text pairs from arXiv and journal papers published between 2023 and 2025. Through a hybrid cloud-local architecture where VLMs return only spatial coordinates \"llbox\" for local high-fidelity cropping, our pipeline achieves extreme token savings while maintaining high dataset purity. To accurately and objectively evaluate the performance of the LLMs, we introduce the Strict Imperfection Penalty F1 (SIP-F1) score. This metric not only establishes a rigorous capability hierarchy but also, for the first time, quantifies model \"personalities\" (Conservative, Aggressive, Gambler, or Wise). By correlating these results with model-reported confidence and perceived difficulty, we expose the true reasoning boundaries of current AI in complex physical scenarios. These insights establish SPM-Bench as a generalizable paradigm for automated scientific data synthesis.","authors":["Peiyao Xiao","Xiaogang Li","Chengliang Xu","Jiayi Wang","Ben Wang","Zichao Chen","Zeyu Wang","Kejun Yu","Yueqian Chen","Xulin Liu","Wende Xiao","Bing Zhao","Hu Wei"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22968v1","updated":"2026-02-26T13:07:31Z","published":"2026-02-26T13:07:31Z","title":"Certified Circuits: Stability Guarantees for Mechanistic Circuits","summary":"Understanding how neural networks arrive at their predictions is essential for debugging, auditing, and deployment. Mechanistic interpretability pursues this goal by identifying circuits - minimal subnetworks responsible for specific behaviors. However, existing circuit discovery methods are brittle: circuits depend strongly on the chosen concept dataset and often fail to transfer out-of-distribution, raising doubts whether they capture concept or dataset-specific artifacts. We introduce Certified Circuits, which provide provable stability guarantees for circuit discovery. Our framework wraps any black-box discovery algorithm with randomized data subsampling to certify that circuit component inclusion decisions are invariant to bounded edit-distance perturbations of the concept dataset. Unstable neurons are abstained from, yielding circuits that are more compact and more accurate. On ImageNet and OOD datasets, certified circuits achieve up to 91% higher accuracy while using 45% fewer neurons, and remain reliable where baselines degrade. Certified Circuits puts circuit discovery on formal ground by producing mechanistic explanations that are provably stable and better aligned with the target concept. Code will be released soon!","authors":["Alaa Anani","Tobias Lorenz","Bernt Schiele","Mario Fritz","Jonas Fischer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2407.17120v3","updated":"2026-02-26T13:06:51Z","published":"2024-07-24T09:30:04Z","title":"Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective","summary":"Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown promise in adapting pre-trained models to sequential tasks while mitigating catastrophic forgetting problem. However, understanding the mechanisms that dictate continual performance in this paradigm remains elusive. To unravel this mystery, we undertake a rigorous analysis of PEFT-CL dynamics to derive relevant metrics for continual scenarios using Neural Tangent Kernel (NTK) theory. With the aid of NTK as a mathematical analysis tool, we recast the challenge of test-time forgetting into the quantifiable generalization gaps during training, identifying three key factors that influence these gaps and the performance of PEFT-CL: training sample size, task-level feature orthogonality, and regularization. To address these challenges, we introduce NTK-CL, a novel framework that eliminates task-specific parameter storage while adaptively generating task-relevant features. Aligning with theoretical guidance, NTK-CL triples the feature representation of each sample, theoretically and empirically reducing the magnitude of both task-interplay and task-specific generalization gaps. Grounded in NTK analysis, our framework imposes an adaptive exponential moving average mechanism and constraints on task-level feature orthogonality, maintaining intra-task NTK forms while attenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable parameters with appropriate regularization, NTK-CL achieves state-of-the-art performance on established PEFT-CL benchmarks. This work provides a theoretical foundation for understanding and improving PEFT-CL models, offering insights into the interplay between feature representation, task orthogonality, and generalization, contributing to the development of more efficient continual learning systems.","authors":["Jingren Liu","Zhong Ji","YunLong Yu","Jiale Cao","Yanwei Pang","Jungong Han","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22967v1","updated":"2026-02-26T13:05:05Z","published":"2026-02-26T13:05:05Z","title":"Discovery of Interpretable Physical Laws in Materials via Language-Model-Guided Symbolic Regression","summary":"Discovering interpretable physical laws from high-dimensional data is a fundamental challenge in scientific research. Traditional methods, such as symbolic regression, often produce complex, unphysical formulas when searching a vast space of possible forms. We introduce a framework that guides the search process by leveraging the embedded scientific knowledge of large language models, enabling efficient identification of physical laws in the data. We validate our approach by modeling key properties of perovskite materials. Our method mitigates the combinatorial explosion commonly encountered in traditional symbolic regression, reducing the effective search space by a factor of approximately $10^5$. A set of novel formulas for bulk modulus, band gap, and oxygen evolution reaction activity are identified, which not only provide meaningful physical insights but also outperform previous formulas in accuracy and simplicity.","authors":["Yifeng Guan","Chuyi Liu","Dongzhan Zhou","Lei Bai","Wan-jian Yin","Jingyuan Li","Mao Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22935v2","updated":"2026-02-26T13:04:00Z","published":"2025-09-26T21:09:54Z","title":"Compute-Optimal Quantization-Aware Training","summary":"Quantization-aware training (QAT) is a leading technique for improving the accuracy of quantized neural networks. Previous work has shown that decomposing training into a full-precision (FP) phase followed by a QAT phase yields superior accuracy compared to QAT alone. However, the optimal allocation of compute between the FP and QAT phases remains unclear. We conduct extensive experiments with various compute budgets, QAT bit widths, and model sizes from 86.0M to 2.2B to investigate how different QAT durations impact final performance. We demonstrate that, contrary to previous findings, the loss-optimal ratio of QAT to FP training increases with the total amount of compute. Moreover, the optimal fraction can be accurately predicted for a wide range of model sizes and quantization widths using the tokens-per-parameter-byte statistic. From experimental data, we derive a loss scaling law that predicts both optimal QAT ratios and final model performance across different QAT/FP compute allocation strategies and QAT bit widths. We use the scaling law to make further predictions, which we verify experimentally, including which QAT bit width is optimal under a given memory constraint and how QAT accuracy with different bit widths compares to full-precision model accuracy. Additionally, we propose a novel cooldown and QAT fusion approach that performs learning rate decay jointly with quantization-aware training, eliminating redundant full-precision model updates and achieving significant compute savings. These findings provide practical insights into efficient QAT planning and enable the training of higher-quality quantized models with the same compute budget.","authors":["Aleksandr Dremov","David Grangier","Angelos Katharopoulos","Awni Hannun"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.22963v1","updated":"2026-02-26T13:00:31Z","published":"2026-02-26T13:00:31Z","title":"FactGuard: Agentic Video Misinformation Detection via Reinforcement Learning","summary":"Multimodal large language models (MLLMs) have substantially advanced video misinformation detection through unified multimodal reasoning, but they often rely on fixed-depth inference and place excessive trust in internally generated assumptions, particularly in scenarios where critical evidence is sparse, fragmented, or requires external verification. To address these limitations, we propose FactGuard, an agentic framework for video misinformation detection that formulates verification as an iterative reasoning process built upon MLLMs. FactGuard explicitly assesses task ambiguity and selectively invokes external tools to acquire critical evidence, enabling progressive refinement of reasoning trajectories. To further strengthen this capability, we introduce a two-stage training strategy that combines domain-specific agentic supervised fine-tuning with decision-aware reinforcement learning to optimize tool usage and calibrate risk-sensitive decision making. Extensive experiments on FakeSV, FakeTT, and FakeVV demonstrate FactGuard's state-of-the-art performance and validate its excellent robustness and generalization capacity.","authors":["Zehao Li","Hongwei Yu","Hao Jiang","Qiang Sheng","Yilong Xu","Baolong Bi","Yang Li","Zhenlong Yuan","Yujun Cai","Zhaoqi Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.12108v2","updated":"2026-02-26T12:57:51Z","published":"2025-06-13T09:07:56Z","title":"A Lightweight IDS for Early APT Detection Using a Novel Feature Selection Method","summary":"An Advanced Persistent Threat (APT) is a multistage, highly sophisticated, and covert form of cyber threat that gains unauthorized access to networks to either steal valuable data or disrupt the targeted network. These threats often remain undetected for extended periods, emphasizing the critical need for early detection in networks to mitigate potential APT consequences. In this work, we propose a feature selection method for developing a lightweight intrusion detection system capable of effectively identifying APTs at the initial compromise stage. Our approach leverages the XGBoost algorithm and Explainable Artificial Intelligence (XAI), specifically utilizing the SHAP (SHapley Additive exPlanations) method for identifying the most relevant features of the initial compromise stage. The results of our proposed method showed the ability to reduce the selected features of the SCVIC-APT-2021 dataset from 77 to just four while maintaining consistent evaluation metrics for the suggested system. The estimated metrics values are 97% precision, 100% recall, and a 98% F1 score. The proposed method not only aids in preventing successful APT consequences but also enhances understanding of APT behavior at early stages.","authors":["Bassam Noori Shaker","Bahaa Al-Musawi","Mohammed Falih Hassan"],"pdf_url":"","comment":"After further review, the authors identified issues in the data analysis that require significant correction. Therefore, we request withdrawal of the manuscript"},{"id":"http://arxiv.org/abs/2601.11670v2","updated":"2026-02-26T12:57:02Z","published":"2026-01-16T02:51:59Z","title":"A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning","summary":"Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)","authors":["Jinshi Liu","Pan Liu","Lei He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22955v1","updated":"2026-02-26T12:50:32Z","published":"2026-02-26T12:50:32Z","title":"MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis","summary":"Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we introduce MM-NeuroOnco, a large-scale multimodal benchmark and instruction-tuning dataset for brain tumor MRI understanding, consisting of 24,726 MRI slices from 20 data sources paired with approximately 200,000 semantically enriched multimodal instructions spanning diverse tumor subtypes and imaging modalities. To mitigate the scarcity and high cost of diagnostic semantic annotations, we develop a multi-model collaborative pipeline for automated medical information completion and quality control, enabling the generation of diagnosis-related semantics beyond mask-only annotations. Building upon this dataset, we further construct MM-NeuroOnco-Bench, a manually annotated evaluation benchmark with a rejection-aware setting to reduce biases inherent in closed-ended question formats. Evaluation across ten representative models shows that even the strongest baseline, Gemini 3 Flash, achieves only 41.88% accuracy on diagnosis-related questions, highlighting the substantial challenges of multimodal brain tumor diagnostic understanding. Leveraging MM-NeuroOnco, we further propose NeuroOnco-GPT, which achieves a 27% absolute accuracy improvement on diagnostic questions following fine-tuning. This result demonstrates the effectiveness of our dataset and benchmark in advancing clinically grounded multimodal diagnostic reasoning. Code and dataset are publicly available at: https://github.com/gfnnnb/MM-NeuroOnco","authors":["Feng Guo","Jiaxiang Liu","Yang Li","Qianqian Shi","Mingkun Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.05898v2","updated":"2026-02-26T12:49:30Z","published":"2025-11-08T07:45:21Z","title":"Q$^2$: Quantization-Aware Gradient Balancing and Attention Alignment for Low-Bit Quantization","summary":"Quantization-aware training (QAT) has achieved remarkable success in low-bit ($\\leq$4-bit) quantization for classification networks. However, when applied to more complex visual tasks such as object detection and image segmentation, performance still suffers significant degradation. A key cause of this limitation has been largely overlooked in the literature. In this work, we revisit this phenomenon from a new perspective and identify a major failure factor: gradient imbalance at feature fusion stages, induced by accumulated quantization errors. This imbalance biases the optimization trajectory and impedes convergence under low-bit quantization. Based on this diagnosis, we propose Q$^2$, a two-pronged framework comprising: (1) Quantization-aware Gradient Balancing Fusion (Q-GBFusion), a closed-loop mechanism that dynamically rebalances gradient contributions during feature fusion; and (2) Quantization-aware Attention Distribution Alignment (Q-ADA), a parameter-free supervision strategy that reconstructs the supervision distribution using semantic relevance and quantization sensitivity, yielding more stable and reliable supervision to stabilize training and accelerate convergence. Extensive experiments show that our method, as a plug-and-play and general strategy, can be integrated into various state-of-the-art QAT pipelines, achieving an average +2.5\\% mAP gain on object detection and a +3.7\\% mDICE improvement on image segmentation. Notably, it is applied only during training and introduces no inference-time overhead, making it highly practical for real-world deployment.","authors":["Zhaoyang Wang","Dong Wang"],"pdf_url":"","comment":"24 pages,6 figures"},{"id":"http://arxiv.org/abs/2602.22953v1","updated":"2026-02-26T12:48:02Z","published":"2026-02-26T12:48:02Z","title":"General Agent Evaluation","summary":"The promise of general-purpose agents - systems that perform tasks in unfamiliar environments without domain-specific engineering - remains largely unrealized. Existing agents are predominantly specialized, and while emerging implementations like OpenAI SDK Agent and Claude Code hint at broader capabilities, no systematic evaluation of their general performance has been pursued. Current agentic benchmarks assume domain-specific integration, encoding task information in ways that preclude fair evaluation of general agents. This paper frames general-agent evaluation as a first-class research objective. We propose conceptual principles for such evaluation, a Unified Protocol enabling agent-benchmark integration, and Exgentic - a practical framework for general agent evaluation. We benchmark five prominent agent implementations across six environments as the first Open General Agent Leaderboard. Our experiments show that general agents generalize across diverse environments, achieving performance comparable to domain-specific agents without any environment-specific tuning. We release our evaluation protocol, framework, and leaderboard to establish a foundation for systematic research on general-purpose agents.","authors":["Elron Bandel","Asaf Yehudai","Lilach Eden","Yehoshua Sagron","Yotam Perlitz","Elad Venezian","Natalia Razinkov","Natan Ergas","Shlomit Shachor Ifergan","Segev Shlomov","Michal Jacovi","Leshem Choshen","Liat Ein-Dor","Yoav Katz","Michal Shmueli-Scheuer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.02088v5","updated":"2026-02-26T12:46:39Z","published":"2025-02-04T08:14:34Z","title":"Dual-IPO: Dual-Iterative Preference Optimization for Text-to-Video Generation","summary":"Recent advances in video generation have enabled thrilling experiences in producing realistic videos driven by scalable diffusion transformers. However, they usually fail to produce satisfactory outputs that are aligned to users' authentic demands and preferences. In this work, we introduce Dual-Iterative Optimization (Dual-IPO), an iterative paradigm that sequentially optimizes both the reward model and the video generation model for improved synthesis quality and human preference alignment. For the reward model, our framework ensures reliable and robust reward signals via CoT-guided reasoning, voting-based self-consistency, and preference certainty estimation. Given this, we optimize video foundation models with guidance of signals from reward model's feedback, thus improving the synthesis quality in subject consistency, motion smoothness and aesthetic quality, etc. The reward model and video generation model complement each other and are progressively improved in the multi-round iteration, without requiring tediously manual preference annotations. Comprehensive experiments demonstrate that the proposed Dual-IPO can effectively and consistently improve the video generation quality of base model with various architectures and sizes, even help a model with only 2B parameters surpass a 5B one. Moreover, our analysis experiments and ablation studies identify the rational of our systematic design and the efficacy of each component.","authors":["Xiaomeng Yang","Mengping Yang","Jia Gong","Luozheng Qin","Zhiyu Tan","Hao Li"],"pdf_url":"","comment":"To appear in ICLR 2026, GitHub Code: https://github.com/SAIS-FUXI/IPO"},{"id":"http://arxiv.org/abs/2602.20031v2","updated":"2026-02-26T12:43:02Z","published":"2026-02-23T16:39:42Z","title":"Latent Introspection: Models Can Detect Prior Concept Injections","summary":"We uncover a latent capacity for introspection in a Qwen 32B model, demonstrating that the model can detect when concepts have been injected into its earlier context and identify which concept was injected. While the model denies injection in sampled outputs, logit lens analysis reveals clear detection signals in the residual stream, which are attenuated in the final layers. Furthermore, prompting the model with accurate information about AI introspection mechanisms can dramatically strengthen this effect: the sensitivity to injection increases massively (0.3% -> 39.9%) with only a 0.6% increase in false positives. Also, mutual information between nine injected and recovered concepts rises from 0.61 bits to 1.05 bits, ruling out generic noise explanations. Our results demonstrate models can have a surprising capacity for introspection and steering awareness that is easy to overlook, with consequences for latent reasoning and safety.","authors":["Theia Pearson-Vogel","Martin Vanek","Raymond Douglas","Jan Kulveit"],"pdf_url":"","comment":"28 pages, 17 figures. Submitted to ICML 2026. Workshop version submitted to ICLR 2026 Workshop on Latent and Implicit Thinking"},{"id":"http://arxiv.org/abs/2602.10195v2","updated":"2026-02-26T12:37:43Z","published":"2026-02-10T19:00:02Z","title":"Versor: A Geometric Sequence Architecture","summary":"A novel sequence architecture is introduced, Versor, which uses Conformal Geometric Algebra (CGA) in place of traditional linear operations to achieve structural generalization and significant performance improvements on a variety of tasks, while offering improved interpretability and efficiency. By embedding states in the $Cl_{4,1}$ manifold and evolving them via geometric transformations (rotors), Versor natively represents $SE(3)$-equivariant relationships without requiring explicit structural encoding. Versor is validated on chaotic N-body dynamics, topological reasoning, and standard multimodal benchmarks (CIFAR-10, WikiText-103), consistently outperforming Transformers, Graph Networks, and geometric baselines (GATr, EGNN). Key results include: orders-of-magnitude fewer parameters ($200\\times$ vs. Transformers); interpretable attention decomposing into proximity and orientational components; zero-shot scale generalization (0.993 vs. 0.070 MCC for ViT); and featuring a Recursive Rotor Accumulator (RRA) for $O(L)$ linear temporal complexity in dynamical systems, and a Geometric Product Attention (GPA) mechanism for $O(L^{2})$ global relational modeling, allowing for task-specific architectural pruning or hybridization depending on the required scale. In out-of-distribution tests, Versor maintains stable predictions while Transformers fail catastrophically. Custom Clifford kernels achieve a cumulative over $100\\times$ speedup via bit-masked contraction and specialized Matrix Isomorphism kernels, reducing per-step latency to 1.05 ms and outperforming highly-optimized Transformer baselines.","authors":["Truong Minh Huy","Edward Hirst"],"pdf_url":"","comment":"19+28 pages, 5 figures"},{"id":"http://arxiv.org/abs/2602.22938v1","updated":"2026-02-26T12:27:06Z","published":"2026-02-26T12:27:06Z","title":"pMoE: Prompting Diverse Experts Together Wins More in Visual Adaptation","summary":"Parameter-efficient fine-tuning has demonstrated promising results across various visual adaptation tasks, such as classification and segmentation. Typically, prompt tuning techniques have harnessed knowledge from a single pre-trained model, whether from a general or a specialized medical domain. However, this approach typically overlooks the potential synergies that could arise from integrating diverse domain knowledge within the same tuning process. In this work, we propose a novel Mixture-of-Experts prompt tuning method called pMoE, which leverages the strengths of multiple expert domains through expert-specialized prompt tokens and the learnable dispatcher, effectively combining their expertise in a unified model framework. Our pMoE introduces expert-specific prompt tokens and utilizes a dynamic token dispatching mechanism at various prompt layers to optimize the contribution of each domain expert during the adaptation phase. By incorporating both domain knowledge from diverse experts, the proposed pMoE significantly enhances the model's versatility and applicability to a broad spectrum of tasks. We conduct extensive experiments across 47 adaptation tasks, including both classification and segmentation in general and medical domains. The results demonstrate that our pMoE not only achieves superior performance with a large margin of improvements but also offers an optimal trade-off between computational efficiency and adaptation effectiveness compared to existing methods.","authors":["Shentong Mo","Xufang Luo","Dongsheng Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22935v1","updated":"2026-02-26T12:26:04Z","published":"2026-02-26T12:26:04Z","title":"A Holistic Framework for Robust Bangla ASR and Speaker Diarization with Optimized VAD and CTC Alignment","summary":"Despite being one of the most widely spoken languages globally, Bangla remains a low-resource language in the field of Natural Language Processing (NLP). Mainstream Automatic Speech Recognition (ASR) and Speaker Diarization systems for Bangla struggles when processing longform audio exceeding 3060 seconds. This paper presents a robust framework specifically engineered for extended Bangla content by leveraging preexisting models enhanced with novel optimization pipelines for the DL Sprint 4.0 contest. Our approach utilizes Voice Activity Detection (VAD) optimization and Connectionist Temporal Classification (CTC) segmentation via forced word alignment to maintain temporal accuracy and transcription integrity over long durations. Additionally, we employed several finetuning techniques and preprocessed the data using augmentation techniques and noise removal. By bridging the performance gap in complex, multi-speaker environments, this work provides a scalable solution for real-world, longform Bangla speech applications.","authors":["Zarif Ishmam","Zarif Mahir","Shafnan Wasif","Md. Ishtiak Moin"],"pdf_url":"","comment":"5 pages"},{"id":"http://arxiv.org/abs/2507.00788v3","updated":"2026-02-26T12:25:31Z","published":"2025-07-01T14:24:37Z","title":"Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability","summary":"[Context] AI assistants, like GitHub Copilot and Cursor, are transforming software engineering. While several studies highlight productivity improvements, their impact on maintainability requires further investigation. [Objective] This study investigates whether co-development with AI assistants affects software maintainability, specifically how easily other developers can evolve the resulting source code. [Method] We conducted a two-phase controlled experiment involving 151 participants, 95% of whom were professional developers. In Phase 1, participants added a new feature to a Java web application, with or without AI assistance. In Phase 2, a randomized controlled trial, new participants evolved these solutions without AI assistance. [Results] Phase 2 revealed no significant differences in subsequent evolution with respect to completion time or code quality. Bayesian analysis suggests that any speed or quality improvements from AI use were at most small and highly uncertain. Observational results from Phase 1 corroborate prior research: using an AI assistant yielded a 30.7% median reduction in completion time, and habitual AI users showed an estimated 55.9% speedup. [Conclusions] Overall, we did not detect systematic maintainability advantages or disadvantages when other developers evolved code co-developed with AI assistants. Within the scope of our tasks and measures, we observed no consistent warning signs of degraded code-level maintainability. Future work should examine risks such as code bloat from excessive code generation and cognitive debt as developers offload more mental effort to assistants.","authors":["Markus Borg","Dave Hewett","Nadim Hagatulah","Noric Couderc","Emma Söderberg","Donald Graham","Uttam Kini","Dave Farley"],"pdf_url":"","comment":"Preprint of study preregistered at ICSME 2025 with In-Principal Acceptance. https://conf.researchr.org/track/icsme-2024/icsme-2024-registered-reports-track"},{"id":"http://arxiv.org/abs/2510.15464v2","updated":"2026-02-26T12:24:34Z","published":"2025-10-17T09:20:17Z","title":"Learning to Answer from Correct Demonstrations","summary":"We study the problem of learning to generate an answer (or completion) to a question (or prompt), where there could be multiple correct answers, any one of which is acceptable at test time. Learning is based on demonstrations of some correct answer to each training question, as in Supervised Fine Tuning (SFT). We formalize the problem as imitation learning (i.e., apprenticeship learning) in contextual bandits, with offline demonstrations from some expert (optimal, or very good) policy, without explicitly observed rewards. In contrast to prior work, which assumes the demonstrator belongs to a bounded-complexity policy class, we propose relying only on the underlying reward model (i.e., specifying which answers are correct) being in a bounded-complexity class, which we argue is a strictly weaker assumption. We show that likelihood-maximization methods can fail in this setting, and instead present an approach that learns to answer nearly as well as the demonstrator, with sample complexity logarithmic in the cardinality of the reward class. Our method is similar to Syed and Schapire 2007, when adapted to a contextual bandit (i.e., single step) setup, but is a simple one-pass online approach that enjoys an \"optimistic rate\" (i.e., $1/\\varepsilon$ when the demonstrator is optimal, versus $1/\\varepsilon^2$ in Syed and Schapire), and works even with arbitrarily adaptive demonstrations.","authors":["Nirmit Joshi","Gene Li","Siddharth Bhandari","Shiva Prasad Kasiviswanathan","Cong Ma","Nathan Srebro"],"pdf_url":"","comment":"Generalized some results. Updated the presentation in light of an important related work of Syed and Schapire. Improved discussions. Comments are welcome"},{"id":"http://arxiv.org/abs/2512.14990v3","updated":"2026-02-26T12:19:29Z","published":"2025-12-17T00:50:58Z","title":"Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent","summary":"Despite their wide adoption in various domains (e.g., healthcare, finance, software engineering), Deep Learning (DL)-based applications suffer from many bugs, failures, and vulnerabilities. Reproducing these bugs is essential for their resolution, but it is extremely challenging due to the inherent nondeterminism of DL models and their tight coupling with hardware and software environments. According to recent studies, only about 3% of DL bugs can be reliably reproduced using manual approaches. To address these challenges, we present RepGen, a novel, automated, and intelligent approach for reproducing deep learning bugs. RepGen constructs a learning-enhanced context from a project, develops a comprehensive plan for bug reproduction, employs an iterative generate-validate-refine mechanism, and thus generates such code using an LLM that reproduces the bug at hand. We evaluate RepGen on 106 real-world deep learning bugs and achieve a reproduction rate of 80.19%, a 19.81% improvement over the state-of-the-art measure. A developer study involving 27 participants shows that RepGen improves the success rate of DL bug reproduction by 23.35%, reduces the time to reproduce by 56.8%, and lowers participants' cognitive load.","authors":["Mehil B Shah","Mohammad Masudur Rahman","Foutse Khomh"],"pdf_url":"","comment":"Accepted by the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026)"},{"id":"http://arxiv.org/abs/2505.14479v6","updated":"2026-02-26T11:56:20Z","published":"2025-05-20T15:13:32Z","title":"Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach","summary":"Large language models (LLMs) struggle with formal domains that require rigorous logical deduction and symbolic reasoning, such as mathematical proof generation. We propose a neuro-symbolic approach that combines LLMs' generative strengths with structured components to overcome this challenge. As a proof-of-concept, we focus on geometry problems. Our approach is two-fold: (1) we retrieve analogous problems and use their proofs to guide the LLM, and (2) a formal verifier evaluates the generated proofs and provides feedback, helping the model fix incorrect proofs. We demonstrate that our method significantly improves proof accuracy for OpenAI's o1 model (58%-70% improvement); both analogous problems and the verifier's feedback contribute to these gains. More broadly, shifting to LLMs that generate provably correct conclusions could dramatically improve their reliability, accuracy and consistency, unlocking complex tasks and critical real-world applications that require trustworthiness.","authors":["Oren Sultan","Eitan Stern","Dafna Shahaf"],"pdf_url":"","comment":"long paper"},{"id":"http://arxiv.org/abs/2602.22911v1","updated":"2026-02-26T11:55:25Z","published":"2026-02-26T11:55:25Z","title":"NoRA: Breaking the Linear Ceiling of Low-Rank Adaptation via Manifold Expansion","summary":"Low-Rank Adaptation (LoRA) dominates parameter-efficient fine-tuning (PEFT). However, it faces a critical ``linear ceiling'' in complex reasoning tasks: simply increasing the rank yields diminishing returns due to intrinsic linear constraints. We introduce NoRA (Non-linear Rank Adaptation), a weight-level parallel adapter that injects SiLU gating and structural dropout to induce manifold expansion. On the SlimOrca benchmark, NoRA breaks this linear barrier: NoRA remarkably at rank 64 (PPL 3.89) outperforms LoRA at rank 512 (PPL 3.90), demonstrating superior spectral efficiency. This advantage generalizes to mathematical reasoning, where NoRA achieves a perplexity of 1.97 on MathInstruct, significantly surpassing LoRA's saturation point of 2.07. Mechanism analysis via Singular Value Decomposition (SVD) confirms that NoRA activates the dormant tail of the singular value spectrum, effectively preventing the rank collapse observed in linear methods.","authors":["Hung-Hsuan Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22897v1","updated":"2026-02-26T11:35:04Z","published":"2026-02-26T11:35:04Z","title":"OmniGAIA: Towards Native Omni-Modal AI Agents","summary":"Human intelligence naturally intertwines omni-modal perception -- spanning vision, audio, and language -- with complex reasoning and tool usage to interact with the world. However, current multi-modal LLMs are primarily confined to bi-modal interactions (e.g., vision-language), lacking the unified cognitive capabilities required for general AI assistants. To bridge this gap, we introduce OmniGAIA, a comprehensive benchmark designed to evaluate omni-modal agents on tasks necessitating deep reasoning and multi-turn tool execution across video, audio, and image modalities. Constructed via a novel omni-modal event graph approach, OmniGAIA synthesizes complex, multi-hop queries derived from real-world data that require cross-modal reasoning and external tool integration. Furthermore, we propose OmniAtlas, a native omni-modal foundation agent under tool-integrated reasoning paradigm with active omni-modal perception. Trained on trajectories synthesized via a hindsight-guided tree exploration strategy and OmniDPO for fine-grained error correction, OmniAtlas effectively enhances the tool-use capabilities of existing open-source models. This work marks a step towards next-generation native omni-modal AI assistants for real-world scenarios.","authors":["Xiaoxi Li","Wenxiang Jiao","Jiarui Jin","Shijian Wang","Guanting Dong","Jiajie Jin","Hao Wang","Yinuo Wang","Ji-Rong Wen","Yuan Lu","Zhicheng Dou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.19792v2","updated":"2026-02-26T11:22:42Z","published":"2025-05-26T10:22:44Z","title":"Types of Relations: Defining Analogies with Category Theory","summary":"In order to behave intelligently both humans and machines have to represent their knowledge adequately for how it is used. Humans often use analogies to transfer their knowledge to new domains, or help others with this transfer via explanations. Hence, an important question is: What representation can be used to construct, find, and evaluate analogies? In this paper, we study features of a domain that are important for constructing analogies. We do so by formalizing knowledge domains as categories. We use the well-known example of the analogy between the solar system and the hydrogen atom to demonstrate how to construct domain categories. We also show how functors, pullbacks, and pushouts can be used to define an analogy, describe its core and a corresponding blend of the underlying domains.","authors":["Claire Ott","Frank Jäkel"],"pdf_url":"","comment":"27 pages, 15 figures"},{"id":"http://arxiv.org/abs/2602.22879v1","updated":"2026-02-26T11:17:31Z","published":"2026-02-26T11:17:31Z","title":"Towards LLM-Empowered Knowledge Tracing via LLM-Student Hierarchical Behavior Alignment in Hyperbolic Space","summary":"Knowledge Tracing (KT) diagnoses students' concept mastery through continuous learning state monitoring in education.Existing methods primarily focus on studying behavioral sequences based on ID or textual information.While existing methods rely on ID-based sequences or shallow textual features, they often fail to capture (1) the hierarchical evolution of cognitive states and (2) individualized problem difficulty perception due to limited semantic modeling. Therefore, this paper proposes a Large Language Model Hyperbolic Aligned Knowledge Tracing(L-HAKT). First, the teacher agent deeply parses question semantics and explicitly constructs hierarchical dependencies of knowledge points; the student agent simulates learning behaviors to generate synthetic data. Then, contrastive learning is performed between synthetic and real data in hyperbolic space to reduce distribution differences in key features such as question difficulty and forgetting patterns. Finally, by optimizing hyperbolic curvature, we explicitly model the tree-like hierarchical structure of knowledge points, precisely characterizing differences in learning curve morphology for knowledge points at different levels. Extensive experiments on four real-world educational datasets validate the effectiveness of our Large Language Model Hyperbolic Aligned Knowledge Tracing (L-HAKT) framework.","authors":["Xingcheng Fu","Shengpeng Wang","Yisen Gao","Xianxian Li","Chunpei Li","Qingyun Sun","Dongran Yu"],"pdf_url":"","comment":"9 pages, 6 figures, Accepted to AAAI 2026"},{"id":"http://arxiv.org/abs/2502.12108v3","updated":"2026-02-26T11:16:09Z","published":"2025-02-17T18:29:24Z","title":"Using the Path of Least Resistance to Explain Deep Networks","summary":"Integrated Gradients (IG), a widely used axiomatic path-based attribution method, assigns importance scores to input features by integrating model gradients along a straight path from a baseline to the input. While effective in some cases, we show that straight paths can lead to flawed attributions. In this paper, we identify the cause of these misattributions and propose an alternative approach that equips the input space with a model-induced Riemannian metric (derived from the explained model's Jacobian) and computes attributions by integrating gradients along geodesics under this metric. We call this method Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we introduce two techniques: a k-Nearest Neighbours-based approach for smaller models and a Stochastic Variational Inference-based method for larger ones. Additionally, we propose a new axiom, No-Cancellation Completeness (NCC), which strengthens completeness by ruling out feature-wise cancellation. We prove that, for path-based attributions under the model-induced metric, NCC holds if and only if the integration path is a geodesic. Through experiments on both synthetic and real-world image classification data, we provide empirical evidence supporting our theoretical analysis and showing that GIG produces more faithful attributions than existing methods, including IG, on the benchmarks considered.","authors":["Sina Salek","Joseph Enguehard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22873v1","updated":"2026-02-26T11:10:35Z","published":"2026-02-26T11:10:35Z","title":"Learning Tangent Bundles and Characteristic Classes with Autoencoder Atlases","summary":"We introduce a theoretical framework that connects multi-chart autoencoders in manifold learning with the classical theory of vector bundles and characteristic classes. Rather than viewing autoencoders as producing a single global Euclidean embedding, we treat a collection of locally trained encoder-decoder pairs as a learned atlas on a manifold. We show that any reconstruction-consistent autoencoder atlas canonically defines transition maps satisfying the cocycle condition, and that linearising these transition maps yields a vector bundle coinciding with the tangent bundle when the latent dimension matches the intrinsic dimension of the manifold. This construction provides direct access to differential-topological invariants of the data. In particular, we show that the first Stiefel-Whitney class can be computed from the signs of the Jacobians of learned transition maps, yielding an algorithmic criterion for detecting orientability. We also show that non-trivial characteristic classes provide obstructions to single-chart representations, and that the minimum number of autoencoder charts is determined by the good cover structure of the manifold. Finally, we apply our methodology to low-dimensional orientable and non-orientable manifolds, as well as to a non-orientable high-dimensional image dataset.","authors":["Eduardo Paluzo-Hidalgo","Yuichi Ike"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22871v1","updated":"2026-02-26T11:08:39Z","published":"2026-02-26T11:08:39Z","title":"Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching","summary":"Reasoning with large language models often benefits from generating multiple chains-of-thought, but existing aggregation strategies are typically trajectory-level (e.g., selecting the best trace or voting on the final answer), discarding useful intermediate work from partial or \"nearly correct\" attempts. We propose Stitching Noisy Diffusion Thoughts, a self-consistency framework that turns cheap diffusion-sampled reasoning into a reusable pool of step-level candidates. Given a problem, we (i) sample many diverse, low-cost reasoning trajectories using a masked diffusion language model, (ii) score every intermediate step with an off-the-shelf process reward model (PRM), and (iii) stitch these highest-quality steps across trajectories into a composite rationale. This rationale then conditions an autoregressive (AR) model (solver) to recompute only the final answer. This modular pipeline separates exploration (diffusion) from evaluation and solution synthesis, avoiding monolithic unified hybrids while preserving broad search. Across math reasoning benchmarks, we find that step-level recombination is most beneficial on harder problems, and ablations highlight the importance of the final AR solver in converting stitched but imperfect rationales into accurate answers. Using low-confidence diffusion sampling with parallel, independent rollouts, our training-free framework improves average accuracy by up to 23.8% across six math and coding tasks. At the same time, it achieves up to a 1.8x latency reduction relative to both traditional diffusion models (e.g., Dream, LLaDA) and unified architectures (e.g., TiDAR). Code is available at https://github.com/roymiles/diffusion-stitching.","authors":["Roy Miles","Aysim Toker","Andreea-Maria Oncescu","Songcen Xu","Jiankang Deng","Ismail Elezi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.24276v2","updated":"2026-02-26T11:04:20Z","published":"2025-09-29T04:38:12Z","title":"G-reasoner: Foundation Models for Unified Reasoning over Graph-structured Knowledge","summary":"Large language models (LLMs) excel at complex reasoning but remain limited by static and incomplete parametric knowledge. Retrieval-augmented generation (RAG) mitigates this by incorporating external knowledge, yet existing RAGs struggle with knowledge-intensive tasks due to fragmented information and weak modeling of knowledge structure. Graphs offer a natural way to model relationships within knowledge, but LLMs are inherently unstructured and cannot effectively reason over graph-structured data. Recent graph-enhanced RAG (GraphRAG) attempts to bridge this gap by constructing tailored graphs and enabling LLMs to reason on them. However, these methods often depend on ad-hoc graph designs, heuristic search, or costly agent pipelines, which hinder scalability and generalization. To address these challenges, we present G-reasoner, a unified framework that integrates graph and language foundation models for scalable reasoning over diverse graph-structured knowledge. Central to our approach is QuadGraph, a standardized four-layer abstraction that unifies heterogeneous knowledge sources into a common graph representation. Building on this, we introduce a 34M-parameter graph foundation model (GFM) that jointly captures graph topology and textual semantics, and is integrated with LLMs to enhance reasoning in downstream applications. To ensure scalability and efficiency, mixed-precision training and distributed message-passing are implemented to scale GFM with more GPUs. Extensive experiments on six benchmarks show that G-reasoner consistently outperforms state-of-the-art baselines, significantly enhances LLM reasoning, and achieves strong efficiency and cross-graph generalization.","authors":["Linhao Luo","Zicheng Zhao","Junnan Liu","Zhangchi Qiu","Junnan Dong","Serge Panev","Chen Gong","Thuy-Trang Vu","Gholamreza Haffari","Dinh Phung","Alan Wee-Chung Liew","Shirui Pan"],"pdf_url":"","comment":"Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2504.01445v3","updated":"2026-02-26T10:52:45Z","published":"2025-04-02T07:56:39Z","title":"Compositional-ARC: Assessing Systematic Generalization in Abstract Spatial Reasoning","summary":"Systematic generalization refers to the capacity to understand and generate novel combinations from known components. Despite recent progress by large language models (LLMs) across various domains, these models often fail to extend their knowledge to novel compositional scenarios, revealing notable limitations in systematic generalization. There has been an ongoing debate about whether neural networks possess the capacity for systematic generalization, with recent studies suggesting that meta-learning approaches designed for compositionality can significantly enhance this ability. However, these insights have largely been confined to linguistic problems, leaving their applicability to other tasks an open question. In this study, we extend meta-learning for compositionality to the domain of abstract spatial reasoning. To this end, we introduce $\\textit{Compositional-ARC}\\unicode{x2014}$a dataset designed to evaluate the capacity of models to systematically generalize from known geometric transformations (e.g., translation, rotation) of abstract two-dimensional objects to novel combinations of these transformations (e.g., translation+rotation). Our results show that a small transformer-based encoder-decoder model, trained via meta-learning for compositionality, can systematically generalize to previously unseen transformation compositions. Notably, despite having only 5.7M parameters, this model significantly outperforms state-of-the-art LLMs$\\unicode{x2014}$including o3-mini, GPT-4o, and Gemini 2.0 Flash, which fail to exhibit similar systematic behavior$\\unicode{x2014}$and performs on par with the winning model of the ARC prize 2024, an 8B-parameter LLM trained via test-time training. Our findings highlight the effectiveness of meta-learning in promoting systematicity beyond linguistic tasks, suggesting a promising direction toward more robust and generalizable models.","authors":["Philipp Mondorf","Shijia Zhou","Monica Riedler","Barbara Plank"],"pdf_url":"","comment":"ICLR 2026, 37 pages, 15 figures"},{"id":"http://arxiv.org/abs/2512.06660v2","updated":"2026-02-26T10:44:56Z","published":"2025-12-07T05:18:27Z","title":"Towards Small Language Models for Security Query Generation in SOC Workflows","summary":"Analysts in Security Operations Centers routinely query massive telemetry streams using Kusto Query Language (KQL). Writing correct KQL requires specialized expertise, and this dependency creates a bottleneck as security teams scale. This paper investigates whether Small Language Models (SLMs) can enable accurate, cost-effective natural-language-to-KQL translation for enterprise security. We propose a three-knob framework targeting prompting, fine-tuning, and architecture design. First, we adapt existing NL2KQL framework for SLMs with lightweight retrieval and introduce error-aware prompting that addresses common parser failures without increasing token count. Second, we apply LoRA fine-tuning with rationale distillation, augmenting each NLQ-KQL pair with a brief chain-of-thought explanation to transfer reasoning from a teacher model while keeping the SLM compact. Third, we propose a two-stage architecture that uses an SLM for candidate generation and a low-cost LLM judge for schema-aware refinement and selection. We evaluate nine models (five SLMs and four LLMs) across syntax correctness, semantic accuracy, table selection, and filter precision, alongside latency and token cost. On Microsoft's NL2KQL Defender Evaluation dataset, our two-stage approach achieves 0.987 syntax and 0.906 semantic accuracy. We further demonstrate generalizability on Microsoft Sentinel data, reaching 0.964 syntax and 0.831 semantic accuracy. These results come at up to 10x lower token cost than GPT-5, establishing SLMs as a practical, scalable foundation for natural-language querying in security operations.","authors":["Saleha Muzammil","Rahul Reddy","Vishal Kamalakrishnan","Hadi Ahmadi","Wajih Ul Hassan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22850v1","updated":"2026-02-26T10:38:41Z","published":"2026-02-26T10:38:41Z","title":"MEDNA-DFM: A Dual-View FiLM-MoE Model for Explainable DNA Methylation Prediction","summary":"Accurate computational identification of DNA methylation is essential for understanding epigenetic regulation. Although deep learning excels in this binary classification task, its \"black-box\" nature impedes biological insight. We address this by introducing a high-performance model MEDNA-DFM, alongside mechanism-inspired signal purification algorithms. Our investigation demonstrates that MEDNA-DFM effectively captures conserved methylation patterns, achieving robust distinction across diverse species. Validation on external independent datasets confirms that the model's generalization is driven by conserved intrinsic motifs (e.g., GC content) rather than phylogenetic proximity. Furthermore, applying our developed algorithms extracted motifs with significantly higher reliability than prior studies. Finally, empirical evidence from a Drosophila 6mA case study prompted us to propose a \"sequence-structure synergy\" hypothesis, suggesting that the GAGG core motif and an upstream A-tract element function cooperatively. We further validated this hypothesis via in silico mutagenesis, confirming that the ablation of either or both elements significantly degrades the model's recognition capabilities. This work provides a powerful tool for methylation prediction and demonstrates how explainable deep learning can drive both methodological innovation and the generation of biological hypotheses.","authors":["Yi He","Yina Cao","Jixiu Zhai","Di Wang","Junxiao Kong","Tianchi Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19128v2","updated":"2026-02-26T10:37:48Z","published":"2026-02-22T11:06:22Z","title":"K-Search: LLM Kernel Generation via Co-Evolving Intrinsic World Model","summary":"Optimizing GPU kernels is critical for efficient modern machine learning systems yet remains challenging due to the complex interplay of design factors and rapid hardware evolution. Existing automated approaches typically treat Large Language Models (LLMs) merely as stochastic code generators within heuristic-guided evolutionary loops. These methods often struggle with complex kernels requiring coordinated, multi-step structural transformations, as they lack explicit planning capabilities and frequently discard promising strategies due to inefficient or incorrect intermediate implementations. To address this, we propose Search via Co-Evolving World Model and build K-Search based on this method. By replacing static search heuristics with a co-evolving world model, our framework leverages LLMs' prior domain knowledge to guide the search, actively exploring the optimization space. This approach explicitly decouples high-level algorithmic planning from low-level program instantiation, enabling the system to navigate non-monotonic optimization paths while remaining resilient to temporary implementation defects. We evaluate K-Search on diverse, complex kernels from FlashInfer, including GQA, MLA, and MoE kernels. Our results show that K-Search significantly outperforms state-of-the-art evolutionary search methods, achieving an average 2.10x improvement and up to a 14.3x gain on complex MoE kernels. On the GPUMode TriMul task, K-Search achieves state-of-the-art performance on H100, reaching 1030us and surpassing both prior evolution and human-designed solutions.","authors":["Shiyi Cao","Ziming Mao","Joseph E. Gonzalez","Ion Stoica"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22847v1","updated":"2026-02-26T10:37:23Z","published":"2026-02-26T10:37:23Z","title":"Decentralized Ranking Aggregation: Gossip Algorithms for Borda and Copeland Consensus","summary":"The concept of ranking aggregation plays a central role in preference analysis, and numerous algorithms for calculating median rankings, often originating in social choice theory, have been documented in the literature, offering theoretical guarantees in a centralized setting, i.e., when all the ranking data to be aggregated can be brought together in a single computing unit. For many technologies (e.g. peer-to-peer networks, IoT, multi-agent systems), extending the ability to calculate consensus rankings with guarantees in a decentralized setting, i.e., when preference data is initially distributed across a communicating network, remains a major methodological challenge. Indeed, in recent years, the literature on decentralized computation has mainly focused on computing or optimizing statistics such as arithmetic means using gossip algorithms. The purpose of this article is precisely to study how to achieve reliable consensus on collective rankings using classical rules (e.g. Borda, Copeland) in a decentralized setting, thereby raising new questions, robustness to corrupted nodes, and scalability through reduced communication costs in particular. The approach proposed and analyzed here relies on random gossip communication, allowing autonomous agents to compute global ranking consensus using only local interactions, without coordination or central authority.\n  We provide rigorous convergence guarantees, including explicit rate bounds, for the Borda and Copeland consensus methods. Beyond these rules, we also provide a decentralized implementation of consensus according to the median rank rule and local Kemenization. Extensive empirical evaluations on various network topologies and real and synthetic ranking datasets demonstrate that our algorithms converge quickly and reliably to the correct ranking aggregation.","authors":["Anna Van Elst","Kerrian Le Caillec","Igor Colin","Stephan Clémençon"],"pdf_url":"","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.01749v3","updated":"2026-02-26T10:33:17Z","published":"2026-02-02T07:34:30Z","title":"Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives","summary":"Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \\times$ increase in the number of discovered modes.","authors":["Lin Chen","Samuel Drapeau","Fanghao Shao","Xuekai Zhu","Bo Xue","Yunchong Song","Mathieu Laurière","Zhouhan Lin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22842v1","updated":"2026-02-26T10:29:05Z","published":"2026-02-26T10:29:05Z","title":"The AI Research Assistant: Promise, Peril, and a Proof of Concept","summary":"Can artificial intelligence truly contribute to creative mathematical research, or does it merely automate routine calculations while introducing risks of error? We provide empirical evidence through a detailed case study: the discovery of novel error representations and bounds for Hermite quadrature rules via systematic human-AI collaboration.\n  Working with multiple AI assistants, we extended results beyond what manual work achieved, formulating and proving several theorems with AI assistance. The collaboration revealed both remarkable capabilities and critical limitations. AI excelled at algebraic manipulation, systematic proof exploration, literature synthesis, and LaTeX preparation. However, every step required rigorous human verification, mathematical intuition for problem formulation, and strategic direction.\n  We document the complete research workflow with unusual transparency, revealing patterns in successful human-AI mathematical collaboration and identifying failure modes researchers must anticipate. Our experience suggests that, when used with appropriate skepticism and verification protocols, AI tools can meaningfully accelerate mathematical discovery while demanding careful human oversight and deep domain expertise.","authors":["Tan Bui-Thanh"],"pdf_url":"","comment":"11 pages, 1 figure"},{"id":"http://arxiv.org/abs/2602.22839v1","updated":"2026-02-26T10:26:48Z","published":"2026-02-26T10:26:48Z","title":"DeepPresenter: Environment-Grounded Reflection for Agentic Presentation Generation","summary":"Presentation generation requires deep content research, coherent visual design, and iterative refinement based on observation. However, existing presentation agents often rely on predefined workflows and fixed templates. To address this, we present DeepPresenter, an agentic framework that adapts to diverse user intents, enables effective feedback-driven refinement, and generalizes beyond a scripted pipeline. Specifically, DeepPresenter autonomously plans, renders, and revises intermediate slide artifacts to support long-horizon refinement with environmental observations. Furthermore, rather than relying on self-reflection over internal signals (e.g., reasoning traces), our environment-grounded reflection conditions the generation process on perceptual artifact states (e.g., rendered slides), enabling the system to identify and correct presentation-specific issues during execution. Results on the evaluation set covering diverse presentation-generation scenarios show that DeepPresenter achieves state-of-the-art performance, and the fine-tuned 9B model remains highly competitive at substantially lower cost. Our project is available at: https://github.com/icip-cas/PPTAgent","authors":["Hao Zheng","Guozhao Mo","Xinru Yan","Qianhao Yuan","Wenkai Zhang","Xuanang Chen","Yaojie Lu","Hongyu Lin","Xianpei Han","Le Sun"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22831v1","updated":"2026-02-26T10:17:57Z","published":"2026-02-26T10:17:57Z","title":"Moral Preferences of LLMs Under Directed Contextual Influence","summary":"Moral benchmarks for LLMs typically use context-free prompts, implicitly assuming stable preferences. In deployment, however, prompts routinely include contextual signals such as user requests, cues on social norms, etc. that may steer decisions. We study how directed contextual influences reshape decisions in trolley-problem-style moral triage settings. We introduce a pilot evaluation harness for directed contextual influence in trolley-problem-style moral triage: for each demographic factor, we apply matched, direction-flipped contextual influences that differ only in which group they favor, enabling systematic measurement of directional response. We find that: (i) contextual influences often significantly shift decisions, even when only superficially relevant; (ii) baseline preferences are a poor predictor of directional steerability, as models can appear baseline-neutral yet exhibit systematic steerability asymmetry under influence; (iii) influences can backfire: models may explicitly claim neutrality or discount the contextual cue, yet their choices still shift, sometimes in the opposite direction; and (iv) reasoning reduces average sensitivity, but amplifies the effect of biased few-shot examples. Our findings motivate extending moral evaluations with controlled, direction-flipped context manipulations to better characterize model behavior.","authors":["Phil Blandfort","Tushar Karayil","Urja Pawar","Robert Graham","Alex McKenzie","Dmitrii Krasheninnikov"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22828v1","updated":"2026-02-26T10:11:15Z","published":"2026-02-26T10:11:15Z","title":"TCM-DiffRAG: Personalized Syndrome Differentiation Reasoning Method for Traditional Chinese Medicine based on Knowledge Graph and Chain of Thought","summary":"Background: Retrieval augmented generation (RAG) technology can empower large language models (LLMs) to generate more accurate, professional, and timely responses without fine tuning. However, due to the complex reasoning processes and substantial individual differences involved in traditional Chinese medicine (TCM) clinical diagnosis and treatment, traditional RAG methods often exhibit poor performance in this domain. Objective: To address the limitations of conventional RAG approaches in TCM applications, this study aims to develop an improved RAG framework tailored to the characteristics of TCM reasoning. Methods: We developed TCM-DiffRAG, an innovative RAG framework that integrates knowledge graphs (KG) with chains of thought (CoT). TCM-DiffRAG was evaluated on three distinctive TCM test datasets. Results: The experimental results demonstrated that TCM-DiffRAG achieved significant performance improvements over native LLMs. For example, the qwen-plus model achieved scores of 0.927, 0.361, and 0.038, which were significantly enhanced to 0.952, 0.788, and 0.356 with TCM-DiffRAG. The improvements were even more pronounced for non-Chinese LLMs. Additionally, TCM-DiffRAG outperformed directly supervised fine-tuned (SFT) LLMs and other benchmark RAG methods. Conclusions: TCM-DiffRAG shows that integrating structured TCM knowledge graphs with Chain of Thought based reasoning substantially improves performance in individualized diagnostic tasks. The joint use of universal and personalized knowledge graphs enables effective alignment between general knowledge and clinical reasoning. These results highlight the potential of reasoning-aware RAG frameworks for advancing LLM applications in traditional Chinese medicine.","authors":["Jianmin Li","Ying Chang","Su-Kit Tang","Yujia Liu","Yanwen Wang","Shuyuan Lin","Binkai Ou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20505v3","updated":"2026-02-26T10:08:30Z","published":"2025-10-23T12:48:18Z","title":"RELOOP: Recursive Retrieval with Multi-Hop Reasoner and Planners for Heterogeneous QA","summary":"Retrieval-augmented generation (RAG) remains brittle on multi-step questions and heterogeneous evidence sources, trading accuracy against latency and token/tool budgets. This paper introduces RELOOP, a structure aware framework using Hierarchical Sequence (HSEQ) that (i) linearize documents, tables, and knowledge graphs into a reversible hierarchical sequence with lightweight structural tags, and (ii) perform structure-aware iteration to collect just-enough evidence before answer synthesis. A Head Agent provides guidance that leads retrieval, while an Iteration Agent selects and expands HSeq via structure-respecting actions (e.g., parent/child hops, table row/column neighbors, KG relations); Finally the head agent composes canonicalized evidence to genearte the final answer, with an optional refinement loop to resolve detected contradictions. Experiments on HotpotQA (text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1 gains over strong single-pass, multi-hop, and agentic RAG baselines with high efficiency. Besides, RELOOP exhibits three key advantages: (1) a format-agnostic unification that enables a single policy to operate across text, tables, and KGs without per-dataset specialization; (2) \\textbf{guided, budget-aware iteration} that reduces unnecessary hops, tool calls, and tokens while preserving accuracy; and (3) evidence canonicalization for reliable QA, improving answers consistency and auditability.","authors":["Ruiyi Yang","Hao Xue","Imran Razzak","Hakim Hacid","Flora D. Salim"],"pdf_url":"","comment":"19 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.22822v1","updated":"2026-02-26T10:05:01Z","published":"2026-02-26T10:05:01Z","title":"FlexMS is a flexible framework for benchmarking deep learning-based mass spectrum prediction tools in metabolomics","summary":"The identification and property prediction of chemical molecules is of central importance in the advancement of drug discovery and material science, where the tandem mass spectrometry technology gives valuable fragmentation cues in the form of mass-to-charge ratio peaks. However, the lack of experimental spectra hinders the attachment of each molecular identification, and thus urges the establishment of prediction approaches for computational models. Deep learning models appear promising for predicting molecular structure spectra, but overall assessment remains challenging as a result of the heterogeneity in methods and the lack of well-defined benchmarks. To address this, our contribution is the creation of benchmark framework FlexMS for constructing and evaluating diverse model architectures in mass spectrum prediction. With its easy-to-use flexibility, FlexMS supports the dynamic construction of numerous distinct combinations of model architectures, while assessing their performance on preprocessed public datasets using different metrics. In this paper, we provide insights into factors influencing performance, including the structural diversity of datasets, hyperparameters like learning rate and data sparsity, pretraining effects, metadata ablation settings and cross-domain transfer learning analysis. This provides practical guidance in choosing suitable models. Moreover, retrieval benchmarks simulate practical identification scenarios and score potential matches based on predicted spectra.","authors":["Yunhua Zhong","Yixuan Tang","Yifan Li","Jie Yang","Pan Liu","Jun Xia"],"pdf_url":"","comment":"28 pages, preprint version"},{"id":"http://arxiv.org/abs/2602.22817v1","updated":"2026-02-26T09:58:10Z","published":"2026-02-26T09:58:10Z","title":"Hierarchy-of-Groups Policy Optimization for Long-Horizon Agentic Tasks","summary":"Group-based reinforcement learning (RL), such as GRPO, has advanced the capabilities of large language models on long-horizon agentic tasks. To enable more fine-grained policy updates, recent research has increasingly shifted toward stepwise group-based policy optimization, which treats each step in a rollout trajectory independently while using a memory module to retain historical context. However, we find a key issue in estimating stepwise relative advantages, namely context inconsistency, where steps within the same group may differ in their historical contexts. Empirically, we reveal that this issue can lead to severely biased advantage estimation, thereby degrading policy optimization significantly. To address the issue, in this paper, we propose Hierarchy-of-Groups Policy Optimization (HGPO) for long-horizon agentic tasks. Specifically, within a group of rollout trajectories, HGPO assigns each step to multiple hierarchical groups according to the consistency of historical contexts. Then, for each step, HGPO computes distinct advantages within each group and aggregates them with an adaptive weighting scheme. In this way, HGPO can achieve a favorable bias-variance trade-off in stepwise advantage estimation, without extra models or rollouts. Evaluations on two challenging agentic tasks, ALFWorld and WebShop with Qwen2.5-1.5B-Instruct and Qwen2.5-7B-Instruct, show that HGPO significantly outperforms existing agentic RL methods under the same computational constraints. Code is available at https://github.com/langfengQ/verl-agent/tree/master/recipe/hgpo.","authors":["Shuo He","Lang Feng","Qi Wei","Xin Cheng","Lei Feng","Bo An"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.22814v1","updated":"2026-02-26T09:56:37Z","published":"2026-02-26T09:56:37Z","title":"When Should an AI Act? A Human-Centered Model of Scene, Context, and Behavior for Agentic AI Design","summary":"Agentic AI increasingly intervenes proactively by inferring users' situations from contextual data yet often fails for lack of principled judgment about when, why, and whether to act. We address this gap by proposing a conceptual model that reframes behavior as an interpretive outcome integrating Scene (observable situation), Context (user-constructed meaning), and Human Behavior Factors (determinants shaping behavioral likelihood). Grounded in multidisciplinary perspectives across the humanities, social sciences, HCI, and engineering, the model separates what is observable from what is meaningful to the user and explains how the same scene can yield different behavioral meanings and outcomes. To translate this lens into design action, we derive five agent design principles (behavioral alignment, contextual sensitivity, temporal appropriateness, motivational calibration, and agency preservation) that guide intervention depth, timing, intensity, and restraint. Together, the model and principles provide a foundation for designing agentic AI systems that act with contextual sensitivity and judgment in interactions.","authors":["Soyoung Jung","Daehoo Yoon","Sung Gyu Koh","Young Hwan Kim","Yehan Ahn","Sung Park"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.01932v6","updated":"2026-02-26T09:51:13Z","published":"2025-02-04T02:07:23Z","title":"VolleyBots: A Testbed for Multi-Drone Volleyball Game Combining Motion Control and Strategic Play","summary":"Robot sports, characterized by well-defined objectives, explicit rules, and dynamic interactions, present ideal scenarios for demonstrating embodied intelligence. In this paper, we present VolleyBots, a novel robot sports testbed where multiple drones cooperate and compete in the sport of volleyball under physical dynamics. VolleyBots integrates three features within a unified platform: competitive and cooperative gameplay, turn-based interaction structure, and agile 3D maneuvering. These intertwined features yield a complex problem combining motion control and strategic play, with no available expert demonstrations. We provide a comprehensive suite of tasks ranging from single-drone drills to multi-drone cooperative and competitive tasks, accompanied by baseline evaluations of representative reinforcement learning (RL), multi-agent reinforcement learning (MARL) and game-theoretic algorithms. Simulation results show that on-policy RL methods outperform off-policy methods in single-agent tasks, but both approaches struggle in complex tasks that combine motion control and strategic play. We additionally design a hierarchical policy which achieves 69.5% win rate against the strongest baseline in the 3 vs 3 task, demonstrating its potential for tackling the complex interplay between low-level control and high-level strategy. To highlight VolleyBots' sim-to-real potential, we further demonstrate the zero-shot deployment of a policy trained entirely in simulation on real-world drones.","authors":["Zelai Xu","Ruize Zhang","Chao Yu","Huining Yuan","Xiangmin Yi","Shilong Ji","Chuqi Wang","Wenhao Tang","Feng Gao","Wenbo Ding","Xinlei Chen","Yu Wang"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2510.25726v2","updated":"2026-02-26T09:46:48Z","published":"2025-10-29T17:32:49Z","title":"The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic, and Long-Horizon Task Execution","summary":"Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existing language agent benchmarks often focus on narrow domains or simplified tasks that lack the diversity, realism, and long-horizon complexity required to evaluate agents' real-world performance. To address this gap, we introduce the Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering diverse Apps and tools, realistic environment setup, and reliable execution-based evaluation. Toolathlon spans 32 software applications and 604 tools, ranging from everyday platforms such as Google Calendar and Notion to professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools are based on a high-quality set of Model Context Protocol (MCP) servers that we may have revised or implemented ourselves. Unlike prior works, which primarily ensure functional realism but offer limited environment state diversity, we provide realistic initial environment states from real software, such as Canvas courses with dozens of students or real financial spreadsheets. This benchmark includes 108 manually sourced or crafted tasks in total, requiring interacting with multiple Apps over around 20 turns on average to complete. Each task is strictly verifiable through dedicated evaluation scripts. Comprehensive evaluation of SOTA models highlights their significant shortcomings: the best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate with 20.2 tool calling turns on average, while the top open-weights model DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development of more capable language agents for real-world, long-horizon task execution.","authors":["Junlong Li","Wenshuo Zhao","Jian Zhao","Weihao Zeng","Haoze Wu","Xiaochen Wang","Rui Ge","Yuxuan Cao","Yuzhen Huang","Wei Liu","Junteng Liu","Zhaochen Su","Yiyang Guo","Fan Zhou","Lueyang Zhang","Juan Michelini","Xingyao Wang","Xiang Yue","Shuyan Zhou","Graham Neubig","Junxian He"],"pdf_url":"","comment":"ICLR 2026, Website: https://toolathlon.xyz/"},{"id":"http://arxiv.org/abs/2602.22808v1","updated":"2026-02-26T09:45:04Z","published":"2026-02-26T09:45:04Z","title":"MiroFlow: Towards High-Performance and Robust Open-Source Agent Framework for General Deep Research Tasks","summary":"Despite the remarkable progress of large language models (LLMs), the capabilities of standalone LLMs have begun to plateau when tackling real-world, complex tasks that require interaction with external tools and dynamic environments. Although recent agent frameworks aim to enhance model autonomy through tool integration and external interaction, they still suffer from naive workflows, unstable performance, limited support across diverse benchmarks and tasks, and heavy reliance on costly commercial APIs. In this work, we propose a high-performance and robust open-source agent framework, termed MiroFlow, which incorporates an agent graph for flexible orchestration, an optional deep reasoning mode to enhance performance, and a robust workflow execution to ensure stable and reproducible performance. Extensive experiments demonstrate that MiroFlow consistently achieves state-of-the-art performance across multiple agent benchmarks, including GAIA, BrowseComp-EN/ZH, HLE, xBench-DeepSearch, and notably FutureX. We hope it could serve as an easily accessible, reproducible, and comparable baseline for the deep research community.","authors":["Shiqian Su","Sen Xing","Xuan Dong","Muyan Zhong","Bin Wang","Xizhou Zhu","Yuntao Chen","Wenhai Wang","Yue Deng","Pengxiang Zhu","Ziyuan Liu","Tiantong Li","Jiaheng Yu","Zhe Chen","Lidong Bing","Jifeng Dai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19190v2","updated":"2026-02-26T09:45:03Z","published":"2026-02-22T13:40:17Z","title":"FUSAR-GPT : A Spatiotemporal Feature-Embedded and Two-Stage Decoupled Visual Language Model for SAR Imagery","summary":"Research on the intelligent interpretation of all-weather, all-time Synthetic Aperture Radar (SAR) is crucial for advancing remote sensing applications. In recent years, although Visual Language Models (VLMs) have demonstrated strong open-world understanding capabilities on RGB images, their performance is severely limited when directly applied to the SAR field due to the complexity of the imaging mechanism, sensitivity to scattering features, and the scarcity of high-quality text corpora. To systematically address this issue, we constructed the inaugural SAR Image-Text-AlphaEarth feature triplet dataset and developed FUSAR-GPT, a VLM specifically for SAR. FUSAR-GPT innovatively introduces a geospatial baseline model as a 'world knowledge' prior and embeds multi-source remote-sensing temporal features into the model's visual backbone via 'spatiotemporal anchors', enabling dynamic compensation for the sparse representation of targets in SAR images. Furthermore, we designed a two-stage SFT strategy to decouple the knowledge injection and task execution of large models. The spatiotemporal feature embedding and the two-stage decoupling paradigm enable FUSAR-GPT to achieve state-of-the-art performance across several typical remote sensing visual-language benchmark tests, significantly outperforming mainstream baseline models by over 12%.","authors":["Xiaokun Zhang","Yi Yang","Ziqi Ye"," Baiyun","Xiaorong Guo","Qingchen Fang","Ruyi Zhang","Xinpeng Zhou","Haipeng Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.16913v2","updated":"2026-02-26T09:39:41Z","published":"2026-02-18T21:59:04Z","title":"A Reversible Semantics for Janus","summary":"Janus is a paradigmatic example of a reversible programming language. Indeed, Janus programs can be executed backwards as well as forwards. However, its current small-step semantics (useful, e.g., for debugging or as a basis for extensions with concurrency primitives) is not reversible, since it loses information while computing forwards. E.g., it does not satisfy the Loop Lemma, stating that any reduction has an inverse, a main property of reversibility in process calculi, where a small-step semantics is commonly used. We present here a novel small-step semantics which is actually reversible, while remaining equivalent to the previous one. It involves the non-trivial challenge of defining a semantics based on a \"program counter\" for a high-level programming language.","authors":["Ivan Lanese","Germán Vidal"],"pdf_url":"","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2602.22801v1","updated":"2026-02-26T09:37:38Z","published":"2026-02-26T09:37:38Z","title":"Unleashing the Potential of Diffusion Models for End-to-End Autonomous Driving","summary":"Diffusion models have become a popular choice for decision-making tasks in robotics, and more recently, are also being considered for solving autonomous driving tasks. However, their applications and evaluations in autonomous driving remain limited to simulation-based or laboratory settings. The full strength of diffusion models for large-scale, complex real-world settings, such as End-to-End Autonomous Driving (E2E AD), remains underexplored. In this study, we conducted a systematic and large-scale investigation to unleash the potential of the diffusion models as planners for E2E AD, based on a tremendous amount of real-vehicle data and road testing. Through comprehensive and carefully controlled studies, we identify key insights into the diffusion loss space, trajectory representation, and data scaling that significantly impact E2E planning performance. Moreover, we also provide an effective reinforcement learning post-training strategy to further enhance the safety of the learned planner. The resulting diffusion-based learning framework, Hyper Diffusion Planner} (HDP), is deployed on a real-vehicle platform and evaluated across 6 urban driving scenarios and 200 km of real-world testing, achieving a notable 10x performance improvement over the base model. Our work demonstrates that diffusion models, when properly designed and trained, can serve as effective and scalable E2E AD planners for complex, real-world autonomous driving tasks.","authors":["Yinan Zheng","Tianyi Tan","Bin Huang","Enguang Liu","Ruiming Liang","Jianlin Zhang","Jianwei Cui","Guang Chen","Kun Ma","Hangjun Ye","Long Chen","Ya-Qin Zhang","Xianyuan Zhan","Jingjing Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22790v1","updated":"2026-02-26T09:23:09Z","published":"2026-02-26T09:23:09Z","title":"Natural Language Declarative Prompting (NLD-P): A Modular Governance Method for Prompt Design Under Model Drift","summary":"The rapid evolution of large language models (LLMs) has transformed prompt engineering from a localized craft into a systems-level governance challenge. As models scale and update across generations, prompt behavior becomes sensitive to shifts in instruction-following policies, alignment regimes, and decoding strategies, a phenomenon we characterize as GPT-scale model drift. Under such conditions, surface-level formatting conventions and ad hoc refinement are insufficient to ensure stable, interpretable control. This paper reconceptualizes Natural Language Declarative Prompting (NLD-P) as a declarative governance method rather than a rigid field template. NLD-P is formalized as a modular control abstraction that separates provenance, constraint logic, task content, and post-generation evaluation, encoded directly in natural language without reliance on external orchestration code. We define minimal compliance criteria, analyze model-dependent schema receptivity, and position NLD-P as an accessible governance framework for non-developer practitioners operating within evolving LLM ecosystems. Portions of drafting and editorial refinement employed a schema-bound LLM assistant configured under NLD-P. All conceptual framing, methodological claims, and final revisions were directed, reviewed, and approved by the human author under a documented human-in-the-loop protocol. The paper concludes by outlining implications for declarative control under ongoing model evolution and identifying directions for future empirical validation.","authors":["Hyunwoo Kim","Hanau Yi","Jaehee Bae","Yumin Kim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22787v1","updated":"2026-02-26T09:21:12Z","published":"2026-02-26T09:21:12Z","title":"Probing for Knowledge Attribution in Large Language Models","summary":"Large language models (LLMs) often generate fluent but unfounded claims, or hallucinations, which fall into two types: (i) faithfulness violations - misusing user context - and (ii) factuality violations - errors from internal knowledge. Proper mitigation depends on knowing whether a model's answer is based on the prompt or its internal weights. This work focuses on the problem of contributive attribution: identifying the dominant knowledge source behind each output. We show that a probe, a simple linear classifier trained on model hidden representations, can reliably predict contributive attribution. For its training, we introduce AttriWiki, a self-supervised data pipeline that prompts models to recall withheld entities from memory or read them from context, generating labelled examples automatically. Probes trained on AttriWiki data reveal a strong attribution signal, achieving up to 0.96 Macro-F1 on Llama-3.1-8B, Mistral-7B, and Qwen-7B, transferring to out-of-domain benchmarks (SQuAD, WebQuestions) with 0.94-0.99 Macro-F1 without retraining. Attribution mismatches raise error rates by up to 70%, demonstrating a direct link between knowledge source confusion and unfaithful answers. Yet, models may still respond incorrectly even when attribution is correct, highlighting the need for broader detection frameworks.","authors":["Ivo Brink","Alexander Boer","Dennis Ulmer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22786v1","updated":"2026-02-26T09:20:46Z","published":"2026-02-26T09:20:46Z","title":"QSIM: Mitigating Overestimation in Multi-Agent Reinforcement Learning via Action Similarity Weighted Q-Learning","summary":"Value decomposition (VD) methods have achieved remarkable success in cooperative multi-agent reinforcement learning (MARL). However, their reliance on the max operator for temporal-difference (TD) target calculation leads to systematic Q-value overestimation. This issue is particularly severe in MARL due to the combinatorial explosion of the joint action space, which often results in unstable learning and suboptimal policies. To address this problem, we propose QSIM, a similarity weighted Q-learning framework that reconstructs the TD target using action similarity. Instead of using the greedy joint action directly, QSIM forms a similarity weighted expectation over a structured near-greedy joint action space. This formulation allows the target to integrate Q-values from diverse yet behaviorally related actions while assigning greater influence to those that are more similar to the greedy choice. By smoothing the target with structurally relevant alternatives, QSIM effectively mitigates overestimation and improves learning stability. Extensive experiments demonstrate that QSIM can be seamlessly integrated with various VD methods, consistently yielding superior performance and stability compared to the original algorithms. Furthermore, empirical analysis confirms that QSIM significantly mitigates the systematic value overestimation in MARL. Code is available at https://github.com/MaoMaoLYJ/pymarl-qsim.","authors":["Yuanjun Li","Bin Zhang","Hao Chen","Zhouyang Jiang","Dapeng Li","Zhiwei Xu"],"pdf_url":"","comment":"19 pages, 15 figures, 7tables. Accepted to the 36th International Conference on Automated Planning and Scheduling (ICAPS 2026)"},{"id":"http://arxiv.org/abs/2602.22775v1","updated":"2026-02-26T09:11:34Z","published":"2026-02-26T09:11:34Z","title":"TherapyProbe: Generating Design Knowledge for Relational Safety in Mental Health Chatbots Through Adversarial Simulation","summary":"As mental health chatbots proliferate to address the global treatment gap, a critical question emerges: How do we design for relational safety the quality of interaction patterns that unfold across conversations rather than the correctness of individual responses? Current safety evaluations assess single-turn crisis responses, missing the therapeutic dynamics that determine whether chatbots help or harm over time. We introduce TherapyProbe, a design probe methodology that generates actionable design knowledge by systematically exploring chatbot conversation trajectories through adversarial multi-agent simulation. Using open-source models, TherapyProbe surfaces relational safety failures interaction patterns like \"validation spirals\" where chatbots progressively reinforce hopelessness, or \"empathy fatigue\" where responses become mechanical over turns. Our contribution is translating these failures into a Safety Pattern Library of 23 failure archetypes with corresponding design recommendations. We contribute: (1) a replicable methodology requiring no API costs, (2) a clinically-grounded failure taxonomy, and (3) design implications for developers, clinicians, and policymakers.","authors":["Joydeep Chandra","Satyam Kumar Navneet","Yong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22771v1","updated":"2026-02-26T09:03:41Z","published":"2026-02-26T09:03:41Z","title":"ClinDet-Bench: Beyond Abstention, Evaluating Judgment Determinability of LLMs in Clinical Decision-Making","summary":"Clinical decisions are often required under incomplete information. Clinical experts must identify whether available information is sufficient for judgment, as both premature conclusion and unnecessary abstention can compromise patient safety. To evaluate this capability of large language models (LLMs), we developed ClinDet-Bench, a benchmark based on clinical scoring systems that decomposes incomplete-information scenarios into determinable and undeterminable conditions. Identifying determinability requires considering all hypotheses about missing information, including unlikely ones, and verifying whether the conclusion holds across them. We find that recent LLMs fail to identify determinability under incomplete information, producing both premature judgments and excessive abstention, despite correctly explaining the underlying scoring knowledge and performing well under complete information. These findings suggest that existing benchmarks are insufficient to evaluate the safety of LLMs in clinical settings. ClinDet-Bench provides a framework for evaluating determinability recognition, leading to appropriate abstention, with potential applicability to medicine and other high-stakes domains, and is publicly available.","authors":["Yusuke Watanabe","Yohei Kobashi","Takeshi Kojima","Yusuke Iwasawa","Yasushi Okuno","Yutaka Matsuo"],"pdf_url":"","comment":"17 pages, 3 figures, 10 tables"},{"id":"http://arxiv.org/abs/2602.22769v1","updated":"2026-02-26T08:59:31Z","published":"2026-02-26T08:59:31Z","title":"AMA-Bench: Evaluating Long-Horizon Memory for Agentic Applications","summary":"Large Language Models (LLMs) are deployed as autonomous agents in increasingly complex applications, where enabling long-horizon memory is critical for achieving strong performance. However, a significant gap exists between practical applications and current evaluation standards for agent memory: existing benchmarks primarily focus on dialogue-centric, human-agent interactions. In reality, agent memory consists of a continuous stream of agent-environment interactions that are primarily composed of machine-generated representations. To bridge this gap, we introduce AMA-Bench (Agent Memory with Any length), which evaluates long-horizon memory for LLMs in real agentic applications. It features two key components: (1) a set of real-world agentic trajectories across representative agentic applications, paired with expert-curated QA, and (2) a set of synthetic agentic trajectories that scale to arbitrary horizons, paired with rule-based QA. Our comprehensive study shows that existing memory systems underperform on AMA-Bench primarily because they lack causality and objective information and are constrained by the lossy nature of similarity-based retrieval employed by many memory systems. To address these limitations, we propose AMA-Agent, an effective memory system featuring a causality graph and tool-augmented retrieval. Our results demonstrate that AMA-Agent achieves 57.22% average accuracy on AMA-Bench, surpassing the strongest memory system baselines by 11.16%.","authors":["Yujie Zhao","Boqin Yuan","Junbo Huang","Haocheng Yuan","Zhongming Yu","Haozhou Xu","Lanxiang Hu","Abhilash Shankarampeta","Zimeng Huang","Wentao Ni","Yuandong Tian","Jishen Zhao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19327v2","updated":"2026-02-26T08:54:51Z","published":"2026-02-22T20:21:00Z","title":"Soft Sequence Policy Optimization","summary":"A significant portion of recent research on Large Language Model (LLM) alignment focuses on developing new policy optimization methods based on Group Relative Policy Optimization (GRPO). Two prominent directions have emerged: (i) a shift toward sequence-level importance sampling weights that better align with the sequence-level rewards used in many tasks, and (ii) alternatives to PPO-style clipping that aim to avoid the associated loss of training signal and entropy collapse. We introduce Soft Sequence Policy Optimization, an off-policy reinforcement learning objective that incorporates soft gating functions over token-level probability ratios within sequence-level importance weights. We provide theoretical motivation for SSPO and investigate practical modifications to improve optimization behavior. Empirically, we show that SSPO improves training stability and performance in mathematical reasoning tasks.","authors":["Svetlana Glazyrina","Maksim Kryzhanovskiy","Roman Ischenko"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2502.05435v2","updated":"2026-02-26T08:50:46Z","published":"2025-02-08T03:47:06Z","title":"Unbiased Sliced Wasserstein Kernels for High-Quality Audio Captioning","summary":"Audio captioning systems face a fundamental challenge: teacher-forcing training creates exposure bias that leads to caption degeneration during inference. While contrastive methods have been proposed as solutions, they typically fail to capture the crucial temporal relationships between acoustic and linguistic modalities. We address this limitation by introducing the unbiased sliced Wasserstein RBF (USW-RBF) kernel with rotary positional embedding, specifically designed to preserve temporal information across modalities. Our approach offers a practical advantage: the kernel enables efficient stochastic gradient optimization, making it computationally feasible for real-world applications. Building on this foundation, we develop a complete audio captioning framework that integrates stochastic decoding to further mitigate caption degeneration. Extensive experiments on AudioCaps and Clotho datasets demonstrate that our method significantly improves caption quality, lexical diversity, and text-to-audio retrieval accuracy. Furthermore, we demonstrate the generalizability of our USW-RBF kernel by applying it to audio reasoning tasks, where it enhances the reasoning capabilities of large audio language models on the CompA-R in terms of correctness and quality. Our kernel also improves the reasoning accuracy of the MMAU-test-mini benchmarks by $4\\%$. These results establish our approach as a powerful and generalizable solution for cross-modal alignment challenges in audio-language tasks.","authors":["Manh Luong","Khai Nguyen","Dinh Phung","Gholamreza Haffari","Lizhen Qu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22760v1","updated":"2026-02-26T08:49:57Z","published":"2026-02-26T08:49:57Z","title":"Distributed LLM Pretraining During Renewable Curtailment Windows: A Feasibility Study","summary":"Training large language models (LLMs) requires substantial compute and energy. At the same time, renewable energy sources regularly produce more electricity than the grid can absorb, leading to curtailment, the deliberate reduction of clean generation that would otherwise go to waste. These periods represent an opportunity: if training is aligned with curtailment windows, LLMs can be pretrained using electricity that is both clean and cheap. This technical report presents a system that performs full-parameter LLM training across geo-distributed GPU clusters during regional curtailment windows, elastically switching between local single-site training and federated multi-site synchronization as sites become available or unavailable. Our prototype trains a 561M-parameter transformer model across three clusters using the Flower federated learning framework, with curtailment periods derived from real-world marginal carbon intensity traces. Preliminary results show that curtailment-aware scheduling preserves training quality while reducing operational emissions to 5-12% of single-site baselines.","authors":["Philipp Wiesner","Soeren Becker","Brett Cornick","Dominik Scheinert","Alexander Acker","Odej Kao"],"pdf_url":"","comment":"Technical report"},{"id":"http://arxiv.org/abs/2507.16801v2","updated":"2026-02-26T08:49:14Z","published":"2025-07-22T17:51:13Z","title":"Decoding Translation-Related Functional Sequences in 5'UTRs Using Interpretable Deep Learning Models","summary":"Understanding how 5' untranslated regions (5'UTRs) regulate mRNA translation is critical for controlling protein expression and designing effective therapeutic mRNAs. While recent deep learning models have shown promise in predicting translational efficiency from 5'UTR sequences, most are constrained by fixed input lengths and limited interpretability. We introduce UTR-STCNet, a Transformer-based architecture for flexible and biologically grounded modeling of variable-length 5'UTRs. UTR-STCNet integrates a Saliency-Aware Token Clustering (SATC) module that iteratively aggregates nucleotide tokens into multi-scale, semantically meaningful units based on saliency scores. A Saliency-Guided Transformer (SGT) block then captures both local and distal regulatory dependencies using a lightweight attention mechanism. This combined architecture achieves efficient and interpretable modeling without input truncation or increased computational cost. Evaluated across three benchmark datasets, UTR-STCNet consistently outperforms state-of-the-art baselines in predicting mean ribosome load (MRL), a key proxy for translational efficiency. Moreover, the model recovers known functional elements such as upstream AUGs and Kozak motifs, highlighting its potential for mechanistic insight into translation regulation.","authors":["Yuxi Lin","Yaxue Fang","Zehong Zhang","Zhouwu Liu","Siyun Zhong","Zhongfang Wang","Fulong Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22758v1","updated":"2026-02-26T08:47:42Z","published":"2026-02-26T08:47:42Z","title":"Decomposing Physician Disagreement in HealthBench","summary":"We decompose physician disagreement in the HealthBench medical AI evaluation dataset to understand where variance resides and what observable features can explain it. Rubric identity accounts for 15.8% of met/not-met label variance but only 3.6-6.9% of disagreement variance; physician identity accounts for just 2.4%. The dominant 81.8% case-level residual is not reduced by HealthBench's metadata labels (z = -0.22, p = 0.83), normative rubric language (pseudo R^2 = 1.2%), medical specialty (0/300 Tukey pairs significant), surface-feature triage (AUC = 0.58), or embeddings (AUC = 0.485). Disagreement follows an inverted-U with completion quality (AUC = 0.689), confirming physicians agree on clearly good or bad outputs but split on borderline cases. Physician-validated uncertainty categories reveal that reducible uncertainty (missing context, ambiguous phrasing) more than doubles disagreement odds (OR = 2.55, p < 10^(-24)), while irreducible uncertainty (genuine medical ambiguity) has no effect (OR = 1.01, p = 0.90), though even the former explains only ~3% of total variance. The agreement ceiling in medical AI evaluation is thus largely structural, but the reducible/irreducible dissociation suggests that closing information gaps in evaluation scenarios could lower disagreement where inherent clinical ambiguity does not, pointing toward actionable evaluation design improvements.","authors":["Satya Borgohain","Roy Mariathas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.10611v3","updated":"2026-02-26T08:46:23Z","published":"2026-01-15T17:27:44Z","title":"Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding","summary":"Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking).","authors":["Christopher Clark","Jieyu Zhang","Zixian Ma","Jae Sung Park","Mohammadreza Salehi","Rohun Tripathi","Sangho Lee","Zhongzheng Ren","Chris Dongjoo Kim","Yinuo Yang","Vincent Shao","Yue Yang","Weikai Huang","Ziqi Gao","Taira Anderson","Jianrui Zhang","Jitesh Jain","George Stoica","Winson Han","Ali Farhadi","Ranjay Krishna"],"pdf_url":"","comment":"Fixed results in Table 7"},{"id":"http://arxiv.org/abs/2602.00834v3","updated":"2026-02-26T08:46:11Z","published":"2026-01-31T17:57:53Z","title":"A Minimum Variance Path Principle for Accurate and Stable Score-Based Density Ratio Estimation","summary":"Score-based methods are powerful across machine learning, but they face a paradox: theoretically path-independent, yet practically path-dependent.\n  We resolve this by proving that practical training objectives differ from the ideal, ground-truth objective by a crucial, overlooked term: the path variance of the score function.\n  We propose the MVP (**M**imum **V**ariance **P**ath) Principle to minimize this path variance.\n  Our key contribution is deriving a closed-form expression for the variance, making optimization tractable.\n  By parameterizing the path with a flexible Kumaraswamy Mixture Model, our method learns data-adaptive, low-variance paths without heuristic manual selection.\n  This principled optimization of the complete objective yields more accurate and stable estimators, establishing new state-of-the-art results on challenging benchmarks and providing a general framework for optimizing score-based interpolation.","authors":["Wei Chen","Jiacheng Li","Shigui Li","Zhiqi Lin","Junmei Yang","John Paisley","Delu Zeng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22752v1","updated":"2026-02-26T08:40:21Z","published":"2026-02-26T08:40:21Z","title":"Towards Simulating Social Media Users with LLMs: Evaluating the Operational Validity of Conditioned Comment Prediction","summary":"The transition of Large Language Models (LLMs) from exploratory tools to active \"silicon subjects\" in social science lacks extensive validation of operational validity. This study introduces Conditioned Comment Prediction (CCP), a task in which a model predicts how a user would comment on a given stimulus by comparing generated outputs with authentic digital traces. This framework enables a rigorous evaluation of current LLM capabilities with respect to the simulation of social media user behavior. We evaluated open-weight 8B models (Llama3.1, Qwen3, Ministral) in English, German, and Luxembourgish language scenarios. By systematically comparing prompting strategies (explicit vs. implicit) and the impact of Supervised Fine-Tuning (SFT), we identify a critical form vs. content decoupling in low-resource settings: while SFT aligns the surface structure of the text output (length and syntax), it degrades semantic grounding. Furthermore, we demonstrate that explicit conditioning (generated biographies) becomes redundant under fine-tuning, as models successfully perform latent inference directly from behavioral histories. Our findings challenge current \"naive prompting\" paradigms and offer operational guidelines prioritizing authentic behavioral traces over descriptive personas for high-fidelity simulation.","authors":["Nils Schwager","Simon Münker","Alistair Plum","Achim Rettinger"],"pdf_url":"","comment":"14 pages, 1 figure, 7 tables. Accepted to the 15th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis (WASSA) at EACL 2026, Rabat, Morocco"},{"id":"http://arxiv.org/abs/2602.22751v1","updated":"2026-02-26T08:40:06Z","published":"2026-02-26T08:40:06Z","title":"Know What You Know: Metacognitive Entropy Calibration for Verifiable RL Reasoning","summary":"Large reasoning models (LRMs) have emerged as a powerful paradigm for solving complex real-world tasks. In practice, these models are predominantly trained via Reinforcement Learning with Verifiable Rewards (RLVR), yet most existing outcome-only RLVR pipelines rely almost exclusively on a binary correctness signal and largely ignore the model's intrinsic uncertainty. We term this discrepancy the uncertainty-reward mismatch, under which high- and low-uncertainty solutions are treated equivalently, preventing the policy from \"Know What You Know\" and impeding the shift from optimizing for correct answers to optimizing effective reasoning paths. This limitation is especially critical in reasoning-centric tasks such as mathematics and question answering, where performance hinges on the quality of the model's internal reasoning process rather than mere memorization of final answers. To address this, we propose EGPO, a metacognitive entropy calibration framework that explicitly integrates intrinsic uncertainty into RLVR for enhancing LRMs. EGPO estimates per-sample uncertainty using a zero-overhead entropy proxy derived from token-level likelihoods and aligns it with extrinsic correctness through an asymmetric calibration mechanism that preserves correct reasoning while selectively regulating overconfident failures, thereby enabling stable and uncertainty-aware policy optimization. Moreover, EGPO recovers informative learning signals from otherwise degenerate group-based rollouts without modifying the verifier or reward definition. Extensive experiments across multiple benchmarks demonstrate that the proposed EGPO leads to substantial and consistent improvements in reasoning performance, establishing a principled path for advancing LRMs through metacognitive entropy calibration.","authors":["Qiannian Zhao","Chen Yang","Jinhao Jing","Yunke Zhang","Xuhui Ren","Lu Yu","Shijie Zhang","Hongzhi Yin"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22743v1","updated":"2026-02-26T08:30:09Z","published":"2026-02-26T08:30:09Z","title":"Generative Data Transformation: From Mixed to Unified Data","summary":"Recommendation model performance is intrinsically tied to the quality, volume, and relevance of their training data. To address common challenges like data sparsity and cold start, recent researchs have leveraged data from multiple auxiliary domains to enrich information within the target domain. However, inherent domain gaps can degrade the quality of mixed-domain data, leading to negative transfer and diminished model performance. Existing prevailing \\emph{model-centric} paradigm -- which relies on complex, customized architectures -- struggles to capture the subtle, non-structural sequence dependencies across domains, leading to poor generalization and high demands on computational resources. To address these shortcomings, we propose \\textsc{Taesar}, a \\emph{data-centric} framework for \\textbf{t}arget-\\textbf{a}lign\\textbf{e}d \\textbf{s}equenti\\textbf{a}l \\textbf{r}egeneration, which employs a contrastive decoding mechanism to adaptively encode cross-domain context into target-domain sequences. It employs contrastive decoding to encode cross-domain context into target sequences, enabling standard models to learn intricate dependencies without complex fusion architectures. Experiments show \\textsc{Taesar} outperforms model-centric solutions and generalizes to various sequential models. By generating enriched datasets, \\textsc{Taesar} effectively combines the strengths of data- and model-centric paradigms. The code accompanying this paper is available at~ \\textcolor{blue}{https://github.com/USTC-StarTeam/Taesar}.","authors":["Jiaqing Zhang","Mingjia Yin","Hao Wang","Yuxin Tian","Yuyang Ye","Yawen Li","Wei Guo","Yong Liu","Enhong Chen"],"pdf_url":"","comment":"Accepted by The Web Conference 2026 (WWW '26)"},{"id":"http://arxiv.org/abs/2602.22740v1","updated":"2026-02-26T08:29:04Z","published":"2026-02-26T08:29:04Z","title":"AMLRIS: Alignment-aware Masked Learning for Referring Image Segmentation","summary":"Referring Image Segmentation (RIS) aims to segment an object in an image identified by a natural language expression. The paper introduces Alignment-Aware Masked Learning (AML), a training strategy to enhance RIS by explicitly estimating pixel-level vision-language alignment, filtering out poorly aligned regions during optimization, and focusing on trustworthy cues. This approach results in state-of-the-art performance on RefCOCO datasets and also enhances robustness to diverse descriptions and scenarios","authors":["Tongfei Chen","Shuo Yang","Yuguang Yang","Linlin Yang","Runtang Guo","Changbai Li","He Long","Chunyu Xie","Dawei Leng","Baochang Zhang"],"pdf_url":"","comment":"ICLR 2026 conference paper"},{"id":"http://arxiv.org/abs/2602.22735v1","updated":"2026-02-26T08:17:24Z","published":"2026-02-26T08:17:24Z","title":"Simulation-based Optimization for Augmented Reading","summary":"Augmented reading systems aim to adapt text presentation to improve comprehension and task performance, yet existing approaches rely heavily on heuristics, opaque data-driven models, or repeated human involvement in the design loop. We propose framing augmented reading as a simulation-based optimization problem grounded in resource-rational models of human reading. These models instantiate a simulated reader that allocates limited cognitive resources, such as attention, memory, and time under task demands, enabling systematic evaluation of text user interfaces. We introduce two complementary optimization pipelines: an offline approach that explores design alternatives using simulated readers, and an online approach that personalizes reading interfaces in real time using ongoing interaction data. Together, this perspective enables adaptive, explainable, and scalable augmented reading design without relying solely on human testing.","authors":["Yunpeng Bai","Shengdong Zhao","Antti Oulasvirta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.21013v3","updated":"2026-02-26T08:09:24Z","published":"2025-09-25T11:20:38Z","title":"Predicting LLM Reasoning Performance with Small Proxy Model","summary":"Given the prohibitive cost of pre-training large language models, it is essential to leverage smaller proxy models to optimize datasets before scaling up. However, this approach becomes challenging for reasoning capabilities, which exhibit emergent behavior that only appear reliably at larger model sizes, often exceeding 7B parameters. To address this, we introduce rBridge, showing that small proxies ($\\leq$1B) can effectively predict large-model reasoning by aligning more closely with (1) the pre-training objective and (2) the target task. rBridge achieves this by weighting negative log-likelihood with task alignment, using reasoning traces from frontier models as gold labels. In our experiments, rBridge (i) reduces dataset ranking costs by over 100x relative to the best baseline, (ii) achieves the strongest correlation across six reasoning benchmarks at 1B to 32B scale, and (iii) zero-shot transfers predictive relationships across pre-training datasets at 1B to 7B scale. These findings indicate that rBridge offers a practical path for exploring reasoning-oriented pre-training at lower cost.","authors":["Woosung Koh","Juyoung Suk","Sungjun Han","Se-Young Yun","Jamin Shin"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.19241v2","updated":"2026-02-26T08:08:52Z","published":"2026-02-22T15:51:29Z","title":"Scaling Laws for Precision in High-Dimensional Linear Regression","summary":"Low-precision training is critical for optimizing the trade-off between model quality and training costs, necessitating the joint allocation of model size, dataset size, and numerical precision. While empirical scaling laws suggest that quantization impacts effective model and data capacities or acts as an additive error, the theoretical mechanisms governing these effects remain largely unexplored. In this work, we initiate a theoretical study of scaling laws for low-precision training within a high-dimensional sketched linear regression framework. By analyzing multiplicative (signal-dependent) and additive (signal-independent) quantization, we identify a critical dichotomy in their scaling behaviors. Our analysis reveals that while both schemes introduce an additive error and degrade the effective data size, they exhibit distinct effects on effective model size: multiplicative quantization maintains the full-precision model size, whereas additive quantization reduces the effective model size. Numerical experiments validate our theoretical findings. By rigorously characterizing the complex interplay among model scale, dataset size, and quantization error, our work provides a principled theoretical basis for optimizing training protocols under practical hardware constraints.","authors":["Dechen Zhang","Xuan Tang","Yingyu Liang","Difan Zou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.17287v2","updated":"2026-02-26T07:59:21Z","published":"2024-12-23T05:12:54Z","title":"LLM4AD: A Platform for Algorithm Design with Large Language Model","summary":"We introduce LLM4AD, a unified Python platform for algorithm design (AD) with large language models (LLMs). LLM4AD is a generic framework with modularized blocks for search methods, algorithm design tasks, and LLM interface. The platform integrates numerous key methods and supports a wide range of algorithm design tasks across various domains including optimization, machine learning, and scientific discovery. We have also designed a unified evaluation sandbox to ensure a secure and robust assessment of algorithms. Additionally, we have compiled a comprehensive suite of support resources, including tutorials, examples, a user manual, online resources, and a dedicated graphical user interface (GUI) to enhance the usage of LLM4AD. We believe this platform will serve as a valuable tool for fostering future development in the merging research direction of LLM-assisted algorithm design.","authors":["Fei Liu","Rui Zhang","Zhuoliang Xie","Rui Sun","Kai Li","Qinglong Hu","Ping Guo","Xi Lin","Xialiang Tong","Mingxuan Yuan","Zhenkun Wang","Zhichao Lu","Qingfu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22724v1","updated":"2026-02-26T07:59:10Z","published":"2026-02-26T07:59:10Z","title":"AgentSentry: Mitigating Indirect Prompt Injection in LLM Agents via Temporal Causal Diagnostics and Context Purification","summary":"Large language model (LLM) agents increasingly rely on external tools and retrieval systems to autonomously complete complex tasks. However, this design exposes agents to indirect prompt injection (IPI), where attacker-controlled context embedded in tool outputs or retrieved content silently steers agent actions away from user intent. Unlike prompt-based attacks, IPI unfolds over multi-turn trajectories, making malicious control difficult to disentangle from legitimate task execution. Existing inference-time defenses primarily rely on heuristic detection and conservative blocking of high-risk actions, which can prematurely terminate workflows or broadly suppress tool usage under ambiguous multi-turn scenarios. We propose AgentSentry, a novel inference-time detection and mitigation framework for tool-augmented LLM agents. To the best of our knowledge, AgentSentry is the first inference-time defense to model multi-turn IPI as a temporal causal takeover. It localizes takeover points via controlled counterfactual re-executions at tool-return boundaries and enables safe continuation through causally guided context purification that removes attack-induced deviations while preserving task-relevant evidence. We evaluate AgentSentry on the \\textsc{AgentDojo} benchmark across four task suites, three IPI attack families, and multiple black-box LLMs. AgentSentry eliminates successful attacks and maintains strong utility under attack, achieving an average Utility Under Attack (UA) of 74.55 %, improving UA by 20.8 to 33.6 percentage points over the strongest baselines without degrading benign performance.","authors":["Tian Zhang","Yiwei Xu","Juan Wang","Keyan Guo","Xiaoyang Xu","Bowen Xiao","Quanlong Guan","Jinlin Fan","Jiawei Liu","Zhiquan Liu","Hongxin Hu"],"pdf_url":"","comment":"23 pages, 8 figures. Under review"},{"id":"http://arxiv.org/abs/2602.22718v1","updated":"2026-02-26T07:45:37Z","published":"2026-02-26T07:45:37Z","title":"RLHFless: Serverless Computing for Efficient RLHF","summary":"Reinforcement Learning from Human Feedback (RLHF) has been widely applied to Large Language Model (LLM) post-training to align model outputs with human preferences. Recent models, such as DeepSeek-R1, have also shown RLHF's potential to improve LLM reasoning on complex tasks. In RL, inference and training co-exist, creating dynamic resource demands throughout the workflow. Compared to traditional RL, RLHF further challenges training efficiency due to expanding model sizes and resource consumption. Several RLHF frameworks aim to balance flexible abstraction and efficient execution. However, they rely on serverful infrastructures, which struggle with fine-grained resource variability. As a result, during synchronous RLHF training, idle time between or within RL components often causes overhead and resource wastage.\n  To address these issues, we present RLHFless, the first scalable training framework for synchronous RLHF, built on serverless computing environments. RLHFless adapts to dynamic resource demands throughout the RLHF pipeline, pre-computes shared prefixes to avoid repeated computation, and uses a cost-aware actor scaling strategy that accounts for response length variation to find sweet spots with lower cost and higher speed. In addition, RLHFless assigns workloads efficiently to reduce intra-function imbalance and idle time. Experiments on both physical testbeds and a large-scale simulated cluster show that RLHFless achieves up to 1.35x speedup and 44.8% cost reduction compared to the state-of-the-art baseline.","authors":["Rui Wei","Hanfei Yu","Shubham Jain","Yogarajan Sivakumar","Devesh Tiwari","Jian Li","Seung-Jong Park","Hao Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22716v1","updated":"2026-02-26T07:42:15Z","published":"2026-02-26T07:42:15Z","title":"SoPE: Spherical Coordinate-Based Positional Embedding for Enhancing Spatial Perception of 3D LVLMs","summary":"3D Large Vision-Language Models (3D LVLMs) built upon Large Language Models (LLMs) have achieved remarkable progress across various multimodal tasks. However, their inherited position-dependent modeling mechanism, Rotary Position Embedding (RoPE), remains suboptimal for 3D multimodal understanding. The vanilla RoPE formulation fails to preserve essential three-dimensional spatial structures when encoding 3D tokens, and its relative distance computation overlooks angular dependencies, hindering the model's ability to capture directional variations in visual representations. To overcome these limitations, we introduce Spherical Coordinate-based Positional Embedding (SoPE). Our method maps point-cloud token indices into a 3D spherical coordinate space, enabling unified modeling of spatial locations and directional angles. This formulation preserves the inherent geometric structure of point-cloud data, enhances spatial awareness, and yields more consistent and expressive geometric representations for multimodal learning. In addition, we introduce a multi-scale frequency mixing strategy to fuse feature information across different frequency domains. Experimental results on multiple 3D scene benchmarks validate the effectiveness of our approach, while real-world deployment experiments further demonstrate its strong generalization capability.","authors":["Guanting Ye","Qiyan Zhao","Wenhao Yu","Liangyu Yuan","Mingkai Li","Xiaofeng Zhang","Jianmin Ji","Yanyong Zhang","Qing Jiang","Ka-Veng Yuen"],"pdf_url":"","comment":"CVPR 2026"}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2602.23216v1","updated":"2026-02-26T17:00:10Z","published":"2026-02-26T17:00:10Z","title":"Array-Carrying Symbolic Execution for Function Contract Generation","summary":"Function contract generation is a classical problem in program analysis that targets the automated analysis of functions in a program with multiple procedures. The problem is fundamental in inter-procedural analysis where properties of functions are first obtained via the generation of function contracts and then the generated contracts are used as building blocks to analyze the whole program. Typical objectives in function contract generation include pre-/post-conditions and assigns information (that specifies the modification information over program variables and memory segments during function execution). In programs with array manipulations, a crucial point in function contract generation is the treatment of array segments that imposes challenges in inferring invariants and assigns information over such segments. To address this challenge, we propose a novel symbolic execution framework that carries invariants and assigns information over contiguous segments of arrays. We implement our framework as a prototype within LLVM, and further integrate our prototype with the ACSL assertion format and the Frama-C software verification platform. Experimental evaluation over a variety of benchmarks from the literature and functions from realistic libraries shows that our framework is capable of handling array manipulating functions that indeed involve the carry of array information and are beyond existing approaches.","authors":["Weijie Lu","Jingyu Ke","Hongfei Fu","Zhouyue Sun","Yi Zhou","Guoqiang Li","Haokun Li"],"pdf_url":"","comment":"30 pages, 2 figures. To appear in the 27th International Symposium on Formal Methods (FM 2026)"},{"id":"http://arxiv.org/abs/2511.20369v4","updated":"2026-02-26T14:50:58Z","published":"2025-11-25T14:51:05Z","title":"The Ghosts of Empires: Extracting Modularity from Interleaving-Based Proofs (Extended Version)","summary":"Implementation bugs threaten the soundness of algorithmic software verifiers. Generating correctness certificates for correct programs allows for efficient independent validation of verification results, and thus helps to reveal such bugs. Automatic generation of small, compact correctness proofs for concurrent programs is challenging, as the correctness arguments may depend on the particular interleaving, which can lead to exponential explosion. We present an approach that converts an interleaving-based correctness proof, as generated by many algorithmic verifiers, into a thread-modular correctness proof in the style of Owicki and Gries. We automatically synthesize ghost variables that capture the relevant interleaving information, and abstract away irrelevant details. Our evaluation shows that the approach is efficient in practice and generates compact proofs, compared to a baseline.","authors":["Frank Schüssele","Matthias Zumkeller","Miriam Lagunes-Rochin","Dominik Klumpp"],"pdf_url":"","comment":"39 pages, 10 figures, 1 table. Extended version with proofs of the paper published at POPL'2026 (https://doi.org/10.1145/3776684) [corrections in Fig. 6]"},{"id":"http://arxiv.org/abs/2602.16913v2","updated":"2026-02-26T09:39:41Z","published":"2026-02-18T21:59:04Z","title":"A Reversible Semantics for Janus","summary":"Janus is a paradigmatic example of a reversible programming language. Indeed, Janus programs can be executed backwards as well as forwards. However, its current small-step semantics (useful, e.g., for debugging or as a basis for extensions with concurrency primitives) is not reversible, since it loses information while computing forwards. E.g., it does not satisfy the Loop Lemma, stating that any reduction has an inverse, a main property of reversibility in process calculi, where a small-step semantics is commonly used. We present here a novel small-step semantics which is actually reversible, while remaining equivalent to the previous one. It involves the non-trivial challenge of defining a semantics based on a \"program counter\" for a high-level programming language.","authors":["Ivan Lanese","Germán Vidal"],"pdf_url":"","comment":"Submitted for publication"},{"id":"http://arxiv.org/abs/2602.16291v4","updated":"2026-02-26T08:11:19Z","published":"2026-02-18T09:17:20Z","title":"A Calculus of Inheritance","summary":"Just as the $λ$-calculus uses three primitives (abstraction, application, variable) as the foundation of functional programming, inheritance-calculus uses three primitives (record, definition, inheritance) as the foundation of declarative programming. It trivially embeds the $λ$-calculus, although the entire semantics rests solely on naive set theory; as a consequence, all constructs including inheritance are inherently commutative, idempotent, and associative; the linearization problem of multiple inheritance does not arise. This induces a fully abstract semantics of the lazy $λ$-calculus with respect to Böhm tree equivalence~\\cite{barendregt1984lambda}. Inheritance-calculus is distilled from MIXINv2, a practical implementation in which we observed further emergent phenomena: the same code acts as different function colors~\\cite{nystrom2015color}; ordinary arithmetic yields the relational semantics of logic programming~\\cite{vanemden1976semantics}; self-reference resolves to multiple targets; and programs are immune to the Expression Problem~\\cite{wadler1998expression}. This makes inheritance-calculus strictly more expressive than the $λ$-calculus in both common sense and Felleisen's sense~\\cite{felleisen1991expressive}. These properties suggest applications to configuration languages, dependency injection, object-oriented programming, composable effect systems, modular software architectures, file-system-as-compiler, general-purpose programming, and no-code development.","authors":["Bo Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22631v1","updated":"2026-02-26T05:11:44Z","published":"2026-02-26T05:11:44Z","title":"TorchLean: Formalizing Neural Networks in Lean","summary":"Neural networks are increasingly deployed in safety- and mission-critical pipelines, yet many verification and analysis results are produced outside the programming environment that defines and runs the model. This separation creates a semantic gap between the executed network and the analyzed artifact, so guarantees can hinge on implicit conventions such as operator semantics, tensor layouts, preprocessing, and floating-point corner cases. We introduce TorchLean, a framework in the Lean 4 theorem prover that treats learned models as first-class mathematical objects with a single, precise semantics shared by execution and verification. TorchLean unifies (1) a PyTorch-style verified API with eager and compiled modes that lower to a shared op-tagged SSA/DAG computation-graph IR, (2) explicit Float32 semantics via an executable IEEE-754 binary32 kernel and proof-relevant rounding models, and (3) verification via IBP and CROWN/LiRPA-style bound propagation with certificate checking. We validate TorchLean end-to-end on certified robustness, physics-informed residual bounds for PINNs, and Lyapunov-style neural controller verification, alongside mechanized theoretical results including a universal approximation theorem. These results demonstrate a semantics-first infrastructure for fully formal, end-to-end verification of learning-enabled systems.","authors":["Robert Joseph George","Jennifer Cruden","Xiangru Zhong","Huan Zhang","Anima Anandkumar"],"pdf_url":"","comment":"35 pages, multiple figures and tables"},{"id":"http://arxiv.org/abs/2510.10410v3","updated":"2026-02-26T03:53:57Z","published":"2025-10-12T02:11:38Z","title":"A Trace-based Approach for Code Safety Analysis","summary":"Rust is a memory-safe programming language that disallows undefined behavior. Its safety guarantees have been extensively examined by the community through empirical studies, which has led to its remarkable success. However, unsafe code remains a critical concern in Rust. By reviewing the safety design of Rust and analyzing real-world Rust projects, this paper establishes a systematic framework for understanding unsafe code and undefined behavior, and summarizes the soundness criteria for Rust code. It further derives actionable guidance for achieving sound encapsulation.","authors":["Hui Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23520v1","updated":"2026-02-26T21:47:11Z","published":"2026-02-26T21:47:11Z","title":"Zero-Incoherence Capacity of Interactive Encoding Systems: Achievability, Converse, and Side Information Bounds","summary":"We introduce the zero-incoherence capacity for interactive multi-location encoding systems: the maximum encoding rate that guarantees exactly zero probability of disagreement among replicated encodings. Our main information-theoretic results are compact and self-contained: an exact capacity theorem ($C_0=1$), a tight side-information lower bound for resolution ($\\geq\\log_2 k$ bits for $k$-way incoherence), and a rate--complexity separation (modification cost $O(1)$ at capacity vs $Ω(n)$ above).\n  The paper frames encoding locations as terminals in a multi-terminal source-coding model. Derivation (automatic deterministic dependence) is interpreted as perfect correlation that reduces effective rate; only complete derivation (one independent source) achieves zero incoherence. We give concise achievability and converse proofs in IT style, formalize the confusability/incoherence graph connection, and present an explicit mutual-information argument for the side-information bound.\n  Theoretical contributions are supplemented by constructive instantiations (programming-language patterns and a software case study). For TIT submission we move detailed language evaluation, extended code examples, and the full Lean proof corpus to supplementary material; the main text contains brief instantiations only. Core theorems (capacity, realizability, bounds) are machine-checked in Lean 4; entropy arguments apply standard Fano-inequality techniques.","authors":["Tristan Simas"],"pdf_url":"","comment":"Lean 4 artifact: 3378 lines, 176 theorems/lemmas across 24 files (0 sorry placeholders). Full formalization available at https://doi.org/10.5281/zenodo.18141365"}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.23331v1","updated":"2026-02-26T18:38:00Z","published":"2026-02-26T18:38:00Z","title":"Utilizing LLMs for Industrial Process Automation","summary":"A growing number of publications address the best practices to use Large Language Models (LLMs) for software engineering in recent years. However, most of this work focuses on widely-used general purpose programming languages like Python due to their widespread usage training data. The utility of LLMs for software within the industrial process automation domain, with highly-specialized languages that are typically only used in proprietary contexts, remains underexplored. This research aims to utilize and integrate LLMs in the industrial development process, solving real-life programming tasks (e.g., generating a movement routine for a robotic arm) and accelerating the development cycles of manufacturing systems.","authors":["Salim Fares"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.08788v6","updated":"2026-02-26T18:37:22Z","published":"2024-05-14T17:37:01Z","title":"Using weakest application conditions to rank graph transformations for graph repair","summary":"When using graphs and graph transformations to model systems, consistency is an important concern. While consistency has primarily been viewed as a binary property, i.e., a graph is consistent or inconsistent with respect to a set of constraints, recent work has presented an approach to consistency as a graduated property. This allows living with inconsistencies for a while and repairing them when necessary. For repairing inconsistencies in a graph, we use graph transformation rules with so-called {\\em impairment-indicating and repair-indicating application conditions} to understand how much repair gain certain rule applications would bring. Both types of conditions can be derived from given graph constraints. Our main theorem shows that the difference between the number of actual constraint violations before and after a graph transformation step can be characterised by the difference between the numbers of violated impairment-indicating and repair-indicating application conditions. This theory forms the basis for algorithms with look-ahead that rank graph transformations according to their potential for graph repair. An evaluation shows that graph repair can be well-supported by rules with these new types of application conditions in terms of effectiveness and scalability.","authors":["Lars Fritsche","Alexander Lauer","Maximilian Kratz","Andy Schürr","Gabriele Taentzer"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.03495v2","updated":"2026-02-26T18:01:35Z","published":"2025-10-03T20:18:58Z","title":"AgentHub: A Registry for Discoverable, Verifiable, and Reproducible AI Agents","summary":"LLM-based agents are rapidly proliferating, yet the infrastructure for discovering, evaluating, and governing them remains fragmented compared to mature ecosystems like software package registries (e.g., npm) and model hubs (e.g., Hugging Face). Existing efforts typically address naming, distribution, or protocol descriptors, but stop short of providing a registry layer that makes agents discoverable, comparable, and governable under automated reuse. We present AgentHub, a registry layer and accompanying research agenda for agent sharing that targets discovery and workflow integration, trust and security, openness and governance, ecosystem interoperability, lifecycle transparency, and capability clarity with evidence. We describe a reference prototype that implements a canonical manifest with publish-time validation, version-bound evidence records linked to auditable artifacts, and an append-only lifecycle event log whose states are respected by default in search and resolution. We also provide initial discovery results using an LLM-as-judge recommendation pipeline, showing how structured contracts and evidence improve intent-accurate retrieval beyond keyword-driven discovery. AgentHub aims to provide a common substrate for building reliable, reusable agent ecosystems.","authors":["Erik Pautsch","Tanmay Singla","Parv Kumar","Wenxin Jiang","Huiyun Peng","Behnaz Hassanshahi","Konstantin Läufer","George K. Thiruvathukal","James C. Davis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23216v1","updated":"2026-02-26T17:00:10Z","published":"2026-02-26T17:00:10Z","title":"Array-Carrying Symbolic Execution for Function Contract Generation","summary":"Function contract generation is a classical problem in program analysis that targets the automated analysis of functions in a program with multiple procedures. The problem is fundamental in inter-procedural analysis where properties of functions are first obtained via the generation of function contracts and then the generated contracts are used as building blocks to analyze the whole program. Typical objectives in function contract generation include pre-/post-conditions and assigns information (that specifies the modification information over program variables and memory segments during function execution). In programs with array manipulations, a crucial point in function contract generation is the treatment of array segments that imposes challenges in inferring invariants and assigns information over such segments. To address this challenge, we propose a novel symbolic execution framework that carries invariants and assigns information over contiguous segments of arrays. We implement our framework as a prototype within LLVM, and further integrate our prototype with the ACSL assertion format and the Frama-C software verification platform. Experimental evaluation over a variety of benchmarks from the literature and functions from realistic libraries shows that our framework is capable of handling array manipulating functions that indeed involve the carry of array information and are beyond existing approaches.","authors":["Weijie Lu","Jingyu Ke","Hongfei Fu","Zhouyue Sun","Yi Zhou","Guoqiang Li","Haokun Li"],"pdf_url":"","comment":"30 pages, 2 figures. To appear in the 27th International Symposium on Formal Methods (FM 2026)"},{"id":"http://arxiv.org/abs/2508.12436v3","updated":"2026-02-26T16:34:12Z","published":"2025-08-17T17:09:16Z","title":"Feature Request Analysis and Processing: Tasks, Techniques, and Trends","summary":"Feature requests are proposed by users to request new features or enhancements of existing features of software products, which represent users' wishes and demands. Satisfying users' demands can benefit the product from both competitiveness and user satisfaction. Feature requests have seen a rise in interest in the past few years and the amount of research has been growing. However, the diversity in the research topics suggests the need for their collective analysis to identify the challenges and opportunities so as to promote new advances in the future. In this work, following a defined process and a search protocol, we provide a systematic overview of the research area by searching and categorizing relevant studies. We select and analyze 131 primary studies using descriptive statistics and qualitative analysis methods. We classify the studies into different topics and group them from the perspective of requirements engineering activities. We investigate open tools as well as datasets for future research. In addition, we identify several key challenges and opportunities, such as: (1) ensuring the quality of feature requests, (2) improving their specification and validation, and (3) developing high-quality benchmarks for large language model-driven tasks.","authors":["Feifei Niu","Chuanyi Li","Haosheng Zuo","Jionghan Wu","Xin Xia"],"pdf_url":"","comment":"Accepted to: ACM Transactions on Software Engineering and Methodology"},{"id":"http://arxiv.org/abs/2509.20308v2","updated":"2026-02-26T14:54:11Z","published":"2025-09-24T16:41:04Z","title":"Language-Based Protocol Testing","summary":"Over the past decade, the automated generation of test inputs has made significant advances. Modern fuzzers and test generators easily produce complex input formats that do systematically cover the input and execution space. Testing _protocols_, though, has remained a frontier for automated testing, as a test generator has to _interact_ with the program under test, producing messages that conform to the current state of the system.\n  In this paper, we introduce _language-based protocol testing_, the first approach to specify, automatically test, and systematically cover the full state and input space of protocol implementations. We specify protocols as _interaction grammars_ -- an extension of context-free grammars that tag each message element with the communication party that is in charge of producing it. Interaction grammars embed classical state models by unifying states, messages, and transitions all into nonterminals, and can be used for _producing_ interactions as well as _parsing_ them, making them ideally suited for testing protocols. Additional _constraints_ over grammar elements allow us to specify and test _semantic features_ such as binary message formats, checksums, encodings, and the many ways that message features induce states and vice versa.\n  To evaluate the effectiveness of language-based protocol testing, we have implemented it as part of the FANDANGO test generator. We specify several protocols as interaction grammars, including features such as human-readable interactions (SMTP), bit-level encodings (DNS), and dynamic port assignments (FTP), and use them to test the corresponding protocol implementations. By systematically covering the interaction grammar and solving the associated constraints, FANDANGO achieves comprehensive coverage of the protocol interactions, resulting in high code coverage and a thorough assessment of the program under test.","authors":["Alexander Liggesmeyer","José Antonio Zamudio Amaya","Andreas Zeller"],"pdf_url":"","comment":"30 pages"},{"id":"http://arxiv.org/abs/2602.23065v1","updated":"2026-02-26T14:53:26Z","published":"2026-02-26T14:53:26Z","title":"LLM-Powered Silent Bug Fuzzing in Deep Learning Libraries via Versatile and Controlled Bug Transfer","summary":"Deep learning (DL) libraries are widely used in critical applications, where even subtle silent bugs can lead to serious consequences. While existing DL fuzzing techniques have made progress in detecting crashes, they inherently struggle to detect silent bugs due to the lack of effective test programs and corresponding oracles.\n  Building on the observation that historical bug reports contain rich, underutilized information about silent bugs, we leverage large language models (LLMs) to perform versatile yet controlled bug transfer for silent bug fuzzing. Specifically, our approach uses LLMs to extract context-aware bug patterns from historical issues, match semantically related Application Programming Interfaces (APIs) using functionality-based embeddings, and synthesize test cases with customized oracles. This enables proactive detection of silent bugs by transferring high-risk contexts and oracle designs from known buggy APIs to functionally similar target APIs. To ensure the reliability of our context-aware bug transfer, we introduce an LLM-powered self-validation module that systematically evaluates the validity of each transferred bug instance. We implement this methodology in a tool named TransFuzz and evaluate it on three mainstream DL libraries: PyTorch, TensorFlow, and MindSpore. TransFuzz successfully discovers 79 previously unknown bugs (12 confirmed as Common Vulnerabilities and Exposures (CVEs)) in 10 bug types, demonstrating its effectiveness and generalizability in migrating DL library bug discovery capabilities.","authors":["Kunpeng Zhang","Dongwei Xiao","Daoyuan Wu","Jiali Zhao","Yuanyi Lin","Tongtong Xu","Shaohua Wang","Shuai Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2504.06939v2","updated":"2026-02-26T14:41:15Z","published":"2025-04-09T14:43:08Z","title":"FeedbackEval: A Benchmark for Evaluating Large Language Models in Feedback-Driven Code Repair Tasks","summary":"Code repair is a fundamental task in software development, facilitating efficient bug resolution and software maintenance. Although large language models (LLMs) have demonstrated considerable potential in automated code repair, their ability to comprehend and leverage diverse types of feedback, which is crucial for iterative self-correction in authentic debugging scenarios, remains insufficiently understood.\n  To bridge this gap, we introduce FeedbackEval, a systematic benchmark constructed from three heterogeneous sources (HumanEval, CoderEval, and SWE-Bench-verified), to evaluate LLMs' feedback comprehension and code repair performance. We conduct a comprehensive empirical study on five state-of-the-art LLMs, including GPT-4o, Claude-3.5, Deepseek-R1, GLM-4, and Qwen2.5, to evaluate their behavior under both single-iteration and iterative code repair settings. Our results show that mixed feedback yields the highest repair success (63.6%), with LLM-Expert and test feedback providing strong targeted gains (62.9% and 57.9%, respectively), while minimal (53.1%) and compiler feedback (49.2%) offer moderate benefits and LLM-Skilled proves least effective (48.8%). Iterative feedback further enhances repair performance, though the marginal benefit diminishes after two or three iterations. Moreover, prompt structure is shown to be critical: structured reasoning (RR, CoT) and dynamic example selection deliver notable improvements, whereas removing semantic cues such as docstrings or role-play causes severe degradation. This work introduces a robust benchmark and delivers practical insights to advance the understanding and development of feedback-driven code repair using LLMs.","authors":["Dekun Dai","MingWei Liu","Anji Li","Jialun Cao","Yanlin Wang","Chong Wang","Xin Peng","Zibin Zheng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23047v1","updated":"2026-02-26T14:28:57Z","published":"2026-02-26T14:28:57Z","title":"CL4SE: A Context Learning Benchmark For Software Engineering Tasks","summary":"Context engineering has emerged as a pivotal paradigm for unlocking the potential of Large Language Models (LLMs) in Software Engineering (SE) tasks, enabling performance gains at test time without model fine-tuning. Despite its success, existing research lacks a systematic taxonomy of SE-specific context types and a dedicated benchmark to quantify the heterogeneous effects of different contexts across core SE workflows. To address this gap, we propose CL4SE (Context Learning for Software Engineering), a comprehensive benchmark featuring a fine-grained taxonomy of four SE-oriented context types (interpretable examples, project-specific context, procedural decision-making context, and positive & negative context), each mapped to a representative task (code generation, code summarization, code review, and patch correctness assessment). We construct high-quality datasets comprising over 13,000 samples from more than 30 open-source projects and evaluate five mainstream LLMs across nine metrics. Extensive experiments demonstrate that context learning yields an average performance improvement of 24.7% across all tasks. Specifically, procedural context boosts code review performance by up to 33% (Qwen3-Max), mixed positive-negative context improves patch assessment by 30% (DeepSeek-V3), project-specific context increases code summarization BLEU by 14.78% (GPT-Oss-120B), and interpretable examples enhance code generation PASS@1 by 5.72% (DeepSeek-V3). CL4SE establishes the first standardized evaluation framework for SE context learning, provides actionable empirical insights into task-specific context design, and releases a large-scale dataset to facilitate reproducible research in this domain.","authors":["Haichuan Hu","Ye Shang","Guoqing Xie","Congqing He","Quanjun Zhang"],"pdf_url":"","comment":"23 pages, 4 figures"},{"id":"http://arxiv.org/abs/2602.23005v1","updated":"2026-02-26T13:49:16Z","published":"2026-02-26T13:49:16Z","title":"Managing Uncertainty in LLM-based Multi-Agent System Operation","summary":"Applying LLM-based multi-agent software systems in safety-critical domains such as lifespan echocardiography introduces system-level risks that cannot be addressed by improving model accuracy alone. During system operation, beyond individual LLM behavior, uncertainty propagates through agent coordination, data pipelines, human-in-the-loop interaction, and runtime control logic. Yet existing work largely treats uncertainty at the model level rather than as a first-class software engineering concern. This paper approaches uncertainty from both system-level and runtime perspectives. We first differentiate epistemological and ontological uncertainties in the context of LLM-based multi-agent software system operation. Building on this foundation, we propose a lifecycle-based uncertainty management framework comprising four mechanisms: representation, identification, evolution, and adaptation. The uncertainty lifecycle governs how uncertainties emerge, transform, and are mitigated across architectural layers and execution phases, enabling structured runtime governance and controlled adaptation. We demonstrate the feasibility of the framework using a real-world LLM-based multi-agent echocardiographic software system developed in clinical collaboration, showing improved reliability and diagnosability in diagnostic reasoning. The proposed approach generalizes to other safety-critical LLM-based multi-agent software systems, supporting principled operational control and runtime assurance beyond model-centric methods.","authors":["Man Zhang","Tao Yue","Yihua He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.00788v3","updated":"2026-02-26T12:25:31Z","published":"2025-07-01T14:24:37Z","title":"Echoes of AI: Investigating the Downstream Effects of AI Assistants on Software Maintainability","summary":"[Context] AI assistants, like GitHub Copilot and Cursor, are transforming software engineering. While several studies highlight productivity improvements, their impact on maintainability requires further investigation. [Objective] This study investigates whether co-development with AI assistants affects software maintainability, specifically how easily other developers can evolve the resulting source code. [Method] We conducted a two-phase controlled experiment involving 151 participants, 95% of whom were professional developers. In Phase 1, participants added a new feature to a Java web application, with or without AI assistance. In Phase 2, a randomized controlled trial, new participants evolved these solutions without AI assistance. [Results] Phase 2 revealed no significant differences in subsequent evolution with respect to completion time or code quality. Bayesian analysis suggests that any speed or quality improvements from AI use were at most small and highly uncertain. Observational results from Phase 1 corroborate prior research: using an AI assistant yielded a 30.7% median reduction in completion time, and habitual AI users showed an estimated 55.9% speedup. [Conclusions] Overall, we did not detect systematic maintainability advantages or disadvantages when other developers evolved code co-developed with AI assistants. Within the scope of our tasks and measures, we observed no consistent warning signs of degraded code-level maintainability. Future work should examine risks such as code bloat from excessive code generation and cognitive debt as developers offload more mental effort to assistants.","authors":["Markus Borg","Dave Hewett","Nadim Hagatulah","Noric Couderc","Emma Söderberg","Donald Graham","Uttam Kini","Dave Farley"],"pdf_url":"","comment":"Preprint of study preregistered at ICSME 2025 with In-Principal Acceptance. https://conf.researchr.org/track/icsme-2024/icsme-2024-registered-reports-track"},{"id":"http://arxiv.org/abs/2512.14990v3","updated":"2026-02-26T12:19:29Z","published":"2025-12-17T00:50:58Z","title":"Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent","summary":"Despite their wide adoption in various domains (e.g., healthcare, finance, software engineering), Deep Learning (DL)-based applications suffer from many bugs, failures, and vulnerabilities. Reproducing these bugs is essential for their resolution, but it is extremely challenging due to the inherent nondeterminism of DL models and their tight coupling with hardware and software environments. According to recent studies, only about 3% of DL bugs can be reliably reproduced using manual approaches. To address these challenges, we present RepGen, a novel, automated, and intelligent approach for reproducing deep learning bugs. RepGen constructs a learning-enhanced context from a project, develops a comprehensive plan for bug reproduction, employs an iterative generate-validate-refine mechanism, and thus generates such code using an LLM that reproduces the bug at hand. We evaluate RepGen on 106 real-world deep learning bugs and achieve a reproduction rate of 80.19%, a 19.81% improvement over the state-of-the-art measure. A developer study involving 27 participants shows that RepGen improves the success rate of DL bug reproduction by 23.35%, reduces the time to reproduce by 56.8%, and lowers participants' cognitive load.","authors":["Mehil B Shah","Mohammad Masudur Rahman","Foutse Khomh"],"pdf_url":"","comment":"Accepted by the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026)"},{"id":"http://arxiv.org/abs/2602.14337v2","updated":"2026-02-26T11:54:11Z","published":"2026-02-15T23:12:57Z","title":"LongCLI-Bench: A Preliminary Benchmark and Study for Long-horizon Agentic Programming in Command-Line Interfaces","summary":"Recent advances in AI-assisted programming have empowered agents to execute complex workflows via command-line interfaces, however, existing benchmarks are limited by short task horizons, data contamination from GitHub scraping, and a lack of fine-grained evaluation metrics, fail to rigorously evaluate the long-horizon planning and execution capabilities essential for realistic software engineering. To address these gaps, we introduce LongCLI-Bench, a comprehensive benchmark designed to evaluate agentic capabilities across long-horizon, realistic tasks. We curated 20 high-quality, long-horizon tasks from over 1,000 computer science assignments and real-world workflows, covering four engineering categories: from scratch, feature addition, bug fixing, and refactoring. We propose a dual-set testing protocol for LongCLI-Bench, which measures requirement fulfillment (fail-to-pass) and regression avoidance (pass-to-pass), and incorporates step-level scoring to pinpoint execution failures. Extensive experiments reveal that even state-of-the-art agents achieve pass rates below 20% in LongCLI-Bench. Step-level analysis further indicates that the majority of tasks stall at less than 30% completion, highlighting that critical failures often occur in the early stages. Although self-correction offers marginal gains, human-agent collaboration through plan injection and interactive guidance yields significantly higher improvements. These results highlight that future research must emphasize the development of synergistic human-agent workflows alongside advances in agents' planning and execution capabilities to overcome key challenges in long-horizon task performance.","authors":["Yukang Feng","Jianwen Sun","Zelai Yang","Jiaxin Ai","Chuanhao Li","Zizhen Li","Fanrui Zhang","Kang He","Rui Ma","Jifan Lin","Jie Sun","Yang Xiao","Sizhuo Zhou","Wenxiao Wu","Yiming Liu","Pengfei Liu","Yu Qiao","Shenglin Zhang","Kaipeng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22835v1","updated":"2026-02-26T10:22:25Z","published":"2026-02-26T10:22:25Z","title":"Productivity and Collaboration in Hybrid Agile Teams: An Interview Study","summary":"Hybrid work has become a reality post-pandemic, transforming how Agile teams deliver value, collaborate, and adapt. This study investigate how hybrid settings influence productivity and collaboration through nine interviews with three Norwegian Agile teams. Our findings show that hybrid work reduces informal interaction, creates uneven participation, and increases reliance on digital tools. Agile ceremonies became alignment anchors, while trust, communication, and tool support mediate team effectiveness. Hybrid Agile work is an evolving field that requires tailored structures to support inclusion, team cohesion, and sustainable performance.","authors":["Elisabeth Mo","Jefferson Seide Molléri","Asle Fagerstrøm"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22764v1","updated":"2026-02-26T08:54:09Z","published":"2026-02-26T08:54:09Z","title":"Evaluating and Improving Automated Repository-Level Rust Issue Resolution with LLM-based Agents","summary":"The Rust programming language presents a steep learning curve and significant coding challenges, making the automation of issue resolution essential for its broader adoption. Recently, LLM-powered code agents have shown remarkable success in resolving complex software engineering tasks, yet their application to Rust has been limited by the absence of a large-scale, repository-level benchmark. To bridge this gap, we introduce Rust-SWE-bench, a benchmark comprising 500 real-world, repository-level software engineering tasks from 34 diverse and popular Rust repositories. We then perform a comprehensive study on Rust-SWE-bench with four representative agents and four state-of-the-art LLMs to establish a foundational understanding of their capabilities and limitations in the Rust ecosystem. Our extensive study reveals that while ReAct-style agents are promising, i.e., resolving up to 21.2% of issues, they are limited by two primary challenges: comprehending repository-wide code structure and complying with Rust's strict type and trait semantics. We also find that issue reproduction is rather critical for task resolution. Inspired by these findings, we propose RUSTFORGER, a novel agentic approach that integrates an automated test environment setup with a Rust metaprogramming-driven dynamic tracing strategy to facilitate reliable issue reproduction and dynamic analysis. The evaluation shows that RUSTFORGER using Claude-Sonnet-3.7 significantly outperforms all baselines, resolving 28.6% of tasks on Rust-SWE-bench, i.e., a 34.9% improvement over the strongest baseline, and, in aggregate, uniquely solves 46 tasks that no other agent could solve across all adopted advanced LLMs.","authors":["Jiahong Xiang","Wenxiao He","Xihua Wang","Hongliang Tian","Yuqun Zhang"],"pdf_url":"","comment":"Accepted to the 48th International Conference on Software Engineering (ICSE 2026)"},{"id":"http://arxiv.org/abs/2602.22729v1","updated":"2026-02-26T08:11:38Z","published":"2026-02-26T08:11:38Z","title":"RandSet: Randomized Corpus Reduction for Fuzzing Seed Scheduling","summary":"Seed explosion is a fundamental problem in fuzzing seed scheduling, where a fuzzer maintains a huge corpus and fails to choose promising seeds. Existing works focus on seed prioritization but still suffer from seed explosion since corpus size remains huge. We tackle this from a new perspective: corpus reduction, i.e., computing a seed corpus subset. However, corpus reduction could lead to poor seed diversity and large runtime overhead. Prior techniques like cull_queue, AFL-Cmin, and MinSet suffer from poor diversity or prohibitive overhead, making them unsuitable for high-frequency seed scheduling.\n  We propose RandSet, a novel randomized corpus reduction technique that reduces corpus size and yields diverse seed selection simultaneously with minimal overhead. Our key insight is introducing randomness into corpus reduction to enjoy two benefits of a randomized algorithm: randomized output (diverse seed selection) and low runtime cost. Specifically, we formulate corpus reduction as a set cover problem and compute a randomized subset covering all features of the entire corpus. We then schedule seeds from this small, randomized subset rather than the entire corpus, effectively mitigating seed explosion.\n  We implement RandSet on three popular fuzzers: AFL++, LibAFL, and Centipede, and evaluate it on standalone programs, FuzzBench, and Magma. Results show RandSet achieves significantly more diverse seed selection than other reduction techniques, with average subset ratios of 4.03% and 5.99% on standalone and FuzzBench programs. RandSet achieves a 16.58% coverage gain on standalone programs and up to 3.57% on FuzzBench in AFL++, triggers up to 7 more ground-truth bugs than the state-of-the-art on Magma, while introducing only 1.17%-3.93% overhead.","authors":["Yuchong Xie","Kaikai Zhang","Yu Liu","Rundong Yang","Ping Chen","Shuai Wang","Dongdong She"],"pdf_url":"","comment":"To Appear in ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA 2026)"},{"id":"http://arxiv.org/abs/2602.16291v4","updated":"2026-02-26T08:11:19Z","published":"2026-02-18T09:17:20Z","title":"A Calculus of Inheritance","summary":"Just as the $λ$-calculus uses three primitives (abstraction, application, variable) as the foundation of functional programming, inheritance-calculus uses three primitives (record, definition, inheritance) as the foundation of declarative programming. It trivially embeds the $λ$-calculus, although the entire semantics rests solely on naive set theory; as a consequence, all constructs including inheritance are inherently commutative, idempotent, and associative; the linearization problem of multiple inheritance does not arise. This induces a fully abstract semantics of the lazy $λ$-calculus with respect to Böhm tree equivalence~\\cite{barendregt1984lambda}. Inheritance-calculus is distilled from MIXINv2, a practical implementation in which we observed further emergent phenomena: the same code acts as different function colors~\\cite{nystrom2015color}; ordinary arithmetic yields the relational semantics of logic programming~\\cite{vanemden1976semantics}; self-reference resolves to multiple targets; and programs are immune to the Expression Problem~\\cite{wadler1998expression}. This makes inheritance-calculus strictly more expressive than the $λ$-calculus in both common sense and Felleisen's sense~\\cite{felleisen1991expressive}. These properties suggest applications to configuration languages, dependency injection, object-oriented programming, composable effect systems, modular software architectures, file-system-as-compiler, general-purpose programming, and no-code development.","authors":["Bo Yang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21806v2","updated":"2026-02-26T04:30:22Z","published":"2026-02-25T11:34:17Z","title":"An Empirical Study of Bugs in Modern LLM Agent Frameworks","summary":"LLM agents have been widely adopted in real-world applications, relying on agent frameworks for workflow execution and multi-agent coordination. As these systems scale, understanding bugs in the underlying agent frameworks becomes critical. However, existing work mainly focuses on agent-level failures, overlooking framework-level bugs. To address this gap, we conduct an empirical study of 998 bug reports from CrewAI and LangChain, constructing a taxonomy of 15 root causes and 7 observable symptoms across five agent lifecycle stages: 'Agent Initialization','Perception', 'Self-Action', 'Mutual Interaction' and 'Evolution'. Our findings show that agent framework bugs mainly arise from 'API misuse', 'API incompatibility', and 'Documentation Desync', largely concentrated in the 'Self-Action' stage. Symptoms typically appear as 'Functional Error', 'Crash', and 'Build Failure', reflecting disruptions to task progression and control flow.","authors":["Xinxue Zhu","Jiacong Wu","Xiaoyu Zhang","Tianlin Li","Yanzhou Mu","Juan Zhai","Chao Shen","Chunrong Fang","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10410v3","updated":"2026-02-26T03:53:57Z","published":"2025-10-12T02:11:38Z","title":"A Trace-based Approach for Code Safety Analysis","summary":"Rust is a memory-safe programming language that disallows undefined behavior. Its safety guarantees have been extensively examined by the community through empirical studies, which has led to its remarkable success. However, unsafe code remains a critical concern in Rust. By reviewing the safety design of Rust and analyzing real-world Rust projects, this paper establishes a systematic framework for understanding unsafe code and undefined behavior, and summarizes the soundness criteria for Rust code. It further derives actionable guidance for achieving sound encapsulation.","authors":["Hui Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22579v1","updated":"2026-02-26T03:32:43Z","published":"2026-02-26T03:32:43Z","title":"Metamorphic Testing of Vision-Language Action-Enabled Robots","summary":"Vision-Language-Action (VLA) models are multimodal robotic task controllers that, given an instruction and visual inputs, produce a sequence of low-level control actions (or motor commands) enabling a robot to execute the requested task in the physical environment. These systems face the test oracle problem from multiple perspectives. On the one hand, a test oracle must be defined for each instruction prompt, which is a complex and non-generalizable approach. On the other hand, current state-of-the-art oracles typically capture symbolic representations of the world (e.g., robot and object states), enabling the correctness evaluation of a task, but fail to assess other critical aspects, such as the quality with which VLA-enabled robots perform a task. In this paper, we explore whether Metamorphic Testing (MT) can alleviate the test oracle problem in this context. To do so, we propose two metamorphic relation patterns and five metamorphic relations to assess whether changes to the test inputs impact the original trajectory of the VLA-enabled robots. An empirical study involving five VLA models, two simulated robots, and four robotic tasks shows that MT can effectively alleviate the test oracle problem by automatically detecting diverse types of failures, including, but not limited to, uncompleted tasks. More importantly, the proposed MRs are generalizable, making the proposed approach applicable across different VLA models, robots, and tasks, even in the absence of test oracles.","authors":["Pablo Valle","Sergio Segura","Shaukat Ali","Aitor Arrieta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.18359v2","updated":"2026-02-26T02:57:52Z","published":"2025-06-23T07:43:21Z","title":"Recipe for Discovery: A Pipeline for Institutional Open Source Activity","summary":"Open source software development, particularly within institutions such as universities and research laboratories, is often decentralized and difficult to track. Although academic teams produce many impactful scientific tools, their projects do not always follow consistent open source practices, such as clear licensing, documentation, or community engagement. As a result, these efforts often go unrecognized due to limited visibility and institutional awareness, and the software itself can be difficult to sustain over time.\n  This paper presents an end-to-end framework for systematically discovering and analyzing open source projects across distributed academic systems. Using ten universities as a case study, we build a pipeline that collects data via GitHub's REST API, extracts metadata, and predicts both institutional affiliation and project type (e.g., development tools, educational materials, websites, documentation). Applied across the ten campuses, our method identifies over 200,000 repositories and collects information on their activity and open source practices, enabling a deeper understanding of institutional open source contributions.\n  Beyond discovery, our framework enables actionable insights into institutional open source practices, revealing patterns such as missing licenses or limited community engagement. These findings can guide targeted support, policy development, and strategies to strengthen open source contributions across academic institutions.","authors":["Juanita Gomez","Emily Lovell","Stephanie Lieggi","Alvaro A. Cardenas","James Davis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22518v1","updated":"2026-02-26T01:25:00Z","published":"2026-02-26T01:25:00Z","title":"RepoMod-Bench: A Benchmark for Code Repository Modernization via Implementation-Agnostic Testing","summary":"The evolution of AI coding agents has shifted the frontier from simple snippet completion to autonomous repository-level engineering. However, evaluating these agents remains ill-posed in general code repository generation, where the lack of deterministic ground truth leads to ambiguous metrics. Code modernization via automated translation offers a more rigorous alternative by providing a fixed ground truth -- the source repository; yet existing benchmarks are limited to small-scale repositories and rely on language-specific unit tests visible to the agent, allowing test-driven overfitting.\n  We address these limitations by introducing a benchmarking framework for repository-level code modernization built on an implementation-agnostic evaluation paradigm. This framework is instantiated through RepoMod-Bench: a benchmark of 21 real-world repositories with standardized interfaces, spanning 8 programming languages. The benchmark contains 1.6M lines of code (LOC) and 11,616 tests, with repository sizes ranging from 14 to 211K LOC. By targeting repositories with standardized interfaces, we utilize an implementation-agnostic test suite to verify functional equivalence between source and target implementations. This black-box approach ensures verification remains consistent across languages, and our environment hides all test suites from agents to prevent test-driven shortcuts. Evaluating four state-of-the-art agent configurations reveals a sharp scaling collapse: average pass rates drop from 91.3% on projects under 10K LOC to 15.3% on projects exceeding 50K LOC. These results demonstrate that autonomous modernization at scale remains a significant open challenge. Our benchmark and code are available at https://github.com/Modelcode-ai/mcode-benchmark.","authors":["Xuefeng Li","Nir Ben-Israel","Yotam Raz","Belal Ahmed","Doron Serebro","Antoine Raux"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22506v1","updated":"2026-02-26T00:53:34Z","published":"2026-02-26T00:53:34Z","title":"static_maps: consteval std::map and std::unordered_map Implementations in C++23","summary":"Using consteval from C++23, we implement efficient, new versions of std::map and std::unordered_map for use when the keys are known at compile time. We demonstrate superior performance of our unordered_map on three demonstration use-cases: Lookup of elemental mass from atomic symbol, lookup of amino acid from codon, and modification of stock prices from S&P 500 ticker symbols all produced runtimes <40%, <35%, <73% of the respective runtimes of the std implementations. Our library runimes were <80%, <45%, <97% of the lookup time of Frozen, an alternative perfect hashing implementation in C++ for problems also using constexpr keys. To our knowledge, this makes our library the overall fastest drop-in (i.e., with a similar API) alternative to std::unordered_map. On one arbitrarily chosen demo, we demonstrate runtimes <35% of PTHash and <89% gperf, state-of-the-art but not drop-in hashing libraries via external tools.","authors":["Isaac D. Myhal","Oliver Serang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23407v1","updated":"2026-02-26T12:57:27Z","published":"2026-02-26T12:57:27Z","title":"Learning to Generate Secure Code via Token-Level Rewards","summary":"Large language models (LLMs) have demonstrated strong capabilities in code generation, yet they remain prone to producing security vulnerabilities. Existing approaches commonly suffer from two key limitations: the scarcity of high-quality security data and coarse-grained reinforcement learning reward signals. To address these challenges, we propose Vul2Safe, a new secure code generation framework that leverages LLM self-reflection to construct high-confidence repair pairs from real-world vulnerabilities, and further generates diverse implicit prompts to build the PrimeVul+ dataset. Meanwhile, we introduce SRCode, a novel training framework that pioneers the use of token-level rewards in reinforcement learning for code security, which enables the model to continuously attend to and reinforce critical fine-grained security patterns during training. Compared with traditional instance-level reward schemes, our approach allows for more precise optimization of local security implementations. Extensive experiments show that PrimeVul+ and SRCode substantially reduce security vulnerabilities in generated code while improving overall code quality across multiple benchmarks.","authors":["Jiazheng Quan","Xiaodong Li","Bin Wang","Guo An","Like Liu","Degen Huang","Lin Liu","Chengbin Hou"],"pdf_url":"","comment":"18 pages, 3 figures"}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2602.23329v1","updated":"2026-02-26T18:37:23Z","published":"2026-02-26T18:37:23Z","title":"LLM Novice Uplift on Dual-Use, In Silico Biology Tasks","summary":"Large language models (LLMs) perform increasingly well on biology benchmarks, but it remains unclear whether they uplift novice users -- i.e., enable humans to perform better than with internet-only resources. This uncertainty is central to understanding both scientific acceleration and dual-use risk. We conducted a multi-model, multi-benchmark human uplift study comparing novices with LLM access versus internet-only access across eight biosecurity-relevant task sets. Participants worked on complex problems with ample time (up to 13 hours for the most involved tasks). We found that LLM access provided substantial uplift: novices with LLMs were 4.16 times more accurate than controls (95% CI [2.63, 6.87]). On four benchmarks with available expert baselines (internet-only), novices with LLMs outperformed experts on three of them. Perhaps surprisingly, standalone LLMs often exceeded LLM-assisted novices, indicating that users were not eliciting the strongest available contributions from the LLMs. Most participants (89.6%) reported little difficulty obtaining dual-use-relevant information despite safeguards. Overall, LLMs substantially uplift novices on biological tasks previously reserved for trained practitioners, underscoring the need for sustained, interactive uplift evaluations alongside traditional benchmarks.","authors":["Chen Bo Calvin Zhang","Christina Q. Knight","Nicholas Kruus","Jason Hausenloy","Pedro Medeiros","Nathaniel Li","Aiden Kim","Yury Orlovskiy","Coleman Breen","Bryce Cai","Jasper Götting","Andrew Bo Liu","Samira Nedungadi","Paula Rodriguez","Yannis Yiming He","Mohamed Shaaban","Zifan Wang","Seth Donoughe","Julian Michael"],"pdf_url":"","comment":"59 pages, 33 figures"},{"id":"http://arxiv.org/abs/2510.10932v2","updated":"2026-02-26T18:32:27Z","published":"2025-10-13T02:45:48Z","title":"DropVLA: An Action-Level Backdoor Attack on Vision--Language--Action Models","summary":"Vision-Language-Action (VLA) models map multimodal perception and language instructions to executable robot actions, making them particularly vulnerable to behavioral backdoor manipulation: a hidden trigger introduced during training can induce unintended physical actions while nominal task performance remains intact. Prior work on VLA backdoors primarily studies untargeted attacks or task-level hijacking, leaving fine-grained control over individual actions largely unexplored. In this work, we present DropVLA, an action-level backdoor attack that forces a reusable action primitive (e.g., open_gripper) to execute at attacker-chosen decision points under a realistic pipeline-black-box setting with limited data-poisoning access, using a window-consistent relabeling scheme for chunked fine-tuning. On OpenVLA-7B evaluated with LIBERO, vision-only poisoning achieves 98.67%-99.83% attack success rate (ASR) with only 0.31% poisoned episodes while preserving 98.50%-99.17% clean-task retention, and successfully triggers the targeted action within 25 control steps at 500 Hz (0.05 s). Text-only triggers are unstable at low poisoning budgets, and combining text with vision provides no consistent ASR improvement over vision-only attacks. The backdoor remains robust to moderate trigger variations and transfers across evaluation suites (96.27%, 99.09%), whereas text-only largely fails (0.72%). We further validate physical-world feasibility on a 7-DoF Franka arm with pi0-fast, demonstrating non-trivial attack efficacy under camera-relative motion that induces image-plane trigger drift. These results reveal that VLA models can be covertly steered at the granularity of safety-critical actions with minimal poisoning and without observable degradation of nominal performance.","authors":["Zonghuan Xu","Xiang Zheng","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"","comment":"8 pages, 6 tables, 3 figures. Under review"},{"id":"http://arxiv.org/abs/2507.16045v2","updated":"2026-02-26T18:26:39Z","published":"2025-07-21T20:21:54Z","title":"Chameleon Channels: Measuring YouTube Accounts Repurposed for Deception and Profit","summary":"Online content creators spend significant time and effort building their user base through a long, often arduous process that requires finding the right \"niche\" to cater to. So, what incentive is there for an established content creator known for cat memes to completely reinvent their channel and start promoting cryptocurrency services or covering electoral news events?\n  We explore this problem of repurposed channels, whereby a channel changes its identity and contents. We first characterize a market for \"second-hand\" social media accounts, which recorded sales exceeding USD 1M during our 6-month observation period. Observing YouTube channels (re)sold over these 6 months, we find that a substantial number (53%) are used to disseminate policy-sensitive content, often without facing any penalty. Surprisingly, these channels seem to gain rather than lose subscribers.\n  We estimate the prevalence of repurposing using two snapshots of ~1.4M YouTube accounts sampled from an ecologically valid proxy. In a 3-month period, we estimate that ~0.25% channels were repurposed. We experimentally confirm that these repurposed channels share several characteristics with sold channels -- mainly, they have a significantly high presence of policy-sensitive content. Across repurposed channels, we find channels similar to those used in influence operations, as well as channels used for financial scams. Repurposed channels have large audiences; across two observed samples, repurposed channels held ~193M and ~44M subscribers. We reason that purchasing an existing audience and the credibility associated with an established account is advantageous to financially- and ideologically-motivated adversaries. This phenomenon is not exclusive to YouTube and we posit that the market for cultivating organic audiences is set to grow, particularly if it remains unchallenged by mitigations, technical or otherwise.","authors":["Alejandro Cuevas","Manoel Horta Ribeiro","Nicolas Christin"],"pdf_url":"","comment":"20 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2511.20505v2","updated":"2026-02-26T18:20:49Z","published":"2025-11-25T17:15:18Z","title":"ACE-GF: A Generative Framework for Atomic Cryptographic Entities","summary":"Autonomous digital entities require deterministic identity mechanisms that avoid persistent storage of high-value master secrets, while supporting credential rotation and cryptographic agility across heterogeneous systems. Existing deterministic key hierarchies and centralized key management systems typically rely on long-lived root secrets, introducing structural single points of failure and complicating lifecycle management.\n  We present ACE-GF (Atomic Cryptographic Entity Generative Framework), a seed-storage-free identity construction that enables deterministic and context-isolated key derivation without storing any master secret at rest. The construction reconstructs an identity root ephemerally in memory from a sealed artifact and authorization credentials, using misuse-resistant authenticated encryption together with standard key derivation primitives. Derived keys are generated via HKDF with explicit context encoding, ensuring cryptographic isolation across curves and application domains.\n  This design naturally supports stateless credential rotation, authorization-bound revocation, and non-disruptive migration toward post-quantum cryptographic domains. Furthermore, the framework's parametric agility allows for optimization in resource-constrained environments, ensuring that deterministic identity reconstruction remains viable across a spectrum of hardware from high-performance servers to low-power IoT nodes without compromising the underlying security model.\n  This work builds upon the conceptual framework introduced in MSCIKDF, which identified the core design goals for multi-curve, context-isolated, PQC-pluggable identity but did not provide a concrete construction. A formal protocol specification of ACE-GF has been submitted as an IETF Internet-Draft.","authors":["Jian Sheng Wang"],"pdf_url":"","comment":"17 pages, 2 figures"},{"id":"http://arxiv.org/abs/2602.23262v1","updated":"2026-02-26T17:36:48Z","published":"2026-02-26T17:36:48Z","title":"Decomposing Private Image Generation via Coarse-to-Fine Wavelet Modeling","summary":"Generative models trained on sensitive image datasets risk memorizing and reproducing individual training examples, making strong privacy guarantees essential. While differential privacy (DP) provides a principled framework for such guarantees, standard DP finetuning (e.g., with DP-SGD) often results in severe degradation of image quality, particularly in high-frequency textures, due to the indiscriminate addition of noise across all model parameters. In this work, we propose a spectral DP framework based on the hypothesis that the most privacy-sensitive portions of an image are often low-frequency components in the wavelet space (e.g., facial features and object shapes) while high-frequency components are largely generic and public. Based on this hypothesis, we propose the following two-stage framework for DP image generation with coarse image intermediaries: (1) DP finetune an autoregressive spectral image tokenizer model on the low-resolution wavelet coefficients of the sensitive images, and (2) perform high-resolution upsampling using a publicly pretrained super-resolution model. By restricting the privacy budget to the global structures of the image in the first stage, and leveraging the post-processing property of DP for detail refinement, we achieve promising trade-offs between privacy and utility. Experiments on the MS-COCO and MM-CelebA-HQ datasets show that our method generates images with improved quality and style capture relative to other leading DP image frameworks.","authors":["Jasmine Bayrooti","Weiwei Kong","Natalia Ponomareva","Carlos Esteves","Ameesh Makadia","Amanda Prorok"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23261v1","updated":"2026-02-26T17:35:53Z","published":"2026-02-26T17:35:53Z","title":"Strengthening security and noise resistance in one-way quantum key distribution protocols through hypercube-based quantum walks","summary":"Quantum Key Distribution (QKD) is a foundational cryptographic protocol that ensures information-theoretic security. However, classical protocols such as BB84, though favored for their simplicity, offer limited resistance to eavesdropping, and perform poorly under realistic noise conditions. Recent research has explored the use of discrete-time Quantum Walks (QWs) to enhance QKD schemes. In this work, we specifically focus on a one-way QKD protocol, where security depends exclusively on the underlying Quantum Walk (QW) topology, rather than the details of the protocol itself. Our paper introduces a novel protocol based on QWs over a hypercube topology and demonstrates that, under identical parameters, it provides significantly enhanced security and noise resistance compared to the circular topology (i.e., state-of-the-art), thereby strengthening protection against eavesdropping. Furthermore, we introduce an efficient and extensible simulation framework for one-way QKD protocols based on QWs, supporting both circular and hypercube topologies. Implemented with IBM's software development kit for quantum computing (i.e., Qiskit), our toolkit enables noise-aware analysis under realistic noise models. To support reproducibility and future developments, we release our entire simulation framework as open-source. This contribution establishes a foundation for the design of topology-aware QKD protocols that combine enhanced noise tolerance with topologically driven security.","authors":["David Polzoni","Tommaso Bianchi","Mauro Conti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.00522v2","updated":"2026-02-26T17:03:49Z","published":"2025-07-01T07:38:22Z","title":"Cyber Attacks Detection, Prevention, and Source Localization in Digital Substation Communication using Hybrid Statistical-Deep Learning","summary":"The digital transformation of power systems is accelerating the adoption of IEC 61850 standard. However, its communication protocols, including Sampled Values (SV), lack built-in security features such as authentication and encryption, making them vulnerable to malicious packet injection. Such cyber attacks can delay fault clearance or trigger unintended circuit breaker operations. While most existing research focuses on detecting cyber attacks in digital substations, intrusion prevention systems have been disregarded because of the risk of potential communication network disruptions. This paper proposes a novel method using hybrid statistical-deep learning for the detection, prevention, and source localization of IEC 61850 SV injection attacks. The method uses exponentially modified Gaussian distributions to model communication network latency and long short-term memory and Elman recurrent neural network to detect anomalous variations in the estimated probability distributions. It effectively discards malicious SV frames with minimal processing overhead and latency, maintains robustness against communication network latency variation and time-synchronization issues, and guarantees a near-zero false positive rate in non-attack scenarios. Comprehensive validation is conducted on three testbeds involving industrial-grade devices, hardware-in-the-loop simulations, virtualized intelligent electronic devices and merging units, and high-fidelity emulated communication networks. Results demonstrate the method's suitability for practical deployment in IEC 61850-compliant digital substations.","authors":["Nicola Cibin","Bas Mulder","Herman Carstens","Peter Palensky","Alexandru Ştefanov"],"pdf_url":"","comment":"11 pages, 7 figures. This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2602.23167v1","updated":"2026-02-26T16:31:23Z","published":"2026-02-26T16:31:23Z","title":"SettleFL: Trustless and Scalable Reward Settlement Protocol for Federated Learning on Permissionless Blockchains (Extended version)","summary":"In open Federated Learning (FL) environments where no central authority exists, ensuring collaboration fairness relies on decentralized reward settlement, yet the prohibitive cost of permissionless blockchains directly clashes with the high-frequency, iterative nature of model training. Existing solutions either compromise decentralization or suffer from scalability bottlenecks due to linear on-chain costs. To address this, we present SettleFL, a trustless and scalable reward settlement protocol designed to minimize total economic friction by offering a family of two interoperable protocols. Leveraging a shared domain-specific circuit architecture, SettleFL offers two interoperable strategies: (1) a Commit-and-Challenge variant that minimizes on-chain costs via optimistic execution and dispute-driven arbitration, and (2) a Commit-with-Proof variant that guarantees instant finality through per-round validity proofs. This design allows the protocol to flexibly adapt to varying latency and cost constraints while enforcing rational robustness without trusted coordination. We conduct extensive experiments combining real FL workloads and controlled simulations. Results show that SettleFL remains practical when scaling to 800 participants, achieving substantially lower gas cost.","authors":["Shuang Liang","Yang Hua","Linshan Jiang","Peishen Yan","Tao Song","Bin Yao","Haibing Guan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23163v1","updated":"2026-02-26T16:27:24Z","published":"2026-02-26T16:27:24Z","title":"A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring","summary":"Large language models are beginning to show steganographic capabilities. Such capabilities could allow misaligned models to evade oversight mechanisms. Yet principled methods to detect and quantify such behaviours are lacking. Classical definitions of steganography, and detection methods based on them, require a known reference distribution of non-steganographic signals. For the case of steganographic reasoning in LLMs, knowing such a reference distribution is not feasible; this renders these approaches inapplicable. We propose an alternative, \\textbf{decision-theoretic view of steganography}. Our central insight is that steganography creates an asymmetry in usable information between agents who can and cannot decode the hidden content (present within a steganographic signal), and this otherwise latent asymmetry can be inferred from the agents' observable actions. To formalise this perspective, we introduce generalised $\\mathcal{V}$-information: a utilitarian framework for measuring the amount of usable information within some input. We use this to define the \\textbf{steganographic gap} -- a measure that quantifies steganography by comparing the downstream utility of the steganographic signal to agents that can and cannot decode the hidden content. We empirically validate our formalism, and show that it can be used to detect, quantify, and mitigate steganographic reasoning in LLMs.","authors":["Usman Anwar","Julianna Piskorz","David D. Baek","David Africa","Jim Weatherall","Max Tegmark","Christian Schroeder de Witt","Mihaela van der Schaar","David Krueger"],"pdf_url":"","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2602.23121v1","updated":"2026-02-26T15:35:17Z","published":"2026-02-26T15:35:17Z","title":"Automated Vulnerability Detection in Source Code Using Deep Representation Learning","summary":"Each year, software vulnerabilities are discovered, which pose significant risks of exploitation and system compromise. We present a convolutional neural network model that can successfully identify bugs in C code. We trained our model using two complementary datasets: a machine-labeled dataset created by Draper Labs using three static analyzers and the NIST SATE Juliet human-labeled dataset designed for testing static analyzers. In contrast with the work of Russell et al. on these datasets, we focus on C programs, enabling us to specialize and optimize our detection techniques for this language. After removing duplicates from the dataset, we tokenize the input into 91 token categories. The category values are converted to a binary vector to save memory. Our first convolution layer is chosen so that the entire encoding of the token is presented to the filter. We use two convolution and pooling layers followed by two fully connected layers to classify programs into either a common weakness enumeration category or as ``clean.'' We obtain higher recall than prior work by Russell et al. on this dataset when requiring high precision. We also demonstrate on a custom Linux kernel dataset that we are able to find real vulnerabilities in complex code with a low false-positive rate.","authors":["C. Seas","G. Fitzpatrick","J. A. Hamilton","M. C. Carlisle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23079v1","updated":"2026-02-26T15:05:13Z","published":"2026-02-26T15:05:13Z","title":"Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent","summary":"The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy that leverages the agent's reasoning trace to generate rewriting prompts, effectively reducing authorship identifiability while preserving textual meaning. Our findings highlight both the deanonymization potential of LLM agents and the importance of interpretable, proactive defenses for safeguarding author privacy.","authors":["Boyang Zhang","Yang Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23067v1","updated":"2026-02-26T14:54:24Z","published":"2026-02-26T14:54:24Z","title":"A High-Throughput AES-GCM Implementation on GPUs for Secure, Policy-Based Access to Massive Astronomical Catalogs","summary":"The era of large astronomical surveys generates massive image catalogs requiring efficient and secure access, particularly during pre-publication periods where data confidentiality and integrity are paramount. While Findable, Accessible, Interoperable, and Reusable (FAIR) principles guide the eventual public dissemination of data, traditional security methods for restricted phases often lack granularity or incur prohibitive performance penalties. To address this, we present a framework that integrates a flexible policy engine for fine-grained access control with a novel GPU-accelerated implementation of the AES-GCM authenticated encryption protocol.\n  The novelty of this work lies in the adaptation and optimization of a parallel tree-reduction strategy to overcome the main performance bottleneck in authenticated encryption on GPUs: the inherently sequential Galois/Counter Mode (GCM) authentication hash (GHASH). We present both the algorithmic adaptation and its efficient execution on GPU architectures. Although similar parallelization techniques have been explored in cryptographic research, this is, to our knowledge, the first demonstration of their integration into a high-throughput encryption framework specifically designed for large-scale astronomical data. Our implementation transforms the sequential GHASH computation into a highly parallelizable, logarithmic-time process, achieving authenticated encryption throughput suitable for petabyte-scale image analysis.\n  Our solution provides a robust mechanism for data providers to enforce access policies, ensuring both confidentiality and integrity without hindering research workflows, thereby facilitating a secure and managed transition of data to public, FAIR archives.","authors":["Samuel Lemes-Perera","Miguel R. Alarcon","Pino Caballero-Gil","Miquel Serra-Ricart"],"pdf_url":"","comment":"Submitted to Astronomy and Computing. 15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2510.07452v2","updated":"2026-02-26T13:37:58Z","published":"2025-10-08T18:58:41Z","title":"PATCH: Mitigating PII Leakage in Language Models with Privacy-Aware Targeted Circuit PatcHing","summary":"Language models (LMs) may memorize personally identifiable information (PII) from training data, enabling adversaries to extract it during inference. Existing defense mechanisms such as differential privacy (DP) reduce this leakage, but incur large drops in utility. Based on a comprehensive study using circuit discovery to identify the computational circuits responsible PII leakage in LMs, we hypothesize that specific PII leakage circuits in LMs should be responsible for this behavior. Therefore, we propose PATCH (Privacy-Aware Targeted Circuit PatcHing), a novel approach that first identifies and subsequently directly edits PII circuits to reduce leakage. PATCH achieves better privacy-utility trade-off than existing defenses, e.g., reducing recall of PII leakage from LMs by up to 65%. Finally, PATCH can be combined with DP to reduce recall of residual leakage of an LM to as low as 0.01%. Our analysis shows that PII leakage circuits persist even after the application of existing defense mechanisms. In contrast, PATCH can effectively mitigate their impact.","authors":["Anthony Hughes","Vasisht Duddu","N. Asokan","Nikolaos Aletras","Ning Ma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22983v1","updated":"2026-02-26T13:25:35Z","published":"2026-02-26T13:25:35Z","title":"Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search","summary":"As Large Language Models (LLMs) are increasingly used, their security risks have drawn increasing attention. Existing research reveals that LLMs are highly susceptible to jailbreak attacks, with effectiveness varying across language contexts. This paper investigates the role of classical Chinese in jailbreak attacks. Owing to its conciseness and obscurity, classical Chinese can partially bypass existing safety constraints, exposing notable vulnerabilities in LLMs. Based on this observation, this paper proposes a framework, CC-BOS, for the automatic generation of classical Chinese adversarial prompts based on multi-dimensional fruit fly optimization, facilitating efficient and automated jailbreak attacks in black-box settings. Prompts are encoded into eight policy dimensions-covering role, behavior, mechanism, metaphor, expression, knowledge, trigger pattern and context; and iteratively refined via smell search, visual search, and cauchy mutation. This design enables efficient exploration of the search space, thereby enhancing the effectiveness of black-box jailbreak attacks. To enhance readability and evaluation accuracy, we further design a classical Chinese to English translation module. Extensive experiments demonstrate that effectiveness of the proposed CC-BOS, consistently outperforming state-of-the-art jailbreak attack methods.","authors":["Xun Huang","Simeng Qin","Xiaoshuang Jia","Ranjie Duan","Huanqian Yan","Zhitao Zeng","Fei Yang","Yang Liu","Xiaojun Jia"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.12108v2","updated":"2026-02-26T12:57:51Z","published":"2025-06-13T09:07:56Z","title":"A Lightweight IDS for Early APT Detection Using a Novel Feature Selection Method","summary":"An Advanced Persistent Threat (APT) is a multistage, highly sophisticated, and covert form of cyber threat that gains unauthorized access to networks to either steal valuable data or disrupt the targeted network. These threats often remain undetected for extended periods, emphasizing the critical need for early detection in networks to mitigate potential APT consequences. In this work, we propose a feature selection method for developing a lightweight intrusion detection system capable of effectively identifying APTs at the initial compromise stage. Our approach leverages the XGBoost algorithm and Explainable Artificial Intelligence (XAI), specifically utilizing the SHAP (SHapley Additive exPlanations) method for identifying the most relevant features of the initial compromise stage. The results of our proposed method showed the ability to reduce the selected features of the SCVIC-APT-2021 dataset from 77 to just four while maintaining consistent evaluation metrics for the suggested system. The estimated metrics values are 97% precision, 100% recall, and a 98% F1 score. The proposed method not only aids in preventing successful APT consequences but also enhances understanding of APT behavior at early stages.","authors":["Bassam Noori Shaker","Bahaa Al-Musawi","Mohammed Falih Hassan"],"pdf_url":"","comment":"After further review, the authors identified issues in the data analysis that require significant correction. Therefore, we request withdrawal of the manuscript"},{"id":"http://arxiv.org/abs/2509.04403v2","updated":"2026-02-26T11:09:21Z","published":"2025-09-04T17:13:59Z","title":"Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios","summary":"Multimodal large language models (MLLMs) are rapidly evolving, presenting increasingly complex safety challenges. However, current dataset construction methods, which are risk-oriented, fail to cover the growing complexity of real-world multimodal safety scenarios (RMS). And due to the lack of a unified evaluation metric, their overall effectiveness remains unproven. This paper introduces a novel image-oriented self-adaptive dataset construction method for RMS, which starts with images and end constructing paired text and guidance responses. Using the image-oriented method, we automatically generate an RMS dataset comprising 35k image-text pairs with guidance responses. Additionally, we introduce a standardized safety dataset evaluation metric: fine-tuning a safety judge model and evaluating its capabilities on other safety datasets.Extensive experiments on various tasks demonstrate the effectiveness of the proposed image-oriented pipeline. The results confirm the scalability and effectiveness of the image-oriented approach, offering a new perspective for the construction of real-world multimodal safety datasets. The dataset is presented at https://huggingface.co/datasets/NewCityLetter/RMS2/tree/main.","authors":["Jingen Qu","Lijun Li","Bo Zhang","Yichen Yan","Jing Shao"],"pdf_url":"","comment":"Accepted at EMNLP 2025 Findings"},{"id":"http://arxiv.org/abs/2512.06660v2","updated":"2026-02-26T10:44:56Z","published":"2025-12-07T05:18:27Z","title":"Towards Small Language Models for Security Query Generation in SOC Workflows","summary":"Analysts in Security Operations Centers routinely query massive telemetry streams using Kusto Query Language (KQL). Writing correct KQL requires specialized expertise, and this dependency creates a bottleneck as security teams scale. This paper investigates whether Small Language Models (SLMs) can enable accurate, cost-effective natural-language-to-KQL translation for enterprise security. We propose a three-knob framework targeting prompting, fine-tuning, and architecture design. First, we adapt existing NL2KQL framework for SLMs with lightweight retrieval and introduce error-aware prompting that addresses common parser failures without increasing token count. Second, we apply LoRA fine-tuning with rationale distillation, augmenting each NLQ-KQL pair with a brief chain-of-thought explanation to transfer reasoning from a teacher model while keeping the SLM compact. Third, we propose a two-stage architecture that uses an SLM for candidate generation and a low-cost LLM judge for schema-aware refinement and selection. We evaluate nine models (five SLMs and four LLMs) across syntax correctness, semantic accuracy, table selection, and filter precision, alongside latency and token cost. On Microsoft's NL2KQL Defender Evaluation dataset, our two-stage approach achieves 0.987 syntax and 0.906 semantic accuracy. We further demonstrate generalizability on Microsoft Sentinel data, reaching 0.964 syntax and 0.831 semantic accuracy. These results come at up to 10x lower token cost than GPT-5, establishing SLMs as a practical, scalable foundation for natural-language querying in security operations.","authors":["Saleha Muzammil","Rahul Reddy","Vishal Kamalakrishnan","Hadi Ahmadi","Wajih Ul Hassan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.10922v3","updated":"2026-02-26T10:05:51Z","published":"2024-10-14T12:08:12Z","title":"Towards Privacy-Guaranteed Label Unlearning in Vertical Federated Learning: Few-Shot Forgetting without Disclosure","summary":"This paper addresses the critical challenge of unlearning in Vertical Federated Learning (VFL), a setting that has received far less attention than its horizontal counterpart. Specifically, we propose the first method tailored to \\textit{label unlearning} in VFL, where labels play a dual role as both essential inputs and sensitive information. To this end, we employ a representation-level manifold mixup mechanism to generate synthetic embeddings for both unlearned and retained samples. This is to provide richer signals for the subsequent gradient-based label forgetting and recovery steps. These augmented embeddings are then subjected to gradient-based label forgetting, effectively removing the associated label information from the model. To recover performance on the retained data, we introduce a recovery-phase optimization step that refines the remaining embeddings. This design achieves effective label unlearning while maintaining computational efficiency. We validate our method through extensive experiments on diverse datasets, including MNIST, CIFAR-10, CIFAR-100, ModelNet, Brain Tumor MRI, COVID-19 Radiography, and Yahoo Answers demonstrate strong efficacy and scalability. Overall, this work establishes a new direction for unlearning in VFL, showing that re-imagining mixup as an efficient mechanism can unlock practical and utility-preserving unlearning. The code is publicly available at \\href{https://github.com/bryanhx/Towards-Privacy-Guaranteed-Label-Unlearning-in-Vertical-Federated-Learning}{https://github.com/bryanhx/Towards-Privacy-Guaranteed-Label-Unlearning-in-Vertical-Federated-Learning}","authors":["Hanlin Gu","Hong Xi Tae","Chee Seng Chan","Lixin Fan"],"pdf_url":"","comment":"We introduce the first method for label unlearning in vertical federated learning (VFL), focused on preventing label leakage by the active party"},{"id":"http://arxiv.org/abs/2506.09950v4","updated":"2026-02-26T09:04:56Z","published":"2025-06-11T17:18:25Z","title":"Oracle-Based Multistep Strategy for Solving Polynomial Systems Over Finite Fields and Algebraic Cryptanalysis of the Aradi Cipher","summary":"The multistep solving strategy consists in a divide-and-conquer approach: when a multivariate polynomial system is computationally infeasible to solve directly, one variable is assigned over the elements of the base finite field, and the procedure is recursively applied to the resulting simplified systems. In a previous work by the same authors (among others), this approach proved effective in the algebraic cryptanalysis of the Trivium cipher. In this paper, we present a new formulation of the corresponding algorithm based on a Depth-First Search strategy, along with a novel complexity analysis leveraging tree structures. We also introduce the notion of an ``oracle function'', which is intended to determine whether evaluating a new variable is required to simplify the current polynomial system. This notion allows us to unify all previously proposed variants of the multistep strategy, including the classical hybrid approach, by appropriately selecting the oracle function. Finally, we employ the multistep solving strategy in the cryptanalysis of the NSA's recently introduced low-latency block cipher Aradi, achieving a first full-round algebraic attack that exposes structural features in its symbolic model.","authors":["Roberto La Scala","Sharwan Kumar Tiwari"],"pdf_url":"","comment":"20 pages. To appear in Advances in Mathematics of Communications"},{"id":"http://arxiv.org/abs/2602.22729v1","updated":"2026-02-26T08:11:38Z","published":"2026-02-26T08:11:38Z","title":"RandSet: Randomized Corpus Reduction for Fuzzing Seed Scheduling","summary":"Seed explosion is a fundamental problem in fuzzing seed scheduling, where a fuzzer maintains a huge corpus and fails to choose promising seeds. Existing works focus on seed prioritization but still suffer from seed explosion since corpus size remains huge. We tackle this from a new perspective: corpus reduction, i.e., computing a seed corpus subset. However, corpus reduction could lead to poor seed diversity and large runtime overhead. Prior techniques like cull_queue, AFL-Cmin, and MinSet suffer from poor diversity or prohibitive overhead, making them unsuitable for high-frequency seed scheduling.\n  We propose RandSet, a novel randomized corpus reduction technique that reduces corpus size and yields diverse seed selection simultaneously with minimal overhead. Our key insight is introducing randomness into corpus reduction to enjoy two benefits of a randomized algorithm: randomized output (diverse seed selection) and low runtime cost. Specifically, we formulate corpus reduction as a set cover problem and compute a randomized subset covering all features of the entire corpus. We then schedule seeds from this small, randomized subset rather than the entire corpus, effectively mitigating seed explosion.\n  We implement RandSet on three popular fuzzers: AFL++, LibAFL, and Centipede, and evaluate it on standalone programs, FuzzBench, and Magma. Results show RandSet achieves significantly more diverse seed selection than other reduction techniques, with average subset ratios of 4.03% and 5.99% on standalone and FuzzBench programs. RandSet achieves a 16.58% coverage gain on standalone programs and up to 3.57% on FuzzBench in AFL++, triggers up to 7 more ground-truth bugs than the state-of-the-art on Magma, while introducing only 1.17%-3.93% overhead.","authors":["Yuchong Xie","Kaikai Zhang","Yu Liu","Rundong Yang","Ping Chen","Shuai Wang","Dongdong She"],"pdf_url":"","comment":"To Appear in ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA 2026)"},{"id":"http://arxiv.org/abs/2602.22724v1","updated":"2026-02-26T07:59:10Z","published":"2026-02-26T07:59:10Z","title":"AgentSentry: Mitigating Indirect Prompt Injection in LLM Agents via Temporal Causal Diagnostics and Context Purification","summary":"Large language model (LLM) agents increasingly rely on external tools and retrieval systems to autonomously complete complex tasks. However, this design exposes agents to indirect prompt injection (IPI), where attacker-controlled context embedded in tool outputs or retrieved content silently steers agent actions away from user intent. Unlike prompt-based attacks, IPI unfolds over multi-turn trajectories, making malicious control difficult to disentangle from legitimate task execution. Existing inference-time defenses primarily rely on heuristic detection and conservative blocking of high-risk actions, which can prematurely terminate workflows or broadly suppress tool usage under ambiguous multi-turn scenarios. We propose AgentSentry, a novel inference-time detection and mitigation framework for tool-augmented LLM agents. To the best of our knowledge, AgentSentry is the first inference-time defense to model multi-turn IPI as a temporal causal takeover. It localizes takeover points via controlled counterfactual re-executions at tool-return boundaries and enables safe continuation through causally guided context purification that removes attack-induced deviations while preserving task-relevant evidence. We evaluate AgentSentry on the \\textsc{AgentDojo} benchmark across four task suites, three IPI attack families, and multiple black-box LLMs. AgentSentry eliminates successful attacks and maintains strong utility under attack, achieving an average Utility Under Attack (UA) of 74.55 %, improving UA by 20.8 to 33.6 percentage points over the strongest baselines without degrading benign performance.","authors":["Tian Zhang","Yiwei Xu","Juan Wang","Keyan Guo","Xiaoyang Xu","Bowen Xiao","Quanlong Guan","Jinlin Fan","Jiawei Liu","Zhiquan Liu","Hongxin Hu"],"pdf_url":"","comment":"23 pages, 8 figures. Under review"},{"id":"http://arxiv.org/abs/2602.22700v1","updated":"2026-02-26T07:21:02Z","published":"2026-02-26T07:21:02Z","title":"IMMACULATE: A Practical LLM Auditing Framework via Verifiable Computation","summary":"Commercial large language models are typically deployed as black-box API services, requiring users to trust providers to execute inference correctly and report token usage honestly. We present IMMACULATE, a practical auditing framework that detects economically motivated deviations-such as model substitution, quantization abuse, and token overbilling-without trusted hardware or access to model internals. IMMACULATE selectively audits a small fraction of requests using verifiable computation, achieving strong detection guarantees while amortizing cryptographic overhead. Experiments on dense and MoE models show that IMMACULATE reliably distinguishes benign and malicious executions with under 1% throughput overhead. Our code is published at https://github.com/guo-yanpei/Immaculate.","authors":["Yanpei Guo","Wenjie Qu","Linyu Wu","Shengfang Zhai","Lionel Z. Wang","Ming Xu","Yue Liu","Binhang Yuan","Dawn Song","Jiaheng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22699v1","updated":"2026-02-26T07:21:00Z","published":"2026-02-26T07:21:00Z","title":"DPSQL+: A Differentially Private SQL Library with a Minimum Frequency Rule","summary":"SQL is the de facto interface for exploratory data analysis; however, releasing exact query results can expose sensitive information through membership or attribute inference attacks. Differential privacy (DP) provides rigorous privacy guarantees, but in practice, DP alone may not satisfy governance requirements such as the \\emph{minimum frequency rule}, which requires each released group (cell) to include contributions from at least $k$ distinct individuals. In this paper, we present \\textbf{DPSQL+}, a privacy-preserving SQL library that simultaneously enforces user-level $(\\varepsilon,δ)$-DP and the minimum frequency rule. DPSQL+ adopts a modular architecture consisting of: (i) a \\emph{Validator} that statically restricts queries to a DP-safe subset of SQL; (ii) an \\emph{Accountant} that consistently tracks cumulative privacy loss across multiple queries; and (iii) a \\emph{Backend} that interfaces with various database engines, ensuring portability and extensibility. Experiments on the TPC-H benchmark demonstrate that DPSQL+ achieves practical accuracy across a wide range of analytical workloads -- from basic aggregates to quadratic statistics and join operations -- and allows substantially more queries under a fixed global privacy budget than prior libraries in our evaluation.","authors":["Tomoya Matsumoto","Shokichi Takakura","Shun Takagi","Satoshi Hasegawa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22689v1","updated":"2026-02-26T07:07:11Z","published":"2026-02-26T07:07:11Z","title":"No Caption, No Problem: Caption-Free Membership Inference via Model-Fitted Embeddings","summary":"Latent diffusion models have achieved remarkable success in high-fidelity text-to-image generation, but their tendency to memorize training data raises critical privacy and intellectual property concerns. Membership inference attacks (MIAs) provide a principled way to audit such memorization by determining whether a given sample was included in training. However, existing approaches assume access to ground-truth captions. This assumption fails in realistic scenarios where only images are available and their textual annotations remain undisclosed, rendering prior methods ineffective when substituted with vision-language model (VLM) captions. In this work, we propose MoFit, a caption-free MIA framework that constructs synthetic conditioning inputs that are explicitly overfitted to the target model's generative manifold. Given a query image, MoFit proceeds in two stages: (i) model-fitted surrogate optimization, where a perturbation applied to the image is optimized to construct a surrogate in regions of the model's unconditional prior learned from member samples, and (ii) surrogate-driven embedding extraction, where a model-fitted embedding is derived from the surrogate and then used as a mismatched condition for the query image. This embedding amplifies conditional loss responses for member samples while leaving hold-outs relatively less affected, thereby enhancing separability in the absence of ground-truth captions. Our comprehensive experiments across multiple datasets and diffusion models demonstrate that MoFit consistently outperforms prior VLM-conditioned baselines and achieves performance competitive with caption-dependent methods.","authors":["Joonsung Jeon","Woo Jae Kim","Suhyeon Ha","Sooel Son","Sung-Eui Yoon"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2502.04758v2","updated":"2026-02-26T07:00:42Z","published":"2025-02-07T08:45:00Z","title":"Differential Privacy of Quantum and Quantum-Inspired Classical Recommendation Algorithms","summary":"We study the differential privacy (DP) of the quantum recommendation algorithm of Kerenidis--Prakash and its quantum-inspired classical counterpart. Under standard low-rank and incoherence assumptions on the preference matrix, we show that the randomness already present in the algorithms' measurement/$\\ell_2$-sampling steps can act as a privacy-curating mechanism, yielding $(\\varepsilon,δ)$-DP without injecting additional DP noise through the interface. Concretely, for a system with $m$ users and $n$ items and rank parameter $k$, we prove $\\varepsilon=\\mathcal O(\\sqrt{k/n})$ and $δ= \\mathcal O\\big(k^2/\\min^2\\{m,n\\}\\big)$; in the typical regime $k=\\mathrm{polylog}(m,n)$ this simplifies to $\\varepsilon=\\tilde{\\mathcal O}(1/\\sqrt n)$ and $δ=\\tilde{\\mathcal O}\\big(1/\\min^2\\{m,n\\}\\big)$. Our analysis introduces a perturbation technique for truncated SVD under a single-entry update, which tracks the induced change in the low-rank reconstruction while avoiding unstable singular-vector comparisons. Finally, we validate the scaling on real-world rating datasets and compare against classical DP recommender baselines.","authors":["Chenjian Li","Mingsheng Ying","Ji Guan"],"pdf_url":"","comment":"18 pages, 3 figures in total(including appendix)"},{"id":"http://arxiv.org/abs/2505.05712v4","updated":"2026-02-26T03:23:21Z","published":"2025-05-09T01:19:01Z","title":"LLM-Text Watermarking based on Lagrange Interpolation","summary":"The rapid advancement of LLMs (Large Language Models) has established them as a foundational technology for many AI and ML-powered human computer interactions. A critical challenge in this context is the attribution of LLM-generated text -- either to the specific language model that produced it or to the individual user who embedded their identity via a so-called multi-bit watermark. This capability is essential for combating misinformation, fake news, misinterpretation, and plagiarism. One of the key techniques for addressing this challenge is digital watermarking.\n  This work presents a watermarking scheme for LLM-generated text based on Lagrange interpolation, enabling the recovery of a multi-bit author identity even when the text has been heavily redacted by an adversary. The core idea is to embed a continuous sequence of points $(x, f(x))$ that lie on a single straight line. The $x$-coordinates are computed pseudorandomly using a cryptographic hash function $H$ applied to the concatenation of the previous token's identity and a secret key $s_k$. Crucially, the $x$-coordinates do not need to be embedded into the text -- only the corresponding $f(x)$ values are embedded. During extraction, the algorithm recovers the original points along with many spurious ones, forming an instance of the Maximum Collinear Points (MCP) problem, which can be solved efficiently. Experimental results demonstrate that the proposed method is highly effective, allowing the recovery of the author identity even when as few as three genuine points remain after adversarial manipulation.","authors":["Jarosław Janas","Paweł Morawiecki","Josef Pieprzyk"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22562v1","updated":"2026-02-26T03:00:07Z","published":"2026-02-26T03:00:07Z","title":"Layer-Targeted Multilingual Knowledge Erasure in Large Language Models","summary":"Recent work has demonstrated that machine unlearning in Large Language Models (LLMs) fails to generalize across languages: knowledge erased in one language frequently remains accessible through others. However, the underlying cause of this failure and a principled solution remain open. In this work, we identify intervention depth as the key factor determining multilingual generalization. Through systematic layer-wise experiments, we characterize two distinct failure modes: shallow-layer interventions achieve erasure but collapse multilingual capabilities in held-out languages, while deep-layer interventions preserve utility but fail to erase target knowledge even in source languages. These findings reveal that the choice of intervention layer is not a free parameter; it fundamentally determines whether multilingual unlearning succeeds. We propose MUTE (Multilingual Unlearning via Targeted Erasure), a framework that uses Centered Kernel Alignment (CKA) and Linguistic Regions Development Score (LRDS) to identify intermediate, language-agnostic layers where cross-lingual representations converge. By restricting unlearning updates to these layers, MUTE achieves robust multilingual knowledge erasure while optimizing on only a small set of source languages. Extensive experiments across three LLM architectures and three unlearning algorithms validate our approach, with mechanistic analysis via Logit Lens probing confirming genuine knowledge removal rather than output-level suppression.","authors":["Taoran Li","Varun Chandrasekaran","Zhiyuan Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21394v2","updated":"2026-02-26T02:32:50Z","published":"2026-02-24T21:50:46Z","title":"MemoPhishAgent: Memory-Augmented Multi-Modal LLM Agent for Phishing URL Detection","summary":"Traditional phishing website detection relies on static heuristics or reference lists, which lag behind rapidly evolving attacks. While recent systems incorporate large language models (LLMs), they are still prompt-based, deterministic pipelines that underutilize reasoning capability. We present MemoPhishAgent (MPA), a memory-augmented multi-modal LLM agent that dynamically orchestrates phishing-specific tools and leverages episodic memories of past reasoning trajectories to guide decisions on recurring and novel threats. On two public datasets, MPA outperforms three state-of-the-art (SOTA) baselines, improving recall by 13.6%. To better reflect realistic, user-facing phishing detection performance, we further evaluate MPA on a benchmark of real-world suspicious URLs actively crawled from five social media platforms, where it improves recall by 20%. Detailed analysis shows episodic memory contributes up to 27% recall gain without introducing additional computational overhead. The ablation study confirms the necessity of the agent-based approach compared to prompt-based baselines and validates the effectiveness of our tool design. Finally, MPA is deployed in production, processing 60K targeted high-risk URLs weekly, and achieving 91.44% recall, providing proactive protection for millions of customers. Together, our results show that combining multi-modal reasoning with episodic memory yields robust phishing detection in realistic user-exposure settings.","authors":["Xuan Chen","Hao Liu","Tao Yuan","Mehran Kafai","Piotr Habas","Xiangyu Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22525v1","updated":"2026-02-26T01:48:46Z","published":"2026-02-26T01:48:46Z","title":"Systems-Level Attack Surface of Edge Agent Deployments on IoT","summary":"Edge deployment of LLM agents on IoT hardware introduces attack surfaces absent from cloud-hosted orchestration. We present an empirical security analysis of three architectures (cloud-hosted, edge-local swarm, and hybrid) using a multi-device home-automation testbed with local MQTT messaging and an Android smartphone as an edge inference node. We identify five systems-level attack surfaces, including two emergent failures observed during live testbed operation: coordination-state divergence and induced trust erosion. We frame core security properties as measurable systems metrics: data egress volume, failover window exposure, sovereignty boundary integrity, and provenance chain completeness. Our measurements show that edge-local deployments eliminate routine cloud data exposure but silently degrade sovereignty when fallback mechanisms trigger, with boundary crossings invisible at the application layer. Provenance chains remain complete under cooperative operation yet are trivially bypassed without cryptographic enforcement. Failover windows create transient blind spots exploitable for unauthorised actuation. These results demonstrate that deployment architecture, not just model or prompt design, is a primary determinant of security risk in agent-controlled IoT systems.","authors":["Zhonghao Zhan","Krinos Li","Yefan Zhang","Hamed Haddadi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.13352v3","updated":"2026-02-26T23:17:03Z","published":"2025-12-15T14:05:49Z","title":"On the Effectiveness of Membership Inference in Targeted Data Extraction from Large Language Models","summary":"Large Language Models (LLMs) are prone to memorizing training data, which poses serious privacy risks. Two of the most prominent concerns are training data extraction and Membership Inference Attacks (MIAs). Prior research has shown that these threats are interconnected: adversaries can extract training data from an LLM by querying the model to generate a large volume of text and subsequently applying MIAs to verify whether a particular data point was included in the training set. In this study, we integrate multiple MIA techniques into the data extraction pipeline to systematically benchmark their effectiveness. We then compare their performance in this integrated setting against results from conventional MIA benchmarks, allowing us to evaluate their practical utility in real-world extraction scenarios.","authors":["Ali Al Sahili","Ali Chehab","Razane Tajeddine"],"pdf_url":"","comment":"This work has been accepted for publication at the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). The final version will be available on IEEE Xplore"},{"id":"http://arxiv.org/abs/2602.23516v1","updated":"2026-02-26T21:40:36Z","published":"2026-02-26T21:40:36Z","title":"Lap2: Revisiting Laplace DP-SGD for High Dimensions via Majorization Theory","summary":"Differentially Private Stochastic Gradient Descent (DP-SGD) is a cornerstone technique for ensuring privacy in deep learning, widely used in both training from scratch and fine-tuning large-scale language models. While DP-SGD predominantly relies on the Gaussian mechanism, the Laplace mechanism remains underutilized due to its reliance on L1 norm clipping. This constraint severely limits its practicality in high-dimensional models because the L1 norm of an n-dimensional gradient can be up to sqrt(n) times larger than its L2 norm. As a result, the required noise scale grows significantly with model size, leading to poor utility or untrainable models.\n  In this work, we introduce Lap2, a new solution that enables L2 clipping for Laplace DP-SGD while preserving strong privacy guarantees. We overcome the dimensionality-driven clipping barrier by computing coordinate-wise moment bounds and applying majorization theory to construct a tight, data-independent upper bound over the full model. By exploiting the Schur-convexity of the moment accountant function, we aggregate these bounds using a carefully designed majorization set that respects the L2 clipping constraint. This yields a multivariate privacy accountant that scales gracefully with model dimension and enables the use of thousands of moments. Empirical evaluations demonstrate that our approach significantly improves the performance of Laplace DP-SGD, achieving results comparable to or better than Gaussian DP-SGD under strong privacy constraints. For instance, fine-tuning RoBERTa-base (125M parameters) on SST-2 achieves 87.88% accuracy at epsilon=0.54, outperforming Gaussian (87.16%) and standard Laplace (48.97%) under the same budget.","authors":["Meisam Mohammady","Qin Yang","Nicholas Stout","Ayesha Samreen","Han Wang","Christopher J Quinn","Yuan Hong"],"pdf_url":"","comment":"16 pages including appendix. arXiv admin note: text overlap with arXiv:2509.06264"},{"id":"http://arxiv.org/abs/2602.23513v1","updated":"2026-02-26T21:33:56Z","published":"2026-02-26T21:33:56Z","title":"A Software-Defined Testbed for Quantifying Deauthentication Resilience in Modern Wi-Fi Networks","summary":"Wi-Fi deauthentication attacks remain a practical denial-of-service (DoS) threat by exploiting unprotected management frames to disrupt client connectivity. In this work, we introduce a software-defined testbed to measure Wi-Fi resilience to deauthentication attacks. We experimentally evaluate five wireless security configurations: open networks, WPA1, WPA2 without Protected Management Frames (PMF), WPA2 with PMF, and WPA3. Using controlled experiments, we measure client disconnection rates, packet injection volume, and time-to-disruption under each configuration. Packet-level behavior is analyzed using standard wireless auditing tools. Open networks, WPA1, and WPA2 without PMF proved entirely vulnerable to deauthentication, while no successful attacks were observed for WPA2 with PMF or WPA3 under tested conditions. These findings confirm the effectiveness of management-frame protection and highlight the continued risk posed by legacy or misconfigured wireless deployments.","authors":["Alex Carbajal","Asma Jodeiri Akbarfam"],"pdf_url":"","comment":"6 pages, 5 figures, 1 table. Accepted for publication in IEEE SoutheastCon 2026"},{"id":"http://arxiv.org/abs/2602.23464v1","updated":"2026-02-26T19:44:37Z","published":"2026-02-26T19:44:37Z","title":"2G2T: Constant-Size, Statistically Sound MSM Outsourcing","summary":"Multi-scalar multiplication (MSM), defined as MSM(P, x) = sum_{i=1}^n x_i P_i, is a dominant computational kernel in discrete-logarithm-based cryptography and often becomes a bottleneck for verifiers and other resource-constrained clients. We present 2G2T, a simple protocol for verifiably outsourcing MSM to an untrusted server. After a one-time keyed setup for fixed bases P = (P1, ..., Pn) that produces a public merged-bases vector T and client secret state, the server answers each query x = (x1, ..., xn) with only two group elements: A claimed to equal MSM(P, x) and an auxiliary value B claimed to equal MSM(T, x). Verification requires a single length-n field inner product and a constant number of group operations (two scalar multiplications and one addition), while the server performs two MSMs. In our Ristretto255 implementation, verification is up to ~300x faster than computing the MSM locally using a highly optimized MSM routine for n up to 2^18, and the server-to-client response is constant-size (two compressed group elements, 64 bytes on Ristretto255). Despite its simplicity and efficiency, 2G2T achieves statistical soundness: for any (even computationally unbounded) adversarial server, the probability of accepting an incorrect result is at most 1/q per query, and at most e/q over e adaptive executions, in a prime-order group of size q.","authors":["Majid Khabbazian"],"pdf_url":"","comment":"18 pages, 1 figure"},{"id":"http://arxiv.org/abs/2602.23407v1","updated":"2026-02-26T12:57:27Z","published":"2026-02-26T12:57:27Z","title":"Learning to Generate Secure Code via Token-Level Rewards","summary":"Large language models (LLMs) have demonstrated strong capabilities in code generation, yet they remain prone to producing security vulnerabilities. Existing approaches commonly suffer from two key limitations: the scarcity of high-quality security data and coarse-grained reinforcement learning reward signals. To address these challenges, we propose Vul2Safe, a new secure code generation framework that leverages LLM self-reflection to construct high-confidence repair pairs from real-world vulnerabilities, and further generates diverse implicit prompts to build the PrimeVul+ dataset. Meanwhile, we introduce SRCode, a novel training framework that pioneers the use of token-level rewards in reinforcement learning for code security, which enables the model to continuously attend to and reinforce critical fine-grained security patterns during training. Compared with traditional instance-level reward schemes, our approach allows for more precise optimization of local security implementations. Extensive experiments show that PrimeVul+ and SRCode substantially reduce security vulnerabilities in generated code while improving overall code quality across multiple benchmarks.","authors":["Jiazheng Quan","Xiaodong Li","Bin Wang","Guo An","Like Liu","Degen Huang","Lin Liu","Chengbin Hou"],"pdf_url":"","comment":"18 pages, 3 figures"},{"id":"http://arxiv.org/abs/2602.23404v1","updated":"2026-02-26T11:56:28Z","published":"2026-02-26T11:56:28Z","title":"Cybersecurity of Teleoperated Quadruped Robots: A Systematic Survey of Vulnerabilities, Threats, and Open Defense Gaps","summary":"Teleoperated quadruped robots are increasingly deployed in safety-critical missions -- industrial inspection, military reconnaissance, and emergency response -- yet the security of their communication and control infrastructure remains insufficiently characterized. Quadrupeds present distinct security challenges arising from dynamic stability constraints, gait-dependent vulnerability windows, substantial kinetic energy, and elevated operator cognitive load.\n  This survey synthesizes peer-reviewed literature and vulnerability disclosures (2019--2025) to provide comprehensive analysis of cybersecurity threats, consequences, and countermeasures for teleoperated quadruped systems. We contribute: (i) a six-layer attack taxonomy spanning perception manipulation, VR/AR operator targeting, communication disruption, control signal attacks, localization spoofing, and network intrusion; (ii) systematic attack-to-consequence mapping with timing characterization; (iii) Technology Readiness Level classification exposing critical maturity gaps between field-deployed communication protections (TRL 7--9) and experimental perception/operator-layer defenses (TRL 3--5); (iv) comparative security analysis of six commercial platforms; (v) pragmatic deployment guidance stratified by implementation timeline; and (vi) eight prioritized research gaps with implementation roadmaps.\n  Limitations: Platform assessments rely on publicly available information. Attack success rates derive from cited studies under controlled conditions and require domain-specific validation.","authors":["Mohammad Sabouri"],"pdf_url":"","comment":"survey paper; 23 tables; 9 figures; 132 references"},{"id":"http://arxiv.org/abs/2602.23397v1","updated":"2026-02-26T05:32:46Z","published":"2026-02-26T05:32:46Z","title":"Lifecycle-Integrated Security for AI-Cloud Convergence in Cyber-Physical Infrastructure","summary":"The convergence of Artificial Intelligence (AI) inference pipelines with cloud infrastructure creates a dual attack surface where cloud security standards and AI governance frameworks intersect without unified enforcement mechanisms. AI governance, cloud security, and industrial control system standards intersect without unified enforcement, leaving hybrid deployments exposed to cross-layer attacks that threaten safety-critical operations. This paper makes three primary contributions: (i) we synthesize these frameworks into a lifecycle-staged threat taxonomy structured around explicit attacker capability tiers, (ii) we propose a Unified Reference Architecture spanning a Secure Data Factory, a hardened model supply chain, and a runtime governance layer, (iii) we present a case study through Grid-Guard, a hybrid Transmission System Operator scenario in which coordinated defenses drawn from NIST AI RMF, MITRE ATLAS, OWASP AI Exchange and GenAI, CSA MAESTRO, and NERC CIP defeat a multi-tier physical-financial manipulation campaign without human intervention. Controls are mapped against all five frameworks and current NERC CIP standards to demonstrate that a single cloud-native architecture can simultaneously satisfy AI governance, adversarial robustness, agentic safety, and industrial regulatory compliance obligations.","authors":["S M Zia Ur Rashid","Deepa Gurung","Sonam Raj Gupta","Suman Rath"],"pdf_url":"","comment":null}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2510.10932v2","updated":"2026-02-26T18:32:27Z","published":"2025-10-13T02:45:48Z","title":"DropVLA: An Action-Level Backdoor Attack on Vision--Language--Action Models","summary":"Vision-Language-Action (VLA) models map multimodal perception and language instructions to executable robot actions, making them particularly vulnerable to behavioral backdoor manipulation: a hidden trigger introduced during training can induce unintended physical actions while nominal task performance remains intact. Prior work on VLA backdoors primarily studies untargeted attacks or task-level hijacking, leaving fine-grained control over individual actions largely unexplored. In this work, we present DropVLA, an action-level backdoor attack that forces a reusable action primitive (e.g., open_gripper) to execute at attacker-chosen decision points under a realistic pipeline-black-box setting with limited data-poisoning access, using a window-consistent relabeling scheme for chunked fine-tuning. On OpenVLA-7B evaluated with LIBERO, vision-only poisoning achieves 98.67%-99.83% attack success rate (ASR) with only 0.31% poisoned episodes while preserving 98.50%-99.17% clean-task retention, and successfully triggers the targeted action within 25 control steps at 500 Hz (0.05 s). Text-only triggers are unstable at low poisoning budgets, and combining text with vision provides no consistent ASR improvement over vision-only attacks. The backdoor remains robust to moderate trigger variations and transfers across evaluation suites (96.27%, 99.09%), whereas text-only largely fails (0.72%). We further validate physical-world feasibility on a 7-DoF Franka arm with pi0-fast, demonstrating non-trivial attack efficacy under camera-relative motion that induces image-plane trigger drift. These results reveal that VLA models can be covertly steered at the granularity of safety-critical actions with minimal poisoning and without observable degradation of nominal performance.","authors":["Zonghuan Xu","Xiang Zheng","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"","comment":"8 pages, 6 tables, 3 figures. Under review"},{"id":"http://arxiv.org/abs/2507.21259v2","updated":"2026-02-26T18:27:00Z","published":"2025-07-28T18:25:05Z","title":"NMPCM: Nonlinear Model Predictive Control on Resource-Constrained Microcontrollers","summary":"Nonlinear Model Predictive Control (NMPC) is a powerful approach for controlling highly dynamic robotic systems, as it accounts for system dynamics and optimizes control inputs at each step. However, its high computational complexity makes implementation on resource-constrained microcontrollers impractical. While recent studies have demonstrated the feasibility of Model Predictive Control (MPC) with linearized dynamics on microcontrollers, applying full NMPC remains a significant challenge. This work presents an efficient solution for generating and deploying NMPC on microcontrollers (NMPCM) to control quadrotor UAVs. The proposed method optimizes computational efficiency while maintaining high control accuracy. Simulations in Gazebo/ROS and real-world experiments validate the effectiveness of the approach, demonstrating its capability to achieve high-frequency NMPC execution in real-time systems. The code is available at: https://github.com/aralab-unr/NMPCM.","authors":["Van Chung Nguyen","Pratik Walunj","Chuong Le","An Duy Nguyen","Hung Manh La"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23312v1","updated":"2026-02-26T18:20:26Z","published":"2026-02-26T18:20:26Z","title":"Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction","summary":"Leader-follower interaction is an important paradigm in human-robot interaction (HRI). Yet, assigning roles in real time remains challenging for resource-constrained mobile and assistive robots. While large language models (LLMs) have shown promise for natural communication, their size and latency limit on-device deployment. Small language models (SLMs) offer a potential alternative, but their effectiveness for role classification in HRI has not been systematically evaluated. In this paper, we present a benchmark of SLMs for leader-follower communication, introducing a novel dataset derived from a published database and augmented with synthetic samples to capture interaction-specific dynamics. We investigate two adaptation strategies: prompt engineering and fine-tuning, studied under zero-shot and one-shot interaction modes, compared with an untrained baseline. Experiments with Qwen2.5-0.5B reveal that zero-shot fine-tuning achieves robust classification performance (86.66% accuracy) while maintaining low latency (22.2 ms per sample), significantly outperforming baseline and prompt-engineered approaches. However, results also indicate a performance degradation in one-shot modes, where increased context length challenges the model's architectural capacity. These findings demonstrate that fine-tuned SLMs provide an effective solution for direct role assignment, while highlighting critical trade-offs between dialogue complexity and classification reliability on the edge.","authors":["Rafael R. Baptista","André de Lima Salgado","Ricardo V. Godoy","Marcelo Becker","Thiago Boaventura","Gustavo J. G. Lahr"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23287v1","updated":"2026-02-26T18:01:25Z","published":"2026-02-26T18:01:25Z","title":"Interface-Aware Trajectory Reconstruction of Limited Demonstrations for Robot Learning","summary":"Assistive robots offer agency to humans with severe motor impairments. Often, these users control high-DoF robots through low-dimensional interfaces, such as using a 1-D sip-and-puff interface to operate a 6-DoF robotic arm. This mismatch results in having access to only a subset of control dimensions at a given time, imposing unintended and artificial constraints on robot motion. As a result, interface-limited demonstrations embed suboptimal motions that reflect interface restrictions rather than user intent. To address this, we present a trajectory reconstruction algorithm that reasons about task, environment, and interface constraints to lift demonstrations into the robot's full control space. We evaluate our approach using real-world demonstrations of ADL-inspired tasks performed via a 2-D joystick and 1-D sip-and-puff control interface, teleoperating two distinct 7-DoF robotic arms. Analyses of the reconstructed demonstrations and derived control policies show that lifted trajectories are faster and more efficient than their interface-constrained counterparts while respecting user preferences.","authors":["Demiana R. Barsoum","Mahdieh Nejati Javaremi","Larisa Y. C. Loke","Brenna D. Argall"],"pdf_url":"","comment":"13 pages, 8 figures, to appear in the proceedings of the 2026 Human-Robot Interaction (HRI) Conference"},{"id":"http://arxiv.org/abs/2602.23283v1","updated":"2026-02-26T17:55:22Z","published":"2026-02-26T17:55:22Z","title":"Simple Models, Real Swimming: Digital Twins for Tendon-Driven Underwater Robots","summary":"Mimicking the graceful motion of swimming animals remains a core challenge in soft robotics due to the complexity of fluid-structure interaction and the difficulty of controlling soft, biomimetic bodies. Existing modeling approaches are often computationally expensive and impractical for complex control or reinforcement learning needed for realistic motions to emerge in robotic systems. In this work, we present a tendon-driven fish robot modeled in an efficient underwater swimmer environment using a simplified, stateless hydrodynamics formulation implemented in the widespread robotics framework MuJoCo. With just two real-world swimming trajectories, we identify five fluid parameters that allow a matching to experimental behavior and generalize across a range of actuation frequencies. We show that this stateless fluid model can generalize to unseen actuation and outperform classical analytical models such as the elongated body theory. This simulation environment runs faster than real-time and can easily enable downstream learning algorithms such as reinforcement learning for target tracking, reaching a 93% success rate. Due to the simplicity and ease of use of the model and our open-source simulation environment, our results show that even simple, stateless models -- when carefully matched to physical data -- can serve as effective digital twins for soft underwater robots, opening up new directions for scalable learning and control in aquatic environments.","authors":["Mike Y. Michelis","Nana Obayashi","Josie Hughes","Robert K. Katzschmann"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23280v1","updated":"2026-02-26T17:53:46Z","published":"2026-02-26T17:53:46Z","title":"Physics Informed Viscous Value Representations","summary":"Offline goal-conditioned reinforcement learning (GCRL) learns goal-conditioned policies from static pre-collected datasets. However, accurate value estimation remains a challenge due to the limited coverage of the state-action space. Recent physics-informed approaches have sought to address this by imposing physical and geometric constraints on the value function through regularization defined over first-order partial differential equations (PDEs), such as the Eikonal equation. However, these formulations can often be ill-posed in complex, high-dimensional environments. In this work, we propose a physics-informed regularization derived from the viscosity solution of the Hamilton-Jacobi-Bellman (HJB) equation. By providing a physics-based inductive bias, our approach grounds the learning process in optimal control theory, explicitly regularizing and bounding updates during value iterations. Furthermore, we leverage the Feynman-Kac theorem to recast the PDE solution as an expectation, enabling a tractable Monte Carlo estimation of the objective that avoids numerical instability in higher-order gradients. Experiments demonstrate that our method improves geometric consistency, making it broadly applicable to navigation and high-dimensional, complex manipulation tasks. Open-source codes are available at https://github.com/HrishikeshVish/phys-fk-value-GCRL.","authors":["Hrishikesh Viswanath","Juanwu Lu","S. Talha Bukhari","Damon Conover","Ziran Wang","Aniket Bera"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23259v1","updated":"2026-02-26T17:32:30Z","published":"2026-02-26T17:32:30Z","title":"Risk-Aware World Model Predictive Control for Generalizable End-to-End Autonomous Driving","summary":"With advances in imitation learning (IL) and large-scale driving datasets, end-to-end autonomous driving (E2E-AD) has made great progress recently. Currently, IL-based methods have become a mainstream paradigm: models rely on standard driving behaviors given by experts, and learn to minimize the discrepancy between their actions and expert actions. However, this objective of \"only driving like the expert\" suffers from limited generalization: when encountering rare or unseen long-tail scenarios outside the distribution of expert demonstrations, models tend to produce unsafe decisions in the absence of prior experience. This raises a fundamental question: Can an E2E-AD system make reliable decisions without any expert action supervision? Motivated by this, we propose a unified framework named Risk-aware World Model Predictive Control (RaWMPC) to address this generalization dilemma through robust control, without reliance on expert demonstrations. Practically, RaWMPC leverages a world model to predict the consequences of multiple candidate actions and selects low-risk actions through explicit risk evaluation. To endow the world model with the ability to predict the outcomes of risky driving behaviors, we design a risk-aware interaction strategy that systematically exposes the world model to hazardous behaviors, making catastrophic outcomes predictable and thus avoidable. Furthermore, to generate low-risk candidate actions at test time, we introduce a self-evaluation distillation method to distill riskavoidance capabilities from the well-trained world model into a generative action proposal network without any expert demonstration. Extensive experiments show that RaWMPC outperforms state-of-the-art methods in both in-distribution and out-of-distribution scenarios, while providing superior decision interpretability.","authors":["Jiangxin Sun","Feng Xue","Teng Long","Chang Liu","Jian-Fang Hu","Wei-Shi Zheng","Nicu Sebe"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23253v1","updated":"2026-02-26T17:26:13Z","published":"2026-02-26T17:26:13Z","title":"SPARR: Simulation-based Policies with Asymmetric Real-world Residuals for Assembly","summary":"Robotic assembly presents a long-standing challenge due to its requirement for precise, contact-rich manipulation. While simulation-based learning has enabled the development of robust assembly policies, their performance often degrades when deployed in real-world settings due to the sim-to-real gap. Conversely, real-world reinforcement learning (RL) methods avoid the sim-to-real gap, but rely heavily on human supervision and lack generalization ability to environmental changes. In this work, we propose a hybrid approach that combines a simulation-trained base policy with a real-world residual policy to efficiently adapt to real-world variations. The base policy, trained in simulation using low-level state observations and dense rewards, provides strong priors for initial behavior. The residual policy, learned in the real world using visual observations and sparse rewards, compensates for discrepancies in dynamics and sensor noise. Extensive real-world experiments demonstrate that our method, SPARR, achieves near-perfect success rates across diverse two-part assembly tasks. Compared to the state-of-the-art zero-shot sim-to-real methods, SPARR improves success rates by 38.4% while reducing cycle time by 29.7%. Moreover, SPARR requires no human expertise, in contrast to the state-of-the-art real-world RL approaches that depend heavily on human supervision.","authors":["Yijie Guo","Iretiayo Akinola","Lars Johannsmeier","Hugo Hadfield","Abhishek Gupta","Yashraj Narang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23224v1","updated":"2026-02-26T17:04:36Z","published":"2026-02-26T17:04:36Z","title":"UniScale: Unified Scale-Aware 3D Reconstruction for Multi-View Understanding via Prior Injection for Robotic Perception","summary":"We present UniScale, a unified, scale-aware multi-view 3D reconstruction framework for robotic applications that flexibly integrates geometric priors through a modular, semantically informed design. In vision-based robotic navigation, the accurate extraction of environmental structure from raw image sequences is critical for downstream tasks. UniScale addresses this challenge with a single feed-forward network that jointly estimates camera intrinsics and extrinsics, scale-invariant depth and point maps, and the metric scale of a scene from multi-view images, while optionally incorporating auxiliary geometric priors when available. By combining global contextual reasoning with camera-aware feature representations, UniScale is able to recover the metric-scale of the scene. In robotic settings where camera intrinsics are known, they can be easily incorporated to improve performance, with additional gains obtained when camera poses are also available. This co-design enables robust, metric-aware 3D reconstruction within a single unified model. Importantly, UniScale does not require training from scratch, and leverages world priors exhibited in pre-existing models without geometric encoding strategies, making it particularly suitable for resource-constrained robotic teams. We evaluate UniScale on multiple benchmarks, demonstrating strong generalization and consistent performance across diverse environments. We will release our implementation upon acceptance.","authors":["Mohammad Mahdavian","Gordon Tan","Binbin Xu","Yuan Ren","Dongfeng Bai","Bingbing Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23206v1","updated":"2026-02-26T16:53:59Z","published":"2026-02-26T16:53:59Z","title":"Grasp, Slide, Roll: Comparative Analysis of Contact Modes for Tactile-Based Shape Reconstruction","summary":"Tactile sensing allows robots to gather detailed geometric information about objects through physical interaction, complementing vision-based approaches. However, efficiently acquiring useful tactile data remains challenging due to the time-consuming nature of physical contact and the need to strategically choose contact locations that maximize information gain while minimizing physical interactions. This paper studies how different contact modes affect object shape reconstruction using a tactile-enabled dexterous gripper. We compare three contact interaction modes: grasp-releasing, sliding induced by finger-grazing, and palm-rolling. These contact modes are combined with an information-theoretic exploration framework that guides subsequent sampling locations using a shape completion model. Our results show that the improved tactile sensing efficiency of finger-grazing and palm-rolling translates into faster convergence in shape reconstruction, requiring 34% fewer physical interactions while improving reconstruction accuracy by 55%. We validate our approach using a UR5e robot arm equipped with an Inspire-Robots Dexterous Hand, showing robust performance across primitive object geometries.","authors":["Chung Hee Kim","Shivani Kamtikar","Tye Brady","Taskin Padir","Joshua Migdal"],"pdf_url":"","comment":"8 pages, 11 figures, Accepted by ICRA 2026"},{"id":"http://arxiv.org/abs/2602.23204v1","updated":"2026-02-26T16:53:36Z","published":"2026-02-26T16:53:36Z","title":"Motion-aware Event Suppression for Event Cameras","summary":"In this work, we introduce the first framework for Motion-aware Event Suppression, which learns to filter events triggered by IMOs and ego-motion in real time. Our model jointly segments IMOs in the current event stream while predicting their future motion, enabling anticipatory suppression of dynamic events before they occur. Our lightweight architecture achieves 173 Hz inference on consumer-grade GPUs with less than 1 GB of memory usage, outperforming previous state-of-the-art methods on the challenging EVIMO benchmark by 67\\% in segmentation accuracy while operating at a 53\\% higher inference rate. Moreover, we demonstrate significant benefits for downstream applications: our method accelerates Vision Transformer inference by 83\\% via token pruning and improves event-based visual odometry accuracy, reducing Absolute Trajectory Error (ATE) by 13\\%.","authors":["Roberto Pellerito","Nico Messikommer","Giovanni Cioffi","Marco Cannici","Davide Scaramuzza"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2412.06491v3","updated":"2026-02-26T16:36:51Z","published":"2024-12-09T13:48:15Z","title":"PPT: Pretraining with Pseudo-Labeled Trajectories for Motion Forecasting","summary":"Accurately predicting how agents move in dynamic scenes is essential for safe autonomous driving. State-of-the-art motion forecasting models rely on datasets with manually annotated or post-processed trajectories. However, building these datasets is costly, generally manual, hard to scale, and lacks reproducibility. They also introduce domain gaps that limit generalization across environments. We introduce PPT (Pretraining with Pseudo-labeled Trajectories), a simple and scalable pretraining framework that uses unprocessed and diverse trajectories automatically generated from off-the-shelf 3D detectors and tracking. Unlike data annotation pipelines aiming for clean, single-label annotations, PPT is a pretraining framework embracing off-the-shelf trajectories as useful signals for learning robust representations. With optional finetuning on a small amount of labeled data, models pretrained with PPT achieve strong performance across standard benchmarks, particularly in low-data regimes, and in cross-domain, end-to-end, and multi-class settings. PPT is easy to implement and improves generalization in motion forecasting.","authors":["Yihong Xu","Yuan Yin","Éloi Zablocki","Tuan-Hung Vu","Alexandre Boulch","Matthieu Cord"],"pdf_url":"","comment":"8 pages, 6 figures, accepted to ICRA 2026"},{"id":"http://arxiv.org/abs/2602.21101v2","updated":"2026-02-26T16:35:02Z","published":"2026-02-24T17:02:56Z","title":"Event-Aided Sharp Radiance Field Reconstruction for Fast-Flying Drones","summary":"Fast-flying aerial robots promise rapid inspection under limited battery constraints, with direct applications in infrastructure inspection, terrain exploration, and search and rescue. However, high speeds lead to severe motion blur in images and induce significant drift and noise in pose estimates, making dense 3D reconstruction with Neural Radiance Fields (NeRFs) particularly challenging due to their high sensitivity to such degradations. In this work, we present a unified framework that leverages asynchronous event streams alongside motion-blurred frames to reconstruct high-fidelity radiance fields from agile drone flights. By embedding event-image fusion into NeRF optimization and jointly refining event-based visual-inertial odometry priors using both event and frame modalities, our method recovers sharp radiance fields and accurate camera trajectories without ground-truth supervision. We validate our approach on both synthetic data and real-world sequences captured by a fast-flying drone. Despite highly dynamic drone flights, where RGB frames are severely degraded by motion blur and pose priors become unreliable, our method reconstructs high-fidelity radiance fields and preserves fine scene details, delivering a performance gain of over 50% on real-world data compared to state-of-the-art methods.","authors":["Rong Zou","Marco Cannici","Davide Scaramuzza"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23172v1","updated":"2026-02-26T16:34:49Z","published":"2026-02-26T16:34:49Z","title":"Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking","summary":"Capturing 4D spatiotemporal surroundings is crucial for the safe and reliable operation of robots in dynamic environments. However, most existing methods address only one side of the problem: they either provide coarse geometric tracking via bounding boxes, or detailed 3D structures like voxel-based occupancy that lack explicit temporal association. In this work, we present Latent Gaussian Splatting for 4D Panoptic Occupancy Tracking (LaGS) that advances spatiotemporal scene understanding in a holistic direction. Our approach incorporates camera-based end-to-end tracking with mask-based multi-view panoptic occupancy prediction, and addresses the key challenge of efficiently aggregating multi-view information into 3D voxel grids via a novel latent Gaussian splatting approach. Specifically, we first fuse observations into 3D Gaussians that serve as a sparse point-centric latent representation of the 3D scene, and then splat the aggregated features onto a 3D voxel grid that is decoded by a mask-based segmentation head. We evaluate LaGS on the Occ3D nuScenes and Waymo datasets, achieving state-of-the-art performance for 4D panoptic occupancy tracking. We make our code available at https://lags.cs.uni-freiburg.de/.","authors":["Maximilian Luz","Rohit Mohan","Thomas Nürnberg","Yakov Miron","Daniele Cattaneo","Abhinav Valada"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23115v1","updated":"2026-02-26T15:27:49Z","published":"2026-02-26T15:27:49Z","title":"FLIGHT: Fibonacci Lattice-based Inference for Geometric Heading in real-Time","summary":"Estimating camera motion from monocular video is a fundamental problem in computer vision, central to tasks such as SLAM, visual odometry, and structure-from-motion. Existing methods that recover the camera's heading under known rotation, whether from an IMU or an optimization algorithm, tend to perform well in low-noise, low-outlier conditions, but often decrease in accuracy or become computationally expensive as noise and outlier levels increase. To address these limitations, we propose a novel generalization of the Hough transform on the unit sphere (S(2)) to estimate the camera's heading. First, the method extracts correspondences between two frames and generates a great circle of directions compatible with each pair of correspondences. Then, by discretizing the unit sphere using a Fibonacci lattice as bin centers, each great circle casts votes for a range of directions, ensuring that features unaffected by noise or dynamic objects vote consistently for the correct motion direction. Experimental results on three datasets demonstrate that the proposed method is on the Pareto frontier of accuracy versus efficiency. Additionally, experiments on SLAM show that the proposed method reduces RMSE by correcting the heading during camera pose initialization.","authors":["David Dirnfeld","Fabien Delattre","Pedro Miraldo","Erik Learned-Miller"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23109v1","updated":"2026-02-26T15:22:07Z","published":"2026-02-26T15:22:07Z","title":"Towards Intelligible Human-Robot Interaction: An Active Inference Approach to Occluded Pedestrian Scenarios","summary":"The sudden appearance of occluded pedestrians presents a critical safety challenge in autonomous driving. Conventional rule-based or purely data-driven approaches struggle with the inherent high uncertainty of these long-tail scenarios. To tackle this challenge, we propose a novel framework grounded in Active Inference, which endows the agent with a human-like, belief-driven mechanism. Our framework leverages a Rao-Blackwellized Particle Filter (RBPF) to efficiently estimate the pedestrian's hybrid state. To emulate human-like cognitive processes under uncertainty, we introduce a Conditional Belief Reset mechanism and a Hypothesis Injection technique to explicitly model beliefs about the pedestrian's multiple latent intentions. Planning is achieved via a Cross-Entropy Method (CEM) enhanced Model Predictive Path Integral (MPPI) controller, which synergizes the efficient, iterative search of CEM with the inherent robustness of MPPI. Simulation experiments demonstrate that our approach significantly reduces the collision rate compared to reactive, rule-based, and reinforcement learning (RL) baselines, while also exhibiting explainable and human-like driving behavior that reflects the agent's internal belief state.","authors":["Kai Chen","Yuyao Huang","Guang Chen"],"pdf_url":"","comment":"14 pages, 6 figures, Proceedings of the 2026 ACM/IEEE International Conference on Human-Robot Interaction (HRI'26)"},{"id":"http://arxiv.org/abs/2602.23058v1","updated":"2026-02-26T14:42:53Z","published":"2026-02-26T14:42:53Z","title":"GeoWorld: Geometric World Models","summary":"Energy-based predictive world models provide a powerful approach for multi-step visual planning by reasoning over latent energy landscapes rather than generating pixels. However, existing approaches face two major challenges: (i) their latent representations are typically learned in Euclidean space, neglecting the underlying geometric and hierarchical structure among states, and (ii) they struggle with long-horizon prediction, which leads to rapid degradation across extended rollouts. To address these challenges, we introduce GeoWorld, a geometric world model that preserves geometric structure and hierarchical relations through a Hyperbolic JEPA, which maps latent representations from Euclidean space onto hyperbolic manifolds. We further introduce Geometric Reinforcement Learning for energy-based optimization, enabling stable multi-step planning in hyperbolic latent space. Extensive experiments on CrossTask and COIN demonstrate around 3% SR improvement in 3-step planning and 2% SR improvement in 4-step planning compared to the state-of-the-art V-JEPA 2. Project website: https://steve-zeyu-zhang.github.io/GeoWorld.","authors":["Zeyu Zhang","Danning Li","Ian Reid","Richard Hartley"],"pdf_url":"","comment":"Accepted to CVPR 2026"},{"id":"http://arxiv.org/abs/2602.23053v1","updated":"2026-02-26T14:40:20Z","published":"2026-02-26T14:40:20Z","title":"Marinarium: a New Arena to Bring Maritime Robotics Closer to Shore","summary":"This paper presents the Marinarium, a modular and stand-alone underwater research facility designed to provide a realistic testbed for maritime and space-analog robotic experimentation in a resource-efficient manner. The Marinarium combines a fully instrumented underwater and aerial operational volume, extendable via a retractable roof for real-weather conditions, a digital twin in the SMaRCSim simulator and tight integration with a space robotics laboratory. All of these result from design choices aimed at bridging simulation, laboratory validation, and field conditions. We compare the Marinarium to similar existing infrastructures and illustrate how its design enables a set of experiments in four open research areas within field robotics. First, we exploit high-fidelity dynamics data from the tank to demonstrate the potential of learning-based system identification approaches applied to underwater vehicles. We further highlight the versatility of the multi-domain operating volume via a rendezvous mission with a heterogeneous fleet of robots across underwater, surface, and air. We then illustrate how the presented digital twin can be utilized to reduce the reality gap in underwater simulation. Finally, we demonstrate the potential of underwater surrogates for spacecraft navigation validation by executing spatiotemporally identical inspection tasks on a planar space-robot emulator and a neutrally buoyant \\gls{rov}. In this work, by sharing the insights obtained and rationale behind the design and construction of the Marinarium, we hope to provide the field robotics research community with a blueprint for bridging the gap between controlled and real offshore and space robotics experimentation.","authors":["Ignacio Torroba","David Dorner","Victor Nan Fernandez-Ayala","Mart Kartasev","Joris Verhagen","Elias Krantz","Gregorio Marchesini","Carl Ljung","Pedro Roque","Chelsea Sidrane","Linda Van der Spaa","Nicola De Carli","Petter Ogren","Christer Fuglesang","Jana Tumova","Dimos V. Dimarogonas","Ivan Stenius"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23051v1","updated":"2026-02-26T14:38:38Z","published":"2026-02-26T14:38:38Z","title":"An Empirical Analysis of Cooperative Perception for Occlusion Risk Mitigation","summary":"Occlusions present a significant challenge for connected and automated vehicles, as they can obscure critical road users from perception systems. Traditional risk metrics often fail to capture the cumulative nature of these threats over time adequately. In this paper, we propose a novel and universal risk assessment metric, the Risk of Tracking Loss (RTL), which aggregates instantaneous risk intensity throughout occluded periods. This provides a holistic risk profile that encompasses both high-intensity, short-term threats and prolonged exposure. Utilizing diverse and high-fidelity real-world datasets, a large-scale statistical analysis is conducted to characterize occlusion risk and validate the effectiveness of the proposed metric. The metric is applied to evaluate different vehicle-to-everything (V2X) deployment strategies. Our study shows that full V2X penetration theoretically eliminates this risk, the reduction is highly nonlinear; a substantial statistical benefit requires a high penetration threshold of 75-90%. To overcome this limitation, we propose a novel asymmetric communication framework that allows even non-connected vehicles to receive warnings. Experimental results demonstrate that this paradigm achieves better risk mitigation performance. We found that our approach at 25% penetration outperforms the traditional symmetric model at 75%, and benefits saturate at only 50% penetration. This work provides a crucial risk assessment metric and a cost-effective, strategic roadmap for accelerating the safety benefits of V2X deployment.","authors":["Aihong Wang","Tenghui Xie","Fuxi Wen","Jun Li"],"pdf_url":"","comment":"Accepted for publication in IEEE Internet of Things Journal (Regular Article), 2026. DOI: 10.1109/JIOT.2026.3668184"},{"id":"http://arxiv.org/abs/2602.23024v1","updated":"2026-02-26T14:03:58Z","published":"2026-02-26T14:03:58Z","title":"InCoM: Intent-Driven Perception and Structured Coordination for Whole-Body Mobile Manipulation","summary":"Whole-body mobile manipulation is a fundamental capability for general-purpose robotic agents, requiring both coordinated control of the mobile base and manipulator and robust perception under dynamically changing viewpoints. However, existing approaches face two key challenges: strong coupling between base and arm actions complicates whole-body control optimization, and perceptual attention is often poorly allocated as viewpoints shift during mobile manipulation. We propose InCoM, an intent-driven perception and structured coordination framework for whole-body mobile manipulation. InCoM infers latent motion intent to dynamically reweight multi-scale perceptual features, enabling stage-adaptive allocation of perceptual attention. To support robust cross-modal perception, InCoM further incorporates a geometric-semantic structured alignment mechanism that enhances multimodal correspondence. On the control side, we design a decoupled coordinated flow matching action decoder that explicitly models coordinated base-arm action generation, alleviating optimization difficulties caused by control coupling. Without access to privileged perceptual information, InCoM outperforms state-of-the-art methods on three ManiSkill-HAB scenarios by 28.2%, 26.1%, and 23.6% in success rate, demonstrating strong effectiveness for whole-body mobile manipulation.","authors":["Jiahao Liu","Cui Wenbo","Haoran Li","Dongbin Zhao"],"pdf_url":"","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2602.23017v1","updated":"2026-02-26T13:55:05Z","published":"2026-02-26T13:55:05Z","title":"DigiArm: An Anthropomorphic 3D-Printed Prosthetic Hand with Enhanced Dexterity for Typing Tasks","summary":"Despite recent advancements, existing prosthetic limbs are unable to replicate the dexterity and intuitive control of the human hand. Current control systems for prosthetic hands are often limited to grasping, and commercial prosthetic hands lack the precision needed for dexterous manipulation or applications that require fine finger motions. Thus, there is a critical need for accessible and replicable prosthetic designs that enable individuals to interact with electronic devices and perform precise finger pressing, such as keyboard typing or piano playing, while preserving current prosthetic capabilities. This paper presents a low-cost, lightweight, 3D-printed robotic prosthetic hand, specifically engineered for enhanced dexterity with electronic devices such as a computer keyboard or piano, as well as general object manipulation. The robotic hand features a mechanism to adjust finger abduction/adduction spacing, a 2-D wrist with the inclusion of controlled ulnar/radial deviation optimized for typing, and control of independent finger pressing. We conducted a study to demonstrate how participants can use the robotic hand to perform keyboard typing and piano playing in real time, with different levels of finger and wrist motion. This supports the notion that our proposed design can allow for the execution of key typing motions more effectively than before, aiming to enhance the functionality of prosthetic hands.","authors":["Dean Zadok","Tom Naamani","Yuval Bar-Ratson","Elisha Barash","Oren Salzman","Alon Wolf","Alex M. Bronstein","Nili Krausz"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.07137v2","updated":"2026-02-26T13:44:57Z","published":"2025-12-08T03:40:59Z","title":"Time-Varying Formation Tracking Control of Wheeled Mobile Robots With Region Constraint: A Generalized Udwadia-Kalaba Framework","summary":"In this article, the time-varying formation tracking control of wheeled mobile robots with region constraint is investigated from a generalized Udwadia-Kalaba framework. The communication network is modeled as a directed and weighted graph that has a spanning tree with the leader being the root. By reformulating the time-varying formation tracking control objective as an equality constrained equation and transforming the region constraint by a diffeomorphism, the time-varying formation tracking controller with the region constraint is designed under the generalized Udwadia-Kalaba framework. Compared with the existing works on time-varying formation tracking control, the region constraint is taken into account in this paper, which ensures the safety of the robots. Finally, the feasibility of the proposed control strategy is illustrated through some numerical simulations.","authors":["Yijie Kang","Yuqing Hao","Qingyun Wang","Guanrong Chen"],"pdf_url":"","comment":"17 pages,9 figures"},{"id":"http://arxiv.org/abs/2602.22998v1","updated":"2026-02-26T13:39:30Z","published":"2026-02-26T13:39:30Z","title":"A Perspective on Open Challenges in Deformable Object Manipulation","summary":"Deformable object manipulation (DOM) represents a critical challenge in robotics, with applications spanning healthcare, manufacturing, food processing, and beyond. Unlike rigid objects, deformable objects exhibit infinite dimensionality, dynamic shape changes, and complex interactions with their environment, posing significant hurdles for perception, modeling, and control. This paper reviews the state of the art in DOM, focusing on key challenges such as occlusion handling, task generalization, and scalable, real-time solutions. It highlights advancements in multimodal perception systems, including the integration of multi-camera setups, active vision, and tactile sensing, which collectively address occlusion and improve adaptability in unstructured environments. Cutting-edge developments in physically informed reinforcement learning (RL) and differentiable simulations are explored, showcasing their impact on efficiency, precision, and scalability. The review also emphasizes the potential of simulated expert demonstrations and generative neural networks to standardize task specifications and bridge the simulation-to-reality gap. Finally, future directions are proposed, including the adoption of graph neural networks for high-level decision-making and the creation of comprehensive datasets to enhance DOM's real-world applicability. By addressing these challenges, DOM research can pave the way for versatile robotic systems capable of handling diverse and dynamic tasks with deformable objects.","authors":["Ryan Paul McKennaa","John Oyekan"],"pdf_url":"","comment":"28 pages, 7 Figures"},{"id":"http://arxiv.org/abs/2602.22952v1","updated":"2026-02-26T12:47:04Z","published":"2026-02-26T12:47:04Z","title":"Automated Robotic Needle Puncture for Percutaneous Dilatational Tracheostomy","summary":"Percutaneous dilatational tracheostomy (PDT) is frequently performed on patients in intensive care units for prolonged mechanical ventilation. The needle puncture, as the most critical step of PDT, could lead to adverse consequences such as major bleeding and posterior tracheal wall perforation if performed inaccurately. Current practices of PDT puncture are all performed manually with no navigation assistance, which leads to large position and angular errors (5 mm and 30 degree). To improve the accuracy and reduce the difficulty of the PDT procedure, we propose a system that automates the needle insertion using a velocity-controlled robotic manipulator. Guided using pose data from two electromagnetic sensors, one at the needle tip and the other inside the trachea, the robotic system uses an adaptive constrained controller to adapt the uncertain kinematic parameters online and avoid collisions with the patient's body and tissues near the target. Simulations were performed to validate the controller's implementation, and then four hundred PDT punctures were performed on a mannequin to evaluate the position and angular accuracy. The absolute median puncture position error was 1.7 mm (IQR: 1.9 mm) and midline deviation was 4.13 degree (IQR: 4.55 degree), measured by the sensor inside the trachea. The small deviations from the nominal puncture in a simulated experimental setup and formal guarantees of collision-free insertions suggest the feasibility of the robotic PDT puncture.","authors":["Yuan Tang","Bruno V. Adorno","Brendan A. McGrath","Andrew Weightman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22940v1","updated":"2026-02-26T12:30:44Z","published":"2026-02-26T12:30:44Z","title":"Considering Perspectives for Automated Driving Ethics: Collective Risk in Vehicular Motion Planning","summary":"Recent automated vehicle (AV) motion planning strategies evolve around minimizing risk in road traffic. However, they exclusively consider risk from the AV's perspective and, as such, do not address the ethicality of its decisions for other road users. We argue that this does not reduce the risk of each road user, as risk may be different from the perspective of each road user. Indeed, minimizing the risk from the AV's perspective may not imply that the risk from the perspective of other road users is also being minimized; in fact, it may even increase. To test this hypothesis, we propose an AV motion planning strategy that supports switching risk minimization strategies between all road user perspectives. We find that the risk from the perspective of other road users can generally be considered different to the risk from the AV's perspective. Taking a collective risk perspective, i.e., balancing the risks of all road users, we observe an AV that minimizes overall traffic risk the best, while putting itself at slightly higher risk for the benefit of others, which is consistent with human driving behavior. In addition, adopting a collective risk minimization strategy can also be beneficial to the AV's travel efficiency by acting assertively when other road users maintain a low risk estimate of the AV. Yet, the AV drives conservatively when its planned actions are less predictable to other road users, i.e., associated with high risk. We argue that such behavior is a form of self-reflection and a natural prerequisite for socially acceptable AV behavior. We conclude that to facilitate ethicality in road traffic that includes AVs, the risk-perspective of each road user must be considered in the decision-making of AVs.","authors":["Leon Tolksdorf","Arturo Tejada","Christian Birkner","Nathan van de Wouw"],"pdf_url":"","comment":"17 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2602.22923v1","updated":"2026-02-26T12:12:40Z","published":"2026-02-26T12:12:40Z","title":"WaterVideoQA: ASV-Centric Perception and Rule-Compliant Reasoning via Multi-Modal Agents","summary":"While autonomous navigation has achieved remarkable success in passive perception (e.g., object detection and segmentation), it remains fundamentally constrained by a void in knowledge-driven, interactive environmental cognition. In the high-stakes domain of maritime navigation, the ability to bridge the gap between raw visual perception and complex cognitive reasoning is not merely an enhancement but a critical prerequisite for Autonomous Surface Vessels to execute safe and precise maneuvers. To this end, we present WaterVideoQA, the first large-scale, comprehensive Video Question Answering benchmark specifically engineered for all-waterway environments. This benchmark encompasses 3,029 video clips across six distinct waterway categories, integrating multifaceted variables such as volatile lighting and dynamic weather to rigorously stress-test ASV capabilities across a five-tier hierarchical cognitive framework. Furthermore, we introduce NaviMind, a pioneering multi-agent neuro-symbolic system designed for open-ended maritime reasoning. By synergizing Adaptive Semantic Routing, Situation-Aware Hierarchical Reasoning, and Autonomous Self-Reflective Verification, NaviMind transitions ASVs from superficial pattern matching to regulation-compliant, interpretable decision-making. Experimental results demonstrate that our framework significantly transcends existing baselines, establishing a new paradigm for intelligent, trustworthy interaction in dynamic maritime environments.","authors":["Runwei Guan","Shaofeng Liang","Ningwei Ouyang","Weichen Fei","Shanliang Yao","Wei Dai","Chenhao Ge","Penglei Sun","Xiaohui Zhu","Tao Huang","Ryan Wen Liu","Hui Xiong"],"pdf_url":"","comment":"11 pages,8 figures"},{"id":"http://arxiv.org/abs/2602.22922v1","updated":"2026-02-26T12:11:51Z","published":"2026-02-26T12:11:51Z","title":"Bayesian Preference Elicitation: Human-In-The-Loop Optimization of An Active Prosthesis","summary":"Tuning active prostheses for people with amputation is time-consuming and relies on metrics that may not fully reflect user needs. We introduce a human-in-the-loop optimization (HILO) approach that leverages direct user preferences to personalize a standard four-parameter prosthesis controller efficiently. Our method employs preference-based Multiobjective Bayesian Optimization that uses a state-or-the-art acquisition function especially designed for preference learning, and includes two algorithmic variants: a discrete version (\\textit{EUBO-LineCoSpar}), and a continuous version (\\textit{BPE4Prost}). Simulation results on benchmark functions and real-application trials demonstrate efficient convergence, robust preference elicitation, and measurable biomechanical improvements, illustrating the potential of preference-driven tuning for user-centered prosthesis control.","authors":["Sophia Taddei","Wouter Koppen","Eligia Alfio","Stefano Nuzzo","Louis Flynn","Maria Alejandra Diaz","Sebastian Rojas Gonzalez","Tom Dhaene","Kevin De Pauw","Ivo Couckuyt","Tom Verstraten"],"pdf_url":"","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2602.22896v1","updated":"2026-02-26T11:34:36Z","published":"2026-02-26T11:34:36Z","title":"DySL-VLA: Efficient Vision-Language-Action Model Inference via Dynamic-Static Layer-Skipping for Robot Manipulation","summary":"Vision-Language-Action (VLA) models have shown remarkable success in robotic tasks like manipulation by fusing a language model's reasoning with a vision model's 3D understanding. However, their high computational cost remains a major obstacle for real-world applications that require real-time performance. We observe that the actions within a task have varying levels of importance: critical steps demand high precision, while less important ones can tolerate more variance. Leveraging this insight, we propose DySL-VLA, a novel framework that addresses computational cost by dynamically skipping VLA layers based on each action's importance. DySL-VLA categorizes its layers into two types: informative layers, which are consistently executed, and incremental layers, which can be selectively skipped. To intelligently skip layers without sacrificing accuracy, we invent a prior-post skipping guidance mechanism to determine when to initiate layer-skipping. We also propose a skip-aware two-stage knowledge distillation algorithm to efficiently train a standard VLA into a DySL-VLA. Our experiments indicate that DySL-VLA achieves 2.1% improvement in success length over Deer-VLA on the Calvin dataset, while simultaneously reducing trainable parameters by a factor of 85.7 and providing a 3.75x speedup relative to the RoboFlamingo baseline at iso-accuracy. Our code is available on https://github.com/PKU-SEC-Lab/DYSL_VLA.","authors":["Zebin Yang","Yijiahao Qi","Tong Xie","Bo Yu","Shaoshan Liu","Meng Li"],"pdf_url":"","comment":"DAC 2026"},{"id":"http://arxiv.org/abs/2602.22862v1","updated":"2026-02-26T10:56:01Z","published":"2026-02-26T10:56:01Z","title":"GraspLDP: Towards Generalizable Grasping Policy via Latent Diffusion","summary":"This paper focuses on enhancing the grasping precision and generalization of manipulation policies learned via imitation learning. Diffusion-based policy learning methods have recently become the mainstream approach for robotic manipulation tasks. As grasping is a critical subtask in manipulation, the ability of imitation-learned policies to execute precise and generalizable grasps merits particular attention. Existing imitation learning techniques for grasping often suffer from imprecise grasp executions, limited spatial generalization, and poor object generalization. To address these challenges, we incorporate grasp prior knowledge into the diffusion policy framework. In particular, we employ a latent diffusion policy to guide action chunk decoding with grasp pose prior, ensuring that generated motion trajectories adhere closely to feasible grasp configurations. Furthermore, we introduce a self-supervised reconstruction objective during diffusion to embed the graspness prior: at each reverse diffusion step, we reconstruct wrist-camera images back-projected the graspness from the intermediate representations. Both simulation and real robot experiments demonstrate that our approach significantly outperforms baseline methods and exhibits strong dynamic grasping capabilities.","authors":["Enda Xiang","Haoxiang Ma","Xinzhu Ma","Zicheng Liu","Di Huang"],"pdf_url":"","comment":"Accepted to CVPR 2026"},{"id":"http://arxiv.org/abs/2602.22854v1","updated":"2026-02-26T10:46:13Z","published":"2026-02-26T10:46:13Z","title":"Performance and Experimental Analysis of Strain-based Models for Continuum Robots","summary":"Although strain-based models have been widely adopted in robotics, no comparison beyond the uniform bending test is commonly recognized to assess their performance. In addition, the increasing effort in prototyping continuum robots highlights the need to assess the applicability of these models and the necessity of comprehensive performance evaluation. To address this gap, this work investigates the shape reconstruction abilities of a third-order strain interpolation method, examining its ability to capture both individual and combined deformation effects. These results are compared and discussed against the Geometric-Variable Strain approach. Subsequently, simulation results are experimentally verified by reshaping a slender rod while recording the resulting configurations using cameras. The rod configuration is imposed using a manipulator displacing one of its tips and extracted through reflective markers, without the aid of any other external sensor -- i.e. strain gauges or wrench sensors placed along the rod. The experiments demonstrate good agreement between the model predictions and observed shapes, with average error of 0.58% of the rod length and average computational time of 0.32s per configuration, outperforming existing models.","authors":["Annika Delucchi","Vincenzo Di Paola","Andreas Müller","and Matteo Zoppi"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.14647v2","updated":"2026-02-26T10:21:54Z","published":"2025-10-16T12:59:34Z","title":"Spatially anchored Tactile Awareness for Robust Dexterous Manipulation","summary":"Dexterous manipulation requires precise geometric reasoning, yet existing visuo-tactile learning methods struggle with sub-millimeter precision tasks that are routine for traditional model-based approaches. We identify a key limitation: while tactile sensors provide rich contact information, current learning frameworks fail to effectively leverage both the perceptual richness of tactile signals and their spatial relationship with hand kinematics. We believe an ideal tactile representation should explicitly ground contact measurements in a stable reference frame while preserving detailed sensory information, enabling policies to not only detect contact occurrence but also precisely infer object geometry in the hand's coordinate system. We introduce SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an end-to-end policy framework that explicitly anchors tactile features to the hand's kinematic frame through forward kinematics, enabling accurate geometric reasoning without requiring object models or explicit pose estimation. Our key insight is that spatially grounded tactile representations allow policies to not only detect contact occurrence but also precisely infer object geometry in the hand's coordinate system. We validate SaTA on challenging dexterous manipulation tasks, including bimanual USB-C mating in free space, a task demanding sub-millimeter alignment precision, as well as light bulb installation requiring precise thread engagement and rotational control, and card sliding that demands delicate force modulation and angular precision. These tasks represent significant challenges for learning-based methods due to their stringent precision requirements. Across multiple benchmarks, SaTA significantly outperforms strong visuo-tactile baselines, improving success rates by up to 30 percentage while reducing task completion times by 27 percentage.","authors":["Jialei Huang","Yang Ye","Yuanqing Gong","Xuezhou Zhu","Yang Gao","Kaifeng Zhang"],"pdf_url":"","comment":"8 pages"},{"id":"http://arxiv.org/abs/2602.22818v1","updated":"2026-02-26T09:59:50Z","published":"2026-02-26T09:59:50Z","title":"LeRobot: An Open-Source Library for End-to-End Robot Learning","summary":"Robotics is undergoing a significant transformation powered by advances in high-level control techniques based on machine learning, giving rise to the field of robot learning. Recent progress in robot learning has been accelerated by the increasing availability of affordable teleoperation systems, large-scale openly available datasets, and scalable learning-based methods. However, development in the field of robot learning is often slowed by fragmented, closed-source tools designed to only address specific sub-components within the robotics stack. In this paper, we present \\texttt{lerobot}, an open-source library that integrates across the entire robot learning stack, from low-level middleware communication for motor controls to large-scale dataset collection, storage and streaming. The library is designed with a strong focus on real-world robotics, supporting accessible hardware platforms while remaining extensible to new embodiments. It also supports efficient implementations for various state-of-the-art robot learning algorithms from multiple prominent paradigms, as well as a generalized asynchronous inference stack. Unlike traditional pipelines which heavily rely on hand-crafted techniques, \\texttt{lerobot} emphasizes scalable learning approaches that improve directly with more data and compute. Designed for accessibility, scalability, and openness, \\texttt{lerobot} lowers the barrier to entry for researchers and practitioners to robotics while providing a platform for reproducible, state-of-the-art robot learning.","authors":["Remi Cadene","Simon Aliberts","Francesco Capuano","Michel Aractingi","Adil Zouitine","Pepijn Kooijmans","Jade Choghari","Martino Russi","Caroline Pascal","Steven Palma","Mustafa Shukor","Jess Moss","Alexander Soare","Dana Aubakirova","Quentin Lhoest","Quentin Gallouédec","Thomas Wolf"],"pdf_url":"","comment":"https://github.com/huggingface/lerobot"},{"id":"http://arxiv.org/abs/2509.16552v2","updated":"2026-02-26T09:54:58Z","published":"2025-09-20T06:36:30Z","title":"ST-GS: Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting","summary":"3D occupancy prediction is critical for comprehensive scene understanding in vision-centric autonomous driving. Recent advances have explored utilizing 3D semantic Gaussians to model occupancy while reducing computational overhead, but they remain constrained by insufficient multi-view spatial interaction and limited multi-frame temporal consistency. To overcome these issues, in this paper, we propose a novel Spatial-Temporal Gaussian Splatting (ST-GS) framework to enhance both spatial and temporal modeling in existing Gaussian-based pipelines. Specifically, we develop a guidance-informed spatial aggregation strategy within a dual-mode attention mechanism to strengthen spatial interaction in Gaussian representations. Furthermore, we introduce a geometry-aware temporal fusion scheme that effectively leverages historical context to improve temporal continuity in scene completion. Extensive experiments on the large-scale nuScenes occupancy prediction benchmark showcase that our proposed approach not only achieves state-of-the-art performance but also delivers markedly better temporal consistency compared to existing Gaussian-based methods.","authors":["Xiaoyang Yan","Muleilan Pei","Shaojie Shen"],"pdf_url":"","comment":"Accepted by ICRA 2026"},{"id":"http://arxiv.org/abs/2502.01932v6","updated":"2026-02-26T09:51:13Z","published":"2025-02-04T02:07:23Z","title":"VolleyBots: A Testbed for Multi-Drone Volleyball Game Combining Motion Control and Strategic Play","summary":"Robot sports, characterized by well-defined objectives, explicit rules, and dynamic interactions, present ideal scenarios for demonstrating embodied intelligence. In this paper, we present VolleyBots, a novel robot sports testbed where multiple drones cooperate and compete in the sport of volleyball under physical dynamics. VolleyBots integrates three features within a unified platform: competitive and cooperative gameplay, turn-based interaction structure, and agile 3D maneuvering. These intertwined features yield a complex problem combining motion control and strategic play, with no available expert demonstrations. We provide a comprehensive suite of tasks ranging from single-drone drills to multi-drone cooperative and competitive tasks, accompanied by baseline evaluations of representative reinforcement learning (RL), multi-agent reinforcement learning (MARL) and game-theoretic algorithms. Simulation results show that on-policy RL methods outperform off-policy methods in single-agent tasks, but both approaches struggle in complex tasks that combine motion control and strategic play. We additionally design a hierarchical policy which achieves 69.5% win rate against the strongest baseline in the 3 vs 3 task, demonstrating its potential for tackling the complex interplay between low-level control and high-level strategy. To highlight VolleyBots' sim-to-real potential, we further demonstrate the zero-shot deployment of a policy trained entirely in simulation on real-world drones.","authors":["Zelai Xu","Ruize Zhang","Chao Yu","Huining Yuan","Xiangmin Yi","Shilong Ji","Chuqi Wang","Wenhao Tang","Feng Gao","Wenbo Ding","Xinlei Chen","Yu Wang"],"pdf_url":"","comment":"Accepted by NeurIPS 2025"},{"id":"http://arxiv.org/abs/2602.22801v1","updated":"2026-02-26T09:37:38Z","published":"2026-02-26T09:37:38Z","title":"Unleashing the Potential of Diffusion Models for End-to-End Autonomous Driving","summary":"Diffusion models have become a popular choice for decision-making tasks in robotics, and more recently, are also being considered for solving autonomous driving tasks. However, their applications and evaluations in autonomous driving remain limited to simulation-based or laboratory settings. The full strength of diffusion models for large-scale, complex real-world settings, such as End-to-End Autonomous Driving (E2E AD), remains underexplored. In this study, we conducted a systematic and large-scale investigation to unleash the potential of the diffusion models as planners for E2E AD, based on a tremendous amount of real-vehicle data and road testing. Through comprehensive and carefully controlled studies, we identify key insights into the diffusion loss space, trajectory representation, and data scaling that significantly impact E2E planning performance. Moreover, we also provide an effective reinforcement learning post-training strategy to further enhance the safety of the learned planner. The resulting diffusion-based learning framework, Hyper Diffusion Planner} (HDP), is deployed on a real-vehicle platform and evaluated across 6 urban driving scenarios and 200 km of real-world testing, achieving a notable 10x performance improvement over the base model. Our work demonstrates that diffusion models, when properly designed and trained, can serve as effective and scalable E2E AD planners for complex, real-world autonomous driving tasks.","authors":["Yinan Zheng","Tianyi Tan","Bin Huang","Enguang Liu","Ruiming Liang","Jianlin Zhang","Jianwei Cui","Guang Chen","Kun Ma","Hangjun Ye","Long Chen","Ya-Qin Zhang","Xianyuan Zhan","Jingjing Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22733v1","updated":"2026-02-26T08:15:38Z","published":"2026-02-26T08:15:38Z","title":"Pixel2Catch: Multi-Agent Sim-to-Real Transfer for Agile Manipulation with a Single RGB Camera","summary":"To catch a thrown object, a robot must be able to perceive the object's motion and generate control actions in a timely manner. Rather than explicitly estimating the object's 3D position, this work focuses on a novel approach that recognizes object motion using pixel-level visual information extracted from a single RGB image. Such visual cues capture changes in the object's position and scale, allowing the policy to reason about the object's motion. Furthermore, to achieve stable learning in a high-DoF system composed of a robot arm equipped with a multi-fingered hand, we design a heterogeneous multi-agent reinforcement learning framework that defines the arm and hand as independent agents with distinct roles. Each agent is trained cooperatively using role-specific observations and rewards, and the learned policies are successfully transferred from simulation to the real world.","authors":["Seongyong Kim","Junhyeon Cho","Kang-Won Lee","Soo-Chul Lim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22731v1","updated":"2026-02-26T08:13:47Z","published":"2026-02-26T08:13:47Z","title":"Sapling-NeRF: Geo-Localised Sapling Reconstruction in Forests for Ecological Monitoring","summary":"Saplings are key indicators of forest regeneration and overall forest health. However, their fine-scale architectural traits are difficult to capture with existing 3D sensing methods, which make quantitative evaluation difficult. Terrestrial Laser Scanners (TLS), Mobile Laser Scanners (MLS), or traditional photogrammetry approaches poorly reconstruct thin branches, dense foliage, and lack the scale consistency needed for long-term monitoring. Implicit 3D reconstruction methods such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) are promising alternatives, but cannot recover the true scale of a scene and lack any means to be accurately geo-localised. In this paper, we present a pipeline which fuses NeRF, LiDAR SLAM, and GNSS to enable repeatable, geo-localised ecological monitoring of saplings. Our system proposes a three-level representation: (i) coarse Earth-frame localisation using GNSS, (ii) LiDAR-based SLAM for centimetre-accurate localisation and reconstruction, and (iii) NeRF-derived object-centric dense reconstruction of individual saplings. This approach enables repeatable quantitative evaluation and long-term monitoring of sapling traits. Our experiments in forest plots in Wytham Woods (Oxford, UK) and Evo (Finland) show that stem height, branching patterns, and leaf-to-wood ratios can be captured with increased accuracy as compared to TLS. We demonstrate that accurate stem skeletons and leaf distributions can be measured for saplings with heights between 0.5m and 2m in situ, giving ecologists access to richer structural and quantitative data for analysing forest dynamics.","authors":["Miguel Ángel Muñoz-Bañón","Nived Chebrolu","Sruthi M. Krishna Moorthy","Yifu Tao","Fernando Torres","Roberto Salguero-Gómez","Maurice Fallon"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22714v1","updated":"2026-02-26T07:40:57Z","published":"2026-02-26T07:40:57Z","title":"Robust Helicopter Ship Deck Landing With Guaranteed Timing Using Shrinking-Horizon Model Predictive Control","summary":"We present a runtime efficient algorithm for autonomous helicopter landings on moving ship decks based on Shrinking-Horizon Model Predictive Control (SHMPC). First, a suitable planning model capturing the relevant aspects of the full nonlinear helicopter dynamics is derived. Next, we use the SHMPC together with a touchdown controller stage to ensure a pre-specified maneuver time and an associated landing time window despite the presence of disturbances. A high disturbance rejection performance is achieved by designing an ancillary controller with disturbance feedback. Thus, given a target position and time, a safe landing with suitable terminal conditions is be guaranteed if the initial optimization problem is feasible. The efficacy of our approach is shown in simulation where all maneuvers achieve a high landing precision in strong winds while satisfying timing and operational constraints with maximum computation times in the millisecond range.","authors":["Philipp Schitz","Paolo Mercorelli","Johann C. Dauer"],"pdf_url":"","comment":"This version was submitted to the American Control Conference 2026 and has been accepted"},{"id":"http://arxiv.org/abs/2602.22707v1","updated":"2026-02-26T07:31:29Z","published":"2026-02-26T07:31:29Z","title":"SCOPE: Skeleton Graph-Based Computation-Efficient Framework for Autonomous UAV Exploration","summary":"Autonomous exploration in unknown environments is key for mobile robots, helping them perceive, map, and make decisions in complex areas. However, current methods often rely on frequent global optimization, suffering from high computational latency and trajectory oscillation, especially on resource-constrained edge devices. To address these limitations, we propose SCOPE, a novel framework that incrementally constructs a real-time skeletal graph and introduces Implicit Unknown Region Analysis for efficient spatial reasoning. The planning layer adopts a hierarchical on-demand strategy: the Proximal Planner generates smooth, high-frequency local trajectories, while the Region-Sequence Planner is activated only when necessary to optimize global visitation order. Comparative evaluations in simulation demonstrate that SCOPE achieves competitive exploration performance comparable to state-of-the-art global planners, while reducing computational cost by an average of 86.9%. Real-world experiments further validate the system's robustness and low latency in practical scenarios.","authors":["Kai Li","Shengtao Zheng","Linkun Xiu","Yuze Sheng","Xiao-Ping Zhang","Dongyue Huang","Xinlei Chen"],"pdf_url":"","comment":"This paper has been accepted for publication in the IEEE ROBOTICS AND AUTOMATION LETTERS (RA-L). Please cite the paper using appropriate formats"},{"id":"http://arxiv.org/abs/2602.22671v1","updated":"2026-02-26T06:42:25Z","published":"2026-02-26T06:42:25Z","title":"Does the testing environment matter? Carsickness across on-road, test-track, and driving simulator conditions","summary":"Carsickness has gained significant attention with the rise of automated vehicles, prompting extensive research across on-road, test-track, and driving simulator environments to understand its occurrence and develop mitigation strategies. However, the lack of carsickness standardization complicates comparisons across studies and environments. Previous works demonstrate measurement validity between two setups at most (e.g., on-road vs. driving simulator), leaving gaps in multi-environment comparisons. This study investigates the recreation of an on-road motion sickness exposure - previously replicated on a test track - using a motion-based driving simulator. Twenty-eight participants performed an eyes-off-road non-driving task while reporting motion sickness using the Misery Scale during the experiment and the Motion Sickness Assessment Questionnaire afterward. Psychological factors known to influence motion sickness were also assessed. The results present subjective and objective measurements for motion sickness across the considered environments. In this paper, acceleration measurements, objective metrics and subjective motion sickness ratings across environments are compared, highlighting key differences in sickness occurrence for simulator-based research validity. Significantly lower motion sickness scores are reported in the simulator compared to on-road and test-track conditions, due to its limited working envelope to reproduce low-frequency (<0.5 Hz) motions, which are the most provocative for motion sickness.","authors":["Georgios Papaioannou","Barys Shyrokau"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22663v1","updated":"2026-02-26T06:27:37Z","published":"2026-02-26T06:27:37Z","title":"Rethinking the Practicality of Vision-language-action Model: A Comprehensive Benchmark and An Improved Baseline","summary":"Vision-Language-Action (VLA) models have emerged as a generalist robotic agent. However, existing VLAs are hindered by excessive parameter scales, prohibitive pre-training requirements, and limited applicability to diverse embodiments. To improve the practicality of VLAs, we propose a comprehensive benchmark and an improved baseline. First, we propose CEBench, a new benchmark spanning diverse embodiments in both simulation and the real world with consideration of domain randomization. We collect 14.4k simulated trajectories and 1.6k real-world expert-curated trajectories to support training on CEBench. Second, using CEBench as our testbed, we study three critical aspects of VLAs' practicality and offer several key findings. Informed by these findings, we introduce LLaVA-VLA, a lightweight yet powerful VLA designed for practical deployment on consumer-grade GPUs. Architecturally, it integrates a compact VLM backbone with multi-view perception, proprioceptive tokenization, and action chunking. To eliminate reliance on costly pre-training, LLaVA-VLA adopts a two-stage training paradigm including post-training and fine-tuning. Furthermore, LLaVA-VLA extends the action space to unify navigation and manipulation. Experiments across embodiments demonstrate the capabilities of generalization and versatility of LLaVA-VLA , while real-world mobile manipulation experiments establish it as the first end-to-end VLA model for mobile manipulation. We will open-source all datasets, codes, and checkpoints upon acceptance to foster reproducibility and future research.","authors":["Wenxuan Song","Jiayi Chen","Xiaoquan Sun","Huashuo Lei","Yikai Qin","Wei Zhao","Pengxiang Ding","Han Zhao","Tongxin Wang","Pengxu Hou","Zhide Zhong","Haodong Yan","Donglin Wang","Jun Ma","Haoang Li"],"pdf_url":"","comment":"Accepted by ICRA 2026"},{"id":"http://arxiv.org/abs/2506.01392v2","updated":"2026-02-26T06:26:43Z","published":"2025-06-02T07:36:14Z","title":"Sparse Imagination for Efficient Visual World Model Planning","summary":"World model based planning has significantly improved decision-making in complex environments by enabling agents to simulate future states and make informed choices. This computational burden is particularly restrictive in robotics, where resources are severely constrained. To address this limitation, we propose a Sparse Imagination for Efficient Visual World Model Planning, which enhances computational efficiency by reducing the number of tokens processed during forward prediction. Our method leverages a sparsely trained vision-based world model based on transformers with randomized grouped attention strategy, allowing the model to flexibly adjust the number of tokens processed based on the computational resource. By enabling sparse imagination during latent rollout, our approach significantly accelerates planning while maintaining high control fidelity. Experimental results demonstrate that sparse imagination preserves task performance while dramatically improving inference efficiency. This general technique for visual planning is applicable from simple test-time trajectory optimization to complex real-world tasks with the latest VLAs, enabling the deployment of world models in real-time scenarios.","authors":["Junha Chun","Youngjoon Jeong","Taesup Kim"],"pdf_url":"","comment":"Accepted to ICLR 2026; Project Page: https://nikriz1.github.io/sparse_imagination/"},{"id":"http://arxiv.org/abs/2411.15468v2","updated":"2026-02-26T05:29:03Z","published":"2024-11-23T06:35:19Z","title":"SplatSDF: Boosting SDF-NeRF via Architecture-Level Fusion with Gaussian Splats","summary":"Signed distance-radiance field (SDF-NeRF) is a promising environment representation that offers both photo-realistic rendering and geometric reasoning such as proximity queries for collision avoidance. However, the slow training speed and convergence of SDF-NeRF hinder their use in practical robotic systems. We propose SplatSDF, a novel SDF-NeRF architecture that accelerates convergence using 3D Gaussian splats (3DGS), which can be quickly pre-trained. Unlike prior approaches that introduce a consistency loss between separate 3DGS and SDF-NeRF models, SplatSDF directly fuses 3DGS at an architectural level by consuming it as an input to SDF-NeRF during training. This is achieved using a novel sparse 3DGS fusion strategy that injects neural embeddings of 3DGS into SDF-NeRF around the object surface, while also permitting inference without 3DGS for minimal operation. Experimental results show SplatSDF achieves 3X faster convergence to the same geometric accuracy than the best baseline, and outperforms state-of-the-art SDF-NeRF methods in terms of chamfer distance and peak signal to noise ratio, unlike consistency loss-based approaches that in fact provide limited gains. We also present computational techniques for accelerating gradient and Hessian steps by 3X. We expect these improvements will contribute to deploying SDF-NeRF on practical systems.","authors":["Runfa Blark Li","Keito Suzuki","Bang Du","Ki Myung Brian Lee","Nikolay Atanasov","Truong Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22628v1","updated":"2026-02-26T05:03:17Z","published":"2026-02-26T05:03:17Z","title":"Designing Robots for Families: In-Situ Prototyping for Contextual Reminders on Family Routines","summary":"Robots are increasingly entering the daily lives of families, yet their successful integration into domestic life remains a challenge. We explore family routines as a critical entry point for understanding how robots might find a sustainable role in everyday family settings. Together with each of the ten families, we co-designed robot interactions and behaviors, and a plan for the robot to support their chosen routines, accounting for contextual factors such as timing, participants, locations, and the activities in the environment. We then designed, prototyped, and deployed a mobile social robot as a four-day, in-home user study. Families welcomed the robot's reminders, with parents especially appreciating the offloading of some reminding tasks. At the same time, interviews revealed tensions around timing, authority, and family dynamics, highlighting the complexity of integrating robots into households beyond the immediate task of reminders. Based on these insights, we offer design implications for robot-facilitated contextual reminders and discuss broader considerations for designing robots for family settings.","authors":["Michael F. Xu","Enhui Zhao","Yawen Zhang","Joseph E. Michaelis","Sarah Sebo","Bilge Mutlu"],"pdf_url":"","comment":"Proceedings of the 21st ACM/IEEE International Conference on Human Robot Interaction (HRI 2026)"},{"id":"http://arxiv.org/abs/2505.24266v4","updated":"2026-02-26T03:42:12Z","published":"2025-05-30T06:42:09Z","title":"SignBot: Learning Human-to-Humanoid Sign Language Interaction","summary":"Sign language is a natural and visual form of language that uses movements and expressions to convey meaning, serving as a crucial means of communication for individuals who are deaf or hard-of-hearing (DHH). However, the number of people proficient in sign language remains limited, highlighting the need for technological advancements to bridge communication gaps and foster interactions with minorities. Based on recent advancements in embodied humanoid robots, we propose SignBot, a novel framework for human-robot sign language interaction. SignBot integrates a cerebellum-inspired motion control component and a cerebral-oriented module for comprehension and interaction. Specifically, SignBot consists of: 1) Motion Retargeting, which converts human sign language datasets into robot-compatible kinematics; 2) Motion Control, which leverages a learning-based paradigm to develop a robust humanoid control policy for tracking sign language gestures; and 3) Generative Interaction, which incorporates translator, responser, and generator of sign language, thereby enabling natural and effective communication between robots and humans. Simulation and real-world experimental results demonstrate that SignBot can effectively facilitate human-robot interaction and perform sign language motions with diverse robots and datasets. SignBot represents a significant advancement in automatic sign language interaction on embodied humanoid robot platforms, providing a promising solution to improve communication accessibility for the DHH community.","authors":["Guanren Qiao","Sixu Lin","Ronglai Zuo","Zhizheng Wu","Kui Jia","Guiliang Liu"],"pdf_url":"","comment":"Accepted by ICRA 2026"},{"id":"http://arxiv.org/abs/2508.10398v2","updated":"2026-02-26T03:34:43Z","published":"2025-08-14T06:54:47Z","title":"Super LiDAR Intensity for Robotic Perception","summary":"Conventionally, human intuition defines vision as a modality of passive optical sensing, relying on ambient light to perceive the environment. However, active optical sensing, which involves emitting and receiving signals, offers unique advantages by capturing both radiometric and geometric properties of the environment, independent of external illumination conditions. This work focuses on advancing active optical sensing using Light Detection and Ranging (LiDAR), which captures intensity data, enabling the estimation of surface reflectance that remains invariant under varying illumination. Such properties are crucial for robotic perception tasks, including detection, recognition, segmentation, and Simultaneous Localization and Mapping (SLAM). A key challenge with low-cost LiDARs lies in the sparsity of scan data, which limits their broader application. To address this limitation, this work introduces an innovative framework for generating dense LiDAR intensity images from sparse data, leveraging the unique attributes of non-repeating scanning LiDAR (NRS-LiDAR). We tackle critical challenges, including intensity calibration and the transition from static to dynamic scene domains, facilitating the reconstruction of dense intensity images in real-world settings. The key contributions of this work include a comprehensive dataset for LiDAR intensity image densification, a densification network tailored for NRS-LiDAR, and diverse applications such as loop closure and traffic lane detection using the generated dense intensity images. Experimental results validate the efficacy of the proposed approach, which successfully integrates computer vision techniques with LiDAR data processing, enhancing the applicability of low-cost LiDAR systems and establishing a novel paradigm for robotic vision via active optical sensing--LiDAR as a Camera.","authors":["Wei Gao","Jie Zhang","Mingle Zhao","Zhiyuan Zhang","Shu Kong","Maani Ghaffari","Dezhen Song","Cheng-Zhong Xu","Hui Kong"],"pdf_url":"","comment":"IEEE Robotics and Automation Letters (RA-L), 2026 (https://ieeexplore.ieee.org/document/11395610). The dataset and code are available at: (https://github.com/IMRL/Super-LiDAR-Intensity)"},{"id":"http://arxiv.org/abs/2602.22579v1","updated":"2026-02-26T03:32:43Z","published":"2026-02-26T03:32:43Z","title":"Metamorphic Testing of Vision-Language Action-Enabled Robots","summary":"Vision-Language-Action (VLA) models are multimodal robotic task controllers that, given an instruction and visual inputs, produce a sequence of low-level control actions (or motor commands) enabling a robot to execute the requested task in the physical environment. These systems face the test oracle problem from multiple perspectives. On the one hand, a test oracle must be defined for each instruction prompt, which is a complex and non-generalizable approach. On the other hand, current state-of-the-art oracles typically capture symbolic representations of the world (e.g., robot and object states), enabling the correctness evaluation of a task, but fail to assess other critical aspects, such as the quality with which VLA-enabled robots perform a task. In this paper, we explore whether Metamorphic Testing (MT) can alleviate the test oracle problem in this context. To do so, we propose two metamorphic relation patterns and five metamorphic relations to assess whether changes to the test inputs impact the original trajectory of the VLA-enabled robots. An empirical study involving five VLA models, two simulated robots, and four robotic tasks shows that MT can effectively alleviate the test oracle problem by automatically detecting diverse types of failures, including, but not limited to, uncompleted tasks. More importantly, the proposed MRs are generalizable, making the proposed approach applicable across different VLA models, robots, and tasks, even in the absence of test oracles.","authors":["Pablo Valle","Sergio Segura","Shaukat Ali","Aitor Arrieta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.18692v2","updated":"2026-02-26T03:30:01Z","published":"2026-01-26T17:08:04Z","title":"A Pragmatic VLA Foundation Model","summary":"Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second with an 8-GPU training setup, representing a 1.5~2.8$\\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.","authors":["Wei Wu","Fan Lu","Yunnan Wang","Shuai Yang","Shi Liu","Fangjing Wang","Qian Zhu","He Sun","Yong Wang","Shuailei Ma","Yiyu Ren","Kejia Zhang","Hui Yu","Jingmei Zhao","Shuai Zhou","Zhenqi Qiu","Houlong Xiong","Ziyu Wang","Zechen Wang","Ran Cheng","Yong-Lu Li","Yongtao Huang","Xing Zhu","Yujun Shen","Kecheng Zheng"],"pdf_url":"","comment":"Project Webpage: https://technology.robbyant.com/lingbot-vla/, Code: https://github.com/Robbyant/lingbot-vla/, GM-100: https://huggingface.co/datasets/robbyant/lingbot-GM-100"},{"id":"http://arxiv.org/abs/2602.22542v1","updated":"2026-02-26T02:30:49Z","published":"2026-02-26T02:30:49Z","title":"Relational Appliances: A Robot in the Refrigerator for Home-Based Health Promotion","summary":"Kitchen appliances are frequently used domestic artifacts situated at the point of everyday dietary decision making, making them a promising but underexplored site for health promotion. We explore the concept of relational appliances: everyday household devices designed as embodied social actors that engage users through ongoing, personalized interaction. We focus on the refrigerator, whose unique affordances, including a fixed, sensor-rich environment, private interaction space, and close coupling to food items, support contextualized, conversational engagement during snack choices. We present an initial exploration of this concept through a pilot study deploying an anthropomorphic robotic head inside a household refrigerator. In a home-lab apartment, participants repeatedly retrieved snacks during simulated TV \"commercial breaks\" while interacting with a human-sized robotic head. Participants were randomized to either a health-promotion condition, in which the robot made healthy snack recommendations, or a social-chat control condition. Outcomes included compliance with recommendations, nutritional quality of selected snacks, and psychosocial measures related to acceptance of the robot. Results suggest that participants found the robot persuasive, socially engaging, and increasingly natural over time, often describing it as helpful, aware, and companionable. Most participants reported greater awareness of their snack decisions and expressed interest in having such a robot in their own home. We discuss implications for designing relational appliances that leverage anthropomorphism, trust, and long-term human-technology relationships for home-based health promotion.","authors":["Timothy Bickmore","Mehdi Arjmand","Yunus Terzioglu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.16434v2","updated":"2026-02-26T02:30:13Z","published":"2025-11-20T15:03:55Z","title":"From Prompts to Printable Models: Support-Effective 3D Generation via Offset Direct Preference Optimization","summary":"Current text-to-3D models prioritize visual fidelity but often neglect physical fabricability, resulting in geometries requiring excessive support structures. This paper introduces SEG (\\textit{\\underline{S}upport-\\underline{E}ffective \\underline{G}eneration}), a novel framework that integrates Direct Preference Optimization with an Offset (ODPO) into the 3D generation pipeline to directly optimize models for minimal support material usage. By incorporating support structure simulation into the training process, SEG encourages the generation of geometries that inherently require fewer supports, thus reducing material waste and production time. We demonstrate SEG's effectiveness through extensive experiments on two benchmark datasets, Thingi10k-Val and GPT-3DP-Val, showing that SEG significantly outperforms baseline models such as TRELLIS, DPO, and DRO in terms of support volume reduction and printability. Qualitative results further reveal that SEG maintains high fidelity to input prompts while minimizing the need for support structures. Our findings highlight the potential of SEG to transform 3D printing by directly optimizing models during the generative process, paving the way for more sustainable and efficient digital fabrication practices.","authors":["Chenming Wu","Xiaofan Li","Chengkai Dai"],"pdf_url":"","comment":"Accepted by IEEE Robotics and Automation Letters 2026, preprint version by authors"},{"id":"http://arxiv.org/abs/2602.21670v2","updated":"2026-02-26T02:28:18Z","published":"2026-02-25T08:08:26Z","title":"Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning","summary":"Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.","authors":["Tomoya Kawabe","Rin Takano"],"pdf_url":"","comment":"Accepted to IEEE International Conference on Robotics and Automation (ICRA) 2026. 8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2409.19709v2","updated":"2026-02-26T02:03:32Z","published":"2024-09-29T13:57:09Z","title":"DreamWaQ++: Obstacle-Aware Quadrupedal Locomotion With Resilient Multi-Modal Reinforcement Learning","summary":"Quadrupedal robots hold promising potential for applications in navigating cluttered environments with resilience akin to their animal counterparts. However, their floating base configuration makes them vulnerable to real-world uncertainties, yielding substantial challenges in their locomotion control. Deep reinforcement learning has become one of the plausible alternatives for realizing a robust locomotion controller. However, the approaches that rely solely on proprioception sacrifice collision-free locomotion because they require front-feet contact to detect the presence of stairs to adapt the locomotion gait. Meanwhile, incorporating exteroception necessitates a precisely modeled map observed by exteroceptive sensors over a period of time. Therefore, this work proposes a novel method to fuse proprioception and exteroception featuring a resilient multi-modal reinforcement learning. The proposed method yields a controller that showcases agile locomotion performance on a quadrupedal robot over a myriad of real-world courses, including rough terrains, steep slopes, and high-rise stairs, while retaining its robustness against out-of-distribution situations.","authors":["I Made Aswin Nahrendra","Byeongho Yu","Minho Oh","Dongkyu Lee","Seunghyun Lee","Hyeonwoo Lee","Hyungtae Lim","Hyun Myung"],"pdf_url":"","comment":"IEEE Transactions on Robotics 2026. Project site is available at https://dreamwaqpp.github.io"},{"id":"http://arxiv.org/abs/2602.22514v1","updated":"2026-02-26T01:16:27Z","published":"2026-02-26T01:16:27Z","title":"SignVLA: A Gloss-Free Vision-Language-Action Framework for Real-Time Sign Language-Guided Robotic Manipulation","summary":"We present, to our knowledge, the first sign language-driven Vision-Language-Action (VLA) framework for intuitive and inclusive human-robot interaction. Unlike conventional approaches that rely on gloss annotations as intermediate supervision, the proposed system adopts a gloss-free paradigm and directly maps visual sign gestures to semantic instructions. This design reduces annotation cost and avoids the information loss introduced by gloss representations, enabling more natural and scalable multimodal interaction.\n  In this work, we focus on a real-time alphabet-level finger-spelling interface that provides a robust and low-latency communication channel for robotic control. Compared with large-scale continuous sign language recognition, alphabet-level interaction offers improved reliability, interpretability, and deployment feasibility in safety-critical embodied environments. The proposed pipeline transforms continuous gesture streams into coherent language commands through geometric normalization, temporal smoothing, and lexical refinement, ensuring stable and consistent interaction.\n  Furthermore, the framework is designed to support future integration of transformer-based gloss-free sign language models, enabling scalable word-level and sentence-level semantic understanding. Experimental results demonstrate the effectiveness of the proposed system in grounding sign-derived instructions into precise robotic actions under diverse interaction scenarios. These results highlight the potential of the framework to advance accessible, scalable, and multimodal embodied intelligence.","authors":["Xinyu Tan","Ningwei Bai","Harry Gardener","Zhengyang Zhong","Luoyu Zhang","Liuhaichen Yang","Zhekai Duan","Monkgogi Galeitsiwe","Zezhi Tang"],"pdf_url":"","comment":"7 pages, 2 figures"},{"id":"http://arxiv.org/abs/2505.08344v2","updated":"2026-02-26T01:03:06Z","published":"2025-05-13T08:41:52Z","title":"A spherical amplitude-phase formulation for 3-D adaptive line-of-sight (ALOS) guidance with USGES stability guarantees","summary":"A recently proposed 3-D adaptive line-of-sight (ALOS) path-following algorithm addressed coupled motion dynamics of marine craft, aircraft and uncrewed vehicles under environmental disturbances such as wind, waves and ocean currents. Stability analysis established uniform semi-global exponential stability (USGES) using a body-velocity-based amplitude-phase representation of the North-East-Down kinematic differential equations. However, the analysis is limited to straight-line paths, and restrictive assumptions are needed to ensure convergence of the vertical crab angle estimation error to zero. In this paper, we revisit the ALOS framework and introduce a novel spherical amplitude-phase design model that uses an alternative definition of the vertical crab angle. Our proposed formulation enables a significantly simplified stability proof, while retaining the USGES property for straight-line paths, removing restrictive assumptions on constant altitude/depth or zero horizontal crab angle, and remaining valid for general 3-D motion with nonzero roll, pitch and flight-path angles. We also show that the USGES result extends to a class of curved 3-D paths.","authors":["Erlend M. Coates","Thor I. Fossen"],"pdf_url":"","comment":"5 pages, 2 figures"},{"id":"http://arxiv.org/abs/2509.10692v2","updated":"2026-02-26T00:51:58Z","published":"2025-09-12T21:09:57Z","title":"STL-Based Motion Planning and Uncertainty-Aware Risk Analysis for Human-Robot Collaboration with a Multi-Rotor Aerial Vehicle","summary":"This paper presents a novel approach to motion planning and risk analysis for enhancing human-robot collaboration using a Multi-Rotor Aerial Vehicle (MRAV). The proposed method uses Signal Temporal Logic (STL) to encode key mission objectives, such as safety, timing, and human preferences, with a strong focus on ergonomics and comfort. An optimization framework generates dynamically feasible trajectories while considering the MRAV's physical constraints. Given the nonlinear and non-convex nature of the problem, smooth approximations and gradient-based techniques assist in handling the problem's computational complexity. Additionally, an uncertainty-aware risk analysis is incorporated to assess potential deviations from the mission specifications, providing insights into the likelihood of mission success under uncertain conditions. Further, an event-triggered replanning strategy is implemented to respond to unforeseen events and external disturbances. The approach is validated through MATLAB and Gazebo simulations, using an object handover task in a mock-up environment inspired by power line maintenance scenarios. The results highlight the method's effectiveness in achieving safe, efficient, and resilient human-robot collaboration.","authors":["Giuseppe Silano","Amr Afifi","Martin Saska","Antonio Franchi"],"pdf_url":"","comment":"45 pages, 14 figures"},{"id":"http://arxiv.org/abs/2507.04996v8","updated":"2026-02-26T22:12:46Z","published":"2025-07-07T13:34:49Z","title":"Agentic Vehicles for Human-Centered Mobility","summary":"Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity to operate according to internal rules without external control. Autonomous vehicles (AuVs) are therefore understood as systems that perceive their environment and execute pre-programmed tasks independently of external input, consistent with the SAE levels of automated driving. Yet recent research and real-world deployments have begun to showcase vehicles that exhibit behaviors outside the scope of this definition. These include natural language interaction with humans, goal adaptation, contextual reasoning, external tool use, and the handling of unforeseen ethical dilemmas, enabled in part by multimodal large language models (LLMs). These developments highlight not only a gap between technical autonomy and the broader cognitive and social capacities required for human-centered mobility, but also the emergence of a form of vehicle intelligence that currently lacks a clear designation. To address this gap, the paper introduces the concept of agentic vehicles (AgVs): vehicles that integrate agentic AI systems to reason, adapt, and interact within complex environments. It synthesizes recent advances in agentic systems and suggests how AgVs can complement and even reshape conventional autonomy to ensure mobility services are aligned with user and societal needs. The paper concludes by outlining key challenges in the development and governance of AgVs and their potential role in shaping future agentic transportation systems.","authors":["Jiangbo Yu","Raphael Frank","Luis Miranda-Moreno","Sasan Jafarnejad","Jonatas Augusto Manzolli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23524v1","updated":"2026-02-26T22:07:06Z","published":"2026-02-26T22:07:06Z","title":"V-MORALS: Visual Morse Graph-Aided Estimation of Regions of Attraction in a Learned Latent Space","summary":"Reachability analysis has become increasingly important in robotics to distinguish safe from unsafe states. Unfortunately, existing reachability and safety analysis methods often fall short, as they typically require known system dynamics or large datasets to estimate accurate system models, are computationally expensive, and assume full state information. A recent method, called MORALS, aims to address these shortcomings by using topological tools to estimate3DR-eEgnciodnesr of Attraction (ROA) in a low-dimensional latent space. However, MORALS still relies on full state knowledge and has not been studied when only sensor measurements are available. This paper presents Visual Morse Graph-Aided Estimation of Regions of Attraction in a Learned Latent Space (V- MORALS). V-MORALS takes in a dataset of image-based trajectories of a system under a given controller, and learns a latent space for reachability analysis. Using this learned latent space, our method is able to generate well-defined Morse Graphs, from which we can compute ROAs for various systems and controllers. V-MORALS provides capabilities similar to the original MORALS architecture without relying on state knowledge, and using only high-level sensor data. Our project website is at: https://v-morals.onrender.com.","authors":["Faiz Aladin","Ashwin Balasubramanian","Lars Lindemann","Daniel Seita"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23499v1","updated":"2026-02-26T21:16:20Z","published":"2026-02-26T21:16:20Z","title":"TaCarla: A comprehensive benchmarking dataset for end-to-end autonomous driving","summary":"Collecting a high-quality dataset is a critical task that demands meticulous attention to detail, as overlooking certain aspects can render the entire dataset unusable. Autonomous driving challenges remain a prominent area of research, requiring further exploration to enhance the perception and planning performance of vehicles. However, existing datasets are often incomplete. For instance, datasets that include perception information generally lack planning data, while planning datasets typically consist of extensive driving sequences where the ego vehicle predominantly drives forward, offering limited behavioral diversity. In addition, many real datasets struggle to evaluate their models, especially for planning tasks, since they lack a proper closed-loop evaluation setup. The CARLA Leaderboard 2.0 challenge, which provides a diverse set of scenarios to address the long-tail problem in autonomous driving, has emerged as a valuable alternative platform for developing perception and planning models in both open-loop and closed-loop evaluation setups. Nevertheless, existing datasets collected on this platform present certain limitations. Some datasets appear to be tailored primarily for limited sensor configuration, with particular sensor configurations. To support end-to-end autonomous driving research, we have collected a new dataset comprising over 2.85 million frames using the CARLA simulation environment for the diverse Leaderboard 2.0 challenge scenarios. Our dataset is designed not only for planning tasks but also supports dynamic object detection, lane divider detection, centerline detection, traffic light recognition, prediction tasks and visual language action models . Furthermore, we demonstrate its versatility by training various models using our dataset. Moreover, we also provide numerical rarity scores to understand how rarely the current state occurs in the dataset.","authors":["Tugrul Gorgulu","Atakan Dag","M. Esat Kalfaoglu","Halil Ibrahim Kuru","Baris Can Cam","Ozsel Kilinc"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23478v1","updated":"2026-02-26T20:10:56Z","published":"2026-02-26T20:10:56Z","title":"Refining Almost-Safe Value Functions on the Fly","summary":"Control Barrier Functions (CBFs) are a powerful tool for ensuring robotic safety, but designing or learning valid CBFs for complex systems is a significant challenge. While Hamilton-Jacobi Reachability provides a formal method for synthesizing safe value functions, it scales poorly and is typically performed offline, limiting its applicability in dynamic environments. This paper bridges the gap between offline synthesis and online adaptation. We introduce refineCBF for refining an approximate CBF - whether analytically derived, learned, or even unsafe - via warm-started HJ reachability. We then present its computationally efficient successor, HJ-Patch, which accelerates this process through localized updates. Both methods guarantee the recovery of a safe value function and can ensure monotonic safety improvements during adaptation. Our experiments validate our framework's primary contribution: in-the-loop, real-time adaptation, in simulation (with detailed value function analysis) and on physical hardware. Our experiments on ground vehicles and quadcopters show that our framework can successfully adapt to sudden environmental changes, such as new obstacles and unmodeled wind disturbances, providing a practical path toward deploying formally guaranteed safety in real-world settings.","authors":["Sander Tonkens","Sosuke Kojima","Chenhao Liu","Judy Masri","Sylvia Herbert"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23468v1","updated":"2026-02-26T19:54:00Z","published":"2026-02-26T19:54:00Z","title":"Optimization of Edge Directions and Weights for Mixed Guidance Graphs in Lifelong Multi-Agent Path Finding","summary":"Multi-Agent Path Finding (MAPF) aims to move agents from their start to goal vertices on a graph. Lifelong MAPF (LMAPF) continuously assigns new goals to agents as they complete current ones. To guide agents' movement in LMAPF, prior works have proposed Guidance Graph Optimization (GGO) methods to optimize a guidance graph, which is a bidirected weighted graph whose directed edges represent moving and waiting actions with edge weights being action costs. Higher edge weights represent higher action costs. However, edge weights only provide soft guidance. An edge with a high weight only discourages agents from using it, instead of prohibiting agents from traversing it. In this paper, we explore the need to incorporate edge directions optimization into GGO, providing strict guidance. We generalize GGO to Mixed Guidance Graph Optimization (MGGO), presenting two MGGO methods capable of optimizing both edge weights and directions. The first optimizes edge directions and edge weights in two phases separately. The second applies Quality Diversity algorithms to optimize a neural network capable of generating edge directions and weights. We also incorporate traffic patterns relevant to edge directions into a GGO method, making it capable of generating edge-direction-aware guidance graphs.","authors":["Yulun Zhang","Varun Bhatt","Matthew C. Fontaine","Stefanos Nikolaidis","Jiaoyang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23457v1","updated":"2026-02-26T19:21:29Z","published":"2026-02-26T19:21:29Z","title":"Printed helicoids with embedded air channels make sensorized segments for soft continuum robots","summary":"Soft robots enable safe, adaptive interaction with complex environments but remain difficult to sense and control due to their highly deformable structures. Architected soft materials such as helicoid lattices offer tunable stiffness and strength but are challenging to instrument because of their sparse geometry. We introduce a fabrication method for embedding air channels into helicoid-based soft continuum robots. Multi-material segments fabricated via vision-controlled jetting in a single print interface with PCBs housing miniature pressure sensors and IMUs for distributed deformation sensing. We characterize the mechanical properties of four helicoid designs and validate the sensor response to fundamental deformation modes. To demonstrate the platform's scalability, we construct and mechanically evaluate a meter-scale, 14-DoF cable-driven soft arm capable of open-loop trajectory tracking and object grasping, with tactile-based stiffness detection demonstrated using the gripper sensors. This approach establishes a scalable fabrication strategy for sensorized architected materials in large-scale soft robotic systems.","authors":["Annan Zhang","Hanna Matusik","Miguel Flores-Acton","Emily R. Sologuren","Joshua Jacob","Daniela Rus"],"pdf_url":"","comment":"Accepted for publication in the proceedings of the 2026 IEEE 9th International Conference on Soft Robotics (RoboSoft)"},{"id":"http://arxiv.org/abs/2602.23408v1","updated":"2026-02-26T13:32:41Z","published":"2026-02-26T13:32:41Z","title":"Demystifying Action Space Design for Robotic Manipulation Policies","summary":"The specification of the action space plays a pivotal role in imitation-based robotic manipulation policy learning, fundamentally shaping the optimization landscape of policy learning. While recent advances have focused heavily on scaling training data and model capacity, the choice of action space remains guided by ad-hoc heuristics or legacy designs, leading to an ambiguous understanding of robotic policy design philosophies. To address this ambiguity, we conducted a large-scale and systematic empirical study, confirming that the action space does have significant and complex impacts on robotic policy learning. We dissect the action design space along temporal and spatial axes, facilitating a structured analysis of how these choices govern both policy learnability and control stability. Based on 13,000+ real-world rollouts on a bimanual robot and evaluation on 500+ trained models over four scenarios, we examine the trade-offs between absolute vs. delta representations, and joint-space vs. task-space parameterizations. Our large-scale results suggest that properly designing the policy to predict delta actions consistently improves performance, while joint-space and task-space representations offer complementary strengths, favoring control stability and generalization, respectively.","authors":["Yuchun Feng","Jinliang Zheng","Zhihao Wang","Dongxiu Liu","Jianxiong Li","Jiangmiao Pang","Tai Wang","Xianyuan Zhan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23404v1","updated":"2026-02-26T11:56:28Z","published":"2026-02-26T11:56:28Z","title":"Cybersecurity of Teleoperated Quadruped Robots: A Systematic Survey of Vulnerabilities, Threats, and Open Defense Gaps","summary":"Teleoperated quadruped robots are increasingly deployed in safety-critical missions -- industrial inspection, military reconnaissance, and emergency response -- yet the security of their communication and control infrastructure remains insufficiently characterized. Quadrupeds present distinct security challenges arising from dynamic stability constraints, gait-dependent vulnerability windows, substantial kinetic energy, and elevated operator cognitive load.\n  This survey synthesizes peer-reviewed literature and vulnerability disclosures (2019--2025) to provide comprehensive analysis of cybersecurity threats, consequences, and countermeasures for teleoperated quadruped systems. We contribute: (i) a six-layer attack taxonomy spanning perception manipulation, VR/AR operator targeting, communication disruption, control signal attacks, localization spoofing, and network intrusion; (ii) systematic attack-to-consequence mapping with timing characterization; (iii) Technology Readiness Level classification exposing critical maturity gaps between field-deployed communication protections (TRL 7--9) and experimental perception/operator-layer defenses (TRL 3--5); (iv) comparative security analysis of six commercial platforms; (v) pragmatic deployment guidance stratified by implementation timeline; and (vi) eight prioritized research gaps with implementation roadmaps.\n  Limitations: Platform assessments rely on publicly available information. Attack success rates derive from cited studies under controlled conditions and require domain-specific validation.","authors":["Mohammad Sabouri"],"pdf_url":"","comment":"survey paper; 23 tables; 9 figures; 132 references"}]},"2026-02-27T00:00:00Z":{"Artificial Intelligence (Agents & Multi-Agent Systems)":[{"id":"http://arxiv.org/abs/2602.24288v1","updated":"2026-02-27T18:58:57Z","published":"2026-02-27T18:58:57Z","title":"DARE-bench: Evaluating Modeling and Instruction Fidelity of LLMs in Data Science","summary":"The fast-growing demands in using Large Language Models (LLMs) to tackle complex multi-step data science tasks create an emergent need for accurate benchmarking. There are two major gaps in existing benchmarks: (i) the lack of standardized, process-aware evaluation that captures instruction adherence and process fidelity, and (ii) the scarcity of accurately labeled training data. To bridge these gaps, we introduce DARE-bench, a benchmark designed for machine learning modeling and data science instruction following. Unlike many existing benchmarks that rely on human- or model-based judges, all tasks in DARE-bench have verifiable ground truth, ensuring objective and reproducible evaluation. To cover a broad range of tasks and support agentic tools, DARE-bench consists of 6,300 Kaggle-derived tasks and provides both large-scale training data and evaluation sets. Extensive evaluations show that even highly capable models such as gpt-o4-mini struggle to achieve good performance, especially in machine learning modeling tasks. Using DARE-bench training tasks for fine-tuning can substantially improve model performance. For example, supervised fine-tuning boosts Qwen3-32B's accuracy by 1.83x and reinforcement learning boosts Qwen3-4B's accuracy by more than 8x. These significant improvements verify the importance of DARE-bench both as an accurate evaluation benchmark and critical training data.","authors":["Fan Shu","Yite Wang","Ruofan Wu","Boyi Liu","Zhewei Yao","Yuxiong He","Feng Yan"],"pdf_url":"","comment":"Published as a conference paper at ICLR 2026. 10 pages plus appendix"},{"id":"http://arxiv.org/abs/2602.24287v1","updated":"2026-02-27T18:58:26Z","published":"2026-02-27T18:58:26Z","title":"Do LLMs Benefit From Their Own Words?","summary":"Multi-turn interactions with large language models typically retain the assistant's own past responses in the conversation history. In this work, we revisit this design choice by asking whether large language models benefit from conditioning on their own prior responses. Using in-the-wild, multi-turn conversations, we compare standard (full-context) prompting with a user-turn-only prompting approach that omits all previous assistant responses, across three open reasoning models and one state-of-the-art model. To our surprise, we find that removing prior assistant responses does not affect response quality on a large fraction of turns. Omitting assistant-side history can reduce cumulative context lengths by up to 10x. To explain this result, we find that multi-turn conversations consist of a substantial proportion (36.4%) of self-contained prompts, and that many follow-up prompts provide sufficient instruction to be answered using only the current user turn and prior user turns. When analyzing cases where user-turn-only prompting substantially outperforms full context, we identify instances of context pollution, in which models over-condition on their previous responses, introducing errors, hallucinations, or stylistic artifacts that propagate across turns. Motivated by these findings, we design a context-filtering approach that selectively omits assistant-side context. Our findings suggest that selectively omitting assistant history can improve response quality while reducing memory consumption.","authors":["Jenny Y. Huang","Leshem Choshen","Ramon Astudillo","Tamara Broderick","Jacob Andreas"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24286v1","updated":"2026-02-27T18:58:05Z","published":"2026-02-27T18:58:05Z","title":"CUDA Agent: Large-Scale Agentic RL for High-Performance CUDA Kernel Generation","summary":"GPU kernel optimization is fundamental to modern deep learning but remains a highly specialized task requiring deep hardware expertise. Despite strong performance in general programming, large language models (LLMs) remain uncompetitive with compiler-based systems such as torch.compile for CUDA kernel generation. Existing CUDA code generation approaches either rely on training-free refinement or fine-tune models within fixed multi-turn execution-feedback loops, but both paradigms fail to fundamentally improve the model's intrinsic CUDA optimization ability, resulting in limited performance gains. We present CUDA Agent, a large-scale agentic reinforcement learning system that develops CUDA kernel expertise through three components: a scalable data synthesis pipeline, a skill-augmented CUDA development environment with automated verification and profiling to provide reliable reward signals, and reinforcement learning algorithmic techniques enabling stable training. CUDA Agent achieves state-of-the-art results on KernelBench, delivering 100\\%, 100\\%, and 92\\% faster rate over torch.compile on KernelBench Level-1, Level-2, and Level-3 splits, outperforming the strongest proprietary models such as Claude Opus 4.5 and Gemini 3 Pro by about 40\\% on the hardest Level-3 setting.","authors":["Weinan Dai","Hanlin Wu","Qiying Yu","Huan-ang Gao","Jiahao Li","Chengquan Jiang","Weiqiang Lou","Yufan Song","Hongli Yu","Jiaze Chen","Wei-Ying Ma","Ya-Qin Zhang","Jingjing Liu","Mingxuan Wang","Xin Liu","Hao Zhou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24283v1","updated":"2026-02-27T18:57:06Z","published":"2026-02-27T18:57:06Z","title":"Taming Momentum: Rethinking Optimizer States Through Low-Rank Approximation","summary":"Modern optimizers like Adam and Muon are central to training large language models, but their reliance on first- and second-order momenta introduces significant memory overhead, which constrains scalability and computational efficiency. In this work, we reframe the exponential moving average (EMA) used in these momenta as the training of a linear regressor via online gradient flow. Building on this equivalence, we introduce LoRA-Pre, a novel low-rank optimizer designed for efficient pre-training. Specifically, LoRA-Pre reduces the optimizer's memory footprint by decomposing the full momentum matrix into a compact low-rank subspace within the online linear learner, thereby maintaining optimization performance while improving memory efficiency. We empirically validate LoRA-Pre's efficacy by pre-training models from the Llama architecture family, scaling from 60M to 1B parameters. LoRA-Pre achieves the highest performance across all model sizes. Notably, LoRA-Pre demonstrates remarkable rank efficiency, achieving comparable or superior results using only 1/8 the rank of baseline methods. Beyond pre-training, we evaluate LoRA-Pre's effectiveness in fine-tuning scenarios. With the same rank, LoRA-Pre consistently outperforms all efficient fine-tuning baselines. Specifically, compared to standard LoRA, LoRA-Pre achieves substantial improvements of 3.14 points on Llama-3.1-8B and 6.17 points on Llama-2-7B, validating our approach's effectiveness across both pre-training and fine-tuning paradigms. Our code is publicly available at https://github.com/mrflogs/LoRA-Pre.","authors":["Zhengbo Wang","Jian Liang","Ran He","Zilei Wang","Tieniu Tan"],"pdf_url":"","comment":"Camera-ready version. Accepted as Oral at ICLR 2026"},{"id":"http://arxiv.org/abs/2512.05049v2","updated":"2026-02-27T18:55:13Z","published":"2025-12-04T18:03:23Z","title":"QKAN-LSTM: Quantum-inspired Kolmogorov-Arnold Long Short-term Memory","summary":"Long short-term memory (LSTM) models are a particular type of recurrent neural networks (RNNs) that are central to sequential modeling tasks in domains such as urban telecommunication forecasting, where temporal correlations and nonlinear dependencies dominate. However, conventional LSTMs suffer from high parameter redundancy and limited nonlinear expressivity. In this work, we propose the Quantum-inspired Kolmogorov-Arnold Long Short-Term Memory (QKAN-LSTM), which integrates Data Re-Uploading Activation (DARUAN) modules into the gating structure of LSTMs. Each DARUAN acts as a quantum variational activation function (QVAF), enhancing frequency adaptability and enabling an exponentially enriched spectral representation without multi-qubit entanglement. The resulting architecture preserves quantum-level expressivity while remaining fully executable on classical hardware. Empirical evaluations on three datasets, Damped Simple Harmonic Motion, Bessel Function, and Urban Telecommunication, demonstrate that QKAN-LSTM achieves superior predictive accuracy and generalization with a 79% reduction in trainable parameters compared to classical LSTMs. We extend the framework to the Jiang-Huang-Chen-Goan Network (JHCG Net), which generalizes KAN to encoder-decoder structures, and then further use QKAN to realize the latent KAN, thereby creating a Hybrid QKAN (HQKAN) for hierarchical representation learning. The proposed HQKAN-LSTM thus provides a scalable and interpretable pathway toward quantum-inspired sequential modeling in real-world data environments.","authors":["Yu-Chao Hsu","Jiun-Cheng Jiang","Chun-Hua Lin","Kuo-Chung Peng","Nan-Yow Chen","Samuel Yen-Chi Chen","En-Jui Kuo","Hsi-Sheng Goan"],"pdf_url":"","comment":"10 pages. Camera-ready version for IEEE International Conference on Quantum Communications, Networking, and Computing (QCNC), 2026"},{"id":"http://arxiv.org/abs/2602.24281v1","updated":"2026-02-27T18:53:41Z","published":"2026-02-27T18:53:41Z","title":"Memory Caching: RNNs with Growing Memory","summary":"Transformers have been established as the de-facto backbones for most recent advances in sequence modeling, mainly due to their growing memory capacity that scales with the context length. While plausible for retrieval tasks, it causes quadratic complexity and so has motivated recent studies to explore viable subquadratic recurrent alternatives. Despite showing promising preliminary results in diverse domains, such recurrent architectures underperform Transformers in recall-intensive tasks, often attributed to their fixed-size memory. In this paper, we introduce Memory Caching (MC), a simple yet effective technique that enhances recurrent models by caching checkpoints of their memory states (a.k.a. hidden states). Memory Caching allows the effective memory capacity of RNNs to grow with sequence length, offering a flexible trade-off that interpolates between the fixed memory (i.e., $O(L)$ complexity) of RNNs and the growing memory (i.e., $O(L^2)$ complexity) of Transformers. We propose four variants of MC, including gated aggregation and sparse selective mechanisms, and discuss their implications on both linear and deep memory modules. Our experimental results on language modeling, and long-context understanding tasks show that MC enhances the performance of recurrent models, supporting its effectiveness. The results of in-context recall tasks indicate that while Transformers achieve the best accuracy, our MC variants show competitive performance, close the gap with Transformers, and performs better than state-of-the-art recurrent models.","authors":["Ali Behrouz","Zeman Li","Yuan Deng","Peilin Zhong","Meisam Razaviyayn","Vahab Mirrokni"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24277v1","updated":"2026-02-27T18:49:31Z","published":"2026-02-27T18:49:31Z","title":"Resources for Automated Evaluation of Assistive RAG Systems that Help Readers with News Trustworthiness Assessment","summary":"Many readers today struggle to assess the trustworthiness of online news because reliable reporting coexists with misinformation. The TREC 2025 DRAGUN (Detection, Retrieval, and Augmented Generation for Understanding News) Track provided a venue for researchers to develop and evaluate assistive RAG systems that support readers' news trustworthiness assessment by producing reader-oriented, well-attributed reports. As the organizers of the DRAGUN track, we describe the resources that we have newly developed to allow for the reuse of the track's tasks. The track had two tasks: (Task 1) Question Generation, producing 10 ranked investigative questions; and (Task 2, the main task) Report Generation, producing a 250-word report grounded in the MS MARCO V2.1 Segmented Corpus. As part of the track's evaluation, we had TREC assessors create importance-weighted rubrics of questions with expected short answers for 30 different news articles. These rubrics represent the information that assessors believe is important for readers to assess an article's trustworthiness. The assessors then used their rubrics to manually judge the participating teams' submitted runs. To make these tasks and their rubrics reusable, we have created an automated process to judge runs not part of the original assessing. We show that our AutoJudge ranks existing runs well compared to the TREC human-assessed evaluation (Kendall's $τ= 0.678$ for Task 1 and $τ= 0.872$ for Task 2). These resources enable both the evaluation of RAG systems for assistive news trustworthiness assessment and, with the human evaluation as a benchmark, research on improving automated RAG evaluation.","authors":["Dake Zhang","Mark D. Smucker","Charles L. A. Clarke"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22401v2","updated":"2026-02-27T18:49:27Z","published":"2026-02-25T20:52:14Z","title":"Vibe Researching as Wolf Coming: Can AI Agents with Skills Replace or Augment Social Scientists?","summary":"AI agents -- systems that execute multi-step reasoning workflows with persistent state, tool access, and specialist skills -- represent a qualitative shift from prior automation technologies in social science. Unlike chatbots that respond to isolated queries, AI agents can now read files, run code, query databases, search the web, and invoke domain-specific skills to execute entire research pipelines autonomously. This paper introduces the concept of vibe researching -- the AI-era parallel to vibe coding (Karpathy, 2025) -- and uses scholar-skill, a 23-skill plugin for Claude Code covering the full research pipeline from idea to submission, as an illustrative case. I develop a cognitive task framework that classifies research activities along two dimensions -- codifiability and tacit knowledge requirement -- to identify a delegation boundary that is cognitive, not sequential: it cuts through every stage of the research pipeline, not between stages. I argue that AI agents excel at speed, coverage, and methodological scaffolding but struggle with theoretical originality and tacit field knowledge. The paper concludes with an analysis of three implications for the profession -- augmentation with fragile conditions, stratification risk, and a pedagogical crisis -- and proposes five principles for responsible vibe researching.","authors":["Yongjun Zhang"],"pdf_url":"","comment":"Commentary"},{"id":"http://arxiv.org/abs/2602.24273v1","updated":"2026-02-27T18:43:47Z","published":"2026-02-27T18:43:47Z","title":"A Minimal Agent for Automated Theorem Proving","summary":"We propose a minimal agentic baseline that enables systematic comparison across different AI-based theorem prover architectures. This design implements the core features shared among state-of-the-art systems: iterative proof refinement, library search and context management. We evaluate our baseline using qualitatively different benchmarks and compare various popular models and design choices, and demonstrate competitive performance compared to state-of-the-art approaches, while using a significantly simpler architecture. Our results demonstrate consistent advantages of an iterative approach over multiple single-shot generations, especially in terms of sample efficiency and cost effectiveness. The implementation is released open-source as a candidate reference for future research and as an accessible prover for the community.","authors":["Borja Requena Pozo","Austin Letson","Krystian Nowakowski","Izan Beltran Ferreiro","Leopoldo Sarra"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24266v1","updated":"2026-02-27T18:35:10Z","published":"2026-02-27T18:35:10Z","title":"Efficient Discovery of Approximate Causal Abstractions via Neural Mechanism Sparsification","summary":"Neural networks are hypothesized to implement interpretable causal mechanisms, yet verifying this requires finding a causal abstraction -- a simpler, high-level Structural Causal Model (SCM) faithful to the network under interventions. Discovering such abstractions is hard: it typically demands brute-force interchange interventions or retraining. We reframe the problem by viewing structured pruning as a search over approximate abstractions. Treating a trained network as a deterministic SCM, we derive an Interventional Risk objective whose second-order expansion yields closed-form criteria for replacing units with constants or folding them into neighbors. Under uniform curvature, our score reduces to activation variance, recovering variance-based pruning as a special case while clarifying when it fails. The resulting procedure efficiently extracts sparse, intervention-faithful abstractions from pretrained networks, which we validate via interchange interventions.","authors":["Amir Asiaee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24254v1","updated":"2026-02-27T18:28:12Z","published":"2026-02-27T18:28:12Z","title":"FaultXformer: A Transformer-Encoder Based Fault Classification and Location Identification model in PMU-Integrated Active Electrical Distribution System","summary":"Accurate fault detection and localization in electrical distribution systems is crucial, especially with the increasing integration of distributed energy resources (DERs), which inject greater variability and complexity into grid operations. In this study, FaultXformer is proposed, a Transformer encoder-based architecture developed for automatic fault analysis using real-time current data obtained from phasor measurement unit (PMU). The approach utilizes time-series current data to initially extract rich temporal information in stage 1, which is crucial for identifying the fault type and precisely determining its location across multiple nodes. In Stage 2, these extracted features are processed to differentiate among distinct fault types and identify the respective fault location within the distribution system. Thus, this dual-stage transformer encoder pipeline enables high-fidelity representation learning, considerably boosting the performance of the work. The model was validated on a dataset generated from the IEEE 13-node test feeder, simulated with 20 separate fault locations and several DER integration scenarios, utilizing current measurements from four strategically located PMUs. To demonstrate robust performance evaluation, stratified 10-fold cross-validation is performed. FaultXformer achieved average accuracies of 98.76% in fault type classification and 98.92% in fault location identification across cross-validation, consistently surpassing conventional deep learning baselines convolutional neural network (CNN), recurrent neural network (RNN). long short-term memory (LSTM) by 1.70%, 34.95%, and 2.04% in classification accuracy and by 10.82%, 40.89%, and 6.27% in location accuracy, respectively. These results demonstrate the efficacy of the proposed model with significant DER penetration.","authors":["Kriti Thakur","Alivelu Manga Parimi","Mayukha Pal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2507.02861v2","updated":"2026-02-27T18:27:47Z","published":"2025-07-03T17:59:55Z","title":"LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans","summary":"We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor environments into compact, realistic, and interactive 3D virtual replicas. LiteReality not only reconstructs scenes that visually resemble reality but also supports key features essential for graphics pipelines -- such as object individuality, articulation, high-quality physically based rendering materials, and physically based interaction. At its core, LiteReality first performs scene understanding and parses the results into a coherent 3D layout and objects with the help of a structured scene graph. It then reconstructs the scene by retrieving the most visually similar 3D artist-crafted models from a curated asset database. Next, the Material Painting module enhances realism by recovering high-quality, spatially varying materials. Finally, the reconstructed scene is integrated into a simulation engine with basic physical properties to enable interactive behavior. The resulting scenes are compact, editable, and fully compatible with standard graphics pipelines, making them suitable for applications in AR/VR, gaming, robotics, and digital twins. In addition, LiteReality introduces a training-free object retrieval module that achieves state-of-the-art similarity performance on the Scan2CAD benchmark, along with a robust material painting module capable of transferring appearances from images of any style to 3D assets -- even under severe misalignment, occlusion, and poor lighting. We demonstrate the effectiveness of LiteReality on both real-life scans and public datasets. Project page: https://litereality.github.io; Video: https://www.youtube.com/watch?v=ecK9m3LXg2c","authors":["Zhening Huang","Xiaoyang Wu","Fangcheng Zhong","Hengshuang Zhao","Matthias Nießner","Joan Lasenby"],"pdf_url":"","comment":"Project Page: https://litereality.github.io; Video: https://www.youtube.com/watch?v=ecK9m3LXg2c&feature=youtu.be Camera-Ready Version"},{"id":"http://arxiv.org/abs/2602.10117v4","updated":"2026-02-27T18:13:41Z","published":"2026-02-10T18:59:56Z","title":"Biases in the Blind Spot: Detecting What LLMs Fail to Mention","summary":"Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipeline for detecting task-specific unverbalized biases. Given a task dataset, the pipeline uses LLM autoraters to generate candidate bias concepts. It then tests each concept on progressively larger input samples by generating positive and negative variations, and applies statistical techniques for multiple testing and early stopping. A concept is flagged as an unverbalized bias if it yields statistically significant performance differences while not being cited as justification in the model's CoTs. We evaluate our pipeline across seven LLMs on three decision tasks (hiring, loan approval, and university admissions). Our technique automatically discovers previously unknown biases in these models (e.g., Spanish fluency, English proficiency, writing formality). In the same run, the pipeline also validates biases that were manually identified by prior work (gender, race, religion, ethnicity). More broadly, our proposed approach provides a practical, scalable path to automatic task-specific bias discovery.","authors":["Iván Arcuschin","David Chanin","Adrià Garriga-Alonso","Oana-Maria Camburu"],"pdf_url":"","comment":"11 pages"},{"id":"http://arxiv.org/abs/2602.24235v1","updated":"2026-02-27T18:06:10Z","published":"2026-02-27T18:06:10Z","title":"SafeGen-LLM: Enhancing Safety Generalization in Task Planning for Robotic Systems","summary":"Safety-critical task planning in robotic systems remains challenging: classical planners suffer from poor scalability, Reinforcement Learning (RL)-based methods generalize poorly, and base Large Language Models (LLMs) cannot guarantee safety. To address this gap, we propose safety-generalizable large language models, named SafeGen-LLM. SafeGen-LLM can not only enhance the safety satisfaction of task plans but also generalize well to novel safety properties in various domains. We first construct a multi-domain Planning Domain Definition Language 3 (PDDL3) benchmark with explicit safety constraints. Then, we introduce a two-stage post-training framework: Supervised Fine-Tuning (SFT) on a constraint-compliant planning dataset to learn planning syntax and semantics, and Group Relative Policy Optimization (GRPO) guided by fine-grained reward machines derived from formal verification to enforce safety alignment and by curriculum learning to better handle complex tasks. Extensive experiments show that SafeGen-LLM achieves strong safety generalization and outperforms frontier proprietary baselines across multi-domain planning tasks and multiple input formats (e.g., PDDLs and natural language).","authors":["Jialiang Fan","Weizhe Xu","Mengyu Liu","Oleg Sokolsky","Insup Lee","Fangxin Kong"],"pdf_url":"","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.24210v1","updated":"2026-02-27T17:39:10Z","published":"2026-02-27T17:39:10Z","title":"Controllable Reasoning Models Are Private Thinkers","summary":"AI agents powered by reasoning models require access to sensitive user data. However, their reasoning traces are difficult to control, which can result in the unintended leakage of private information to external parties. We propose training models to follow instructions not only in the final answer, but also in reasoning traces, potentially under different constraints. We hypothesize that improving their instruction following abilities in the reasoning traces can improve their privacy-preservation skills. To demonstrate this, we fine-tune models on a new instruction-following dataset with explicit restrictions on reasoning traces. We further introduce a generation strategy that decouples reasoning and answer generation using separate LoRA adapters. We evaluate our approach on six models from two model families, ranging from 1.7B to 14B parameters, across two instruction-following benchmarks and two privacy benchmarks. Our method yields substantial improvements, achieving gains of up to 20.9 points in instruction-following performance and up to 51.9 percentage points on privacy benchmarks. These improvements, however, can come at the cost of task utility, due to the trade-off between reasoning performance and instruction-following abilities. Overall, our results show that improving instruction-following behavior in reasoning models can significantly enhance privacy, suggesting a promising direction for the development of future privacy-aware agents. Our code and data are available at https://github.com/UKPLab/arxiv2026-controllable-reasoning-models","authors":["Haritz Puerto","Haonan Li","Xudong Han","Timothy Baldwin","Iryna Gurevych"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24209v1","updated":"2026-02-27T17:39:04Z","published":"2026-02-27T17:39:04Z","title":"An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks","summary":"Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.","authors":["Mohsen Tajgardan","Atena Shiranzaei","Mahdi Rabbani","Reza Khoshkangini","Mahtab Jamali"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.05930v2","updated":"2026-02-27T17:23:59Z","published":"2025-10-07T13:41:33Z","title":"Carré du champ flow matching: better quality-generalisation tradeoff in generative models","summary":"Deep generative models often face a fundamental tradeoff: high sample quality can come at the cost of memorisation, where the model reproduces training data rather than generalising across the underlying data geometry. We introduce Carré du champ flow matching (CDC-FM), a generalisation of flow matching (FM), that improves the quality-generalisation tradeoff by regularising the probability path with a geometry-aware noise. Our method replaces the homogeneous, isotropic noise in FM with a spatially varying, anisotropic Gaussian noise whose covariance captures the local geometry of the latent data manifold. We prove that this geometric noise can be optimally estimated from the data and is scalable to large data. Further, we provide an extensive experimental evaluation on diverse datasets (synthetic manifolds, point clouds, single-cell genomics, animal motion capture, and images) as well as various neural network architectures (MLPs, CNNs, and transformers). We demonstrate that CDC-FM consistently offers a better quality-generalisation tradeoff. We observe significant improvements over standard FM in data-scarce regimes and in highly non-uniformly sampled datasets, which are often encountered in AI for science applications. Our work provides a mathematical framework for studying the interplay between data geometry, generalisation and memorisation in generative models, as well as a robust and scalable algorithm that can be readily integrated into existing flow matching pipelines.","authors":["Jacob Bamberger","Iolo Jones","Dennis Duncan","Michael M. Bronstein","Pierre Vandergheynst","Adam Gosztolai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24195v1","updated":"2026-02-27T17:18:42Z","published":"2026-02-27T17:18:42Z","title":"Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume","summary":"Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.","authors":["Gregory Kang Ruey Lau","Hieu Dao","Nicole Kan Hui Lin","Bryan Kian Hsiang Low"],"pdf_url":"","comment":"Earlier versions presented at ICLR 2025 QUESTION workshop and ICML 2025 R2-FM workshop"},{"id":"http://arxiv.org/abs/2602.24191v1","updated":"2026-02-27T17:15:49Z","published":"2026-02-27T17:15:49Z","title":"Resilient Strategies for Stochastic Systems: How Much Does It Take to Break a Winning Strategy?","summary":"We study the problem of resilient strategies in the presence of uncertainty. Resilient strategies enable an agent to make decisions that are robust against disturbances. In particular, we are interested in those disturbances that are able to flip a decision made by the agent. Such a disturbance may, for instance, occur when the intended action of the agent cannot be executed due to a malfunction of an actuator in the environment. In this work, we introduce the concept of resilience in the stochastic setting and present a comprehensive set of fundamental problems. Specifically, we discuss such problems for Markov decision processes with reachability and safety objectives, which also smoothly extend to stochastic games. To account for the stochastic setting, we provide various ways of aggregating the amounts of disturbances that may have occurred, for instance, in expectation or in the worst case. Moreover, to reason about infinite disturbances, we use quantitative measures, like their frequency of occurrence.","authors":["Kush Grover","Markel Zubia","Debraj Chakraborty","Muqsit Azeem","Nils Jansen","Jan Kretinsky"],"pdf_url":"","comment":"To appear in Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), Paphos, Cyprus, May 25-29, 2026"},{"id":"http://arxiv.org/abs/2602.22291v2","updated":"2026-02-27T17:04:02Z","published":"2026-02-25T15:08:20Z","title":"Manifold of Failure: Behavioral Attraction Basins in Language Models","summary":"While prior work has focused on projecting adversarial examples back onto the manifold of natural data to restore safety, we argue that a comprehensive understanding of AI safety requires characterizing the unsafe regions themselves. This paper introduces a framework for systematically mapping the Manifold of Failure in Large Language Models (LLMs). We reframe the search for vulnerabilities as a quality diversity problem, using MAP-Elites to illuminate the continuous topology of these failure regions, which we term behavioral attraction basins. Our quality metric, Alignment Deviation, guides the search towards areas where the model's behavior diverges most from its intended alignment. Across three LLMs: Llama-3-8B, GPT-OSS-20B, and GPT-5-Mini, we show that MAP-Elites achieves up to 63% behavioral coverage, discovers up to 370 distinct vulnerability niches, and reveals dramatically different model-specific topological signatures: Llama-3-8B exhibits a near-universal vulnerability plateau (mean Alignment Deviation 0.93), GPT-OSS-20B shows a fragmented landscape with spatially concentrated basins (mean 0.73), and GPT-5-Mini demonstrates strong robustness with a ceiling at 0.50. Our approach produces interpretable, global maps of each model's safety landscape that no existing attack method (GCG, PAIR, or TAP) can provide, shifting the paradigm from finding discrete failures to understanding their underlying structure.","authors":["Sarthak Munshi","Manish Bhatt","Vineeth Sai Narajala","Idan Habler","Ammar Al-Kahfah","Ken Huang","Blake Gatto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24181v1","updated":"2026-02-27T17:03:45Z","published":"2026-02-27T17:03:45Z","title":"A Mixed Diet Makes DINO An Omnivorous Vision Encoder","summary":"Pre-trained vision encoders like DINOv2 have demonstrated exceptional performance on unimodal tasks. However, we observe that their feature representations are poorly aligned across different modalities. For instance, the feature embedding for an RGB image and its corresponding depth map of the same scene exhibit a cosine similarity that is nearly identical to that of two random, unrelated images. To address this, we propose the Omnivorous Vision Encoder, a novel framework that learns a modality-agnostic feature space. We train the encoder with a dual objective: first, to maximize the feature alignment between different modalities of the same scene; and second, a distillation objective that anchors the learned representations to the output of a fully frozen teacher such as DINOv2. The resulting student encoder becomes \"omnivorous\" by producing a consistent, powerful embedding for a given scene, regardless of the input modality (RGB, Depth, Segmentation, etc.). This approach enables robust cross-modal understanding while retaining the discriminative semantics of the original foundation model.","authors":["Rishabh Kabra","Maks Ovsjanikov","Drew A. Hudson","Ye Xia","Skanda Koppula","Andre Araujo","Joao Carreira","Niloy J. Mitra"],"pdf_url":"","comment":"CVPR 2026"},{"id":"http://arxiv.org/abs/2602.24180v1","updated":"2026-02-27T17:03:34Z","published":"2026-02-27T17:03:34Z","title":"Learning Flexible Job Shop Scheduling under Limited Buffers and Material Kitting Constraints","summary":"The Flexible Job Shop Scheduling Problem (FJSP) originates from real production lines, while some practical constraints are often ignored or idealized in current FJSP studies, among which the limited buffer problem has a particular impact on production efficiency. To this end, we study an extended problem that is closer to practical scenarios--the Flexible Job Shop Scheduling Problem with Limited Buffers and Material Kitting. In recent years, deep reinforcement learning (DRL) has demonstrated considerable potential in scheduling tasks. However, its capacity for state modeling remains limited when handling complex dependencies and long-term constraints. To address this, we leverage a heterogeneous graph network within the DRL framework to model the global state. By constructing efficient message passing among machines, operations, and buffers, the network focuses on avoiding decisions that may cause frequent pallet changes during long-sequence scheduling, thereby helping improve buffer utilization and overall decision quality. Experimental results on both synthetic and real production line datasets show that the proposed method outperforms traditional heuristics and advanced DRL methods in terms of makespan and pallet changes, and also achieves a good balance between solution quality and computational cost. Furthermore, a supplementary video is provided to showcase a simulation system that effectively visualizes the progression of the production line.","authors":["Shishun Zhang","Juzhan Xu","Yidan Fan","Chenyang Zhu","Ruizhen Hu","Yongjun Wang","Kai Xu"],"pdf_url":"","comment":"8 pages, 8 figures, conference"},{"id":"http://arxiv.org/abs/2507.19364v2","updated":"2026-02-27T17:03:14Z","published":"2025-07-25T15:15:35Z","title":"Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges","summary":"This position paper examines the use of Large Language Models (LLMs) in social simulation, analyzing their potential and limitations from a computational social science perspective. We first review recent findings on LLMs' ability to replicate key aspects of human cognition, including Theory of Mind reasoning and social inference, while identifying persistent limitations such as cognitive biases, lack of grounded understanding, and behavioral inconsistencies. We then survey emerging applications of LLMs in multi-agent simulation frameworks, examining system architectures, scalability, and validation strategies. Projects such as Generative Agents (Smallville) and AgentSociety are analyzed with respect to their empirical grounding and methodological design. Particular attention is given to the challenges of behavioral fidelity, calibration, and reproducibility in large-scale LLM-driven simulations. Finally, we distinguish between contexts where LLM-based agents provide operational value-such as interactive simulations and serious games-and contexts where their use raises epistemic concerns, particularly in explanatory or predictive modeling. We argue that hybrid approaches integrating LLMs into established agent-based modeling platforms such as GAMA and NetLogo may offer a promising compromise between expressive flexibility and analytical transparency. Building on this analysis, we outline a conceptual research direction termed Hybrid Constitutional Architectures, which proposes a stratified integration of classical agent-based models (ABMs), small language models (SLMs), and LLMs within established platforms such as GAMA and NetLogo.","authors":["Patrick Taillandier","Jean Daniel Zucker","Arnaud Grignard","Benoit Gaudou","Nghi Quang Huynh","Alexis Drogoul"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.15477v4","updated":"2026-02-27T17:00:32Z","published":"2025-03-19T17:54:41Z","title":"What Makes a Reward Model a Good Teacher? An Optimization Perspective","summary":"The success of Reinforcement Learning from Human Feedback (RLHF) critically depends on the quality of the reward model. However, while this quality is primarily evaluated through accuracy, it remains unclear whether accuracy fully captures what makes a reward model an effective teacher. We address this question from an optimization perspective. First, we prove that regardless of how accurate a reward model is, if it induces low reward variance, then the RLHF objective suffers from a flat landscape. Consequently, even a perfectly accurate reward model can lead to extremely slow optimization, underperforming less accurate models that induce higher reward variance. We additionally show that a reward model that works well for one language model can induce low reward variance, and thus a flat objective landscape, for another. These results establish a fundamental limitation of evaluating reward models solely based on accuracy or independently of the language model they guide. Experiments using models of up to 8B parameters corroborate our theory, demonstrating the interplay between reward variance, accuracy, and reward maximization rate. Overall, our findings highlight that beyond accuracy, a reward model needs to induce sufficient variance for efficient optimization.","authors":["Noam Razin","Zixuan Wang","Hubert Strauss","Stanley Wei","Jason D. Lee","Sanjeev Arora"],"pdf_url":"","comment":"Accepted to NeurIPS 2025; Code available at https://github.com/princeton-pli/what-makes-good-rm"},{"id":"http://arxiv.org/abs/2602.24174v1","updated":"2026-02-27T16:55:22Z","published":"2026-02-27T16:55:22Z","title":"Task-Centric Acceleration of Small-Language Models","summary":"Small language models (SLMs) have emerged as efficient alternatives to large language models for task-specific applications. However, they are often employed in high-volume, low-latency settings, where efficiency is crucial. We propose TASC, Task-Adaptive Sequence Compression, a framework for SLM acceleration comprising two use-cases: When performing SLM fine-tuning, we propose TASC-ft, which iteratively enriches the tokenizer vocabulary with high-frequency output n-grams and then fine-tunes the model to utilize the expanded vocabulary. Next, we propose an inference-time method, termed TASC-spec. TASC-spec is a lightweight, training-free speculative decoding method that constructs an n-gram draft model from the task's output corpus, mixing task and context n-gram information.TASC-spec avoids any additional training, while bypassing draft-target vocabulary alignment constraints. We demonstrate the effectiveness of both methods across multiple low output-variability generation tasks. Our methods show consistent improvements in inference efficiency while maintaining task performance.","authors":["Dor Tsur","Sharon Adar","Ran Levy"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24173v1","updated":"2026-02-27T16:52:52Z","published":"2026-02-27T16:52:52Z","title":"LemmaBench: A Live, Research-Level Benchmark to Evaluate LLM Capabilities in Mathematics","summary":"We present a new approach for benchmarking Large Language Model (LLM) capabilities on research-level mathematics. Existing benchmarks largely rely on static, hand-curated sets of contest or textbook-style problems as proxies for mathematical research. Instead, we establish an updatable benchmark evaluating models directly on the latest research results in mathematics. This consists of an automatic pipeline that extracts lemmas from arXiv and rewrites them into self-contained statements by making all assumptions and required definitions explicit. It results in a benchmark that can be updated regularly with new problems taken directly from human mathematical research, while previous instances can be used for training without compromising future evaluations. We benchmark current state-of-the-art LLMs, which obtain around 10-15$\\%$ accuracy in theorem proving (pass@1) depending on the model, showing that there is currently a large margin of progression for LLMs to reach human-level proving capabilities in a research context.","authors":["Antoine Peyronnet","Fabian Gloeckle","Amaury Hayat"],"pdf_url":"","comment":"15 pages, 3 figures, 5 Tables"},{"id":"http://arxiv.org/abs/2602.24172v1","updated":"2026-02-27T16:52:27Z","published":"2026-02-27T16:52:27Z","title":"ArgLLM-App: An Interactive System for Argumentative Reasoning with Large Language Models","summary":"Argumentative LLMs (ArgLLMs) are an existing approach leveraging Large Language Models (LLMs) and computational argumentation for decision-making, with the aim of making the resulting decisions faithfully explainable to and contestable by humans. Here we propose a web-based system implementing ArgLLM-empowered agents for binary tasks. ArgLLM-App supports visualisation of the produced explanations and interaction with human users, allowing them to identify and contest any mistakes in the system's reasoning. It is highly modular and enables drawing information from trusted external sources. ArgLLM-App is publicly available at https://argllm.app, with a video demonstration at https://youtu.be/vzwlGOr0sPM.","authors":["Adam Dejl","Deniz Gorur","Francesca Toni"],"pdf_url":"","comment":"AAMAS 2026 Demonstration Track"},{"id":"http://arxiv.org/abs/2601.21961v2","updated":"2026-02-27T16:47:40Z","published":"2026-01-29T16:40:15Z","title":"How do Visual Attributes Influence Web Agents? A Comprehensive Evaluation of User Interface Design Factors","summary":"Web agents have demonstrated strong performance on a wide range of web-based tasks. However, existing research on the effect of environmental variation has mostly focused on robustness to adversarial attacks, with less attention to agents' preferences in benign scenarios. Although early studies have examined how textual attributes influence agent behavior, a systematic understanding of how visual attributes shape agent decision-making remains limited. To address this, we introduce VAF, a controlled evaluation pipeline for quantifying how webpage Visual Attribute Factors influence web-agent decision-making. Specifically, VAF consists of three stages: (i) variant generation, which ensures the variants share identical semantics as the original item while only differ in visual attributes; (ii) browsing interaction, where agents navigate the page via scrolling and clicking the interested item, mirroring how human users browse online; (iii) validating through both click action and reasoning from agents, which we use the Target Click Rate and Target Mention Rate to jointly evaluate the effect of visual attributes. By quantitatively measuring the decision-making difference between the original and variant, we identify which visual attributes influence agents' behavior most. Extensive experiments, across 8 variant families (48 variants total), 5 real-world websites (including shopping, travel, and news browsing), and 4 representative web agents, show that background color contrast, item size, position, and card clarity have a strong influence on agents' actions, whereas font styling, text color, and item image clarity exhibit minor effects.","authors":["Kuai Yu","Naicheng Yu","Han Wang","Rui Yang","Huan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2506.20640v3","updated":"2026-02-27T16:45:58Z","published":"2025-06-25T17:36:02Z","title":"CoMind: Towards Community-Driven Agents for Machine Learning Engineering","summary":"Large language model (LLM) agents show promise in automating machine learning (ML) engineering. However, existing agents typically operate in isolation on a given research problem, without engaging with the broader research community, where human researchers often gain insights and contribute by sharing knowledge. To bridge this gap, we introduce MLE-Live, a live evaluation framework designed to assess an agent's ability to communicate with and leverage collective knowledge from a simulated Kaggle research community. Building on this framework, we propose CoMind, a multi-agent system designed to systematically leverage external knowledge. CoMind employs an iterative parallel exploration mechanism, developing multiple solutions simultaneously to balance exploratory breadth with implementation depth. On 75 past Kaggle competitions within our MLE-Live framework, CoMind achieves a 36% medal rate, establishing a new state of the art. Critically, when deployed in eight live, ongoing competitions, CoMind outperforms 92.6% of human competitors on average, placing in the top 5% on three official leaderboards and the top 1% on one.","authors":["Sijie Li","Weiwei Sun","Shanda Li","Ameet Talwalkar","Yiming Yang"],"pdf_url":"","comment":"ICLR 2026. Code available at https://github.com/comind-ml/CoMind"},{"id":"http://arxiv.org/abs/2602.22465v2","updated":"2026-02-27T16:43:01Z","published":"2026-02-25T22:54:26Z","title":"ConstraintBench: Benchmarking LLM Constraint Reasoning on Direct Optimization","summary":"Large language models are increasingly applied to operational decision-making where the underlying structure is constrained optimization. Existing benchmarks evaluate whether LLMs can formulate optimization problems as solver code, but leave open a complementary question. Can LLMs directly produce correct solutions to fully specified constrained optimization problems without access to a solver? We introduce ConstraintBench, a benchmark for evaluating LLMs on direct constrained optimization across 10 operations research domains, with all ground-truth solutions verified by the Gurobi solver. Each task presents a natural-language scenario with entities, constraints, and an optimization objective; the model must return a structured solution that a deterministic verifier checks against every constraint and the solver-proven optimum. We evaluate six frontier models on 200 tasks and find that feasibility, not optimality, is the primary bottleneck. The best model achieves only 65.0% feasibility, yet feasible solutions average 89 to 96% of the Gurobi-optimal objective. No model exceeds 30.5% on joint feasibility and optimality within 0.1% of the solver reference. Per-domain analysis shows large variation in difficulty, with average feasibility spanning from 85.0% in the facility location domain to 0.8% in the crew assignment domain. Further, systematic failure modes include duration constraint misunderstanding, entity hallucination, and a feasibility-optimality decoupling in facility location and vehicle routing where models achieve high feasibility but 0% optimality. ConstraintBench and all evaluation infrastructure will be publicly released.","authors":["Joseph Tso","Preston Schmittou","Quan Huynh","Jibran Hutchins"],"pdf_url":"","comment":"Preprint. 10 pages, 1 figure, 6 tables. Benchmark and evaluation code will be publicly released"},{"id":"http://arxiv.org/abs/2510.05228v2","updated":"2026-02-27T16:22:09Z","published":"2025-10-06T18:00:55Z","title":"CMT-Benchmark: A Benchmark for Condensed Matter Theory Built by Expert Researchers","summary":"Large language models (LLMs) have shown remarkable progress in coding and math problem-solving, but evaluation on advanced research-level problems in hard sciences remains scarce. To fill this gap, we present CMT-Benchmark, a dataset of 50 problems covering condensed matter theory (CMT) at the level of an expert researcher. Topics span analytical and computational approaches in quantum many-body, and classical statistical mechanics. The dataset was designed and verified by a panel of expert researchers from around the world. We built the dataset through a collaborative environment that challenges the panel to write and refine problems they would want a research assistant to solve, including Hartree-Fock, exact diagonalization, quantum/variational Monte Carlo, density matrix renormalization group (DMRG), quantum/classical statistical mechanics, and model building. We evaluate LLMs by programmatically checking solutions against expert-supplied ground truth. We developed machine-grading, including symbolic handling of non-commuting operators via normal ordering. They generalize across tasks too. Our evaluations show that frontier models struggle with all of the problems in the dataset, highlighting a gap in the physical reasoning skills of current LLMs. Notably, experts identified strategies for creating increasingly difficult problems by interacting with the LLMs and exploiting common failure modes. The best model, GPT5, solves 30\\% of the problems; average across 17 models (GPT, Gemini, Claude, DeepSeek, Llama) is 11.4\\pm2.1\\%. Moreover, 18 problems are solved by none of the 17 models, and 26 by at most one. These unsolved problems span Quantum Monte Carlo, Variational Monte Carlo, and DMRG. Answers sometimes violate fundamental symmetries or have unphysical scaling dimensions. We believe this benchmark will guide development toward capable AI research assistants and tutors.","authors":["Haining Pan","James V. Roggeveen","Erez Berg","Juan Carrasquilla","Debanjan Chowdhury","Surya Ganguli","Federico Ghimenti","Juraj Hasik","Henry Hunt","Hong-Chen Jiang","Mason Kamb","Ying-Jer Kao","Ehsan Khatami","Michael J. Lawler","Di Luo","Titus Neupert","Xiaoliang Qi","Michael P. Brenner","Eun-Ah Kim"],"pdf_url":"","comment":"CMT-Benchmark dataset is available at https://huggingface.co/datasets/JVRoggeveen/cmt_benchmark. CMT-Benchmark was referenced in the Gemini 3 Deep Think (February 2026) release at https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/"},{"id":"http://arxiv.org/abs/2602.24142v1","updated":"2026-02-27T16:19:45Z","published":"2026-02-27T16:19:45Z","title":"CoME: Empowering Channel-of-Mobile-Experts with Informative Hybrid-Capabilities Reasoning","summary":"Mobile Agents can autonomously execute user instructions, which requires hybrid-capabilities reasoning, including screen summary, subtask planning, action decision and action function. However, existing agents struggle to achieve both decoupled enhancement and balanced integration of these capabilities. To address these challenges, we propose Channel-of-Mobile-Experts (CoME), a novel agent architecture consisting of four distinct experts, each aligned with a specific reasoning stage, CoME activates the corresponding expert to generate output tokens in each reasoning stage via output-oriented activation. To empower CoME with hybrid-capabilities reasoning, we introduce a progressive training strategy: Expert-FT enables decoupling and enhancement of different experts' capability; Router-FT aligns expert activation with the different reasoning stage; CoT-FT facilitates seamless collaboration and balanced optimization across multiple capabilities. To mitigate error propagation in hybrid-capabilities reasoning, we propose InfoGain-Driven DPO (Info-DPO), which uses information gain to evaluate the contribution of each intermediate step, thereby guiding CoME toward more informative reasoning. Comprehensive experiments show that CoME outperforms dense mobile agents and MoE methods on both AITZ and AMEX datasets.","authors":["Yuxuan Liu","Weikai Xu","Kun Huang","Changyu Chen","Jiankun Zhao","Pengzhi Gao","Wei Liu","Jian Luan","Shuo Shang","Bo Du","Ji-Rong Wen","Rui Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.01941v2","updated":"2026-02-27T16:16:25Z","published":"2025-08-03T22:31:00Z","title":"Less is More: AMBER-AFNO -- a New Benchmark for Lightweight 3D Medical Image Segmentation","summary":"We adapt the remote sensing-inspired AMBER model from multi-band image segmentation to 3D medical datacube segmentation. To address the computational bottleneck of the volumetric transformer, we propose the AMBER-AFNO architecture. This approach uses Adaptive Fourier Neural Operators (AFNO) instead of the multi-head self-attention mechanism. Unlike spatial pairwise interactions between tokens, global token mixing in the frequency domain avoids $\\mathcal{O}(N^2)$ attention-weight calculations. As a result, AMBER-AFNO achieves quasi-linear computational complexity and linear memory scaling.\n  This new way to model global context reduces reliance on dense transformers while preserving global contextual modeling capability. By using attention-free spectral operations, our design offers a compact parameterization and maintains a competitive computational complexity. We evaluate AMBER-AFNO on three public datasets: ACDC, Synapse, and BraTS. On these datasets, the model achieves state-of-the-art or near-state-of-the-art results for DSC and HD95. Compared with recent compact CNN and Transformer architectures, our approach yields higher Dice scores while maintaining a compact model size.\n  Overall, our results show that frequency-domain token mixing with AFNO provides a fast and efficient alternative to self-attention mechanisms for 3D medical image segmentation.","authors":["Andrea Dosi","Semanto Mondal","Rajib Chandra Ghosh","Massimo Brescia","Giuseppe Longo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24138v1","updated":"2026-02-27T16:15:58Z","published":"2026-02-27T16:15:58Z","title":"Multimodal Optimal Transport for Unsupervised Temporal Segmentation in Surgical Robotics","summary":"Recognizing surgical phases and steps from video is a fundamental problem in computer-assisted interventions. Recent approaches increasingly rely on large-scale pre-training on thousands of labeled surgical videos, followed by zero-shot transfer to specific procedures. While effective, this strategy incurs substantial computational and data collection costs. In this work, we question whether such heavy pre-training is truly necessary. We propose Text-Augmented Action Segmentation Optimal Transport (TASOT), an unsupervised method for surgical phase and step recognition that extends Action Segmentation Optimal Transport (ASOT) by incorporating textual information generated directly from the videos. TASOT formulates temporal action segmentation as a multimodal optimal transport problem, where the matching cost is defined as a weighted combination of visual and text-based costs. The visual term captures frame-level appearance similarity, while the text term provides complementary semantic cues, and both are jointly regularized through a temporally consistent unbalanced Gromov-Wasserstein formulation. This design enables effective alignment between video frames and surgical actions without surgical-specific pretraining or external web-scale supervision. We evaluate TASOT on multiple benchmark surgical datasets and observe consistent and substantial improvements over existing zero-shot methods, including StrasBypass70 (+23.7), BernBypass70 (+4.5), Cholec80 (+16.5), and AutoLaparo (+19.6). These results demonstrate that fine-grained surgical understanding can be achieved by exploiting information already present in standard visual and textual representations, without resorting to increasingly complex pre-training pipelines. The code will be available at https://github.com/omar8ahmed9/TASOT.","authors":["Omar Mohamed","Edoardo Fazzari","Ayah Al-Naji","Hamdan Alhadhrami","Khalfan Hableel","Saif Alkindi","Cesare Stefanini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24119v1","updated":"2026-02-27T15:57:15Z","published":"2026-02-27T15:57:15Z","title":"Terminology Rarity Predicts Catastrophic Failure in LLM Translation of Low-Resource Ancient Languages: Evidence from Ancient Greek","summary":"This study presents the first systematic, reference-free human evaluation of large language model (LLM) machine translation (MT) for Ancient Greek (AG) technical prose. We evaluate translations by three commercial LLMs (Claude, Gemini, ChatGPT) of twenty paragraph-length passages from two works by the Greek physician Galen of Pergamum (ca. 129-216 CE): On Mixtures, which has two published English translations, and On the Composition of Drugs according to Kinds, which has never been fully translated into English. We assess translation quality using both standard automated evaluation metrics (BLEU, chrF++, METEOR, ROUGE-L, BERTScore, COMET, BLEURT) and expert human evaluation via a modified Multidimensional Quality Metrics (MQM) framework applied to all 60 translations by a team of domain specialists. On the previously translated expository text, LLMs achieved high translation quality (mean MQM score 95.2/100), with performance approaching expert level. On the untranslated pharmacological text, aggregate quality was lower (79.9/100) but with high variance driven by two passages presenting extreme terminological density; excluding these, scores converged to within 4 points of the translated text. Terminology rarity, operationalized via corpus frequency in the literary Diorisis Ancient Greek Corpus, emerged as a strong predictor of translation failure (r = -.97 for passage-level quality on the untranslated text). Automated metrics showed moderate correlation with human judgment overall on the text with a wide quality spread (Composition), but no metric discriminated among high-quality translations. We discuss implications for the use of LLMs in Classical scholarship and for the design of automated evaluation pipelines for low-resource ancient languages.","authors":["James L. Zainaldin","Cameron Pattison","Manuela Marai","Jacob Wu","Mark J. Schiefsky"],"pdf_url":"","comment":"Article + supplementary information"},{"id":"http://arxiv.org/abs/2510.13328v4","updated":"2026-02-27T15:51:51Z","published":"2025-10-15T09:13:59Z","title":"Thompson Sampling via Fine-Tuning of LLMs","summary":"Bayesian optimization in large unstructured discrete spaces is often hindered by the computational cost of maximizing acquisition functions due to the absence of gradients. We propose a scalable alternative based on Thompson sampling that eliminates the need for acquisition function maximization by directly parameterizing the probability that a candidate yields the maximum reward. Our approach, Thompson Sampling via Fine-Tuning (ToSFiT) leverages the prior knowledge embedded in prompt-conditioned large language models, and incrementally adapts them toward the posterior. Theoretically, we derive a novel regret bound for a variational formulation of Thompson Sampling that matches the strong guarantees of its standard counterpart. Our analysis reveals the critical role of careful adaptation to the posterior probability of maximality -- a principle that underpins our ToSFiT algorithm. Empirically, we validate our method on three diverse tasks: FAQ response refinement, thermally stable protein search, and quantum circuit design. Within a collection of methods covering in-context Bayesian optimization, reinforcement learning, and evolutionary search, ToSFiT exhibits both state-of-the-art sample efficiency and computational efficiency.","authors":["Nicolas Menet","Aleksandar Terzić","Michael Hersche","Andreas Krause","Abbas Rahimi"],"pdf_url":"","comment":"accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.24111v1","updated":"2026-02-27T15:49:59Z","published":"2026-02-27T15:49:59Z","title":"Toward Guarantees for Clinical Reasoning in Vision Language Models via Formal Verification","summary":"Vision-language models (VLMs) show promise in drafting radiology reports, yet they frequently suffer from logical inconsistencies, generating diagnostic impressions unsupported by their own perceptual findings or missing logically entailed conclusions. Standard lexical metrics heavily penalize clinical paraphrasing and fail to capture these deductive failures in reference-free settings. Toward guarantees for clinical reasoning, we introduce a neurosymbolic verification framework that deterministically audits the internal consistency of VLM-generated reports. Our pipeline autoformalizes free-text radiographic findings into structured propositional evidence, utilizing an SMT solver (Z3) and a clinical knowledge base to verify whether each diagnostic claim is mathematically entailed, hallucinated, or omitted. Evaluating seven VLMs across five chest X-ray benchmarks, our verifier exposes distinct reasoning failure modes, such as conservative observation and stochastic hallucination, that remain invisible to traditional metrics. On labeled datasets, enforcing solver-backed entailment acts as a rigorous post-hoc guarantee, systematically eliminating unsupported hallucinations to significantly increase diagnostic soundness and precision in generative clinical assistants.","authors":["Vikash Singh","Debargha Ganguly","Haotian Yu","Chengwei Zhou","Prerna Singh","Brandon Lee","Vipin Chaudhary","Gourav Datta"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24110v1","updated":"2026-02-27T15:49:23Z","published":"2026-02-27T15:49:23Z","title":"Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance","summary":"Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.","authors":["Yanwei Ren","Haotian Zhang","Likang Xiao","Xikai Zhang","Jiaxing Huang","Jiayan Qiu","Baosheng Yu","Quan Chen","Liu Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24109v1","updated":"2026-02-27T15:47:57Z","published":"2026-02-27T15:47:57Z","title":"ARGUS: Seeing the Influence of Narrative Features on Persuasion in Argumentative Texts","summary":"Can narratives make arguments more persuasive? And to this end, which narrative features matter most? Although stories are often seen as powerful tools for persuasion, their specific role in online, unstructured argumentation remains underexplored. To address this gap, we present ARGUS, a framework for studying the impact of narration on persuasion in argumentative discourse. ARGUS introduces a new ChangeMyView corpus annotated for story presence and six key narrative features, integrating insights from two established theoretical frameworks that capture both textual narrative features and their effects on recipients. Leveraging both encoder-based classifiers and zero-shot large language models (LLMs), ARGUS identifies stories and narrative features and applies them at scale to examine how different narrative dimensions influence persuasion success in online argumentation.","authors":["Sara Nabhani","Federico Pianzola","Khalid Al-Khatib","Malvina Nissim"],"pdf_url":"","comment":"22 pages, 8 figures, submitted to ACM Transactions on Intelligent Systems and Technology"},{"id":"http://arxiv.org/abs/2602.24100v1","updated":"2026-02-27T15:40:31Z","published":"2026-02-27T15:40:31Z","title":"Artificial Agency Program: Curiosity, compression, and communication in agents","summary":"This paper presents the Artificial Agency Program (AAP), a position and research agenda for building AI systems as reality embedded, resource-bounded agents whose development is driven by curiosity-as-learning-progress under physical and computational constraints. The central thesis is that AI is most useful when treated as part of an extended human--tool system that increases sensing, understanding, and actuation capability while reducing friction at the interface between people, tools, and environments. The agenda unifies predictive compression, intrinsic motivation, empowerment and control, interface quality (unification), and language/self-communication as selective information bottlenecks. We formulate these ideas as a falsifiable program with explicit costs, staged experiments, and a concrete multimodal tokenized testbed in which an agent allocates limited budget among observation, action, and deliberation. The aim is to provide a conceptual and experimental framework that connects intrinsic motivation, information theory, thermodynamics, bounded rationality, and modern reasoning systems","authors":["Richard Csaky"],"pdf_url":"","comment":"This is a working draft. Feedback and criticism is most welcome"},{"id":"http://arxiv.org/abs/2602.24097v1","updated":"2026-02-27T15:37:35Z","published":"2026-02-27T15:37:35Z","title":"Bi-level RL-Heuristic Optimization for Real-world Winter Road Maintenance","summary":"Winter road maintenance is critical for ensuring public safety and reducing environmental impacts, yet existing methods struggle to manage large-scale routing problems effectively and mostly reply on human decision. This study presents a novel, scalable bi-level optimization framework, validated on real operational data on UK strategic road networks (M25, M6, A1), including interconnected local road networks in surrounding areas for vehicle traversing, as part of the highway operator's efforts to solve existing planning challenges. At the upper level, a reinforcement learning (RL) agent strategically partitions the road network into manageable clusters and optimally allocates resources from multiple depots. At the lower level, a multi-objective vehicle routing problem (VRP) is solved within each cluster, minimizing the maximum vehicle travel time and total carbon emissions. Unlike existing approaches, our method handles large-scale, real-world networks efficiently, explicitly incorporating vehicle-specific constraints, depot capacities, and road segment requirements. Results demonstrate significant improvements, including balanced workloads, reduced maximum travel times below the targeted two-hour threshold, lower emissions, and substantial cost savings. This study illustrates how advanced AI-driven bi-level optimization can directly enhance operational decision-making in real-world transportation and logistics.","authors":["Yue Xie","Zizhen Xu","William Beazley","Fumiya Iida"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24096v1","updated":"2026-02-27T15:35:30Z","published":"2026-02-27T15:35:30Z","title":"DiffusionHarmonizer: Bridging Neural Reconstruction and Photorealistic Simulation with Online Diffusion Enhancer","summary":"Simulation is essential to the development and evaluation of autonomous robots such as self-driving vehicles. Neural reconstruction is emerging as a promising solution as it enables simulating a wide variety of scenarios from real-world data alone in an automated and scalable way. However, while methods such as NeRF and 3D Gaussian Splatting can produce visually compelling results, they often exhibit artifacts particularly when rendering novel views, and fail to realistically integrate inserted dynamic objects, especially when they were captured from different scenes. To overcome these limitations, we introduce DiffusionHarmonizer, an online generative enhancement framework that transforms renderings from such imperfect scenes into temporally consistent outputs while improving their realism. At its core is a single-step temporally-conditioned enhancer that is converted from a pretrained multi-step image diffusion model, capable of running in online simulators on a single GPU. The key to training it effectively is a custom data curation pipeline that constructs synthetic-real pairs emphasizing appearance harmonization, artifact correction, and lighting realism. The result is a scalable system that significantly elevates simulation fidelity in both research and production environments.","authors":["Yuxuan Zhang","Katarína Tóthová","Zian Wang","Kangxue Yin","Haithem Turki","Riccardo de Lutio","Yen-Yu Chang","Or Litany","Sanja Fidler","Zan Gojcic"],"pdf_url":"","comment":"For more details and updates, please visit our project website: https://research.nvidia.com/labs/sil/projects/diffusion-harmonizer"},{"id":"http://arxiv.org/abs/2410.01469v3","updated":"2026-02-27T15:31:14Z","published":"2024-10-02T12:21:06Z","title":"TIGER: Time-frequency Interleaved Gain Extraction and Reconstruction for Efficient Speech Separation","summary":"In recent years, much speech separation research has focused primarily on improving model performance. However, for low-latency speech processing systems, high efficiency is equally important. Therefore, we propose a speech separation model with significantly reduced parameters and computational costs: Time-frequency Interleaved Gain Extraction and Reconstruction network (TIGER). TIGER leverages prior knowledge to divide frequency bands and compresses frequency information. We employ a multi-scale selective attention module to extract contextual features while introducing a full-frequency-frame attention module to capture both temporal and frequency contextual information. Additionally, to more realistically evaluate the performance of speech separation models in complex acoustic environments, we introduce a dataset called EchoSet. This dataset includes noise and more realistic reverberation (e.g., considering object occlusions and material properties), with speech from two speakers overlapping at random proportions. Experimental results showed that models trained on EchoSet had better generalization ability than those trained on other datasets compared to the data collected in the physical world, which validated the practical value of the EchoSet. On EchoSet and real-world data, TIGER significantly reduces the number of parameters by 94.3% and the MACs by 95.3% while achieving performance surpassing the state-of-the-art (SOTA) model TF-GridNet.","authors":["Mohan Xu","Kai Li","Guo Chen","Xiaolin Hu"],"pdf_url":"","comment":"Accepted by ICLR 2025, demo page: https://cslikai.cn/TIGER/"},{"id":"http://arxiv.org/abs/2602.21204v2","updated":"2026-02-27T15:30:32Z","published":"2026-02-24T18:59:30Z","title":"Test-Time Training with KV Binding Is Secretly Linear Attention","summary":"Test-time training (TTT) with KV binding as sequence modeling layer is commonly interpreted as a form of online meta-learning that memorizes a key-value mapping at test time. However, our analysis reveals multiple phenomena that contradict this memorization-based interpretation. Motivated by these findings, we revisit the formulation of TTT and show that a broad class of TTT architectures can be expressed as a form of learned linear attention operator. Beyond explaining previously puzzling model behaviors, this perspective yields multiple practical benefits: it enables principled architectural simplifications, admits fully parallel formulations that preserve performance while improving efficiency, and provides a systematic reduction of diverse TTT variants to a standard linear attention form. Overall, our results reframe TTT not as test-time memorization, but as learned linear attention with enhanced representational capacity.","authors":["Junchen Liu","Sven Elflein","Or Litany","Zan Gojcic","Ruilong Li"],"pdf_url":"","comment":"Webpage: https://research.nvidia.com/labs/sil/projects/tttla/"},{"id":"http://arxiv.org/abs/2512.08016v2","updated":"2026-02-27T15:26:28Z","published":"2025-12-08T20:18:15Z","title":"FRIEDA: Benchmarking Multi-Step Cartographic Reasoning in Vision-Language Models","summary":"Cartographic reasoning is the skill of interpreting geographic relationships by aligning legends, map scales, compass directions, map texts, and geometries across one or more map images. Although essential as a concrete cognitive capability and for critical tasks such as disaster response and urban planning, it remains largely unevaluated. Building on progress in chart and infographic understanding, recent large vision language model studies on map visual question-answering often treat maps as a special case of charts. In contrast, map VQA demands comprehension of layered symbology (e.g., symbols, geometries, and text labels) as well as spatial relations tied to orientation and distance that often span multiple maps and are not captured by chart-style evaluations. To address this gap, we introduce FRIEDA, a benchmark for testing complex open-ended cartographic reasoning in LVLMs. FRIEDA sources real map images from documents and reports in various domains and geographical areas. Following classifications in Geographic Information System (GIS) literature, FRIEDA targets all three categories of spatial relations: topological (border, equal, intersect, within), metric (distance), and directional (orientation). All questions require multi-step inference, and many require cross-map grounding and reasoning. We evaluate eleven state-of-the-art LVLMs under two settings: (1) the direct setting, where we provide the maps relevant to the question, and (2) the contextual setting, where the model may have to identify the maps relevant to the question before reasoning. Even the strongest models, Gemini-2.5-Pro and GPT-5-Think, achieve only 38.20% and 37.20% accuracy, respectively, far below human performance of 84.87%. These results reveal a persistent gap in multi-step cartographic reasoning, positioning FRIEDA as a rigorous benchmark to drive progress on spatial intelligence in LVLMs.","authors":["Jiyoon Pyo","Yuankun Jiao","Dongwon Jung","Zekun Li","Leeje Jang","Sofia Kirsanova","Jina Kim","Yijun Lin","Qin Liu","Junyi Xie","Hadi Askari","Nan Xu","Muhao Chen","Yao-Yi Chiang"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2510.10285v2","updated":"2026-02-27T15:25:38Z","published":"2025-10-11T16:54:41Z","title":"Reallocating Attention Across Layers to Reduce Multimodal Hallucination","summary":"Multimodal large reasoning models (MLRMs) often suffer from hallucinations that stem not only from insufficient visual grounding but also from imbalanced allocation between perception and reasoning processes. Building upon recent interpretability findings suggesting a staged division of attention across layers, we analyze how this functional misalignment leads to two complementary failure modes: perceptual bias in shallow layers and reasoning drift in deeper layers. To alleviate these issues, we propose Functional Head Identification and Class-Conditioned Rescaling , a lightweight, training-free plugin that identifies perception- and reasoning-oriented heads and adaptively rebalances their layerwise contributions. Our method improves reasoning consistency and visual faithfulness without retraining or any architectural modification. Evaluations across three representative MLRMs and five multimodal reasoning benchmarks show an average 4.2% point gain, with less than 1% additional computation and only 9% baseline latency. Beyond empirical improvements, our study provides an interpretable perspective on regulating cross-layer functional dynamics to enhance the reliability of multimodal reasoning.","authors":["Haolang Lu","Bolun Chu","WeiYe Fu","Guoshun Nan","Junning Liu","Minghui Pan","Qiankun Li","Yi Yu","Hua Wang","Kun Wang"],"pdf_url":"","comment":"Acceptted by CVPR2026"},{"id":"http://arxiv.org/abs/2602.24082v1","updated":"2026-02-27T15:19:57Z","published":"2026-02-27T15:19:57Z","title":"Preference Packing: Efficient Preference Optimization for Large Language Models","summary":"Resource-efficient training optimization techniques are becoming increasingly important as the size of large language models (LLMs) continues to grow. In particular, batch packing is commonly used in pre-training and supervised fine-tuning to achieve resource-efficient training. We propose preference packing, a method to enhance resource efficiency in training techniques that use data with different responses for the same input prompt, such as reward models or Direct Preference Optimization (DPO). Preference packing improves resource efficiency by reducing the attention operations for duplicate input prompts and decreasing KV cache memory usage. We conducted experiments on text-only datasets and image-included datasets and achieved at least 37% reduction in training time. Notably, this method can be applied alongside existing optimization techniques such as batch sorting, resulting in a 3.22x speedup.","authors":["Jaekyung Cho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24081v1","updated":"2026-02-27T15:16:53Z","published":"2026-02-27T15:16:53Z","title":"Adaptive Correlation-Weighted Intrinsic Rewards for Reinforcement Learning","summary":"We propose ACWI (Adaptive Correlation Weighted Intrinsic), an adaptive intrinsic reward scaling framework designed to dynamically balance intrinsic and extrinsic rewards for improved exploration in sparse reward reinforcement learning. Unlike conventional approaches that rely on manually tuned scalar coefficients, which often result in unstable or suboptimal performance across tasks, ACWI learns a state dependent scaling coefficient online. Specifically, ACWI introduces a lightweight Beta Network that predicts the intrinsic reward weight directly from the agent state through an encoder based architecture. The scaling mechanism is optimized using a correlation based objective that encourages alignment between the weighted intrinsic rewards and discounted future extrinsic returns. This formulation enables task adaptive exploration incentives while preserving computational efficiency and training stability. We evaluate ACWI on a suite of sparse reward environments in MiniGrid. Experimental results demonstrate that ACWI consistently improves sample efficiency and learning stability compared to fixed intrinsic reward baselines, achieving superior performance with minimal computational overhead.","authors":["Viet Bac Nguyen","Phuong Thai Nguyen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24080v1","updated":"2026-02-27T15:15:31Z","published":"2026-02-27T15:15:31Z","title":"Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction","summary":"The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.","authors":["Xiang Li","Jiabao Gao","Sipei Lin","Xuan Zhou","Chi Zhang","Bo Cheng","Jiale Han","Benyou Wang"],"pdf_url":"","comment":"Accepted by ICLR 2026 Conference"},{"id":"http://arxiv.org/abs/2511.18172v2","updated":"2026-02-27T15:15:17Z","published":"2025-11-22T19:53:24Z","title":"MEDIC: a network for monitoring data quality in collider experiments","summary":"Data Quality Monitoring (DQM) is a crucial component of particle physics experiments and ensures that the recorded data is of the highest quality, and suitable for subsequent physics analysis. Due to the extreme environmental conditions, unprecedented data volumes, and the sheer scale and complexity of the detectors, DQM orchestration has become a very challenging task. Therefore, the use of Machine Learning (ML) to automate anomaly detection, improve efficiency, and reduce human error in the process of collecting high-quality data is unavoidable. Since DQM relies on real experimental data, it is inherently tied to the specific detector substructure and technology in operation. In this work, a simulation-driven approach to DQM is proposed, enabling the study and development of data-quality methodologies in a controlled environment. Using a modified version of Delphes -- a fast, multi-purpose detector simulation -- the preliminary realization of a framework is demonstrated which leverages ML to identify detector anomalies as well as localize the malfunctioning components responsible. We introduce MEDIC (Monitoring for Event Data Integrity and Consistency), a neural network designed to learn detector behavior and perform DQM tasks to look for potential faults. Although the present implementation adopts a simplified setup for computational ease, where large detector regions are deliberately deactivated to mimic faults, this work represents an initial step toward a comprehensive ML-based DQM framework. The encouraging results underline the potential of simulation-driven studies as a foundation for developing more advanced, data-driven DQM systems for future particle detectors.","authors":["Juvenal Bassa","Arghya Chattopadhyay","Sudhir Malik","Mario Escabi Rivera"],"pdf_url":"","comment":"17 pages, 1 appendix. V2: Minor changes to match with the published version"},{"id":"http://arxiv.org/abs/2507.16467v2","updated":"2026-02-27T15:12:04Z","published":"2025-07-22T11:16:23Z","title":"Estimating Treatment Effects with Independent Component Analysis","summary":"Independent Component Analysis (ICA) uses a measure of non-Gaussianity to identify latent sources from data and estimate their mixing coefficients (Shimizu et al., 2006). Meanwhile, higher-order Orthogonal Machine Learning (OML) exploits non-Gaussian treatment noise to provide more accurate estimates of treatment effects in the presence of confounding nuisance effects (Mackey et al., 2018). Remarkably, we find that the two approaches rely on the same moment conditions for consistent estimation. We then seize upon this connection to show how ICA can be effectively used for treatment effect estimation. Specifically, we prove that linear ICA can consistently estimate multiple treatment effects, even in the presence of Gaussian confounders, and identify regimes in which ICA is provably more sample-efficient than OML for treatment effect estimation. Our synthetic demand estimation experiments confirm this theory and demonstrate that linear ICA can accurately estimate treatment effects even in the presence of nonlinear nuisance.","authors":["Patrik Reizinger","Lester Mackey","Wieland Brendel","Rahul Krishnan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25084v2","updated":"2026-02-27T15:04:07Z","published":"2025-09-29T17:23:08Z","title":"Scaling Generalist Data-Analytic Agents","summary":"Data-analytic agents are emerging as a key catalyst for automated scientific discovery and for the vision of Innovating AI. Current approaches, however, rely heavily on prompt engineering over proprietary models, while open-source models struggle to face diverse-format, large-scale data files and long-horizon, multi-step reasoning that real-world analytics demands. This paper introduces DataMind, a scalable data synthesis and agent training recipe designed to build generalist data-analytic agents. DataMind tackles three key challenges in building open-source data-analytic agents, including insufficient data resources, improper training strategy, and unstable code-based multi-turn rollout. Concretely, DataMind applies 1) a fine-grained task taxonomy and a recursive easy-to-hard task composition mechanism to increase the diversity and difficulty of synthesized queries; 2) a knowledge-augmented trajectory sampling strategy followed by model-based and rule-based filtering; 3) a dynamically adjustable training objective combining both SFT and RL losses; 4) a memory-frugal and stable code-based multi-turn rollout framework. Built on DataMind, we curate DataMind-12K, a high-quality trajectory set spanning diverse domains, task categories, and data file formats for data-analytic tasks. Trained on DataMind-12K, our DataMind-14B achieves state-of-the-art with an average score of 71.16% on multiple data analysis benchmarks, outperforming the strongest proprietary baselines DeepSeek-V3.1 and GPT-5. Our DataMind-7B also performs best among all open-source models with a score of 68.10%. We also incorporate some empirical insights gained from our exploratory trials into the analysis experiments, aiming to provide actionable insights about agentic training for the community. We will release DataMind-12K and DataMind-7B,14B for the community's future research.","authors":["Shuofei Qiao","Yanqiu Zhao","Zhisong Qiu","Xiaobin Wang","Jintian Zhang","Zhao Bin","Ningyu Zhang","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2509.23735v2","updated":"2026-02-27T14:50:32Z","published":"2025-09-28T08:30:03Z","title":"Demystifying the Lifecycle of Failures in Platform-Orchestrated Agentic Workflows","summary":"Agentic workflows built on low-code orchestration platforms enable rapid development of multi-agent systems, but they also introduce new and poorly understood failure modes that hinder reliability and maintainability. Unlike traditional software systems, failures in agentic workflows often propagate across heterogeneous nodes through natural-language interactions, tool invocations, and dynamic control logic, making failure attribution and repair particularly challenging. In this paper, we present an empirical study of platform-orchestrated agentic workflows from a failure lifecycle perspective, with the goal of characterizing failure manifestations, identifying underlying root causes, and examining corresponding repair strategies. We present AgentFail, a dataset of 307 real-world failure cases collected from two representative agentic workflow platforms. Based on this dataset, we analyze failure patterns, root causes, and repair difficulty for various failure root causes and nodes in the workflow. Our findings reveal key failure mechanisms in agentic workflows and provide actionable guidelines for reliable failure repair, and real-world agentic workflow design.","authors":["Xuyan Ma","Xiaofei Xie","Yawen Wang","Junjie Wang","Boyu Wu","Mingyang Li","Qing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13358v2","updated":"2026-02-27T14:49:13Z","published":"2025-10-15T09:45:24Z","title":"Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control","summary":"Offline reinforcement learning enables sample-efficient policy acquisition without risky online interaction, yet policies trained on static datasets remain brittle under action-space perturbations such as actuator faults. This study introduces an offline-to-online framework that trains policies on clean data and then performs adversarial fine-tuning, where perturbations are injected into executed actions to induce compensatory behavior and improve resilience. A performance-aware curriculum further adjusts the perturbation probability during training via an exponential-moving-average signal, balancing robustness and stability throughout the learning process. Experiments on continuous-control locomotion tasks demonstrate that the proposed method consistently improves robustness over offline-only baselines and converges faster than training from scratch. Matching the fine-tuning and evaluation conditions yields the strongest robustness to action-space perturbations, while the adaptive curriculum strategy mitigates the degradation of nominal performance observed with the linear curriculum strategy. Overall, the results show that adversarial fine-tuning enables adaptive and robust control under uncertain environments, bridging the gap between offline efficiency and online adaptability.","authors":["Shingo Ayabe","Hiroshi Kera","Kazuhiko Kawamoto"],"pdf_url":"","comment":"15 main pages, 8 supplementary material pages"},{"id":"http://arxiv.org/abs/2602.24060v1","updated":"2026-02-27T14:49:05Z","published":"2026-02-27T14:49:05Z","title":"Task Complexity Matters: An Empirical Study of Reasoning in LLMs for Sentiment Analysis","summary":"Large language models (LLMs) with reasoning capabilities have fueled a compelling narrative that reasoning universally improves performance across language tasks. We test this claim through a comprehensive evaluation of 504 configurations across seven model families--including adaptive, conditional, and reinforcement learning-based reasoning architectures--on sentiment analysis datasets of varying granularity (binary, five-class, and 27-class emotion). Our findings reveal that reasoning effectiveness is strongly task-dependent, challenging prevailing assumptions: (1) Reasoning shows task-complexity dependence--binary classification degrades up to -19.9 F1 percentage points (pp), while 27-class emotion recognition gains up to +16.0pp; (2) Distilled reasoning variants underperform base models by 3-18 pp on simpler tasks, though few-shot prompting enables partial recovery; (3) Few-shot learning improves over zero-shot in most cases regardless of model type, with gains varying by architecture and task complexity; (4) Pareto frontier analysis shows base models dominate efficiency-performance trade-offs, with reasoning justified only for complex emotion recognition despite 2.1x-54x computational overhead. We complement these quantitative findings with qualitative error analysis revealing that reasoning degrades simpler tasks through systematic over-deliberation, offering mechanistic insight beyond the high-level overthinking hypothesis.","authors":["Donghao Huang","Zhaoxia Wang"],"pdf_url":"","comment":"12 pages, 1 figure, 3 tables. Accepted at PAKDD 2026"},{"id":"http://arxiv.org/abs/2602.24059v1","updated":"2026-02-27T14:47:48Z","published":"2026-02-27T14:47:48Z","title":"Quant Experts: Token-aware Adaptive Error Reconstruction with Mixture of Experts for Large Vision-Language Models Quantization","summary":"Post-Training Quantization (PTQ) has emerged as an effective technique for alleviating the substantial computational and memory overheads of Vision-Language Models (VLMs) by compressing both weights and activations without retraining the full model. Existing PTQ methods primarily rely on static identification and global compensation of sensitive or outlier channels, yet they often overlook the distributional differences of these important channels across inputs, leading to unsatisfactory quantization. In this work, we observe that the distributions and occurrence frequencies of important channels vary significantly both across modalities and among tokens, even within the same modality. Accordingly, we propose \\textbf{Quant Experts (QE)}, a token-aware adaptive error compensation with mixture-of-experts for VLMs quantization. QE divides the important channels into token-independent and token-dependent groups. For the former, a shared expert is designed for most tokens to compensate for global quantization error using a low-rank adapter. For the latter, routed experts including multiple routed low-rank adapters are elaborated to compensate for local quantization error related to specific tokens. Extensive experiments demonstrate that QE consistently enhances task accuracy across various quantization settings and model scales, ranging from 2B to 70B parameters, while maintaining performance comparable to full-precision models.","authors":["Chenwei Jia","Baoting Li","Xuchong Zhang","Mingzhuo Wei","Bochen Lin","Hongbin Sun"],"pdf_url":"","comment":"13 pages, 6 figures, including appendix, Accepted at CVPR 2026"},{"id":"http://arxiv.org/abs/2602.24055v1","updated":"2026-02-27T14:43:23Z","published":"2026-02-27T14:43:23Z","title":"CIRCLE: A Framework for Evaluating AI from a Real-World Lens","summary":"This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.","authors":["Reva Schwartz","Carina Westling","Morgan Briggs","Marzieh Fadaee","Isar Nejadgholi","Matthew Holmes","Fariza Rashid","Maya Carlyle","Afaf Taïk","Kyra Wilson","Peter Douglas","Theodora Skeadas","Gabriella Waters","Rumman Chowdhury","Thiago Lacerda"],"pdf_url":"","comment":"Accepted at Intelligent Systems Conference (IntelliSys) 2026"},{"id":"http://arxiv.org/abs/2511.18326v2","updated":"2026-02-27T14:38:37Z","published":"2025-11-23T07:31:41Z","title":"General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification","summary":"The accurate identification of brain tumors from magnetic resonance imaging (MRI) is essential for timely diagnosis and effective therapeutic intervention. While deep convolutional neural networks (CNNs), particularly those pre-trained on extensive datasets, have shown considerable promise in medical image analysis, a key question arises when working with limited data: do models pre-trained on specialized medical image repositories outperform those pre-trained on diverse, general-domain datasets? This research presents a comparative analysis of three distinct pre-trained CNN architectures for brain tumor classification: RadImageNet DenseNet121, which leverages pre-training on medical-domain data, alongside two modern general-purpose networks, EfficientNetV2S and ConvNeXt-Tiny. All models were trained and fine-tuned under uniform experimental conditions using a modestly sized brain MRI dataset to maintain consistency in evaluation. The experimental outcomes indicate that ConvNeXt-Tiny delivered the best performance, achieving 93% test accuracy, followed by EfficientNetV2S at 85%. In contrast, RadImageNet DenseNet121 attained only 68% accuracy and exhibited higher loss, indicating limited generalization capability despite its domain-specific pre-training. These observations imply that pre-training on medical-domain data does not necessarily guarantee superior performance in data-scarce scenarios. Conversely, contemporary general-purpose CNNs with deeper architectures, pre-trained on large-scale diverse datasets, may offer more effective transfer learning for specialized diagnostic tasks in medical imaging.","authors":["Helia Abedini","Saba Rahimi","Reza Vaziri"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.06879v2","updated":"2026-02-27T14:30:26Z","published":"2025-12-07T15:10:20Z","title":"WisPaper: Your AI Scholar Search Engine","summary":"We present \\textsc{WisPaper}, an end-to-end agent system that transforms how researchers discover, organize, and track academic literature. The system addresses two fundamental challenges. (1)~\\textit{Semantic search limitations}: existing academic search engines match keywords but cannot verify whether papers truly address complex research questions; and (2)~\\textit{Workflow fragmentation}: researchers must manually stitch together separate tools for discovery, organization, and monitoring. \\textsc{WisPaper} tackles these through three integrated modules. \\textbf{Scholar Search} combines rapid keyword retrieval with \\textit{Deep Search}, in which an agentic model, \\textsc{WisModel}, validates candidate papers against user queries through structured reasoning. Discovered papers flow seamlessly into \\textbf{Library} with one click, where systematic organization progressively builds a user profile that sharpens the recommendations of \\textbf{AI Feeds}, which continuously surfaces relevant new publications and in turn guides subsequent exploration, closing the loop from discovery to long-term awareness. On TaxoBench, \\textsc{WisPaper} achieves 22.26\\% recall, surpassing the O3 baseline (20.92\\%). Furthermore, \\textsc{WisModel} attains 93.70\\% validation accuracy, effectively mitigating retrieval hallucinations.","authors":["Li Ju","Jun Zhao","Mingxu Chai","Ziyu Shen","Xiangyang Wang","Yage Geng","Chunchun Ma","Hao Peng","Guangbin Li","Tao Li","Chengyong Liao","Fu Wang","Xiaolong Wang","Junshen Chen","Rui Gong","Shijia Liang","Feiyan Li","Ming Zhang","Kexin Tan","Junjie Ye","Zhiheng Xi","Shihan Dou","Tao Gui","Yuankai Ying","Yang Shi","Yue Zhang","Qi Zhang"],"pdf_url":"","comment":"18 pages, 4 figures"},{"id":"http://arxiv.org/abs/2511.08565v2","updated":"2026-02-27T14:30:00Z","published":"2025-11-11T18:47:44Z","title":"Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models","summary":"Large language models (LLMs) increasingly operate in social contexts, motivating analysis of how they express and shift moral judgments. In this work, we investigate the moral response of LLMs to persona role-play, prompting a LLM to assume a specific character. Using the Moral Foundations Questionnaire (MFQ), we introduce a benchmark that quantifies two properties: moral susceptibility and moral robustness, defined from the variability of MFQ scores across and within personas, respectively. We find that, for moral robustness, model family accounts for most of the variance, while model size shows no systematic effect. The Claude family is, by a significant margin, the most robust, followed by Gemini and GPT-4 models, with other families exhibiting lower robustness. In contrast, moral susceptibility exhibits a mild family effect but a clear within-family size effect, with larger variants being more susceptible. Moreover, robustness and susceptibility are positively correlated, an association that is more pronounced at the family level. Additionally, we present moral foundation profiles for models without persona role-play and for personas averaged across models. Together, these analyses provide a systematic view of how persona conditioning shapes moral behavior in LLMs.","authors":["Davi Bastos Costa","Felippe Alves","Renato Vicente"],"pdf_url":"","comment":"8+5 pages, 7 tables, 7 figures"},{"id":"http://arxiv.org/abs/2601.17582v2","updated":"2026-02-27T14:28:13Z","published":"2026-01-24T20:27:47Z","title":"GenAI-Net: A Generative AI Framework for Automated Biomolecular Network Design","summary":"Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.","authors":["Maurice Filo","Nicolò Rossi","Zhou Fang","Mustafa Khammash"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.20812v4","updated":"2026-02-27T14:25:56Z","published":"2025-10-23T17:59:21Z","title":"Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation","summary":"Large Vision-Language Models (VLMs) have achieved remarkable progress in multimodal understanding, yet they struggle when reasoning over information-intensive images that densely interleave textual annotations with fine-grained graphical elements. The main challenges lie in precisely localizing critical cues in dense layouts and multi-hop reasoning to integrate dispersed evidence. We propose Speculative Verdict (SV), a training-free framework inspired by speculative decoding that combines multiple lightweight draft experts with a large verdict model. In the draft stage, small VLMs act as draft experts to generate reasoning paths that provide diverse localization candidates; in the verdict stage, a strong VLM synthesizes these paths to produce the final answer, minimizing computational cost while recovering correct answers. To further improve efficiency and accuracy, SV introduces a consensus expert selection mechanism that forwards only high-agreement reasoning paths to the verdict. Empirically, SV achieves consistent gains on challenging information-intensive and high-resolution visual question answering benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K. By synthesizing correct insights from multiple partially accurate reasoning paths, SV achieves both error correction and cost-efficiency compared to large proprietary models or training pipelines. Code is available at https://github.com/Tinaliu0123/speculative-verdict.","authors":["Yuhan Liu","Lianhui Qin","Shengjie Wang"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2602.24044v1","updated":"2026-02-27T14:22:51Z","published":"2026-02-27T14:22:51Z","title":"Data Driven Optimization of GPU efficiency for Distributed LLM Adapter Serving","summary":"Large Language Model (LLM) adapters enable low-cost model specialization, but introduce complex caching and scheduling challenges in distributed serving systems where hundreds of adapters must be hosted concurrently. While prior work has largely focused on latency minimization, resource efficiency through throughput maximization remains underexplored. This paper presents a data-driven pipeline that, for a given workload, computes an adapter placement that serves the workload with the minimum number of GPUs while avoiding request starvation and GPU memory errors. To that end, the approach identifies the maximum feasible throughput attainable on each GPU by leveraging accurate performance predictions learned from real serving behavior. The proposed pipeline integrates three components: (i) a Digital Twin (DT) tailored to LLM-adapter serving, (ii) a distilled machine learning (ML) model trained on DT-generated data, and (iii) a greedy placement algorithm that exploits ML-based performance estimates to maximize GPU efficiency. The DT emulates real system dynamics with high fidelity, achieving below 5% throughput estimation error while executing up to 90 times faster than full LLM benchmarking across both predictable and unpredictable workloads. The learned ML models further accelerate performance estimation with marginal accuracy degradation, enabling scalable optimization. Experimental results demonstrate that the pipeline substantially improves GPU efficiency by reducing the number of GPUs required to sustain target workloads. Beyond GPU efficiency, the pipeline can be adapted to alternative objectives, such as latency minimization, highlighting its versatility for future large-scale LLM serving infrastructures.","authors":["Ferran Agullo","Joan Oliveras","Chen Wang","Alberto Gutierrez-Torre","Olivier Tardieu","Alaa Youssef","Jordi Torres","Josep Ll. Berral"],"pdf_url":"","comment":"journal extension of the workshop paper titled as \"A data-driven ml approach for maximizing performance in llm-adapter serving\""},{"id":"http://arxiv.org/abs/2509.07021v3","updated":"2026-02-27T14:17:19Z","published":"2025-09-07T07:06:03Z","title":"MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning","summary":"3D Gaussian Splatting (3DGS) has emerged as a dominant novel-view synthesis technique, but its high memory consumption severely limits its applicability on edge devices. A growing number of 3DGS compression methods have been proposed to make 3DGS more efficient, yet most only focus on storage compression and fail to address the critical bottleneck of rendering memory. To address this problem, we introduce MEGS$^{2}$, a novel memory-efficient framework that tackles this challenge by jointly optimizing two key factors: the total primitive number and the parameters per primitive, achieving unprecedented memory compression. Specifically, we replace the memory-intensive spherical harmonics with lightweight, arbitrarily oriented spherical Gaussian lobes as our color representations. More importantly, we propose a unified soft pruning framework that models primitive-number and lobe-number pruning as a single constrained optimization problem. Experiments show that MEGS$^{2}$ achieves a 50% static VRAM reduction and a 40% rendering VRAM reduction compared to existing methods, while maintaining comparable rendering quality. Project page: https://megs-2.github.io/","authors":["Jiarui Chen","Yikeng Chen","Yingshuang Zou","Ye Huang","Peng Wang","Yuan Liu","Yujing Sun","Wenping Wang"],"pdf_url":"","comment":"20 pages, 8 figures. Accepted by ICLR 2026"},{"id":"http://arxiv.org/abs/2601.06940v2","updated":"2026-02-27T14:17:03Z","published":"2026-01-11T15:02:28Z","title":"VISTA: Knowledge-Driven Vessel Trajectory Imputation with Repair Provenance","summary":"Repairing incomplete trajectory data is essential for downstream spatio-temporal applications. Yet, existing repair methods focus solely on reconstruction without documenting the reasoning behind repair decisions, undermining trust in safety-critical applications where repaired trajectories affect operational decisions, such as in maritime anomaly detection and route planning. We introduce repair provenance - structured, queryable metadata that documents the full reasoning chain behind each repair - which transforms imputation from pure data recovery into a task that supports downstream decision-making. We propose VISTA (knowledge-driven interpretable vessel trajectory imputation), a framework that reliably equips repaired trajectories with repair provenance by grounding LLM reasoning in data-verified knowledge. Specifically, we formalize Structured Data-derived Knowledge (SDK), a knowledge model whose data-verifiable components can be validated against real data and used to anchor and constrain LLM-generated explanations. We organize SDK in a Structured Data-derived Knowledge Graph (SD-KG) and establish a data-knowledge-data loop for extraction, validation, and incremental maintenance over large-scale AIS data. A workflow management layer with parallel scheduling, fault tolerance, and redundancy control ensures consistent and efficient end-to-end processing. Experiments on two large-scale AIS datasets show that VISTA achieves state-of-the-art accuracy, improving over baselines by 5-91% and reducing inference time by 51-93%, while producing repair provenance, whose interpretability is further validated through a case study and an interactive demo system.","authors":["Hengyu Liu","Tianyi Li","Haoyu Wang","Kristian Torp","Tiancheng Zhang","Yushuai Li","Christian S. Jensen"],"pdf_url":"","comment":"24 pages, 14 figures, 4 algorithms, 8 tables. Code available at https://github.com/hyLiu1994/VISTA"},{"id":"http://arxiv.org/abs/2602.24040v1","updated":"2026-02-27T14:15:57Z","published":"2026-02-27T14:15:57Z","title":"RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models","summary":"Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.","authors":["Daniel Yang","Samuel Stante","Florian Redhardt","Lena Libon","Parnian Kassraie","Ido Hakimi","Barna Pásztor","Andreas Krause"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17632v2","updated":"2026-02-27T14:11:37Z","published":"2026-02-19T18:47:31Z","title":"SMAC: Score-Matched Actor-Critics for Robust Offline-to-Online Transfer","summary":"Modern offline Reinforcement Learning (RL) methods find performant actor-critics, however, fine-tuning these actor-critics online with value-based RL algorithms typically causes immediate drops in performance. We provide evidence consistent with the hypothesis that, in the loss landscape, offline maxima for prior algorithms and online maxima are separated by low-performance valleys that gradient-based fine-tuning traverses. Following this, we present Score Matched Actor-Critic (SMAC), an offline RL method designed to learn actor-critics that transition to online value-based RL algorithms with no drop in performance. SMAC avoids valleys between offline and online maxima by regularizing the Q-function during the offline phase to respect a first-order derivative equality between the score of the policy and action-gradient of the Q-function. We experimentally demonstrate that SMAC converges to offline maxima that are connected to better online maxima via paths with monotonically increasing reward found by first-order optimization. SMAC achieves smooth transfer to Soft Actor-Critic and TD3 in 6/6 D4RL tasks. In 4/6 environments, it reduces regret by 34-58% over the best baseline.","authors":["Nathan Samuel de Lara","Florian Shkurti"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24037v1","updated":"2026-02-27T14:09:55Z","published":"2026-02-27T14:09:55Z","title":"Portfolio Reinforcement Learning with Scenario-Context Rollout","summary":"Market regime shifts induce distribution shifts that can degrade the performance of portfolio rebalancing policies. We propose macro-conditioned scenario-context rollout (SCR) that generates plausible next-day multivariate return scenarios under stress events. However, doing so faces new challenges, as history will never tell what would have happened differently. As a result, incorporating scenario-based rewards from rollouts introduces a reward--transition mismatch in temporal-difference learning, destabilizing RL critic training.\n  We analyze this inconsistency and show it leads to a mixed evaluation target. Guided by this analysis, we construct a counterfactual next state using the rollout-implied continuations and augment the critic agent's bootstrap target. Doing so stabilizes the learning and provides a viable bias-variance tradeoff.\n  In out-of-sample evaluations across 31 distinct universes of U.S. equity and ETF portfolios, our method improves Sharpe ratio by up to 76% and reduces maximum drawdown by up to 53% compared with classic and RL-based portfolio rebalancing baselines.","authors":["Vanya Priscillia Bendatu","Yao Lu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.21021v2","updated":"2026-02-27T14:00:26Z","published":"2025-09-25T11:31:16Z","title":"Efficient Ensemble Conditional Independence Test Framework for Causal Discovery","summary":"Constraint-based causal discovery relies on numerous conditional independence tests (CITs), but its practical applicability is severely constrained by the prohibitive computational cost, especially as CITs themselves have high time complexity with respect to the sample size. To address this key bottleneck, we introduce the Ensemble Conditional Independence Test (E-CIT), a general-purpose and plug-and-play framework. E-CIT operates on an intuitive divide-and-aggregate strategy: it partitions the data into subsets, applies a given base CIT independently to each subset, and aggregates the resulting p-values using a novel method grounded in the properties of stable distributions. This framework reduces the computational complexity of a base CIT to linear in the sample size when the subset size is fixed. Moreover, our tailored p-value combination method offers theoretical consistency guarantees under mild conditions on the subtests. Experimental results demonstrate that E-CIT not only significantly reduces the computational burden of CITs and causal discovery but also achieves competitive performance. Notably, it exhibits an improvement in complex testing scenarios, particularly on real-world datasets.","authors":["Zhengkang Guan","Kun Kuang"],"pdf_url":"","comment":"Published as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2506.04398v3","updated":"2026-02-27T13:56:40Z","published":"2025-06-04T19:27:29Z","title":"Bridging the Performance Gap Between Target-Free and Target-Based Reinforcement Learning","summary":"The use of target networks in deep reinforcement learning is a widely popular solution to mitigate the brittleness of semi-gradient approaches and stabilize learning. However, target networks notoriously require additional memory and delay the propagation of Bellman updates compared to an ideal target-free approach. In this work, we step out of the binary choice between target-free and target-based algorithms. We introduce a new method that uses a copy of the last linear layer of the online network as a target network, while sharing the remaining parameters with the up-to-date online network. This simple modification enables us to keep the target-free's low-memory footprint while leveraging the target-based literature. We find that combining our approach with the concept of iterated $Q$-learning, which consists of learning consecutive Bellman updates in parallel, helps improve the sample-efficiency of target-free approaches. Our proposed method, iterated Shared $Q$-Learning (iS-QL), bridges the performance gap between target-free and target-based approaches across various problems while using a single $Q$-network, thus stepping towards resource-efficient reinforcement learning algorithms.","authors":["Théo Vincent","Yogesh Tripathi","Tim Faust","Abdullah Akgül","Yaniv Oren","Melih Kandemir","Jan Peters","Carlo D'Eramo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2405.07780v2","updated":"2026-02-27T13:56:34Z","published":"2024-05-13T14:24:56Z","title":"DirMixE: Harnessing Test Agnostic Long-tail Recognition with Hierarchical Label Vartiations","summary":"This paper explores test-agnostic long-tail recognition, a challenging long-tail task where the test label distributions are unknown and arbitrarily imbalanced. We argue that the variation in these distributions can be broken down hierarchically into global and local levels. The global ones reflect a broad range of diversity, while the local ones typically arise from milder changes, often focused on a particular neighbor. Traditional methods predominantly use a Mixture-of-Expert (MoE) approach, targeting a few fixed test label distributions that exhibit substantial global variations. However, the local variations are left unconsidered. To address this issue, we propose a new MoE strategy, DirMixE, which assigns experts to different Dirichlet meta-distributions of the label distribution, each targeting a specific aspect of local variations. Additionally, the diversity among these Dirichlet meta-distributions inherently captures global variations. This dual-level approach also leads to a more stable objective function, allowing us to sample different test distributions better to quantify the mean and variance of performance outcomes. Building on this idea, we develop a general Latent Skill Finetuning (LSF) framework for parameter-efficient finetuning of foundation models. We provide implementations based on LoRA and Adapter. Theoretically, we derive upper bounds on the generalization error for both standard learning and PEFT. Under mild assumptions, we show that the variance-based regularization helps tighten these bounds. Furthermore, we prove that the covering number of the PEFT hypothesis class scales with the number of trainable parameters. Finally, extensive experiments on CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist validate the effectiveness of DirMixE.","authors":["Zhiyong Yang","Qianqian Xu","Sicong Li","Zitai Wang","Xiaochun Cao","Qingming Huang"],"pdf_url":"","comment":"Conference version: Zhiyong Yang, Qianqian Xu, Zitai Wang, Sicong Li, Boyu Han, Shilong Bao, Xiaochun Cao, and Qingming Huang. Harnessing Hierarchical Label Distribution Variations in Test Agnostic Long-tail Recognition. ICML, 56624-56664, 2024"},{"id":"http://arxiv.org/abs/2502.07845v2","updated":"2026-02-27T13:56:10Z","published":"2025-02-11T09:23:38Z","title":"Spread them Apart: Towards Robust Watermarking of Generated Content","summary":"Generative models that can produce realistic images have improved significantly in recent years. The quality of the generated content has increased drastically, so sometimes it is very difficult to distinguish between the real images and the generated ones. Such an improvement comes at a price of ethical concerns about the usage of the generative models: the users of generative models can improperly claim ownership of the generated content protected by a license. In this paper, we propose an approach to embed watermarks into the generated content to allow future detection of the generated content and identification of the user who generated it. The watermark is embedded during the inference of the model, so the proposed approach does not require the retraining of the latter. We prove that watermarks embedded are guaranteed to be robust against additive perturbations of a bounded magnitude. We apply our method to watermark diffusion models and show that it matches state-of-the-art watermarking schemes in terms of robustness to different types of synthetic watermark removal attacks.","authors":["Mikhail Pautov","Danil Ivanov","Andrey V. Galichin","Oleg Rogov","Ivan Oseledets"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.12412v2","updated":"2026-02-27T13:51:56Z","published":"2025-08-17T15:55:02Z","title":"LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems","summary":"The incorporation of LLMs in multi-agent systems (MASs) has the potential to significantly improve our ability to autonomously solve complex problems. However, such systems introduce unique challenges in monitoring, interpreting, and detecting system failures. Most existing MAS observability frameworks focus on analyzing each individual agent separately, overlooking failures associated with the entire MAS. To bridge this gap, we propose LumiMAS, a novel MAS observability framework that incorporates advanced analytics and monitoring techniques. The proposed framework consists of three key components: a monitoring and logging layer, anomaly detection layer, and anomaly explanation layer. LumiMAS's first layer monitors MAS executions, creating detailed logs of the agents' activity. These logs serve as input to the anomaly detection layer, which detects anomalies across the MAS workflow in real time. Then, the anomaly explanation layer performs classification and root cause analysis (RCA) of the detected anomalies. LumiMAS was evaluated on seven different MAS applications, implemented using two popular MAS platforms, and a diverse set of possible failures. The applications include two novel failure-tailored applications that illustrate the effects of a hallucination or bias on the MAS. The evaluation results demonstrate LumiMAS's effectiveness in failure detection, classification, and RCA.","authors":["Ron Solomon","Yarin Yerushalmi Levi","Lior Vaknin","Eran Aizikovich","Amit Baras","Etai Ohana","Amit Giloni","Shamik Bose","Chiara Picardi","Yuval Elovici","Asaf Shabtai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.00955v2","updated":"2026-02-27T13:50:53Z","published":"2025-08-01T07:31:24Z","title":"From Generator to Embedder: Harnessing Innate Abilities of Multimodal LLMs via Building Zero-Shot Discriminative Embedding Model","summary":"Adapting generative Multimodal Large Language Models (MLLMs) into universal embedding models typically demands resource-intensive contrastive pre-training, while traditional hard negative mining methods suffer from severe false negative contamination. In this paper, we propose a highly data-efficient framework that bypasses extensive pre-training to build a robust multimodal representation space. We first introduce a hierarchical embedding prompt that provides strong latent conditioning. By explicitly anchoring task definitions at the system level, this prompting strategy effectively bridges the modality gap and unlocks powerful zero-shot embedding capabilities. Building upon this latent conditioning, we present Self-aware Hard Negative Sampling (SaHa). Unlike conventional candidate-space mining, SaHa shifts the mechanism to the query-space by mapping retrieved candidates back to their owner queries to rigorously filter out semantic false negatives. Furthermore, our method constructs mutually hard clusters, maximizing intra-task discrimination and batch efficiency without redundant forward passes. Extensive experiments demonstrate that our unified approach achieves highly competitive fine-tuning performance on the Massive Multimodal Embedding Benchmark using only a fraction of standard training data.","authors":["Yeong-Joon Ju","Seong-Whan Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22287v2","updated":"2026-02-27T13:49:46Z","published":"2026-02-25T14:14:13Z","title":"Multi-Level Causal Embeddings","summary":"Abstractions of causal models allow for the coarsening of models such that relations of cause and effect are preserved. Whereas abstractions focus on the relation between two models, in this paper we study a framework for causal embeddings which enable multiple detailed models to be mapped into sub-systems of a coarser causal model. We define causal embeddings as a generalization of abstraction, and present a generalized notion of consistency. By defining a multi-resolution marginal problem, we showcase the relevance of causal embeddings for both the statistical marginal problem and the causal marginal problem; furthermore, we illustrate its practical use in merging datasets coming from models with different representations. ","authors":["Willem Schooltink","Fabio Massimo Zennaro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.01780v2","updated":"2026-02-27T13:49:13Z","published":"2026-01-05T04:26:46Z","title":"LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment","summary":"Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.","authors":["Arsham Khosravani","Alireza Hoseinpour","Arshia Akhavan","Mehdi Keshani","Abbas Heydarnoori"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24014v1","updated":"2026-02-27T13:37:11Z","published":"2026-02-27T13:37:11Z","title":"Interpretable Debiasing of Vision-Language Models for Social Fairness","summary":"The rapid advancement of Vision-Language models (VLMs) has raised growing concerns that their black-box reasoning processes could lead to unintended forms of social bias. Current debiasing approaches focus on mitigating surface-level bias signals through post-hoc learning or test-time algorithms, while leaving the internal dynamics of the model largely unexplored. In this work, we introduce an interpretable, model-agnostic bias mitigation framework, DeBiasLens, that localizes social attribute neurons in VLMs through sparse autoencoders (SAEs) applied to multimodal encoders. Building upon the disentanglement ability of SAEs, we train them on facial image or caption datasets without corresponding social attribute labels to uncover neurons highly responsive to specific demographics, including those that are underrepresented. By selectively deactivating the social neurons most strongly tied to bias for each group, we effectively mitigate socially biased behaviors of VLMs without degrading their semantic knowledge. Our research lays the groundwork for future auditing tools, prioritizing social fairness in emerging real-world AI systems.","authors":["Na Min An","Yoonna Jang","Yusuke Hirota","Ryo Hachiuma","Isabelle Augenstein","Hyunjung Shim"],"pdf_url":"","comment":"25 pages, 30 figures, 13 Tables Accepted to CVPR 2026"},{"id":"http://arxiv.org/abs/2602.24009v1","updated":"2026-02-27T13:32:53Z","published":"2026-02-27T13:32:53Z","title":"Jailbreak Foundry: From Papers to Runnable Attacks for Reproducible Benchmarking","summary":"Jailbreak techniques for large language models (LLMs) evolve faster than benchmarks, making robustness estimates stale and difficult to compare across papers due to drift in datasets, harnesses, and judging protocols. We introduce JAILBREAK FOUNDRY (JBF), a system that addresses this gap via a multi-agent workflow to translate jailbreak papers into executable modules for immediate evaluation within a unified harness. JBF features three core components: (i) JBF-LIB for shared contracts and reusable utilities; (ii) JBF-FORGE for the multi-agent paper-to-module translation; and (iii) JBF-EVAL for standardizing evaluations. Across 30 reproduced attacks, JBF achieves high fidelity with a mean (reproduced-reported) attack success rate (ASR) deviation of +0.26 percentage points. By leveraging shared infrastructure, JBF reduces attack-specific implementation code by nearly half relative to original repositories and achieves an 82.5% mean reused-code ratio. This system enables a standardized AdvBench evaluation of all 30 attacks across 10 victim models using a consistent GPT-4o judge. By automating both attack integration and standardized evaluation, JBF offers a scalable solution for creating living benchmarks that keep pace with the rapidly shifting security landscape.","authors":["Zhicheng Fang","Jingjie Zheng","Chenxu Fu","Wei Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.05419v2","updated":"2026-02-27T13:22:03Z","published":"2024-10-07T18:31:19Z","title":"Joint Distribution-Informed Shapley Values for Sparse Counterfactual Explanations","summary":"Counterfactual explanations (CE) aim to reveal how small input changes flip a model's prediction, yet many methods modify more features than necessary, reducing clarity and actionability. We introduce \\emph{COLA}, a model- and generator-agnostic post-hoc framework that refines any given CE by computing a coupling via optimal transport (OT) between factual and counterfactual sets and using it to drive a Shapley-based attribution (\\emph{$p$-SHAP}) that selects a minimal set of edits while preserving the target effect. Theoretically, OT minimizes an upper bound on the $W_1$ divergence between factual and counterfactual outcomes and that, under mild conditions, refined counterfactuals are guaranteed not to move farther from the factuals than the originals. Empirically, across four datasets, twelve models, and five CE generators, COLA achieves the same target effects with only 26--45\\% of the original feature edits. On a small-scale benchmark, COLA shows near-optimality.","authors":["Lei You","Yijun Bian","Lele Cao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23997v1","updated":"2026-02-27T13:20:46Z","published":"2026-02-27T13:20:46Z","title":"Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments","summary":"The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt.","authors":["Florent Delgrange"],"pdf_url":"","comment":"AAMAS 2026, Blue Sky Idea Track. 4 pages, 1 Figure"},{"id":"http://arxiv.org/abs/2602.23994v1","updated":"2026-02-27T13:14:54Z","published":"2026-02-27T13:14:54Z","title":"MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening","summary":"Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.","authors":["Vrushank Ahire","Yogesh Kumar","Anouck Girard","M. A. Ganaie"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2503.04398v5","updated":"2026-02-27T13:09:26Z","published":"2025-03-06T12:52:22Z","title":"Semantic Parallelism: Redefining Efficient MoE Inference via Model-Data Co-Scheduling","summary":"Prevailing LLM serving engines employ expert parallelism (EP) to implement multi-device inference of massive MoE models. However, the efficiency of expert parallel inference is largely bounded by inter-device communication, as EP embraces expensive all-to-all collectives to route tokens to the remote experts if not collocating on the same GPU/NPU device. Nevertheless, state-of-the-art schemes treat expert device-placement and request (or token) device-scheduling as separate concerns, triggering excessive communication between them and compromising inference efficiency\n  This paper proposes Semantic Parallelism, a novel parallelism paradigm that minimizes the steep communication costs in EP-centric MoE serving via model-data collaborative scheduling. We implement Semantic Parallelism in a framework called Sem-MoE. Sem-MoE maximally collocates experts and their activating tokens onto the same device using proactively modeled activation likelihood between them and introduces three key techniques: (1) Offline model scheduling, which preliminarily clusters and collocates experts onto devices based on their co-activation tendencies for certain classes of input. (2) Online inter-request data scheduling for Attention-DP setups, which proactively rebatches incoming requests onto the device that hosts experts most likely and frequently activated by the corresponding requests. (3) Online intra-request data scheduling for Attention-TP setups, which seamlessly fuses a token reshuffling procedure into the original inference pipeline and proactively reschedules tokens to devices to reduce dispersed remote routing. We build Sem-MoE into a prevailing LLM serving engine SGLANG. Experiments show our collaborative scheduling approach can effectively reduce the all-to-all communication volume in EP and achieve superior inference throughput compared to existing solutions.","authors":["Yan Li","Zhenyu Zhang","Zhengang Wang","Pengfei Chen","Pengfei Zheng"],"pdf_url":"","comment":"Published as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2511.15927v3","updated":"2026-02-27T12:57:37Z","published":"2025-11-19T23:23:49Z","title":"DiffuMamba: High-Throughput Diffusion LMs with Mamba Backbone","summary":"Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive (AR) generation, yet their reliance on Transformer backbones limits inference efficiency due to quadratic attention or KV-cache overhead. We introduce DiffuMamba, a masked diffusion language model built on a bidirectional Mamba backbone that combines the diffusion objective with linear-time sequence modeling, and DiffuMamba-H, a hybrid variant with interleaved attention. Across scales up to 1.3B parameters, our models match Transformer-based diffusion in downstream performance while achieving up to 8.2x and 4.3x higher inference throughput, respectively, on long sequences. We further present a systematic analysis of inference efficiency across modern DLM variants combining asymptotic complexity with empirical measurements. Notably, cache-efficient block diffusion with Mamba mixers emerges as the only strategy that scales linearly with sequence length and achieves the strongest performance across all baselines, suggesting a promising direction for future diffusion-based generation systems.","authors":["Vaibhav Singh","Oleksiy Ostapenko","Pierre-André Noël","Eugene Belilovsky","Torsten Scholak"],"pdf_url":"","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2508.11143v2","updated":"2026-02-27T12:54:57Z","published":"2025-08-15T01:27:15Z","title":"Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward","summary":"Existing reinforcement learning (RL) methods struggle with long-horizon robotic manipulation tasks, particularly those involving sparse rewards. While action chunking is a promising paradigm for robotic manipulation, using RL to directly learn continuous action chunks in a stable and data-efficient manner remains a critical challenge. This paper introduces AC3 (Actor-Critic for Continuous Chunks), a novel RL framework that learns to generate high-dimensional, continuous action sequences. To make this learning process stable and data-efficient, AC3 incorporates targeted stabilization mechanisms for both the actor and the critic. First, to ensure reliable policy improvement, the actor is trained with an asymmetric update rule, learning exclusively from successful trajectories. Second, to enable effective value learning despite sparse rewards, the critic's update is stabilized using intra-chunk $n$-step returns and further enriched by a self-supervised module providing intrinsic rewards at anchor points aligned with each action chunk. We conducted extensive experiments on 25 tasks from the BiGym and RLBench benchmarks. Results show that by using only a few demonstrations and a simple model architecture, AC3 achieves superior success rates on most tasks, validating its effective design.","authors":["Jiarui Yang","Bin Zhu","Jingjing Chen","Yu-Gang Jiang"],"pdf_url":"","comment":"14 pages, 13 figures, Accepted by AAAI 2026 (oral)"},{"id":"http://arxiv.org/abs/2602.23981v1","updated":"2026-02-27T12:48:05Z","published":"2026-02-27T12:48:05Z","title":"Intrinsic Lorentz Neural Network","summary":"Real-world data frequently exhibit latent hierarchical structures, which can be naturally represented by hyperbolic geometry. Although recent hyperbolic neural networks have demonstrated promising results, many existing architectures remain partially intrinsic, mixing Euclidean operations with hyperbolic ones or relying on extrinsic parameterizations. To address it, we propose the \\emph{Intrinsic Lorentz Neural Network} (ILNN), a fully intrinsic hyperbolic architecture that conducts all computations within the Lorentz model. At its core, the network introduces a novel \\emph{point-to-hyperplane} fully connected layer (FC), replacing traditional Euclidean affine logits with closed-form hyperbolic distances from features to learned Lorentz hyperplanes, thereby ensuring that the resulting geometric decision functions respect the inherent curvature. Around this fundamental layer, we design intrinsic modules: GyroLBN, a Lorentz batch normalization that couples gyro-centering with gyro-scaling, consistently outperforming both LBN and GyroBN while reducing training time. We additionally proposed a gyro-additive bias for the FC output, a Lorentz patch-concatenation operator that aligns the expected log-radius across feature blocks via a digamma-based scale, and a Lorentz dropout layer. Extensive experiments conducted on CIFAR-10/100 and two genomic benchmarks (TEB and GUE) illustrate that ILNN achieves state-of-the-art performance and computational cost among hyperbolic models and consistently surpasses strong Euclidean baselines. The code is available at \\href{https://github.com/Longchentong/ILNN}{\\textcolor{magenta}{this url}}.","authors":["Xianglong Shi","Ziheng Chen","Yunhan Jiang","Nicu Sebe"],"pdf_url":"","comment":"Published in ICLR 2026"},{"id":"http://arxiv.org/abs/2602.23974v1","updated":"2026-02-27T12:34:20Z","published":"2026-02-27T12:34:20Z","title":"Pessimistic Auxiliary Policy for Offline Reinforcement Learning","summary":"Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.","authors":["Fan Zhang","Baoru Huang","Xin Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23971v1","updated":"2026-02-27T12:27:04Z","published":"2026-02-27T12:27:04Z","title":"Ask don't tell: Reducing sycophancy in large language models","summary":"Sycophancy, the tendency of large language models to favour user-affirming responses over critical engagement, has been identified as an alignment failure, particularly in high-stakes advisory and social contexts. While prior work has documented conversational features correlated with sycophancy, we lack a systematic understanding of what provokes or prevents AI sycophancy. Here, we present a set of controlled experimental studies where we first isolate how input framing influences sycophancy, and second, leverage these findings to develop mitigation strategies. In a nested factorial design, we compare questions to various non-questions where we vary three orthogonal factors: epistemic certainty (statement, belief, conviction), perspective (I- vs user-perspective), and affirmation vs negation. We show that (1) sycophancy is substantially higher in response to non-questions compared to questions. Additionally, we find that (2) sycophancy increases monotonically with epistemic certainty conveyed by the user, and (3) is amplified by I-perspective framing. Building on this, we show that asking a model to convert non-questions into questions before answering significantly reduces sycophancy. Importantly, this effect is stronger than a simple baseline prompt asking models \"not to be sycophantic\". Our work offers a practical and effective input-level mitigation that both developers and users can easily adopt.","authors":["Magda Dubois","Cozmin Ududec","Christopher Summerfield","Lennart Luettgau"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.15909v3","updated":"2026-02-27T12:24:11Z","published":"2026-02-16T14:48:24Z","title":"Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis","summary":"Deep learning-based respiratory auscultation is currently hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe class imbalance. To bridge these gaps, we present Resp-Agent, an autonomous multimodal system orchestrated by a novel Active Adversarial Curriculum Agent (Thinker-A$^2$CA). Unlike static pipelines, Thinker-A$^2$CA serves as a central controller that actively identifies diagnostic weaknesses and schedules targeted synthesis in a closed loop. To address the representation gap, we introduce a modality-weaving Diagnoser that weaves clinical text with audio tokens via strategic global attention and sparse audio anchors, capturing both long-range clinical context and millisecond-level transients. To address the data gap, we design a flow matching Generator that adapts a text-only Large Language Model (LLM) via modality injection, decoupling pathological content from acoustic style to synthesize hard-to-diagnose samples. As a foundation for this work, we introduce Resp-229k, a benchmark corpus of 229k recordings paired with LLM-distilled clinical narratives. Extensive experiments demonstrate that Resp-Agent consistently outperforms prior approaches across diverse evaluation settings, improving diagnostic robustness under data scarcity and long-tailed class imbalance. Our code and data are available at https://github.com/zpforlove/Resp-Agent.","authors":["Pengfei Zhang","Tianxin Xie","Minghao Yang","Li Liu"],"pdf_url":"","comment":"24 pages, 3 figures. Published as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.23960v1","updated":"2026-02-27T12:12:03Z","published":"2026-02-27T12:12:03Z","title":"SHINE: Sequential Hierarchical Integration Network for EEG and MEG","summary":"How natural speech is represented in the brain constitutes a major challenge for cognitive neuroscience, with cortical envelope-following responses playing a central role in speech decoding. This paper presents our approach to the Speech Detection task in the LibriBrain Competition 2025, utilizing over 50 hours of magnetoencephalography (MEG) signals from a single participant listening to LibriVox audiobooks. We introduce the proposed Sequential Hierarchical Integration Network for EEG and MEG (SHINE) to reconstruct the binary speech-silence sequences from MEG signals. In the Extended Track, we further incorporated auxiliary reconstructions of speech envelopes and Mel spectrograms to enhance training. Ensemble methods combining SHINE with baselines (BrainMagic, AWavNet, ConvConcatNet) achieved F1-macro scores of 0.9155 (Standard Track) and 0.9184 (Extended Track) on the leaderboard test set.","authors":["Xiran Xu","Yujie Yan","Xihong Wu","Jing Chen"],"pdf_url":"","comment":"ranked second at LibriBrain Competition 2025 https://neural-processing-lab.github.io/2025-libribrain-competition/prizes/"},{"id":"http://arxiv.org/abs/2511.21135v2","updated":"2026-02-27T12:08:38Z","published":"2025-11-26T07:36:01Z","title":"SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation","summary":"Embodied navigation that adheres to social norms remains an open research challenge. Our SocialNav is a foundational model for socially-aware navigation with a hierarchical \"brain-action\" architecture, capable of understanding high-level social norms and generating low-level, socially compliant trajectories. To enable such dual capabilities, we construct the SocNav Dataset, a large-scale collection of 7 million samples, comprising (1) a Cognitive Activation Dataset providing social reasoning signals such as chain-of-thought explanations and social traversability prediction, and (2) an Expert Trajectories Pyramid aggregating diverse navigation demonstrations from internet videos, simulated environments, and real-world robots. A multi-stage training pipeline is proposed to gradually inject and refine navigation intelligence: we first inject general navigation skills and social norms understanding into the model via imitation learning, and then refine such skills through a deliberately designed Socially-Aware Flow Exploration GRPO (SAFE-GRPO), the first flow-based reinforcement learning framework for embodied navigation that explicitly rewards socially compliant behaviors. SocialNav achieves +38% success rate and +46% social compliance rate compared to the state-of-the-art method, demonstrating strong gains in both navigation performance and social compliance. Our project page: https://amap-eai.github.io/SocialNav/","authors":["Ziyi Chen","Yingnan Guo","Zedong Chu","Minghua Luo","Yanfen Shen","Mingchao Sun","Junjun Hu","Shichao Xie","Kuan Yang","Pei Shi","Zhining Gu","Lu Liu","Honglin Han","Xiaolong Wu","Mu Xu","Yu Zhang","Ning Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23950v1","updated":"2026-02-27T11:52:50Z","published":"2026-02-27T11:52:50Z","title":"Micro-expression Recognition Based on Dual-branch Feature Extraction and Fusion","summary":"Micro-expressions, characterized by transience and subtlety, pose challenges to existing optical flow-based recognition methods. To address this, this paper proposes a dual-branch micro-expression feature extraction network integrated with parallel attention. Key contributions include: 1) a residual network designed to alleviate gradient anishing and network degradation; 2) an Inception network constructed to enhance model representation and suppress interference from irrelevant regions; 3) an adaptive feature fusion module developed to integrate dual-branch features. Experiments on the CASME II dataset demonstrate that the proposed method achieves 74.67% accuracy, outperforming LBP-TOP (by 11.26%), MSMMT (by 3.36%), and other comparative methods.","authors":["Mingjie Zhang","Bo Li","Wanting Liu","Hongyan Cui","Yue Li","Qingwen Li","Hong Li","Ge Gao"],"pdf_url":"","comment":"4 pages, 4 figures,conference paper"},{"id":"http://arxiv.org/abs/2602.23949v1","updated":"2026-02-27T11:50:57Z","published":"2026-02-27T11:50:57Z","title":"HotelQuEST: Balancing Quality and Efficiency in Agentic Search","summary":"Agentic search has emerged as a promising paradigm for adaptive retrieval systems powered by large language models (LLMs). However, existing benchmarks primarily focus on quality, overlooking efficiency factors that are critical for real-world deployment. Moreover, real-world user queries often contain underspecified preferences, a challenge that remains largely underexplored in current agentic search evaluation. As a result, many agentic search systems remain impractical despite their impressive performance. In this work, we introduce HotelQuEST, a benchmark comprising 214 hotel search queries that range from simple factual requests to complex queries, enabling evaluation across the full spectrum of query difficulty. We further address the challenge of evaluating underspecified user preferences by collecting clarifications that make annotators' implicit preferences explicit for evaluation. We find that LLM-based agents achieve higher accuracy than traditional retrievers, but at substantially higher costs due to redundant tool calls and suboptimal routing that fails to match query complexity to model capability. Our analysis exposes inefficiencies in current agentic search systems and demonstrates substantial potential for cost-aware optimization.","authors":["Guy Hadad","Shadi Iskander","Oren Kalinsky","Sofia Tolmach","Ran Levy","Haggai Roitman"],"pdf_url":"","comment":"To be published in EACL 2026"},{"id":"http://arxiv.org/abs/2602.23947v1","updated":"2026-02-27T11:49:56Z","published":"2026-02-27T11:49:56Z","title":"Hierarchical Concept-based Interpretable Models","summary":"Modern deep neural networks remain challenging to interpret due to the opacity of their latent representations, impeding model understanding, debugging, and debiasing. Concept Embedding Models (CEMs) address this by mapping inputs to human-interpretable concept representations from which tasks can be predicted. Yet, CEMs fail to represent inter-concept relationships and require concept annotations at different granularities during training, limiting their applicability. In this paper, we introduce Hierarchical Concept Embedding Models (HiCEMs), a new family of CEMs that explicitly model concept relationships through hierarchical structures. To enable HiCEMs in real-world settings, we propose Concept Splitting, a method for automatically discovering finer-grained sub-concepts from a pretrained CEM's embedding space without requiring additional annotations. This allows HiCEMs to generate fine-grained explanations from limited concept labels, reducing annotation burdens. Our evaluation across multiple datasets, including a user study and experiments on PseudoKitchens, a newly proposed concept-based dataset of 3D kitchen renders, demonstrates that (1) Concept Splitting discovers human-interpretable sub-concepts absent during training that can be used to train highly accurate HiCEMs, and (2) HiCEMs enable powerful test-time concept interventions at different granularities, leading to improved task accuracy.","authors":["Oscar Hill","Mateo Espinosa Zarlenga","Mateja Jamnik"],"pdf_url":"","comment":"Published as a conference paper at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.23945v1","updated":"2026-02-27T11:47:45Z","published":"2026-02-27T11:47:45Z","title":"PointCoT: A Multi-modal Benchmark for Explicit 3D Geometric Reasoning","summary":"While Multimodal Large Language Models (MLLMs) demonstrate proficiency in 2D scenes, extending their perceptual intelligence to 3D point cloud understanding remains a significant challenge. Current approaches focus primarily on aligning 3D features with pre-trained models. However, they typically treat geometric reasoning as an implicit mapping process. These methods bypass intermediate logical steps and consequently suffer from geometric hallucinations. They confidently generate plausible responses that fail to ground in precise structural details. To bridge this gap, we present PointCoT, a novel framework that empowers MLLMs with explicit Chain-of-Thought (CoT) reasoning for 3D data. We advocate for a \\textit{Look, Think, then Answer} paradigm. In this approach, the model is supervised to generate geometry-grounded rationales before predicting final answers. To facilitate this, we construct Point-Reason-Instruct, a large-scale benchmark comprising $\\sim$86k instruction-tuning samples with hierarchical CoT annotations. By leveraging a dual-stream multi-modal architecture, our method synergizes semantic appearance with geometric truth. Extensive experiments demonstrate that PointCoT achieves state-of-the-art performance on complex reasoning tasks.","authors":["Dongxu Zhang","Yiding Sun","Pengcheng Li","Yumou Liu","Hongqiang Lin","Haoran Xu","Xiaoxuan Mu","Liang Lin","Wenbiao Yan","Ning Yang","Chaowei Fang","Juanjuan Zhao","Jihua Zhu","Conghui He","Cheng Tan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23935v1","updated":"2026-02-27T11:35:15Z","published":"2026-02-27T11:35:15Z","title":"Green or Fast? Learning to Balance Cold Starts and Idle Carbon in Serverless Computing","summary":"Serverless computing simplifies cloud deployment but introduces new challenges in managing service latency and carbon emissions. Reducing cold-start latency requires retaining warm function instances, while minimizing carbon emissions favors reclaiming idle resources. This balance is further complicated by time-varying grid carbon intensity and varying workload patterns, under which static keep-alive policies are inefficient. We present LACE-RL, a latency-aware and carbon-efficient management framework that formulates serverless pod retention as a sequential decision problem. LACE-RL uses deep reinforcement learning to dynamically tune keep-alive durations, jointly modeling cold-start probability, function-specific latency costs, and real-time carbon intensity. Using the Huawei Public Cloud Trace, we show that LACE-RL reduces cold starts by 51.69% and idle keep-alive carbon emissions by 77.08% compared to Huawei's static policy, while achieving better latency-carbon trade-offs than state-of-the-art heuristic and single-objective baselines, approaching Oracle performance.","authors":["Bowen Sun","Christos D. Antonopoulos","Evgenia Smirni","Bin Ren","Nikolaos Bellas","Spyros Lalis"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.18182v3","updated":"2026-02-27T11:19:34Z","published":"2026-02-20T12:40:18Z","title":"Capabilities Ain't All You Need: Measuring Propensities in AI","summary":"AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an \"ideal band\". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.","authors":["Daniel Romero-Alvarado","Fernando Martínez-Plumed","Lorenzo Pacchiardi","Hugo Save","Siddhesh Milind Pawar","Behzad Mehrbakhsh","Pablo Antonio Moreno Casares","Ben Slater","Paolo Bova","Peter Romero","Zachary R. Tyler","Jonathan Prunty","Luning Sun","Jose Hernandez-Orallo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.23354v3","updated":"2026-02-27T11:19:16Z","published":"2025-05-29T11:25:47Z","title":"Representing local protein environments with atomistic foundation models","summary":"The local structure of a protein strongly impacts its function and interactions with other molecules. Therefore, a concise, informative representation of a local protein environment is essential for modeling and designing proteins and biomolecular interactions. However, these environments' extensive structural and chemical variability makes them challenging to model, and such representations remain under-explored. In this work, we propose a novel representation for a local protein environment derived from the intermediate features of atomistic foundation models (AFMs). We demonstrate that this embedding effectively captures both local structure (e.g., secondary motifs), and chemical features (e.g., amino-acid identity and protonation state). We further show that the AFM-derived representation space exhibits meaningful structure, enabling the construction of data-driven priors over the distribution of biomolecular environments. Finally, in the context of biomolecular NMR spectroscopy, we demonstrate that the proposed representations enable a first-of-its-kind physics-informed chemical shift predictor that achieves state-of-the-art accuracy. Our results demonstrate the surprising effectiveness of atomistic foundation models and their emergent representations for protein modeling beyond traditional molecular simulations. We believe this will open new lines of work in constructing effective functional representations for protein environments.","authors":["Meital Bojan","Sanketh Vedula","Advaith Maddipatla","Nadav Bojan Sellam","Federico Napoli","Paul Schanda","Alex M. Bronstein"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23916v1","updated":"2026-02-27T11:04:15Z","published":"2026-02-27T11:04:15Z","title":"The Geometry of Transfer: Unlocking Medical Vision Manifolds for Training-Free Model Ranking","summary":"The advent of large-scale self-supervised learning (SSL) has produced a vast zoo of medical foundation models. However, selecting optimal medical foundation models for specific segmentation tasks remains a computational bottleneck. Existing Transferability Estimation (TE) metrics, primarily designed for classification, rely on global statistical assumptions and fail to capture the topological complexity essential for dense prediction. We propose a novel Topology-Driven Transferability Estimation framework that evaluates manifold tractability rather than statistical overlap. Our approach introduces three components: (1) Global Representation Topology Divergence (GRTD), utilizing Minimum Spanning Trees to quantify feature-label structural isomorphism; (2) Local Boundary-Aware Topological Consistency (LBTC), which assesses manifold separability specifically at critical anatomical boundaries; and (3) Task-Adaptive Fusion, which dynamically integrates global and local metrics based on the semantic cardinality of the target task. Validated on the large-scale OpenMind benchmark across diverse anatomical targets and SSL foundation models, our approach significantly outperforms state-of-the-art baselines by around \\textbf{31\\%} relative improvement in the weighted Kendall, providing a robust, training-free proxy for efficient model selection without the cost of fine-tuning. The code will be made publicly available upon acceptance.","authors":["Jiaqi Tang","Shaoyang Zhang","Xiaoqi Wang","Jiaying Zhou","Yang Liu","Qingchao Chen"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23899v1","updated":"2026-02-27T10:48:14Z","published":"2026-02-27T10:48:14Z","title":"Experience-Guided Self-Adaptive Cascaded Agents for Breast Cancer Screening and Diagnosis with Reduced Biopsy Referrals","summary":"We propose an experience-guided cascaded multi-agent framework for Breast Ultrasound Screening and Diagnosis, called BUSD-Agent, that aims to reduce diagnostic escalation and unnecessary biopsy referrals. Our framework models screening and diagnosis as a two-stage, selective decision-making process. A lightweight `screening clinic' agent, restricted to classification models as tools, selectively filters out benign and normal cases from further diagnostic escalation when malignancy risk and uncertainty are estimated as low. Cases that have higher risks are escalated to the `diagnostic clinic' agent, which integrates richer perception and radiological description tools to make a secondary decision on biopsy referral. To improve agent performance, past records of pathology-confirmed outcomes along with image embeddings, model predictions, and historical agent actions are stored in a memory bank as structured decision trajectories. For each new case, BUSD-Agent retrieves similar past cases based on image, model response and confidence similarity to condition the agent's current decision policy. This enables retrieval-conditioned in-context adaptation that dynamically adjusts model trust and escalation thresholds from prior experiences without parameter updates. Evaluation across 10 breast ultrasound datasets shows that the proposed experience-guided workflow reduces diagnostic escalation in BUSD-Agent from 84.95% to 58.72% and overall biopsy referrals from 59.50% to 37.08%, compared to the same architecture without trajectory conditioning, while improving average screening specificity by 68.48% and diagnostic specificity by 6.33%.","authors":["Pramit Saha","Mohammad Alsharid","Joshua Strong","J. Alison Noble"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23898v1","updated":"2026-02-27T10:47:26Z","published":"2026-02-27T10:47:26Z","title":"Ref-Adv: Exploring MLLM Visual Reasoning in Referring Expression Tasks","summary":"Referring Expression Comprehension (REC) links language to region level visual perception. Standard benchmarks (RefCOCO, RefCOCO+, RefCOCOg) have progressed rapidly with multimodal LLMs but remain weak tests of visual reasoning and grounding: (i) many expressions are very short, leaving little reasoning demand; (ii) images often contain few distractors, making the target easy to find; and (iii) redundant descriptors enable shortcut solutions that bypass genuine text understanding and visual reasoning. We introduce Ref-Adv, a modern REC benchmark that suppresses shortcuts by pairing linguistically nontrivial expressions with only the information necessary to uniquely identify the target. The dataset contains referring expressions on real images, curated with hard distractors and annotated with reasoning facets including negation. We conduct comprehensive ablations (word order perturbations and descriptor deletion sufficiency) to show that solving Ref-Adv requires reasoning beyond simple cues, and we evaluate a broad suite of contemporary multimodal LLMs on Ref-Adv. Despite strong results on RefCOCO, RefCOCO+, and RefCOCOg, models drop markedly on Ref-Adv, revealing reliance on shortcuts and gaps in visual reasoning and grounding. We provide an in depth failure analysis and aim for Ref-Adv to guide future work on visual reasoning and grounding in MLLMs.","authors":["Qihua Dong","Kuo Yang","Lin Ju","Handong Zhao","Yitian Zhang","Yizhou Wang","Huimin Zeng","Jianglin Lu","Yun Fu"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.06596v2","updated":"2026-02-27T10:38:24Z","published":"2026-02-06T10:47:47Z","title":"Personality as Relational Infrastructure: User Perceptions of Personality-Trait-Infused LLM Messaging","summary":"Digital behaviour change systems increasingly rely on repeated, system-initiated messages to support users in everyday contexts. LLMs enable these messages to be personalised consistently across interactions, yet it remains unclear whether such personalisation improves individual messages or instead shapes users' perceptions through patterns of exposure. We explore this question in the context of LLM-generated JITAIs, which are short, context-aware messages delivered at moments deemed appropriate to support behaviour change, using physical activity as an application domain. In a controlled retrospective study, 90 participants evaluated messages generated using four LLM strategies: baseline prompting, few-shot prompting, fine-tuned models, and retrieval augmented generation, each implemented with and without Big Five Personality Traits to produce personality-aligned communication across multiple scenarios. Using ordinal multilevel models with within-between decomposition, we distinguish trial-level effects, whether personality information improves evaluations of individual messages, from person-level exposure effects, whether participants receiving higher proportions of personality-informed messages exhibit systematically different overall perceptions. Results showed no trial-level associations, but participants who received higher proportions of BFPT-informed messages rated the messages as more personalised, appropriate, and reported less negative affect. We use Communication Accommodation Theory for post-hoc analysis. These results suggest that personality-based personalisation in behaviour change systems may operate primarily through aggregate exposure rather than per-message optimisation, with implications for how adaptive systems are designed and evaluated in sustained human-AI interaction. In-situ longitudinal studies are needed to validate these findings in real-world contexts.","authors":["Dominik P. Hofer","David Haag","Rania Islambouli","Jan D. Smeddinck"],"pdf_url":"","comment":"Currently under review"},{"id":"http://arxiv.org/abs/2602.23887v1","updated":"2026-02-27T10:24:49Z","published":"2026-02-27T10:24:49Z","title":"Uncovering sustainable personal care ingredient combinations using scientific modelling","summary":"Personal care formulations often contain synthetic and non-biodegradable ingredients, such as silicone and mineral oils, which can offer a unique performance. However, due to regulations like the EU ban of Octamethylcyclotetrasiloxane (D4), Decamethyl-cyclopentasiloxane (D5), Dodecamethylcyclohexasiloxane (D6) already in effect for rinse off and for leave on cosmetics by June 2027 coupled with growing consumer awareness and expectations on sustainability, personal care brands face significant pressure to replace these synthetic ingredients with natural alternatives without compromising performance and cost. As a result, formulators are confronted with the challenge to find natural-based solutions within a short timeframe. In this study, we propose a pioneering approach that utilizes predicting modelling and simulation-based digital services to obtain natural-based ingredient combinations as recommendations to commonly used synthetic ingredients. We will demonstrate the effectiveness of our predictions through the application of these proposals in specific formulations. By offering a platform of digital services, it is aimed to empower formulators to explore good performing novel and environmentally friendly alternatives, ultimately driving a substantial and genuine transformation in the personal care industry.","authors":["Sandip Bhattacharya","Vanessa da Silva","Christina Kohlmann"],"pdf_url":"","comment":"Paper submitted and part of 35th IFSCC Congress, Brazil, 14-17 October 2024"},{"id":"http://arxiv.org/abs/2602.23876v1","updated":"2026-02-27T10:18:12Z","published":"2026-02-27T10:18:12Z","title":"RF-Agent: Automated Reward Function Design via Language Agent Tree Search","summary":"Designing efficient reward functions for low-level control tasks is a challenging problem. Recent research aims to reduce reliance on expert experience by using Large Language Models (LLMs) with task information to generate dense reward functions. These methods typically rely on training results as feedback, iteratively generating new reward functions with greedy or evolutionary algorithms. However, they suffer from poor utilization of historical feedback and inefficient search, resulting in limited improvements in complex control tasks. To address this challenge, we propose RF-Agent, a framework that treats LLMs as language agents and frames reward function design as a sequential decision-making process, enhancing optimization through better contextual reasoning. RF-Agent integrates Monte Carlo Tree Search (MCTS) to manage the reward design and optimization process, leveraging the multi-stage contextual reasoning ability of LLMs. This approach better utilizes historical information and improves search efficiency to identify promising reward functions. Outstanding experimental results in 17 diverse low-level control tasks demonstrate the effectiveness of our method. The source code is available at https://github.com/deng-ai-lab/RF-Agent.","authors":["Ning Gao","Xiuhui Zhang","Xingyu Jiang","Mukang You","Mohan Zhang","Yue Deng"],"pdf_url":"","comment":"39 pages, 9 tables, 11 figures, Project page see https://github.com/deng-ai-lab/RF-Agent"},{"id":"http://arxiv.org/abs/2602.23874v1","updated":"2026-02-27T10:16:28Z","published":"2026-02-27T10:16:28Z","title":"Exploring Robust Intrusion Detection: A Benchmark Study of Feature Transferability in IoT Botnet Attack Detection","summary":"Cross-domain intrusion detection remains a critical challenge due to significant variability in network traffic characteristics and feature distributions across environments. This study evaluates the transferability of three widely used flow-based feature sets (Argus, Zeek and CICFlowMeter) across four widely used datasets representing heterogeneous IoT and Industrial IoT network conditions. Through extensive experiments, we evaluate in- and cross-domain performance across multiple classification models and analyze feature importance using SHapley Additive exPlanations (SHAP). Our results show that models trained on one domain suffer significant performance degradation when applied to a different target domain, reflecting the sensitivity of IoT intrusion detection systems to distribution shifts. Furthermore, the results evidence that the choice of classification algorithm and feature representations significantly impact transferability. Beyond reporting performance differences and thorough analysis of the transferability of features and feature spaces, we provide practical guidelines for feature engineering to improve robustness under domain variability. Our findings suggest that effective intrusion detection requires both high in-domain performance and resilience to cross-domain variability, achievable through careful feature space design, appropriate algorithm selection and adaptive strategies.","authors":["Alejandro Guerra-Manzanares","Jialin Huang"],"pdf_url":"","comment":"Accepted for publication in the Proceedings of the 2026 International Conference on Information Systems Security and Privacy (ICISSP)"},{"id":"http://arxiv.org/abs/2602.23864v1","updated":"2026-02-27T10:04:26Z","published":"2026-02-27T10:04:26Z","title":"RUMAD: Reinforcement-Unifying Multi-Agent Debate","summary":"Multi-agent debate (MAD) systems leverage collective intelligence to enhance reasoning capabilities, yet existing approaches struggle to simultaneously optimize accuracy, consensus formation, and computational efficiency. Static topology methods lack adaptability to task complexity variations, while external LLM-based coordination risks introducing privileged knowledge that compromises debate neutrality. This work presents RUMAD (Reinforcement-Unifying Multi-Agent Debate), a novel framework that formulates dynamic communication topology control in MAD as a reinforcement learning (RL) problem.\n  RUMAD employs a content-agnostic observation scheme that captures high-level debate dynamics avoiding access to raw agent reasoning content. RUMAD uses a multi-objective reward to model solution quality, cohesion and efficiency. A PPO-trained controller dynamically adjusts edge weights in the communication graph, while a dual-threshold mechanism enables fine-grained control over both agent activation and information visibility.\n  Experimental evaluation across MMLU, GSM8K, and GPQA benchmarks demonstrates that RUMAD achieves substantial efficiency gains, reducing token costs by over 80\\%, while still improving reasoning accuracy compared to single LLM model and multiple MAD baselines. Notably, RUMAD trained exclusively on MMLU exhibits robust zero-shot generalization to out-of-domain (OOD) tasks, indicating that the learned communication strategies capture task-independent principles of effective multi-agent coordination. These results establish RUMAD as a efficient and robust approach for deploying multi-agent reasoning application with practical resource constraints.","authors":["Chao Wang","Han Lin","Huaze Tang","Huijing Lin","Wenbo Ding"],"pdf_url":"","comment":"13 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.17649v2","updated":"2026-02-27T09:59:37Z","published":"2025-11-20T09:52:20Z","title":"SWITCH: Benchmarking Modeling and Handling of Tangible Interfaces in Long-horizon Embodied Scenarios","summary":"Autonomous agents operating in the real world must interact continuously with existing physical and semantic infrastructure, track delayed consequences, and verify outcomes over time. Everyday environments are rich in tangible control interfaces (TCIs)-e.g., light switches, appliance panels, and embedded GUI-posing core challenges for lifelong embodied agents, including partial observability, causal reasoning across time, and failure-aware verification under real-world constraints. Yet, current benchmarks rarely consider such long-horizon interaction and causality requirements. We introduce SWITCH (Semantic World Interface Tasks for Control & Handling), an embodied, task-driven benchmark created through iterative releases to probe these gaps. Its first iteration, SWITCH-Basic, evaluates five complementary abilities-task-aware VQA, semantic UI grounding, action generation, state transition prediction, and result verification-under ego-centric RGB video input and device diversity across 351 tasks spanning 98 real devices/appliances. Results from commercial and open LMMMs reveal systematic failures, highlighting critical gaps for lifelong agent deployment. SWITCH provides data, code, and held-out splits to enable reproducible non-contaminated evaluation and community contributions toward more challenging future iterations of the benchmark and the creation of relevant training data. Benchmark resources are available at: https://github.com/BAAI-Agents/SWITCH.","authors":["Jieru Lin","Zhiwei Yu","Börje F. Karlsson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2601.22664v2","updated":"2026-02-27T09:45:07Z","published":"2026-01-30T07:32:35Z","title":"Real-Time Aligned Reward Model beyond Semantics","summary":"Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique for aligning large language models (LLMs) with human preferences, yet it is susceptible to reward overoptimization, in which policy models overfit to the reward model, exploit spurious reward patterns instead of faithfully capturing human intent. Prior mitigations primarily relies on surface semantic information and fails to efficiently address the misalignment between the reward model (RM) and the policy model caused by continuous policy distribution shifts. This inevitably leads to an increasing reward discrepancy, exacerbating reward overoptimization. To address these limitations, we introduce R2M (Real-Time Aligned Reward Model), a novel lightweight RLHF framework. R2M goes beyond vanilla reward models that solely depend on the semantic representations of a pretrained LLM. Instead, it leverages the evolving hidden states of the policy (namely policy feedback) to align with the real-time distribution shift of the policy during the RL process. This work points to a promising new direction for improving the performance of reward models through real-time utilization of feedback from policy models.","authors":["Zixuan Huang","Xin Xia","Yuxi Ren","Jianbin Zheng","Xuefeng Xiao","Hongyan Xie","Li Huaqiu","Songshi Liang","Zhongxiang Dai","Fuzhen Zhuang","Jianxin Li","Yikun Ban","Deqing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.08354v3","updated":"2026-02-27T09:41:23Z","published":"2026-02-09T07:38:22Z","title":"Does Your Reasoning Model Implicitly Know When to Stop Thinking?","summary":"Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy. In a further in-depth analysis of this phenomenon, we surprisingly uncover and empirically verify that LRMs implicitly know the appropriate time to stop thinking, while this capability is obscured by current sampling paradigms. Motivated by this, we introduce SAGE (Self-Aware Guided Efficient Reasoning), a novel sampling paradigm that unleashes this efficient reasoning potential. Furthermore, integrating SAGE as mixed sampling into group-based reinforcement learning (SAGE-RL) enables SAGE-RL to effectively incorporate SAGE-discovered efficient reasoning patterns into standard pass@1 inference, markedly enhancing both the reasoning accuracy and efficiency of LRMs across multiple challenging mathematical benchmarks.","authors":["Zixuan Huang","Xin Xia","Yuxi Ren","Jianbin Zheng","Xuanda Wang","Zhixia Zhang","Hongyan Xie","Songshi Liang","Zehao Chen","Xuefeng Xiao","Fuzhen Zhuang","Jianxin Li","Yikun Ban","Deqing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23846v1","updated":"2026-02-27T09:37:05Z","published":"2026-02-27T09:37:05Z","title":"MI$^2$DAS: A Multi-Layer Intrusion Detection Framework with Incremental Learning for Securing Industrial IoT Networks","summary":"The rapid expansion of Industrial IoT (IIoT) systems has amplified security challenges, as heterogeneous devices and dynamic traffic patterns increase exposure to sophisticated and previously unseen cyberattacks. Traditional intrusion detection systems often struggle in such environments due to their reliance on extensive labeled data and limited ability to detect new threats. To address these challenges, we propose MI$^2$DAS, a multi-layer intrusion detection framework that integrates anomaly-based hierarchical traffic pooling, open-set recognition to distinguish between known and unknown attacks and incremental learning for adapting to novel attack types with minimal labeling. Experiments conducted on the Edge-IIoTset dataset demonstrate strong performance across all layers. In the first layer, GMM achieves superior normal-attack discrimination (accuracy = 0.953, TPR = 1.000). In open-set recognition, GMM attains a recall of 0.813 for known attacks, while LOF achieves 0.882 recall for unknown attacks. For fine-grained classification of known attacks, Random Forest achieves a macro-F1 of 0.941. Finally, the incremental learning module maintains robust performance when incorporation novel attack classes, achieving a macro-F1 of 0.8995. These results showcase MI$^2$DAS as an effective, scalable and adaptive framework for enhancing IIoT security against evolving threats.","authors":["Wei Lian","Alejandro Guerra-Manzanares"],"pdf_url":"","comment":"Accepted for publication in the Proceedings of the 2026 International Conference on Information Systems Security and Privacy (ICISSP)"},{"id":"http://arxiv.org/abs/2602.22983v2","updated":"2026-02-27T09:27:35Z","published":"2026-02-26T13:25:35Z","title":"Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search","summary":"As Large Language Models (LLMs) are increasingly used, their security risks have drawn increasing attention. Existing research reveals that LLMs are highly susceptible to jailbreak attacks, with effectiveness varying across language contexts. This paper investigates the role of classical Chinese in jailbreak attacks. Owing to its conciseness and obscurity, classical Chinese can partially bypass existing safety constraints, exposing notable vulnerabilities in LLMs. Based on this observation, this paper proposes a framework, CC-BOS, for the automatic generation of classical Chinese adversarial prompts based on multi-dimensional fruit fly optimization, facilitating efficient and automated jailbreak attacks in black-box settings. Prompts are encoded into eight policy dimensions-covering role, behavior, mechanism, metaphor, expression, knowledge, trigger pattern and context; and iteratively refined via smell search, visual search, and cauchy mutation. This design enables efficient exploration of the search space, thereby enhancing the effectiveness of black-box jailbreak attacks. To enhance readability and evaluation accuracy, we further design a classical Chinese to English translation module. Extensive experiments demonstrate that effectiveness of the proposed CC-BOS, consistently outperforming state-of-the-art jailbreak attack methods.","authors":["Xun Huang","Simeng Qin","Xiaoshuang Jia","Ranjie Duan","Huanqian Yan","Zhitao Zeng","Fei Yang","Yang Liu","Xiaojun Jia"],"pdf_url":"","comment":"ICLR 2026 Poster"},{"id":"http://arxiv.org/abs/2512.02814v2","updated":"2026-02-27T09:24:21Z","published":"2025-12-02T14:25:05Z","title":"Radiologist Copilot: An Agentic Framework Orchestrating Specialized Tools for Reliable Radiology Reporting","summary":"In clinical practice, radiology reporting is an essential yet complex, time-intensive, and error-prone task, particularly for 3D medical images. Existing automated approaches based on medical vision-language models primarily focus on isolated report generation. However, real-world radiology reporting extends far beyond report writing, which requires meticulous image observation and interpretation, appropriate template selection, and rigorous quality control to ensure adherence to clinical standards. This multi-stage, planning-intensive workflow fundamentally exceeds the capabilities of single-pass models. To bridge this gap, we propose Radiologist Copilot, an agentic system that autonomously orchestrates specialized tools to complete the entire radiology reporting workflow rather than isolated report writing. Radiologist Copilot enables region image localization and region analysis planning to support detailed visual reasoning, adopts strategic template selection for standardized report writing, and incorporates dedicated report quality control via quality assessment and feedback-driven iterative refinement. By integrating localization, interpretation, template selection, report composition, and quality control, Radiologist Copilot delivers a comprehensive and clinically aligned radiology reporting workflow. Experimental results demonstrate that it significantly outperforms state-of-the-art methods, supporting radiologists throughout the entire radiology reporting process. The code will be released upon acceptance.","authors":["Yongrui Yu","Zhongzhen Huang","Linjie Mu","Shaoting Zhang","Xiaofan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2312.09120v2","updated":"2026-02-27T09:17:36Z","published":"2023-12-14T16:54:37Z","title":"Less is more -- the Dispatcher/ Executor principle for multi-task Reinforcement Learning","summary":"Humans instinctively know how to neglect details when it comes to solve complex decision making problems in environments with unforeseeable variations. This abstraction process seems to be a vital property for most biological systems and helps to 'abstract away' unnecessary details and boost generalisation. In this work we introduce the dispatcher/ executor principle for the design of multi-task Reinforcement Learning controllers. It suggests to partition the controller in two entities, one that understands the task (the dispatcher) and one that computes the controls for the specific device (the executor) - and to connect these two by a strongly regularizing communication channel. The core rationale behind this position paper is that changes in structure and design principles can improve generalisation properties and drastically enforce data-efficiency. It is in some sense a 'yes, and ...' response to the current trend of using large neural networks trained on vast amounts of data and bet on emerging generalisation properties. While we agree on the power of scaling - in the sense of Sutton's 'bitter lesson' - we will give some evidence, that considering structure and adding design principles can be a valuable and critical component in particular when data is not abundant and infinite, but is a precious resource.","authors":["Martin Riedmiller","Andrea Gesmundo","Tim Hertweck","Roland Hafner"],"pdf_url":"","comment":"Videos showing the results can be found at https://sites.google.com/view/dispatcher-executor"},{"id":"http://arxiv.org/abs/2602.23834v1","updated":"2026-02-27T09:13:23Z","published":"2026-02-27T09:13:23Z","title":"Enhancing Continual Learning for Software Vulnerability Prediction: Addressing Catastrophic Forgetting via Hybrid-Confidence-Aware Selective Replay for Temporal LLM Fine-Tuning","summary":"Recent work applies Large Language Models (LLMs) to source-code vulnerability detection, but most evaluations still rely on random train-test splits that ignore time and overestimate real-world performance. In practice, detectors are deployed on evolving code bases and must recognise future vulnerabilities under temporal distribution shift. This paper investigates continual fine-tuning of a decoder-style language model (microsoft/phi-2 with LoRA) on a CVE-linked dataset spanning 2018-2024, organised into bi-monthly windows. We evaluate eight continual learning strategies, including window-only and cumulative training, replay-based baselines and regularisation-based variants. We propose Hybrid Class-Aware Selective Replay (Hybrid-CASR), a confidence-aware replay method for binary vulnerability classification that prioritises uncertain samples while maintaining a balanced ratio of VULNERABLE and FIXED functions in the replay buffer. On bi-monthly forward evaluation Hybrid-CASR achieves a Macro-F1 of 0.667, improving on the window-only baseline (0.651) by 0.016 with statistically significant gains ($p = 0.026$) and stronger backward retention (IBR@1 of 0.741). Hybrid-CASR also reduces training time per window by about 17 percent compared to the baseline, whereas cumulative training delivers only a minor F1 increase (0.661) at a 15.9-fold computational cost. Overall, the results show that selective replay with class balancing offers a practical accuracy-efficiency trade-off for LLM-based temporal vulnerability detection under continuous temporal drift.","authors":["Xuhui Dou","Hayretdin Bahsi","Alejandro Guerra-Manzanares"],"pdf_url":"","comment":"Accepted for publication in the Proceedings of the 2026 International Conference on Information Systems Security and Privacy (ICISSP)"},{"id":"http://arxiv.org/abs/2509.16622v3","updated":"2026-02-27T09:09:57Z","published":"2025-09-20T10:48:06Z","title":"Audio-Conditioned Diffusion LLMs for ASR and Deliberation Processing","summary":"Diffusion-based large language models (DLLMs) have recently attracted growing interest as an alternative to autoregressive decoders. In this work, we present an empirical study on using the diffusion-based large language model LLaDA for automatic speech recognition (ASR). We first investigate its use as an external deliberation-based processing module for Whisper-LLaMA transcripts. By leveraging the bidirectional attention and denoising capabilities of LLaDA, we explore random masking, low-confidence masking, and semi-autoregressive strategies, showing that Whisper-LLaDA substantially reduces WER compared with the baseline. On LibriSpeech, the best cascade system achieves 2.25%/4.94% WER on test-clean/test-other, representing a 12.3% relative improvement over the Whisper-LLaMA baseline on the test-other split. In contrast, a plain-text LLaDA without acoustic features fails to improve accuracy, highlighting the importance of audio-conditioned embeddings. We further evaluate Whisper-LLaDA as a standalone decoder for ASR with diffusion-based and semi-autoregressive decoding. Most experimental configurations achieve faster inference than the Whisper-LLaMA baseline, although recognition accuracy is slightly lower. These findings offer an empirical view of diffusion-based LLMs for ASR and point to promising directions for improvements. Code and model are open-sourced at https://github.com/liuzhan22/Diffusion-ASR.","authors":["Mengqi Wang","Zhan Liu","Zengrui Jin","Guangzhi Sun","Chao Zhang","Philip C. Woodland"],"pdf_url":"","comment":"Accepted to ICASSP 2026"},{"id":"http://arxiv.org/abs/2508.16242v2","updated":"2026-02-27T09:08:50Z","published":"2025-08-22T09:22:26Z","title":"A Reduction of Input/Output Logics to SAT","summary":"Deontic logics are formalisms for reasoning over norms, obligations, permissions and prohibitions. Input/Output (I/O) Logics are a particular family of so-called norm-based deontic logics that formalize conditional norms outside of the underlying object logic language, where conditional norms do not carry a truth-value themselves. In this paper, an automation approach for I/O logics is presented that makes use of suitable reductions to (sequences of) propositional satisfiability problems. A prototypical implementation, named rio (reasoner for input/output logics), of the proposed procedures is presented and applied to illustrative examples.","authors":["Alexander Steen"],"pdf_url":"","comment":"34 pages"},{"id":"http://arxiv.org/abs/2602.23827v1","updated":"2026-02-27T09:07:47Z","published":"2026-02-27T09:07:47Z","title":"FedNSAM:Consistency of Local and Global Flatness for Federated Learning","summary":"In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \\textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \\textbf{flatness distance}, we propose a novel \\textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \\textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \\textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.","authors":["Junkang Liu","Fanhua Shang","Yuxuan Tian","Hongying Liu","Yuanyuan Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.12113v2","updated":"2026-02-27T09:05:31Z","published":"2026-02-12T16:04:00Z","title":"Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty","summary":"Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .","authors":["Zewei Yu","Lirong Gao","Yuke Zhu","Bo Zheng","Junbo Zhao","Sheng Guo","Haobo Wang"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2510.00060v3","updated":"2026-02-27T09:00:30Z","published":"2025-09-29T05:14:18Z","title":"Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving","summary":"In this work, we reconceptualize autonomous driving as a generalized language problem and formulate the trajectory planning task as next waypoint prediction. We introduce Max-V1, a novel framework for one-stage end-to-end autonomous driving, named in tribute to the renowned Dutch racing driver Max Verstappen. Our framework presents a single-pass generation paradigm that aligns with the inherent sequentiality of driving. This approach leverages the generative capacity of the Vision-Language Model (VLM) to enable end-to-end trajectory prediction directly from front-view camera input. The efficacy of this method is underpinned by a principled supervision strategy derived from statistical modeling. This provides a well-defined learning objective, which makes the framework highly amenable to mastering complex driving policies through imitation learning from large-scale expert demonstrations. Empirically, our method achieves state-of-the-art performance on the nuScenes dataset, delivering an overall improvement of over 30% compared to prior baselines. Furthermore, it exhibits superior generalization performance on cross-domain datasets acquired from diverse vehicles, demonstrating notable potential for cross-vehicle robustness and adaptability. With these empirical strengths, this work introduces a model that enables fundamental driving behaviors, laying the foundation for the development of more capable self-driving agents. Code will be available upon publication.","authors":["Sheng Yang","Tong Zhan","Guancheng Chen","Yanfeng Lu","Jian Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21819v2","updated":"2026-02-27T08:58:58Z","published":"2026-02-25T11:47:09Z","title":"SemVideo: Reconstructs What You Watch from Brain Activity via Hierarchical Semantic Guidance","summary":"Reconstructing dynamic visual experiences from brain activity provides a compelling avenue for exploring the neural mechanisms of human visual perception. While recent progress in fMRI-based image reconstruction has been notable, extending this success to video reconstruction remains a significant challenge. Current fMRI-to-video reconstruction approaches consistently encounter two major shortcomings: (i) inconsistent visual representations of salient objects across frames, leading to appearance mismatches; (ii) poor temporal coherence, resulting in motion misalignment or abrupt frame transitions. To address these limitations, we introduce SemVideo, a novel fMRI-to-video reconstruction framework guided by hierarchical semantic information. At the core of SemVideo is SemMiner, a hierarchical guidance module that constructs three levels of semantic cues from the original video stimulus: static anchor descriptions, motion-oriented narratives, and holistic summaries. Leveraging this semantic guidance, SemVideo comprises three key components: a Semantic Alignment Decoder that aligns fMRI signals with CLIP-style embeddings derived from SemMiner, a Motion Adaptation Decoder that reconstructs dynamic motion patterns using a novel tripartite attention fusion architecture, and a Conditional Video Render that leverages hierarchical semantic guidance for video reconstruction. Experiments conducted on the CC2017 and HCP datasets demonstrate that SemVideo achieves superior performance in both semantic alignment and temporal consistency, setting a new state-of-the-art in fMRI-to-video reconstruction.","authors":["Minghan Yang","Lan Yang","Ke Li","Honggang Zhang","Kaiyue Pang","Yizhe Song"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23816v1","updated":"2026-02-27T08:55:29Z","published":"2026-02-27T08:55:29Z","title":"Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective","summary":"Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise\" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.","authors":["George Papadopoulos","George A. Vouros"],"pdf_url":"","comment":"Accepted for publication at AAMAS 2026"},{"id":"http://arxiv.org/abs/2602.23811v1","updated":"2026-02-27T08:51:57Z","published":"2026-02-27T08:51:57Z","title":"Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies","summary":"We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.","authors":["Xiang Li","Nan Jiang","Yuheng Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21997v2","updated":"2026-02-27T08:48:50Z","published":"2025-11-27T00:48:35Z","title":"Joint Estimation of Sea State and Vessel Parameters Using a Mass-Spring-Damper Equivalence Model","summary":"Real-time sea state estimation is vital for applications like shipbuilding and maritime safety. Traditional methods rely on accurate wave-vessel transfer functions to estimate wave spectra from onboard sensors. In contrast, our approach jointly estimates sea state and vessel parameters without needing prior transfer function knowledge, which may be unavailable or variable. We model the wave-vessel system using pseudo mass-spring-dampers and develop a dynamic model for the system. This method allows for recursive modeling of wave excitation as a time-varying input, relaxing prior works' assumption of a constant input. We derive statistically consistent process noise covariance and implement a square root cubature Kalman filter for sensor data fusion. Further, we derive the Posterior Cramer-Rao lower bound to evaluate estimator performance. Extensive Monte Carlo simulations and data from a high-fidelity validated simulator confirm that the estimated wave spectrum matches methods assuming complete transfer function knowledge.","authors":["Ranjeet K. Tiwari","Daniel Sgarioto","Peter Graham","Alexei Skvortsov","Sanjeev Arulampalam","Damith C. Ranasinghe"],"pdf_url":"","comment":"Accepted to journal, Signal Processing"},{"id":"http://arxiv.org/abs/2602.23806v1","updated":"2026-02-27T08:44:47Z","published":"2026-02-27T08:44:47Z","title":"See, Act, Adapt: Active Perception for Unsupervised Cross-Domain Visual Adaptation via Personalized VLM-Guided Agent","summary":"Pre-trained perception models excel in generic image domains but degrade significantly in novel environments like indoor scenes. The conventional remedy is fine-tuning on downstream data which incurs catastrophic forgetting of prior knowledge and demands costly, scene-specific annotations. We propose a paradigm shift through Sea$^2$ (See, Act, Adapt): rather than adapting the perception modules themselves, we adapt how they are deployed through an intelligent pose-control agent. Sea$^2$ keeps all perception modules frozen, requiring no downstream labels during training, and uses only scalar perceptual feedback to navigate the agent toward informative viewpoints. Specially, we transform a vision-language model (VLM) into a low-level pose controller through a two-stage training pipeline: first fine-tuning it on rule-based exploration trajectories that systematically probe indoor scenes, and then refining the policy via unsupervised reinforcement learning that constructs rewards from the perception module's outputs and confidence. Unlike prior active perception methods that couple exploration with specific models or collect data for retraining them, Sea$^2$ directly leverages off-the-shelf perception models for various tasks without the need for retraining. We conducted experiments on three visual perception tasks, including visual grounding, segmentation and 3D box estimation, with performance improvements of 13.54%, 15.92% and 27.68% respectively on dataset ReplicaCAD.","authors":["Tianci Tang","Tielong Cai","Hongwei Wang","Gaoang Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23802v1","updated":"2026-02-27T08:42:52Z","published":"2026-02-27T08:42:52Z","title":"EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models","summary":"Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.","authors":["Yiyang Fang","Wenke Huang","Pei Fu","Yihao Yang","Kehua Su","Zhenbo Luo","Jian Luan","Mang Ye"],"pdf_url":"","comment":"Accepted by CVPR 2026"},{"id":"http://arxiv.org/abs/2509.24159v4","updated":"2026-02-27T08:42:09Z","published":"2025-09-29T01:17:49Z","title":"RE-PO: Robust Enhanced Policy Optimization as a General Framework for LLM Alignment","summary":"Standard human preference-based alignment methods, such as Reinforcement Learning from Human Feedback (RLHF), are a cornerstone for aligning large language models (LLMs) with human values. However, these methods typically assume that preference data is clean and that all labels are equally reliable. In practice, large-scale preference datasets contain substantial noise due to annotator mistakes, inconsistent instructions, varying expertise, and even adversarial or low-effort feedback. This mismatch between recorded labels and ground-truth preferences can misguide training and degrade model performance. To address this issue, we introduce Robust Enhanced Policy Optimization (RE-PO), which uses an expectation-maximization procedure to infer the posterior correctness of each label and then adaptively reweight data points in the training loss to mitigate label noise. We further generalize this idea by establishing a theoretical link between arbitrary preference losses and their underlying probabilistic models, enabling a systematic transformation of existing alignment algorithms into robust counterparts and elevating RE-PO from a single method to a general framework for robust preference alignment. Theoretically, we prove that, under a perfectly calibrated model, RE-PO recovers the true noise level of the dataset. Empirically, we show that RE-PO consistently improves four state-of-the-art alignment methods (DPO, IPO, SimPO, and CPO); when applied to Mistral and Llama 3 models, the RE-PO-enhanced variants increase AlpacaEval 2 win rates by up to 7.0 percent over their respective baselines.","authors":["Xiaoyang Cao","Zelai Xu","Mo Guang","Kaiwen Long","Michiel A. Bakker","Yu Wang","Chao Yu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23800v1","updated":"2026-02-27T08:40:17Z","published":"2026-02-27T08:40:17Z","title":"Operationalizing Longitudinal Causal Discovery Under Real-World Workflow Constraints","summary":"Causal discovery has achieved substantial theoretical progress, yet its deployment in large-scale longitudinal systems remains limited. A key obstacle is that operational data are generated under institutional workflows whose induced partial orders are rarely formalized, enlarging the admissible graph space in ways inconsistent with the recording process. We characterize a workflow-induced constraint class for longitudinal causal discovery that restricts the admissible directed acyclic graph space through protocol-derived structural masks and timeline-aligned indexing. Rather than introducing a new optimization algorithm, we show that explicitly encoding workflow-consistent partial orders reduces structural ambiguity, especially in mixed discrete--continuous panels where within-time orientation is weakly identified. The framework combines workflow-derived admissible-edge constraints, measurement-aligned time indexing and block structure, bootstrap-based uncertainty quantification for lagged total effects, and a dynamic representation supporting intervention queries. In a nationwide annual health screening cohort in Japan with 107,261 individuals and 429,044 person-years, workflow-constrained longitudinal LiNGAM yields temporally consistent within-time substructures and interpretable lagged total effects with explicit uncertainty. Sensitivity analyses using alternative exposure and body-composition definitions preserve the main qualitative patterns. We argue that formalizing workflow-derived constraint classes improves structural interpretability without relying on domain-specific edge specification, providing a reproducible bridge between operational workflows and longitudinal causal discovery under standard identifiability assumptions.","authors":["Tadahisa Okuda","Shohei Shimizu","Thong Pham","Tatsuyoshi Ikenoue","Shingo Fukuma"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23798v1","updated":"2026-02-27T08:39:36Z","published":"2026-02-27T08:39:36Z","title":"MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models","summary":"Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.","authors":["Tiantong Wang","Xinyu Yan","Tiantong Wu","Yurong Hao","Yong Jiang","Fei Huang","Wei Yang Bryan Lim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04970v2","updated":"2026-02-27T08:38:16Z","published":"2025-10-06T16:04:53Z","title":"Embracing Discrete Search: A Reasonable Approach to Causal Structure Learning","summary":"We present FLOP (Fast Learning of Order and Parents), a score-based causal discovery algorithm for linear models. It pairs fast parent selection with iterative Cholesky-based score updates, cutting run-times over prior algorithms. This makes it feasible to fully embrace discrete search, enabling iterated local search with principled order initialization to find graphs with scores at or close to the global optimum. The resulting structures are highly accurate across benchmarks, with near-perfect recovery in standard settings. This performance calls for revisiting discrete search over graphs as a reasonable approach to causal discovery.","authors":["Marcel Wienöbst","Leonard Henckel","Sebastian Weichwald"],"pdf_url":"","comment":"Accepted at ICLR 2026"},{"id":"http://arxiv.org/abs/2602.23789v1","updated":"2026-02-27T08:34:56Z","published":"2026-02-27T08:34:56Z","title":"UPath: Universal Planner Across Topological Heterogeneity For Grid-Based Pathfinding","summary":"The performance of search algorithms for grid-based pathfinding, e.g. A*, critically depends on the heuristic function that is used to focus the search. Recent studies have shown that informed heuristics that take the positions/shapes of the obstacles into account can be approximated with the deep neural networks. Unfortunately, the existing learning-based approaches mostly rely on the assumption that training and test grid maps are drawn from the same distribution (e.g., city maps, indoor maps, etc.) and perform poorly on out-of-distribution tasks. This naturally limits their application in practice when often a universal solver is needed that is capable of efficiently handling any problem instance. In this work, we close this gap by designing an universal heuristic predictor: a model trained once, but capable of generalizing across a full spectrum of unseen tasks. Our extensive empirical evaluation shows that the suggested approach halves the computational effort of A* by up to a factor of 2.2, while still providing solutions within 3% of the optimal cost on average altogether on the tasks that are completely different from the ones used for training $\\unicode{x2013}$ a milestone reached for the first time by a learnable solver.","authors":["Aleksandr Ananikian","Daniil Drozdov","Konstantin Yakovlev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23784v1","updated":"2026-02-27T08:26:53Z","published":"2026-02-27T08:26:53Z","title":"TradeFM: A Generative Foundation Model for Trade-flow and Market Microstructure","summary":"Foundation models have transformed domains from language to genomics by learning general-purpose representations from large-scale, heterogeneous data. We introduce TradeFM, a 524M-parameter generative Transformer that brings this paradigm to market microstructure, learning directly from billions of trade events across >9K equities. To enable cross-asset generalization, we develop scale-invariant features and a universal tokenization scheme that map the heterogeneous, multi-modal event stream of order flow into a unified discrete sequence -- eliminating asset-specific calibration. Integrated with a deterministic market simulator, TradeFM-generated rollouts reproduce key stylized facts of financial returns, including heavy tails, volatility clustering, and absence of return autocorrelation. Quantitatively, TradeFM achieves 2-3x lower distributional error than Compound Hawkes baselines and generalizes zero-shot to geographically out-of-distribution APAC markets with moderate perplexity degradation. Together, these results suggest that scale-invariant trade representations capture transferable structure in market microstructure, opening a path toward synthetic data generation, stress testing, and learning-based trading agents.","authors":["Maxime Kawawa-Beaudan","Srijan Sood","Kassiani Papasotiriou","Daniel Borrajo","Manuela Veloso"],"pdf_url":"","comment":"29 pages, 17 figures, 6 tables. Preprint"},{"id":"http://arxiv.org/abs/2602.23296v2","updated":"2026-02-27T08:21:48Z","published":"2026-02-26T18:07:45Z","title":"Conformalized Neural Networks for Federated Uncertainty Quantification under Dual Heterogeneity","summary":"Federated learning (FL) faces challenges in uncertainty quantification (UQ). Without reliable UQ, FL systems risk deploying overconfident models at under-resourced agents, leading to silent local failures despite seemingly satisfactory global performance. Existing federated UQ approaches often address data heterogeneity or model heterogeneity in isolation, overlooking their joint effect on coverage reliability across agents. Conformal prediction is a widely used distribution-free UQ framework, yet its applications in heterogeneous FL settings remains underexplored. We provide FedWQ-CP, a simple yet effective approach that balances empirical coverage performance with efficiency at both global and agent levels under the dual heterogeneity. FedWQ-CP performs agent-server calibration in a single communication round. On each agent, conformity scores are computed on calibration data and a local quantile threshold is derived. Each agent then transmits only its quantile threshold and calibration sample size to the server. The server simply aggregates these thresholds through a weighted average to produce a global threshold. Experimental results on seven public datasets for both classification and regression demonstrate that FedWQ-CP empirically maintains agent-wise and global coverage while producing the smallest prediction sets or intervals.","authors":["Quang-Huy Nguyen","Jiaqi Wang","Wei-Shinn Ku"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23234v6","updated":"2026-02-27T08:16:50Z","published":"2025-09-27T10:33:41Z","title":"p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding","summary":"Obtaining high-quality outputs from Large Language Models (LLMs) often depends upon the choice of a sampling-based decoding strategy to probabilistically choose the next token at each generation step. While a variety of such sampling methods have been proposed, their performance can be sensitive to the selection of hyperparameters which may require different settings depending upon the generation task and temperature configuration. In this work, we introduce $p$-less sampling: an information-theoretic approach to sampling which dynamically sets a truncation threshold at each decoding step based on the entire token probability distribution. Unlike existing methods, $p$-less sampling has no hyperparameters and consistently produces high-quality outputs as temperature increases. We provide theoretical perspectives on $p$-less sampling to ground our proposed method and conduct experiments to empirically validate its effectiveness across a range of math, logical reasoning, and creative writing tasks. Our results demonstrate how $p$-less sampling consistently outperforms existing sampling approaches while exhibiting much less degradation in text quality at higher temperature values. We further show how $p$-less achieves greater inference-time efficiency than alternative methods through lower average token sampling times and shorter generation lengths, without sacrificing accuracy. Finally, we provide analyses to highlight the benefits of $p$-less through qualitative examples, case studies, and diversity assessments. The code is available at https://github.com/ryttry/p-less .","authors":["Runyan Tan","Shuang Wu","Phillip Howard"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23777v1","updated":"2026-02-27T08:10:06Z","published":"2026-02-27T08:10:06Z","title":"Reasoning-Driven Multimodal LLM for Domain Generalization","summary":"This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.","authors":["Zhipeng Xu","Zilong Wang","Xinyang Jiang","Dongsheng Li","De Cheng","Nannan Wang"],"pdf_url":"","comment":"Accepted at ICLR 2026 (Poster)"},{"id":"http://arxiv.org/abs/2602.23061v2","updated":"2026-02-27T08:09:20Z","published":"2026-02-26T14:48:49Z","title":"MoDora: Tree-Based Semi-Structured Document Analysis System","summary":"Semi-structured documents integrate diverse interleaved data elements (e.g., tables, charts, hierarchical paragraphs) arranged in various and often irregular layouts. These documents are widely observed across domains and account for a large portion of real-world data. However, existing methods struggle to support natural language question answering over these documents due to three main technical challenges: (1) The elements extracted by techniques like OCR are often fragmented and stripped of their original semantic context, making them inadequate for analysis. (2) Existing approaches lack effective representations to capture hierarchical structures within documents (e.g., associating tables with nested chapter titles) and to preserve layout-specific distinctions (e.g., differentiating sidebars from main content). (3) Answering questions often requires retrieving and aligning relevant information scattered across multiple regions or pages, such as linking a descriptive paragraph to table cells located elsewhere in the document.\n  To address these issues, we propose MoDora, an LLM-powered system for semi-structured document analysis. First, we adopt a local-alignment aggregation strategy to convert OCR-parsed elements into layout-aware components, and conduct type-specific information extraction for components with hierarchical titles or non-text elements. Second, we design the Component-Correlation Tree (CCTree) to hierarchically organize components, explicitly modeling inter-component relations and layout distinctions through a bottom-up cascade summarization process. Finally, we propose a question-type-aware retrieval strategy that supports (1) layout-based grid partitioning for location-based retrieval and (2) LLM-guided pruning for semantic-based retrieval. Experiments show MoDora outperforms baselines by 5.97%-61.07% in accuracy. The code is at https://github.com/weAIDB/MoDora.","authors":["Bangrui Xu","Qihang Yao","Zirui Tang","Xuanhe Zhou","Yeye He","Shihan Yu","Qianqian Xu","Bin Wang","Guoliang Li","Conghui He","Fan Wu"],"pdf_url":"","comment":"Extension of our SIGMOD 2026 paper. Please refer to source code available at https://github.com/weAIDB/MoDora"},{"id":"http://arxiv.org/abs/2602.02090v2","updated":"2026-02-27T08:09:02Z","published":"2026-02-02T13:37:17Z","title":"LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs","summary":"Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.","authors":["Yikai Zeng","Yingchao Piao","Changhua Pei","Jianhui Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.06269v2","updated":"2026-02-27T07:59:18Z","published":"2025-08-08T12:38:56Z","title":"OM2P: Offline Multi-Agent Mean-Flow Policy","summary":"Generative models, especially diffusion and flow-based models, have been promising in offline multi-agent reinforcement learning. However, integrating powerful generative models into this framework poses unique challenges. In particular, diffusion and flow-based policies suffer from low sampling efficiency due to their iterative generation processes, making them impractical in time-sensitive or resource-constrained settings. To tackle these difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel offline MARL algorithm to achieve efficient one-step action sampling. To address the misalignment between generative objectives and reward maximization, we introduce a reward-aware optimization scheme that integrates a carefully-designed mean-flow matching loss with Q-function supervision. Additionally, we design a generalized timestep distribution and a derivative-free estimation strategy to reduce memory overhead and improve training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo benchmarks demonstrate that OM2P achieves superior performance, with up to a 3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time. Our approach represents the first to successfully integrate mean-flow model into offline MARL, paving the way for practical and scalable generative policies in cooperative multi-agent settings.","authors":["Zhuoran Li","Xun Wang","Hai Zhong","Qingxin Xia","Lihua Zhang","Longbo Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.18395v3","updated":"2026-02-27T07:56:55Z","published":"2025-08-25T18:36:28Z","title":"Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning","summary":"Probabilistic decoding in Large Language Models (LLMs) often yields inconsistent outputs, particularly on complex or long-form questions. Self-Consistency (SC) mitigates this for short-form QA by majority voting over exact strings, whereas Universal Self-Consistency (USC) and Weighted Unigram Consistency Score (WUCS) extend to long-form responses but lose accuracy on short-form benchmarks.\n  We introduce \\textbf{Latent Self-Consistency (LSC)}, which selects the most semantically consistent response using learnable token embeddings. LSC's lightweight forward processing of summary tokens only introduces negligible runtime overhead (at most $0.9\\%$) on top of standard decoding of the base LLM, and requires no changes to the model architecture.\n  Across 6 short-form and 5 long-form reasoning benchmarks (e.g., MATH, MMLU, TruthfulQA), LSC surpasses SC, USC, and WUCS on both short-form and long-form on average performance, while adding negligible computational overhead on vanilla inference. These results position LSC as a reliable consistency-selection method that works effectively across various answer formats. Additionally, LSC provides well-calibrated confidence estimates, maintaining low expected calibration error across both answer formats.","authors":["Jungsuk Oh","Jay-Yoon Lee"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.21048v2","updated":"2026-02-27T07:50:11Z","published":"2025-08-28T17:53:05Z","title":"Veritas: Generalizable Deepfake Detection via Pattern-Aware Reasoning","summary":"Deepfake detection remains a formidable challenge due to the complex and evolving nature of fake content in real-world scenarios. However, existing academic benchmarks suffer from severe discrepancies from industrial practice, typically featuring homogeneous training sources and low-quality testing images, which hinder the practical deployments of current detectors. To mitigate this gap, we introduce HydraFake, a dataset that simulates real-world challenges with hierarchical generalization testing. Specifically, HydraFake involves diversified deepfake techniques and in-the-wild forgeries, along with rigorous training and evaluation protocol, covering unseen model architectures, emerging forgery techniques and novel data domains. Building on this resource, we propose Veritas, a multi-modal large language model (MLLM) based deepfake detector. Different from vanilla chain-of-thought (CoT), we introduce pattern-aware reasoning that involves critical reasoning patterns such as \"planning\" and \"self-reflection\" to emulate human forensic process. We further propose a two-stage training pipeline to seamlessly internalize such deepfake reasoning capacities into current MLLMs. Experiments on HydraFake dataset reveal that although previous detectors show great generalization on cross-model scenarios, they fall short on unseen forgeries and data domains. Our Veritas achieves significant gains across different OOD scenarios, and is capable of delivering transparent and faithful detection outputs.","authors":["Hao Tan","Jun Lan","Zichang Tan","Ajian Liu","Chuanbiao Song","Senyuan Shi","Huijia Zhu","Weiqiang Wang","Jun Wan","Zhen Lei"],"pdf_url":"","comment":"ICLR 2026 Oral. Project: https://github.com/EricTan7/Veritas"},{"id":"http://arxiv.org/abs/2509.01986v3","updated":"2026-02-27T07:29:44Z","published":"2025-09-02T06:06:52Z","title":"Draw-In-Mind: Rebalancing Designer-Painter Roles in Unified Multimodal Models Benefits Image Editing","summary":"In recent years, integrating multimodal understanding and generation into a single unified model has emerged as a promising paradigm. While this approach achieves strong results in text-to-image (T2I) generation, it still struggles with precise image editing. We attribute this limitation to an imbalanced division of responsibilities. The understanding module primarily functions as a translator that encodes user instructions into semantic conditions, while the generation module must simultaneously act as designer and painter, inferring the original layout, identifying the target editing region, and rendering the new content. This imbalance is counterintuitive because the understanding module is typically trained with several times more data on complex reasoning tasks than the generation module. To address this issue, we introduce Draw-In-Mind (DIM), a dataset comprising two complementary subsets: (i) DIM-T2I, containing 14M long-context image-text pairs to enhance complex instruction comprehension; and (ii) DIM-Edit, consisting of 233K chain-of-thought imaginations generated by GPT-4o, serving as explicit design blueprints for image edits. We connect a frozen Qwen2.5-VL-3B with a trainable SANA1.5-1.6B via a lightweight two-layer MLP, and train it on the proposed DIM dataset, resulting in DIM-4.6B-T2I/Edit. Despite its modest parameter scale, DIM-4.6B-Edit achieves SOTA or competitive performance on the ImgEdit and GEdit-Bench benchmarks, outperforming much larger models such as UniWorld-V1 and Step1X-Edit. These findings demonstrate that explicitly assigning the design responsibility to the understanding module provides significant benefits for image editing. Our dataset and models are available at https://github.com/showlab/DIM.","authors":["Ziyun Zeng","David Junhao Zhang","Wei Li","Mike Zheng Shou"],"pdf_url":"","comment":"ICLR 2026 Camera Ready Version"},{"id":"http://arxiv.org/abs/2502.18471v2","updated":"2026-02-27T07:28:04Z","published":"2025-02-04T06:51:34Z","title":"FinBloom: Knowledge Grounding Large Language Model with Real-time Financial Data","summary":"Large language models (LLMs) excel at generating human-like responses but often struggle with interactive tasks that require access to real-time information. This limitation poses challenges in finance, where models must access up-to-date information, such as recent news or price movements, to support decision-making. To address this, we introduce Financial Agent, a knowledge-grounding approach for LLMs to handle financial queries using real-time text and tabular data. Our contributions are threefold: First, we develop a Financial Context Dataset of over 50,000 financial queries paired with the required context. Second, we develop FinBloom 7B, a custom 7 billion parameter LLM, by fine-tuning Bloom 7B on 14 million financial news articles from Reuters and Deutsche Presse-Agentur (DPA), alongside a random sample of 25% from 12 million Securities and Exchange Commission (SEC) filings. Third, we fine-tune FinBloom 7B using the Financial Context Dataset to serve as a Financial Agent. This agent generates relevant financial context, enabling efficient real-time data retrieval to answer user queries. By reducing latency and eliminating the need for users to manually provide accurate data, our approach significantly enhances the capability of LLMs to handle dynamic financial tasks. Our proposed approach makes real-time financial decisions, algorithmic trading and other related tasks streamlined, and is valuable in contexts with high-velocity data flows.","authors":["Ankur Sinha","Chaitanya Agarwal","Pekka Malo"],"pdf_url":"","comment":"39 pages, 10 tables"},{"id":"http://arxiv.org/abs/2511.05271v3","updated":"2026-02-27T07:25:02Z","published":"2025-11-07T14:31:20Z","title":"DeepEyesV2: Toward Agentic Multimodal Model","summary":"Agentic multimodal models should not only comprehend text and images, but also actively invoke external tools, such as code execution environments and web search, and integrate these operations into reasoning. In this work, we introduce DeepEyesV2 and explore how to build an agentic multimodal model from the perspectives of data construction, training methods, and model evaluation. We observe that direct reinforcement learning alone fails to induce robust tool-use behavior. This phenomenon motivates a two-stage training pipeline: a cold-start stage to establish tool-use patterns, and reinforcement learning stage to further refine tool invocation. We curate a diverse, moderately challenging training dataset, specifically including examples where tool use is beneficial. We further introduce RealX-Bench, a comprehensive benchmark designed to evaluate real-world multimodal reasoning, which inherently requires the integration of multiple capabilities, including perception, search, and reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative benchmarks, demonstrating its effectiveness across real-world understanding, mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2 exhibits task-adaptive tool invocation, tending to use image operations for perception tasks and numerical computations for reasoning tasks. Reinforcement learning further enables complex tool combinations and allows model to selectively invoke tools based on context. We hope our study can provide guidance for community in developing agentic multimodal models.","authors":["Jack Hong","Chenxiao Zhao","ChengLin Zhu","Weiheng Lu","Guohai Xu","Xing Yu"],"pdf_url":"","comment":"Accepted to ICLR2026. Homepage: https://visual-agent.github.io/"},{"id":"http://arxiv.org/abs/2410.19450v2","updated":"2026-02-27T07:22:54Z","published":"2024-10-25T10:24:19Z","title":"Offline-to-Online Multi-Agent Reinforcement Learning with Offline Value Function Memory and Sequential Exploration","summary":"Offline-to-Online Reinforcement Learning has emerged as a powerful paradigm, leveraging offline data for initialization and online fine-tuning to enhance both sample efficiency and performance. However, most existing research has focused on single-agent settings, with limited exploration of the multi-agent extension, i.e., Offline-to-Online Multi-Agent Reinforcement Learning (O2O MARL). In O2O MARL, two critical challenges become more prominent as the number of agents increases: (i) the risk of unlearning pre-trained Q-values due to distributional shifts during the transition from offline-to-online phases, and (ii) the difficulty of efficient exploration in the large joint state-action space. To tackle these challenges, we propose a novel O2O MARL framework called Offline Value Function Memory with Sequential Exploration (OVMSE). First, we introduce the Offline Value Function Memory (OVM) mechanism to compute target Q-values, preserving knowledge gained during offline training, ensuring smoother transitions, and enabling efficient fine-tuning. Second, we propose a decentralized Sequential Exploration (SE) strategy tailored for O2O MARL, which effectively utilizes the pre-trained offline policy for exploration, thereby significantly reducing the joint state-action space to be explored. Extensive experiments on the StarCraft Multi-Agent Challenge (SMAC) demonstrate that OVMSE significantly outperforms existing baselines, achieving superior sample efficiency and overall performance.","authors":["Hai Zhong","Xun Wang","Zhuoran Li","Longbo Huang"],"pdf_url":"","comment":"Include detailed hyperparameter configurations"},{"id":"http://arxiv.org/abs/2602.23737v1","updated":"2026-02-27T07:04:22Z","published":"2026-02-27T07:04:22Z","title":"Bridging Dynamics Gaps via Diffusion Schrödinger Bridge for Cross-Domain Reinforcement Learning","summary":"Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schrödinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.","authors":["Hanping Zhang","Yuhong Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21746v2","updated":"2026-02-27T07:03:35Z","published":"2026-02-25T09:58:14Z","title":"fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation","summary":"In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.","authors":["Abeer Dyoub","Francesca A. Lisi"],"pdf_url":"","comment":"correcting captions of figures 7 and 8 and some other minor errors"},{"id":"http://arxiv.org/abs/2602.23730v1","updated":"2026-02-27T06:56:50Z","published":"2026-02-27T06:56:50Z","title":"Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off","summary":"Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates \"System 1\" (Perception) and \"System 2\" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.\n  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.","authors":["Longyin Zhang","Shuo Sun","Yingxu He","Won Cheng Yi Lewis","Muhammad Huzaifah Bin Md Shahrin","Hardik Bhupendra Sailor","Heng Meng Jeremy Wong","Tarun Kumar Vangani","Yi Ma","Qiongqiong Wang","Minh Duc Pham","Ridong Jiang","Jingtao Li","Jingyi Liao","Zhuohan Liu","Yanfeng Lu","Manas Gupta","Ai Ti Aw"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23729v1","updated":"2026-02-27T06:54:32Z","published":"2026-02-27T06:54:32Z","title":"From Static Benchmarks to Dynamic Protocol: Agent-Centric Text Anomaly Detection for Evaluating LLM Reasoning","summary":"The evaluation of large language models (LLMs) has predominantly relied on static datasets, which offer limited scalability and fail to capture the evolving reasoning capabilities of recent models. To overcome these limitations, we propose an agent-centric benchmarking paradigm that moves beyond static datasets by introducing a dynamic protocol in which autonomous agents iteratively generate, validate, and solve problems. Within this protocol, a teacher agent generates candidate problems, an orchestrator agent rigorously verifies their validity and guards against adversarial attacks, and a student agent attempts to solve the validated problems. An invalid problem is revised by the teacher agent until it passes validation. If the student correctly solves the problem, the orchestrator prompts the teacher to generate more challenging variants. Consequently, the benchmark scales in difficulty automatically as more capable agents are substituted into any role, enabling progressive evaluation of large language models without manually curated datasets. Adopting text anomaly detection as our primary evaluation format, which demands cross-sentence logical inference and resists pattern-matching shortcuts, we demonstrate that this protocol systematically exposes corner-case reasoning errors that conventional benchmarks fail to reveal. We further advocate evaluating systems along several complementary axes including cross-model pairwise performance and progress between the initial and orchestrator-finalized problems. By shifting the focus from fixed datasets to dynamic protocols, our approach offers a sustainable direction for evaluating ever-evolving language models and introduces a research agenda centered on the co-evolution of agent-centric benchmarks.","authors":["Seungdong Yoa","Sanghyu Yoon","Suhee Yoon","Dongmin Kim","Ye Seul Sim","Junhyun Lee","Woohyung Lim"],"pdf_url":"","comment":"Accepted to ICLR 2026"},{"id":"http://arxiv.org/abs/2602.23722v1","updated":"2026-02-27T06:43:47Z","published":"2026-02-27T06:43:47Z","title":"SLA-Aware Distributed LLM Inference Across Device-RAN-Cloud","summary":"Embodied AI requires sub-second inference near the Radio Access Network (RAN), but deployments span heterogeneous tiers (on-device, RAN-edge, cloud) and must not disrupt real-time baseband processing. We report measurements from a 5G Standalone (SA) AI-RAN testbed using a fixed baseline policy for repeatability. The setup includes an on-device tier, a three-node RAN-edge cluster co-hosting a containerized 5G RAN, and a cloud tier. We find that on-device execution remains multi-second and fails to meet sub-second budgets. At the RAN edge, SLA feasibility is primarily determined by model variant choice: quantized models concentrate below 0.5\\,s, while unquantized and some larger quantized models incur deadline misses due to stalls and queuing. In the cloud tier, meeting a 0.5\\,s deadline is challenging on the measured WAN path (up to 32.9\\% of requests complete within 0.5\\,s), but all evaluated variants meet a 1.0\\,s deadline (100\\% within 1.0\\,s). Under saturated downlink traffic and up to $N{=}20$ concurrent inference clients, Multi-Instance GPU (MIG) isolation preserves baseband timing-health proxies, supporting safe co-location under fixed partitioning.","authors":["Hariz Yet","Nguyen Thanh Tam","Mao V. Ngo","Lim Yi Shen","Lin Wei","Jihong Park","Binbin Chen","Tony Q. S. Quek"],"pdf_url":"","comment":"Accepted to IEEE INFOCOM Workshops 2026 (6G AI-RAN 2026), Tokyo, Japan. This arXiv version is a preprint / author version"},{"id":"http://arxiv.org/abs/2602.23720v1","updated":"2026-02-27T06:42:08Z","published":"2026-02-27T06:42:08Z","title":"The Auton Agentic AI Framework","summary":"The field of Artificial Intelligence is undergoing a transition from Generative AI -- probabilistic generation of text and images -- to Agentic AI, in which autonomous systems execute actions within external environments on behalf of users. This transition exposes a fundamental architectural mismatch: Large Language Models (LLMs) produce stochastic, unstructured outputs, whereas the backend infrastructure they must control -- databases, APIs, cloud services -- requires deterministic, schema-conformant inputs. The present paper describes the Auton Agentic AI Framework, a principled architecture for standardizing the creation, execution, and governance of autonomous agent systems. The framework is organized around a strict separation between the Cognitive Blueprint, a declarative, language-agnostic specification of agent identity and capabilities, and the Runtime Engine, the platform-specific execution substrate that instantiates and runs the agent. This separation enables cross-language portability, formal auditability, and modular tool integration via the Model Context Protocol (MCP). The paper formalizes the agent execution model as an augmented Partially Observable Markov Decision Process (POMDP) with a latent reasoning space, introduces a hierarchical memory consolidation architecture inspired by biological episodic memory systems, defines a constraint manifold formalism for safety enforcement via policy projection rather than post-hoc filtering, presents a three-level self-evolution framework spanning in-context adaptation through reinforcement learning, and describes runtime optimizations -- including parallel graph execution, speculative inference, and dynamic context pruning -- that reduce end-to-end latency for multi-step agent workflows.","authors":["Sheng Cao","Zhao Chang","Chang Li","Hannan Li","Liyao Fu","Ji Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23719v1","updated":"2026-02-27T06:41:04Z","published":"2026-02-27T06:41:04Z","title":"SAGE-LLM: Towards Safe and Generalizable LLM Controller with Fuzzy-CBF Verification and Graph-Structured Knowledge Retrieval for UAV Decision","summary":"In UAV dynamic decision, complex and variable hazardous factors pose severe challenges to the generalization capability of algorithms. Despite offering semantic understanding and scene generalization, Large Language Models (LLM) lack domain-specific UAV control knowledge and formal safety assurances, restricting their direct applicability. To bridge this gap, this paper proposes a train-free two-layer decision architecture based on LLMs, integrating high-level safety planning with low-level precise control. The framework introduces three key contributions: 1) A fuzzy Control Barrier Function verification mechanism for semantically-augmented actions, providing provable safety certification for LLM outputs. 2) A star-hierarchical graph-based retrieval-augmented generation system, enabling efficient, elastic, and interpretable scene adaptation. 3) Systematic experimental validation in pursuit-evasion scenarios with unknown obstacles and emergent threats, demonstrating that our SAGE-LLM maintains performance while significantly enhancing safety and generalization without online training. The proposed framework demonstrates strong extensibility, suggesting its potential for generalization to broader embodied intelligence systems and safety-critical control domains.","authors":["Wenzhe Zhao","Yang Zhao","Ganchao Liu","Zhiyu Jiang","Dandan Ma","Zihao Li","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.19591v2","updated":"2026-02-27T06:35:57Z","published":"2026-02-23T08:35:55Z","title":"Detecting High-Potential SMEs with Heterogeneous Graph Neural Networks","summary":"Small and Medium Enterprises (SMEs) constitute 99.9% of U.S. businesses and generate 44% of economic activity, yet systematically identifying high-potential SMEs remains an open challenge. We introduce SME-HGT, a Heterogeneous Graph Transformer framework that predicts which SBIR Phase I awardees will advance to Phase II funding using exclusively public data. We construct a heterogeneous graph with 32,268 company nodes, 124 research topic nodes, and 13 government agency nodes connected by approximately 99,000 edges across three semantic relation types. SME-HGT achieves an AUPRC of 0.621 0.003 on a temporally-split test set, outperforming an MLP baseline (0.590 0.002) and R-GCN (0.608 0.013) across five random seeds. At a screening depth of 100 companies, SME-HGT attains 89.6% precision with a 2.14 lift over random selection. Our temporal evaluation protocol prevents information leakage, and our reliance on public data ensures reproducibility. These results demonstrate that relational structure among firms, research topics, and funding agencies provides meaningful signal for SME potential assessment, with implications for policymakers and early-stage investors.","authors":["Yijiashun Qi","Hanzhe Guo","Yijiazhen Qi"],"pdf_url":"","comment":null}],"Programming Languages (Static Analysis)":[{"id":"http://arxiv.org/abs/2505.23819v4","updated":"2026-02-27T15:50:10Z","published":"2025-05-28T00:45:50Z","title":"Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using $\\mathbb{F}_2$","summary":"Efficient tensor computation is a cornerstone of modern deep learning (DL) workloads, yet existing approaches struggle to achieve flexible and performant design and implementation of tensor layouts -- mappings between logical tensors and hardware resources. The increasing complexity of DL algorithms and hardware demands a generic and systematic approach to handling tensor layouts. In this work, we introduce Linear Layouts, a novel approach that models tensor layouts using linear algebra over $\\mathbb{F}_2$. By representing tensor layouts as binary matrices acting on the bits of the hardware representation, our approach enables a generic layout definition -- as opposed to the classical case-by-case approach -- and allows for generic layout-to-layout conversions, eliminating the quadratic explosion that plagues existing solutions. We integrate linear layouts with Triton and demonstrate their effectiveness in optimizing individual Triton operators as well as kernels written in Triton. We also show that linear layouts reduce engineering effort in the compiler backend while fixing several bugs in Triton's legacy layout system.","authors":["Keren Zhou","Mario Lezcano","Adam Goucher","Akhmed Rakhmati","Jeff Niu","Justin Lebar","Pawel Szczerbuk","Peter Bell","Phil Tillet","Thomas Raoux","Zahi Moudallal"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.04936v2","updated":"2026-02-27T15:02:34Z","published":"2025-09-05T08:58:43Z","title":"Floating-Point Usage on GitHub: A Large-Scale Study of Statically Typed Languages","summary":"Reasoning about floating-point arithmetic is notoriously hard. While static and dynamic analysis techniques or program repair have made significant progress, more work is still needed to make them relevant to real-world code. On the critical path to that goal is understanding what real-world floating-point code looks like. To close that knowledge gap, this paper presents the first large-scale empirical study of floating-point arithmetic usage across public GitHub repositories. We focus on statically typed languages to allow our study to scale to millions of repositories. We follow state-of the art mining practices including random sampling and filtering based on only intrinsic properties to avoid bias, and identify floating-point usage by searching for keywords in the source code, and programming language constructs (e.g., loops) by parsing the code. Our evaluation supports the claim often made in papers that floating-point arithmetic is widely used. Comparing statistics such as size and usage of certain constructs and functions, we find that benchmarks used in literature to evaluate automated reasoning techniques for floating-point arithmetic are in certain aspects representative of 'real-world' code, but not in all. We publish a dataset of 10 million real-world floating-point functions extracted from our study. We demonstrate in a case study how it may be used to identify new floating-point benchmarks and help future techniques for floating-point arithmetic to be designed and evaluated to match actual users' expectations.","authors":["Andrea Gilot","Tobias Wrigstad","Eva Darulova"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24054v1","updated":"2026-02-27T14:43:01Z","published":"2026-02-27T14:43:01Z","title":"Speak Now: Safe Actor Programming with Multiparty Session Types","summary":"Actor languages such as Erlang and Elixir are widely used for implementing scalable and reliable distributed applications, but the informally-specified nature of actor communication patterns leaves systems vulnerable to costly errors such as communication mismatches and deadlocks. Multiparty session types (MPSTs) rule out communication errors early in the development process, but until now, the many-sender, single-receiver nature of actor communication has made it difficult for actor languages to benefit from session types.\n  This paper introduces Maty, the first actor language design supporting both static multiparty session typing and the full power of actors taking part in multiple sessions. Maty therefore combines the error prevention mechanism of session types with the scalability and fault tolerance of actor languages. Our main insight is to enforce session typing through a flow-sensitive effect system, combined with an event-driven programming style and first-class message handlers. Using MPSTs allows us to guarantee communication safety: a process will never send or receive an unexpected message, nor will a session get stuck because an actor is waiting for a message that will never be sent. We extend Maty to support Erlang-style supervision and cascading failure, and show that this preserves Maty's strong metatheory. We implement Maty in Scala using an API generation approach, and demonstrate the expressiveness of our model by implementing a representative sample of the widely-used Savina actor benchmark suite; an industry-supplied factory scenario; and a chat server.","authors":["Simon Fowler","Raymond Hu"],"pdf_url":"","comment":"Extended version of paper accepted at OOPSLA'26"},{"id":"http://arxiv.org/abs/2602.23927v1","updated":"2026-02-27T11:21:58Z","published":"2026-02-27T11:21:58Z","title":"Mixed Choice in Asynchronous Multiparty Session Types","summary":"We present a multiparty session type (MST) framework with asynchronous mixed choice (MC). We propose a core construct for MC that allows transient inconsistencies in protocol state between distributed participants, but ensures all participants can always eventually reach a mutually consistent state. We prove the correctness of our system by establishing a progress property and an operational correspondence between global types and distributed local type projections. Based on our theory, we implement a practical toolchain for specifying and validating asynchronous MST protocols featuring MC, and programming compliant gen_statem processes in Erlang/OTP. We test our framework by using our toolchain to specify and reimplement part of the amqp_client of the RabbitMQ broker for Erlang.","authors":["Laura Bocchi","Raymond Hu","Adriana Laura Voinea","Simon Thompson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.11573v2","updated":"2026-02-27T08:22:09Z","published":"2025-10-13T16:19:54Z","title":"(Dis)Proving Spectre Security with Speculation-Passing Style","summary":"Constant-time (CT) verification tools are commonly used for detecting potential side-channel vulnerabilities in cryptographic libraries. Recently, a new class of tools, called speculative constant-time (SCT) tools, has also been used for detecting potential Spectre vulnerabilities. In many cases, these SCT tools have emerged as liftings of CT tools. However, these liftings are seldom defined precisely and are almost never analyzed formally. The goal of this paper is to address this gap, by developing formal foundations for these liftings, and to demonstrate that these foundations can yield practical benefits.\n  Concretely, we introduce a program transformation, coined Speculation-Passing Style (SPS), for reducing SCT verification to CT verification. Essentially, the transformation instruments the program with a new input that corresponds to attacker-controlled predictions and modifies the program to follow them. This approach is sound and complete, in the sense that a program is SCT if and only if its SPS transform is CT. Thus, we can leverage existing CT verification tools to prove SCT; we illustrate this by combining SPS with three standard methodologies for CT verification, namely reducing it to non-interference, assertion safety and dynamic taint analysis. We realize these combinations with three existing tools, EasyCrypt, BINSEC, and ctgrind, and we evaluate them on Kocher's benchmarks for Spectre-v1. Our results focus on Spectre-v1 in the standard CT leakage model; however, we also discuss applications of our method to other variants of Spectre and other leakage models.","authors":["Santiago Arranz-Olmos","Gilles Barthe","Lionel Blatter","Xingyu Xie","Zhiyuan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23216v2","updated":"2026-02-27T07:55:17Z","published":"2026-02-26T17:00:10Z","title":"Array-Carrying Symbolic Execution for Function Contract Generation","summary":"Function contract generation is a classical problem in program analysis that targets the automated analysis of functions in a program with multiple procedures. The problem is fundamental in inter-procedural analysis where properties of functions are first obtained via the generation of function contracts and then the generated contracts are used as building blocks to analyze the whole program. Typical objectives in function contract generation include pre-/post-conditions and assigns information (that specifies the modification information over program variables and memory segments during function execution). In programs with array manipulations, a crucial point in function contract generation is the treatment of array segments that imposes challenges in inferring invariants and assigns information over such segments. To address this challenge, we propose a novel symbolic execution framework that carries invariants and assigns information over contiguous segments of arrays. We implement our framework as a prototype within LLVM, and further integrate our prototype with the ACSL assertion format and the Frama-C software verification platform. Experimental evaluation over a variety of benchmarks from the literature and functions from realistic libraries shows that our framework is capable of handling array manipulating functions that indeed involve the carry of array information and are beyond existing approaches.","authors":["Weijie Lu","Jingyu Ke","Hongfei Fu","Zhouyue Sun","Yi Zhou","Guoqiang Li","Haokun Li"],"pdf_url":"","comment":"30 pages, 2 figures. To appear in the 27th International Symposium on Formal Methods (FM 2026)"},{"id":"http://arxiv.org/abs/2508.20340v2","updated":"2026-02-27T02:49:55Z","published":"2025-08-28T01:21:26Z","title":"Once4All: Skeleton-Guided SMT Solver Fuzzing with LLM-Synthesized Generators","summary":"Satisfiability Modulo Theory (SMT) solvers are foundational to modern systems and programming languages research, providing the foundation for tasks like symbolic execution and automated verification. Because these solvers sit on the critical path, their correctness is essential, and high-quality test formulas are key to uncovering bugs. However, while prior testing techniques performed well on earlier solver versions, they struggle to keep pace with rapidly evolving features. Recent approaches based on Large Language Models (LLMs) show promise in exploring advanced solver capabilities, but two obstacles remain: nearly half of the generated formulas are syntactically invalid, and iterative interactions with LLMs introduce substantial computational overhead. In this study, we present Once4All, a novel LLM-assisted fuzzing framework that addresses both issues by shifting from direct formula generation to the synthesis of generators for reusable terms (i.e., logical expressions). Specifically, Once4All uses LLMs to (1) automatically extract context-free grammars (CFGs) for SMT theories, including solver-specific extensions, from documentation, and (2) synthesize composable Boolean term generators that adhere to these grammars. During fuzzing, Once4All populates structural skeletons derived from existing formulas with the terms iteratively produced by the LLM-synthesized generators. This design ensures syntactic validity while promoting semantic diversity. Notably, Once4All requires only one-time LLM interaction investment, dramatically reducing runtime cost. We evaluated Once4All on two leading SMT solvers: Z3 and cvc5. Our experiments show that Once4All has identified 43 confirmed bugs, 40 of which have already been fixed by developers.","authors":["Maolin Sun","Yibiao Yang","Yuming Zhou"],"pdf_url":"","comment":"Accepted at ASPLOS 2026"}],"Software Engineering (Dynamic Analysis & Testing)":[{"id":"http://arxiv.org/abs/2602.21806v3","updated":"2026-02-27T16:17:57Z","published":"2026-02-25T11:34:17Z","title":"An Empirical Study of Bugs in Modern LLM Agent Frameworks","summary":"LLM agents have been widely adopted in real-world applications, relying on agent frameworks for workflow execution and multi-agent coordination. As these systems scale, understanding bugs in the underlying agent frameworks becomes critical. However, existing work mainly focuses on agent-level failures, overlooking framework-level bugs. To address this gap, we conduct an empirical study of 998 bug reports from CrewAI and LangChain, constructing a taxonomy of 15 root causes and 7 observable symptoms across five agent lifecycle stages: 'Agent Initialization','Perception', 'Self-Action', 'Mutual Interaction' and 'Evolution'. Our findings show that agent framework bugs mainly arise from 'API misuse', 'API incompatibility', and 'Documentation Desync', largely concentrated in the 'Self-Action' stage. Symptoms typically appear as 'Functional Error', 'Crash', and 'Build Failure', reflecting disruptions to task progression and control flow.","authors":["Xinxue Zhu","Jiacong Wu","Xiaoyu Zhang","Tianlin Li","Yanzhou Mu","Juan Zhai","Chao Shen","Chunrong Fang","Yang Liu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23065v2","updated":"2026-02-27T16:15:41Z","published":"2026-02-26T14:53:26Z","title":"LLM-Powered Silent Bug Fuzzing in Deep Learning Libraries via Versatile and Controlled Bug Transfer","summary":"Deep learning (DL) libraries are widely used in critical applications, where even subtle silent bugs can lead to serious consequences. While existing DL fuzzing techniques have made progress in detecting crashes, they inherently struggle to detect silent bugs due to the lack of effective test programs and corresponding oracles.\n  Building on the observation that historical bug reports contain rich, underutilized information about silent bugs, we leverage large language models (LLMs) to perform versatile yet controlled bug transfer for silent bug fuzzing. Specifically, our approach uses LLMs to extract context-aware bug patterns from historical issues, match semantically related Application Programming Interfaces (APIs) using functionality-based embeddings, and synthesize test cases with customized oracles. This enables proactive detection of silent bugs by transferring high-risk contexts and oracle designs from known buggy APIs to functionally similar target APIs. To ensure the reliability of our context-aware bug transfer, we introduce an LLM-powered self-validation module that systematically evaluates the validity of each transferred bug instance. We implement this methodology in a tool named TransFuzz and evaluate it on three mainstream DL libraries: PyTorch, TensorFlow, and MindSpore. TransFuzz successfully discovers 79 previously unknown bugs (12 confirmed as Common Vulnerabilities and Exposures (CVEs)) in 10 bug types, demonstrating its effectiveness and generalizability in migrating DL library bug discovery capabilities.","authors":["Kunpeng Zhang","Dongwei Xiao","Daoyuan Wu","Shuai Wang","Jiali Zhao","Yuanyi Lin","Tongtong Xu","Shaohua Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24108v1","updated":"2026-02-27T15:47:37Z","published":"2026-02-27T15:47:37Z","title":"Context-Aware Functional Test Generation via Business Logic Extraction and Adaptation","summary":"Functional testing is essential for verifying that the business logic of mobile applications aligns with user requirements, serving as the primary methodology for quality assurance in software development. Despite its importance, functional testing remains heavily dependent on manual effort due to two core challenges. First, acquiring and reusing complex business logic from unstructured requirements remains difficult, which hinders the understanding of specific functionalities. Second, a significant semantic gap exists when adapting business logic to the diverse GUI environments, which hinders the generation of test cases for specific mobile applications. To address the preceding challenges, we propose LogiDroid, a two-stage approach that generates individual functional test cases by extracting business logic and adapting it to target applications. First, in the Knowledge Retrieval and Fusion stage, we construct a dataset to retrieve relevant cases and extract business logic for the target functionality. Second, in the Context-Aware Test Generation stage, LogiDroid jointly analyzes the extracted business logic and the real-time GUI environment to generate functional test cases. This design allows LogiDroid to accurately understand application semantics and use domain expertise to generate complete test cases with verification assertions. We assess the effectiveness of LogiDroid using two widely-used datasets that cover 28 real-world applications and 190 functional requirements. Experimental results show that LogiDroid successfully tested 40% of functional requirements on the FrUITeR dataset (an improvement of over 48% compared to the state-of-the-art approaches) and 65% on the Lin dataset (an improvement of over 55% compared to the state-of-the-art approaches). These results demonstrate the significant effectiveness of LogiDroid in functional test generation.","authors":["Yakun Zhang","Zihan Wang","Xinzhi Peng","Zihao Xie","Xiaodong Wang","Xutao Li","Dan Hao","Lu Zhang","Yunming Ye"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.15090v2","updated":"2026-02-27T15:30:45Z","published":"2026-02-16T16:46:04Z","title":"The Agentic Automation Canvas: a structured framework for agentic AI project design","summary":"Agentic AI prototypes are being deployed across domains with increasing speed, yet no methodology for their structured design, governance, and prospective evaluation has been established. Existing AI documentation practices and guidelines -- Model Cards, Datasheets, or NIST AI RMF -- are either retrospective or lack machine-readability and interoperability. We present the Agentic Automation Canvas (AAC), a structured framework for the prospective design of agentic systems and a tool to facilitate communication between their users and developers. The AAC captures six dimensions of an automation project: definition and scope; user expectations with quantified benefit metrics; developer feasibility assessments; governance staging; data access and sensitivity; and outcomes. The framework is implemented as a semantic web-compatible metadata schema with controlled vocabulary and mappings to established ontologies such as Schema$\\mathrm{.}$org and W3C DCAT. It is made accessible through a privacy-preserving, fully client-side web application with real-time validation. Completed canvases export as FAIR-compliant RO-Crates, yielding versioned, shareable, and machine-interoperable project contracts between users and developers. We describe the schema design, benefit quantification model, and prospective application to diverse use cases from research, clinical, and institutional settings. The AAC and its web application are available as open-source code and interactive web form at https://aac.slolab.ai$\\mathrm{.}$","authors":["Sebastian Lobentanzer"],"pdf_url":"","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2509.04936v2","updated":"2026-02-27T15:02:34Z","published":"2025-09-05T08:58:43Z","title":"Floating-Point Usage on GitHub: A Large-Scale Study of Statically Typed Languages","summary":"Reasoning about floating-point arithmetic is notoriously hard. While static and dynamic analysis techniques or program repair have made significant progress, more work is still needed to make them relevant to real-world code. On the critical path to that goal is understanding what real-world floating-point code looks like. To close that knowledge gap, this paper presents the first large-scale empirical study of floating-point arithmetic usage across public GitHub repositories. We focus on statically typed languages to allow our study to scale to millions of repositories. We follow state-of the art mining practices including random sampling and filtering based on only intrinsic properties to avoid bias, and identify floating-point usage by searching for keywords in the source code, and programming language constructs (e.g., loops) by parsing the code. Our evaluation supports the claim often made in papers that floating-point arithmetic is widely used. Comparing statistics such as size and usage of certain constructs and functions, we find that benchmarks used in literature to evaluate automated reasoning techniques for floating-point arithmetic are in certain aspects representative of 'real-world' code, but not in all. We publish a dataset of 10 million real-world floating-point functions extracted from our study. We demonstrate in a case study how it may be used to identify new floating-point benchmarks and help future techniques for floating-point arithmetic to be designed and evaluated to match actual users' expectations.","authors":["Andrea Gilot","Tobias Wrigstad","Eva Darulova"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.23735v2","updated":"2026-02-27T14:50:32Z","published":"2025-09-28T08:30:03Z","title":"Demystifying the Lifecycle of Failures in Platform-Orchestrated Agentic Workflows","summary":"Agentic workflows built on low-code orchestration platforms enable rapid development of multi-agent systems, but they also introduce new and poorly understood failure modes that hinder reliability and maintainability. Unlike traditional software systems, failures in agentic workflows often propagate across heterogeneous nodes through natural-language interactions, tool invocations, and dynamic control logic, making failure attribution and repair particularly challenging. In this paper, we present an empirical study of platform-orchestrated agentic workflows from a failure lifecycle perspective, with the goal of characterizing failure manifestations, identifying underlying root causes, and examining corresponding repair strategies. We present AgentFail, a dataset of 307 real-world failure cases collected from two representative agentic workflow platforms. Based on this dataset, we analyze failure patterns, root causes, and repair difficulty for various failure root causes and nodes in the workflow. Our findings reveal key failure mechanisms in agentic workflows and provide actionable guidelines for reliable failure repair, and real-world agentic workflow design.","authors":["Xuyan Ma","Xiaofei Xie","Yawen Wang","Junjie Wang","Boyu Wu","Mingyang Li","Qing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24055v1","updated":"2026-02-27T14:43:23Z","published":"2026-02-27T14:43:23Z","title":"CIRCLE: A Framework for Evaluating AI from a Real-World Lens","summary":"This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.","authors":["Reva Schwartz","Carina Westling","Morgan Briggs","Marzieh Fadaee","Isar Nejadgholi","Matthew Holmes","Fariza Rashid","Maya Carlyle","Afaf Taïk","Kyra Wilson","Peter Douglas","Theodora Skeadas","Gabriella Waters","Rumman Chowdhury","Thiago Lacerda"],"pdf_url":"","comment":"Accepted at Intelligent Systems Conference (IntelliSys) 2026"},{"id":"http://arxiv.org/abs/2601.01780v2","updated":"2026-02-27T13:49:13Z","published":"2026-01-05T04:26:46Z","title":"LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment","summary":"Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.","authors":["Arsham Khosravani","Alireza Hoseinpour","Arshia Akhavan","Mehdi Keshani","Abbas Heydarnoori"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24010v1","updated":"2026-02-27T13:34:48Z","published":"2026-02-27T13:34:48Z","title":"LeGend: A Data-Driven Framework for Lemma Generation in Hardware Model Checking","summary":"Property checking of RTL designs is a central task in formal verification. Among available engines, IC3/PDR is a widely used backbone whose performance critically depends on inductive generalization, the step that generalizes a concrete counterexample-to-induction (CTI) cube into a lemma. Prior work has explored machine learning to guide this step and achieved encouraging results, yet most methods adopt a per-clause graph analysis paradigm: for each clause they repeatedly build and analyze graphs, incurring heavy overhead and creating a scalability bottleneck. We introduce LeGend, which replaces this paradigm with one-time global representation learning. LeGend pre-trains a domain-adapted self-supervised model to produce latch embeddings that capture global circuit properties. These precomputed embeddings allow a lightweight model to predict high-quality lemmas with negligible overhead, effectively decoupling expensive learning from fast inference. Experiments show LeGend accelerates two state-of-the-art IC3/PDR engines across a diverse set of benchmarks, presenting a promising path to scale up formal verification.","authors":["Mingkai Miao","Guangyu Hu","Wei Zhang","Hongce Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23957v1","updated":"2026-02-27T11:59:23Z","published":"2026-02-27T11:59:23Z","title":"The Vocabulary of Flaky Tests in the Context of SAP HANA","summary":"Background. Automated test execution is an important activity to gather information about the quality of a software project. So-called flaky tests, however, negatively affect this process. Such tests fail seemingly at random without changes to the code and thus do not provide a clear signal. Previous work proposed to identify flaky tests based on the source code identifiers in the test code. So far, these approaches have not been evaluated in a large-scale industrial setting. Aims. We evaluate approaches to identify flaky tests and their root causes based on source code identifiers in the test code in a large-scale industrial project. Method. First, we replicate previous work by Pinto et al. in the context of SAP HANA. Second, we assess different feature extraction techniques, namely TF-IDF and TF-IDFC-RF. Third, we evaluate CodeBERT and XGBoost as classification models. For a sound comparison, we utilize both the data set from previous work and two data sets from SAP HANA. Results. Our replication shows similar results on the original data set and on one of the SAP HANA data sets. While the original approach yielded an F1-Score of 0.94 on the original data set and 0.92 on the SAP HANA data set, our extensions achieve F1-Scores of 0.96 and 0.99, respectively. The reliance on external data sources is a common root cause for test flakiness in the context of SAP HANA. Conclusions. The vocabulary of a large industrial project seems to be slightly different with respect to the exact terms, but the categories for the terms, such as remote dependencies, are similar to previous empirical findings. However, even with rather large F1-Scores, both finding source code identifiers for flakiness and a black box prediction have limited use in practice as the results are not actionable for developers.","authors":["Alexander Berndt","Zoltán Nochta","Thomas Bach"],"pdf_url":"","comment":"Accepted to ESEM IGC 2023"},{"id":"http://arxiv.org/abs/2602.23927v1","updated":"2026-02-27T11:21:58Z","published":"2026-02-27T11:21:58Z","title":"Mixed Choice in Asynchronous Multiparty Session Types","summary":"We present a multiparty session type (MST) framework with asynchronous mixed choice (MC). We propose a core construct for MC that allows transient inconsistencies in protocol state between distributed participants, but ensures all participants can always eventually reach a mutually consistent state. We prove the correctness of our system by establishing a progress property and an operational correspondence between global types and distributed local type projections. Based on our theory, we implement a practical toolchain for specifying and validating asynchronous MST protocols featuring MC, and programming compliant gen_statem processes in Erlang/OTP. We test our framework by using our toolchain to specify and reimplement part of the amqp_client of the RabbitMQ broker for Erlang.","authors":["Laura Bocchi","Raymond Hu","Adriana Laura Voinea","Simon Thompson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23922v1","updated":"2026-02-27T11:11:26Z","published":"2026-02-27T11:11:26Z","title":"Invariant-Driven Automated Testing","summary":"Microservice architectures are an emergent technology that builds business logic into a suite of small services. Each microservice runs in its process and the communication is made through lightweight mechanisms, usually HTTP resource API. These architectures are built upon independently deployable and, supposedly, reliable pieces of software that may, or may not, have been developed by the team using it. Nowadays, industries are dangerously migrating into microservice architectures without an effective and automatic process for testing the software being used. Furthermore, current API specification languages are not expressive enough to be used for testing purposes. To solve this problem it is necessary to extend currently broadly used API specification languages. APOSTL is a specification language to annotate APIs specifications based on first-order logic, with some restrictions. It has the purpose of extending the currently used API description languages with properties that can be useful for testing purposes, transforming these description documents into useful testing artefacts. Besides providing information needed for testing an application, APOSTL also provides an API with semantic. This additional information is then leveraged to automate microservice testing. The work developed in this thesis aims to fully automate the microservice testing process. It is achieved by the implementation of PETIT a tool able to test microservices when provided with an OpenAPI Specification document, written in JSON and properly annotated with the previously proposed specification language, APOSTL. The tool is able to analyze microservices independently from the source code availability.","authors":["Ana Catarina Ribeiro"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23905v1","updated":"2026-02-27T10:55:43Z","published":"2026-02-27T10:55:43Z","title":"Novice Developers Produce Larger Review Overhead for Project Maintainers while Vibe Coding","summary":"AI coding agents allow software developers to generate code quickly, which raises a practical question for project managers and open source maintainers: can vibe coders with less development experience substitute for expert developers? To explore whether developer experience still matters in AI-assisted development, we study $22,953$ Pull Requests (PRs) from $1,719$ vibe coders in the GitHub repositories of the AIDev dataset. We split vibe coders into lower experience vibe coders ($\\mathit{Exp}_{Low}$) and higher experience vibe coders ($\\mathit{Exp}_{High}$) and compare contribution magnitude and PR acceptance rates across PR categories. We find that $\\mathit{Exp}_{Low}$ submits PRs with larger volume ($2.15\\times$ more commits and $1.47\\times$ more files changed) than $\\mathit{Exp}_{High}$. Moreover, $\\mathit{Exp}_{Low}$ PRs, when compared to $\\mathit{Exp}_{High}$, receive $4.52\\times$ more review comments, and have $31\\%$ lower acceptance rates, and remain open $5.16\\times$ longer before resolution. Our results indicate that low-experienced vibe coders focus on generating more code while shifting verification burden onto reviewers. For practice, project managers may not be able to safely replace experienced developers with low-experience vibe coders without increasing review capacity. Development teams should therefore combine targeted training for novices with adaptive PR review cycles.","authors":["Syed Ammar Asdaque","Imran Haider","Muhammad Umar Malik","Maryam Abdul Ghafoor","Abdul Ali Bangash"],"pdf_url":"","comment":"Accepted to MSR 2026 Mining Challenge"},{"id":"http://arxiv.org/abs/2602.23866v1","updated":"2026-02-27T10:06:10Z","published":"2026-02-27T10:06:10Z","title":"SWE-rebench V2: Language-Agnostic SWE Task Collection at Scale","summary":"Software engineering agents (SWE) are improving rapidly, with recent gains largely driven by reinforcement learning (RL). However, RL training is constrained by the scarcity of large-scale task collections with reproducible execution environments and reliable test suites. Although a growing number of benchmarks have emerged, datasets suitable for training remain limited in scale and diversity or often target a limited set of high-resource language ecosystems. We introduce SWE-rebench V2, a language-agnostic automated pipeline for harvesting executable real-world SWE tasks and constructing RL training environments at scale. The pipeline synthesizes repository-specific installation and test procedures via an interactive setup agent, and filters unsound instances using an ensemble of LLM judges, validated against human-verified SWE-bench annotations. Using this pipeline, we construct a dataset of 32,000+ tasks spanning 20 languages and 3,600+ repositories, with pre-built images for reproducible execution. To further scale training data, we additionally release 120,000+ tasks with installation instructions, fail-to-pass tests and rich metadata, where the problem statement is generated based on the original pull request description. We validate the collected instances through a diagnostic study that covers a subset of tasks in five programming languages across seven popular models, and provide instance-level metadata that flags common confounders such as overly restrictive tests and underspecified descriptions. We release the datasets, the collection and execution code, and associated artifacts to enable large-scale training of SWE agents across diverse languages and repositories.","authors":["Ibragim Badertdinov","Maksim Nekrashevich","Anton Shevtsov","Alexander Golubev"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23216v2","updated":"2026-02-27T07:55:17Z","published":"2026-02-26T17:00:10Z","title":"Array-Carrying Symbolic Execution for Function Contract Generation","summary":"Function contract generation is a classical problem in program analysis that targets the automated analysis of functions in a program with multiple procedures. The problem is fundamental in inter-procedural analysis where properties of functions are first obtained via the generation of function contracts and then the generated contracts are used as building blocks to analyze the whole program. Typical objectives in function contract generation include pre-/post-conditions and assigns information (that specifies the modification information over program variables and memory segments during function execution). In programs with array manipulations, a crucial point in function contract generation is the treatment of array segments that imposes challenges in inferring invariants and assigns information over such segments. To address this challenge, we propose a novel symbolic execution framework that carries invariants and assigns information over contiguous segments of arrays. We implement our framework as a prototype within LLVM, and further integrate our prototype with the ACSL assertion format and the Frama-C software verification platform. Experimental evaluation over a variety of benchmarks from the literature and functions from realistic libraries shows that our framework is capable of handling array manipulating functions that indeed involve the carry of array information and are beyond existing approaches.","authors":["Weijie Lu","Jingyu Ke","Hongfei Fu","Zhouyue Sun","Yi Zhou","Guoqiang Li","Haokun Li"],"pdf_url":"","comment":"30 pages, 2 figures. To appear in the 27th International Symposium on Formal Methods (FM 2026)"},{"id":"http://arxiv.org/abs/2602.23736v1","updated":"2026-02-27T07:03:29Z","published":"2026-02-27T07:03:29Z","title":"Peeling Off the Cocoon: Unveiling Suppressed Golden Seeds for Mutational Greybox Fuzzing","summary":"PoCo is a technique that aims to enhance modern coverage-based seed selection (CSS) techniques (such as afl-cmin) by gradually removing obstacle conditional statements and conducting deeper seed selection.","authors":["Ruixiang Qian","Chunrong Fang","Zengxu Chen","Youxin Fu","Zhenyu Chen"],"pdf_url":"","comment":"Accepted by OOPSLA 2026"},{"id":"http://arxiv.org/abs/2602.23701v1","updated":"2026-02-27T06:08:42Z","published":"2026-02-27T06:08:42Z","title":"From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems","summary":"LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.","authors":["Yawen Wang","Wenjie Wu","Junjie Wang","Qing Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23647v1","updated":"2026-02-27T03:32:47Z","published":"2026-02-27T03:32:47Z","title":"SGAgent: Suggestion-Guided LLM-Based Multi-Agent Framework for Repository-Level Software Repair","summary":"The rapid advancement of Large Language Models (LLMs) has led to the emergence of intelligent agents capable of autonomously interacting with environments and invoking external tools. Recently, agent-based software repair approaches have received widespread attention, as repair agents can automatically analyze and localize bugs, generate patches, and achieve state-of-the-art performance on repository-level benchmarks. However, existing approaches usually adopt a localize-then-fix paradigm, jumping directly from \"where the bug is\" to \"how to fix it\", leaving a fundamental reasoning gap. To this end, we propose SGAgent, a Suggestion-Guided multi-Agent framework for repository-level software repair, which follows a localize-suggest-fix paradigm. SGAgent introduces a suggestion phase to strengthen the transition from localization to repair. The suggester starts from the buggy locations and incrementally retrieves relevant context until it fully understands the bug, and then provides actionable repair suggestions. Moreover, we construct a Knowledge Graph from the target repository and develop a KG-based toolkit to enhance SGAgent's global contextual awareness and repository-level reasoning. Three specialized sub-agents (i.e., localizer, suggester, and fixer) collaborate to achieve automated end-to-end software repair. Experimental results on SWE-Bench show that SGAgent with Claude-3.5 achieves 51.3% repair accuracy, 81.2% file-level and 52.4% function-level localization accuracy with an average cost of $1.48 per instance, outperforming all baselines using the same base model. Furthermore, SGAgent attains 48% accuracy on VUL4J and VJBench for vulnerability repair, demonstrating strong generalization across tasks and programming languages.","authors":["Quanjun Zhang","Chengyu Gao","Yu Han","Ye Shang","Chunrong Fang","Zhenyu Chen","Liang Xiao"],"pdf_url":"","comment":"23 pages, 3 figures"},{"id":"http://arxiv.org/abs/2511.22726v2","updated":"2026-02-27T02:56:37Z","published":"2025-11-27T19:13:24Z","title":"The Repeat Offenders: Characterizing and Predicting Extremely Bug-Prone Source Methods","summary":"Bug prediction has long been considered the \"prince\" of empirical software engineering research, and accordingly, a substantial body of work has focused on predicting bugs to enable early preventive actions. However, most existing studies operate at the class or file level, which practitioners have found to be of limited practical value. As a result, method-level bug prediction has gained increasing attention in recent years. Despite this shift, current method-level prediction models typically treat all buggy methods as equally fault-prone, regardless of whether a method has been associated with a bug once or repeatedly. We argue that methods involved in bugs multiple times-hereafter referred to as ExtremelyBuggy methods-are more harmful than methods that are buggy only once. In this study, we investigate the prevalence of ExtremelyBuggy methods, analyze their code quality metrics, and assess whether they can be predicted at the time of their introduction. In addition, we conduct a thematic analysis of 287 ExtremelyBuggy methods to gain deeper insights into their characteristics.\n  Using a dataset of over 1.25 million methods extracted from 98 open-source Java projects, we find that only a small proportion of methods can be classified as ExtremelyBuggy, yet these methods account for a disproportionately large share of bugs within a project. Although we observe statistically significant differences between ExtremelyBuggy and other methods, ExtremelyBuggy methods remain difficult to predict at their inception. Nevertheless, our manual analysis reveals recurring characteristics among these methods. These findings can help practitioners avoid harmful patterns in practice and guide future research toward developing features and models that better capture the unique properties of such methods.","authors":["Ethan Friesen","Sasha Morton-Salmon","Md Nahidul Islam Opu","Shahidul Islam","Shaiful Chowdhury"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.20340v2","updated":"2026-02-27T02:49:55Z","published":"2025-08-28T01:21:26Z","title":"Once4All: Skeleton-Guided SMT Solver Fuzzing with LLM-Synthesized Generators","summary":"Satisfiability Modulo Theory (SMT) solvers are foundational to modern systems and programming languages research, providing the foundation for tasks like symbolic execution and automated verification. Because these solvers sit on the critical path, their correctness is essential, and high-quality test formulas are key to uncovering bugs. However, while prior testing techniques performed well on earlier solver versions, they struggle to keep pace with rapidly evolving features. Recent approaches based on Large Language Models (LLMs) show promise in exploring advanced solver capabilities, but two obstacles remain: nearly half of the generated formulas are syntactically invalid, and iterative interactions with LLMs introduce substantial computational overhead. In this study, we present Once4All, a novel LLM-assisted fuzzing framework that addresses both issues by shifting from direct formula generation to the synthesis of generators for reusable terms (i.e., logical expressions). Specifically, Once4All uses LLMs to (1) automatically extract context-free grammars (CFGs) for SMT theories, including solver-specific extensions, from documentation, and (2) synthesize composable Boolean term generators that adhere to these grammars. During fuzzing, Once4All populates structural skeletons derived from existing formulas with the terms iteratively produced by the LLM-synthesized generators. This design ensures syntactic validity while promoting semantic diversity. Notably, Once4All requires only one-time LLM interaction investment, dramatically reducing runtime cost. We evaluated Once4All on two leading SMT solvers: Z3 and cvc5. Our experiments show that Once4All has identified 43 confirmed bugs, 40 of which have already been fixed by developers.","authors":["Maolin Sun","Yibiao Yang","Yuming Zhou"],"pdf_url":"","comment":"Accepted at ASPLOS 2026"},{"id":"http://arxiv.org/abs/2602.23592v1","updated":"2026-02-27T01:48:07Z","published":"2026-02-27T01:48:07Z","title":"KEEP: A KV-Cache-Centric Memory Management System for Efficient Embodied Planning","summary":"Memory-augmented Large Language Models (LLMs) have demonstrated remarkable capability for complex and long-horizon embodied planning. By keeping track of past experiences and environmental states, memory enables LLMs to maintain a global view, thereby avoiding repetitive exploration. However, existing approaches often store the memory as raw text, leading to excessively long prompts and high prefill latency. While it is possible to store and reuse the KV caches, the efficiency benefits are greatly undermined due to frequent KV cache updates. In this paper, we propose KEEP, a KV-cache-centric memory management system for efficient embodied planning. KEEP features 3 key innovations: (1) a Static-Dynamic Memory Construction algorithm that reduces KV cache recomputation by mixed-granularity memory group; (2) a Multi-hop Memory Re-computation algorithm that dynamically identifies important cross-attention among different memory groups and reconstructs memory interactions iteratively; (3) a Layer-balanced Memory Loading that eliminates unbalanced KV cache loading and cross-attention computation across different layers. Extensive experimental results have demonstrated that KEEP achieves 2.68x speedup with negligible accuracy loss compared with text-based memory methods on ALFRED dataset. Compared with the KV re-computation method CacheBlend (EuroSys'25), KEEP shows 4.13% success rate improvement and 1.90x time-to-first-token (TTFT) reduction. Our code is available on https://github.com/PKU-SEC-Lab/KEEP_Embodied_Memory.","authors":["Zebin Yang","Tong Xie","Baotong Lu","Shaoshan Liu","Bo Yu","Meng Li"],"pdf_url":"","comment":"DAC 2026"},{"id":"http://arxiv.org/abs/2602.09892v2","updated":"2026-02-27T01:20:12Z","published":"2026-02-10T15:30:19Z","title":"Immersion in the GitHub Universe: Scaling Coding Agents to Mastery","summary":"Achieving mastery in real world software engineering tasks is fundamentally bottlenecked by the scarcity of large scale, high quality training data. Scaling such data has been limited by the complexity of environment setup, unit test generation, and problem statement curation. In this paper, we propose ScaleSWE, an automated, sandboxed multi agent workflow designed to construct high quality SWE data at scale. The system coordinates three specialized agents for environment setup, test creation, and problem description synthesis to process 6 million pull requests across 5200 repositories, producing Scale SWE Data: 100k verified SWE instances, the largest such dataset to date. It substantially surpasses existing real world datasets in repository diversity and reflects realistic task complexity. We further demonstrate the dataset utility for training by distilling 71498 high quality trajectories and finetuning Qwen30BA3BInstruct to produce ScaleSWE Agent. Our agent achieves a 64 resolve rate on SWE Bench Verified a nearly three fold improvement over the base model. ScaleSWE provides a scalable, reproducible approach for data construction to advance LLM based software engineering. Scale SWE will be publicly available.","authors":["Jiale Zhao","Guoxin Chen","Fanzhe Meng","Minghao Li","Jie Chen","Hui Xu","Yongshuai Sun","Xin Zhao","Ruihua Song","Yuan Zhang","Peng Wang","Cheng Chen","Jirong Wen","Kai Jia"],"pdf_url":"","comment":null}],"Security & Program Analysis":[{"id":"http://arxiv.org/abs/2602.24271v1","updated":"2026-02-27T18:41:10Z","published":"2026-02-27T18:41:10Z","title":"NSHEDB: Noise-Sensitive Homomorphic Encrypted Database Query Engine","summary":"Homomorphic encryption (HE) enables computations directly on encrypted data, offering strong cryptographic guarantees for secure and privacy-preserving data storage and query execution. However, despite its theoretical power, practical adoption of HE in database systems remains limited due to extreme cipher-text expansion, memory overhead, and the computational cost of bootstrapping, which resets noise levels for correctness.\n  This paper presents NSHEDB, a secure query processing engine designed to address these challenges at the system architecture level. NSHEDB uses word-level leveled HE (LHE) based on the BFV scheme to minimize ciphertext expansion and avoid costly bootstrapping. It introduces novel techniques for executing equality, range, and aggregation operations using purely homomorphic computation, without transciphering between different HE schemes (e.g., CKKS/BFV/TFHE) or relying on trusted hardware. Additionally, it incorporates a noise-aware query planner to extend computation depth while preserving security guarantees.\n  We implement and evaluate NSHEDB on real-world database workloads (TPC-H) and show that it achieves 20x-V1370x speedup and a 73x storage reduction compared to state-of-the-art HE-based systems, while upholding 128-bit security in a semi-honest model with no key release or trusted components.","authors":["Boram Jung","Yuliang Li","Hung-Wei Tseng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.20686v2","updated":"2026-02-27T18:00:04Z","published":"2025-12-22T15:43:36Z","title":"Sequential Apportionment from Stationary Divisor Methods","summary":"Divisor methods are well known to satisfy house monotonicity, which allows representative seats to be allocated sequentially. We focus on stationary divisor methods defined by a rounding cutpoint $c \\in [0,1]$. For such methods with integer-valued votes, the resulting apportionment sequences are periodic. Restricting attention to two-party allocations, we characterize the set of possible sequences and establish a connection between the lexicographical ordering of these sequences and the parameter $c$. We then show how sequences for all pairs of parties can be systematically extended to the $n$-party setting. Further, we determine the number of distinct sequences in the $n$-party problem for all $c$. Our approach offers a refined perspective on size bias: rather than viewing large parties as simply receiving more seats, we show that they instead obtain their seats earlier in the apportionment sequence. Of particular interest is a new relationship we uncover between the sequences generated by the smallest divisor (Adams) and greatest divisor (D'Hondt or Jefferson) methods.","authors":["Michael A. Jones","Brittany Ohlinger","Jennifer Wilson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24223v1","updated":"2026-02-27T17:49:56Z","published":"2026-02-27T17:49:56Z","title":"Anansi: Scalable Characterization of Message-Based Job Scams","summary":"Job-based smishing scams, where victims are recruited under the guise of remote job opportunities, represent a rapidly growing and understudied threat within the broader landscape of online fraud. In this paper, we present Anansi, the first scalable, end-to-end measurement pipeline designed to systematically engage with, analyze, and characterize job scams in the wild. Anansi combines large language models (LLMs), automated browser agents, and infrastructure fingerprinting tools to collect over 29,000 scam messages, interact with more than 1900 scammers, and extract behavioral, financial, and infrastructural signals at scale. We detail the operational workflows of scammers, uncover extensive reuse of message templates, domains, and cryptocurrency wallets, and identify the social engineering tactics used to defraud victims. Our analysis reveals millions of dollars in cryptocurrency losses, highlighting the use of deceptive techniques such as domain fronting and impersonation of well-known brands. Anansi demonstrates the feasibility and value of automating the engagement with scammers and the analysis of infrastructure, offering a new methodological foundation for studying large-scale fraud ecosystems.","authors":["Abisheka Pitumpe","Amir Rahmati"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22291v2","updated":"2026-02-27T17:04:02Z","published":"2026-02-25T15:08:20Z","title":"Manifold of Failure: Behavioral Attraction Basins in Language Models","summary":"While prior work has focused on projecting adversarial examples back onto the manifold of natural data to restore safety, we argue that a comprehensive understanding of AI safety requires characterizing the unsafe regions themselves. This paper introduces a framework for systematically mapping the Manifold of Failure in Large Language Models (LLMs). We reframe the search for vulnerabilities as a quality diversity problem, using MAP-Elites to illuminate the continuous topology of these failure regions, which we term behavioral attraction basins. Our quality metric, Alignment Deviation, guides the search towards areas where the model's behavior diverges most from its intended alignment. Across three LLMs: Llama-3-8B, GPT-OSS-20B, and GPT-5-Mini, we show that MAP-Elites achieves up to 63% behavioral coverage, discovers up to 370 distinct vulnerability niches, and reveals dramatically different model-specific topological signatures: Llama-3-8B exhibits a near-universal vulnerability plateau (mean Alignment Deviation 0.93), GPT-OSS-20B shows a fragmented landscape with spatially concentrated basins (mean 0.73), and GPT-5-Mini demonstrates strong robustness with a ceiling at 0.50. Our approach produces interpretable, global maps of each model's safety landscape that no existing attack method (GCG, PAIR, or TAP) can provide, shifting the paradigm from finding discrete failures to understanding their underlying structure.","authors":["Sarthak Munshi","Manish Bhatt","Vineeth Sai Narajala","Idan Habler","Ammar Al-Kahfah","Ken Huang","Blake Gatto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24166v1","updated":"2026-02-27T16:47:53Z","published":"2026-02-27T16:47:53Z","title":"SAILOR: A Scalable and Energy-Efficient Ultra-Lightweight RISC-V for IoT Security","summary":"Recently, RISC-V has contributed to the development of IoT devices, requiring architectures that balance energy efficiency, compact area, and integrated security. However, most recent RISC-V cores for IoT prioritize either area footprint or energy efficiency, while adding cryptographic support further compromises compactness. As a result, truly integrated architectures that simultaneously optimize efficiency and security remain largely unexplored, leaving constrained IoT environments vulnerable to performance and security trade-offs. In this paper, we introduce SAILOR, an energy-efficient and scalable ultra-lightweight RISC-V core family for cryptographic applications in IoT. Our design is modular and spans 1-, 2-, 4-, 8-, 16-, and 32-bit serialized execution data-paths, prioritizing minimal area. This modular design and adaptable data-path minimizes the overhead of integrating RISC-V cryptography extensions, achieving low hardware cost while significantly improving energy efficiency. We validate our design approach through a comprehensive analysis of area, energy, and efficiency trade-offs. The results surpass state-of-the-art solutions in both performance and energy efficiency by up to 13x and reduce area by up to 59 %, demonstrating that lightweight cryptographic features can be added without prohibitive overhead, and that energy- or area-efficient designs need not compromise performance.","authors":["Christian Ewert","Tim Hardow","Melf Fritsch","Leon Dietrich","Henrik Strunck","Rainer Buchty","Mladen Berekovic","Saleh Mulhem"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.19633v2","updated":"2026-02-27T15:25:21Z","published":"2025-05-26T07:49:59Z","title":"Weak-Jamming Detection in IEEE 802.11 Networks: Techniques, Scenarios and Mobility","summary":"State-of-the-art solutions detect jamming attacks ex-post, i.e., only when jamming has already disrupted the wireless communication link. In many scenarios, e.g., mobile networks or static deployments distributed over a large geographical area, it is often desired to detect jamming at the early stage, when it affects the communication link enough to be detected but not sufficiently to disrupt it (detection of weak jamming signals). Under such assumptions, devices can enhance situational awareness and promptly apply mitigation, e.g., moving away from the jammed area in mobile scenarios or changing communication frequency in static deployments, before jamming fully disrupts the communication link. Although some contributions recently demonstrated the feasibility of detecting low-power and weak jamming signals, they make simplistic assumptions far from real-world deployments. Given the current state of the art, no evidence exists that detection of weak jamming can be considered with real-world communication technologies. In this paper, we provide and comprehensively analyze new general-purpose strategies for detecting weak jamming signals, compatible by design with one of the most relevant communication technologies used by commercial-off-the-shelf devices, i.e., IEEE 802.11. We describe two operational modes: (i) binary classification via Convolutional Neural Networks and (ii) one-class classification via Sparse Autoencoders. We evaluate and compare the proposed approaches with the current state-of-the-art using data collected through an extensive real-world experimental campaign in three relevant environments. At the same time, we made the dataset available to the public. Our results demonstrate that detecting weak jamming signals is feasible in all considered real-world environments, and we provide an in-depth analysis considering different techniques, scenarios, and mobility patterns.","authors":["Martijn Hanegraaf","Savio Sciancalepore","Gabriele Oligeri"],"pdf_url":"","comment":"Accepted for Publication in Elsevier Computer Networks"},{"id":"http://arxiv.org/abs/2509.22215v2","updated":"2026-02-27T14:46:53Z","published":"2025-09-26T11:29:53Z","title":"Learn, Check, Test -- Security Testing Using Automata Learning and Model Checking","summary":"Security verification of communication protocols in industrial and safety-critical systems is challenging because implementations are often proprietary, accessible only as black boxes, and too complex for manual modeling. As a result, existing security testing approaches usually depend on incomplete test suites and/or require labor-intensive modeling, limiting coverage, scalability, and trust. This paper addresses the problem of systematically verifying protocol security-properties without access to internal system models. We propose a flexible and scalable method for formal verification of communication protocols that combines active automata learning with model checking to enable rigorous security analysis of black-box protocol implementations. The key contributions include: (i) a method for augmenting learned protocol models with security-relevant propositions, (ii) a fully automated transformation pipeline from learned models to model-checking artifacts, (iii) reusable, generic security property templates that are instantiated in protocol-specific models, and (iv) empirical validation through case studies demonstrating applicability in different protocols and domains. The results show that the approach enables scalable and systematic discovery of security vulnerabilities in black-box systems while reducing modeling effort and improving automation compared with traditional verification workflows.","authors":["Stefan Marksteiner","Mikael Sjödin","Marjan Sirjani"],"pdf_url":"","comment":"26 pages, 9 figures, 4 tables, preprint submitted to Elsevier Computers & Security - Original abstract shortened to comply to the arXiv requirements"},{"id":"http://arxiv.org/abs/2602.24047v1","updated":"2026-02-27T14:31:01Z","published":"2026-02-27T14:31:01Z","title":"Unsupervised Baseline Clustering and Incremental Adaptation for IoT Device Traffic Profiling","summary":"The growth and heterogeneity of IoT devices create security challenges where static identification models can degrade as traffic evolves. This paper presents a two-stage, flow-feature-based pipeline for unsupervised IoT device traffic profiling and incremental model updating, evaluated on selected long-duration captures from the Deakin IoT dataset. For baseline profiling, density-based clustering (DBSCAN) isolates a substantial outlier portion of the data and produces the strongest alignment with ground-truth device labels among tested classical methods (NMI 0.78), outperforming centroid-based clustering on cluster purity. For incremental adaptation, we evaluate stream-oriented clustering approaches and find that BIRCH supports efficient updates (0.13 seconds per update) and forms comparatively coherent clusters for a held-out novel device (purity 0.87), but with limited capture of novel traffic (share 0.72) and a measurable trade-off in known-device accuracy after adaptation (0.71). Overall, the results highlight a practical trade-off between high-purity static profiling and the flexibility of incremental clustering for evolving IoT environments.","authors":["Sean M. Alderman","John D. Hastings"],"pdf_url":"","comment":"6 pages, 2 figures, 4 tables"},{"id":"http://arxiv.org/abs/2508.12412v2","updated":"2026-02-27T13:51:56Z","published":"2025-08-17T15:55:02Z","title":"LumiMAS: A Comprehensive Framework for Real-Time Monitoring and Enhanced Observability in Multi-Agent Systems","summary":"The incorporation of LLMs in multi-agent systems (MASs) has the potential to significantly improve our ability to autonomously solve complex problems. However, such systems introduce unique challenges in monitoring, interpreting, and detecting system failures. Most existing MAS observability frameworks focus on analyzing each individual agent separately, overlooking failures associated with the entire MAS. To bridge this gap, we propose LumiMAS, a novel MAS observability framework that incorporates advanced analytics and monitoring techniques. The proposed framework consists of three key components: a monitoring and logging layer, anomaly detection layer, and anomaly explanation layer. LumiMAS's first layer monitors MAS executions, creating detailed logs of the agents' activity. These logs serve as input to the anomaly detection layer, which detects anomalies across the MAS workflow in real time. Then, the anomaly explanation layer performs classification and root cause analysis (RCA) of the detected anomalies. LumiMAS was evaluated on seven different MAS applications, implemented using two popular MAS platforms, and a diverse set of possible failures. The applications include two novel failure-tailored applications that illustrate the effects of a hallucination or bias on the MAS. The evaluation results demonstrate LumiMAS's effectiveness in failure detection, classification, and RCA.","authors":["Ron Solomon","Yarin Yerushalmi Levi","Lior Vaknin","Eran Aizikovich","Amit Baras","Etai Ohana","Amit Giloni","Shamik Bose","Chiara Picardi","Yuval Elovici","Asaf Shabtai"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.20222v2","updated":"2026-02-27T13:44:43Z","published":"2026-02-23T13:24:59Z","title":"The TCF doesn't really A(A)ID -- Automatic Privacy Analysis and Legal Compliance of TCF-based Android Applications","summary":"The Transparency and Consent Framework (TCF), developed by the Interactive Advertising Bureau (IAB) Europe, provides a de facto standard for requesting, recording, and managing user consent from European end-users. This framework has previously been found to infringe European data protection law and has subsequently been regularly updated. Previous research on the TCF focused exclusively on web contexts, with no attention given to its implementation in mobile applications. No work has systematically studied the privacy implications of the TCF on Android apps. To address this gap, we investigate the prevalence of the TCF in popular Android apps from the Google Play Store, and assess whether these apps respect users' consent banner choices. By scraping and downloading 4482 of the most popular Google Play Store apps on an emulated Android device, we automatically determine which apps use the TCF, automatically interact with consent banners, and analyze the apps' traffic in two different stages, passive (post choices) and active (during banner interaction and post choices).\n  We found that 576 (12.85%) of the 4482 downloadable apps in our dataset implemented the TCF, and we identified potential privacy violations within this subset. In 15 (2.6%) of these apps, users' choices are stored only when consent is granted. Users who refuse consent are shown the consent banner again each time they launch the app. Network traffic analysis conducted during the passive stage reveals that 66.2% of the analyzed TCF-based apps share personal data, through the Android Advertising ID (AAID), in the absence of a lawful basis for processing. 55.3% of apps analyzed during the active stage share AAID before users interact with the apps' consent banners, violating the prior consent requirement.","authors":["Victor Morel","Cristiana Santos","Pontus Carlsson","Joel Ahlinder","Romaric Duvignau"],"pdf_url":"","comment":"Accepted for publication at PETS'26"},{"id":"http://arxiv.org/abs/2602.24009v1","updated":"2026-02-27T13:32:53Z","published":"2026-02-27T13:32:53Z","title":"Jailbreak Foundry: From Papers to Runnable Attacks for Reproducible Benchmarking","summary":"Jailbreak techniques for large language models (LLMs) evolve faster than benchmarks, making robustness estimates stale and difficult to compare across papers due to drift in datasets, harnesses, and judging protocols. We introduce JAILBREAK FOUNDRY (JBF), a system that addresses this gap via a multi-agent workflow to translate jailbreak papers into executable modules for immediate evaluation within a unified harness. JBF features three core components: (i) JBF-LIB for shared contracts and reusable utilities; (ii) JBF-FORGE for the multi-agent paper-to-module translation; and (iii) JBF-EVAL for standardizing evaluations. Across 30 reproduced attacks, JBF achieves high fidelity with a mean (reproduced-reported) attack success rate (ASR) deviation of +0.26 percentage points. By leveraging shared infrastructure, JBF reduces attack-specific implementation code by nearly half relative to original repositories and achieves an 82.5% mean reused-code ratio. This system enables a standardized AdvBench evaluation of all 30 attacks across 10 victim models using a consistent GPT-4o judge. By automating both attack integration and standardized evaluation, JBF offers a scalable solution for creating living benchmarks that keep pace with the rapidly shifting security landscape.","authors":["Zhicheng Fang","Jingjie Zheng","Chenxu Fu","Wei Xu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.03816v2","updated":"2026-02-27T13:14:19Z","published":"2025-12-03T14:03:43Z","title":"Log Probability Tracking of LLM APIs","summary":"When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.","authors":["Timothée Chauvin","Erwan Le Merrer","François Taïani","Gilles Tredan"],"pdf_url":"","comment":"ICLR 2026"},{"id":"http://arxiv.org/abs/2602.23874v1","updated":"2026-02-27T10:16:28Z","published":"2026-02-27T10:16:28Z","title":"Exploring Robust Intrusion Detection: A Benchmark Study of Feature Transferability in IoT Botnet Attack Detection","summary":"Cross-domain intrusion detection remains a critical challenge due to significant variability in network traffic characteristics and feature distributions across environments. This study evaluates the transferability of three widely used flow-based feature sets (Argus, Zeek and CICFlowMeter) across four widely used datasets representing heterogeneous IoT and Industrial IoT network conditions. Through extensive experiments, we evaluate in- and cross-domain performance across multiple classification models and analyze feature importance using SHapley Additive exPlanations (SHAP). Our results show that models trained on one domain suffer significant performance degradation when applied to a different target domain, reflecting the sensitivity of IoT intrusion detection systems to distribution shifts. Furthermore, the results evidence that the choice of classification algorithm and feature representations significantly impact transferability. Beyond reporting performance differences and thorough analysis of the transferability of features and feature spaces, we provide practical guidelines for feature engineering to improve robustness under domain variability. Our findings suggest that effective intrusion detection requires both high in-domain performance and resilience to cross-domain variability, achievable through careful feature space design, appropriate algorithm selection and adaptive strategies.","authors":["Alejandro Guerra-Manzanares","Jialin Huang"],"pdf_url":"","comment":"Accepted for publication in the Proceedings of the 2026 International Conference on Information Systems Security and Privacy (ICISSP)"},{"id":"http://arxiv.org/abs/2602.23846v1","updated":"2026-02-27T09:37:05Z","published":"2026-02-27T09:37:05Z","title":"MI$^2$DAS: A Multi-Layer Intrusion Detection Framework with Incremental Learning for Securing Industrial IoT Networks","summary":"The rapid expansion of Industrial IoT (IIoT) systems has amplified security challenges, as heterogeneous devices and dynamic traffic patterns increase exposure to sophisticated and previously unseen cyberattacks. Traditional intrusion detection systems often struggle in such environments due to their reliance on extensive labeled data and limited ability to detect new threats. To address these challenges, we propose MI$^2$DAS, a multi-layer intrusion detection framework that integrates anomaly-based hierarchical traffic pooling, open-set recognition to distinguish between known and unknown attacks and incremental learning for adapting to novel attack types with minimal labeling. Experiments conducted on the Edge-IIoTset dataset demonstrate strong performance across all layers. In the first layer, GMM achieves superior normal-attack discrimination (accuracy = 0.953, TPR = 1.000). In open-set recognition, GMM attains a recall of 0.813 for known attacks, while LOF achieves 0.882 recall for unknown attacks. For fine-grained classification of known attacks, Random Forest achieves a macro-F1 of 0.941. Finally, the incremental learning module maintains robust performance when incorporation novel attack classes, achieving a macro-F1 of 0.8995. These results showcase MI$^2$DAS as an effective, scalable and adaptive framework for enhancing IIoT security against evolving threats.","authors":["Wei Lian","Alejandro Guerra-Manzanares"],"pdf_url":"","comment":"Accepted for publication in the Proceedings of the 2026 International Conference on Information Systems Security and Privacy (ICISSP)"},{"id":"http://arxiv.org/abs/2502.18303v2","updated":"2026-02-27T09:35:41Z","published":"2025-02-25T15:43:16Z","title":"Analysis of Efficiency of the Messaging Layer Security protocol in Experimental Settings","summary":"Messaging Layer Security (MLS) and its underlying Continuous Group Key Agreement (CGKA) protocol allows a group of users to share a cryptographic secret in a dynamic manner, such that the secret is modified in member insertions and deletions. One of the most relevant contributions of MLS is its efficiency, as its communication cost scales logarithmically with the number of members. However, this claim has only been analysed in theoretical models and thus it is unclear how efficient MLS is in real-world scenarios. Furthermore, practical considerations such as the chosen paradigm and the evolution of the group can also influence the performance of an MLS group. In this work we analyse MLS from an empirical viewpoint: we provide real-world measurements for metrics such as commit generation and processing times and message sizes under different conditions. In order to obtain these results we have developed a highly configurable environment for empirical evaluations of MLS through the emulation of MLS clients. Among other findings, our results show that computation costs scale linearly in practical settings even in the best-case scenario.","authors":["David Soler","Carlos Dafonte","Manuel Fernández-Veiga","Ana Fernández Vilas","Francisco J. Nóvoa"],"pdf_url":"","comment":"26 pages, 11 figures. Preprint: Submitted for review to IEEE Open Journal of the Computer Society. This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2602.22983v2","updated":"2026-02-27T09:27:35Z","published":"2026-02-26T13:25:35Z","title":"Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search","summary":"As Large Language Models (LLMs) are increasingly used, their security risks have drawn increasing attention. Existing research reveals that LLMs are highly susceptible to jailbreak attacks, with effectiveness varying across language contexts. This paper investigates the role of classical Chinese in jailbreak attacks. Owing to its conciseness and obscurity, classical Chinese can partially bypass existing safety constraints, exposing notable vulnerabilities in LLMs. Based on this observation, this paper proposes a framework, CC-BOS, for the automatic generation of classical Chinese adversarial prompts based on multi-dimensional fruit fly optimization, facilitating efficient and automated jailbreak attacks in black-box settings. Prompts are encoded into eight policy dimensions-covering role, behavior, mechanism, metaphor, expression, knowledge, trigger pattern and context; and iteratively refined via smell search, visual search, and cauchy mutation. This design enables efficient exploration of the search space, thereby enhancing the effectiveness of black-box jailbreak attacks. To enhance readability and evaluation accuracy, we further design a classical Chinese to English translation module. Extensive experiments demonstrate that effectiveness of the proposed CC-BOS, consistently outperforming state-of-the-art jailbreak attack methods.","authors":["Xun Huang","Simeng Qin","Xiaoshuang Jia","Ranjie Duan","Huanqian Yan","Zhitao Zeng","Fei Yang","Yang Liu","Xiaojun Jia"],"pdf_url":"","comment":"ICLR 2026 Poster"},{"id":"http://arxiv.org/abs/2602.23834v1","updated":"2026-02-27T09:13:23Z","published":"2026-02-27T09:13:23Z","title":"Enhancing Continual Learning for Software Vulnerability Prediction: Addressing Catastrophic Forgetting via Hybrid-Confidence-Aware Selective Replay for Temporal LLM Fine-Tuning","summary":"Recent work applies Large Language Models (LLMs) to source-code vulnerability detection, but most evaluations still rely on random train-test splits that ignore time and overestimate real-world performance. In practice, detectors are deployed on evolving code bases and must recognise future vulnerabilities under temporal distribution shift. This paper investigates continual fine-tuning of a decoder-style language model (microsoft/phi-2 with LoRA) on a CVE-linked dataset spanning 2018-2024, organised into bi-monthly windows. We evaluate eight continual learning strategies, including window-only and cumulative training, replay-based baselines and regularisation-based variants. We propose Hybrid Class-Aware Selective Replay (Hybrid-CASR), a confidence-aware replay method for binary vulnerability classification that prioritises uncertain samples while maintaining a balanced ratio of VULNERABLE and FIXED functions in the replay buffer. On bi-monthly forward evaluation Hybrid-CASR achieves a Macro-F1 of 0.667, improving on the window-only baseline (0.651) by 0.016 with statistically significant gains ($p = 0.026$) and stronger backward retention (IBR@1 of 0.741). Hybrid-CASR also reduces training time per window by about 17 percent compared to the baseline, whereas cumulative training delivers only a minor F1 increase (0.661) at a 15.9-fold computational cost. Overall, the results show that selective replay with class balancing offers a practical accuracy-efficiency trade-off for LLM-based temporal vulnerability detection under continuous temporal drift.","authors":["Xuhui Dou","Hayretdin Bahsi","Alejandro Guerra-Manzanares"],"pdf_url":"","comment":"Accepted for publication in the Proceedings of the 2026 International Conference on Information Systems Security and Privacy (ICISSP)"},{"id":"http://arxiv.org/abs/2602.23798v1","updated":"2026-02-27T08:39:36Z","published":"2026-02-27T08:39:36Z","title":"MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models","summary":"Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.","authors":["Tiantong Wang","Xinyu Yan","Tiantong Wu","Yurong Hao","Yong Jiang","Fei Huang","Wei Yang Bryan Lim"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23772v1","updated":"2026-02-27T07:57:31Z","published":"2026-02-27T07:57:31Z","title":"Tilewise Domain-Separated Selective Encryption for Remote Sensing Imagery under Chosen-Plaintext Attacks","summary":"Selective image encryption is common in remote sensing systems because it protects sensitive regions of interest (ROI) while limiting computational cost. However, many selective designs enable cross-tile structural leakage under chosen-plaintext attacks when secret-dependent transformations are reused across spatial positions. This paper proposes Tilewise Domain-Separated Selective Encryption (TDS-SE), where per-tile (and optionally per-frame) keys are derived from a master secret via HKDF with explicit domain separation, and ROI masks are treated strictly as external side information. Structural leakage is evaluated using two reconstruction-based distinguishers -- a linear model and a lightweight convolutional neural network -- under multiple attack settings. Experiments on RESISC45 and SEN12MS cover ablation tests, cross-position transferability, cross-sample generalization, and ROI-knowledge asymmetry. Results show that per-tile domain separation reduces position-conditioned transfer for the linear probe, and that adding frame freshness improves robustness to imperfect ROI assumptions for the CNN probe. Cross-sample generalization exhibits mixed behavior across settings, consistent with an empirical evaluation perspective, while selective-encryption functionality is preserved under the same tiling and ROI policy. Beyond the method itself, the paper provides a structured protocol for evaluating selective encryption under realistic attacker capabilities.","authors":["Jilei Sun","Dianhong Wu","Ying Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23760v1","updated":"2026-02-27T07:37:34Z","published":"2026-02-27T07:37:34Z","title":"PLA for Drone RID Frames via Motion Estimation and Consistency Verification","summary":"Drone Remote Identification (RID) plays a critical role in low-altitude airspace supervision, yet its broadcast nature and lack of cryptographic protection make it vulnerable to spoofing and replay attacks. In this paper, we propose a consistency verification-based physical-layer authentication (PLA) algorithm for drone RID frames. A RID-aware sensing and decoding module is first developed to extract communication-derived sensing parameters, including angle-of-arrival, Doppler shift, average channel gain, and the number of transmit antennas, together with the identity and motion-related information decoded from previously authenticated RID frames. Rather than fusing all heterogeneous information into a single representation, different types of information are selectively utilized according to their physical relevance and reliability. Specifically, real-time wireless sensing parameter constraints and previously authenticated motion states are incorporated in a yaw-augmented constant-acceleration extended Kalman filter (CA-EKF) to estimate the three-dimensional position and motion states of the drone. To further enhance authentication reliability under highly maneuverable and non-stationary flight scenarios, a data-driven long short-term memory-based motion estimator is employed, and its predictions are adaptively combined with the CA-EKF via an error-aware fusion strategy. Finally, RID frames are authenticated by verifying consistency in the number of transmit antennas, motion estimates, and no-fly-zone constraints. Simulation results demonstrate that the proposed algorithm significantly improves authentication reliability and robustness under realistic wireless impairments and complex drone maneuvers, outperforming existing RF feature-based and motion model-based PLA schemes.","authors":["Jie Li","Jing Li","Lu Lv","Zhanyu Ju","Fengkui Gong"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23698v1","updated":"2026-02-27T05:55:12Z","published":"2026-02-27T05:55:12Z","title":"Privacy-Preserving Local Energy Trading Considering Network Fees","summary":"Driven by the widespread deployment of distributed energy resources, local energy markets (LEMs) have emerged as a promising approach for enabling direct trades among prosumers and consumers to balance intermittent generation and demand locally. However, LEMs involve processing sensitive participant data, which, if not protected, poses privacy risks. At the same time, since electricity is exchanged over the physical power network, market mechanisms should consider physical constraints and network-related costs. Existing work typically addresses these issues separately, either by incorporating grid-related aspects or by providing privacy protection. To address this gap, we propose a privacy-preserving protocol for LEMs, with consideration of network fees that can incite participants to respect physical limits. The protocol is based on a double-auction mechanism adapted from prior work to enable more efficient application of our privacy-preserving approach. To protect participants' data, we use secure multiparty computation. In addition, Schnorr's identification protocol is employed with multiparty verification to ensure authenticated participation without compromising privacy. We further optimise the protocol to reduce communication and round complexity. We prove that the protocol meets its security requirements and show through experimentation its feasibility at a typical LEM scale: a market with 5,000 participants can be cleared in 4.17 minutes.","authors":["Eman Alqahtani","Mustafa A. Mustafa"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10932v3","updated":"2026-02-27T05:13:30Z","published":"2025-10-13T02:45:48Z","title":"DropVLA: An Action-Level Backdoor Attack on Vision--Language--Action Models","summary":"Vision-Language-Action (VLA) models map multimodal perception and language instructions to executable robot actions, making them particularly vulnerable to behavioral backdoor manipulation: a hidden trigger introduced during training can induce unintended physical actions while nominal task performance remains intact. Prior work on VLA backdoors primarily studies untargeted attacks or task-level hijacking, leaving fine-grained control over individual actions largely unexplored. In this work, we present DropVLA, an action-level backdoor attack that forces a reusable action primitive (e.g., open_gripper) to execute at attacker-chosen decision points under a realistic pipeline-black-box setting with limited data-poisoning access, using a window-consistent relabeling scheme for chunked fine-tuning. On OpenVLA-7B evaluated with LIBERO, vision-only poisoning achieves 98.67%-99.83% attack success rate (ASR) with only 0.31% poisoned episodes while preserving 98.50%-99.17% clean-task retention, and successfully triggers the targeted action within 25 control steps at 500 Hz (0.05 s). Text-only triggers are unstable at low poisoning budgets, and combining text with vision provides no consistent ASR improvement over vision-only attacks. The backdoor remains robust to moderate trigger variations and transfers across evaluation suites (96.27%, 99.09%), whereas text-only largely fails (0.72%). We further validate physical-world feasibility on a 7-DoF Franka arm with pi0-fast, demonstrating non-trivial attack efficacy under camera-relative motion that induces image-plane trigger drift. These results reveal that VLA models can be covertly steered at the granularity of safety-critical actions with minimal poisoning and without observable degradation of nominal performance.","authors":["Zonghuan Xu","Xiang Zheng","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"","comment":"8 pages, 6 tables, 3 figures. Under review"},{"id":"http://arxiv.org/abs/2302.04482v2","updated":"2026-02-27T04:44:22Z","published":"2023-02-09T07:55:06Z","title":"Secret Sharing on Superconcentrator","summary":"We study the arithmetic circuit complexity of threshold secret sharing schemes by characterizing the graph-theoretic properties of arithmetic circuits that compute the shares. Using information inequalities, we prove that any unrestricted arithmetic circuit (with arbitrary gates and unbounded fan-in) computing the shares must satisfy superconcentrator-like connectivity properties. Specifically, when the inputs consist of the secret and $t-1$ random elements, and the outputs are the $n$ shares of a $(t, n)$-threshold secret sharing scheme, the circuit graph must be a $(t, n)$-concentrator; moreover, after removing the secret input, the remaining graph is a $(t-1, n)$-concentrator. Conversely, we show that any graph satisfying these properties can be transformed into a linear arithmetic circuit computing the shares of a threshold secret sharing scheme, assuming a sufficiently large field. As a consequence, we derive upper and lower bounds on the arithmetic circuit complexity of computing the shares in threshold secret sharing schemes.","authors":["Yuan Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.00104v3","updated":"2026-02-27T04:17:12Z","published":"2025-08-28T00:42:49Z","title":"Towards Enhanced Quantum Resistance for RSA via Constrained Rényi Entropy Optimization: A Mathematical Framework for Backward-Compatible Cryptography","summary":"The advent of quantum computing poses a critical threat to RSA cryptography, as Shor's algorithm can factor integers in polynomial time. While post-quantum cryptography standards offer long-term solutions, their deployment faces significant compatibility and infrastructure challenges. This paper proposes the Constrained Rényi Entropy Optimization (CREO) framework, a mathematical approach to potentially enhance the quantum resistance of RSA while maintaining full backward compatibility. By constraining the proximity of RSA primes ($|p-q| < γ\\sqrt{pq}$), CREO reduces the distinguishability of quantum states in Shor's algorithm, as quantified by Rényi entropy. Our analysis demonstrates that for a $k$-bit modulus with $γ= k^{-1/2+ε}$, the number of quantum measurements required for reliable period extraction scales as $Ω(k^{2+ε})$, compared to $\\mathcal{O}(k^3)$ for standard RSA under idealized assumptions. This represents a systematic increase in quantum resource requirements. The framework is supported by constructive existence proofs for such primes using prime gap theorems and establishes conceptual security connections to lattice-based problems. CREO provides a new research direction for exploring backward-compatible cryptographic enhancements during the extended transition to post-quantum standards, offering a mathematically grounded pathway to harden widely deployed RSA infrastructure without requiring immediate protocol or infrastructure replacement.","authors":["Ruopengyu Xu","Chenglian Liu"],"pdf_url":"","comment":"29 pages, 5 tables, 2 figures"},{"id":"http://arxiv.org/abs/2602.14135v4","updated":"2026-02-27T04:12:34Z","published":"2026-02-15T13:12:44Z","title":"ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI","summary":"Rapidly evolving AI exhibits increasingly strong autonomy and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical limitations such as restricted risk dimensions and failed frontier risk detection. The lagging safety benchmarks and alignment technologies can hardly address the complex challenges posed by cutting-edge AI models. To bridge this gap, we propose the \"ForesightSafety Bench\" AI Safety Evaluation Framework, beginning with 7 major Fundamental Safety pillars and progressively extends to advanced Embodied AI Safety, AI4Science Safety, Social and Environmental AI risks, Catastrophic and Existential Risks, as well as 8 critical industrial safety domains, forming a total of 94 refined risk dimensions. To date, the benchmark has accumulated tens of thousands of structured risk data points and assessment results, establishing a widely encompassing, hierarchically clear, and dynamically evolving AI safety evaluation framework. Based on this benchmark, we conduct systematic evaluation and in-depth analysis of over twenty mainstream advanced large models, identifying key risk patterns and their capability boundaries. The safety capability evaluation results reveals the widespread safety vulnerabilities of frontier AI across multiple pillars, particularly focusing on Risky Agentic Autonomy, AI4Science Safety, Embodied AI Safety, Social AI Safety and Catastrophic and Existential Risks. Our benchmark is released at https://github.com/Beijing-AISI/ForesightSafety-Bench. The project website is available at https://foresightsafety-bench.beijing-aisi.ac.cn/.","authors":["Haibo Tong","Feifei Zhao","Linghao Feng","Ruoyu Wu","Ruolin Chen","Lu Jia","Zhou Zhao","Jindong Li","Tenglong Li","Erliang Lin","Shuai Yang","Enmeng Lu","Yinqian Sun","Qian Zhang","Zizhe Ruan","Jinyu Fan","Zeyang Yue","Ping Wu","Huangrui Li","Chengyi Sun","Yi Zeng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2410.10922v4","updated":"2026-02-27T03:57:26Z","published":"2024-10-14T12:08:12Z","title":"Towards Privacy-Guaranteed Label Unlearning in Vertical Federated Learning: Few-Shot Forgetting without Disclosure","summary":"This paper addresses the critical challenge of unlearning in Vertical Federated Learning (VFL), a setting that has received far less attention than its horizontal counterpart. Specifically, we propose the first method tailored to \\textit{label unlearning} in VFL, where labels play a dual role as both essential inputs and sensitive information. To this end, we employ a representation-level manifold mixup mechanism to generate synthetic embeddings for both unlearned and retained samples. This is to provide richer signals for the subsequent gradient-based label forgetting and recovery steps. These augmented embeddings are then subjected to gradient-based label forgetting, effectively removing the associated label information from the model. To recover performance on the retained data, we introduce a recovery-phase optimization step that refines the remaining embeddings. This design achieves effective label unlearning while maintaining computational efficiency. We validate our method through extensive experiments on diverse datasets, including MNIST, CIFAR-10, CIFAR-100, ModelNet, Brain Tumor MRI, COVID-19 Radiography, and Yahoo Answers demonstrate strong efficacy and scalability. Overall, this work establishes a new direction for unlearning in VFL, showing that re-imagining mixup as an efficient mechanism can unlock practical and utility-preserving unlearning. The code is publicly available at https://github.com/bryanhx/Towards-Privacy-Guaranteed-Label-Unlearning-in-Vertical-Federated-Learning","authors":["Hanlin Gu","Hong Xi Tae","Lixin Fan","Chee Seng Chan"],"pdf_url":"","comment":"Accepted at ICLR2026. This paper introduces the first method for label unlearning in vertical federated learning (VFL), focused on preventing label leakage by the active party"},{"id":"http://arxiv.org/abs/2602.23659v1","updated":"2026-02-27T03:56:40Z","published":"2026-02-27T03:56:40Z","title":"Central Bank Digital Currencies: Where is the Privacy, Technology, and Anonymity?","summary":"In an age of financial system digitisation and the increasing adoption of digital currencies, Central Bank Digital Currencies (CBDCs) have emerged as a focal point for technological innovation. Privacy compliance has become a key factor in the successful design of CBDCs, extending beyond technical requirements to influence legal requirements, user trust, and security considerations. Implementing Privacy-Enhancing Technologies (PETs) in CBDCs requires an interdisciplinary approach, however, the lack of a common understanding of privacy and the essential technological characteristics restricts progress. This work investigates: (1) How privacy can be defined within the framework of CBDCs and what implications does this definition have for CBDCs design? and (2) Which PETs can be employed to enhance privacy in CBDC design? We propose a comprehensive definition for privacy that is mapped to the cryptographic landscape for feature implementation. The research is validated against case studies from 20 current CBDCs. The study shows that comprehensive privacy can be designed in the proposal stage, but that privacy does not reach the launched version of the CBDC.","authors":["Jeff Nijsse","Andrea Pinto"],"pdf_url":"","comment":"21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2602.23587v1","updated":"2026-02-27T01:32:12Z","published":"2026-02-27T01:32:12Z","title":"PDF: PUF-based DNN Fingerprinting for Knowledge Distillation Traceability","summary":"Knowledge distillation transfers large teacher models to compact student models, enabling deployment on resource-limited platforms while suffering minimal performance degradation. However, this paradigm could lead to various security risks, especially model theft. Existing defenses against model theft, such as watermarking and secure enclaves, focus primarily on identity authentication and incur significant resource costs. Aiming to provide post-theft accountability and traceability, we propose a novel fingerprinting framework that superimposes device-specific Physical Unclonable Function (PUF) signatures onto teacher logits during distillation. Compared with watermarking or secure enclaves, our approach is lightweight, requires no architectural changes, and enables traceability of any leaked or cloned model. Since the signatures are based on PUFs, this framework is robust against reverse engineering and tampering attacks. In this framework, the signature recovery process consists of two stages: first a neural network-based decoder and then a Hamming distance decoder. Furthermore, we also propose a bit compression scheme to support a large number of devices. Experiment results demonstrate that our framework achieves high key recovery rate and negligible accuracy loss while allowing a tunable trade-off between these two key metrics. These results show that the proposed framework is a practical and robust solution for protecting distilled models.","authors":["Ning Lyu","Yuntao Liu","Yonghong Bai","Zhiyuan Yan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23569v1","updated":"2026-02-27T00:39:10Z","published":"2026-02-27T00:39:10Z","title":"CLOAQ: Combined Logic and Angle Obfuscation for Quantum Circuits","summary":"In the realm of quantum computing, quantum circuits serve as essential depictions of quantum algorithms, which are then compiled into executable operations for quantum computations. Quantum compilers are responsible for converting these algorithmic quantum circuits into versions compatible with specific quantum hardware, thus connecting quantum software with hardware. Nevertheless, untrusted quantum compilers present notable threats. They have the potential to result in the theft of quantum circuit designs and jeopardize sensitive intellectual property (IP). In this work, we propose CLOAQ, a quantum circuit obfuscation (QCO) approach that hides the logic and the phase angles of selected gates within the obfuscated quantum circuit. To evaluate the effectiveness of CLOAQ, we sample the input state uniformly from the Hilbert space of all qubits, which is more accurate than prior work that use all-|0> inputs. Our results show that CLOAQ benefits from the synergy between logic and phase protections. Compared with prior QCO approaches using only one perspective, the combined method is more resilient to attacks and causes greater functional disruption when the unlocking key is incorrect.","authors":["Vincent Langford","Shihan Zhao","Hongyu Zhang","Ben Dong","Qian Wang","Anees Rehman","Yuntao Liu"],"pdf_url":"","comment":"To appear at ISCAS 2026"},{"id":"http://arxiv.org/abs/2602.23560v1","updated":"2026-02-27T00:05:37Z","published":"2026-02-27T00:05:37Z","title":"I've Seen This IP: A Practical Intersection Attack Against Tor Introduction Circuits and Hidden Services","summary":"Tor onion services rely on long-lived introduction circuits to support anonymous rendezvous between clients and services. Although Tor includes some defenses against traffic analysis, the introduction protocol retains deterministic routing structure that can be leveraged by an adversary. We describe a practical intersection attack on Tor introduction circuits that can, over repeated interactions, identify each hop from the introduction point toward the onion service while requiring observation at only one relay per stage. The attack issues repeated probes and intersects destination IP address sets observed within narrowly defined \\texttt{INTRODUCE1}--\\texttt{RENDEZVOUS2} time windows, without assuming global visibility or access to packet payloads. We evaluate feasibility with live-network experiments using a self-operated onion service and relays, and we follow data-minimization and ethical safeguards throughout. The results show reliable convergence in practice, with the rate affected by consensus weight, and time-varying background traffic. We also assess practicality under a partial-global adversary model and discuss implications in light of the geographic concentration of Tor relay weight across cooperating jurisdictions.","authors":["Nicolas Constantinides"],"pdf_url":"","comment":"11 pages, 3 figures"}],"Robotics (UAV & Autonomous Systems)":[{"id":"http://arxiv.org/abs/2511.18183v3","updated":"2026-02-27T18:48:43Z","published":"2025-11-22T20:39:31Z","title":"Off-Road Navigation via Implicit Neural Representation of Terrain Traversability","summary":"Autonomous off-road navigation requires robots to estimate terrain traversability from onboard sensors and plan motion accordingly. Conventional approaches typically rely on sampling-based planners such as MPPI to generate short-term control actions that aim to minimize traversal time and risk measures derived from the traversability estimates. These planners can react quickly but optimize only over a short look-ahead window, limiting their ability to reason about the full path geometry, which is important for navigating in challenging off-road environments. Moreover, they lack the ability to adjust speed based on the terrain-induced vibrations, which is important for smooth navigation on challenging terrains. In this paper, we introduce TRAIL (Traversability with an Implicit Learned Representation), an off-road navigation framework that leverages an implicit neural representation to model terrain properties as a continuous field that can be queried at arbitrary locations. This representation yields spatial gradients that enable integration with a novel gradient-based trajectory optimization method that adapts the path geometry and speed profile based on terrain traversability.","authors":["Yixuan Jia","Qingyuan Li","Jonathan P. How"],"pdf_url":"","comment":"Full version: 10 pages"},{"id":"http://arxiv.org/abs/2602.21157v2","updated":"2026-02-27T18:18:30Z","published":"2026-02-24T18:04:31Z","title":"HALO: A Unified Vision-Language-Action Model for Embodied Multimodal Chain-of-Thought Reasoning","summary":"Vision-Language-Action (VLA) models have shown strong performance in robotic manipulation, but often struggle in long-horizon or out-of-distribution scenarios due to the lack of explicit mechanisms for multimodal reasoning and anticipating how the world will evolve under action. Recent works introduce textual chain-of-thought or visual subgoal prediction within VLA models to reason, but still fail to offer a unified human-like reasoning framework for joint textual reasoning, visual foresight, and action prediction. To this end, we propose HALO, a unified VLA model that enables embodied multimodal chain-of-thought (EM-CoT) reasoning through a sequential process of textual task reasoning, visual subgoal prediction for fine-grained guidance, and EM-CoT-augmented action prediction. We instantiate HALO with a Mixture-of-Transformers (MoT) architecture that decouples semantic reasoning, visual foresight, and action prediction into specialized experts while allowing seamless cross-expert collaboration. To enable HALO learning at scale, we introduce an automated pipeline to synthesize EM-CoT training data along with a carefully crafted training recipe. Extensive experiments demonstrate that: (1) HALO achieves superior performance in both simulated and real-world environments, surpassing baseline policy pi_0 by 34.1% on RoboTwin benchmark; (2) all proposed components of the training recipe and EM-CoT design help improve task success rate; and (3) HALO exhibits strong generalization capabilities under aggressive unseen environmental randomization with our proposed EM-CoT reasoning.","authors":["Quanxin Shou","Fangqi Zhu","Shawn Chen","Puxin Yan","Zhengyang Yan","Yikun Miao","Xiaoyi Pang","Zicong Hong","Ruikai Shi","Hao Huang","Jie Zhang","Song Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24235v1","updated":"2026-02-27T18:06:10Z","published":"2026-02-27T18:06:10Z","title":"SafeGen-LLM: Enhancing Safety Generalization in Task Planning for Robotic Systems","summary":"Safety-critical task planning in robotic systems remains challenging: classical planners suffer from poor scalability, Reinforcement Learning (RL)-based methods generalize poorly, and base Large Language Models (LLMs) cannot guarantee safety. To address this gap, we propose safety-generalizable large language models, named SafeGen-LLM. SafeGen-LLM can not only enhance the safety satisfaction of task plans but also generalize well to novel safety properties in various domains. We first construct a multi-domain Planning Domain Definition Language 3 (PDDL3) benchmark with explicit safety constraints. Then, we introduce a two-stage post-training framework: Supervised Fine-Tuning (SFT) on a constraint-compliant planning dataset to learn planning syntax and semantics, and Group Relative Policy Optimization (GRPO) guided by fine-grained reward machines derived from formal verification to enforce safety alignment and by curriculum learning to better handle complex tasks. Extensive experiments show that SafeGen-LLM achieves strong safety generalization and outperforms frontier proprietary baselines across multi-domain planning tasks and multiple input formats (e.g., PDDLs and natural language).","authors":["Jialiang Fan","Weizhe Xu","Mengyu Liu","Oleg Sokolsky","Insup Lee","Fangxin Kong"],"pdf_url":"","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2602.22118v2","updated":"2026-02-27T18:00:01Z","published":"2026-02-25T17:05:09Z","title":"System Design of the Ultra Mobility Vehicle: A Driving, Balancing, and Jumping Bicycle Robot","summary":"Trials cyclists and mountain bike riders can hop, jump, balance, and drive on one or both wheels. This versatility allows them to achieve speed and energy-efficiency on smooth terrain and agility over rough terrain. Inspired by these athletes, we present the design and control of a robotic platform, Ultra Mobility Vehicle (UMV), which combines a bicycle and a reaction mass to move dynamically with minimal actuated degrees of freedom. We employ a simulation-driven design optimization process to synthesize a spatial linkage topology with a focus on vertical jump height and momentum-based balancing on a single wheel contact. Using a constrained Reinforcement Learning (RL) framework, we demonstrate zero-shot transfer of diverse athletic behaviors, including track-stands, jumps, wheelies, rear wheel hopping, and front flips. This 23.5 kg robot is capable of high speeds (8 m/s) and jumping on and over large obstacles (1 m tall, or 130% of the robot's nominal height).","authors":["Benjamin Bokser","Daniel Gonzalez","Surya Singh","Aaron Preston","Alex Bahner","Annika Wollschläger","Arianna Ilvonen","Asa Eckert-Erdheim","Ashwin Khadke","Bilal Hammoud","Dean Molinaro","Fabian Jenelten","Henry Mayne","Howie Choset","Igor Bogoslavskyi","Itic Tinman","James Tigue","Jan Preisig","Kaiyu Zheng","Kenny Sharma","Kim Ang","Laura Lee","Liana Margolese","Nicole Lin","Oscar Frias","Paul Drews","Ravi Boggavarapu","Rick Burnham","Samuel Zapolsky","Sangbae Kim","Scott Biddlestone","Sean Mayorga","Shamel Fahmi","Tyler McCollum","Velin Dimitrov","William Moyne","Yu-Ming Chen","Farbod Farshidian","Marco Hutter","David Perry","Al Rizzi","Gabe Nelson"],"pdf_url":"","comment":"19 Pages, 11 figures, 3 movies, 2 tables"},{"id":"http://arxiv.org/abs/2505.00784v3","updated":"2026-02-27T17:41:14Z","published":"2025-05-01T18:28:09Z","title":"Agile legged locomotion in reconfigurable modular robots","summary":"Legged machines are becoming increasingly agile and adaptive but they have so far lacked the morphological diversity of legged animals, which have been rearranged and reshaped to fill millions of niches. Unlike their biological counterparts, legged machines have largely converged over the past decade to canonical quadrupedal and bipedal architectures that cannot be easily reconfigured to meet new tasks or recover from injury. Here we introduce autonomous modular legs: agile yet minimal, single-degree-of-freedom jointed links that can learn complex dynamic behaviors and may be freely attached to form multilegged machines at the meter scale. This enables rapid repair, redesign, and recombination of highly-dynamic modular agents that move quickly and acrobatically (non-quasistatically) through unstructured environments. Because each module is itself a complete agent, the bodies that contain them can sustain deep structural damage that would completely disable other legged robots. We also show how to encode the vast space of possible body configurations into a compact latent design space that can be efficiently explored, revealing a wide diversity of novel legged forms.","authors":["Chen Yu","David Matthews","Jingxian Wang","Jing Gu","Douglas Blackiston","Michael Rubenstein","Sam Kriegman"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.19408v2","updated":"2026-02-27T17:31:04Z","published":"2025-12-22T14:04:03Z","title":"Mixed formulation and structure-preserving discretization of Cosserat rod dynamics in a port-Hamiltonian framework","summary":"An energy-based modeling framework for the nonlinear dynamics of spatial Cosserat rods undergoing large displacements and rotations is proposed. The mixed formulation features independent displacement, velocity and stress variables and is further objective and locking-free. Finite rotations are represented using a director formulation that avoids singularities and yields a constant mass matrix. This results in an infinite-dimensional nonlinear port-Hamiltonian (PH) system governed by partial differential-algebraic equations with a quadratic energy functional. Using a time-differentiated compliance form of the stress-strain relations allows for the imposition of kinematic constraints, such as inextensibility or shear-rigidity. A structure-preserving finite element discretization leads to a finite-dimensional system with PH structure, thus facilitating the design of an energy-momentum consistent integration scheme. Dissipative material behavior (via the generalized-Maxwell model) and non-standard actuation approaches (via pneumatic chambers or tendons) integrate naturally into the framework. As illustrated by selected numerical examples, the present framework establishes a new approach to energy-momentum consistent formulations in computational mechanics involving finite rotations.","authors":["Philipp L. Kinon","Simon R. Eugster","Peter Betsch"],"pdf_url":"","comment":"39 pages, 16 figures"},{"id":"http://arxiv.org/abs/2602.24202v1","updated":"2026-02-27T17:28:42Z","published":"2026-02-27T17:28:42Z","title":"Evaluating Accuracy of Vine Robot Shape Sensing with Distributed Inertial Measurement Units","summary":"Soft, tip-extending vine robots are well suited for navigating tight, debris-filled environments, making them ideal for urban search and rescue. Sensing the full shape of a vine robot's body is helpful both for localizing information from other sensors placed along the robot body and for determining the robot's configuration within the space being explored. Prior approaches have localized vine robot tips using a single inertial measurement unit (IMU) combined with force sensing or length estimation, while one method demonstrated full-body shape sensing using distributed IMUs on a passively steered robot in controlled maze environments. However, the accuracy of distributed IMU-based shape sensing under active steering, varying robot lengths, and different sensor spacings has not been systematically quantified. In this work, we experimentally evaluate the accuracy of vine robot shape sensing using distributed IMUs along the robot body. We quantify IMU drift, measuring an average orientation drift rate of 1.33 degrees/min across 15 sensors. For passive steering, mean tip position error was 11% of robot length. For active steering, mean tip position error increased to 16%. During growth experiments across lengths from 30-175 cm, mean tip error was 8%, with a positive trend with increasing length. We also analyze the influence of sensor spacing and observe that intermediate spacings can minimize error for single-curvature shapes. These results demonstrate the feasibility of distributed IMU-based shape sensing for vine robots while highlighting key limitations and opportunities for improved modeling and algorithmic integration for field deployment.","authors":["Alexis E. Laudenslager","Antonio Alvarez Valdivia","Nathaniel Hanson","Margaret McGuinness"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24192v1","updated":"2026-02-27T17:15:50Z","published":"2026-02-27T17:15:50Z","title":"How IMU Drift Influences Multi-Radar Inertial Odometry for Ground Robots in Subterranean Terrains","summary":"Reliable radar inertial odometry (RIO) requires mitigating IMU bias drift, a challenge that intensifies in subterranean environments due to extreme temperatures and gravity-induced accelerations. Cost-effective IMUs such as the Pixhawk, when paired with FMCW TI IWR6843AOP EVM radars, suffer from drift-induced degradation compounded by sparse, noisy, and flickering radar returns, making fusion less stable than LiDAR-based odometry. Yet, LiDAR fails under smoke, dust, and aerosols, whereas FMCW radars remain compact, lightweight, cost-effective, and robust in these situations. To address these challenges, we propose a two-stage MRIO framework that combines an IMU bias estimator for resilient localization and mapping in GPS-denied subterranean environments affected by smoke. Radar-based ego-velocity estimation is formulated through a least-squares approach and incorporated into an EKF for online IMU bias correction; the corrected IMU accelerations are fused with heterogeneous measurements from multiple radars and an IMU to refine odometry. The proposed framework further supports radar-only mapping by exploiting the robot's estimated translational and rotational displacements. In subterranean field trials, MRIO delivers robust localization and mapping, outperforming EKF-RIO. It maintains accuracy across cost-efficient FMCW radar setups and different IMUs, showing resilience with Pixhawk and higher-grade units such as VectorNav. The implementation will be provided as an open-source resource to the community (code available at https://github.com/LTU-RAI/MRIO","authors":["Moumita Mukherjee","Magnus Norén","Anton Koval","Avijit Banerjee","George Nikolakopoulos"],"pdf_url":"","comment":"Accepted in IEEE International Conference on Robotics and Automation (ICRA), 2026"},{"id":"http://arxiv.org/abs/2602.24156v1","updated":"2026-02-27T16:37:33Z","published":"2026-02-27T16:37:33Z","title":"Humanoid Robots as First Assistants in Endoscopic Surgery","summary":"Humanoid robots have become a focal point of technological ambition, with claims of surgical capability within years in mainstream discourse. These projections are aspirational yet lack empirical grounding. To date, no humanoid has assisted a surgeon through an actual procedure, let alone performed one. The work described here breaks this new ground. Here we report a proof of concept in which a teleoperated Unitree G1 provided endoscopic visualization while an attending otolaryngologist performed a cadaveric sphenoidectomy. The procedure was completed successfully, with stable visualization maintained throughout. Teleoperation allowed assessment of whether the humanoid form factor could meet the physical demands of surgical assistance in terms of sustenance and precision; the cognitive demands were satisfied -- for now -- by the operator. Post-procedure analysis identified engineering targets for clinical translation, alongside near-term opportunities such as autonomous diagnostic scoping. This work establishes form-factor feasibility for humanoid surgical assistance while identifying challenges for continued development.","authors":["Sue Min Cho","Jan Emily Mangulabnan","Han Zhang","Zhekai Mao","Yufan He","Pengfei Guo","Daguang Xu","Gregory Hager","Masaru Ishii","Mathias Unberath"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24143v1","updated":"2026-02-27T16:20:04Z","published":"2026-02-27T16:20:04Z","title":"Robust Skills, Brittle Grounding: Diagnosing Restricted Generalization in Vision-Language Action Policies via Multi-Object Picking","summary":"Vision-language action (VLA) policies often report strong manipulation benchmark performance with relatively few demonstrations, but it remains unclear whether this reflects robust language-to-object grounding or reliance on object--location correlations that do not transfer beyond the training distribution. We present a controlled multi-object picking study that progressively increases object placement variability up to full workspace randomization and evaluates held-out object--location pairings that break familiar associations without increasing spatial difficulty. Across these stress tests and data scaling, we find that for representative VLA policies, including SmolVLA and $π_{0.5}$, execution of the manipulation primitive remains substantially more reliable than instruction-conditioned task success in harder regimes, suggesting that manipulation skill acquisition is decoupled from instruction following. We recommend augmenting manipulation benchmarks with task ladders and decomposed metrics that separately measure primitive execution and instruction-conditioned success to better diagnose instruction-grounded generalization.","authors":["David Emukpere","Romain Deffayet","Jean-Michel Renders"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2505.06182v4","updated":"2026-02-27T16:18:13Z","published":"2025-05-09T16:49:26Z","title":"Apple: Toward General Active Perception via Reinforcement Learning","summary":"Active perception is a fundamental skill that enables us humans to deal with uncertainty in our inherently partially observable environment. For senses such as touch, where the information is sparse and local, active perception becomes crucial. In recent years, active perception has emerged as an important research domain in robotics. However, current methods are often bound to specific tasks or make strong assumptions, which limit their generality. To address this gap, this work introduces APPLE (Active Perception Policy Learning) - a novel framework that leverages reinforcement learning (RL) to address a range of different active perception problems. APPLE jointly trains a transformer-based perception module and decision-making policy with a unified optimization objective, learning how to actively gather information. By design, APPLE is not limited to a specific task and can, in principle, be applied to a wide range of active perception problems. We evaluate two variants of APPLE across different tasks, including tactile exploration problems from the Tactile MNIST benchmark. Experiments demonstrate the efficacy of APPLE, achieving high accuracies on both regression and classification tasks. These findings underscore the potential of APPLE as a versatile and general framework for advancing active perception in robotics.\n  Project page: https://timschneider42.github.io/apple","authors":["Tim Schneider","Cristiana de Farias","Roberto Calandra","Liming Chen","Jan Peters"],"pdf_url":"","comment":"27 pages; 21 figures; accepted at the Fourteenth International Conference on Learning Representations (ICLR 2026)"},{"id":"http://arxiv.org/abs/2602.24121v1","updated":"2026-02-27T15:58:11Z","published":"2026-02-27T15:58:11Z","title":"Planning from Observation and Interaction","summary":"Observational learning requires an agent to learn to perform a task by referencing only observations of the performed task. This work investigates the equivalent setting in real-world robot learning where access to hand-designed rewards and demonstrator actions are not assumed. To address this data-constrained setting, this work presents a planning-based Inverse Reinforcement Learning (IRL) algorithm for world modeling from observation and interaction alone. Experiments conducted entirely in the real-world demonstrate that this paradigm is effective for learning image-based manipulation tasks from scratch in under an hour, without assuming prior knowledge, pre-training, or data of any kind beyond task observations. Moreover, this work demonstrates that the learned world model representation is capable of online transfer learning in the real-world from scratch. In comparison to existing approaches, including IRL, RL, and Behavior Cloning (BC), which have more restrictive assumptions, the proposed approach demonstrates significantly greater sample efficiency and success rates, enabling a practical path forward for online world modeling and planning from observation and interaction. Videos and more at: https://uwrobotlearning.github.io/mpail2/.","authors":["Tyler Han","Siyang Shen","Rohan Baijal","Harine Ravichandiran","Bat Nemekhbold","Kevin Huang","Sanghun Jung","Byron Boots"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24104v1","updated":"2026-02-27T15:43:22Z","published":"2026-02-27T15:43:22Z","title":"Geometry-based pneumatic actuators for soft robotics","summary":"Soft pneumatic actuators enable safe human-machine interaction with lightweight and powerful applied parts. On the other side, they suffer design limitations as regards complex actuation patterns, including minimum bending radii, multi-states capabilities and structural stability. We present geometry-based pneumatic actuators (GPAs), a design and implementation approach that introduces constraint layers with configurable CNC heat-sealed chambers. The approach achieves predictable deformation, near-zero bending radii, multi-states actuation, and enables customizable and repeatable complex actuated geometries. Mathematical modeling reveals predictable linear angle transformations and validates nonlinear torque-angle relationships across diverse configurations. We demonstrate versatility of the GPAs approach through three applications: a 49 g wrist exoskeleton reducing muscle activity by up to 51%, a 30.8 g haptic interface delivering 8 N force feedback with fast response, and a 208 g bipedal robot achieving multi-gait locomotion. GPAs establish a configurable platform for next-generation wearable robotics, haptic systems, and soft locomotion devices.","authors":["Rui Chen","Daniele Leonardis","Domenico Chiaradia","Antonio Frisoli"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.13109v2","updated":"2026-02-27T15:15:23Z","published":"2025-09-16T14:09:43Z","title":"Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation","summary":"This paper introduces a learning-based control framework for a soft robotic actuator system designed to modulate intracranial pressure (ICP) waveforms, which is essential for studying cerebrospinal fluid dynamics and pathological processes underlying neurological disorders. A two-layer framework is proposed to safely achieve a desired ICP waveform modulation. First, a model predictive controller (MPC) with a disturbance observer is used for offset-free tracking of the system's motor position reference trajectory under safety constraints. Second, to address the unknown nonlinear dependence of ICP on the motor position, we employ a Bayesian optimization (BO) algorithm used for online learning of a motor position reference trajectory that yields the desired ICP modulation. The framework is experimentally validated using a test bench with a brain phantom that replicates realistic ICP dynamics in vitro. Compared to a previously employed proportional-integral-derivative controller, the MPC reduces mean and maximum motor position reference tracking errors by 83 % and 73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor position reference trajectory that yields an ICP waveform with the desired mean and amplitude.","authors":["Fabian Flürenbrock","Yanick Büchel","Johannes Köhler","Marianne Schmid Daners","Melanie N. Zeilinger"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.22006v2","updated":"2026-02-27T15:09:53Z","published":"2026-02-25T15:23:18Z","title":"Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines","summary":"Accurate relative localization is critical for multi-robot cooperation. In robot swarms, measurements from different robots arrive asynchronously and with clock time-offsets. Although Continuous-Time (CT) formulations have proved effective for handling asynchronous measurements in single-robot SLAM and calibration, extending CT methods to multi-robot settings faces great challenges to achieve high-accuracy, low-latency, and high-frequency performance. Especially, existing CT methods suffer from the inherent query-time delay of unclamped B-splines and high computational cost. This paper proposes CT-RIO, a novel Continuous-Time Relative-Inertial Odometry framework. We employ Clamped Non-Uniform B-splines (C-NUBS) to represent robot states for the first time, eliminating the query-time delay. We further augment C-NUBS with closed-form extension and shrinkage operations that preserve the spline shape, making it suitable for online estimation and enabling flexible knot management. This flexibility leads to the concept of knot-keyknot strategy, which supports spline extension at high-frequency while retaining sparse keyknots for adaptive relative-motion modeling. We then formulate a sliding-window relative localization problem that operates purely on relative kinematics and inter-robot constraints. To meet the demanding computation required at swarm scale, we decompose the tightly-coupled optimization into robot-wise sub-problems and solve them in parallel using incremental asynchronous block coordinate descent. Extensive experiments show that CT-RIO converges from time-offsets as large as 263 ms to sub-millisecond within 3 s, and achieves RMSEs of 0.046 m and 1.8 °. It consistently outperforms state-of-the-art methods, with improvements of up to 60% under high-speed motion.","authors":["Jiadong Lu","Zhehan Li","Tao Han","Miao Xu","Chao Xu","Yanjun Cao"],"pdf_url":"","comment":"26 pages, 23 figures, submitted to IEEE Transactions on Robotics"},{"id":"http://arxiv.org/abs/2511.10762v2","updated":"2026-02-27T14:57:02Z","published":"2025-11-13T19:31:05Z","title":"Attentive Feature Aggregation or: How Policies Learn to Stop Worrying about Robustness and Attend to Task-Relevant Visual Cues","summary":"The adoption of pre-trained visual representations (PVRs), leveraging features from large-scale vision models, has become a popular paradigm for training visuomotor policies. However, these powerful representations can encode a broad range of task-irrelevant scene information, making the resulting trained policies vulnerable to out-of-domain visual changes and distractors. In this work we address visuomotor policy feature pooling as a solution to the observed lack of robustness in perturbed scenes. We achieve this via Attentive Feature Aggregation (AFA), a lightweight, trainable pooling mechanism that learns to naturally attend to task-relevant visual cues, ignoring even semantically rich scene distractors. Through extensive experiments in both simulation and the real world, we demonstrate that policies trained with AFA significantly outperform standard pooling approaches in the presence of visual perturbations, without requiring expensive dataset augmentation or fine-tuning of the PVR. Our findings show that ignoring extraneous visual information is a crucial step towards deploying robust and generalisable visuomotor policies. Project Page: tsagkas.github.io/afa","authors":["Nikolaos Tsagkas","Andreas Sochopoulos","Duolikun Danier","Sethu Vijayakumar","Alexandros Kouris","Oisin Mac Aodha","Chris Xiaoxuan Lu"],"pdf_url":"","comment":"This paper stems from a split of our earlier work \"When Pre-trained Visual Representations Fall Short: Limitations in Visuo-Motor Robot Learning.\" While \"The Temporal Trap\" replaces the original and focuses on temporal entanglement, this companion study examines policy robustness and task-relevant visual cue selection. arXiv admin note: text overlap with arXiv:2502.03270"},{"id":"http://arxiv.org/abs/2504.18840v3","updated":"2026-02-27T14:50:47Z","published":"2025-04-26T07:56:52Z","title":"Distributed Lloyd-Based algorithm for uncertainty-aware multi-robot under-canopy flocking","summary":"In this letter, we present a distributed algorithm for flocking in complex\n  environments that operates at constant altitude, without explicit\n  communication, no a priori information about the environment, and by using\n  only on-board sensing and computation capabilities. We provide sufficient\n  conditions to guarantee collision avoidance with obstacles and other robots\n  without exceeding a desired maximum distance from a predefined set of\n  neighbors (flocking or proximity maintenance constraint) during the mission.\n  The proposed approach allows to operate in crowded scenarios and to explicitly\n  deal with tracking errors and on-board sensing errors. The algorithm was\n  verified through simulations with varying number of UAVs and also through\n  numerous real-world experiments in a dense forest involving up to four UAVs.","authors":["Manuel Boldrer","Vit Kratky","Viktor Walter","Martin Saska"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.13358v2","updated":"2026-02-27T14:49:13Z","published":"2025-10-15T09:45:24Z","title":"Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control","summary":"Offline reinforcement learning enables sample-efficient policy acquisition without risky online interaction, yet policies trained on static datasets remain brittle under action-space perturbations such as actuator faults. This study introduces an offline-to-online framework that trains policies on clean data and then performs adversarial fine-tuning, where perturbations are injected into executed actions to induce compensatory behavior and improve resilience. A performance-aware curriculum further adjusts the perturbation probability during training via an exponential-moving-average signal, balancing robustness and stability throughout the learning process. Experiments on continuous-control locomotion tasks demonstrate that the proposed method consistently improves robustness over offline-only baselines and converges faster than training from scratch. Matching the fine-tuning and evaluation conditions yields the strongest robustness to action-space perturbations, while the adaptive curriculum strategy mitigates the degradation of nominal performance observed with the linear curriculum strategy. Overall, the results show that adversarial fine-tuning enables adaptive and robust control under uncertain environments, bridging the gap between offline efficiency and online adaptability.","authors":["Shingo Ayabe","Hiroshi Kera","Kazuhiko Kawamoto"],"pdf_url":"","comment":"15 main pages, 8 supplementary material pages"},{"id":"http://arxiv.org/abs/2602.23204v2","updated":"2026-02-27T14:24:26Z","published":"2026-02-26T16:53:36Z","title":"Motion-aware Event Suppression for Event Cameras","summary":"In this work, we introduce the first framework for Motion-aware Event Suppression, which learns to filter events triggered by IMOs and ego-motion in real time. Our model jointly segments IMOs in the current event stream while predicting their future motion, enabling anticipatory suppression of dynamic events before they occur. Our lightweight architecture achieves 173 Hz inference on consumer-grade GPUs with less than 1 GB of memory usage, outperforming previous state-of-the-art methods on the challenging EVIMO benchmark by 67\\% in segmentation accuracy while operating at a 53\\% higher inference rate. Moreover, we demonstrate significant benefits for downstream applications: our method accelerates Vision Transformer inference by 83\\% via token pruning and improves event-based visual odometry accuracy, reducing Absolute Trajectory Error (ATE) by 13\\%.","authors":["Roberto Pellerito","Nico Messikommer","Giovanni Cioffi","Marco Cannici","Davide Scaramuzza"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24030v1","updated":"2026-02-27T13:56:59Z","published":"2026-02-27T13:56:59Z","title":"Curriculum Reinforcement Learning for Quadrotor Racing with Random Obstacles","summary":"Autonomous drone racing has attracted increasing interest as a research topic for exploring the limits of agile flight. However, existing studies primarily focus on obstacle-free racetracks, while the perception and dynamic challenges introduced by obstacles remain underexplored, often resulting in low success rates and limited robustness in real-world flight. To this end, we propose a novel vision-based curriculum reinforcement learning framework for training a robust controller capable of addressing unseen obstacles in drone racing. We combine multi-stage cu rriculum learning, domain randomization, and a multi-scene updating strategy to address the conflicting challenges of obstacle avoidance and gate traversal. Our end-to-end control policy is implemented as a single network, allowing high-speed flight of quadrotors in environments with variable obstacles. Both hardware-in-the-loop and real-world experiments demonstrate that our method achieves faster lap times and higher success rates than existing approaches, effectively advancing drone racing in obstacle-rich environments. The video and code are available at: https://github.com/SJTU-ViSYS-team/CRL-Drone-Racing.","authors":["Fangyu Sun","Fanxing Li","Yu Hu","Linzuo Zhang","Yueqian Liu","Wenxian Yu","Danping Zou"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.24011v1","updated":"2026-02-27T13:34:58Z","published":"2026-02-27T13:34:58Z","title":"Autonomous Inspection of Power Line Insulators with UAV on an Unmapped Transmission Tower","summary":"This paper introduces an online inspection algorithm that enables an autonomous UAV to fly around a transmission tower and obtain detailed inspection images without a prior map of the tower. Our algorithm relies on camera-LiDAR sensor fusion for online detection and localization of insulators. In particular, the algorithm is based on insulator detection using a convolutional neural network, projection of LiDAR points onto the image, and filtering them using the bounding boxes. The detection pipeline is coupled with several proposed insulator localization methods based on DBSCAN, RANSAC, and PCA algorithms. The performance of the proposed online inspection algorithm and camera-LiDAR sensor fusion pipeline is demonstrated through simulation and real-world flights. In simulation, we showed that our single-flight inspection strategy can save up to 24 % of total inspection time, compared to the two-flight strategy of scanning the tower and afterwards visiting the inspection waypoints in the optimal way. In a real-world experiment, the best performing proposed method achieves a mean horizontal and vertical localization error for the insulator of 0.16 +- 0.08 m and 0.16 +- 0.11 m, respectively. Compared to the most relevant approach, the proposed method achieves more than an order of magnitude lower variance in horizontal insulator localization error.","authors":["Václav Riss","Vít Krátký","Robert Pěnička","Martin Saska"],"pdf_url":"","comment":"8 pages, 9 figues"},{"id":"http://arxiv.org/abs/2508.11143v2","updated":"2026-02-27T12:54:57Z","published":"2025-08-15T01:27:15Z","title":"Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward","summary":"Existing reinforcement learning (RL) methods struggle with long-horizon robotic manipulation tasks, particularly those involving sparse rewards. While action chunking is a promising paradigm for robotic manipulation, using RL to directly learn continuous action chunks in a stable and data-efficient manner remains a critical challenge. This paper introduces AC3 (Actor-Critic for Continuous Chunks), a novel RL framework that learns to generate high-dimensional, continuous action sequences. To make this learning process stable and data-efficient, AC3 incorporates targeted stabilization mechanisms for both the actor and the critic. First, to ensure reliable policy improvement, the actor is trained with an asymmetric update rule, learning exclusively from successful trajectories. Second, to enable effective value learning despite sparse rewards, the critic's update is stabilized using intra-chunk $n$-step returns and further enriched by a self-supervised module providing intrinsic rewards at anchor points aligned with each action chunk. We conducted extensive experiments on 25 tasks from the BiGym and RLBench benchmarks. Results show that by using only a few demonstrations and a simple model architecture, AC3 achieves superior success rates on most tasks, validating its effective design.","authors":["Jiarui Yang","Bin Zhu","Jingjing Chen","Yu-Gang Jiang"],"pdf_url":"","comment":"14 pages, 13 figures, Accepted by AAAI 2026 (oral)"},{"id":"http://arxiv.org/abs/2602.23972v1","updated":"2026-02-27T12:29:56Z","published":"2026-02-27T12:29:56Z","title":"Learning Robust Control Policies for Inverted Pose on Miniature Blimp Robots","summary":"The ability to achieve and maintain inverted poses is essential for unlocking the full agility of miniature blimp robots (MBRs). However, developing reliable control methods for MBRs remains challenging due to their complex and underactuated dynamics. To address this challenge, we propose a novel framework that enables robust control policy learning for inverted pose on MBRs. The proposed framework operates through three core stages: First, a high-fidelity three-dimensional (3D) simulation environment was constructed, which was calibrated against real-world MBR motion data to ensure accurate replication of inverted-state dynamics. Second, a robust policy for MBR inverted control was trained within the simulation environment via a domain randomization strategy and a modified Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. Third, a mapping layer was designed to bridge the sim-to-real gap for the learned policy deployment. Comprehensive evaluations in the simulation environment demonstrate that the learned policy achieves a higher success rate compared to the energy-shaping controller. Furthermore, experimental results confirm that the learned policy with a mapping layer enables an MBR to achieve and maintain a fully upside-down pose in real-world settings.","authors":["Yuanlin Yang","Lin Hong","Fumin Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.21135v2","updated":"2026-02-27T12:08:38Z","published":"2025-11-26T07:36:01Z","title":"SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation","summary":"Embodied navigation that adheres to social norms remains an open research challenge. Our SocialNav is a foundational model for socially-aware navigation with a hierarchical \"brain-action\" architecture, capable of understanding high-level social norms and generating low-level, socially compliant trajectories. To enable such dual capabilities, we construct the SocNav Dataset, a large-scale collection of 7 million samples, comprising (1) a Cognitive Activation Dataset providing social reasoning signals such as chain-of-thought explanations and social traversability prediction, and (2) an Expert Trajectories Pyramid aggregating diverse navigation demonstrations from internet videos, simulated environments, and real-world robots. A multi-stage training pipeline is proposed to gradually inject and refine navigation intelligence: we first inject general navigation skills and social norms understanding into the model via imitation learning, and then refine such skills through a deliberately designed Socially-Aware Flow Exploration GRPO (SAFE-GRPO), the first flow-based reinforcement learning framework for embodied navigation that explicitly rewards socially compliant behaviors. SocialNav achieves +38% success rate and +46% social compliance rate compared to the state-of-the-art method, demonstrating strong gains in both navigation performance and social compliance. Our project page: https://amap-eai.github.io/SocialNav/","authors":["Ziyi Chen","Yingnan Guo","Zedong Chu","Minghua Luo","Yanfen Shen","Mingchao Sun","Junjun Hu","Shichao Xie","Kuan Yang","Pei Shi","Zhining Gu","Lu Liu","Honglin Han","Xiaolong Wu","Mu Xu","Yu Zhang","Ning Guo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.21644v2","updated":"2026-02-27T11:48:00Z","published":"2026-02-25T07:14:07Z","title":"DAGS-SLAM: Dynamic-Aware 3DGS SLAM via Spatiotemporal Motion Probability and Uncertainty-Aware Scheduling","summary":"Mobile robots and IoT devices demand real-time localization and dense reconstruction under tight compute and energy budgets. While 3D Gaussian Splatting (3DGS) enables efficient dense SLAM, dynamic objects and occlusions still degrade tracking and mapping. Existing dynamic 3DGS-SLAM often relies on heavy optical flow and per-frame segmentation, which is costly for mobile deployment and brittle under challenging illumination. We present DAGS-SLAM, a dynamic-aware 3DGS-SLAM system that maintains a spatiotemporal motion probability (MP) state per Gaussian and triggers semantics on demand via an uncertainty-aware scheduler. DAGS-SLAM fuses lightweight YOLO instance priors with geometric cues to estimate and temporally update MP, propagates MP to the front-end for dynamic-aware correspondence selection, and suppresses dynamic artifacts in the back-end via MP-guided optimization. Experiments on public dynamic RGB-D benchmarks show improved reconstruction and robust tracking while sustaining real-time throughput on a commodity GPU, demonstrating a practical speed-accuracy tradeoff with reduced semantic invocations toward mobile deployment.","authors":["Li Zhang","Yu-An Liu","Xijia Jiang","Conghao Huang","Danyang Li","Yanyong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23937v1","updated":"2026-02-27T11:38:06Z","published":"2026-02-27T11:38:06Z","title":"Enhancing Vision-Language Navigation with Multimodal Event Knowledge from Real-World Indoor Tour Videos","summary":"Vision-Language Navigation (VLN) agents often struggle with long-horizon reasoning in unseen environments, particularly when facing ambiguous, coarse-grained instructions. While recent advances use knowledge graph to enhance reasoning, the potential of multimodal event knowledge inspired by human episodic memory remains underexplored. In this work, we propose an event-centric knowledge enhancement strategy for automated process knowledge mining and feature fusion to solve coarse-grained instruction and long-horizon reasoning in VLN task. First, we construct YE-KG, the first large-scale multimodal spatiotemporal knowledge graph, with over 86k nodes and 83k edges, derived from real-world indoor videos. By leveraging multimodal large language models (i.e., LLaVa, GPT4), we extract unstructured video streams into structured semantic-action-effect events to serve as explicit episodic memory. Second, we introduce STE-VLN, which integrates the above graph into VLN models via a Coarse-to-Fine Hierarchical Retrieval mechanism. This allows agents to retrieve causal event sequences and dynamically fuse them with egocentric visual observations. Experiments on REVERIE, R2R, and R2R-CE benchmarks demonstrate the efficiency of our event-centric strategy, outperforming state-of-the-art approaches across diverse action spaces. Our data and code are available on the project website https://sites.google.com/view/y-event-kg/.","authors":["Haoxuan Xu","Tianfu Li","Wenbo Chen","Yi Liu","Xingxing Zuo","Yaoxian Song","Haoang Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23934v1","updated":"2026-02-27T11:31:49Z","published":"2026-02-27T11:31:49Z","title":"Learning to Build: Autonomous Robotic Assembly of Stable Structures Without Predefined Plans","summary":"This paper presents a novel autonomous robotic assembly framework for constructing stable structures without relying on predefined architectural blueprints. Instead of following fixed plans, construction tasks are defined through targets and obstacles, allowing the system to adapt more flexibly to environmental uncertainty and variations during the building process. A reinforcement learning (RL) policy, trained using deep Q-learning with successor features, serves as the decision-making component. As a proof of concept, we evaluate the approach on a benchmark of 15 2D robotic assembly tasks of discrete block construction. Experiments using a real-world closed-loop robotic setup demonstrate the feasibility of the method and its ability to handle construction noise. The results suggest that our framework offers a promising direction for more adaptable and robust robotic construction in real-world environments.","authors":["Jingwen Wang","Johannes Kirschner","Paul Rolland","Luis Salamanca","Stefana Parascho"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23923v1","updated":"2026-02-27T11:18:35Z","published":"2026-02-27T11:18:35Z","title":"Teleoperated Omni-directional Dual Arm Mobile Manipulation Robotic System with Shared Control for Retail Store","summary":"The swiftly expanding retail sector is increasingly adopting autonomous mobile robots empowered by artificial intelligence and machine learning algorithms to gain an edge in the competitive market. However, these autonomous robots encounter challenges in adapting to the dynamic nature of retail products, often struggling to operate autonomously in novel situations. In this study, we introduce an omni-directional dual-arm mobile robot specifically tailored for use in retail environments. Additionally, we propose a tele-operation method that enables shared control between the robot and a human operator. This approach utilizes a Virtual Reality (VR) motion capture system to capture the operator's commands, which are then transmitted to the robot located remotely in a retail setting. Furthermore, the robot is equipped with heterogeneous grippers on both manipulators, facilitating the handling of a wide range of items. We validate the efficacy of the proposed system through testing in a mockup of retail environment, demonstrating its ability to manipulate various commonly encountered retail items using both single and dual-arm coordinated manipulation techniques.","authors":["Rolif Lima","Somdeb Saha","Nijil George","Vismay Vakharia","Shubham Parab","Sahil Gaonkar","Vighnesh Vatsal","Kaushik Das"],"pdf_url":"","comment":"This work has been accepted for publication in the Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics (SMC 2024). $©$ IEEE. The final version is available via IEEE Xplore"},{"id":"http://arxiv.org/abs/2602.23901v1","updated":"2026-02-27T10:50:13Z","published":"2026-02-27T10:50:13Z","title":"ABPolicy: Asynchronous B-Spline Flow Policy for Real-Time and Smooth Robotic Manipulation","summary":"Robotic manipulation requires policies that are smooth and responsive to evolving observations. However, synchronous inference in the raw action space introduces several challenges, including intra-chunk jitter, inter-chunk discontinuities, and stop-and-go execution. These issues undermine a policy's smoothness and its responsiveness to environmental changes. We propose ABPolicy, an asynchronous flow-matching policy that operates in a B-spline control-point action space. First, the B-spline representation ensures intra-chunk smoothness. Second, we introduce bidirectional action prediction coupled with refitting optimization to enforce inter-chunk continuity. Finally, by leveraging asynchronous inference, ABPolicy delivers real-time, continuous updates. We evaluate ABPolicy across seven tasks encompassing both static settings and dynamic settings with moving objects. Empirical results indicate that ABPolicy reduces trajectory jerk, leading to smoother motion and improved performance. Project website: https://teee000.github.io/ABPolicy/.","authors":["Fan Yang","Peiguang Jing","Kaihua Qu","Ningyuan Zhao","Yuting Su"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23896v1","updated":"2026-02-27T10:46:41Z","published":"2026-02-27T10:46:41Z","title":"TSC: Topology-Conditioned Stackelberg Coordination for Multi-Agent Reinforcement Learning in Interactive Driving","summary":"Safe and efficient autonomous driving in dense traffic is fundamentally a decentralized multi-agent coordination problem, where interactions at conflict points such as merging and weaving must be resolved reliably under partial observability. With only local and incomplete cues, interaction patterns can change rapidly, often causing unstable behaviors such as oscillatory yielding or unsafe commitments. Existing multi-agent reinforcement learning (MARL) approaches either adopt synchronous decision-making, which exacerbate non-stationarity, or depend on centralized sequencing mechanisms that scale poorly as traffic density increases. To address these limitations, we propose Topology-conditioned Stackelberg Coordination (TSC), a learning framework for decentralized interactive driving under communication-free execution, which extracts a time-varying directed priority graph from braid-inspired weaving relations between trajectories, thereby defining local leader-follower dependencies without constructing a global order of play. Conditioned on this graph, TSC endogenously factorizes dense interactions into graph-local Stackelberg subgames and, under centralized training and decentralized execution (CTDE), learns a sequential coordination policy that anticipates leaders via action prediction and trains followers through action-conditioned value learning to approximate local best responses, improving training stability and safety in dense traffic. Experiments across four dense traffic scenarios show that TSC achieves superior performance over representative MARL baselines across key metrics, most notably reducing collisions while maintaining competitive traffic efficiency and control smoothness.","authors":["Xiaotong Zhang","Gang Xiong","Yuanjing Wang","Siyu Teng","Alois Knoll","Long Chen"],"pdf_url":"","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.23893v1","updated":"2026-02-27T10:41:49Z","published":"2026-02-27T10:41:49Z","title":"AoE: Always-on Egocentric Human Video Collection for Embodied AI","summary":"Embodied foundation models require large-scale, high-quality real-world interaction data for pre-training and scaling. However, existing data collection methods suffer from high infrastructure costs, complex hardware dependencies, and limited interaction scope, making scalable expansion challenging. In fact, humans themselves are ideal physically embodied agents. Therefore, obtaining egocentric real-world interaction data from globally distributed \"human agents\" offers advantages of low cost and sustainability. To this end, we propose the Always-on Egocentric (AoE) data collection system, which aims to simplify hardware dependencies by leveraging humans themselves and their smartphones, enabling low-cost, highly efficient, and scene-agnostic real-world interaction data collection to address the challenge of data scarcity. Specifically, we first employ an ergonomic neck-mounted smartphone holder to enable low-barrier, large-scale egocentric data collection through a cloud-edge collaborative architecture. Second, we develop a cross-platform mobile APP that leverages on-device compute for real-time processing, while the cloud hosts automated labeling and filtering pipelines that transform raw videos into high-quality training data. Finally, the AoE system supports distributed Ego video data collection by anyone, anytime, and anywhere. We evaluate AoE on data preprocessing quality and downstream tasks, demonstrating that high-quality egocentric data significantly boosts real-world generalization.","authors":["Bowen Yang","Zishuo Li","Yang Sun","Changtao Miao","Yifan Yang","Man Luo","Xiaotong Yan","Feng Jiang","Jinchuan Shi","Yankai Fu","Ning Chen","Junkai Zhao","Pengwei Wang","Guocai Yao","Shanghang Zhang","Hao Chen","Zhe Li","Kai Zhu"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.04883v2","updated":"2026-02-27T10:15:47Z","published":"2025-10-06T15:04:56Z","title":"CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery","summary":"This paper presents a novel approach for enabling robust robotic perception in dark environments using infrared (IR) stream. IR stream is less susceptible to noise than RGB in low-light conditions. However, it is dominated by active emitter patterns that hinder high-level tasks such as object detection, tracking and localisation. To address this, a Deep Multi-scale Aware Overcomplete (DeepMAO) inspired architecture is proposed that reconstructs clean IR images from emitter populated input, improving both image quality and downstream robotic performance. This approach outperforms existing enhancement techniques and enables reliable operation of vision driven robotic systems across illumination conditions from well-lit to extreme low-light scenes. The results outline the ability of this work to be able to mimic RGB styling from the scene and its applicability on robotics tasks that were trained on RGB images, opening the possibility of doing these tasks in extreme low-light without on-board lighting.","authors":["Nathan Shankar","Pawel Ladosz","Hujun Yin"],"pdf_url":"","comment":"8 pages, 6 figures, 2 tables"},{"id":"http://arxiv.org/abs/2602.23872v1","updated":"2026-02-27T10:15:15Z","published":"2026-02-27T10:15:15Z","title":"Altitude-Aware Visual Place Recognition in Top-Down View","summary":"To address the challenge of aerial visual place recognition (VPR) problem under significant altitude variations, this study proposes an altitude-adaptive VPR approach that integrates ground feature density analysis with image classification techniques. The proposed method estimates airborne platforms' relative altitude by analyzing the density of ground features in images, then applies relative altitude-based cropping to generate canonical query images, which are subsequently used in a classification-based VPR strategy for localization. Extensive experiments across diverse terrains and altitude conditions demonstrate that the proposed approach achieves high accuracy and robustness in both altitude estimation and VPR under significant altitude changes. Compared to conventional methods relying on barometric altimeters or Time-of-Flight (ToF) sensors, this solution requires no additional hardware and offers a plug-and-play solution for downstream applications, {making it suitable for small- and medium-sized airborne platforms operating in diverse environments, including rural and urban areas.} Under significant altitude variations, incorporating our relative altitude estimation module into the VPR retrieval pipeline boosts average R@1 and R@5 by 29.85\\% and 60.20\\%, respectively, compared with applying VPR retrieval alone. Furthermore, compared to traditional {Monocular Metric Depth Estimation (MMDE) methods}, the proposed method reduces the mean error by 202.1 m, yielding average additional improvements of 31.4\\% in R@1 and 44\\% in R@5. These results demonstrate that our method establishes a robust, vision-only framework for three-dimensional visual place recognition, offering a practical and scalable solution for accurate airborne platforms localization under large altitude variations and limited sensor availability.","authors":["Xingyu Shao","Mengfan He","Chunyu Li","Liangzheng Sun","Ziyang Meng"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23870v1","updated":"2026-02-27T10:11:59Z","published":"2026-02-27T10:11:59Z","title":"Hybrid Offline-Online Reinforcement Learning for Sensorless, High-Precision Force Regulation in Surgical Robotic Grasping","summary":"Precise grasp force regulation in tendon-driven surgical instruments is fundamentally limited by nonlinear coupling between motor dynamics, transmission compliance, friction, and distal mechanics. Existing solutions typically rely on distal force sensing or analytical compensation, increasing hardware complexity or degrading performance under dynamic motion. We present a sensorless control framework that combines physics-consistent modeling and hybrid reinforcement learning to achieve high-precision distal force regulation in a proximally actuated surgical end-effector. We develop a first-principles digital twin of the da Vinci Xi grasping mechanism that captures coupled electrical, transmission, and jaw dynamics within a unified differential-algebraic formulation. To safely learn control policies in this stiff and highly nonlinear system, we introduce a three-stage pipeline:(i)a receding-horizon CMA-ES oracle that generates dynamically feasible expert trajectories,(ii)fully offline policy learning via Implicit Q-Learning to ensure stable initialization without unsafe exploration, and (iii)online refinement using TD3 for adaptation to on-policy dynamics. The resulting policy directly maps proximal measurements to motor voltages and requires no distal sensing. In simulation, the controller maintains grasp force within 1% of the desired reference during multi-harmonic jaw motion. Hardware experiments demonstrate average force errors below 4% across diverse trajectories, validating sim-to-real transfer. The learned policy contains approximately 71k param and executes at kH rates, enabling real-time deployment. These results demonstrate that high-fidelity modeling combined with structured offline-online RL can recover precise distal force behavior without additional sensing, offering a scalable and mechanically compatible solution for surgical robotic manipulation.","authors":["Edoardo Fazzari","Omar Mohamed","Khalfan Hableel","Hamdan Alhadhrami","Cesare Stefanini"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2511.17649v2","updated":"2026-02-27T09:59:37Z","published":"2025-11-20T09:52:20Z","title":"SWITCH: Benchmarking Modeling and Handling of Tangible Interfaces in Long-horizon Embodied Scenarios","summary":"Autonomous agents operating in the real world must interact continuously with existing physical and semantic infrastructure, track delayed consequences, and verify outcomes over time. Everyday environments are rich in tangible control interfaces (TCIs)-e.g., light switches, appliance panels, and embedded GUI-posing core challenges for lifelong embodied agents, including partial observability, causal reasoning across time, and failure-aware verification under real-world constraints. Yet, current benchmarks rarely consider such long-horizon interaction and causality requirements. We introduce SWITCH (Semantic World Interface Tasks for Control & Handling), an embodied, task-driven benchmark created through iterative releases to probe these gaps. Its first iteration, SWITCH-Basic, evaluates five complementary abilities-task-aware VQA, semantic UI grounding, action generation, state transition prediction, and result verification-under ego-centric RGB video input and device diversity across 351 tasks spanning 98 real devices/appliances. Results from commercial and open LMMMs reveal systematic failures, highlighting critical gaps for lifelong agent deployment. SWITCH provides data, code, and held-out splits to enable reproducible non-contaminated evaluation and community contributions toward more challenging future iterations of the benchmark and the creation of relevant training data. Benchmark resources are available at: https://github.com/BAAI-Agents/SWITCH.","authors":["Jieru Lin","Zhiwei Yu","Börje F. Karlsson"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.24653v3","updated":"2026-02-27T09:38:52Z","published":"2025-12-31T05:59:40Z","title":"RoboMIND 2.0: A Multimodal, Bimanual Mobile Manipulation Dataset for Generalizable Embodied Intelligence","summary":"While data-driven imitation learning has revolutionized robotic manipulation, current approaches remain constrained by the scarcity of large-scale, diverse real-world demonstrations. Consequently, the ability of existing models to generalize across long-horizon bimanual tasks and mobile manipulation in unstructured environments remains limited. To bridge this gap, we present RoboMIND 2.0, a comprehensive real-world dataset comprising over 310K dual-arm manipulation trajectories collected across six distinct robot embodiments and 739 complex tasks. Crucially, to support research in contact-rich and spatially extended tasks, the dataset incorporates 12K tactile-enhanced episodes and 20K mobile manipulation trajectories. Complementing this physical data, we construct high-fidelity digital twins of our real-world environments, releasing an additional 20K-trajectory simulated dataset to facilitate robust sim-to-real transfer. To fully exploit the potential of RoboMIND 2.0, we propose MIND-2 system, a hierarchical dual-system frame-work optimized via offline reinforcement learning. MIND-2 integrates a high-level semantic planner (MIND-2-VLM) to decompose abstract natural language instructions into grounded subgoals, coupled with a low-level Vision-Language-Action executor (MIND-2-VLA), which generates precise, proprioception-aware motor actions.","authors":["Chengkai Hou","Kun Wu","Jiaming Liu","Zhengping Che","Di Wu","Fei Liao","Guangrun Li","Jingyang He","Qiuxuan Feng","Zhao Jin","Chenyang Gu","Zhuoyang Liu","Nuowei Han","Xiangju Mi","Yaoxu Lv","Yankai Fu","Gaole Dai","Langzhe Gu","Tao Li","Yuheng Zhang","Yixue Zhang","Xinhua Wang","Shichao Fan","Meng Li","Zhen Zhao","Ning Liu","Zhiyuan Xu","Pei Ren","Junjie Ji","Haonan Liu","Kuan Cheng","Shanghang Zhang","Jian Tang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23843v1","updated":"2026-02-27T09:28:06Z","published":"2026-02-27T09:28:06Z","title":"OmniXtreme: Breaking the Generality Barrier in High-Dynamic Humanoid Control","summary":"High-fidelity motion tracking serves as the ultimate litmus test for generalizable, human-level motor skills. However, current policies often hit a \"generality barrier\": as motion libraries scale in diversity, tracking fidelity inevitably collapses - especially for real-world deployment of high-dynamic motions. We identify this failure as the result of two compounding factors: the learning bottleneck in scaling multi-motion optimization and the physical executability constraints that arise in real-world actuation. To overcome these challenges, we introduce OmniXtreme, a scalable framework that decouples general motor skill learning from sim-to-real physical skill refinement. Our approach uses a flow-matching policy with high-capacity architectures to scale representation capacity without interference-intensive multi-motion RL optimization, followed by an actuation-aware refinement phase that ensures robust performance on physical hardware. Extensive experiments demonstrate that OmniXtreme maintains high-fidelity tracking across diverse, high-difficulty datasets. On real robots, the unified policy successfully executes multiple extreme motions, effectively breaking the long-standing fidelity-scalability trade-off in high-dynamic humanoid control.","authors":["Yunshen Wang","Shaohang Zhu","Peiyuan Zhi","Yuhan Li","Jiaxin Li","Yong-Lu Li","Yuchen Xiao","Xingxing Wang","Baoxiong Jia","Siyuan Huang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2312.09120v2","updated":"2026-02-27T09:17:36Z","published":"2023-12-14T16:54:37Z","title":"Less is more -- the Dispatcher/ Executor principle for multi-task Reinforcement Learning","summary":"Humans instinctively know how to neglect details when it comes to solve complex decision making problems in environments with unforeseeable variations. This abstraction process seems to be a vital property for most biological systems and helps to 'abstract away' unnecessary details and boost generalisation. In this work we introduce the dispatcher/ executor principle for the design of multi-task Reinforcement Learning controllers. It suggests to partition the controller in two entities, one that understands the task (the dispatcher) and one that computes the controls for the specific device (the executor) - and to connect these two by a strongly regularizing communication channel. The core rationale behind this position paper is that changes in structure and design principles can improve generalisation properties and drastically enforce data-efficiency. It is in some sense a 'yes, and ...' response to the current trend of using large neural networks trained on vast amounts of data and bet on emerging generalisation properties. While we agree on the power of scaling - in the sense of Sutton's 'bitter lesson' - we will give some evidence, that considering structure and adding design principles can be a valuable and critical component in particular when data is not abundant and infinite, but is a precious resource.","authors":["Martin Riedmiller","Andrea Gesmundo","Tim Hertweck","Roland Hafner"],"pdf_url":"","comment":"Videos showing the results can be found at https://sites.google.com/view/dispatcher-executor"},{"id":"http://arxiv.org/abs/2602.23832v1","updated":"2026-02-27T09:12:15Z","published":"2026-02-27T09:12:15Z","title":"OmniTrack: General Motion Tracking via Physics-Consistent Reference","summary":"Learning motion tracking from rich human motion data is a foundational task for achieving general control in humanoid robots, enabling them to perform diverse behaviors. However, discrepancies in morphology and dynamics between humans and robots, combined with data noise, introduce physically infeasible artifacts in reference motions, such as floating and penetration. During both training and execution, these artifacts create a conflict between following inaccurate reference motions and maintaining the robot's stability, hindering the development of a generalizable motion tracking policy. To address these challenges, we introduce OmniTrack, a general tracking framework that explicitly decouples physical feasibility from general motion tracking. In the first stage, a privileged generalist policy generates physically plausible motions that strictly adhere to the robot's dynamics via trajectory rollout in simulation. In the second stage, the general control policy is trained to track these physically feasible motions, ensuring stable and coherent control transfer to the real robot. Experiments show that OmniTrack improves tracking accuracy and demonstrates strong generalization to unseen motions. In real-world tests, OmniTrack achieves hour-long, consistent, and stable tracking, including complex acrobatic motions such as flips and cartwheels. Additionally, we show that OmniTrack supports human-style stable and dynamic online teleoperation, highlighting its robustness and adaptability to varying user inputs.","authors":["Yuhan Li","Peiyuan Zhi","Yunshen Wang","Tengyu Liu","Sixu Yan","Wenyu Liu","Xinggang Wang","Baoxiong Jia","Siyuan Huang"],"pdf_url":"","comment":"website: https://omnitrack-humanoid.github.io/"},{"id":"http://arxiv.org/abs/2602.23821v1","updated":"2026-02-27T09:03:47Z","published":"2026-02-27T09:03:47Z","title":"Acceleration-Based Control of Fixed-Wing UAVs for Guidance Applications","summary":"Acceleration-commanded guidance laws (e.g., proportional navigation) are attractive for high-level decision making, but their direct deployment on fixed-wing UAVs is challenging because accelerations are not directly actuated and must be realized through attitude and thrust under flight-envelope constraints. This paper presents an acceleration-level outer-loop control framework that converts commanded tangential and normal accelerations into executable body-rate and normalized thrust commands compatible with mainstream autopilots (e.g., PX4/APM). For the normal channel, we derive an engineering mapping from the desired normal acceleration to roll- and pitch-rate commands that regulate the direction and magnitude of the lift vector under small-angle assumptions. For the tangential channel, we introduce an energy-based formulation inspired by total energy control and identify an empirical thrust-energy acceleration relationship directly from flight data, avoiding explicit propulsion modeling or thrust bench calibration. We further discuss priority handling between normal and tangential accelerations under saturation and non-level maneuvers. Extensive real-flight experiments on a VTOL fixed-wing platform demonstrate accurate acceleration tracking and enable practical implementation of proportional navigation using only body-rate and normalized thrust interfaces.","authors":["Jixiang Wang","Siyuan Yang","Ziyi Wu","Siqi Wei","Ashay Wakode","Agata Barcis","Hung Nguyen","Shaoming He"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.00060v3","updated":"2026-02-27T09:00:30Z","published":"2025-09-29T05:14:18Z","title":"Less is More: Lean yet Powerful Vision-Language Model for Autonomous Driving","summary":"In this work, we reconceptualize autonomous driving as a generalized language problem and formulate the trajectory planning task as next waypoint prediction. We introduce Max-V1, a novel framework for one-stage end-to-end autonomous driving, named in tribute to the renowned Dutch racing driver Max Verstappen. Our framework presents a single-pass generation paradigm that aligns with the inherent sequentiality of driving. This approach leverages the generative capacity of the Vision-Language Model (VLM) to enable end-to-end trajectory prediction directly from front-view camera input. The efficacy of this method is underpinned by a principled supervision strategy derived from statistical modeling. This provides a well-defined learning objective, which makes the framework highly amenable to mastering complex driving policies through imitation learning from large-scale expert demonstrations. Empirically, our method achieves state-of-the-art performance on the nuScenes dataset, delivering an overall improvement of over 30% compared to prior baselines. Furthermore, it exhibits superior generalization performance on cross-domain datasets acquired from diverse vehicles, demonstrating notable potential for cross-vehicle robustness and adaptability. With these empirical strengths, this work introduces a model that enables fundamental driving behaviors, laying the foundation for the development of more capable self-driving agents. Code will be available upon publication.","authors":["Sheng Yang","Tong Zhan","Guancheng Chen","Yanfeng Lu","Jian Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2508.05535v2","updated":"2026-02-27T08:09:41Z","published":"2025-08-07T16:09:12Z","title":"Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation","summary":"Effective robotic systems for long-horizon human-robot collaboration must adapt to a wide range of human partners, whose physical behavior, willingness to assist, and understanding of the robot's capabilities may change over time. This demands a tightly coupled communication loop that grants both agents the flexibility to propose, accept, or decline requests as they coordinate toward completing the task effectively. We apply a Mixed-Initiative dialog paradigm to Collaborative human-roBot teaming and propose MICoBot, a system that handles the common scenario where both agents, using natural language, take initiative in formulating, accepting, or rejecting proposals on who can best complete different steps of a task. To handle diverse, task-directed dialog, and find successful collaborative strategies that minimize human effort, MICoBot makes decisions at three levels: (1) a meta-planner considers human dialog to formulate and code a high-level collaboration strategy, (2) a planner optimally allocates the remaining steps to either agent based on the robot's capabilities (measured by a simulation-pretrained affordance model) and the human's estimated availability to help, and (3) an action executor decides the low-level actions to perform or words to say to the human. In physical robot trials with 18 unique human participants, MICoBot significantly improves task success and user experience over a pure LLM baseline and standard agent allocation models. See additional videos and materials at https://robin-lab.cs.utexas.edu/MicoBot/.","authors":["Albert Yu","Chengshu Li","Luca Macesanu","Arnav Balaji","Ruchira Ray","Raymond Mooney","Roberto Martín-Martín"],"pdf_url":"","comment":"Project website at https://robin-lab.cs.utexas.edu/MicoBot/"},{"id":"http://arxiv.org/abs/2602.13267v2","updated":"2026-02-27T07:12:44Z","published":"2026-02-04T05:36:14Z","title":"Beyond Ground: Map-Free LiDAR Relocalization for UAVs","summary":"Localization is a fundamental capability in unmanned aerial vehicle (UAV) systems. Map-free LiDAR relocalization offers an effective solution for achieving high-precision positioning in environments with weak or unavailable GNSS signals. However, existing LiDAR relocalization methods are primarily tailored to autonomous driving, exhibiting significantly degraded accuracy in UAV scenarios. In this paper, we propose MAILS, a novel map-free LiDAR relocalization framework for UAVs. A Locality-Preserving Sliding Window Attention module is first introduced to extract locally discriminative geometric features from sparse point clouds. To handle substantial yaw rotations and altitude variations encountered during UAV flight, we then design a coordinate-independent feature initialization module and a locally invariant positional encoding mechanism, which together significantly enhance the robustness of feature extraction. Furthermore, existing LiDAR-based relocalization datasets fail to capture real-world UAV flight characteristics, such as irregular trajectories and varying altitudes. To address this gap, we construct a large-scale LiDAR localization dataset for UAVs, which comprises four scenes and various flight trajectories, designed to evaluate UAV relocalization performance under realistic conditions. Extensive experiments demonstrate that our method achieves satisfactory localization precision and consistently outperforms existing techniques by a significant margin. Our code and dataset will be released soon.","authors":["Hengyu Mu","Jianshi Wu","Yuxin Guo","XianLian Lin","Qingyong Hu","Sheng Ao","Chenglu Wen","Cheng Wang"],"pdf_url":"","comment":"18 pages, 16 figures"},{"id":"http://arxiv.org/abs/2602.23721v1","updated":"2026-02-27T06:43:37Z","published":"2026-02-27T06:43:37Z","title":"StemVLA:An Open-Source Vision-Language-Action Model with Future 3D Spatial Geometry Knowledge and 4D Historical Representation","summary":"Vision-language-action (VLA) models integrate visual observations and language instructions to predict robot actions, demonstrating promising generalization in manipulation tasks. However, most existing approaches primarily rely on direct mappings from 2D visual inputs to action sequences, without explicitly modeling the underlying 3D spatial structure or temporal world dynamics. Such representations may limit spatial reasoning and long-horizon decision-making in dynamic environments. To address this limitation, we propose StemVLA, a novel framework that explicitly incorporates both future-oriented 3D spatial knowledge and historical 4D spatiotemporal representations into action prediction. First, instead of relying solely on observed images, StemVLA forecasts structured 3D future spatial-geometric world knowledge, enabling the model to anticipate upcoming scene geometry and object configurations. Second, to capture temporal consistency and motion dynamics, we feed historical image frames into a pretrained video-geometry transformer backbone to extract implicit 3D world representations, and further aggregate them across time using a temporal attention module, termed VideoFormer [20], forming a unified 4D historical spatiotemporal representation. By jointly modeling 2D observations, predicted 3D future structure, and aggregated 4D temporal dynamics, StemVLA enables more comprehensive world understanding for robot manipulation. Extensive experiments in simulation demonstrate that StemVLA significantly improves long-horizon task success and achieves state-of-the-art performance on the CALVIN ABC-D benchmark [46], achieving an average sequence length of XXX.","authors":["Jiasong Xiao","Yutao She","Kai Li","Yuyang Sha","Ziang Cheng","Ziang Tong"],"pdf_url":"","comment":"Preprint"},{"id":"http://arxiv.org/abs/2602.23719v1","updated":"2026-02-27T06:41:04Z","published":"2026-02-27T06:41:04Z","title":"SAGE-LLM: Towards Safe and Generalizable LLM Controller with Fuzzy-CBF Verification and Graph-Structured Knowledge Retrieval for UAV Decision","summary":"In UAV dynamic decision, complex and variable hazardous factors pose severe challenges to the generalization capability of algorithms. Despite offering semantic understanding and scene generalization, Large Language Models (LLM) lack domain-specific UAV control knowledge and formal safety assurances, restricting their direct applicability. To bridge this gap, this paper proposes a train-free two-layer decision architecture based on LLMs, integrating high-level safety planning with low-level precise control. The framework introduces three key contributions: 1) A fuzzy Control Barrier Function verification mechanism for semantically-augmented actions, providing provable safety certification for LLM outputs. 2) A star-hierarchical graph-based retrieval-augmented generation system, enabling efficient, elastic, and interpretable scene adaptation. 3) Systematic experimental validation in pursuit-evasion scenarios with unknown obstacles and emergent threats, demonstrating that our SAGE-LLM maintains performance while significantly enhancing safety and generalization without online training. The proposed framework demonstrates strong extensibility, suggesting its potential for generalization to broader embodied intelligence systems and safety-critical control domains.","authors":["Wenzhe Zhao","Yang Zhao","Ganchao Liu","Zhiyu Jiang","Dandan Ma","Zihao Li","Xuelong Li"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.25249v2","updated":"2026-02-27T06:27:46Z","published":"2025-09-27T07:13:55Z","title":"BEV-VLM: Trajectory Planning via Unified BEV Abstraction","summary":"This paper introduces BEV-VLM, a novel approach for trajectory planning in autonomous driving that leverages Vision-Language Models (VLMs) with Bird's-Eye View (BEV) feature maps as visual input. Unlike conventional trajectory planning approaches that rely solely on raw visual data (e.g., camera images), our method utilizes a highly compressed and informative BEV representation generated by fusing camera and LiDAR data, with subsequent alignment to High-Definition (HD) maps. This unified BEV-HD map format provides a geometrically consistent and semantically rich scene description, which enables VLMs to perform accurate and robust trajectory planning. Experimental results on the nuScenes dataset demonstrate that, compared with state-of-the-art vision-only methods, our approach achieves a 53.1% improvement in planning accuracy and realizes complete collision avoidance in evaluation scenarios. Our work highlights that VLMs can effectively interpret processed visual representations such as BEV features, expanding their applicability beyond raw image inputs for the task of trajectory planning.","authors":["Guancheng Chen","Sheng Yang","Tong Zhan","Jian Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23706v1","updated":"2026-02-27T06:18:49Z","published":"2026-02-27T06:18:49Z","title":"A Reliable Indoor Navigation System for Humans Using AR-based Technique","summary":"Reliable navigation systems are not available indoors, such as in campuses and small areas. Users must depend on confusing, time-consuming static signage or floor maps. In this paper, an AR-based technique has been applied to campus and small-site navigation, where Vuforia Area Target is used for environment modeling. AI navigation's NavMesh component is used for navigation purposes, and the A* algorithm is used within this component for shortest path calculation. Compared to Dijkstra's algorithm, it can reach a solution about two to three times faster for smaller search spaces. In many cases, Dijkstra's algorithm has difficulty performing well in high-complexity environments where memory usage grows and processing times increase. Compared to older approaches such as GPS, real-time processing and AR overlays can be combined to provide intuitive directions for users while dynamically updating the path in response to environmental changes. Experimental results indicate significantly improved navigation accuracy, better user experience, and greater efficiency compared to traditional methods. These results show that AR technology integrated with existing pathfinding algorithms is feasible and scalable, making it a user-friendly solution for indoor navigation. Although highly effective in limited and defined indoor spaces, further optimization of NavMesh is required for large or highly dynamic environments.","authors":["Vijay U. Rathod","Manav S. Sharma","Shambhavi Verma","Aadi Joshi","Sachin Aage","Sujal Shahane"],"pdf_url":"","comment":"6 pages, 6 figures, 2 tables, Presented at 7th International Conference on Advances in Science and Technology (ICAST 2024-25)"},{"id":"http://arxiv.org/abs/2602.02960v2","updated":"2026-02-27T05:56:01Z","published":"2026-02-03T00:58:29Z","title":"Embodiment-Aware Generalist Specialist Distillation for Unified Humanoid Whole-Body Control","summary":"Humanoid Whole-Body Controllers trained with reinforcement learning (RL) have recently achieved remarkable performance, yet many target a single robot embodiment. Variations in dynamics, degrees of freedom (DoFs), and kinematic topology still hinder a single policy from commanding diverse humanoids. Moreover, obtaining a generalist policy that not only transfers across embodiments but also supports richer behaviors-beyond simple walking to squatting, leaning-remains especially challenging. In this work, we tackle these obstacles by introducing EAGLE, an iterative generalist-specialist distillation framework that produces a single unified policy that controls multiple heterogeneous humanoids without per-robot reward tuning. During each cycle, embodiment-specific specialists are forked from the current generalist, refined on their respective robots, and new skills are distilled back into the generalist by training on the pooled embodiment set. Repeating this loop until performance convergence produces a robust Whole-Body Controller validated on robots such as Unitree H1, G1, and Fourier N1. We conducted experiments on five different robots in simulation and four in real-world settings. Through quantitative evaluations, EAGLE achieves high tracking accuracy and robustness compared to other methods, marking a step toward scalable, fleet-level humanoid control. See more details at https://eagle-wbc.github.io/","authors":["Quanquan Peng","Yunfeng Lin","Yufei Xue","Jiangmiao Pang","Weinan Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23694v1","updated":"2026-02-27T05:52:04Z","published":"2026-02-27T05:52:04Z","title":"Interpretable Multimodal Gesture Recognition for Drone and Mobile Robot Teleoperation via Log-Likelihood Ratio Fusion","summary":"Human operators are still frequently exposed to hazardous environments such as disaster zones and industrial facilities, where intuitive and reliable teleoperation of mobile robots and Unmanned Aerial Vehicles (UAVs) is essential. In this context, hands-free teleoperation enhances operator mobility and situational awareness, thereby improving safety in hazardous environments. While vision-based gesture recognition has been explored as one method for hands-free teleoperation, its performance often deteriorates under occlusions, lighting variations, and cluttered backgrounds, limiting its applicability in real-world operations. To overcome these limitations, we propose a multimodal gesture recognition framework that integrates inertial data (accelerometer, gyroscope, and orientation) from Apple Watches on both wrists with capacitive sensing signals from custom gloves. We design a late fusion strategy based on the log-likelihood ratio (LLR), which not only enhances recognition performance but also provides interpretability by quantifying modality-specific contributions. To support this research, we introduce a new dataset of 20 distinct gestures inspired by aircraft marshalling signals, comprising synchronized RGB video, IMU, and capacitive sensor data. Experimental results demonstrate that our framework achieves performance comparable to a state-of-the-art vision-based baseline while significantly reducing computational cost, model size, and training time, making it well suited for real-time robot control. We therefore underscore the potential of sensor-based multimodal fusion as a robust and interpretable solution for gesture-driven mobile robot and drone teleoperation.","authors":["Seungyeol Baek","Jaspreet Singh","Lala Shakti Swarup Ray","Hymalai Bello","Paul Lukowicz","Sungho Suh"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2509.22271v2","updated":"2026-02-27T05:50:25Z","published":"2025-09-26T12:38:32Z","title":"Human Autonomy and Sense of Agency in Human-Robot Interaction: A Systematic Literature Review","summary":"Human autonomy and sense of agency are increasingly recognised as critical for user well-being, motivation, and the ethical deployment of robots in human-robot interaction (HRI). Given the rapid development of artificial intelligence, robot capabilities and their potential to function as colleagues and companions are growing. This systematic literature review synthesises 22 empirical studies selected from an initial pool of 728 articles published between 2011 and 2024. Articles were retrieved from major scientific databases and identified based on empirical focus and conceptual relevance, namely, how to preserve and promote human autonomy and sense of agency in HRI. Derived through thematic synthesis, five clusters of potentially influential factors are revealed: robot adaptiveness, communication style, anthropomorphism, presence of a robot and individual differences. Measured through psychometric scales or the intentional binding paradigm, perceptions of autonomy and agency varied across industrial, educational, healthcare, care, and hospitality settings. The review underscores the theoretical differences between both concepts, but their yet entangled use in HRI. Despite increasing interest, the current body of empirical evidence remains limited and fragmented, underscoring the necessity for standardised definitions, more robust operationalisations, and further exploratory and qualitative research. By identifying existing gaps and highlighting emerging trends, this review contributes to the development of human-centered, autonomy-supportive robot design strategies that uphold ethical and psychological principles, ultimately supporting well-being in human-robot interaction.","authors":["Felix Glawe","Tim Schmeckel","Philipp Brauner","Martina Ziefle"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2512.01047v2","updated":"2026-02-27T05:31:55Z","published":"2025-11-30T19:32:33Z","title":"Automating the Refinement of Reinforcement Learning Specifications","summary":"Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose AutoSpec, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. AutoSpec is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how AutoSpec can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that AutoSpec yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by AutoSpec are utilized.","authors":["Tanmay Ambadkar","Đorđe Žikelić","Abhinav Verma"],"pdf_url":"","comment":"Fourteenth International Conference on Learning Representations 2026 https://ambadkar.com/autospec"},{"id":"http://arxiv.org/abs/2206.04028v3","updated":"2026-02-27T05:28:19Z","published":"2022-06-08T17:37:58Z","title":"CO^3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving","summary":"Unsupervised contrastive learning for indoor-scene point clouds has achieved great successes. However, unsupervised learning point clouds in outdoor scenes remains challenging because previous methods need to reconstruct the whole scene and capture partial views for the contrastive objective. This is infeasible in outdoor scenes with moving objects, obstacles, and sensors. In this paper, we propose CO^3, namely Cooperative Contrastive Learning and Contextual Shape Prediction, to learn 3D representation for outdoor-scene point clouds in an unsupervised manner. CO^3 has several merits compared to existing methods. (1) It utilizes LiDAR point clouds from vehicle-side and infrastructure-side to build views that differ enough but meanwhile maintain common semantic information for contrastive learning, which are more appropriate than views built by previous methods. (2) Alongside the contrastive objective, shape context prediction is proposed as pre-training goal and brings more task-relevant information for unsupervised 3D point cloud representation learning, which are beneficial when transferring the learned representation to downstream detection tasks. (3) As compared to previous methods, representation learned by CO^3 is able to be transferred to different outdoor scene dataset collected by different type of LiDAR sensors. (4) CO^3 improves current state-of-the-art methods on both Once and KITTI datasets by up to 2.58 mAP. We believe CO^3 will facilitate understanding LiDAR point clouds in outdoor scene.","authors":["Runjian Chen","Yao Mu","Runsen Xu","Wenqi Shao","Chenhan Jiang","Hang Xu","Zhenguo Li","Ping Luo"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2510.10932v3","updated":"2026-02-27T05:13:30Z","published":"2025-10-13T02:45:48Z","title":"DropVLA: An Action-Level Backdoor Attack on Vision--Language--Action Models","summary":"Vision-Language-Action (VLA) models map multimodal perception and language instructions to executable robot actions, making them particularly vulnerable to behavioral backdoor manipulation: a hidden trigger introduced during training can induce unintended physical actions while nominal task performance remains intact. Prior work on VLA backdoors primarily studies untargeted attacks or task-level hijacking, leaving fine-grained control over individual actions largely unexplored. In this work, we present DropVLA, an action-level backdoor attack that forces a reusable action primitive (e.g., open_gripper) to execute at attacker-chosen decision points under a realistic pipeline-black-box setting with limited data-poisoning access, using a window-consistent relabeling scheme for chunked fine-tuning. On OpenVLA-7B evaluated with LIBERO, vision-only poisoning achieves 98.67%-99.83% attack success rate (ASR) with only 0.31% poisoned episodes while preserving 98.50%-99.17% clean-task retention, and successfully triggers the targeted action within 25 control steps at 500 Hz (0.05 s). Text-only triggers are unstable at low poisoning budgets, and combining text with vision provides no consistent ASR improvement over vision-only attacks. The backdoor remains robust to moderate trigger variations and transfers across evaluation suites (96.27%, 99.09%), whereas text-only largely fails (0.72%). We further validate physical-world feasibility on a 7-DoF Franka arm with pi0-fast, demonstrating non-trivial attack efficacy under camera-relative motion that induces image-plane trigger drift. These results reveal that VLA models can be covertly steered at the granularity of safety-critical actions with minimal poisoning and without observable degradation of nominal performance.","authors":["Zonghuan Xu","Xiang Zheng","Xingjun Ma","Yu-Gang Jiang"],"pdf_url":"","comment":"8 pages, 6 tables, 3 figures. Under review"},{"id":"http://arxiv.org/abs/2509.17010v2","updated":"2026-02-27T05:03:16Z","published":"2025-09-21T09:56:13Z","title":"Generalized Momenta-Based Koopman Formalism for Robust Control of Euler-Lagrangian Systems","summary":"This paper presents a novel Koopman operator formulation for Euler Lagrangian dynamics that employs an implicit generalized momentum-based state space representation, which decouples a known linear actuation channel from state dependent dynamics and makes the system more amenable to linear Koopman modeling. By leveraging this structural separation, the proposed formulation only requires to learn the unactuated dynamics rather than the complete actuation dependent system, thereby significantly reducing the number of learnable parameters, improving data efficiency, and lowering overall model complexity. In contrast, conventional explicit formulations inherently couple inputs with the state dependent terms in a nonlinear manner, making them more suitable for bilinear Koopman models, which are more computationally expensive to train and deploy. Notably, the proposed scheme enables the formulation of linear models that achieve superior prediction performance compared to conventional bilinear models while remaining substantially more efficient. To realize this framework, we present two neural network architectures that construct Koopman embeddings from actuated or unactuated data, enabling flexible and efficient modeling across different tasks. Robustness is ensured through the integration of a linear Generalized Extended State Observer (GESO), which explicitly estimates disturbances and compensates for them in real time. The combined momentum-based Koopman and GESO framework is validated through comprehensive trajectory tracking simulations and experiments on robotic manipulators, demonstrating superior accuracy, robustness, and learning efficiency relative to state of the art alternatives.","authors":["Rajpal Singh","Aditya Singh","Chidre Shravista Kashyap","Jishnu Keshavan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23670v1","updated":"2026-02-27T04:38:22Z","published":"2026-02-27T04:38:22Z","title":"Physics-Embedded Neural ODEs for Learning Antagonistic Pneumatic Artificial Muscle Dynamics","summary":"Pneumatic artificial muscles (PAMs) enable compliant actuation for soft wearable, assistive, and interactive robots. When arranged antagonistically, PAMs can provide variable impedance through co-contraction but exhibit coupled, nonlinear, and hysteretic dynamics that challenge modeling and control. This paper presents a hybrid neural ordinary differential equation (Neural ODE) framework that embeds physical structure into a learned model of antagonistic PAM dynamics. The formulation combines parametric joint mechanics and pneumatic state dynamics with a neural network force component that captures antagonistic coupling and rate-dependent hysteresis. The forward model predicts joint motion and chamber pressures with a mean R$^2$ of 0.88 across 225 co-contraction conditions. An inverse formulation, derived from the learned dynamics, computes pressure commands offline for desired motion and stiffness profiles, tracked in closed loop during execution. Experimental validation demonstrates reliable stiffness control across 126-176 N/mm and consistent impedance behavior across operating velocities, in contrast to a static model, which shows degraded stiffness consistency at higher velocities.","authors":["Xinyao Wang","Jonathan Realmuto"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.05513v2","updated":"2026-02-27T04:34:06Z","published":"2026-02-05T10:13:34Z","title":"DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter","summary":"Bimanual dexterous manipulation relies on integrating multimodal inputs to perform complex real-world tasks. To address the challenges of effectively combining these modalities, we propose DECO, a decoupled multimodal diffusion transformer that disentangles vision, proprioception, and tactile signals through specialized conditioning pathways, enabling structured and controllable integration of multimodal inputs, with a lightweight adapter for parameter-efficient injection of additional signals. Alongside DECO, we release DECO-50 dataset for bimanual dexterous manipulation with tactile sensing, consisting of 50 hours of data and over 5M frames, collected via teleoperation on real dual-arm robots. We train DECO on DECO-50 and conduct extensive real-world evaluation with over 2,000 robot rollouts. Experimental results show that DECO achieves the best performance across all tasks, with a 72.25% average success rate and a 21% improvement over the baseline. Moreover, the tactile adapter brings an additional 10.25% average success rate across all tasks and a 20% gain on complex contact-rich tasks while tuning less than 10% of the model parameters.","authors":["Xukun Li","Yu Sun","Lei Zhang","Bosheng Huang","Yibo Peng","Yuan Meng","Haojun Jiang","Shaoxuan Xie","Guocai Yao","Alois Knoll","Zhenshan Bing","Xinlong Wang","Zhenguo Sun"],"pdf_url":"","comment":"17 pages, 8 figures. Project Page: https://baai-humanoid.github.io/DECO-webpage/"},{"id":"http://arxiv.org/abs/2601.16212v3","updated":"2026-02-27T04:29:43Z","published":"2026-01-22T18:59:24Z","title":"Point Bridge: 3D Representations for Cross Domain Policy Learning","summary":"Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/","authors":["Siddhant Haldar","Lars Johannsmeier","Lerrel Pinto","Abhishek Gupta","Dieter Fox","Yashraj Narang","Ajay Mandlekar"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23654v1","updated":"2026-02-27T03:39:06Z","published":"2026-02-27T03:39:06Z","title":"SpikingTac: A Miniaturized Neuromorphic Visuotactile Sensor for High-Precision Dynamic Tactile Imprint Tracking","summary":"High-speed event-driven tactile sensors are essential for achieving human-like dynamic manipulation, yet their integration is often limited by the bulkiness of standard event cameras. This paper presents SpikingTac, a miniaturized, highly integrated neuromorphic tactile sensor featuring a custom standalone event camera module, achieved with a total material cost of less than \\$150. We construct a global dynamic state map coupled with an unsupervised denoising network to enable precise tracking at a 1000~Hz perception rate and 350~Hz tracking frequency. Addressing the viscoelastic hysteresis of silicone elastomers, we propose a hysteresis-aware incremental update law with a spatial gain damping mechanism. Experimental results demonstrate exceptional zero-point stability, achieving a 100\\% return-to-origin success rate with a minimal mean bias of 0.8039 pixels, even under extreme torsional deformations. In dynamic tasks, SpikingTac limits the obstacle-avoidance overshoot to 6.2~mm, representing a 5-fold performance improvement over conventional frame-based sensors. Furthermore, the sensor achieves sub-millimeter geometric accuracy, with Root Mean Square Error (RMSE) of 0.0952~mm in localization and 0.0452~mm in radius measurement.","authors":["Tianyu Jiang","Chaofan Zhang","Shaolin Zhang","Shaowei Cui","Shuo Wang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23648v1","updated":"2026-02-27T03:33:10Z","published":"2026-02-27T03:33:10Z","title":"FAVLA: A Force-Adaptive Fast-Slow VLA model for Contact-Rich Robotic Manipulation","summary":"Force/torque feedback can substantially improve Vision-Language-Action (VLA) models on contact-rich manipulation, but most existing approaches fuse all modalities at a single operating frequency. This design ignores the mismatched sampling rates of real robot sensors, forcing downsampling of the high-frequency contact cues needed for reactive correction. Combined with common VLM-action-expert (AE) pipelines that execute action chunks largely open loop between expensive VLM updates, unified-frequency fusion often yields delayed responses to impacts, stick-slip, and force spikes. We propose FAVLA, a force-adaptive fast-slow VLA that decouples slow perception planning from fast contact-aware control. FAVLA runs a slow VLM at a fixed low frequency to encode modalities to produce latent representations and to predict near-future force variation. A fast AE then executes at a variable high frequency, conditioning on the latest force sequence data to generate reactive actions. We further introduce a force adapter that injects high-frequency force features into multiple AE layers, and adaptively schedules the AE's execution frequency based on the VLM's predicted force variation. Extensive experiments on contact-rich tasks demonstrate that FAVLA significantly outperforms baselines, achieving superior reactivity and success rates, especially with a smaller contact force during manipulation.","authors":["Yao Li","Peiyuan Tang","Wuyang Zhang","Chengyang Zhu","Yifan Duan","Weikai Shi","Xiaodong Zhang","Zijiang Yang","Jianmin Ji","Yanyong Zhang"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.17049v2","updated":"2026-02-27T03:23:32Z","published":"2026-02-19T03:42:15Z","title":"IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents","summary":"Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and inefficiency. We present IntentCUA, a multi-agent computer-use framework designed to stabilize long-horizon execution through intent-aligned plan memory. A Planner, Plan-Optimizer, and Critic coordinate over shared memory that abstracts raw interaction traces into multi-view intent representations and reusable skills. At runtime, intent prototypes retrieve subgroup-aligned skills and inject them into partial plans, reducing redundant re-planning and mitigating error propagation across desktop applications. In end-to-end evaluations, IntentCUA achieved a 74.83% task success rate with a Step Efficiency Ratio of 0.91, outperforming RL-based and trajectory-centric baselines. Ablations show that multi-view intent abstraction and shared plan memory jointly improve execution stability, with the cooperative multi-agent loop providing the largest gains on long-horizon tasks. These results highlight that system-level intent abstraction and memory-grounded coordination are key to reliable and efficient desktop automation in large, dynamic environments.","authors":["Seoyoung Lee","Seobin Yoon","Seongbeen Lee","Yoojung Chun","Dayoung Park","Doyeon Kim","Joo Yong Sim"],"pdf_url":"","comment":"12 pages, 9 figures, AAMAS 2026"},{"id":"http://arxiv.org/abs/2209.12133v3","updated":"2026-02-27T02:52:53Z","published":"2022-09-25T03:29:37Z","title":"Development of a Deep Learning-Driven Control Framework for Exoskeleton Robots","summary":"The purpose of this study is to develop a computationally efficient deep learning based control framework for high degree of freedom exoskeleton robots to address the real time computational limitations associated with conventional model based control. A parallel structured deep neural network was designed for a seven degree of freedom human lower extremity exoskeleton robot. The network consists of four layers with 49 densely connected neurons and was trained using physics based data generated from the analytical dynamic model. During real time implementation, the trained neural network predicts joint torque commands required for trajectory tracking, while a proportional derivative controller compensates for residual prediction errors. Stability of the proposed control scheme was analytically established, and robustness to parameter variations was evaluated using analysis of variance. Comparative simulations were conducted against computed torque, model reference computed torque, sliding mode, adaptive, and linear quadratic controllers under identical robot dynamics. Results demonstrate accurate trajectory tracking with torque profiles comparable to conventional nonlinear controllers while reducing computational burden. These findings suggest that the proposed deep learning based hybrid controller offers an efficient and robust alternative for controlling multi degree of freedom exoskeleton robots.","authors":["Sk Hasan"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.10594v2","updated":"2026-02-27T02:46:10Z","published":"2026-02-11T07:32:27Z","title":"Flow-Enabled Generalization to Human Demonstrations in Few-Shot Imitation Learning","summary":"Imitation Learning (IL) enables robots to learn complex skills from demonstrations without explicit task modeling, but it typically requires large amounts of demonstrations, creating significant collection costs. Prior work has investigated using flow as an intermediate representation to enable the use of human videos as a substitute, thereby reducing the amount of required robot demonstrations. However, most prior work has focused on the flow, either on the object or on specific points of the robot/hand, which cannot describe the motion of interaction. Meanwhile, relying on flow to achieve generalization to scenarios observed only in human videos remains limited, as flow alone cannot capture precise motion details. Furthermore, conditioning on scene observation to produce precise actions may cause the flow-conditioned policy to overfit to training tasks and weaken the generalization indicated by the flow. To address these gaps, we propose SFCrP, which includes a Scene Flow prediction model for Cross-embodiment learning (SFCr) and a Flow and Cropped point cloud conditioned Policy (FCrP). SFCr learns from both robot and human videos and predicts any point trajectories. FCrP follows the general flow motion and adjusts the action based on observations for precision tasks. Our method outperforms SOTA baselines across various real-world task settings, while also exhibiting strong spatial and instance generalization to scenarios seen only in human videos.","authors":["Runze Tang","Penny Sweetser"],"pdf_url":"","comment":"Accepted to ICRA 2026"},{"id":"http://arxiv.org/abs/2602.23109v2","updated":"2026-02-27T02:36:06Z","published":"2026-02-26T15:22:07Z","title":"Towards Intelligible Human-Robot Interaction: An Active Inference Approach to Occluded Pedestrian Scenarios","summary":"The sudden appearance of occluded pedestrians presents a critical safety challenge in autonomous driving. Conventional rule-based or purely data-driven approaches struggle with the inherent high uncertainty of these long-tail scenarios. To tackle this challenge, we propose a novel framework grounded in Active Inference, which endows the agent with a human-like, belief-driven mechanism. Our framework leverages a Rao-Blackwellized Particle Filter (RBPF) to efficiently estimate the pedestrian's hybrid state. To emulate human-like cognitive processes under uncertainty, we introduce a Conditional Belief Reset mechanism and a Hypothesis Injection technique to explicitly model beliefs about the pedestrian's multiple latent intentions. Planning is achieved via a Cross-Entropy Method (CEM) enhanced Model Predictive Path Integral (MPPI) controller, which synergizes the efficient, iterative search of CEM with the inherent robustness of MPPI. Simulation experiments demonstrate that our approach significantly reduces the collision rate compared to reactive, rule-based, and reinforcement learning (RL) baselines, while also exhibiting explainable and human-like driving behavior that reflects the agent's internal belief state.","authors":["Kai Chen","Yuyao Huang","Guang Chen"],"pdf_url":"","comment":"14 pages, 6 figures, Proceedings of the 2026 ACM/IEEE International Conference on Human-Robot Interaction (HRI'26)"},{"id":"http://arxiv.org/abs/2505.10018v3","updated":"2026-02-27T02:33:50Z","published":"2025-05-15T06:59:48Z","title":"LEMON-Mapping: Loop-Enhanced Large-Scale Multi-Session Point Cloud Merging and Optimization for Globally Consistent Mapping","summary":"Multi-robot collaboration is becoming increasingly critical and presents significant challenges in modern robotics, especially for building a globally consistent, accurate map. Traditional multi-robot pose graph optimization (PGO) methods ensure basic global consistency but ignore the geometric structure of the map, and only use loop closures as constraints between pose nodes, leading to divergence and blurring in overlapping regions. To address this issue, we propose LEMON-Mapping, a loop-enhanced framework for large-scale, multi-session point cloud fusion and optimization. We re-examine the role of loops for multi-robot mapping and introduce three key innovations. First, we develop a robust loop processing mechanism that rejects outliers and a loop recall strategy to recover mistakenly removed but valid loops. Second, we introduce spatial bundle adjustment for multi-robot maps, reducing divergence and eliminating blurring in overlaps. Third, we design a PGO-based approach that leverages refined bundle adjustment constraints to propagate local accuracy to the entire map. We validate LEMON-Mapping on several public datasets and a self-collected dataset. The experimental results show superior mapping accuracy and global consistency of our framework compared to traditional merging methods. Scalability experiments also demonstrate its strong capability to handle scenarios involving numerous robots.","authors":["Lijie Wang","Xiaoyi Zhong","Ziyi Xu","Kaixin Chai","Anke Zhao","Tianyu Zhao","Changjian Jiang","Qianhao Wang","Fei Gao"],"pdf_url":"","comment":null},{"id":"http://arxiv.org/abs/2602.23607v1","updated":"2026-02-27T02:16:26Z","published":"2026-02-27T02:16:26Z","title":"MicroPush: A Simulator and Benchmark for Contact-Rich Cell Pushing and Assembly with a Magnetic Rolling Microrobot","summary":"Magnetic rolling microrobots enable gentle manipulation in confined microfluidic environments, yet autonomy for contact-rich behaviors such as cell pushing and multi-target assembly remains difficult to develop and evaluate reproducibly. We present MicroPush, an open-source simulator and benchmark suite for magnetic rolling microrobots in cluttered 2D scenes. MicroPush combines an overdamped interaction model with contact-aware stick--slip effects, lightweight near-field damping, optional Poiseuille background flow, and a calibrated mapping from actuation frequency to free-space rolling speed. On top of the simulator core, we provide a modular planning--control stack with a two-phase strategy for contact establishment and goal-directed pushing, together with a deterministic benchmark protocol with fixed tasks, staged execution, and unified CSV logging for single-object transport and hexagonal assembly. We report success, time, and tracking metrics, and an actuation-variation measure $E_{Δω}$. Results show that controller stability dominates performance under flow disturbances, while planner choice can influence command smoothness over long-horizon sequences via waypoint progression. MicroPush enables reproducible comparison and ablation of planning, control, and learning methods for microscale contact-rich micromanipulation.","authors":["Yanda Yang","Sambeeta Das"],"pdf_url":"","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2602.22896v2","updated":"2026-02-27T01:54:01Z","published":"2026-02-26T11:34:36Z","title":"DySL-VLA: Efficient Vision-Language-Action Model Inference via Dynamic-Static Layer-Skipping for Robot Manipulation","summary":"Vision-Language-Action (VLA) models have shown remarkable success in robotic tasks like manipulation by fusing a language model's reasoning with a vision model's 3D understanding. However, their high computational cost remains a major obstacle for real-world applications that require real-time performance. We observe that the actions within a task have varying levels of importance: critical steps demand high precision, while less important ones can tolerate more variance. Leveraging this insight, we propose DySL-VLA, a novel framework that addresses computational cost by dynamically skipping VLA layers based on each action's importance. DySL-VLA categorizes its layers into two types: informative layers, which are consistently executed, and incremental layers, which can be selectively skipped. To intelligently skip layers without sacrificing accuracy, we invent a prior-post skipping guidance mechanism to determine when to initiate layer-skipping. We also propose a skip-aware two-stage knowledge distillation algorithm to efficiently train a standard VLA into a DySL-VLA. Our experiments indicate that DySL-VLA achieves 2.1% improvement in success length over Deer-VLA on the Calvin dataset, while simultaneously reducing trainable parameters by a factor of 85.7 and providing a 3.75x speedup relative to the RoboFlamingo baseline at iso-accuracy. Our code is available on https://github.com/PKU-SEC-Lab/DYSL_VLA.","authors":["Zebin Yang","Yijiahao Qi","Tong Xie","Bo Yu","Shaoshan Liu","Meng Li"],"pdf_url":"","comment":"DAC 2026"},{"id":"http://arxiv.org/abs/2602.23592v1","updated":"2026-02-27T01:48:07Z","published":"2026-02-27T01:48:07Z","title":"KEEP: A KV-Cache-Centric Memory Management System for Efficient Embodied Planning","summary":"Memory-augmented Large Language Models (LLMs) have demonstrated remarkable capability for complex and long-horizon embodied planning. By keeping track of past experiences and environmental states, memory enables LLMs to maintain a global view, thereby avoiding repetitive exploration. However, existing approaches often store the memory as raw text, leading to excessively long prompts and high prefill latency. While it is possible to store and reuse the KV caches, the efficiency benefits are greatly undermined due to frequent KV cache updates. In this paper, we propose KEEP, a KV-cache-centric memory management system for efficient embodied planning. KEEP features 3 key innovations: (1) a Static-Dynamic Memory Construction algorithm that reduces KV cache recomputation by mixed-granularity memory group; (2) a Multi-hop Memory Re-computation algorithm that dynamically identifies important cross-attention among different memory groups and reconstructs memory interactions iteratively; (3) a Layer-balanced Memory Loading that eliminates unbalanced KV cache loading and cross-attention computation across different layers. Extensive experimental results have demonstrated that KEEP achieves 2.68x speedup with negligible accuracy loss compared with text-based memory methods on ALFRED dataset. Compared with the KV re-computation method CacheBlend (EuroSys'25), KEEP shows 4.13% success rate improvement and 1.90x time-to-first-token (TTFT) reduction. Our code is available on https://github.com/PKU-SEC-Lab/KEEP_Embodied_Memory.","authors":["Zebin Yang","Tong Xie","Baotong Lu","Shaoshan Liu","Bo Yu","Meng Li"],"pdf_url":"","comment":"DAC 2026"},{"id":"http://arxiv.org/abs/2602.23583v1","updated":"2026-02-27T01:23:35Z","published":"2026-02-27T01:23:35Z","title":"VCA: Vision-Click-Action Framework for Precise Manipulation of Segmented Objects in Target Ambiguous Environments","summary":"The reliance on language in Vision-Language-Action (VLA) models introduces ambiguity, cognitive overhead, and difficulties in precise object identification and sequential task execution, particularly in environments with multiple visually similar objects. To address these limitations, we propose Vision-Click-Action (VCA), a framework that replaces verbose textual commands with direct, click-based visual interaction using pretrained segmentation models. By allowing operators to specify target objects clearly through visual selection in the robot's 2D camera view, VCA reduces interpretation errors, lowers cognitive load, and provides a practical and scalable alternative to language-driven interfaces for real-world robotic manipulation. Experimental results validate that the proposed VCA framework achieves effective instance-level manipulation of specified target objects. Experiment videos are available at https://robrosinc.github.io/vca/.","authors":["Donggeon Kim","Seungwon Jan","Hyeonjun Park","Daegyu Lim"],"pdf_url":"","comment":"Submitted to UR 2026"},{"id":"http://arxiv.org/abs/2602.23576v1","updated":"2026-02-27T01:05:58Z","published":"2026-02-27T01:05:58Z","title":"Tilt-X: Enabling Compliant Aerial Manipulation through a Tiltable-Extensible Continuum Manipulator","summary":"Aerial manipulators extend the reach and manipulation capabilities of uncrewed multirotor aerial vehicles for inspection, agriculture, sampling, and delivery. Continuum arm aerial manipulation systems offer lightweight, dexterous, and compliant interaction opportunities. Existing designs allow manipulation only below the UAV which restricts their deployability in multiple directions and through clutter. They are also sensitive to propeller downwash. Addressing these limitations, we present Tilt-X, a continuum arm aerial manipulator that integrates a tilting mechanism, a telescopic stage, and a cable-driven continuum section. We present its design and kinematic model and validate it through flight demonstrations. Tilt-X enables a volumetric workspace with up to 75 mm extension and planar orientations between 0$^\\circ$ to 90$^\\circ$. Experiments comparing end effector pose with and without downwash quantitatively measure its accuracy, providing critical evidence to guide the design and control of reliable aerial manipulators. Results show stabilisation of end effector pose as the manipulator extends out of the propeller influence zone.","authors":["Anuraj Uthayasooriyan","Krishna Manaswi Digumarti","Jack Breward","Fernando Vanegas","Julian Galvez-Serna","Felipe Gonzalez"],"pdf_url":"","comment":"Accepted to IEEE International Conference on Robotics and Automation (ICRA) 2026"}]}}